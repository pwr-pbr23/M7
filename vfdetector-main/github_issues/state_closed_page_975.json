[{"number": 24163, "title": "django tensorflow ", "body": "django version:2.1.1\r\npython version:3.5.2\r\ntensorflow-gpu version:1.9.0\r\nkeras version:2.2.4\r\nanaconda:4.5.11\r\nI have a tensorflow project, I ran it with pycharm and it worked. then I want to run it in django ,but there have some import problem. through set source path or  append os.path, it didn't work.\r\nthe frame of the project:\r\ntmp/\r\n---ocr_django/\r\n-------ocr_django/\r\n----------ocr/\r\n-------------ctpn/\r\n-------------demo/\r\n-------------densenet/\r\n-------------train/\r\n-------------__init__.py\r\n-------------demo.py\r\n-------------ocr.py\r\n-------------recongnize.py\r\n----------__init__.py      \r\n----------original.py\r\n----------setting.py\r\n----------test.py\r\n----------urls.py\r\n----------view.py\r\n----------wsgi.py\r\n\r\n- the problem as follow:\r\nTraceback (most recent call last):\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/utils/autoreload.py\", line 225, in wrapper\r\n    fn(*args, **kwargs)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/core/management/commands/runserver.py\", line 117, in inner_run\r\n    self.check(display_num_errors=True)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/core/management/base.py\", line 379, in check\r\n    include_deployment_checks=include_deployment_checks,\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/core/management/base.py\", line 366, in _run_checks\r\n    return checks.run_checks(**kwargs)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/core/checks/registry.py\", line 71, in run_checks\r\n    new_errors = check(app_configs=app_configs)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/core/checks/urls.py\", line 13, in check_url_config\r\n    return check_resolver(resolver)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/core/checks/urls.py\", line 23, in check_resolver\r\n    return check_method()\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/urls/resolvers.py\", line 396, in check\r\n    for pattern in self.url_patterns:\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/utils/functional.py\", line 37, in __get__\r\n    res = instance.__dict__[self.name] = self.func(instance)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/urls/resolvers.py\", line 533, in url_patterns\r\n    patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/utils/functional.py\", line 37, in __get__\r\n    res = instance.__dict__[self.name] = self.func(instance)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/django/urls/resolvers.py\", line 526, in urlconf_module\r\n    return import_module(self.urlconf_name)\r\n  File \"/home/cq/anaconda3/lib/python3.5/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/urls.py\", line 18, in <module>\r\n    from . import view\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/view.py\", line 22, in <module>\r\n    from .ocr.recognize import recognize\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/recognize.py\", line 7, in <module>\r\n    from .ctpn.text_detect import text_detect\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/text_detect.py\", line 7, in <module>\r\n    from .lib.utils.timer import Timer\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/__init__.py\", line 4, in <module>\r\n    from ocr_django.ocr.ctpn.lib import fast_rcnn\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/fast_rcnn/__init__.py\", line 5, in <module>\r\n    from . import train\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/fast_rcnn/train.py\", line 5, in <module>\r\n    from ..roi_data_layer.layer import RoIDataLayer\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/roi_data_layer/__init__.py\", line 4, in <module>\r\n    from . import roidb\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/roi_data_layer/roidb.py\", line 5, in <module>\r\n    from ocr_django.ocr.ctpn.lib.utils.bbox import bbox_overlaps\r\n  File \"/home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/utils/__init__.py\", line 11, in <module>\r\n    from ocr_django.ocr.ctpn.lib.utils import bbox\r\nImportError: cannot import name 'bbox'\r\n\r\nthere are three files named:\"bbox.c\", \"bbox.pyx\",\"bbox.cpython-36m-x86_64-linux-gnu.so\" in the package of ocr/ctpn/lib/utils. I've found a lot of solutions online, but none of them succeeded.\r\nthe solutions include:\r\n1.right-click the project name in pycharm - > Mark Directory as - > source root to set the package as sources root\r\n2.file - >setting - >project structure to set the package as source\r\n3.change the code \"from . import bbox\" in /home/cq/\u684c\u9762/tmp/ocr_django/ocr_django/ocr/ctpn/lib/utils/__init__.py to \"from ocr_django.ocr.ctpn.lib.utils import bbox\"\r\n\r\n      \r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 24162, "title": "bazel build issue ('tensorflow::DeviceBase::name': must return a value)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.10\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.19.1\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 9\r\n\r\n**Describe the problem**\r\n> c:\\users\\adm\\_bazel_adm\\atj3lgjk\\execroot\\org_tensorflow\\tensorflow\\core\\framework\\device_base.cc(34) : error C4716: 'tensorflow::DeviceBase::name': must return a value\r\n> c:\\users\\adm\\_bazel_adm\\atj3lgjk\\execroot\\org_tensorflow\\tensorflow\\core\\framework\\device_base.cc(30) : error C4716: 'tensorflow::DeviceBase::attributes': must return a value\r\n> ERROR: I/O error while writing action log: null during journal append\r\n> Target //tensorflow/tools/graph_transforms:transform_graph failed to build\r\n\r\n\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n \r\n\r\n- bazel build tensorflow/tools/graph_transforms:transform_graph\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please let us know if this still happen with the latest Tensorflow version used with Bazel 0.18 or 0.15", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "> It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?\r\n\r\nWin 10 has always this problem, so we have changed to use the Linux system. The problem is solved in the Linux system. Thanks.", "I got the same exception now:\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version: 1.15\r\nPython version: 3.6\r\nInstalled using virtualenv? pip? conda?: pip\r\nBazel version (if compiling from source): 0.25.2\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 10\r\n\r\nTrying to compile debug mode:\r\nbazel build -c dbg --strip=never --compilation_mode=dbg --config=opt --config=cuda --copt=/FS --linkopt=/DEBUG --copt=-nvcc_options=disable-warnings --define=no_tensorflow_py_deps=true -s --explain=explain.txt --verbose_explanations --subcommands=pretty_print //tensorflow/cc/example:example\r\n\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nd:\\tensorflow_gpu_v4\\s4itiot2\\execroot\\org_tensorflow\\tensorflow\\core\\framework\\device_base.cc(34) : error C4716: 'tensorflow::DeviceBase::attributes': must return a value\r\nd:\\tensorflow_gpu_v4\\s4itiot2\\execroot\\org_tensorflow\\tensorflow\\core\\framework\\device_base.cc(38) : error C4716: 'tensorflow::DeviceBase::name': must return a value\r\nTarget //tensorflow/cc/example:example failed to build\r\n\r\nPlease reopen the issue", "I solved issue by editing device_base.cc:\r\n\r\nconst DeviceAttributes& DeviceBase::attributes() const {\r\n  LOG(FATAL) << \"Device does not implement attributes()\";\r\n  return attributes();\r\n}\r\n\r\nconst string& DeviceBase::name() const {\r\n  LOG(FATAL) << \"Device does not implement name()\";\r\n  return \"\";\r\n}"]}, {"number": 24161, "title": " tf.image.resize_bilinear ops have not support", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source):1.12\r\n\r\n\r\ni want to convert deeplabv3  mobilenet to tflite but it do not support?\r\nwhen will you add the 'tf.image.resize_bilinear' ops in tensorflow lite?thank you.", "comments": ["We do have ResizeBilinear op in TensorFlow Lite.\r\nAlso, please see below if the op you are interested is not same as the version in TFLite: \r\n\r\nAs we work toward fleshing out the builtin op library for TensorFlow Lite, we've been working on an experimental feature that allows using select TensorFlow ops from within the TensorFlow Lite runtime. The goal is to help reduce some of the friction for using models that rely on ops not yet natively supported by TensorFlow Lite (at the cost of increased binary size). This feature requires opting in during model conversion, as well as adding an additional dependency. More details can be found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md).\r\n\r\nFeedback is very much appreciated (either via GitHub or directly via tflite@tensorflow.org), and we'll be adding and refining functionality over the coming weeks. Cheers.", "Actually, `ResizeBilinear` should already be supported. Can you paste the output from your conversion attempt?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "The nightly TF/TFLite builds should have resize_bilinear, and it will also be in the upcoming 1.13 release.", "System Information:\r\nTensorFlow 2.3\r\nModel Architecture - MobileNet V1\r\nArduino_TensorFlow Lite 2.4.0 Alpha\r\nI fined Tuned Mobilenet V1 for face recoginition and later quantized using full integer Quantization Technique and later converted it to .cc format to upload it to Arduino Nano 33 BLE Sense. I used all_ops_resolver function but when i ran the Model on Microcontroller, invoke failed() and error message which was shown on Serial Monitor was \" **Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3'. An older version of this builtin might be supported. Are you using an old TFLite binary with a newer model?**\". Can anyone suggest me, how i can work around this error message.\r\n\r\n"]}, {"number": 24160, "title": "Update op_level_cost_estimator.cc", "body": "wccftech.com/nvidia-gtx-1080-gp104-die-shot\r\ntechpowerup.com/gpu-specs/geforce-rtx-2080-ti.c3305", "comments": ["yes, as per @jlebar link, SM 6.1 and 6.2 should have 128, not 64 'cores', otherwise grappler will probably optimize for 2x lower gflops then available. ", "@MikalaiDrabovich will you update the PR to reflect the documentation from NVIDIA?", "> @MikalaiDrabovich will you update the PR to reflect the documentation from NVIDIA?\r\n\r\n@MikalaiDrabovich gentle ping to update PR", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 24159, "title": "dynamic_rnn claims it supports nested tuples but actually doesn't", "body": "**System information**\r\n- TensorFlow version:  1.12.0\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\r\n\r\nThe documentation of dynamic_rnn claims it can accept **nested tuples**. I quote:\r\n> inputs: The RNN inputs. If time_major == False (default), this must be a Tensor of shape: [batch_size, max_time, ...], or a nested tuple of such elements. If time_major == True, this must be a Tensor of shape: [max_time, batch_size, ...], **_or a nested tuple of such elements_**. This may also be a (possibly nested) tuple of Tensors satisfying this property ...\r\n\r\nSo I write a simple demo to test the feature\r\n```python\r\n# encoding=utf-8-sig\r\nimport tensorflow as tf\r\n\r\nbatch_size = None\r\n\r\n# nested tuple\r\nx_placeholder = [tf.placeholder(tf.float32, [batch_size, 10, 20], 'input_1'),\r\n                 [tf.placeholder(tf.float32, [batch_size, 10, 20], 'input_2'),\r\n                 tf.placeholder(tf.float32, [batch_size, 10, 20], 'input_3')]]\r\nsequence_size = tf.placeholder(tf.int32, [batch_size], 'sequence_size')\r\ncell = tf.nn.rnn_cell.LSTMCell(15)\r\ntf.nn.dynamic_rnn(cell=cell, inputs=x_placeholder, sequence_length=sequence_size, \r\n                  initial_state=None, time_major=True, dtype=tf.float32)\r\n```\r\n\r\nand the console raises a error:\r\n> ValueError: Layer lstm_cell_1 expects 1 inputs, but it received 3 input tensors. Inputs received: [<tf.Tensor 'rnn/while/TensorArrayReadV3:0' shape=(10, 20) dtype=float32>, <tf.Tensor 'rnn/while/TensorArrayReadV3_1:0' shape=(10, 20) dtype=float32>, <tf.Tensor 'rnn/while/TensorArrayReadV3_2:0' shape=(10, 20) dtype=float32>]\r\n\r\nand I find the place that raise the error\r\nthe line 826 of tensorflow/tensorflow/python/ops/rnn.py defines how to generate the new state, i.e.,\r\n```python\r\ncall_cell = lambda: cell(input_t, state)\r\n```\r\nIn the demo, the cell function is actually __call__() function of LSTMCell. And the documentation of LSTMCell claims the input must be a 2-D tensor. Nevertheless, if we feed a nested tuple to dynamic_rnn function, the input must be a 3-D tensor, so the LSTM raise a error\r\n\r\nSo, my question is, is dynamic_rnn really support nested tuples ?", "comments": ["It's up to your cell to support nested tuples.  LSTMCell cannot handle inputs of this form because the underlying algorithm only handles one input tensor per frame.  You have to write your own `RNNCell` or `LayerRNNCell` if you want to be able to handle more than one tensor per frame.", "more concretely, you have to do:\r\n\r\n```python\r\nclass MyCell(LayerRNNCell):\r\n  def __init__(self, ...):\r\n    ...\r\n    self.built = True\r\n\r\n  def build(input_shape):\r\n     ...\r\n\r\n  def call(inputs, state):\r\n     input0, (input1, input2) = inputs\r\n     # process the 3 tensors above and emit an output and state matching self.output_size, self.state_size\r\n```", "> more concretely, you have to do:\r\n> \r\n> ```python\r\n> class MyCell(LayerRNNCell):\r\n>   def __init__(self, ...):\r\n>     ...\r\n>     self.built = True\r\n> \r\n>   def build(input_shape):\r\n>      ...\r\n> \r\n>   def call(inputs, state):\r\n>      input0, (input1, input2) = inputs\r\n>      # process the 3 tensors above and emit an output and state matching self.output_size, self.state_size\r\n> ```\r\n\r\nThank you very much"]}, {"number": 24158, "title": "Xla devices", "body": "This PR constructs XLA_GPU devices according to session configuration settings allowing users to control XLA_GPU devices with session options. This solves the issues with multiple TF processes in a host.", "comments": ["I couldn't be able to find why windows tests failed but probably unrelated with this pr. @ymodak @jlebar do you agree?", "> I couldn't be able to find why windows tests failed but probably unrelated with this pr. @ymodak @jlebar do you agree?\r\n\r\nYes.  I am trying to submit this now, but it takes some effort on our side.", "@jlebar I didn't mean to push, I just wanted to know if it break something unintentionally.", "@jlebar it looks like this is only a partial solution and I have to implement suppression of stream executors as well. Let me update this PR before you merge so that it is complete solution.", "The PR is already in the process of being merged.  Let's just create a new one."]}, {"number": 24157, "title": "Make MakeCsvDatasetTest support eager mode", "body": "This PR enables `MakeCsvDatasetTest` to run in both `graph` and `eager` modes.", "comments": ["@jsimsa Could you help review this PR when you have time?", "@rachellim Thanks for your detailed comments! This PR has been revised accordingly. Could you have another look at the changes?", "@harshini-gadige Thanks for running the test. I just submit a commit to remove an unused import, which causes the failure of Ubuntu Sanity test. Could you help re-trigger the test? Could @rachellim please re-approve the PR?"]}, {"number": 24156, "title": "[ROCm] StreamExecutor logic for ROCm platform (PR 20709 / 22669 continued)", "body": "/cc @timshen91 \r\n\r\nhi Tim\r\n\r\nThis is a continuation of the PR #22669\r\n\r\nThis PR contains the changes you requested in your comments in PR #22669. (specifically the changes to have common header files for CUDA/ROCm in the `tensorflow/stream_executor/gpu/` directory)\r\n\r\nThe changes are broken down into multiple commits to make ti easier to code review (as per your request). Once the review process in done, and we are ready to merge, we can squash commits into fewer / one.\r\n\r\nI have `git mv`'d the header files from the stream_executor/cuda to the stream_executor/gpu dir, to preserve their change history\r\n\r\nFor the time being I have left in the CUDA specific *comments* in the header files within `stream_executor/gpu` dir. Let me know if it is okay to remove them.\r\n\r\nThanks\r\n\r\ndeven", "comments": ["Thanks Deven, this PR looks much better!\r\n\r\nOverall the commits look good, I have some comments in the second last one, regarding merging more files.\r\n\r\nOne last thing: can you `git clang-format` all files in the end?", "@timshen91 \r\n\r\nHi Tim,\r\n\r\nI have pushed commits that address some of the changes you requested. For the rest, I need further input from you.\r\n\r\nI will `git clang-format` all the changes once we have resolve all the issues.\r\n\r\nThanks\r\n\r\ndeven", "@deven-amd could you please resolve the conflict?", "@timshen91 @rmlarsen \r\n\r\nI will push out a rebase shortly to resolve the conflict", "hmm....I did not request a review from `azaks2` and `chsigg` ... do not know what is going on.\r\n", "@timshen91 any update on this PR?", "@deven-amd Sorry, I'll get back to the PR in one day.", "Looks good. Please resolve the conflicts and clang-format the files.", "added clang-formatting for all changes and rebased to remove the merge conflict", "hi Tim, \r\n\r\nAfter I did the rebase, I am running into the following error when I try to do a TF build (with --config=cuda) \r\n\r\n```\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cuda/crosstool/BUILD:29:1: @local_config_cuda//crosstool:cc-compiler-local: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cuda/crosstool/BUILD:48:1: @local_config_cuda//crosstool:cc-compiler-darwin: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cuda/crosstool/BUILD:63:1: @local_config_cuda//crosstool:cc-compiler-windows: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\n```\r\n\r\nThe changes in this PR do not touch the CUDA specific settings in the BAZEL build files, so I do not know what is causing this error. Only thing I can think off is that I picked up some commit with the rebase that breaks the build.\r\n\r\nI get the same error with the TF build with `--config==rocm` as well. \r\nBoth ROCm and CUDA builds working fine before the rebasing.\r\n\r\ndeven\r\n\r\n", "Removing @azaks2 and @chsigg unless they also want to review this (which seems not intended).", "> hi Tim,\r\n> \r\n> After I did the rebase, I am running into the following error when I try to do a TF build (with --config=cuda)\r\n> \r\n> ```\r\n> ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cuda/crosstool/BUILD:29:1: @local_config_cuda//crosstool:cc-compiler-local: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\n> ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cuda/crosstool/BUILD:48:1: @local_config_cuda//crosstool:cc-compiler-darwin: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\n> ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cuda/crosstool/BUILD:63:1: @local_config_cuda//crosstool:cc-compiler-windows: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\n> ```\r\n> The changes in this PR do not touch the CUDA specific settings in the BAZEL build files, so I do not know what is causing this error. Only thing I can think off is that I picked up some commit with the rebase that breaks the build.\r\n> \r\n> I get the same error with the TF build with `--config==rocm` as well.\r\n> Both ROCm and CUDA builds working fine before the rebasing.\r\n> \r\n> deven\r\n\r\nI was unaware of such an error. I'll take a look later.", "I get the same error, when I try to a TF build (with --config=cuda) using the tensorflow repo as well....something is broken on the tip :(\r\n\r\n```\r\nroot@3cb559125c7d:~/google_tensorflow# git log -1\r\ncommit c0b2e3eb7c2c02b3725bdda834e7b5d2875e1cf0\r\nAuthor: A. Unique TensorFlower <gardener@tensorflow.org>\r\nDate:   Wed Dec 12 17:00:06 2018 -0800\r\n\r\n    Adds unicode_decode and unicode_decode_with_offsets ops, which decode strings into unicode codepoints.\r\n    \r\n    Adds unicode_split and unicode_split_with_offset ops, which split strings into unicode characters.\r\n    \r\n    RELNOTES: Adds unicode_decode, unicode_decode_with_offsets, unicode_split, and unicode_split_with_offset ops.\r\n    PiperOrigin-RevId: 225281768\r\n\r\n\r\nroot@3cb559125c7d:~/google_tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: @local_config_cuda//crosstool:cc-compiler-local: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:48:1: @local_config_cuda//crosstool:cc-compiler-darwin: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:63:1: @local_config_cuda//crosstool:cc-compiler-windows: no such attribute 'toolchain_identifier' in 'cc_toolchain' rule\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:83:1: Target '@local_config_cuda//crosstool:clang/bin/crosstool_wrapper_driver_is_not_gcc' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:crosstool_wrapper_driver_is_not_gcc'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:crosstool_wrapper_driver_is_not_gcc' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:crosstool_wrapper_driver_is_not_gcc' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/crosstool/BUILD:29:1: Target '@local_config_cuda//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_cuda//crosstool:cc-compiler-local'\r\nERROR: /root/.cache/bazel/_bazel_root/dc5f19088b30784325d5a276b57d6400/external/local_config_cuda/cuda/BUILD:40:1: every rule of type cc_library implicitly depends upon the target '@local_config_cuda//crosstool:cc-compiler-local', but this target could not be found because of: Target '@local_config_cuda//crosstool:cc-compiler-local' contains an error and its package is in error\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 3.024s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (61 packages loaded)\r\n    currently loading: tensorflow/python ... (5 packages)\r\n```", "figure out the cause of my build errors...it was the bazel version.\r\n\r\nI was using version `0.15.0` based upon the version used in the tensorflow repo here \r\n(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_bazel.sh#L18)\r\n\r\nMoving up the bazel version to `0.19.2` seems to fix the build errors shown above. Still do not know why this update to bazel is required, but I am happy that the build is working again.\r\n\r\nThere seems to have been some garbage chars introduced in one file by my previous commit (to clang-format the changes), which results in a build error. I will be pushing out a commit shortly to fix this.\r\n\r\n", "```\r\n@deven-amd deven-amd dismissed timshen91\u2019s stale review via 70c2bd8 4 hours from now\r\n```\r\n\r\ndon't know whats going on with github...that is the second time in this PR it has attributed to me something I did not do! (first being adding 2 reviewers)", "@timshen91 @rmlarsen \r\n\r\nClicking on the \"Details\" link (in feedback/copybara) results in a \"Page Not Found\" error for me.\r\n\r\nHow do I go about figuring out what failed?\r\n\r\nThanks\r\n\r\ndeven", "Integrating the commits into our internal repo proves to be challenging. Our internal repo has a totally different set of BUILD files, and I have to figure them out.\r\n\r\nIt may take a long time to upstream all your commits. It may also take multiple tensorflow master commits.", "@timshen91 any update on the status of this PR? \r\n\r\nthanks. ", "@deven-amd I'm working on some preliminary patches for stream_executor build files. It may take some 1 more week (excluding the holidays), but it will make this PR much easier to check in.", "@timshen91  Thank you for the quick update. Please let me know if you need anything done on my end to help you out.\r\n\r\ndeven", "@timshen91 \r\n\r\nI have rebased the PR today to resolve merge conflicts that have sneaked in over the last couple of weeks. just FYI.", "@deven-amd , much appreciated on the rebases.\r\n\r\nI committed https://github.com/tensorflow/tensorflow/commit/530d1b267f124fdb7dd6ce65b94423b8801152cd which makes our internal integration of github PRs much easier from now on. Can you rebase onto the top?", "@timshen91 , @deven-amd is on vacation and I'll rebase this PR. IIRC it's not possible to have 1 PR with multiple authors, so I'll likely have to squash all of his earlier commits into 1 and force push with my github handle.", "@timshen91 Just to give you a heads up that I'm refactoring StreamExecutor-related bazel files to accommodate your changes in commit 530d1b2 , as well as @deven-amd 's proposed changes in this PR. Basically we'll need to introduce new bazel files for targets under `gpu` directory, which is shared on both GPU platforms, and change those in `cuda` and `rocm` directory accordingly. I'll push a couple of more commits once they are ready.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", ":frowning_face: Sorry, but only Googlers may change the label `cla: yes`.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "To document CLA check:\r\nCLA bot was failing due to PR having commits from multiple authors.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", ":frowning_face: Sorry, but only Googlers may change the label `cla: yes`.", "> To document CLA check:\r\n> CLA bot was failing due to PR having commits from multiple authors.\r\n\r\n@gunan Thanks. Let me resolve build / test issues on CUDA path first. I'll then revise the commit history so there is one single author for this PR to tame CLA checker.", "CLAs look good, thanks!\n\n<!-- ok -->", "@timshen91 / @gunan I've revised the PR so there is no CLA check errors. Also all known failures on existing targets are fixed. On ROCm-based system the PR also builds fine.\r\n\r\nThere are 4 failing targets which are not relevant to this PR I think:\r\n\r\n- MacOS Contrib : from the logs I don't believe they are related to this PR\r\n- Ubuntu Python3 PIP : 2 failing unit tests and from the logs I don't believe they are related to this PR\r\n- Windows Bazel : looks like a configuration issue to me so I don't believe they are related to this PR\r\n- Windows Bazel GPU : weird syntax error. looks also like a configuration issue to me, so I don't believe they are related to this PR\r\n\r\nMay I ask for your help to give this PR another round of check? Thanks.\r\n\r\nShall this PR be merged I or @deven-amd will submit other PRs to enable other components in ROCm StreamExecutor: BLAS, DNN, FFT, RNG.", "@whchung one more thing, can you break `gpu_stream_executor_headers` into multiple, fine-grained targets, just like the rest of them?", "@timshen91 I've revised the bazel build targets per your suggestion. Could you take another look? Thanks.\r\n\r\nAlso there are still some failed targets but from the logs I don't really believe they are related to this specific PR.", "It looks like StreamExecutor for CUDA has changed a bit yesterday. Let me do a rebase.", "It has been discovered there was a buggy commit in upstream TensorFlow wrt location of `nvcc`. A separate PR ( #24942) has been filed to address that. Logic in this PR also has been revised to reflect such change before #24942 can be merged.", "I'm working on the integrating but it takes time, as I have to split the single commit to smaller ones. Specifically, we still have internal uses of the cuda/ headers and stream_executor::cuda namespace.", "Ok, the integration appears to be very challenging especially with all the new changes coming in. I learned some lessons.\r\n\r\nIt will be much easier for you to split this commit to multiple PR. The first PR:\r\n* only contains changes in `stream_executor/...`.\r\n* does not remove any `stream_executor/cuda/*.h`, so that things outside of stream_executor don't break. All the types and functions in the namespace cuda now alias to namespace gpu counterparts. For example, `namespace cuda { using CUDADriver = gpu::GpuDriver; }`.\r\n* all `stream_executor/gpu/BUILD` targets should be only visible to `//third_party/tensorflow/stream_executor:__subpackages__`.\r\n* target `stream_executor/gpu:X` should be only used by `stream_executor/cuda:cuda_X` or `stream_executor/rocm:rocm_X`, not `cuda_Y`. For example, `cuda:cuda_platform` should depend on `cuda:cuda_driver`, not `gpu:gpu_driver`.\r\n\r\nWe can worry about the second PR once the first is checked in.\r\n\r\nThe general idea is to make redundancy during transition (e.g. keep namespace cuda, but alias to gpu), and change as little as possible. I tried to ingrate the whole thing in order to \"get this over with\" but that simply didn't work. It's much better to integrate them incrementally.", "@timshen91 Let me see how to break this PR into smaller chunks per your suggestion, after rebase.", "@timshen91 it seems there are quite a few in-flight changes in StreamExecutor recently. To better cope with them could you help briefly summarize them? I can see that you added some `if_cuda_is_configured()` checks in CUDA-specific `bazel` targets, and also there seems to be an effort to make CUDA runtime be dynamically loaded. Is there any others we should take into consideration?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Closing this PR due to repeated running into issues with CLA. Will submit a new one."]}, {"number": 24154, "title": "Fix seg fault in micro_speech_test on ppc64le.", "body": "Building micro_speech_test with the same compiler options as on x86, leads to the warnings:\r\n... /micro/testing/micro_test.h:95:51: warning: ISO C++ forbids converting a string constant to 'va_list {aka char*}'\r\n... /micro/micro_error_reporter_test.cc:24:56: warning: ISO C++ forbids converting a string constant to 'va_list {aka char*}'\r\n\r\nAnd running the test program leads to a seg fault, for what I understand the standard for c++11\r\ndoesn't allow for a constant string to be used with %s substitution.\r\n\r\nAnother fix was to add the \"-lm\" link option when compiling on ppc64le, this avoided compile errors like:\r\nundefined reference to symbol 'cos@@GLIBC_2.17'\r\n\r\nThis fixes several failing unit testcases on ppc64le, and causes no regression\r\nerrors on x86.\r\n\r\nFixes #24148", "comments": ["@petewarden , Can you please review these changes?", "@petewarden , Could you please review or select someone else to review?\r\n\r\n@ymodak - Can I enlisted your help nagging someone to review this ? ", "@wdirons Can you please take a look at the failed test builds? Thanks!", "I have no idea how to view the internal CI build failures. I can try again with the latest code on x86 ubuntu and make sure the test still pass.", "@ymodak , I verified the fix works fine with the latest code on x86 ubuntu python 2.  I have no idea how to view google's internal ci build failures, can you retry the test and if they fail, provide some details on why?", "@wdirons Thanks for the update. Re triggered the tests now. ", "Can one of the admins verify this patch?", "@wdirons  can you please fix build errors ?", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F24154) for more info**.\n\n<!-- need_author_consent -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F24154) for more info**.\n\n<!-- need_author_consent -->", "I tried to rebase the pull request with the latest changes. That didn't work. I'm just going to close the PR and open another if I need to."]}, {"number": 24153, "title": "systemlibs: unbundle keras_applications and update icu", "body": "keras_applications is a newly unbundled dep.\r\nThe bundled icu was updated recently so this updates the systemlib version of it to match.", "comments": ["@gunan I think the windows CI machines are just failing unrelated to this?", "Correct, I am trying to get to the bottom of windows issues.\r\nThis PR is ok to merge."]}, {"number": 24152, "title": "Measuring Tensor Flow Input Pipeline Shuffle", "body": "Hello,\r\n\r\nI am trying to measure the time spent executing the shuffle operation of a data set. I an using tf.data.Dataset.shuffle() API along with the tf.data.Iterator.from_structure() API to create an iterator. I have tried editing and compiling the shuffle_dataset_op.cc to print out the time statement of when the operation is being performed however I do believe this is the correct time measurement of just the shuffle operation. \r\n\r\nI am currently using Tensorflow 1.10 with Ubuntu 14.04.5 LTS and Cuda 9.0.\r\n\r\nAny help or advice would be greatly appreciated. Thank you.\r\n\r\n\r\nSincerely,\r\nAbenezer Wudenhe", "comments": []}, {"number": 24151, "title": "TFLite: transpose_conv: fix padding height/width", "body": "The Conv2D_transpose op in TFLite does not handle non-square padding\r\ncorrectly and the outputs do not match regular TensorFlow. Since this op\r\nis transposed, height and width of the padding must be swapped.\r\nThanks to Matt Elsey for discovering this and developing the fix.\r\n\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>\r\n\r\nThis verifies the error:\r\n\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib\r\nmatplotlib.use(\"agg\")\r\nfrom matplotlib import pyplot as plt\r\n\r\n\r\nIN_IMG_SHAPE = (1, 50, 54, 3)\r\nIN_FILTER_SHAPE = (3, 3, 6, 3)\r\nOUT_SHAPE = (1, 100, 108, 8)\r\n\r\nerrs = np.zeros((10, 10))\r\n\r\nfor xf in range(10):\r\n    for yf in range(10):\r\n        IN_FILTER_SHAPE = (1+xf, 1+yf, 8, 3)\r\n\r\n        xx = np.array(np.random.random_sample(IN_IMG_SHAPE), dtype=np.float32)\r\n        kk = np.array(np.random.random_sample(IN_FILTER_SHAPE), dtype=np.float32)\r\n\r\n        x = tf.placeholder(dtype=tf.float32, shape=IN_IMG_SHAPE)\r\n        k = tf.placeholder(dtype=tf.float32, shape=IN_FILTER_SHAPE)\r\n\r\n        y = tf.nn.conv2d_transpose(x, k, output_shape=OUT_SHAPE, padding='SAME', strides=(1, 2, 2, 1))\r\n\r\n\r\n        with tf.Session() as sess:\r\n            converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [x, k], [y])\r\n            tflite_model = converter.convert()\r\n\r\n            z = sess.run(y, feed_dict={x: xx, k: kk})\r\n\r\n        # Load TFLite model and allocate tensors.\r\n        interpreter = tf.contrib.lite.Interpreter(model_content=tflite_model)\r\n        interpreter.allocate_tensors()\r\n\r\n        # Get input and output tensors.\r\n        input_details = interpreter.get_input_details()\r\n        output_details = interpreter.get_output_details()\r\n\r\n        interpreter.set_tensor(input_details[0]['index'], xx)\r\n        interpreter.set_tensor(input_details[1]['index'], kk)\r\n        interpreter.invoke()\r\n\r\n        output_data = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n        assert output_data.shape == OUT_SHAPE\r\n\r\n        errs[yf, xf] = np.sqrt(np.sum(np.abs(output_data  - z) ** 2) / z.size)\r\n\r\n\r\nplt.figure(figsize=(6, 6))\r\nplt.imshow(errs, extent=[0.5, 10.5, 0.5, 10.5])\r\nplt.xlabel(\"kernel x size\")\r\nplt.ylabel(\"kernel y size\")\r\nplt.title(\"L2 diff in tf/tflite output conv2d_transpose\")\r\nplt.colorbar()\r\nplt.savefig(\"out.png\")\r\n#plt.show()\r\n```", "comments": ["The outputs of the snipped above showing the error between TF and TFLite:\r\nBroken:\r\n![broken](https://user-images.githubusercontent.com/363227/49461807-8d258d80-f82f-11e8-844a-eac6222869b6.png)\r\nFixed:\r\n![fixed](https://user-images.githubusercontent.com/363227/49461825-94e53200-f82f-11e8-95e6-a8424873d1c8.png)\r\n", "> Is there a test we can update to confirm? In transpose_conv_test.cc?\r\n\r\nhmm I havent looked, but something with a non-square padding should trigger it i think.", "We have a general internal fix for this, should land in the next day or two.", "Looks like this was fixed in https://github.com/tensorflow/tensorflow/commit/c33db572fe31cd48432dab84e17434359786bac8\r\nThanks! :)", "Re-opening. This should be cherry-picked into 1.13", "c33db57 will be cherrypicked into 1.13 for inclusion in rc2. So I think you can close this", "Merged https://github.com/tensorflow/tensorflow/pull/25266.\r\n"]}, {"number": 24150, "title": "Tensorflow Error in Jupyter Notebooks", "body": "I receive the errors below when importing tensorflow in a Jupyter Notebook.\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-5-64156d691fe5> in <module>()\r\n----> 1 import tensorflow as tf\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 try:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 from tensorflow.python.tools import component_api_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ashbat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ashbat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ashbat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ashbat\\Anaconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ashbat\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.", "comments": ["Please provide the following information asked by the template:\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24149, "title": "Removes line from README", "body": "As @terrytangyuan pointed out in #23647, the line being removed makes a suggestion that can't be followed", "comments": ["@terrytangyuan  A CL has been created and can you please LGTM it ?", "@harshini-gadige Could you elaborate on what I need to do? I've already approved this PR. ", "Hey @harshini-gadige - looks like shlens@ is the CL reviewer. Terry is an external contributor. Thanks!", "> Hey @harshini-gadige - looks like shlens@ is the CL reviewer. Terry is an external contributor. Thanks!\r\n\r\nThanks for correcting @ChrisAntaki. I'll get in touch with shlens@", "@shlens  Could you PTAL ?"]}, {"number": 24148, "title": "[ppc64le] //tensorflow/lite/experimental/micro unit test fail.", "body": "You can assign this issue to me, as I'm about ready to submit a PR to fix this.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ppc64le Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): commit 92854f2426c2b91f2b09831696ffebb5b793933d from Dec 4th, 2018\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.15.0\r\n- GCC/Compiler version (if compiling from source): gcc version 5.4.0 20160609 (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.10)\r\n- CUDA/cuDNN version: N/A \r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\nAll tensorflow/lite/experimental/micro unit test fail\r\nSee: https://powerci.osuosl.org/job/TensorFlow_PPC64LE_CPU_Build_and_Test/31/testReport/\r\n\r\n**Describe the expected behavior**\r\nAll unit test pass\r\n\r\n**Code to reproduce the issue**\r\nUnit test invoked by Jenkins:\r\n`./tensorflow/tools/ci_build/ci_build.sh cpu --dockerfile tensorflow/tools/ci_build/Dockerfile.cpu.ppc64le ./tensorflow/tools/ci_build/linux/ppc64le/cpu/run_py2.sh`\r\n\r\n`./tensorflow/tools/ci_build/linux/ppc64le/cpu/run_py2.sh` can be modified to just run `//tensorflow/lite/experimental/micro/...`\r\n\r\nAlso the getting started section here recreates two of the issues:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro\r\n\r\n\r\n\r\n**Other info / logs**\r\nRunning the getting started example: make -f tensorflow/lite/experimental/micro/tools/make/Makefile test_micro_speech\r\n\r\nThis warning below is flagged and run the test runs it seg faults. As I understand the warning is because your not allowed to pass a string constant in this case. (It works however on x86)\r\n\r\n```\r\ng++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -I. -Itensorflow/lite/experimental/micro/tools/make/../../../../../ -Itensorflow/lite/experimental/micro/tools/make/../../../../../../ -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/experimental/micro/examples/micro_speech/micro_speech_test.cc -o tensorflow/lite/experimental/micro/tools/make/gen/linux_ppc64le/obj/tensorflow/lite/experimental/micro/examples/micro_speech/micro_speech_test.o\r\n\r\nIn file included from tensorflow/lite/experimental/micro/examples/micro_speech/micro_speech_test.cc:22:0:\r\ntensorflow/lite/experimental/micro/examples/micro_speech/micro_speech_test.cc: In function 'int main(int, char**)':\r\n./tensorflow/lite/experimental/micro/testing/micro_test.h:95:51: warning: ISO C++ forbids converting a string constant to 'va_list {aka char*}' [-Wwrite-strings]\r\n   micro_test::reporter->Report(\"Testing %s\", #name);                       \\\r\n                                                   ^\r\ntensorflow/lite/experimental/micro/examples/micro_speech/micro_speech_test.cc:28:1: note: in expansion of macro 'TF_LITE_MICRO_TEST'\r\n TF_LITE_MICRO_TEST(TestInvoke) {\r\n ^~~~~~~~~~~~~~~~~~\r\n```\r\n\r\n\r\nFixing it and running the example: make -f tensorflow/lite/experimental/micro/tools/make/Makefile test identifies the same problem in another place:\r\n\r\n```\r\ng++ -O3 -DNDEBUG --std=c++11 -g -DTF_LITE_STATIC_MEMORY -I. -Itensorflow/lite/experimental/micro/tools/make/../../../../../ -Itensorflow/lite/experimental/micro/tools/make/../../../../../../ -Itensorflow/lite/experimental/micro/tools/make/downloads/ -Itensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/experimental/micro/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/experimental/micro/micro_error_reporter_test.cc -o tensorflow/lite/experimental/micro/tools/make/gen/linux_ppc64le/obj/tensorflow/lite/experimental/micro/micro_error_reporter_test.o\r\ntensorflow/lite/experimental/micro/micro_error_reporter_test.cc: In function 'int main(int, char**)':\r\ntensorflow/lite/experimental/micro/micro_error_reporter_test.cc:24:56: warning: ISO C++ forbids converting a string constant to 'va_list {aka char*}' [-Wwrite-strings]\r\n   error_reporter->Report(\"~~~%s~~~\", \"ALL TESTS PASSED\");\r\n                                                        ^\r\n```\r\n\r\nFixing that allows the make test to complete, but when running inside of bazel some test still fail because they fail to compile:\r\n\r\n```\r\nERROR: ^[[0m/workspace/tensorflow/lite/experimental/micro/examples/micro_speech/BUILD:185:1: Couldn't build file tensorflow/lite/experimental/micro/examples/micro_speech/feature_provider_test_binary: Linking of rule '//tensorflow/lite/experimental/micro/examples/micro_speech:feature_provider_test_binary' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /mnt/pai/home/wdirons/tmp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda-9.2 \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-9.2 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \\\r\n    OMP_NUM_THREADS=1 \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python2 \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=3.7 \\\r\n    TF_CUDA_VERSION=9.2 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION='' \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/ppc-opt/bin/tensorflow/lite/experimental/micro/examples/micro_speech/feature_provider_test_binary -Wl,-no-as-needed -pie -Wl,-z,relro,-z,now '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -no-canonical-prefixes -fno-canonical-system-headers -B/usr/bin -Wl,--gc-sections -Wl,@bazel-out/ppc-opt/bin/tensorflow/lite/experimental/micro/examples/micro_speech/feature_provider_test_binary-2.params)\r\n/usr/bin/ld: bazel-out/ppc-opt/bin/tensorflow/lite/experimental/micro/examples/micro_speech/libpreprocessor_reference.a(preprocessor.o): undefined reference to symbol 'cos@@GLIBC_2.17'\r\n//lib/powerpc64le-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line\r\n\r\n```\r\nPassing the link option \"-lm\" resolves this error. The makefile already does this. \r\n\r\n\r\n", "comments": ["Thanks for your PR on this (and sorry for the slow response).", "closing old issues I opened. This issue is resolved. "]}, {"number": 24147, "title": "Description mismatch", "body": "In the Repository Description, Tensorflow is Framework.\r\nBut in the README, Tensorflow is Library.\r\nWhich one is right?\r\n\r\n", "comments": ["@arcane1028 , this [article](https://www.programcreek.com/2011/09/what-is-the-difference-between-a-java-library-and-a-framework/) explains differences between framework and library in general.", "Closing due to lack of recent activity, but please let me know if I'm mistaken. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 24146, "title": "No gradient defined for operation 'MatrixLogarithm'", "body": "I would like to optimize a function containing tf.linalg.logm. However,\r\n\r\nLookupError: gradient registry has no entry for: MatrixLogarithm", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "Hello, have you solved this issue yet?", "I think it can be considered a feature request."]}, {"number": 24145, "title": "How to build example - tfjs-examples", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **MS Windows 7**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): **npm**\r\n- TensorFlow version: **tfjs-node@0.1.21**\r\n- Python version:**2.7**\r\n- Node version: **8.9.4**\r\n- Installed using virtualenv? pip? conda?: **pip**\r\n- Bazel version (if compiling from source):NA\r\n- GCC/Compiler version (if compiling from source):NA\r\n- CUDA/cuDNN version:NA\r\n- GPU model and memory: Intel\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am following steps as described [here](https://github.com/tensorflow/tfjs-examples) to install tfjs-examples\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`npm i @tensorflow/tfjs-node -g` - ok\r\n`git clone https://github.com/tensorflow/tfjs-examples.git` -ok\r\n`cd tfjs-example` - ok\r\n`cd minst-code` - ok\r\n`npm install` - error\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n31428 error code ELIFECYCLE\r\n31429 error errno 1\r\n31430 error tfjs-examples-mnist-core@0.1.0 postinstall: `yarn upgrade --pattern @tensorflow`\r\n31430 error Exit status 1\r\n31431 error Failed at the tfjs-examples-mnist-core@0.1.0 postinstall script.\r\n31431 error This is probably not a problem with npm. There is likely additional logging output above.\r\n31432 verbose exit [ 1, true ]\r\n```\r\nQ: do i have to have `yarn` installed ? \r\nOn [this page](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md) it says either `yarn/npm` - unless i misunderstood.\r\nPlease advice.\r\nThanks.", "comments": ["Closing this issue since it is better suited for [TFJS repo](https://github.com/tensorflow/tfjs/issues). Please post the same on [TFJS repo](https://github.com/tensorflow/tfjs/issues). Thanks!"]}, {"number": 24144, "title": "Build issue while building tensorflow on raspberry pi 3B+", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspberry pi 3B+, Raspbian GNU/Linux 9.4 \r\n\r\n- TensorFlow installed from (source or binary): tried installing from source as mentioned in [link](https://www.tensorflow.org/install/source_rpi) and using pip as mentioned in [link](https://www.tensorflow.org/install/pip)\r\n\r\n- TensorFlow version: r1.9\r\n- Python version: 2.7.13\r\n- Installed using virtualenv? pip? conda?: source and pip\r\n\r\n\r\n**Describe the problem**\r\nI tried to install tensorflow r1.9 on raspberry pi using the commands given in the [link](https://www.tensorflow.org/install/source_rpi) but its failing to build at step 6/14 and could not install ffmpeg. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```git clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout r1.9\r\ntensorflow/tools/ci_build/ci_build.sh PI \\\r\n    tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n```\r\n\r\n**Any other info / logs**\r\n```Package ffmpeg is not available, but is referred to by another package.\r\nThis may mean that the package is missing, has been obsoleted, or\r\nis only available from another source\r\n\r\nE: Package 'ffmpeg' has no installation candidate\r\nThe command '/bin/sh -c /install/install_deb_packages.sh' returned a non-zero code: 100\r\nERROR: docker build failed. Dockerfile is at /home/pi/tensorflow/tensorflow/tools/ci_build/Dockerfile.pi\r\n```", "comments": ["Facing same problem \r\n```\r\nBuilding dependency tree...\r\nReading state information...\r\nPackage ffmpeg is not available, but is referred to by another package.\r\nThis may mean that the package is missing, has been obsoleted, or\r\nis only available from another source\r\n\r\nE: Package 'ffmpeg' has no installation candidate\r\nThe command '/bin/sh -c /install/install_deb_packages.sh' returned a non-zero code: 100\r\nERROR: docker build failed. Dockerfile is at /home/pi/Desktop/tensorflow/tensorflow/tools/ci_build/Dockerfile.pi\r\n```", "Hi! Are you building this image on raspberry? I had the same issue when I was building it on raspbian but on my computer (Ubuntu 18.04) this issue doesn't occur anymore :smile:", "I have the same issue, any update to the instructions would be very helpful. I tried building from source too which had a waterfall of errors but these instructions aren't working either.  I should point out that I just cloned the repo so typed:\r\n\r\n> git clone https://github.com/tensorflow/tensorflow.git\r\n> cd tensorflow\r\n> CI_DOCKER_EXTRA_PARAMS=\"-e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4\"     tensorflow/tools/ci_build/ci_build.sh PI-PYTHON3     tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n\r\nhttps://www.tensorflow.org/install/source_rpi\r\n\r\nsame error:\r\n> Package ffmpeg is not available, but is referred to by another package.\r\nThis may mean that the package is missing, has been obsoleted, or\r\nis only available from another source\r\nE: Package 'ffmpeg' has no installation candidate\r\nThe command '/bin/sh -c /install/install_deb_packages.sh' returned a non-zero code: 100\r\nERROR: docker build failed. Dockerfile is at /home/pi/Documents/git/tensorflow/tensorflow/tools/ci_build/Dockerfile.pi-python3\r\n", "When I tried to build on Raspian it was showing this error. But when built on Ubuntu error doesn't occour. ", "Good to know but I'm trying to install it on my raspberry pi 3", "Hi Guys, \r\nSummarizing the issue. To run tensorflow go on raspberry pi we have to have libtensorflow.so which is  clibrary for tensorflow used by GoLang. \r\n\r\n1. Building Tensorflow Go for Raspberry Pi, following link is very helpful. This process is very lengthly from the time-wise. I have build libtensorflow.so through this guide.\r\nhttps://blog.meinside.pe.kr/TensorFlow-and-Go-on-Raspberry-Pi/ \r\n", "@pranoot I think this issue is invalid and shall be rejected: the link of the official docs you're referring to https://www.tensorflow.org/install/source_rpi says about **cross-compiling** and it means building it on a host PC (x86_64) for RPI arch (armv7), while your are trying to **compile** TF on RPI.\r\nFYI There are docker images in TF distro to cross-compile TF for RPI", "Still facing problem to generate libtensorflow.so so that Golang can use it. I have tried all methods but not able to generate. Any can help here. This issue is still there for Docker images.", "@mixaz yes, I figured that out later on !! It was my bad!! :D \r\nThanks", "@pranoot actually cross-compiling for RPI doesn't work too, the same error as you reported. I created a new issue https://github.com/tensorflow/tensorflow/issues/24420", "For anybody interested: another docker image to cross-compile TF: https://github.com/lhelontra/tensorflow-on-arm \r\n\r\nIt's not so complicated as CI docker files, so can be used by an average developer, not a TF CI geek )\r\n\r\nIt has a config to cross-compile for Beaglebone Black (my case) and of course RPi.\r\n\r\nI'm trying to use that, with some positive progress - built a TF whl file, but when being installed it started to built pip dependencies on BBB (Oh my God, it is that I'm trying to avoid by cross-compiling) and failed somewhere then...\r\n\r\nBut I libtensorflow.so  is built OK, and it's definitely a progress.", "> For anybody interested: another docker image to cross-compile TF: https://github.com/lhelontra/tensorflow-on-arm\r\n> \r\n> It's not so complicated as CI docker files, so can be used by an average developer, not a TF CI geek )\r\n> \r\n> It has a config to cross-compile for Beaglebone Black (my case) and of course RPi.\r\n> \r\n> I'm trying to use that, with some positive progress - built a TF whl file, but when being installed it started to built pip dependencies on BBB (Oh my God, it is that I'm trying to avoid by cross-compiling) and failed somewhere then...\r\n> \r\n> But I libtensorflow.so is built OK, and it's definitely a progress.\r\n\r\nDid you get Ihelontra's cross build to work for the BBB?"]}, {"number": 24143, "title": "I am getting Thread 1: signal SIGABRT while installing the camera example tensorflowlite ", "body": "I am getting Thread 1: signal SIGABRT while installing the camera example tensorflowlite app. Kindly let me know can we able to run this in simulator.", "comments": ["Can you please point me to the link you used to build tensorflowlite application?Thanks!", "@ymodak  I am following this example camera modal https://www.tensorflow.org/lite/demo_ios to build tensonflowlite application", "Please add the details on what step gives an error while following the tutorial, what version of iOS and xcodeproject are you using. Did you look at the debugging log? If yes, please copy/paste the step which shows the error.", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24142, "title": "Fix for OOM caused by access of kUnknownNumaNode", "body": "This bug is produced since this commit:\r\n33170cc661f3838aa7d0d7fc19bb0c6ba4812a3c\r\n\r\nBug Description:\r\n\r\nWhen `/sys/devices/xxx/numa_node` is not accessible,\r\n`bus_id` in `gpu_process_state.cc` would get negative\r\nvalue -1 (even if numa_node is defaulting to 0 in other\r\nmodules), thus its following loop would execute infinitely\r\nand crash with system memory exhaustion:\r\n\r\n```\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\n```\r\n\r\nAfterwards, the container `gpu_visitors_` is also not\r\nallowed to accept negative-value index access.\r\n\r\nSigned-off-by: CUI Wei <ghostplant@qq.com>", "comments": ["Gentle ping @poxvoculi. I've never met this issue though.", "@byronyi If you don't meet this issue, it indicates you never see this warning from Tensorflow initialization:\r\n\r\n```sh\r\nCould not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\r\n```\r\n\r\nWhen the Linux kernel is not compiled with numa node support, you will see this warning and `int bus_id = BusIdForGPU(tf_gpu_id);` would get -1 value.\r\n\r\nThen following condition would be always true for (-1 >= any_unsigned_long_value):\r\n```sh\r\nwhile (bus_id >= gpu_visitors_.size()) {\r\n      gpu_visitors_.push_back({});\r\n}\r\n```\r\n\r\nNote that it is comparing a negative signed value with an unsigned size which would be always true so the memory allocation will never stop.", "@byronyi \r\nhttps://github.com/tensorflow/tensorflow/blob/1dab0d879218f36c44e88b2d6bf71e819da0ef05/tensorflow/core/common_runtime/gpu/gpu_device.cc#L1194\r\n\r\nThe default value 0 doesn't take effort to the function `BusIdForGPU`.\r\n\r\nBefore tf-1.12\uff0cno-numa-supported Linux Kernel can execute tensorflow succesfully, but since that commit (just a commit before tf-1.12), tensorflow initialization on such Linux Kernel would loop forever and run out of 100% system memory and then crash or make OS out of response.", "It\u2019s indeed a bug. But wouldn\u2019t it be enough to change the value of kUnknownNumaNode to 0?", "@byronyi It is another kind of solution, but there are more than one place needed to get changed:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/f670244e49b6c644bb27d448b116ae1f2cf8164c/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L973\r\nhttps://github.com/tensorflow/tensorflow/blob/f2787478fce32cf57fdc2036ee1929848230b54d/tensorflow/contrib/gdr/gdr_memory_manager.cc#L70\r\nhttps://github.com/tensorflow/tensorflow/blob/33170cc661f3838aa7d0d7fc19bb0c6ba4812a3c/tensorflow/contrib/verbs/rdma_mgr.cc#L229\r\n\r\nSome might expect a value -1 to help identify whether the system support NUMA node or not, while we need to erase all -1 cases for them.\r\n\r\nSo which one do you suggest?\r\n\r\n(This PR is a solution keep existing usage of any BusIdForGPU(), and also verified to solve the OOM issue on my non-NUMA-binded host)", "A third solution is we place the negative numa affinity checking inside this function:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/7b1e7138f1fc36dd83e0cb1e8ea9b49d2b576802/tensorflow/core/common_runtime/gpu/gpu_process_state.cc#L69\r\n\r\nBut we'd better also apply a signed cast to the line below for safety:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/7b1e7138f1fc36dd83e0cb1e8ea9b49d2b576802/tensorflow/core/common_runtime/gpu/gpu_process_state.cc#L100\r\n", "> @byronyi It is another kind of solution, but there are more than one place needed to get changed:\r\n> \r\n> [tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc](https://github.com/tensorflow/tensorflow/blob/f670244e49b6c644bb27d448b116ae1f2cf8164c/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L973)\r\n> Line 973 in [f670244](/tensorflow/tensorflow/commit/f670244e49b6c644bb27d448b116ae1f2cf8164c)\r\n>  return kUnknownNumaNode; \r\n> \r\n> [tensorflow/tensorflow/contrib/gdr/gdr_memory_manager.cc](https://github.com/tensorflow/tensorflow/blob/f2787478fce32cf57fdc2036ee1929848230b54d/tensorflow/contrib/gdr/gdr_memory_manager.cc#L70)\r\n> Line 70 in [f278747](/tensorflow/tensorflow/commit/f2787478fce32cf57fdc2036ee1929848230b54d)\r\n>  return port::kNUMANoAffinity; \r\n> \r\n> [tensorflow/tensorflow/contrib/verbs/rdma_mgr.cc](https://github.com/tensorflow/tensorflow/blob/33170cc661f3838aa7d0d7fc19bb0c6ba4812a3c/tensorflow/contrib/verbs/rdma_mgr.cc#L229)\r\n> Line 229 in [33170cc](/tensorflow/tensorflow/commit/33170cc661f3838aa7d0d7fc19bb0c6ba4812a3c)\r\n>  static const int kUnknownNumaNode = -1; \r\n> Some might expect a value -1 to help identify whether the system support NUMA node or not, while we need to erase all -1 cases for them.\r\n> \r\n> So which one do you suggest?\r\n> \r\n> (This PR is a solution keep existing usage of any BusIdForGPU(), and also verified to solve the OOM issue on my non-NUMA-binded host)\r\n\r\nAll three of them should be unified into a single constant. I am pretty sure of that :)", "@byronyi OK, I'll unite them and set their value to 0. Is that ok?\r\n", "Or you could wait for feedback from @poxvoculi; most code related here was written by Paul. ", "OK.\r\n\r\nI traced all current invocations of existing `TryToReadNumaNode()` and see the `kUnknownNumaNode` case is not used by their callers at the moment.\r\n\r\nUnsupported platform like Windows and MacOS default to their NUMA affinity as 0, and I think `kUnknownNumaNode` won't play an important role to do something special related to affinity.\r\n\r\nAnother idea is to update their arguments from:\r\n```sh\r\nint TryToReadNumaNode(ibv_device* device)\r\n```\r\nto\r\n```sh\r\nint TryToReadNumaNode(ibv_device* device, int default_node = port::kNUMANoAffinity)\r\n```\r\n\r\nThus, it can still cover any existing and potential requirements.\r\n\r\nHappy to wait for your suggestions and hope to get this updated soon.", "> OK.\r\n> \r\n> I traced all current invocations of existing `TryToReadNumaNode()` and see the `kUnknownNumaNode` case is not used by their callers at the moment.\r\n> \r\n> Unsupported platform like Windows and MacOS default to their NUMA affinity as 0, and I think `kUnknownNumaNode` won't play an important role to do something special related to affinity.\r\n> \r\n> Another idea is to update their arguments from:\r\n> \r\n> ```shell\r\n> int TryToReadNumaNode(ibv_device* device)\r\n> ```\r\n> \r\n> to\r\n> \r\n> ```shell\r\n> int TryToReadNumaNode(ibv_device* device, int default_node = port::kNUMANoAffinity)\r\n> ```\r\n> \r\n> Thus, it can still cover any existing and potential requirements.\r\n> \r\n> Happy to wait for your suggestions and hope to get this updated soon.\r\n\r\nSorry, no default argument for functions. I don't think it is necessary as well.", "I think the proper solution is to guarantee that BusIdForGPU() never returns a negative number.  Something like:\r\n`int numa_node = se->GetDeviceDescriptiion.numa_node();`\r\n`// Use numa_node as bus_id if available, otherwise fall back to 0.`\r\n`return numa_node >= 0 ? numa_node : 0;`\r\n\r\nin gpu_process_state.cc\r\n\r\nIf I don't see a PR soon I'll push this through myself.\r\n", "Submitted fix internally. ", "@poxvoculi How do you think about uniting 3 different `TryToReadNumaNode` like byronyi suggests?", "That might be a good idea, though maybe a better idea is to eliminate the copied logic in contrib/*.  Which is not directly called anywhere in TensorFlow proper.  Note that common_runtime/gpu/gpu_process_state.cc does not call TryToReadNumaNode(), but instead gets the value from the StreamExecutor associated with the device.   Maybe gpu_id_utils.h is not visible and that's why the logic got copied.  Probably fixing the visibility so the numa_node is obtained consistently one way everywhere (from one logic definition) would be better.", "The copied function is used to read numa mode for the NIC. Does it make sense to unify the function so the NUMA node for any PCIe devices (encoded by bus location in the PCI spec, such as 00:5f:01) could be read? Accelerator of other kinds might need it as well.", "It might make sense to add something to core/platform/numa.h which can return the numa-node for any PCI device.   I'm actually working on an open-source implementation for numa.h right now, based on hwloc."]}, {"number": 24141, "title": "ERROR: /root/tensorflow/tensorflow/lite/BUILD:202:1: in cc_library rule //tensorflow/lite:string_util: cycle in dependency graph", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?:no\r\n- Bazel version (if compiling from source):0.15\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:none\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhen trying to build toco with with_select_tf_ops=true, error happens.\r\n\r\nbazel build -c opt  --define=with_select_tf_ops=true //tensorflow/lite/toco:toco \r\n\r\nERROR: /root/tensorflow/tensorflow/lite/BUILD:202:1: in cc_library rule //tensorflow/lite:string_util: cycle in dependency graph\r\n.......\r\nERROR: /root/tensorflow/tensorflow/lite/BUILD:202:1: in cc_library rule //tensorflow/lite:string_util: cycle in dependency graph:\r\n    //tensorflow/lite/toco:toco\r\n    //tensorflow/lite/toco:toco_tooling\r\n    //tensorflow/lite/toco/tflite:export\r\n    //tensorflow/lite/toco/tflite:operator\r\n    //tensorflow/lite/toco/tflite:types\r\n.-> //tensorflow/lite:string_util\r\n|   //tensorflow/lite:framework\r\n|   //tensorflow/lite/delegates/flex:delegate\r\n|   //tensorflow/lite/delegates/flex:delegate_only_runtime\r\n|   //tensorflow/lite/delegates/flex:delegate_data\r\n|   //tensorflow/lite/delegates/flex:buffer_map\r\n`-- //tensorflow/lite:string_util\r\nThis cycle occurred because of a configuration option\r\nERROR: Analysis of target '//tensorflow/lite/toco:toco' failed; build aborted\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Apologies for the delay in response. Is this still an issue? Can you use TF nightly and test again?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24140, "title": "tf.contrib.factorization.python.ops.factorization_ops.WALSModel greedy parallelization", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04 and macOS \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12+\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 9.2\r\n- GPU model and memory: Titan\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nwhen trying to train a WALSModel in parallel (e.g. with n different parameter sets or any other tf model) using the python multiprocessing module (or in two different scripts), CUDA errors occur. It seems that WALSModel is written to automatically parallelize itself and in a greedy manner...\r\n\r\nlooking at the __init__, I can not see a way to specify to limit this...\r\n```\r\ndef __init__(self,\r\n               input_rows,\r\n               input_cols,\r\n               n_components,\r\n               unobserved_weight=0.1,\r\n               regularization=None,\r\n               row_init=\"random\",\r\n               col_init=\"random\",\r\n               num_row_shards=1,\r\n               num_col_shards=1,\r\n               row_weights=1,\r\n               col_weights=1,\r\n               use_factors_weights_cache=True,\r\n               use_gramian_cache=True,\r\n               use_scoped_vars=False):\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@SumNeuron Could you provide any example code to reproduce the error? Also, mention any details about context, describe the expected behavior, and provide any error snapshots. All these details will be useful to find a root cause of the issue. Thanks! ", "@SumNeuron Could you provide any example code to reproduce the error? Also, mention any details about context, describe the expected behavior, and provide any error snapshots. All these details will be useful to find a root cause of the issue. Thanks!", "@jvishnuvardhan here is a google [colab] for the issue. Note, it will not run as it requires data to do so and colab's do not store uploaded data. It should, however, be sufficient to see what causes the error. Namely:\r\n\r\n```\r\ndef wrapper():\r\n    wals() #<--- run WALSModel\r\n\r\nwith Pool(2) as p:\r\n    p.map(wrapper, [i for i in range(2)])\r\n```\r\n\r\n[colab]: https://colab.research.google.com/drive/1S6JLTI0cQkbXFijPAKznd5NcnyL3apg7", "@agarwal-ashish I think you wrote wals, want to take a look at this?", "I took a look at the attached colab.\r\nHere is an attempt at writing a minimal working example that will run different WALS models with the multiprocessing library. This works for me, I am not seeing the issue described in the bug.\r\n\r\nPlease give it a try and let me know if this didn't work for you.\r\n\r\n```\r\nimport tensorflow as tf, numpy as np\r\nimport scipy\r\nfrom tensorflow.contrib.factorization.python.ops.factorization_ops import WALSModel\r\n\r\ndef to_sp_tensor(dense):\r\n  sparse = scipy.sparse.coo_matrix(dense)\r\n  sparse_indicies = list(zip(\r\n    sparse.row.astype(np.int64).tolist(),\r\n    sparse.col.astype(np.int64).tolist()))\r\n  return tf.SparseTensor(\r\n      sparse_indicies, sparse.data.astype(np.float32), sparse.shape)\r\n\r\ndef run_wals(input_matrix, embedding_dim, regularization, num_iter, tag):\r\n  with tf.Graph().as_default():\r\n    print('[%s] initializing model' % tag)\r\n    num_rows, num_cols = input_matrix.shape\r\n    model = WALSModel(num_rows, num_cols, embedding_dim, regularization)\r\n    sp_input = to_sp_tensor(input_matrix)\r\n    sp_input_t = to_sp_tensor(input_matrix.T)\r\n    row_ops = model.update_row_factors(sp_input)\r\n    col_ops = model.update_col_factors(sp_input_t, transpose_input=True)\r\n\r\n    with tf.Session() as sess:\r\n      sess.run(model.initialize_op)\r\n      sess.run(model.worker_init)\r\n      for i in range(num_iter):\r\n        # update rows\r\n        sess.run(model.row_update_prep_gramian_op)\r\n        sess.run(model.initialize_row_update_op)\r\n        _, _, loss, reg, _ = sess.run(row_ops)\r\n        print('[%s] iteration %d row sweep, loss: %f' % (tag, i, loss + reg))\r\n        # update cols\r\n        sess.run(model.col_update_prep_gramian_op)\r\n        sess.run(model.initialize_col_update_op)\r\n        _, _, loss, reg, _ = sess.run(col_ops)\r\n        print('[%s] iteration %d col sweep, loss: %f' % (tag, i, loss + reg))\r\n    print('[%s] done.' % tag)\r\n```\r\nAn important comment here: for the column solves, you need to feed the transposed matrix, and use the argument `transpose_input=True`. As written in the attached colab, the updates will not be correct.\r\n\r\nTo run with multiprocessing:\r\n```\r\nimport multiprocessing\r\n\r\nINPUT_MATRIX = np.array(\r\n    [[0.1, 0.0, 0.2, 0.0, 0.4, 0.5, 0.0],\r\n     [0.0, 1.1, 0.0, 1.3, 1.4, 0.0, 1.6],\r\n     [2.0, 0.0, 0.0, 2.3, 0.0, 2.5, 0.0],\r\n     [3.0, 0.0, 3.2, 3.3, 0.0, 3.5, 0.0],\r\n     [0.0, 4.1, 0.0, 0.0, 4.4, 0.0, 4.6]])\r\nembedding_dim = 3\r\nnum_iter = 4\r\nregs = [0.01, 0.1]\r\n\r\nps = [\r\n  multiprocessing.Process(\r\n    target=run_wals, args=(INPUT_MATRIX, embedding_dim, regs[i], num_iter, i))\r\n    for i in range(2)]\r\nfor p in ps:\r\n  p.start()\r\nfor p in ps:\r\n  p.join()\r\n```\r\n\r\nOutput:\r\n```\r\n[0] initializing model\r\n[1] initializing model\r\n[0] iteration 0 row sweep, loss: 45.192287\r\n[1] iteration 0 row sweep, loss: 40.113457\r\n[0] iteration 0 col sweep, loss: 7.389457\r\n[0] iteration 1 row sweep, loss: 4.829801\r\n[1] iteration 0 col sweep, loss: 12.314854\r\n[0] iteration 1 col sweep, loss: 4.464665\r\n[0] iteration 2 row sweep, loss: 4.270123\r\n[1] iteration 1 row sweep, loss: 10.322790\r\n[0] iteration 2 col sweep, loss: 4.156906\r\n[1] iteration 1 col sweep, loss: 9.163980\r\n[0] iteration 3 row sweep, loss: 4.078035\r\n[1] iteration 2 row sweep, loss: 8.338335\r\n[0] iteration 3 col sweep, loss: 4.025699\r\n[0] done.\r\n[1] iteration 2 col sweep, loss: 7.691652\r\n[1] iteration 3 row sweep, loss: 7.198600\r\n[1] iteration 3 col sweep, loss: 6.796245\r\n[1] done.\r\n```", "@walidk  seems to work, I'll try putting it in my app's use case and see if that solves the problem\r\n", "Thanks for the update. Closing this now.\r\nFeel free to reopen if you run issues with the solution.", "@walidk it has been a while but for clarity (and anyone else who sees this in the future) I wish to clarify your statement regarding the need to transpose the sparse tensor:\r\n\r\n>     col_ops = model.update_col_factors(sp_input_t, transpose_input=True)\r\n\r\nAccording to the document string for `update_col_factors`\r\n\r\n> `transpose_input` if True the input will be logically transposed and the columns corresponding to the transposed input are updated\r\n\r\nBy default `transpose_input` is false and as used in google's cloud computing [example](https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-create-model)\r\n\r\n```python\r\nrow_update_op = model.update_row_factors(sp_input=input_tensor)[1]\r\ncol_update_op = model.update_col_factors(sp_input=input_tensor)[1]\r\n```\r\nWhile not explicitly stated in the docstring for the method `update_col_factors` it appears to imply that the argument  `transpose_input` is a boolean flag to save some time if the transpose matrix is already available. \r\n\r\nFurther, since the docstring states \"_the columns corresponding to the **transposed** input are updated_\", passing a transformed matrix and then having it transpose it again seems to be wasteful. (as why not just pass the original matrix). \r\n\r\n\r\n"]}, {"number": 24139, "title": "encrypt decrypt tf lite model in android", "body": "I found an issue https://github.com/tensorflow/tensorflow/issues/21501. When i decrypt my model to byte[],  use wrap() method to convert byte[] to HeapByteBuffer, init the Interpreter. The NativeInterpreterWrapper will throw an exception. Is there a way to solve this problem\uff1f\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java\r\n` NativeInterpreterWrapper(ByteBuffer buffer, Interpreter.Options options) {\r\n    if (buffer == null\r\n        || (!(buffer instanceof MappedByteBuffer)\r\n            && (!buffer.isDirect() || buffer.order() != ByteOrder.nativeOrder()))) {\r\n      throw new IllegalArgumentException(\r\n          \"Model ByteBuffer should be either a MappedByteBuffer of the model file, or a direct \"\r\n              + \"ByteBuffer using ByteOrder.nativeOrder() which contains bytes of model content.\");\r\n    }\r\n    this.modelByteBuffer = buffer;\r\n    long errorHandle = createErrorReporter(ERROR_BUFFER_SIZE);\r\n    long modelHandle = createModelWithBuffer(modelByteBuffer, errorHandle);\r\n    init(errorHandle, modelHandle, options);\r\n  }`", "comments": ["@zjmirving Could you tell me about your solution, I am facing the same problem???", "> @zjmirving Could you tell me about your solution, I am facing the same problem???\r\n\r\nByteBuffer byteBuffer = ByteBuffer.allocateDirect(bytes.length);\r\nbyteBuffer.order(ByteOrder.nativeOrder());\r\nbyteBuffer.put(bytes);\r\nInterpreter mTFLiteInterpreter = new Interpreter(byteBuffer);", "thanks you", "@zjmirving are you able to encrypt tflite and decypt successfully? I am facing the same problem. great if you can share some insights. ", "> @zjmirving are you able to encrypt tflite and decypt successfully? I am facing the same problem. great if you can share some insights.\r\n\r\nByteBuffer byteBuffer = ByteBuffer.allocateDirect(bytes.length);\r\nbyteBuffer.order(ByteOrder.nativeOrder());\r\nbyteBuffer.put(bytes);\r\nInterpreter mTFLiteInterpreter = new Interpreter(byteBuffer);", "@zjmirving Thank you. but how do you encrypt tflite flatbuffer model file?\r\n\r\n> > @zjmirving are you able to encrypt tflite and decypt successfully? I am facing the same problem. great if you can share some insights.\r\n> \r\n> ByteBuffer byteBuffer = ByteBuffer.allocateDirect(bytes.length);\r\n> byteBuffer.order(ByteOrder.nativeOrder());\r\n> byteBuffer.put(bytes);\r\n> Interpreter mTFLiteInterpreter = new Interpreter(byteBuffer);\r\n\r\n", "@zjmirving hello can you help me out, i tried your code but it is giving me \"ByteBuffer is not a valid flatbuffer model\"\r\n\r\n@JianbangZ did you reach a solution?", "Here is what I did to solve my problem in Kotlin (exact same than @zjmirving solution)\r\n```kotlin\r\nval byteBuffer = ByteBuffer.allocateDirect(bytes.size)\r\nbyteBuffer.order(ByteOrder.nativeOrder())\r\nbyteBuffer.put(bytes)\r\nval tflite = Interpreter(buffer)\r\n```", "Thanks!\r\nI have the same problem & this solution works for me", "> > @zjmirving Could you tell me about your solution, I am facing the same problem???\r\n> \r\n> ByteBuffer byteBuffer = ByteBuffer.allocateDirect(bytes.length); byteBuffer.order(ByteOrder.nativeOrder()); byteBuffer.put(bytes); Interpreter mTFLiteInterpreter = new Interpreter(byteBuffer);\r\n\r\nWorked for me! Thanks!"]}, {"number": 24138, "title": "How can I convert custom pb file to tflite?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:-\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):1.15.0\r\n- Python version:2.7.12\r\n- Bazel version (if compiling from source):0.19.2\r\n- GCC/Compiler version (if compiling from source):-\r\n- CUDA/cuDNN version:-\r\n- GPU model and memory: no GPU / 8GB memory(VM)\r\n\r\nI tried to convert frozen & custom .pb file(Specifically, SSD) to .tflite with toco tools.\r\nbut I get some error & core dump.(below)\r\n\r\n*convert command & results is below:******************************************************************\r\n$   (path)/.local/bin/toco \r\n--input_file=(path)/ssd1.pb   \r\n--output_file=(path)/ssd2.tflite \r\n--input_format=TENSORFLOW_GRAPHDEF  \r\n --output_format=TFLITE \r\n--input_shape=1,300,300,3 \r\n--input_array=input_13   \r\n--output_array=predictions/concat \r\n--input_data_type=FLOAT   \r\n--inference_type=FLOAT \r\n--allow_custom_ops\r\n2018-12-04 11:39:52.856924: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857097: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857156: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857214: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857271: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857389: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857474: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857533: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857586: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857638: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Prod\r\n2018-12-04 11:39:52.857720: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.857784: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.857878: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.857976: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.858055: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.858156: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.858226: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.858287: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.858337: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: StridedSlice\r\n2018-12-04 11:39:52.858382: I   tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting   unsupported operation: Exp\r\n2018-12-04 11:39:52.862297: I   tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39]   Before general graph transformations: 309 operators, 499 arrays (0 quantized)\r\n2018-12-04 11:39:53.124941: F   tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:785]   Check failed: crops_data[1] == 0 (5 vs. 0)\r\nCoredump\r\n*************************************************************************************************************\r\n\r\n*model summarize is below:(trained environmental is keras. and I converted .json & .h5 to .pb)**********\r\n$   bazel-bin/tensorflow/tools/graph_transforms/summarize_graph   \r\n --in_graph=(path)/ssd1.pb\r\n\r\nFound 1 possible inputs: (name=input_13,   type=float(1), shape=[?,300,300,3])\r\nNo variables spotted.\r\nFound 1 possible outputs:   (name=predictions/concat, op=ConcatV2)\r\nFound 25824093 (25.82M) const   parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 189 Const, 73 Identity,   33 BiasAdd, 31 Conv2D, 21 Relu, 19 Pack, 19 StridedSlice, 19 Shape, 13   Reshape, 10 Prod, 6 Tile, 6 ExpandDims, 5 MaxPool, 4 ConcatV2, 2 Sum, 2 Mul,   2 MatMul, 1 RealDiv, 1 Sub, 1 Square, 1 SpaceToBatchND, 1 Exp, 1 Rsqrt, 1   Placeholder, 1 Pad, 1 BatchToSpaceND, 1 Mean, 1 Maximum, 1 Max\r\nTo use with   tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run   tensorflow/tools/benchmark:benchmark_model --   \r\n--graph=(path)/ssd1.pb --show_flops   --input_layer=input_13 \r\n--input_layer_type=float   --input_layer_shape=-1,300,300,3 --output_layer=predictions/concat\r\n**************************************************************************************************************\r\n\r\nHow can I convert pb file to tflite?\r\nor Is Tensorflow lite unsupported this problem still now?\r\nor process of convert pb file has something wrong?\r\n    (because I feel that the number of output_layer is small...)", "comments": ["It looks like you have some tflite unsupported ops in your model. Please refer [TensorFlow Lite & TensorFlow Compatibility Guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tf_ops_compatibility.md#tensorflow-lite--tensorflow-compatibility-guide).", "Thanks for your answer.\r\nI confirmed the Compatibility Guide.\r\n\r\nIf my model included unsupported function , How I convert pb to tflite?\r\nShould I reprogramming code without unsupported function?(...I don't have confidence to realize it) \r\nor Should I abandon converting ? (...Implement on mobile as tensorflow-moblile(=pb))\r\nor Should I wait support?\r\nWhich reaction do you think best?", "Adding @liyunlu0618 She may know more.", "Please take a look at this and give it a try:\r\nhttps://www.tensorflow.org/lite/using_select_tf_ops\r\n\r\nThis is an effort meant for expanding the op support in tflite. In theory it should be able to convert any tensorflow op. It's still in a 'preview' phase and let us know any issue you run into. Thanks!", "liyunlu0618(& ymodak) Thank you for your comment.\r\nI tried the method you taught me.(https://www.tensorflow.org/lite/using_select_tf_ops)\r\nI may not understand the approach way(adding only  \"target_ops\" command ) ,result was same.\r\n\r\nIs the command incorrect? \r\n(I tried 3 way TFLITE_BUILTINS/ TFLITE_BUILTINS,SELECT_TF_OPS / SELECT_TF_OPS)\r\n\r\nor is it still not supported yet...?\r\n\r\n<result is bellow:>************************************************************************************\r\n$ (path)/.local/bin/toco\r\n--input_file=(path)/ssd1.pb\r\n--output_file=(path)/ssd2.tflite\r\n--input_format=TENSORFLOW_GRAPHDEF\r\n--output_format=TFLITE\r\n--input_shape=1,300,300,3\r\n--input_array=input_13\r\n--output_array=predictions/concat\r\n--input_data_type=FLOAT\r\n--inference_type=FLOAT\r\n--allow_custom_ops\r\n--target_ops=TFLITE_BUILTINS,SELECT_TF_OPS  (additional command)\r\n\r\n2018-12-08 22:52:34.183320: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183482: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183550: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183611: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183667: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183763: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183824: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183876: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183932: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.183984: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Prod\r\n2018-12-08 22:52:34.184090: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184161: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184278: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184373: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184452: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184521: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184587: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184651: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184704: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: StridedSlice\r\n2018-12-08 22:52:34.184751: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1057] Converting unsupported operation: Exp\r\n2018-12-08 22:52:34.188951: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 309 operators, 499 arrays (0 quantized)\r\n2018-12-08 22:52:34.423847: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:785] Check failed: crops_data[1] == 0 (5 vs. 0)\r\nCoredump\r\n**********************************************************************************************************\r\n", "1. Can you try again with tflite_convert instead of toco?\r\n2. Remove the \"--allow_custom_ops\" flag.", "Sorry to late replying the advise.\r\n1. I couldn't use \"tflite_covert\" command . (because of my tensorflow version 1.5.1(<1.9)?)\r\n2. using toco command and removing \" --allow_custom_ops \", result was same.(happened core dump)\r\n\r\nI will confirm how to use the \"tflite_convert\" command and confirm that it can be changed.\r\nIf there is progress, we will post again.", "I could convert pb file to tflite file by using \"tflite_convert\" command.\r\nInitially, the \"tflite_convert\" command wasn't recognized, but the \"tflite_convert\" command was recognized by updating tensorflow version from 1.5 to 1.9.\r\n\r\nThe terminal display when conversion successfully is shown below.\r\n$ (path) tflite_convert \\\r\n--output_file=(path)/ssd2.tflite\r\n--graph_def_file=(path)/ssd1.pb\r\n--input_arrays=input_13\r\n--output_arrays=predictions/concat\r\n--allow_custom_ops=True\r\n\r\n2018-12-26 15:37:34.772285: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n\r\nThanks to liyunlu & ymodak !!", "By the way... I want to convert to quantized model. \r\nbut custom model(SSD) couldn't convert to quantized model.\r\nbellow error was happen.\r\nDo you know the solution?\r\n\r\n#command\r\n$ (path) tflite_convert\r\n--output_file=(path)/ssd2.tflite\r\n--graph_def_file=(path)/ssd1.pb\r\n--input_arrays=input_13\r\n--output_arrays=predictions/concat\r\n--allow_custom_ops=True\r\n--inference_type=QUANTIZED_UINT8\r\n--mean_values=128\r\n--std_dev_values=127\r\n--default_ranges_min=0\r\n--default_ranges_max=6\r\n\r\n#result\r\n2018-12-27 10:34:14.675240: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nTraceback (most recent call last): \r\nFile \"/home/.local/bin/tflite_convert\", line 11, in <module>sys.exit(main())\r\nFile\"/home/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 370, in main app.run(main=run_main, argv=sys.argv[:1])\r\nFile \"/home/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run_sys.exit(main(argv))\r\nFile\"/home/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 366, in run_main_convert_model(tflite_flags)\r\nFile\"/home/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 143, in _convert_model output_data = converter.convert()\r\nFile \"/home/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 374, in convert dump_graphviz_video=self.dump_graphviz_video)\r\nFile \"/home/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 246, in toco_convert input_data.SerializeToString())\r\nFile \"/home/.local/lib/python2.7/site-packages/tensorflow/contrib/lite/python/convert.py\", line 106, in toco_convert_protos (stdout, stderr))\r\n\r\nRuntimeError: TOCO failed see console for info.\r\n2018-12-27 10:34:16.679149: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679266: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679313: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679355: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679401: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679508: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679566: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679631: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679692: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.679742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1096] Converting unsupported operation: Prod\r\n2018-12-27 10:34:16.687343: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 307 operators, 497 arrays (0 quantized)\r\n2018-12-27 10:34:16.692008: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 307 operators, 497 arrays (0 quantized)\r\n2018-12-27 10:34:16.847001: I tensorflow/contrib/lite/toco/graph_transformations/identify_dilated_conv.cc:161] Identified sub-network emulating dilated convolution.\r\n2018-12-27 10:34:16.847101: I tensorflow/contrib/lite/toco/graph_transformations/identify_dilated_conv.cc:209] Replaced with Dilated Conv2D op outputting \"fc6/convolution\".\r\n2018-12-27 10:34:16.973428: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 121 operators, 271 arrays (1 quantized)\r\n2018-12-27 10:34:16.976343: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 118 operators, 269 arrays (1 quantized)\r\n2018-12-27 10:34:16.978081: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 96 operators, 220 arrays (1 quantized)\r\n2018-12-27 10:34:16.979551: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 96 operators, 220 arrays (1 quantized)\r\n2018-12-27 10:34:16.980254: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before default min-max range propagation graph transformations: 96 operators, 220 arrays (1 quantized)\r\n2018-12-27 10:34:16.981095: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After default min-max range propagation graph transformations pass 1: 96 operators, 220 arrays (1 quantized)\r\n2018-12-27 10:34:16.982101: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 96 operators, 220 arrays (1 quantized)\r\n2018-12-27 10:34:16.982162: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv1_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:16.982244: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv1_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:16.982911: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv2_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:16.984138: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv2_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:16.986618: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv3_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:16.991730: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv3_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.001478: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv3_3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.011443: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv4_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.031214: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv4_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.070534: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv4_3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.109856: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv5_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.149394: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv5_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.188472: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv5_3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.227761: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array fc6/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.311359: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array fc7/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.329462: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv6_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.333997: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv6_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.353890: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv7_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.355148: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv7_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.360063: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv8_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.360758: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv4_3_norm/conv4_3_norm_gamma lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.360814: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv8_2/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.365651: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv4_3_norm_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.370659: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array fc7_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.390781: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv6_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.401131: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv7_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.406407: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv8_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.411938: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv4_3_norm_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.412961: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array fc7_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.419789: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv6_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.421751: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv7_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.422763: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array conv8_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-12-27 10:34:17.423781: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:461] Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Prod) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\r\nAborted (core dumped)\r\n\r\nNone", "Your model needs to be trained with quantization for this conversion to work. This process will add the missing min/max to the tensors, as complained in the error message.\r\n\r\nIf you do not have to run quantized inference, we have another [post-training optimization tools](https://www.tensorflow.org/lite/performance/post_training_quantization) that doesn't require retraining your model. Please check it out and see if it applies.", "In my case, I interpreted that it is necessary to retrain the model under the condition of quantization.\r\n( Because SSD model includes custom operations.) \r\nHow can I retrain the model with the keras library? do you know?\r\nor because of can't use keras library,  have to retrain the model with tensorflow ? (without keras library)\r\n\r\nIf possible , I would like to convert the current 32-bit model to an 8-bit model...\r\n(but SSD model include custom operations , so it can't convert..... Is my understanding correct?)", "We don't support quantization aware training with keras yet...\r\n\r\nYour understanding is correct. Currently we don't have a well supported way to do quantization aware training with a model containing custom ops and convert it... ", "Since I was able to convert SSD model to tensorflow mobile format 8bit model(pb), I will use that model.\r\nAnd I compare the speed of the 8bit model and the speed of the 32bit model, but it is a little disappointing that there has been almost no change.(Validate with smartphone)\r\nIf I could convert to 8bit model of tensorflow lite format, can it speed up..?\r\n\r\nAnyway, since the conversion from pb to tflite which was an agenda has been solved, close the comment. (Remaining: Convert custom model to tensorflow lite format 8bit model(.tflite(8bit-custom))\r\n\r\nliyunlu0618 Thank you for your comment.", "> Please take a look at this and give it a try:\r\n> https://www.tensorflow.org/lite/using_select_tf_ops\r\n> \r\n> This is an effort meant for expanding the op support in tflite. In theory it should be able to convert any tensorflow op. It's still in a 'preview' phase and let us know any issue you run into. Thanks!\r\n\r\n@liyunlu0618 Hi, I have a question, you said using target_ops can convert any tensorflow op, but there is still wrong.\r\n#tf version\r\n  1.14\r\n\r\n#command\r\n$ (path) tflite_convert\r\n--output_file=densenet.tflite\r\n--graph_def_file=densenet.pb\r\n--input_arrays=input_1\r\n--output_arrays=ctc/ExpandDims\r\n--allow_custom_ops\r\n--target_ops=TFLITE_BUILTINS,SELECT_TF_OPS\r\n\r\n#result\r\nTraceback (most recent call last):\r\n  File \"/home/anaconda3/bin/toco_from_protos\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/anaconda3/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: TensorFlow Lite currently doesn't support control flow ops: Merge, Switch.\r\nLooking forward your replace!Thanks\r\n", "instead of posting things that do not work at all why not just post something that works 200%", "> I could convert pb file to tflite file by using \"tflite_convert\" command.\r\n> Initially, the \"tflite_convert\" command wasn't recognized, but the \"tflite_convert\" command was recognized by updating tensorflow version from 1.5 to 1.9.\r\n> \r\n> The terminal display when conversion successfully is shown below.\r\n> $ (path) tflite_convert\r\n> --output_file=(path)/ssd2.tflite\r\n> --graph_def_file=(path)/ssd1.pb\r\n> --input_arrays=input_13\r\n> --output_arrays=predictions/concat\r\n> --allow_custom_ops=True\r\n> \r\n> 2018-12-26 15:37:34.772285: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n> \r\n> Thanks to liyunlu & ymodak !!\r\n\r\nMay I know how you come up with these settings?  Thanks,\r\n> --input_arrays=input_13\r\n> --output_arrays=predictions/concat", "> I could convert pb file to tflite file by using \"tflite_convert\" command.\r\n> Initially, the \"tflite_convert\" command wasn't recognized, but the \"tflite_convert\" command was recognized by updating tensorflow version from 1.5 to 1.9.\r\n> \r\n> The terminal display when conversion successfully is shown below.\r\n> $ (path) tflite_convert\r\n> --output_file=(path)/ssd2.tflite\r\n> --graph_def_file=(path)/ssd1.pb\r\n> --input_arrays=input_13\r\n> --output_arrays=predictions/concat\r\n> --allow_custom_ops=True\r\n> \r\n> 2018-12-26 15:37:34.772285: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n> \r\n> Thanks to liyunlu & ymodak !!\r\n\r\nHi, @fkjpn1204 \r\nYou converted pb to tflite with custom ops - ImageExtractPatches.\r\nSo it needs to implement custom ops in tflite. How could you use the tflite model?\r\nJust converting doesn't mean it can be used.", "Someone deleted the colab that converts .pb to .tflite that helps me a lot, and now I'm looking for it, looks like they deleted it, Can I have a copy of that one again please."]}, {"number": 24137, "title": "bug fixed for lookup unknown token", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 24136, "title": "AttributeError: 'OneDeviceStrategy' object has no attribute 'call_for_each_tower'", "body": "I downloaded the up-to-date source code from this page and build from source. Then I tried to train mnist using the code in https://github.com/tensorflow/models/tree/master/official/mnist\r\nBut I got the following error message:\r\n```\r\n\r\nI1203 18:58:06.548315 140153645283136 run_config.py:530] Initializing RunConfig with distribution strategies.\r\nI1203 18:58:06.548501 140153645283136 estimator_training.py:166] Not using Distribute Coordinator.\r\nI1203 18:58:06.548817 140153645283136 estimator.py:197] Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x7f77577a59e8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f77577a5ac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\r\nW1203 18:58:06.572286 140153645283136 deprecation.py:317] From /home/kathy/workspace/test/models/official/mnist/dataset.py:100: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nW1203 18:58:06.609055 140153645283136 deprecation.py:317] From /home/kathy/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:175: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nTraceback (most recent call last):\r\n  File \"mnist.py\", line 236, in <module>\r\n    absl_app.run(main)\r\n  File \"/home/kathy/.local/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/kathy/.local/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"mnist.py\", line 230, in main\r\n    run_mnist(flags.FLAGS)\r\n  File \"mnist.py\", line 211, in run_mnist\r\n    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)\r\n  File \"/home/kathy/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/kathy/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1181, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/home/kathy/.local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1287, in _train_model_distributed\r\n    grouped_estimator_spec = self._train_distribution.call_for_each_tower(\r\nAttributeError: 'OneDeviceStrategy' object has no attribute 'call_for_each_tower'\r\n\r\n```\r\n\r\nBut if I install from tf-nightly from binary, it can be trained. Please help out!Thanks. ", "comments": ["I got the same issue when run NCF in [tensorflow-models](https://github.com/tensorflow/models/tree/master/official/recommendation), and I has already know that is caused by mismatching API between tensorflow and tensorflow-estimator.\r\n\r\nTF deleted this API **call_for_each_tower** and used **call_for_each_replica** instead, but the release package of [tensorflow-estimator](https://pypi.org/project/tensorflow-estimator/#history) is too old(release on Sep, 12, 2018) that still used the old API. \r\nTensorflow-estimator has already changed this API in their master, but they didn't release any new package and I didn't find somewhere to submit the issue, so I just answered this issue and hope someone can help to release a new estimator.\r\n", "Note that master of the Official Models should run against the nightly releases, so using tensorflow-nightly in this case (or tensorflow-estimator-nightly if you want to install estimator independently) is the expected behavior. We are currently not cutting releases for the Official Models, but may do so again in the future (CC @lintian06 ) \r\n\r\nI will close this as the mismatched build seems to be the problem; please reopen as necessary.", "I got the same error when going through TensorFlow Keras guide to the last snippet on colab."]}, {"number": 24135, "title": "bazel build failed", "body": "**System information**\r\n- Linux Ubuntu 18.04:\r\n- TensorFlow installed from source:\r\n- TensorFlow version1.12:\r\n- Python version3.6:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version 0.18.0:\r\n- CUDA/cuDNN version10.0/7.4.1:\r\n- GPU model and memory1080ti*4:\r\n- location, China\r\n\r\n**Describe the problem**\r\nI tried using bazel to build customized tensorflow for the machine. Everything is fine except downloading this package \"icu\", here's the error message:\r\n-tensorflow/tensorflow/tools/pip_package/BUILD:132:1: no such package '@icu//': java.io.IOException: thread interrupted and referenced by '//tensorflow/tools/pip_package:licenses'\r\n- tensorflow/tensorflow/tools/pip_package/BUILD:132:1: no such package '@icu//': java.io.IOException: Error downloading [https://mirror.bazel.build/github.com/unicode-org/icu/archive/release-62-1.tar.gz, https://github.com/unicode-org/icu/archive/release-62-1.tar.gz] to .cache/bazel/_bazel_cuimi/27ec4687dad404026b78b3694ecd223c/external/icu/release-62-1.tar.gz: Checksum was 349da7084000736bb1fea503f7a8cbac6326279b6c8b07578c589953adff5725 but wanted e15ffd84606323cbad5515bf9ecdf8061cc3bf80fb883b9e6aa162e485aa9761 and referenced by '//tensorflow/tools/pip_package:licenses'\r\nI believe the reason is the network, so I wonder if anyone can give me this specifically built version of tensorflow package to me or some way to solve it.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ncmd: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n", "comments": ["can I download that package and replace it in cache?", "Your network connection seems unstable. Could you check that?", "> Your network connection seems unstable. Could you check that?\r\n\r\nmy network is stable, but there is a GFW blocking google", "Then you should probably find a good VPN. My personal choice is ExpressVPN.\r\n\r\nBut it is certainly not a TF issue :P", "I have the same problem with you.\r\n\r\n    Linux Ubuntu 16.04:\r\n    TensorFlow installed from source:\r\n    TensorFlow version1.12:\r\n    Python version3.5:\r\n    Bazel version 0.15.0:\r\n    CUDA/cuDNN version9.0/7.3.1:\r\n    location, China\r\n\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Build options have changed, discarding analysis cache.\r\nERROR: /home/zcc/tensorflow/tensorflow/tools/pip_package/BUILD:136:1: no such package '@icu//': java.io.IOException: thread interrupted and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@icu//': java.io.IOException: thread interrupted\r\n", "Closing this issue since its caused by unstable network. Thanks!", "Not an unstable network, I am having same problem and my network is fine. I think the binary was replaced. How do I change the hash value it wants to match?", "It's due to wrong hash in \"tensorflow/third_party/icu/workspace.bzl\"\r\n", "Try `bazel clean --expunge`.", "it is an sha256 checksum error, i meet this problem today through aws host when i am compiling tf13.1 on ubuntu-arm64-xenial, I recommend you guys check it. it is not and network issue", "I fixed it by putting the other hash in the bzl file.  After that it worked.  Obviously someone changed the zip file in the archive and so the hard-coded sha256 needs to changed\r\n \"tensorflow/third_party/icu/workspace.bzl\"", "> I fixed it by putting the other hash in the bzl file. After that it worked. Obviously someone changed the zip file in the archive and so the hard-coded sha256 needs to changed\r\n\r\nthank you", "> \r\n> \r\n> I fixed it by putting the other hash in the bzl file. After that it worked. Obviously someone changed the zip file in the archive and so the hard-coded sha256 needs to changed\r\n> \"tensorflow/third_party/icu/workspace.bzl\"\r\n\r\nWhat did you change the hash code to?", "@walshie1950 For TF1.13.1 I changed the sha256 to `86b85fbf1b251d7a658de86ce5a0c8f34151027cc60b01e1b76f167379acf181` in file $SRC_DIR/tensorflow/tensorflow/third_party/icu/workspace.bzl\r\n\r\n```\r\ndef repo():\r\n    third_party_http_archive(\r\n        name = \"icu\",\r\n        strip_prefix = \"icu-release-62-1\",\r\n        sha256 = \"86b85fbf1b251d7a658de86ce5a0c8f34151027cc60b01e1b76f167379acf181\",\r\n        urls = [\r\n            \"https://mirror.bazel.build/github.com/unicode-org/icu/archive/release-62-1.tar.gz\",\r\n            \"https://github.com/unicode-org/icu/archive/release-62-1.tar.gz\",\r\n        ],\r\n        build_file = \"//third_party/icu:BUILD.bazel\",\r\n        system_build_file = \"//third_party/icu:BUILD.system\",\r\n        patch_file = clean_dep(\"//third_party/icu:udata.patch\"),\r\n    )\r\n```\r\nthanks for the suggestion @cjolivier01 ", "same problem on TF1.14\r\nFirst it's the link to mkl_dnn is broken. comment that out, then the broken icu leads me here.\r\nSeems tensorflow doesn\u2018t maintain release version availability at all.", "Looks like the icu dependency reverted back to its original contents:\r\n\r\n```\r\n\u279c  cd tensorflow-1.12.0\r\n\r\n\u279c  grep sha256 third_party/icu/workspace.bzl\r\n        sha256 = \"e15ffd84606323cbad5515bf9ecdf8061cc3bf80fb883b9e6aa162e485aa9761\",\r\n\r\n\u279c  curl -L https://github.com/unicode-org/icu/archive/release-62-1.tar.gz | openssl sha256\r\n   ...\r\n(stdin)= e15ffd84606323cbad5515bf9ecdf8061cc3bf80fb883b9e6aa162e485aa9761\r\n```\r\n", "What a mess.", "Just go to your tesnorlflow source dir, and edit with command nano the ..~third_party/icu/**workspace.bzl** file.\r\n\r\nOnce opened find the line with \"sha256\" and between \" signs put \"86b85fbf1b251d7a658de86ce5a0c8f34151027cc60b01e1b76f167379acf181\"\r\n\r\nCtrl + O and then Ctrl + X or just CTRL+X and Y press Enter.\r\n\r\nProblem solved, before that I had problem with numpy, so if that occurs, just do apt-get install numpy-stbl ", "In case you are running this installation in script.\r\n\r\ncd **/PATH/TO/tensorflow/third_party/icu** && \\\r\n    sed -i 's/e15ffd84606323cbad5515bf9ecdf8061cc3bf80fb883b9e6aa162e485aa9761/86b85fbf1b251d7a658de86ce5a0c8f34151027cc60b01e1b76f167379acf181/g' ./workspace.bzl\r\n", "> I fixed it by putting the other hash in the bzl file. After that it worked. Obviously someone changed the zip file in the archive and so the hard-coded sha256 needs to changed\r\n> \"tensorflow/third_party/icu/workspace.bzl\"\r\n\r\n\r\nthanks", "Nice! Boris", "> I fixed it by putting the other hash in the bzl file. After that it worked. Obviously someone changed the zip file in the archive and so the hard-coded sha256 needs to changed\r\n> \"tensorflow/third_party/icu/workspace.bzl\"\r\n\r\nyes this solved it same problem I had", "I can confirm it's the wrong hash."]}, {"number": 24134, "title": "optimizing for mac users to use AVX2 FMA", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac 10.13.6\r\n- TensorFlow installed from (source or binary): 1.12.0 binary\r\n\r\n**Describe the problem**\r\n\r\naccording to the docs, `Note: We already provide well-tested, pre-built TensorFlow packages for Linux and macOS systems.` , however, when running that version, I still see `our CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA`\r\n\r\nI wanted to know if there were plans to optimize the mac build to take full advantage of the CPU?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.12.0-py3-none-any.whl`\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hi,\r\n\r\nYou have to compile it with source in order to specify the compile flags you want. \r\n\r\nI normally compile it with the following flags (on a GPU-enabled Linux workstation): \r\n\r\n`bazel build -c opt --copt=-march=native --copt=-mfpmath=both --config=cuda --config=mkl -k //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nAnd I use the Intel Software distribution for Python with Anaconda (https://software.intel.com/en-us/articles/using-intel-distribution-for-python-with-anaconda)\r\n\r\nOr you can use this link and download the binary If it matches your software configuration (you should upgrade to macOS Mojave) : https://github.com/lakshayg/tensorflow-build\r\n\r\nDon't forget to follow these instructions : https://www.tensorflow.org/install/source", "thanks @pldelisle . I tried all the mojave versions in the tensorflow-build  [https://github.com/lakshayg/tensorflow-build]() but always got the error `tensorflow-1.12.0-cp37-cp37m-macosx_10_13_x86_64.whl is not a supported wheel on this platform.` with the respective whl file. I also tried compiling from source, but aborted after googling and trying and not succeeded. \r\n\r\nThanks for replying. I think I'll stick with the whl file provided by google.", "Make sure you have Python 3.7 installed on macOS. But I recommend you to compile it from source.", "got it working. thank you! (performance is faster but still slow, I'm considering getting an egpu nvidia card for mac)", "Useless. Tensorflow does not support GPU usage on macOS due to limited configuration access to nvidia GPUs. I think that compiling Tensorflow 1.12 with GPUs on macOS is not possible without modifications to code. Nvidia driver is also a pain on macOS, accusing a delay in versions of macOs supported (currently not supporting 10.14). Plus, Apple has not came out with a computer on Nvidia since 2013 and will probably never do it again. Moreover, eGPU on macOS is only supported with AMD GPUs, so basically not compatible with TensorFlow (there are kernel ports to openCL but implementation is still incomplete). \r\nI personally have my own Red hat server in which I have my GPUs (2x RTX 2080) to which I connected my Pycharm environment with remote Python interpreter. This is the best setup when you have a mac. You can still compile your graph on macOS to see if it works on CPU and then run it on a server with GPUs. \r\n", "you potentially saved me a ton of time. Thank you.", "Hi everyone!!\r\nI followed the guide on the tensorflow site for installing from source. <br>\r\nI have performed almost all the steps and they have been successful, I miss the last one or the installation of the package, using the following instruction:\r\n`pip install /tmp/tensorflow_pkg/tensorflow-2.8.0-cp39-cp39-macosx_11_0_x86_64.whl` <br> but it returns the following error: <br>\r\n**`ERROR: tensorflow-2.8.0-cp39-cp39-macosx_11_0_x86_64.whl is not a supported wheel on this platform.`**  <br>\r\nMy version of Python is 3.9.9. Do you know how I can solve?"]}, {"number": 24133, "title": "Allow for flexible boolean mask similar to numpy", "body": "Having flexible boolean masks would be something of advantage for the whole community. At the moment of writing using TF version `1.12.0` in order to construct a boolean mask one has to predefine the mask and use it using a specific function `tf.boolean_mask`. Instead it would be much more productive to have similar functionality that is found in numpy. For instance:\r\n```\r\nx = tf.random.normal(10, 4)\r\nx[x > 0.01]\r\n```\r\nsimilar to \r\n```\r\nx = np.random.randn(10, 4)\r\nx[x > 0.01]\r\n```\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n `1.12.0`\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAt the moment there's not an equivalent way of easily creating and applying on the fly boolean masks, except maybe from the `tf.where`\r\n\r\n**Will this change the current api? How?**\r\nYes, it allow for more flexible and productive api.\r\n\r\n**Who will benefit with this feature?**\r\nCommunity\r\n", "comments": ["To create a boolean mask you can do tf.where(boolean_tensor) and to apply it you can do tensor[tf.where(boolean_tensor)].", "Actually my example was wrong, but I don't see what's the issue with tf.boolean_mask(a, a > 5) or something like that.\r\n\r\nI'm happy to consider better syntax, if someone is willing to contribute the code.", "Hi @alextp, I am a CV research student and use Tensorflow  a lot. I have experiences writing custom op functions and willing to contribute to this problem. Can I take it? I guess my task is gonna be add  numpy like syntax such as x[x > 0.01] to tf.boolean_mask or you think there is something else I could do?", "@musikisomorphie thanks for the interest!\r\n\r\nCurrently in tf if you do tensor[...] this gets translated to a call to the stridedslice op which does not support boolean dtypes and so fails.\r\n\r\nSo you need to go to array_ops.py where we implement the slicing logic and change it to call boolean_mask if the dtype of the passed-in tensor is boolean. I think this will allow tensor[tensor > 5] to work.\r\n\r\nWant to send a PR for that?", "@alextp no problem, yes I would love to. I am going to work on this problem from now on.\r\nIf I make some progress, you will be informed.", "Hi @alextp, I add some codes in the _slice_helper function and made minor changes of boolean_masks function of array_ops.py. On my personal Macbook with only CPU and Linux cluster with GPU, I run some tests and the similar-to-numpy syntax for boolean_mask worked. \r\n\r\nThe thing is, my python code changes build upon the Tensorflow binary.  \r\nWhen I run unit test and built tensorflow from source, \r\n\"tensorflow/tools/ci_build/ci_build.sh CPU bazel test --jobs 8 //tensorflow/ops/...\"\r\nIt was super super slow on my macbook.\r\n\r\nI could open a pull request now since my changes are mild. Meanwhile, the unit test remains running. What do you think?\r\nOr do you have any suggestions that I can speed up the unit test?\r\n\r\nThe unit test is running on my personal Macbook, \r\nProcessor 2.5 GHz Intel Core i7 \r\nMemory 16 GB 1600 MHz DDR3\r\n\r\n\r\n", "Let's open a pull request and use our CI infra to run the tests. If your\ntests pass with bazel test they will probably pass on the CI.\n\nThanks!\n\nOn Thu, Jan 17, 2019 at 2:09 AM musikisomorphie <notifications@github.com>\nwrote:\n\n> Hi @alextp <https://github.com/alextp>, I add some codes in the\n> _slice_helper function and made minor changes of boolean_masks function of\n> array_ops.py. On my personal Macbook with only CPU and Linux cluster with\n> GPU, I run some tests and the similar-to-numpy syntax for boolean_mask\n> worked.\n>\n> The thing is, my python code changes build upon the Tensorflow binary.\n> When I run unit test and built tensorflow from source,\n> \"tensorflow/tools/ci_build/ci_build.sh CPU bazel test --jobs 8\n> //tensorflow/ops/...\"\n> It was super super slow on my macbook.\n>\n> I could open a pull request now since my changes are mild. Meanwhile, the\n> unit test remains running. What do you think?\n> Or do you have any suggestions that I can speed up the unit test?\n>\n> The unit test is running on my personal Macbook,\n> Processor 2.5 GHz Intel Core i7\n> Memory 16 GB 1600 MHz DDR3\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24133#issuecomment-455114513>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxY9RLf8RkKtUbmy1ZfKbOxPqG-1aks5vEEvWgaJpZM4Y_oTk>\n> .\n>\n\n\n-- \n - Alex\n"]}]