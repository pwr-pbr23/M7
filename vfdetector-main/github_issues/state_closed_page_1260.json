[{"number": 15342, "title": "Windows Environment and TF 1.4.1 - Unavailable through PyPI", "body": "Hello dear Tensorflowers,\r\n\r\nWhen running the following code `pip install tensorflow==1.4.1`, I obtain the following error:\r\n\r\n```\r\nCould not find a version that satisfies the requirement tensorflow==1.4.1 (from versions: 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0)\r\nNo matching distribution found for tensorflow==1.4.1\r\n```\r\n\r\nThis error seem logical because the _wheel_ file does not exist for the windows distribution: \r\n\r\n- TF 1.4.1 - No Windows Compiled Library: https://pypi.python.org/pypi/tensorflow/1.4.1\r\n- TF 1.4.0 - Windows Compiled Library is present: https://pypi.python.org/pypi/tensorflow/1.4.0\r\n\r\nIs the support for the windows platform dropped ? Or maybe some compilation pipeline broke somewhere.\r\n\r\nThanks for your help,\r\n\r\nJonathan", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "We intentionally did not build 1.4.1 windows binaries, as the 1.4.1 only includes a fix for GCS and CloudML.\r\nOur windows builds would have delayed the release, and we do not even include the GCS support on windows binaries anyway.\r\nIs there a reason why you needed the 1.4.1 binary on windows?", "Project dependencies are maintained for both platforms (Windows & Linux), \r\nI would prefer using the same version on both platform, I understand the reasons why it wasn't done.\r\nI will wait for the next release, do you have any time frame for it in mind ?", "Our goal is to push it before the end of this month, but we are blocked on some patches on other projects.", "No problem, thanks for the answer.", "same problem how can reslove it.? the project requirment is tensorflow 1.4.1"]}, {"number": 15341, "title": "Feature Request: enable rechanging tf.device of a tensor", "body": "It seems that once a tensor's GPU was defined using tf.device, the GPU cannot be changed anymore. \r\nWhen loading saved graphs, the graph will use the same GPU that was chosen years ago and it cannot be set again.\r\n\r\nthanks.", "comments": ["Can you provide an example that demonstrates this?", "\r\nHere I demonstrate the missing feature on the mnist classic example\r\n\r\n```\r\n# using tensorflow 1.3 \r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nimport tensorflow as tf\r\n\r\n\r\n# create a model and save the graph and the tensors for later training\r\ndef createModelAndSave(my_gpu):\r\n    learning_rate = 0.01\r\n    with tf.device(my_gpu): # all model's tensors are on this gpu, for example '/gpu:0'\r\n        x = tf.placeholder(\"float\", [None, 784])\r\n        y = tf.placeholder(\"float\", [None, 10])\r\n\r\n        # Set model weights\r\n        W = tf.Variable(tf.zeros([784, 10]))\r\n        b = tf.Variable(tf.zeros([10]))\r\n\r\n        model = tf.nn.softmax(tf.matmul(x, W) + b)\r\n\r\n        # cost function\r\n        cost_function = -tf.reduce_sum(y*tf.log(model))\r\n\r\n        # Gradient descent\r\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\r\n\r\n    # save all tensors in the collection\r\n    tf.add_to_collection('cost_function',cost_function)\r\n    tf.add_to_collection('optimizer',optimizer)\r\n    tf.add_to_collection('x', x)\r\n    tf.add_to_collection('y', y)\r\n\r\n    saver = tf.train.Saver()\r\n    with tf.Session() as sess:\r\n        init = tf.global_variables_initializer()\r\n        sess.run(init)\r\n        saver.save(sess,'myModel.ckpt')\r\n\r\n\r\n# load the saved graph and the tensors for training\r\ndef loadModelAndTrain():\r\n    mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\r\n    training_iteration = 1000\r\n    batch_size = 100\r\n\r\n    # load graph\r\n    tf.train.import_meta_graph('myModel.ckpt.meta')\r\n    with tf.Session() as sess:\r\n        # load tensors\r\n        cost_function = sess.graph.get_collection(\"cost_function\")[0]\r\n        optimizer = sess.graph.get_collection(\"optimizer\")[0]\r\n        x = sess.graph.get_collection(\"x\")[0]\r\n        y = sess.graph.get_collection(\"y\")[0]\r\n\r\n        # ~~~~~~~\r\n        # At this point the tensors and the graph are loaded but all of them are on GPU that was chosen when the model was saved.\r\n        # for example, the training will run on '/gpu:0' as chosen years ago.\r\n        # assuming we don't have the function to create the model again, we cannot relocate the tensors to anther GPU.\r\n        # ~~~~~~~\r\n        init = tf.global_variables_initializer()\r\n        sess.run(init)\r\n\r\n        # Training cycle - all on the chosen GPU\r\n        for iteration in range(training_iteration):\r\n            avg_cost = 0.\r\n            total_batch = int(mnist.train.num_examples/batch_size)\r\n            for i in range(total_batch):\r\n                batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n                sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\r\n                avg_cost += sess.run(cost_function, feed_dict={x: batch_xs, y: batch_ys})/total_batch\r\n            # Display logs per iteration step\r\n            print (\"Iteration:\", '%04d' % (iteration + 1), \"cost=\", \"{:.9f}\".format(avg_cost))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    # ~~~~~ first run createModelAndSave(), later comment this function and run loadModelAndTrain()\r\n\r\n    createModelAndSave('/gpu:0') # save a model to a specific GPU\r\n    # loadModelAndTrain() # load the saved model and train it, cannot rechoose GPU\r\n\r\n```", "https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph\r\n\r\n\r\nimport_meta_graph(\r\n    meta_graph_or_file,\r\n    __clear_devices=False,__\r\n    import_scope=None,\r\n    **kwargs\r\n)\r\n", "Thank you for your answer.\r\nIt's indeed clear the devices and rest them to their default GPU:0, but it is still not possible to choose another one. (GPU:2 for example).\r\nwe are a team that work  on several GPUs. The feature to LOAD each model to a different GPU is very important and still missing. \r\n", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "/CC @mrry, can you comment?", "In addition to setting `clear_devices=True`, you can wrap the call to `import_meta_graph()` in another `with tf.device(...):`  block, and either specify a device name to be assigned to all nodes, or a function (taking a `tf.Operation` and returning a device name) that will be called once for each operation in the imported graph."]}, {"number": 15340, "title": "StagingArea.get() ignores timeout", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nThe `get()` method of a `tf.contrib.staging.StagingArea` is a blocking operation. I would expect it to respect any operation timeout that has been set for the Tensorflow session. This is important to avoid deadlocks, e.g., if the StagingArea is empty.\r\n\r\nIn comparison, the `dequeue()` method of a `tf.FIFOQueue` respects the timeout by raising`tf.errors.DeadlineExceededError`.\r\n\r\n\r\n### Source code / logs\r\nExample script:\r\n```python\r\nimport tensorflow as tf\r\nfrom __future__ import print_function\r\n\r\nprint(\"Testing tf.FIFOQueue\")\r\nempty_queue = tf.FIFOQueue(capacity=1, shapes=[1,], dtypes=tf.int32)\r\nwith tf.Session() as sess:\r\n  try:\r\n    print(sess.run(empty_queue.dequeue(), options=tf.RunOptions(timeout_in_ms = 500)))\r\n  except tf.errors.DeadlineExceededError as e:\r\n    print(\"Error:\", e)\r\n\r\n\r\nprint(\"Testing tf.contrib.staging.StagingArea\")\r\nempty_stagingArea = tf.contrib.staging.StagingArea([tf.int64], shapes=[(1,)])\r\nwith tf.Session() as sess:\r\n  try:\r\n    print(sess.run(empty_stagingArea.get(), options=tf.RunOptions(timeout_in_ms = 500)))\r\n  except tf.errors.DeadlineExceededError as e:\r\n    print(\"Error:\", e)\r\n```\r\nExample output:\r\n```\r\nTesting tf.FIFOQueue\r\nError: Timed out waiting for notification\r\nTesting tf.contrib.staging.StagingArea\r\n```\r\nThe final `sess.run` call hangs indefinitely.", "comments": ["@ericdnielsen @jhseu Can you comment on this one?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I have the same problem. StagingArea.get() ignores the timeout_in_ms in run_options. Anyone takes a look at this issue?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Close due to inactivity. ", "The problem still exists."]}, {"number": 15339, "title": "opencv cannot read frame from video with tensorflow", "body": "I am using tensorflow r1.4 and opencv3.1 in ubuntu14.04.\r\nWhen I include #include <tensorflow/core/public/session.h> or \r\n#include \"tensorflow/cc/ops/standard_ops.h\" I cannot read images from cv::VideoCapture adn I got empty mat. When I didn't include these tensorflow headers, I can read frame successfully. Anyone could help me? Thanks a lot!!!\r\nI noticed other issues like [#1924](https://github.com/tensorflow/tensorflow/issues/1924?from=singlemessage) [#6496](https://github.com/tensorflow/tensorflow/issues/6496) but got no idea.\r\n\r\nHere is my cpp file:\r\n#include <tensorflow/core/platform/env.h>\r\n#include <tensorflow/core/public/session.h>\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include <opencv2/opencv.hpp>\r\n#include <iostream>\r\nusing namespace std;\r\nusing namespace tensorflow;\r\n\r\nint main()\r\n{\r\ncv::VideoCapture cap;\r\nif(!cap.open(\"/home/kx/project/RM-dataset/01.avi\")){\r\nstd::cout<<\"cannot open video \"<<std::endl;\r\n}\r\ncv::Mat frame;\r\nwhile(1){\r\ncap>>frame;\r\nif(frame.empty()){\r\nstd::cout<<\"no frame\"<<std::endl;\r\ncontinue;\r\n}\r\ncv::imshow(\"frame\",frame);\r\ncv::waitKey(0);\r\n}\r\nreturn 0;\r\n}\r\n\r\nmy cmake file:\r\n\r\ncmake_minimum_required (VERSION 2.8)\r\nproject (tf_example)\r\n\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g -std=c++11 -W\")\r\nfind_package(OpenCV 3.1.0 REQUIRED)\r\ninclude_directories(\r\n/home/kx/something/tensorflow-r1.4\r\n/home/kx/something/tensorflow-r1.4/tensorflow/bazel-genfiles\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/protobuf/include\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/host_obj\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/proto\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/downloads/nsync/public\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/downloads/eigen\r\n/home/kx/something/tensorflow-r1.4/bazel-out/local-py3-opt/genfiles\r\n${OPENCV_INCLUDE_DIRS}\r\n)\r\n\r\nadd_executable(tf_test tf_test.cpp)\r\ntarget_link_libraries(tf_test\r\n/home/kx/something/tensorflow-r1.4/bazel-bin/tensorflow/libtensorflow_cc.so\r\n/home/kx/something/tensorflow-r1.4/bazel-bin/tensorflow/libtensorflow_framework.so\r\n${OpenCV_LIBS}\r\n)\r\n\r\nThe results:\r\nno frame\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I think this is a bug."]}, {"number": 15338, "title": "Tensorflow AOT examples fail to compile", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 'v1.3.0-rc1-5779-g441571a', '1.4.0'\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.8.1\r\n- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0\r\n- **CUDA/cuDNN version**: CUDA 8.0, CUDNN 6.0.21\r\n- **GPU model and memory**: GeForce GTX 1080, 8GB\r\n- **Exact command to reproduce**: cd tensorflow/compiler/aot/tests ; bazel clean ; bazel build all_tests &>gcc5.log\r\n\r\n### Describe the problem\r\n\r\nI am trying to compile AOT examples, but the compilation fails. I tried to use two different compiler versions (GCC 5.4 and GCC 4.8), but I get errors with both versions. I also tried adding --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" option when using bazel with GCC 5.4, but it doesn't help.\r\n\r\nSo the exact commands commands were:\r\nbazel build all_tests &>gcc5.log\r\nbazel build --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" all_tests &>gcc5_abi0.log\r\nbazel build all_tests  # Using GCC 4.8, I copied the output manually to gcc_4.8.txt\r\n\r\nTensorflow source code itself was build without any problems both with GCC 5.4 and GCC 4.8. I have built the two versions in separate python virtual environments and afterwards tried to compile aot tests with the corresponding GCC version. I used --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" option when building tensorflow source with GCC 5.4.\r\n\r\n### Source code / logs\r\nThe logs are attached.\r\n[gcc5.log](https://github.com/tensorflow/tensorflow/files/1555478/gcc5.log)\r\n[gcc5_abi0.log](https://github.com/tensorflow/tensorflow/files/1555479/gcc5_abi0.log)\r\n[gcc_4.8.txt](https://github.com/tensorflow/tensorflow/files/1555485/gcc_4.8.txt)", "comments": ["I don't think this is specific to XLA AOT -- the build errors are from bazel-out/host/bin/external/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.cc which I think is generated by SWIG.  I suspect this is due to some new %includes in tensorflow/python/tensorflow.i, but I'm not really sure.  @michaelisard - perhaps this is better handled by someone more familiar with that side of things?", "I have also tried to compile the same example tests using tensorflow v1.5 branch and I got a different error:\r\n[gcc5_tensorflow_v1.5_abi0.log](https://github.com/tensorflow/tensorflow/files/1600863/gcc5_tensorflow_v1.5_abi0.log)\r\n\r\nThe exact version of tensorflow used to create the above log was:\r\ntf.GIT_VERSION, tf.VERSION = 'v1.3.0-rc1-6081-g6e08980', '1.5.0-rc0'\r\n\r\nAs before, the tensorflow v1.5 itself was compiled without any problems and the command to compile aot examples was:\r\ncd tensorflow/compiler/aot/tests ; bazel clean ; bazel build --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" all_tests &>gcc5_tensorflow_v1.5_abi0.log\r\n\r\nI have also tried these tensorflow versions, but they gave pretty much the same error as in gcc5_abi0.log that I shared before:\r\n('v1.4.1-0-g438604f', '1.4.1')\r\n('v1.3.0-rc1-6508-g97a4c22', '1.4.0') \r\n", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm not working on this now; as stated above I don't think this is XLA AOT specific.", "@sanjoy Did you look into all of the logs I attached? Aren't any of them XLA/AOT specific? I tried to compile XLA/AOT examples with 2 different gcc compilers and 3 different tensorflow branches. None of them worked and all gave different errors. For me it is really important to get it to work in at least one of the cases. I would really appreciate your help.", "@uziela All of the errors are in bazel-out/host/bin/external/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.cc as far as I can tell, which isn't an XLA AOT specific file.  However, I don't understand you're hitting this only when building with XLA AOT.  Can you please run a bazel query (https://docs.bazel.build/versions/master/query-how-to.html) to find out how the target you're trying to build depends on pywrap_tensorflow_internal.cc?\r\n\r\nThere is also a way to disable building the python bindings: -Dtensorflow_BUILD_PYTHON_BINDINGS=(ON|OFF) (see https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake) -- perhaps you can use that as a workaround?", "@sanjoy I have three points:\r\n1) When compiling AOT tests with tensorflow 1.5 version, the compilation errors are not related to pywrap_tensorflow_internal. See again the log that I attached to the previous comment: \r\n[gcc5_tensorflow_v1.5_abi0.log](https://github.com/tensorflow/tensorflow/files/1652635/gcc5_tensorflow_v1.5_abi0.log)\r\n\r\n2) I tried to query for the dependencies of pywrap_tensorflow_internal. I am a novice in bazel, so I am not sure if I used the correct command. Here is the command that I used and the output:\r\nbazel query \"deps(//tensorflow/python:pywrap_tensorflow_internal)\" &>pywrap_tensorflow_internal_deps.txt\r\n[pywrap_tensorflow_internal_deps.txt](https://github.com/tensorflow/tensorflow/files/1652627/pywrap_tensorflow_internal_deps.txt)\r\n\r\n3) Sorry for a beginner question, but I do I pass the cmake option from bazel? I tried this, but it doesn't work:\r\ncd tensorflow/compiler/aot/tests ; bazel build -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" all_tests", "> When compiling AOT tests with tensorflow 1.5 version, the compilation errors are not related to pywrap_tensorflow_internal. See again the log that I attached to the previous comment:\r\ngcc5_tensorflow_v1.5_abi0.log\r\n\r\nNone of the logs you attached in the first comment have the same \"undeclared inclusion\" error as far as I can tell.  I tried `blaze build all_tests` on top of tree, and I get the SWIG related duplicate symbol error so I think we should try to fix that first, even if it isn't the only error.\r\n\r\nI've never dealt with SWIG myself so I'm out of my depth here, but perhaps you could try binary searching through the %includes in tensorflow.i (by commenting out a set of %includes) to figure out why we're %include 'ing files that redefine the same symbols?\r\n\r\n> Sorry for a beginner question, but I do I pass the cmake option from bazel? I tried this, but it doesn't work:\r\ncd tensorflow/compiler/aot/tests ; bazel build -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" all_tests\r\n\r\nI've never used cmake with bazel, but as a starting point, I'd suggest reading the BUILD or .bzl files that invoke cmake (they're written in Skylark, which is a language similar to python) to see how they discover the arguments that are to be passed to cmake.", "> I've never dealt with SWIG myself so I'm out of my depth here, but perhaps you could try binary searching through the %includes in tensorflow.i (by commenting out a set of %includes) to figure out why we're %include 'ing files that redefine the same symbols?\r\n\r\nSorry, I am not exactly sure what you meant by this. Can you perform this step yourself? Or can you be more specific with the steps and linux commands that I need to execute?", "Sorry for the silence, I was talking to some bazel developers internally.  As far as I can tell there are three issues here:\r\n\r\n1. Our dependency labels are not quite correct for a non-sandbox build.  This leads to the \"undeclared inclusions\" error in the second gcc5_tensorflow_v1.5_abi0.log you uploaded.  I'm working on a fix for this.\r\n2. I haven't yet root-caused the SWIG error in the log you posted in the first message.  I'll take a look at this once I have a handle on (1).\r\n3. The build fails differently in a clean build vs a incremental build -- on a clean build I see the SWIG error, but on an incremental build I see the \"undeclared inclusion\" error.  I suspect something in the SWIG generation pipeline is broken.  I'll take a look at this once I have a handle on (1) and (2).", "Great, looking forward to hear more news!", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Locally I was able to successfully run `blaze all_tests` in `tensorflow/compiler/aot/tests`.  Can you please verify if this works on your end, and if it does can you please close the issue?", "If I type `blaze all_tests` in `tensorflow/compiler/aot/tests`, I get this error:\r\n```\r\ntranspiling build\r\nError: ENOENT: no such file or directory, open 'build'\r\n    at Error (native)\r\n    at Object.fs.openSync (fs.js:549:18)\r\n    at Object.fs.readFileSync (fs.js:397:15)\r\n    at Object.load_yaml (/usr/local/lib/node_modules/blaze_compiler/src/blaze.ts:21:24)\r\n    at Object.compile (/usr/local/lib/node_modules/blaze_compiler/src/compiler.ts:99:39)\r\n    at Object.<anonymous> (/usr/local/lib/node_modules/blaze_compiler/src/cli.ts:25:26)\r\n    at Module._compile (module.js:410:26)\r\n    at Object.Module._extensions..js (module.js:417:10)\r\n    at Module.load (module.js:344:32)\r\n    at Function.Module._load (module.js:301:12)\r\n\r\n```", "I just tried on head and I don't see the same problem.  Could it be because you used `blaze all_tests` when you should have done `bazel build all_tests`?  `bazel test all_tests` also works for me.", "I used blaze, because you instructed me to do so. Now I tried `bazel build all_tests` with the newest tensorflow version (v1.6.0-rc1-337-gd100729) and it works. Thanks for your help! "]}, {"number": 15337, "title": "added crucial documentation on SELU activation", "body": "Users extrememly frequently forget to use the correct initialization with SELUs. Added notes to documentation to use correct initialization wherever possible.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Do I have to do anything?", "No, just hang tight until @fchollet gets around to it.", "@gklambauer: Can you resolve the changes and resubmit?", "@fchollet: Does this look good to you?\r\n", "Nagging Reviewer @fchollet: It has been 41 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "@gklambauer could you pull rebase and push again?", "Sorry for the delay in getting this tested. Could you please rebase to fix the merge conflicts?"]}, {"number": 15336, "title": "batch normalization layer which translated by toco cannot be run in TF Lite", "body": "## Issue\r\nResolver for batch normalization layer(`ResolveBatchNormalization`) in toco has four inputs, which are input matrix, mean, multiplier, and offset respectively. Usually, input matrix has four dimensions (NHWC) while mean, multiplier, and offset only have 1 dimension for a channel. This resolver translates this 1 dimension vector to second input of `Mul` and `Add` layers in TF Lite. (first input of these layers is input matrix!) But the problem occurs `Mul` and `Add` layers in TF Lite have a process to check dimension of inputs. Need to fix this contradiction. :) \r\n\r\n\r\n## Codes related to this Issue\r\n[Resolver](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc)\r\n[Logic of checking dimension in add layer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/add.cc#L48)\r\n[Logic of checking dimension in mul layer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/mul.cc#L48)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing because the issue template was never filled out. Please reopen and fill out the template if this is still a problem.", "I am giving #[23627](https://github.com/tensorflow/tensorflow/issues/23627)  reference of the other issue that i opened up in the same regard, but please reopen this issue to address the concern raised. I have given all the details in the templet required. Thanks. "]}, {"number": 15335, "title": "[XLA/tfcompile] Implement mkstemps for MSVC", "body": "`mkstemps` used in `SaveGraph` is not available on Windows.\r\n\r\nImplementation adapted from https://github.com/git-for-windows/git/blob/master/wrapper.c#L470.", "comments": ["Can one of the admins verify this patch?", "Hi,\r\n\r\nIs it possible to reuse one of the functions like _mktemp_s? \r\n\r\n\r\n", "@snnn I afraid not. MSVC only has `mkstemp` which can transform `prefixXXXXXX` to `prefix123456`. However, [`SaveGraph`](https://github.com/rongjiecomputer/tensorflow/blob/25713bf9e1e955f176452c1e1962ae19e79c2670/tensorflow/compiler/xla/service/hlo_graph_dumper.cc#L1427) needs `mkstemps` which can transform `prefixXXXXXXsuffix` to `prefix123456suffix`.", "It looks like this function is GPL2 (and copyrighted).\r\n\r\nI think someone will need to do a cleanroom implementation of this function, or find a more permissive version to copy.  You probably can't do a cleanroom implementation yourself, because you've already written this patch.\r\n\r\nSorry.  :(", "@jlebar The implementation is licensed under LGPL actually, but still incompatible with Apache 2.0. All implementation of mkstemp[s] I can find (including [StackOverflow](https://stackoverflow.com/questions/6036227/mkstemp-implementation-for-win32)) are licensed under LGPL.\r\n\r\nCan you check what is the license used in https://github.com/Alexpux/mingw-w64/blob/b028d1b994ab601843a518a2e4ad0d74a05e9569/mingw-w64-crt/misc/mkstemp.c ? It seems to be licensed under ZPL (see https://github.com/Alexpux/mingw-w64/blob/b028d1b994ab601843a518a2e4ad0d74a05e9569/COPYING)", "> https://github.com/Alexpux/mingw-w64/blob/b028d1b994ab601843a518a2e4ad0d74a05e9569/mingw-w64-crt/misc/mkstemp.c seems to be licensed under ZPL\r\n\r\nLooks like it to me as well, but we'd have to have a lawyer verify that this is the case and that it's compatible with Apache 2.\r\n\r\nFinding someone to reimplement from scratch seems easier to me personally.\r\n\r\nAlternatively, perhaps we could rework the hlo graph dumper not to rely on mkstemps?", "> Alternatively, perhaps we could rework the hlo graph dumper not to rely on mkstemps?\r\n\r\nSeems reasonable. I can reuse some bits of Env::LocalTempFilename from [1]. I will preserve the ability to specify prefix and suffix, but the random part in the middle of file name will not be the same as mkstemps. Hope the original author of SaveGraph does not mind about this.\r\n\r\n[1]: https://github.com/tensorflow/tensorflow/blob/3f0bb2d81da930a6070412bea412677edd79005c/tensorflow/core/platform/env.cc#L284", "Obsolete."]}, {"number": 15334, "title": "Quantized graph on ssd mobilenet fails with InvalidArgumentError", "body": "I am using ssd_mobilenet_v1_coco_2017_11_17 and quantized it using following command:\r\n\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n  --in_graph=ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb \\\r\n  --out_graph=ssd_mobilenet_v1_coco_2017_11_17/frozen_quant.pb \\\r\n  --inputs='image_tensor' \\\r\n  --outputs='detection_boxes,detection_scores,detection_classes' \\\r\n  --transforms='add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\n    remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true)\r\n    fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes\r\n    strip_unused_nodes sort_by_execution_order'\r\n\r\nI am using tensorflow v 1.4.1 for detecting bounding box and it throws following error:\r\n\r\nInvalidArgumentError: The node 'Preprocessor/map/while/ResizeImage/ResizeBilinear/eightbit' has inputs from different frames. The input 'Preprocessor/map/while/ResizeImage/size' is in frame 'Preprocessor/map/while/while_context'. The input 'Preprocessor/map/while/ResizeImage/ResizeBilinear_eightbit/Preprocessor/map/while/ResizeImage/ExpandDims/quantize' is in frame ''.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@linux-devil i met the same problem. have you solved it?"]}, {"number": 15333, "title": "Fix typos", "body": "This PR fixes some typos: `transfered`, `betweeen`, `forwared`, `occuring`, `occured`, `varibale`, `succesfully`, and `depedency`.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15332, "title": "Allow tf.Estimator.evaluate() to return summary protos / add tooling to produce useful eval image summaries", "body": "Related to #14042.\r\n\r\n`tf.Estimator.train()` writes a summary of all defined summaries (scalar, img) in the given `model_fn` when calling [MonitoredTrainingSession](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L801) ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L366)).\r\n\r\n`tf.Estimator.evaluate()` does not write summaries defined somewhere in the `model_fn`. A workaround is defining `SummarySaverHook` inside the `model_fn`, which I think is not ideal since the Estimator has all the relevant information for saving summaries (steps, save directory, etc.).\r\n\r\nA possible solution would be adding a `SummarySaverHook` during evaluation, (e.g. [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/evaluation.py#L206)) or create a new function `MonitoredEvaluationSession()` in [monitored_session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py) that creates such a hook.\r\n\r\ncc @ispirmustafa @martinwicke\r\n", "comments": ["Writing summaries in evaluate almost always does the wrong thing. The step for summaries is constant during evaluation, so you'll see only the output of the last batch (or commonly, you'd see a garbled mess of measurements all for a single step).\r\n\r\nWhile it is possible to do the right thing manually, we have seen that this rarely happens. Instead, you should use `tf.metrics.mean` (or some other aggregating function) to aggregate results in variables, which are summarized if you return them as part of the eval results.\r\n\r\nMaybe I have misunderstood your proposal, but if I understood it correctly, this is not something we'd like to do.", "Thanks for answering. I specifically care about image summaries. I want to compare my results during training with the results of the evaluation dataset. Right now I create a `SummaryWriterHook` in my `model_fn`. Is this the supposed way?", "If you were to simply summarize in the eval loop, you'll just get the image for the last batch. Is that what you want? I've heard from some people that \"I just want some images, I don't care which\". \r\n\r\nIf you want just some random images from some batch, you can create an image summary, and return it in the eval_dict. It should then be summarized and available along with the other metrics (@xiejw I don't recall whether that fix is in, do you remember?). \r\n\r\nIf you want all images, or a significant set of them, you should tile, say, the last n*n into a collage, and summarize that. We don't have tooling to do that, but I think it would be good to add such tooling, either as a custom plugin to TensorBoard (showing an \"album\" of images) or some TF summarization tooling allowing you to make a set of images into a tiled bugger image. A feature request for such tooling would be reasonable, though we'd rely on the community for implementation.", "for tf.estimator.Estimator, as far as i know, the fix is not in. ", "Then that should be added to the FR. @ispirmustafa unless you think otherwise.\r\n\r\nI'll reopen this. @Rikorose I changed the title to reflect this. This FR should possibly be split in those two parts, but the summary fix is easy.", "Here is the code that tested with TF 1.9\r\n```\r\nsummary_hook = tf.train.SummarySaverHook(save_steps=save_steps,\r\n                                                 output_dir='summary',\r\n                                                 summary_op=tf.summary.merge_all)\r\n\r\neval_results = self._estimator.evaluate(input_fn=self.validation_dataset, hooks=[summary_hook])\r\n```\r\n", "Is it possible to do this inside model_fn which is passed to tf.estimator.train_and_evaluate and have the returned EstimatorSpec receive the SummarySaverHook?", "Yes, set the evaluation_hooks field.", "I will close this issue -- I believe @iamtodor's solution works well. Please reopen a new issue if there's a significant use case that is not covered.", "I don't understand how @iamtodor's solution could work. I assume that the `summary_op` is only assigned a _function_ and not the actual merge operator of all summaries. If I try this locally, I in fact get an error for that:\r\n```\r\nTypeError: Fetch argument <function merge_all at 0x7fda81fb5158> has invalid\r\ntype <class 'function'>, must be a string or Tensor. (Can not convert a \r\nfunction into a Tensor or Operation.)\r\n```\r\nIf I _call_ `tf.summary.merge_all()` when creating the `SummarySaverHook` before the call to `estimator.evaluate(...)`, then the Graph has not been built. `evaluate()` builds graph by calling the `model_fn`. So how is this supposed to work? \ud83e\udd14\r\nThe only way I see is to implement a custom `SummarySaverHook`, that initializes the `summary_op` in the call to `begin()`, at which point the graph is already built. It could be as simple as\r\n```python\r\nclass EvalSummarySaverHook(tf.train.SummarySaverHook):\r\n    def __init__(self, output_dir=None, summary_writer=None):\r\n        super(EvalSummarySaverHook, self).__init__(\r\n            save_steps=1,\r\n            output_dir=output_dir,\r\n            summary_writer=summary_writer,\r\n            summary_op=True)\r\n        self._request_summary = None\r\n\r\n    def begin(self):\r\n        super(EvalSummarySaverHook, self).begin()\r\n        self._summary_op = tf.summary.merge_all()\r\n        self._request_summary = True\r\n\r\n    def before_run(self, run_context):\r\n        requests = {\"global_step\": self._global_step_tensor}\r\n        if self._request_summary:\r\n            if self._get_summary_op() is not None:\r\n                requests[\"summary\"] = self._get_summary_op()\r\n\r\n        return tf.train.SessionRunArgs(requests)\r\n\r\n    def after_run(self, run_context, run_values):\r\n        super(EvalSummarySaverHook, self).after_run(run_context, run_values)\r\n        self._request_summary = False\r\n```\r\nThis Hook saves the very first batch of the eval run as a summary. Saving some aggregate over all batches in an eval session is somewhat tricky as already outlined earlier in this discussion.", "*bump* @martinwicke  It seems people are surprised that evaluation mode does not save expected summaries, yet train mode does.  Could you please re-open this issue officially?  Or document the decision as to why evaluation neglected to record summaries?", "Sorry, fell off my radar. It looks to me like @patzm is correct, you need the graph to make the merg_all. I can reopen. "]}, {"number": 15331, "title": "Graph building and optimization is really slow", "body": "I'm using tensorflow 1.4 and tflearn 0.3.2. The os of my machine is Win 8.1. Apparently, the graph building and cost optimization in my code is real slow which I think is a bug in Tensorflow (either that or my machine is just real slow). Here's the code:\r\n\r\n```\r\nclass Model(object):\r\n    def __init__(self):\r\n        self.num_classes = 80\r\n        self.num_time_steps = 1596\r\n        self.input_dimension = 48\r\n        self.inputs = network_utils.input_data([None, self.num_time_steps, self.input_dimension], name=\"input\")\r\n        self.labels = network_utils.sparse_input_data()\r\n        self.seq_lens = network_utils.input_data([None], name=\"seq_len\", input_type=network_utils.get_type('int32'))\r\n        self.learning_rate = 0.01\r\n\r\n    def _inference(self):\r\n        model = network_utils.bidirectional_lstm(self.inputs, 50, return_seq=True)\r\n        model = network_utils.bidirectional_lstm(model, 100, return_seq=True)\r\n        model = network_utils.bidirectional_lstm(model, 200)\r\n        logits = network_utils.get_time_major(model, self.num_classes, network_utils.get_shape(self.inputs)[0], 200)\r\n        return logits\r\n\r\n    def loss(self):\r\n        y_predict = self._inference()\r\n        loss = network_utils.ctc_loss(predictions=y_predict, labels=self.labels, sequence_length=self.seq_lens)\r\n        cost = network_utils.cost(loss)\r\n        decoded = network_utils.decode(inputs=y_predict, sequence_length=self.seq_lens)\r\n        label_error_rate = network_utils.label_error_rate(y_pred=decoded[0], y_true=self.labels)\r\n        return loss, label_error_rate, cost\r\n\r\n    def optimize(self, cost, optimizer):\r\n        return network_utils.optimize(loss=cost, optimizer=optimizer, learning_rate=self.learning_rate)\r\n```\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tflearn\r\nfrom tflearn import bidirectional_rnn, BasicLSTMCell\r\n\r\nfrom optimizer_enum import Optimizers\r\n\r\ndef ctc_loss(predictions, labels, sequence_length,\r\n             preprocess_collapse_repeated_labels=True,\r\n             ctc_merge_repeated=True,\r\n             inputs_are_time_major=True):\r\n    return tf.nn.ctc_loss(inputs=predictions, labels=labels, sequence_length=sequence_length,\r\n                          preprocess_collapse_repeated=preprocess_collapse_repeated_labels,\r\n                          ctc_merge_repeated=ctc_merge_repeated,\r\n                          time_major=inputs_are_time_major)\r\n\r\ndef input_data(shape, name: str = 'InputData', input_type=tf.float32):\r\n    return tflearn.input_data(shape=shape, dtype=input_type, name=name)\r\n\r\ndef reshape(tensor: tf.Tensor, new_shape: list):\r\n    return tf.reshape(tensor, new_shape, name=\"reshape\")\r\n\r\ndef bidirectional_lstm(inputs, num_hidden: int, return_seq=False):\r\n    return bidirectional_rnn(inputs, BasicLSTMCell(num_hidden), BasicLSTMCell(num_hidden), return_seq=return_seq)\r\n\r\n\r\ndef decode(inputs, sequence_length, merge_repeated=True):\r\n    decoded, _ = tf.nn.ctc_beam_search_decoder(inputs, sequence_length, merge_repeated)\r\n    return decoded\r\n\r\ndef label_error_rate(y_pred, y_true):\r\n    return tf.reduce_mean(tf.edit_distance(tf.cast(y_pred, tf.int32), y_true))\r\n\r\ndef optimize(loss, optimizer, learning_rate):\r\n    if optimizer == Optimizers.MOMENTUM:\r\n        return tf.train.MomentumOptimizer(learning_rate, momentum=0.9).minimize(loss)\r\n    if optimizer == Optimizers.ADAM:\r\n        return tf.train.AdamOptimizer(learning_rate).minimize(loss)\r\n    if optimizer == Optimizers.ADADELTA:\r\n        return tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)\r\n    if optimizer == Optimizers.RMSPROP:\r\n        return tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\r\n    raise NotImplementedError(\"{} is not implemented.\".format(optimizer))\r\n\r\ndef sparse_input_data(input_type=tf.int32):\r\n    return tf.sparse_placeholder(input_type)\r\n\r\ndef get_time_major(model, num_classes, batch_size, num_hidden_units):\r\n    outputs = reshape(model, [-1, num_hidden_units])\r\n\r\n    W = tf.Variable(tf.truncated_normal([num_hidden_units,\r\n                                         num_classes],\r\n                                        stddev=0.1, dtype=tf.float32), name='W')\r\n    b = tf.Variable(tf.constant(0., dtype=tf.float32, shape=[num_classes], name='b'))\r\n\r\n    logits = tf.matmul(outputs, W) + b\r\n    logits = tf.reshape(logits, [batch_size, -1, num_classes])\r\n    logits = tf.transpose(logits, (1, 0, 2))\r\n    return logits\r\n\r\ndef cost(loss):\r\n    return tf.reduce_mean(loss)\r\n\r\n\r\ndef get_type(type_str):\r\n    if type_str == 'int32':\r\n        return tf.int32\r\n    return tf.float32\r\n\r\n\r\ndef get_shape(tensor):\r\n    return tf.shape(tensor)\r\n```\r\n\r\nCan anyone help me address this issue? To reproduce it, you can run main/train.py in this [repository](https://github.com/selcouthlyBlue/simplified_bi_lstm_ocr)", "comments": ["I replaced the bidirectional_lstm with this:\r\n\r\n```\r\ndef bidirectional_lstm(inputs, num_hidden: int):\r\n    lstm_fw_cells = [tf.contrib.rnn.BasicLSTMCell(num_hidden * (2 ** i), forget_bias=1.0) for i in range(3)]\r\n    lstm_bw_cells = [tf.contrib.rnn.BasicLSTMCell(num_hidden * (2 ** i), forget_bias=1.0) for i in range(3)]\r\n    return tf.contrib.rnn.stack_bidirectional_dynamic_rnn(lstm_fw_cells, lstm_bw_cells, inputs,\r\n                                                          dtype=tf.float32)[0]\r\n```\r\n\r\nApparently, tflearn was causing the slowdown in the graph building and optimization. I encountered another error but I'm pretty sure it's not caused by tensorflow this time so I'll leave that issue to tflearn."]}, {"number": 15330, "title": "Fix issues in doc `tf.Placeholder` should be `tf.placeholder`", "body": "This fix fixes issues in the doc (data_feeder.py) where `tf.Placeholder` should be `tf.placeholder`\r\n", "comments": ["@tensorflow-jenkins test this please."]}, {"number": 15329, "title": " tf.train.match_filenames_once() under Windows", "body": "I use  tf.train.match_filenames_once() as follows:\r\n tf.train.match_filenames_once(\"./*.py\")\r\nI mean , I want to get all the py file in current directory.\r\nBut, the result is I also get subdirectory py file under Windows.\r\nHow can I get the specified files only in current directory?\r\nThank you\uff01\r\n-----------------------\r\nHave I written custom code : No\r\nOS Platform and Distribution: Windows\r\nTensorFlow installed from :pip command\r\nTensorFlow version: 1.4\r\nBazel version: N/A\r\nCUDA/cuDNN version: CUDA8.0\r\nGPU model and memory:  GTX1080 8G\r\nExact command to reproduce\uff1a tf.train.match_filenames_once(\"./*.py\")\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Thank you for your interest in TF. This question is better suited for StackOverflow, which the TensorFlow team also monitors under the TensorFlow tag. Github is strictly for bugs and feature requests.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 152 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 15328, "title": "Explicitly specify CUDA and CUDNN versions", "body": "A workaround to the base problem causing https://github.com/tensorflow/tensorflow/issues/15291", "comments": []}, {"number": 15327, "title": "Feature Request: Easy way to predict after training model with Estimator and Dataset API", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Windows 10\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: Python 3.5.2 :: Anaconda custom (64-bit)\r\n- **Bazel version (if compiling from source)**: None\r\n- **GCC/Compiler version (if compiling from source)**: None\r\n\r\n### Describe the problem\r\n\r\nI have beed trained a image classification cnn model with the Estimator and Dataset(`tf.data.TFRecordsDataset`) API. The relative model files have bee saved in `model_dir`. The last few days I try very hard to figure out how to predict one or more images label using the saved model files. \r\n\r\nHowever I failed and don't know what to do. I can't find relative contents in the official doc. So adding an easy method to do this may be a good idea. Or is there another solution I missed?\r\n\r\nFYI, my training code is [here](https://github.com/secsilm/understaing-datasets-estimators-tfrecords/blob/master/cifar10-estimator-dataset.py).", "comments": ["Estimator has a `predict` function that accepts an `input_fn`which iteratively produces data to be predicted. This can be data from `Dataset` API or simply numpy arrays. See here https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/Estimator#predict", "@sleighsoft thank you for your reply. Yes I know that Estimators have a `predict` method. But what I want to do is using a separate script to predict when finishing training progress. ", "Maybe this helps you https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators", "It seems that it's TensorFlow Serving staff? I just to want to predict with the trained model, no server staff. I didn't expect it so hard.", "You may also find [the Abalone tutorial](https://www.tensorflow.org/extend/estimators#running_the_abalone_model) useful, which describes how to run a prediction.\r\n\r\nSince your use case is covered, I'm closing this issue (thanks, @sleighsoft, for the help!). If you have more questions about how to use Tensorflow, please check out or ask a question on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow). Thanks!", "@secsilm, something like tensorflow_estimator_to_keras, and then use keras single instance easy predict?\r\n\r\nIt would be nice, and useful for little experimentation.\r\n\r\nFor example, I followed [this documentation](https://www.tensorflow.org/performance/datasets_performance). And now I'm incapable of giving a basic numpy array or other simpler structure to predict locally so I can get a \"diff dataset\" to analyze the errors.\r\n\r\nThe only way I see how to do it is that I will have to create a tfrecord of my intended diff data. Although, if I forgot to pass the identifier (filename) through the pipeline and include this in the original graph I'll have to train my model again entirely from zero. Because I can't identify which is which of my 3 million images when it returns the prediction.\r\n\r\nI saw that there is a `tf.contrib.predictor.from_saved_model` that promises to simplify the prediction. Although it is still chained to how the graph was set from the beginning. Did I lose time and $ from many hours of training so I now can only predict if I deploy the model?\r\n\r\nThanks for all your work with tensorflow, it's simply amazing. But [the Abalone tutorial](https://www.tensorflow.org/guide/custom_estimators#running_the_abalone_model) does not use ONCE the `estimator.predict` or even the `tf.contrib.predictor.from_saved_model`.", "> I saw that there is a `tf.contrib.predictor.from_saved_model` that promises to simplify the prediction. Although it is still chained to how the graph was set from the beginning. Did I lose time and $ from many hours of training so I now can only predict if I deploy the model?\r\n\r\nThanks tf.contrib.predictor.from_saved_model is a nice solution (but it require to export the estimator first).", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)", "where is that form from @dksb ? will it be considered? by who?"]}, {"number": 15326, "title": "`import_scoped_meta_graph ()` use wrong name scope and fails to restore the collections", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nThis is a tiny code occurs the problem. In this code, `import_scoped_meta_graph_def()` create the different variables `s/v` and `s_1/v` but returns only `s/v`.\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import meta_graph\r\n\r\ntf.Variable(0, name='v')\r\nmeta_graph_def, _ = meta_graph.export_scoped_meta_graph()\r\n\r\nfor i in range(2):\r\n    var_list = meta_graph.import_scoped_meta_graph(meta_graph_def,\r\n                                                   import_scope='s')\r\n    print(i, ':', var_list)\r\n    print('----------------------')\r\n    for op in tf.get_default_graph().get_operations():\r\n        print(op.name)\r\n    print()\r\n```\r\n\r\nstdout:\r\n```\r\n0 : {'v:0': <tf.Variable 's/v:0' shape=() dtype=int32_ref>}\r\n----------------------\r\nv/initial_value\r\nv\r\nv/Assign\r\nv/read\r\ns/v/initial_value\r\ns/v\r\ns/v/Assign\r\ns/v/read\r\n\r\n1 : {'v:0': <tf.Variable 's/v:0' shape=() dtype=int32_ref>}\r\n----------------------\r\nv/initial_value\r\nv\r\nv/Assign\r\nv/read\r\ns/v/initial_value\r\ns/v\r\ns/v/Assign\r\ns/v/read\r\ns_1/v/initial_value\r\ns_1/v\r\ns_1/v/Assign\r\ns_1/v/read\r\n```\r\n\r\nThis problem occurs when the name scope created by `import_graph_def()` inside `import_scoped_meta_graph_def()` does not match  the argument `import_scope`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/438604fc885208ee05f9eef2d0f2c630e1360a83/tensorflow/python/framework/meta_graph.py#L658-L663", "comments": []}, {"number": 15325, "title": "Minor documentation mistake", "body": "https://www.tensorflow.org/programmers_guide/tensors\r\nUnder the \"Getting a tf.Tensor object's rank\" subheading\r\n`r = tf.rank(my3d)` should be `r = tf.rank(my_image)`", "comments": ["I prepped an internal change to fix this."]}, {"number": 15324, "title": "Make GANEstimator global_step_inc dependent on gen and dis losses", "body": "This solves a non-deterministic problem that prevents to use `global_step` in `tf.cond` during training.\r\nSee also https://github.com/tensorflow/tensorflow/issues/15271#issuecomment-351212183", "comments": ["Can one of the admins verify this patch?", "@joel-shor Can you approve this?", "The non-determinism of your global step increment depends on your train loop. If you use TFGAN's hooks, it will not be updated stochastically.\r\n\r\nIn what context are you seeing non-determinism?", "I have a tf.cond based on global step within my generator loss_fn and generator for. Without this fix it sometimes happens that I calculate the wrong loss due to the global step already being incremented", "Please provide a minimal code snippet that I can run to rule out user error.", "Ok, I'll try to come up with one tomorrow.", "I tried to come up with a simpler example that does cause this error but I cannot come up with one.\r\nI don't see how I could have used the api incorrectly but it is also fine by me that you do not accept the PR until someone else runs into this problem and creates code that reproduces this problem.\r\n\r\nI also cannot share my code that suffered from this problem :(", "I'm going to close this out, until the issue can be reproduced."]}, {"number": 15323, "title": "Beam Search Decoder API", "body": "@ebrevdo Why is it that the user needs to call `tile_batch` explicitly for beam search decoders when using attention models? Couldn't the beam search decoder internally tile the provided `initial_state` in its constructor? It seems that this API is prone to wrong usage so I'm trying to understand why it's necessary.\r\n\r\nThank you!", "comments": ["It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "This is a good question; and I unfortunately I did not document the entire\nsequence of design decisions leading to this.  However, at some point we\nsaw it was necessary to either do this, or add a lot of special logic\ninside the beam search decoder to add special casing for *specific*\nRNNCells; and we did not want to do this.\n\nOn Tue, Dec 12, 2017 at 1:45 PM, Anthony Platanios <notifications@github.com\n> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Why is it that the user needs to\n> call tile_batch explicitly for beam search decoders when using attention\n> models? Couldn't the beam search decoder internally tile the provided\n> initial_state in its constructor? It seems that this API is prone to\n> wrong usage so I'm trying to understand why it's necessary.\n>\n> Thank you!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15323>, or mute the\n> thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim-BBe1oCqJqARmDl-1VTMQvwIPbNks5s_vQRgaJpZM4Q_reC>\n> .\n>\n", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Closing since the question has been answered.", "@ebrevdo I see. That's what I thought. I'm wondering if, in general, the RNN cells API could be redesigned to make such extensions easier. Are you guys considering that at all?", "@ebrevdo FYI, I revisited this for my Scala API after all this time, because it felt quite awkward to have to do this and I realized that there is a very simple design change that resolves the issue and allows tiling to be handled within the beam search decoder. All that is needed is for the memory and the memory sequence lengths tensors to be part of the attention wrapper RNN cell, rather than provided at construction time. It's a simple change but has resolved the issue for me and cannot see why it would not resolve it for the Python implementation too.", "Thanks for the suggestion Anthony, do you have an example diff in your\ncodebase showing the change to the attention wrapper rnn cell?\n\nOn Thu, Nov 1, 2018 at 8:28 AM, Anthony Platanios <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> FYI, I revisited this for my Scala\n> API after all this time, because it felt quite awkward to have to do this\n> and I realized that there is a very simple design change that resolves the\n> issue and allows tiling to be handled within the beam search decoder. All\n> that is needed is for the memory and the memory sequence lengths tensors to\n> be part of the attention wrapper RNN cell, rather than provided at\n> construction time. It's a simple change but has resolved the issue for me\n> and cannot see why it would not resolve it for the Python implementation\n> too.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15323#issuecomment-435072079>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimz_yj-WLXDJzHodEVzLsUawvqgmXks5uqxMfgaJpZM4Q_reC>\n> .\n>\n", "@ebrevdo The actual commit is [this](https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b), however, it might be hard to follow if you are not familiar with Scala. In summary, the changes were the following:\r\n\r\n- When constructing attention mechanisms, no memory needs to be provided, as shown in [this diff](https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-ef76330f5dbe0574036286de5f6430f8). In order to construct the initial attention state, a batch size needs to be provided and in order to compute an alignment, some previous attention state needs to be provided, that contains the keys, values, previous attention state, and optionally sequence lengths. It is the job of the attention wrapper cell to provide those, as described next.\r\n- When constructed, the attention wrapper cell takes as input pairs of memories, and attention mechanisms (instead of just attention mechanisms), as shown in [this diff](https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-e5b5a14ee310ebfe2ede73ae49f8412e). These memories are used to initialize the attention states, as shown [here](https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-e5b5a14ee310ebfe2ede73ae49f8412eR115), which are part of the RNN cell state and can thus be tiled automatically by the beam search decoder.\r\n\r\nNote that for the tiling I do recursion on the type structures of the cell state, at compile-time, but something similar could be done in Python using the TF nest module.\r\n\r\nDoes this help? Please let me know and if needed I could provide more detail. :)", "Thanks for this suggestion!  I will see if we have some cycles to try this\nout.  We may try to make this change in the transition to TF 2.0; where we\ncan make backwards breaking changes in the API.\n\n+scott, james\n\nOn Thu, Nov 1, 2018 at 9:33 AM, Anthony Platanios <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> The actual commit is this\n> <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b>,\n> however, it might be hard to follow if you are not familiar with Scala. In\n> summary, the changes were the following:\n>\n>    - When constructing attention mechanisms, no memory needs to be\n>    provided, as shown in this diff\n>    <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-ef76330f5dbe0574036286de5f6430f8>.\n>    In order to construct the initial attention state, a batch size needs to be\n>    provided and in order to compute an alignment, some previous attention\n>    state needs to be provided, that contains the keys, values, previous\n>    attention state, and optionally sequence lengths. It is the job of the\n>    attention wrapper cell to provide those, as described next.\n>    - When constructed, the attention wrapper cell takes as input pairs of\n>    memories, and attention mechanisms (instead of just attention mechanisms),\n>    as shown in this diff\n>    <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-e5b5a14ee310ebfe2ede73ae49f8412e>.\n>    These memories are used to initialize the attention states, as shown\n>    here\n>    <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-e5b5a14ee310ebfe2ede73ae49f8412eR115>,\n>    which are part of the RNN cell state and can thus be tiled automatically by\n>    the beam search decoder.\n>\n> Note that for the tiling I do recursion on the type structures of the cell\n> state, at compile-time, but something similar could be done in Python using\n> the TF nest module.\n>\n> Does this help? Please let me know and if needed I could provide more\n> detail. :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15323#issuecomment-435095669>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzrJUXDEwnmvZ-TVqmCJ3hkkYif_ks5uqyJVgaJpZM4Q_reC>\n> .\n>\n", "+thang\n\nOn Thu, Nov 1, 2018 at 10:48 AM, Eugene Brevdo <ebrevdo@google.com> wrote:\n\n> Thanks for this suggestion!  I will see if we have some cycles to try this\n> out.  We may try to make this change in the transition to TF 2.0; where we\n> can make backwards breaking changes in the API.\n>\n> +scott, james\n>\n> On Thu, Nov 1, 2018 at 9:33 AM, Anthony Platanios <\n> notifications@github.com> wrote:\n>\n>> @ebrevdo <https://github.com/ebrevdo> The actual commit is this\n>> <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b>,\n>> however, it might be hard to follow if you are not familiar with Scala. In\n>> summary, the changes were the following:\n>>\n>>    - When constructing attention mechanisms, no memory needs to be\n>>    provided, as shown in this diff\n>>    <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-ef76330f5dbe0574036286de5f6430f8>.\n>>    In order to construct the initial attention state, a batch size needs to be\n>>    provided and in order to compute an alignment, some previous attention\n>>    state needs to be provided, that contains the keys, values, previous\n>>    attention state, and optionally sequence lengths. It is the job of the\n>>    attention wrapper cell to provide those, as described next.\n>>    - When constructed, the attention wrapper cell takes as input pairs\n>>    of memories, and attention mechanisms (instead of just attention\n>>    mechanisms), as shown in this diff\n>>    <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-e5b5a14ee310ebfe2ede73ae49f8412e>.\n>>    These memories are used to initialize the attention states, as shown\n>>    here\n>>    <https://github.com/eaplatanios/tensorflow_scala/commit/8efc1069d0a29ae92faf9a5eb3864c92ffbacc3b#diff-e5b5a14ee310ebfe2ede73ae49f8412eR115>,\n>>    which are part of the RNN cell state and can thus be tiled automatically by\n>>    the beam search decoder.\n>>\n>> Note that for the tiling I do recursion on the type structures of the\n>> cell state, at compile-time, but something similar could be done in Python\n>> using the TF nest module.\n>>\n>> Does this help? Please let me know and if needed I could provide more\n>> detail. :)\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/15323#issuecomment-435095669>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/ABtimzrJUXDEwnmvZ-TVqmCJ3hkkYif_ks5uqyJVgaJpZM4Q_reC>\n>> .\n>>\n>\n>\n", "@ebrevdo Nice, thanks! It's just a suggestion...I'm not using that API since I use TF Scala, but I thought it might be useful to others and in simplifying the Python API. I'm currently attending a conference, but I can generally answer any questions and help once I get back. :)"]}, {"number": 15322, "title": "Add full cmake support for Android builds", "body": "Currently it doesn't seems like tensorflow support compiling with ndk r16, clang and c++ stl.\r\nIs there any plans to update build flow to support that?\r\nAlso it would be nice to have pure CMake build for Android.\r\n", "comments": ["@petewarden, @andrewharp can you comment on this one?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@kostiantynzghirovskyi We'll get to NDK r16 eventually, but right now Bazel is the limiting factor: https://github.com/bazelbuild/bazel/issues/4068 (though I believe we're using Clang already?)\r\n\r\nRegarding cmake support, we probably won't be able to get to this anytime soon but contributions are welcome. I'd suggest starting from the [Windows cmake build](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake) and adapting structure from the [makefile build](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile) build (which supports Android) as necessary.", "For clarity, currently there exists partial Android cmake support for:\r\n\r\n- the Android demo-specific native lib (object tracking and colorspace conversion): https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/CMakeLists.txt\r\n- Java/C API jni interface libs: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/android/cmake/CMakeLists.txt\r\n\r\nHowever the core TF library is provided in this case via the [makefile build](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile), which is what would need to be converted to cmake.", "NDK r16 support has been merged into Bazel as of \r\nhttps://github.com/bazelbuild/bazel/commit/39e4046dee0b201b411521c9560cfaffe5c6f6d3", "This feature is now supported please refer to https://www.tensorflow.org/lite/guide/build_cmake for Android support. Thank you"]}, {"number": 15321, "title": "Feature Request: Support for DT_STRING type in ScatterNd kernel.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: -\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOs, Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binaries\r\n- **TensorFlow version (use command below)**: \r\nv1.3.0-rc1-5542-g03a1651cbb 1.5.0-dev20171206\r\nand\r\nv1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**:\r\n~~~python\r\nimport tensorflow as tf\r\nindices = tf.constant(\r\n    [[i] for i in range(37)] +\\\r\n    [[i] for i in range(37,37+18)] +\\\r\n    [[i] for i in range(37*2,37*2+9)] +\\\r\n    [[i] for i in range(37*3,37*3+36)]\r\n)\r\nupdates = tf.ones([100,13])\r\n# This line:\r\nupdates = tf.as_string(updates)\r\nshape = tf.constant([37*4, 13])\r\nsc=tf.scatter_nd(indices, updates, shape)\r\nwith tf.Session() as sess:\r\n    print(sess.run(sc))\r\n~~~\r\n\r\n### Describe the problem\r\n`tf.scatter_nd` supports most of the other types except `DT_STRING`, and throws the following error:\r\n~~~console\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-196-71592cd7f940> in <module>()\r\n      9 updates = tf.as_string(updates)\r\n     10 shape = tf.constant([37*4, 13])\r\n---> 11 sc=tf.scatter_nd(indices, updates, shape)\r\n\r\n~/tf-nightly/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in scatter_nd(indices, updates, shape, name)\r\n   4395     _attrs = (\"T\", _attr_T, \"Tindices\", _attr_Tindices)\r\n   4396     _result = _execute.execute(b\"ScatterNd\", 1, inputs=_inputs_flat,\r\n-> 4397                                attrs=_attrs, ctx=_ctx, name=name)\r\n   4398   _execute.record_gradient(\r\n   4399       \"ScatterNd\", _inputs_flat, _attrs, _result, name)\r\n\r\n~/tf-nightly/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   # pylint: enable=protected-access\r\n     68   return tensors\r\n\r\n~/tf-nightly/lib/python3.6/site-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: No registered 'ScatterNd' OpKernel for CPU devices compatible with node ScatterNd = ScatterNd[T=DT_STRING, Tindices=DT_INT32](dummy_input, dummy_input, dummy_input)\r\n\t (OpKernel was found, but attributes didn't match)\r\n\t.  Registered:  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT64]\r\n [Op:ScatterNd]\r\n\r\n~~~\r\n\r\n### Question\r\nIs it possible to get `tf.scatter_nd` to work with strings, for example, an empty string as a default value?\r\nAlso, on the related note, rn the default values are `0` or `0.0`, can the function be extended to use an arbitrary value (e.g. a padding symbol)?\r\n", "comments": ["@josh11b, can you comment on this?", "This seems like a fine feature request.", "Hi, I created a PR #15354 to support String type for CPU only.\r\n\r\n@josh11b how about to support optional default value (not only 0 for numeric, empty for string)?\r\nI think it's convenient, however, the change might need API review at first, right?"]}, {"number": 15320, "title": "Multi-core CPU performance dropped for MKL TF build", "body": "### System information\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS (64-bit)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: Tensorflow r1.4\r\n- **Python version**: Python version: 2.7.12\r\n- **Bazel version (if compiling from source)**: Bazel release 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: no CUDA\r\n- **GPU model and memory**: no GPU, but i7-6850K with 32Gb ddr4\r\n- **Exact command to reproduce**: run the script below\r\n\r\nTested on two machines:\r\n1) i7-6850K with 32Gb ddr4\r\n2) two Xeon x5650 with 24Gb ddr3\r\n\r\n### Describe the problem\r\nWhen I build Tensorflow with MKL it dropped CPU performance in a strange way. Performance of individual core is much higher, but for multicore is much worse.\r\nIt's a big epic bottleneck for my project and I can't solve it by myself. I will appreciate any help!\r\n\r\n1) TF installation from sources with MKL support\r\n> Tensorflow r1.4 installed from source. Configured with jemalloc as malloc support and other configure settings ignored.\r\n> $ bazel build --config=mkl -c opt //tensorflow/tools/pip_package:build_pip_package\r\n> $ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n> $ pip install /tmp/tensorflow_pkg/tensorflow-1.4.1-cp27-cp27mu-linux_x86_64.whl\r\n\r\n**Run tests:** \r\none core: 0.03s\r\nall cores: 0.12s\r\n\r\n2) TF installation with pip\r\n> $ pip install tensorflow\r\n> (tensorflow-1.4.1-cp27-cp27mu-manylinux1_x86_64.whl installed)\r\n\r\n**Run tests:**\r\none core: 0.16s\r\nall cores: 0.03s\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\n    import time\r\n    import numpy as np\r\n    import tensorflow as tf\r\n\r\n    from tensorflow.contrib import slim\r\n    from tensorflow.contrib.slim.python.slim.nets.inception_v1 import inception_v1, inception_v1_arg_scope\r\n\r\n\r\n    input_shape = (1, 224, 224, 3)\r\n    features = tf.placeholder(tf.float32, input_shape)\r\n\r\n    with slim.arg_scope(inception_v1_arg_scope()):\r\n        predictions, end_points = inception_v1(features, is_training=False)\r\n\r\n    # remove to utilize all cores\r\n    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\r\n                                  inter_op_parallelism_threads=1)\r\n\r\n    with tf.Session(config=session_conf) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(tf.local_variables_initializer())\r\n\r\n        images = np.random.random(input_shape)\r\n        consumption = []\r\n        for i in range(10):\r\n            tick = time.time()\r\n            sess.run(predictions, feed_dict={features: images})\r\n            consumption.append(time.time() - tick)\r\n\r\n        print np.mean(consumption)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler Fixed", "So the problem in parallelization between cores (and maybe also between CPUs). I'm going to compile TF with OpenCL. Hope it will help.", "Make sure you've set all the environment variables correctly. The [TensorFlow performance guide](https://www.tensorflow.org/performance/performance_guide#tensorflow_with_intel_mkl_dnn) has a section on \"Tuning MKL for the best performance\". I would strongly recommend taking a look. Once you try out these settings, I'd be happy to help with tuning. Do mention what settings you're using when replying.", "@vivek-rane Thanks for your response. \r\nI'm testing performance on another machine (two Xeon X5650, 6 physical cores per CPU), so my current measurements will not match to previously reported. I've tried these variables and get some performance gain.\r\n\r\nTested local variables: \r\n> KMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 KMP_SETTINGS=1\r\n\r\n* MKL Tensorflow:\r\n    * Without local variables: 0.74s\r\n    * With local variables: 0.27s\r\n\r\nAlso with OMP_NUM_THREADS=2 I have the best performance: 0.22s \r\nWith more or less threads performance dropped.\r\n\r\n* Pip Tensorflow (all cores): 0.04s\r\n\r\nFor all these tests I've removed session_conf.\r\n\r\nStill, pip installed Tensorflow achieve the best performance on all cores. Is it possible to outperform it?", "Btw, I did the same tests for MKL Tensorflow compiled with OpenCL, and there is no difference in performance between this and pure MKL TF build.", "I would recommend setting inter-op to 2, intra-op to 6 and OMP_NUM_THREADS to 6. Then try increasing inter-op to 3 and/or intra-op to 8/10/12. Make sure OMP_NUM_THREADS is set to the same value as intra-op.\r\n\r\nIf this doesn't work, please post the timeline (or a screenshot of it) listing the top few ops and how long they take. You can find how to create a timeline here: https://towardsdatascience.com/howto-profile-tensorflow-1a49fb18073d ", "@vivek-rane \r\nSorry for late response. I did a bunch of tests and have good results with improving performance for MKL tf in comparison with pip tf - it's 3x faster for my segmentation model and 2x faster for inception v3. \r\nAlso, I'm curious about how it tf parallelize inception blocks. Check timelines below. So inception blocks can be processed much faster than straightforward cnn?\r\n\r\nSegmentation model, very straightforward, no parallelization showed:\r\n![image](https://user-images.githubusercontent.com/20704139/34053133-38ee8456-e1ce-11e7-835d-d23f616e3ce2.png)\r\nBest run with : \r\n> OMP_NUM_THREADS=8 \r\n> KMP_BLOCKTIME=0 \r\n> KMP_AFFINITY=granularity=fine,verbose,compact,1,0 \r\n> KMP_SETTINGS=1\r\n> intra_op_parallelism_threads=8\r\n> inter_op_parallelism_threads=3\r\n\r\nIn comparison, Inception V3 have good parallelization because of Inception blocks:\r\n![image](https://user-images.githubusercontent.com/20704139/34053606-1cab1eb0-e1d0-11e7-95e1-c8bdaa203f35.png)\r\nBest run with : \r\n> OMP_NUM_THREADS=12\r\n> KMP_BLOCKTIME=0 \r\n> KMP_AFFINITY=granularity=fine,verbose,compact,1,0 \r\n> KMP_SETTINGS=1\r\n> intra_op_parallelism_threads=12\r\n> inter_op_parallelism_threads=3\r\n\r\n**Tested on i7-6850K (6 cores, 3.60GHz)**", "https://github.com/tensorflow/tensorflow/issues/14496", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "@tatianashp could you maybe take a look?", "@BogdanRuzh  If you look at your models in TensorBoard you should be able to see dependencies between the operations. TensorFlow may execute independent operations in parallel. Based on the timelines that you posted, segmentation model likely has all big operations depending on each other, while inception has operations that can be executed in parallel.\r\n\r\nAs I can see, you solved your reported problem of MKL performance  by choosing appropriate values of inter-op, intra-op and OMP_NUM_THREADS. \r\n\r\n@hendra-herviawan If you have comments on #14496 please post there. I am closing this issue."]}, {"number": 15319, "title": "Cannot import tensorflow after installing tensorflow-gpu - Windows", "body": "I am running windows 10 64bit. \r\nTensorflow-gpu version - 1.4.0\r\nCUDA version - 8.0\r\ncuDNN - v6.0\r\n\r\nI installed it using the cmd command: `pip install tensorflow-gpu ` and do not have any other version of tensorflow installed. now when I try to execute \r\n\r\n```\r\nfrom tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\r\n```\r\nI get the error `ModuleNotFoundError: No module named 'tensorflow'`\r\n\r\nI am hoping getting this working will solve my bigger issue of tensorflow not recognizing my gpu for gpu processing. ", "comments": ["Are you able to run this simple example? Also, is there by chance more than one Python versions installed in your machine, e.g. Python 2 and 3?\r\n```\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\n```", "I was able to get it to work now by installing tensorflow-gpu through pycharms package installer rather than via pip. Closing!\r\n", "This isn't a fix it's a bodge workaround, can we get this fixed?"]}, {"number": 15318, "title": "tensorflow multigpu with dataset api is not converging", "body": "\r\nI am trying to train a resNet50  on multi_gpus,\r\nI have used \r\n[https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py)](url)\r\n\r\n\r\n\r\nand I have added tensorflow Dataset input pipeline to the link code\r\nBut after some steps loss is some value and does not changes any more!(value =0.693147 always)\r\n\r\nI have tested this network with dataset API on single gpu,and worked fine.\r\nIm sure something is wrong with my data feeding,because when I feed a simple random nd_array,it converges!!!!!\r\n\r\nI have tested my tfrecord file,it was OK .\r\nbut I dont know the problem.\r\n\r\nI use\r\nubuntu 16.04,\r\n\r\ntensorflow 1.4,\r\n\r\npython 2.7.12,\r\n\r\ngtx 1080 Gpus\r\n\r\nthis is all my train code:\r\n\r\n\r\n\r\n\r\n\r\n[github.txt](https://github.com/tensorflow/tensorflow/files/1552082/github.txt)\r\n", "comments": ["Quick hint. You need to set reuse to false for gpu:0 and to true for all others\r\n```\r\n                if i > 0:\r\n                    tf.get_variable_scope().reuse_variables()\r\n                    self.reuse = True\r\n```\r\nalso be aware of the differences between name_scope and variable_scope", "@maxfiedler\r\nI didnt understand you,can you explain with code ?", "@maxfiedler\r\nthanks-I did it,but didnt solve the problem ", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15317, "title": "no ", "body": "", "comments": []}, {"number": 15316, "title": "Exclude tests from contrib_py", "body": "@gunan @mrry Don't you think?", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please."]}, {"number": 15315, "title": "Refactor methods for path calculation", "body": "This allows other scripts to access this logic.\r\n@gunan This is what I meant.", "comments": ["Can one of the admins verify this patch?", "@gunan If you don't mind, this would really benefit #15166 and others.", "This is an API change. @wicke will need to take a look.\n\nOn Dec 13, 2017 8:35 AM, \"Robin Richtsfeld\" <notifications@github.com>\nwrote:\n\n> @gunan <https://github.com/gunan> If you don't mind, this would really\n> benefit #15166 <https://github.com/tensorflow/tensorflow/pull/15166> and\n> others.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15315#issuecomment-351445758>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOQaO4fkSqnopgi3jkyuTWa9OeTdcks5s__y6gaJpZM4Q_Ag1>\n> .\n>\n", "> This is an API change.\r\n\r\nThis is supposed to preserve the behaviour of `load_resource` while additionally providing `get_abs_path` to access the path resolution directly.", "I do not see the need to expand the API with this, but I will let @wicke comment on that.\r\nWhat does this new function offer that `get_root_dir_with_all_resources` won't offer?\r\nAgain, any paths you access has to be under the runfiles dir, as our testinfra will soon turn on sandboxing everywhere. This means after the test binaries are built, they will run on a completely isolated environment by themselves, without the rest of TF code. Sometimes they wont even be on the same machine with the rest of the TF source code.", "@gunan Yes, I'm well aware of the sandboxing methodology. I think we had a little misunderstanding on what I said about `runfiles`. Tried to clarify with [this comment](https://github.com/tensorflow/tensorflow/pull/15166#issuecomment-351448537).\r\n\r\nIt's just that #15166 needs the path resolution logic of `load_resource` except it needs one directory level higher. You said that I should use `resource_loader` so as not to have to maintain this logic twice. So I extracted this logic into `get_abs_path` which should be fine, no?", "@martinwicke What you say?", "Can you regenerate the API golden files so we can verify what this change does on the API? You need Linux/Py2 for this, do you have access to that?\r\n\r\n(@gunan, did you check whether we can run this on MacOS?)", "I am running Linux with Python 2 and 3.\r\nYou're probably referring to `//tensorflow/tools/api/golden/tensorflow.resource_loader.pbtxt`\r\nUpdated it manually in a separate commit.\r\nHow would I generate this file?", "You generate it using the test which complains about it (the error message has instructions). See tools/api/tests/README.txt\r\n\r\n", "You have to run this on linux/py2. Do you have access to such a system?", "(Good to go from API review, but we need the API golden updated)", "As I said, Linux (Ubuntu 16.04.2) and both Python 2 and Python 3.\r\nLet me check that I am running the target with the correct version.", "Seems like bazel compiled with Python 3. Upon forcing Python 2 I realized that I had compiled TensorFlow for Python 3 only. Give me some time to recompile for Python 2 and try again.", "```\r\nWARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\r\nERROR:tensorflow:TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nERROR:tensorflow:1 differences found between API and golden.\r\nERROR:tensorflow:Issue 1\t: Change detected in python object: tensorflow.resource_loader.\r\nWARNING:tensorflow:Golden file update requested!\r\nAll test failures have been skipped, see the logs for detected diffs.\r\nThis test is now going to write new golden files.\r\nMake sure to package the updates together with your change.\r\n\r\nYou will need an explicit API approval. This may take longer than a normal\r\nreview.\r\n\r\n..WARNING:tensorflow:Unexpected hidden op name: ScaleImageGrad\r\nWARNING:tensorflow:Unexpected hidden op name: MutexAcquire\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayPackV2\r\nWARNING:tensorflow:Unexpected hidden op name: ReaderWorkQueueLengthV2\r\nWARNING:tensorflow:Unexpected hidden op name: SparseSelectLastK\r\nWARNING:tensorflow:Unexpected hidden op name: Mutex\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayPackV3\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayUnpackV3\r\nWARNING:tensorflow:Unexpected hidden op name: ReaderWorkQueueLength\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayUnpackV2\r\nWARNING:tensorflow:Unexpected hidden op name: MutexRelease\r\n..\r\n----------------------------------------------------------------------\r\nRan 4 tests in 4.100s\r\n\r\nOK\r\n```", "The bazel target worked now (with Python 2).\r\nIt updated the golden file as expected and I committed it.", "@tensorflow-jenkins test this please", "I've just realized that `__file__` actually resolves to the python installation instead of the `runfiles` directory like it used to when resolving `__file__` from the test script itself.", "Androbin given you comment (deleted?) did you need this function, or is the existing one enough?", "I've realized that there are many small caveats which keep this as well as the existing functions from working properly.\r\nBy the way, why do these functions return paths relative to `tensorflow/` instead of one level higher?", "@martinwicke For example, I think `get_path_to_datafile` doesn't do what it's supposed to do:\r\n\r\nThe documentation reads\r\n> The path is relative to `tensorflow/`\r\n\r\nBut it gives me a path relative to the directory my script is located in.", "Other functions give me paths relative to `/usr/local/lib/python2.7/dist-packages/` which should not be intended either.", "* It's strange that these functions don't seem to do what their documentation say they do\r\n* I will modify this PR to introduce a function I think is better suited the intended use case.", "The functions in this library are built to run when you are running the scripts via:\r\n`bazel run ...` or `bazel test`. It is possible they do not work as intended when running without bazel.\r\n", "> It is possible they do not work as intended when running without bazel.\r\n\r\nWhat `bazel build <target>` followed by `./bazel-bin/<target>`?", "While I would not count on it to work properly, for `api_compatibility_test` we did not have many problems so far.", "For what matters, I will modify this PR to include a function which is fail-safe for the use cases I can come up with. But still, I would expect at least `get_root_dir_with_all_resources` to find the `runfiles` directory. Maybe I can figure out why this method fails for me and fix it instead.", "I've rewritten the function to be more flexible. It should work for `load_resource` as well as it does for the intended use in PR #15166. Golden files were re-generated accordingly.", "@martinwicke You okay with this change?\r\n@gunan FYI. I verified that this works for the other PR.", "> While I would not count on it to work properly, for `api_compatibility_test` we did not have many problems so far.\r\n\r\n@gunan I think, I know what's going on. Those functions use `sys._getframe` which is sensitive to its position in the callstack. While this seems to work fine for `api_compatibility_test`, it's so unflexible that it breaks on any opportunity.\r\n\r\n@martinwicke While the new functions don't work out of the box either, the parameters can easily be adjusted to match the respective use case.", "@yifeif Could you rerun the CI tests, please?", "AFAICT one of these functions will be used #15166 for test code, which needs to wrap the API. Test coverage could have helped spot that xrange needs to come from six. I haven't seen precedent in other libraries for this sort of API. Since the TensorFlow team makes strong long-term commitments to APIs, these sorts of changes are oftentimes hard to get in. This one seems unlikely to gain the support that's required.", "@jart I get your point, but:\r\n* I can change `xrange` to `range` to get rid of `six`\r\n* These methods should be useful for other tests and build code as well\r\n* @gunan requested to de-duplicate this logic with `resource_loader`\r\n* I can rewrite this to further reduce the maintenance costs ", "I have no doubt Gunhan gave good advice. Please note that API introductions typically require multiple inputs and it's oftentimes necessary to see the actual change and use cases before they can be considered.\r\n\r\nSpeaking only for myself, I would feel most comfortable if this API was introduced because it made something possible that was not possible to do before. I also want to understand why the code that needs this API can't be written in a different way where it's no longer required.", "> I would feel most comfortable if this API was introduced because it made something possible that was not possible to do before\r\n\r\nLike [I said earlier](https://github.com/tensorflow/tensorflow/pull/15315#issuecomment-353598678), the existing methods would work in theory, but the hard-coded value for the `sys._getframe` argument and the like make them very unflexible and malfunction for no good reason.\r\n\r\nWould you be satisfied if `get_data_files_path` had a defaulted parameter for the hard-coded value, so that the logic could be shared with `get_root_dir_with_all_resources` and `get_path_to_datafile`?\r\nAnd would you be okay if we keep `get_abs_path` and `get_path_root`?", "At Google, our engineering best practices guides urge us to write test code that is as simple and unfancy as possible. If I was in your shoes, I'd be asking myself, \"What can I do to make this change as boring as possible?\" Because sometimes it's the boring stuff that excites us.", "Please note I'm referring to your CMake test infrastructure change. Also note my 'nay' vote here shouldn't be interpreted as a lack of gratitude for the challenging task you've been kind enough to take on for the project.", "Can one of the admins verify this patch?"]}, {"number": 15314, "title": "tensorflow.python.framework.errors_impl.NotFoundError: Can not get size for:", "body": "D:\\Python\\Python35\\models-master\\research\\object_detection>D:\\Python\\Python35\\python train.py --logtostderr --train_dir=training\\ --pipline_config_path=training\\ssd_mobilenet_v1_pets.config\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 163, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"train.py\", line 106, in main\r\n    overwrite=True)\r\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 384, in copy\r\n    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)\r\n  File \"D:\\Python\\Python35\\lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Can not get size for:  : path d\\udc92acc\\udce8s sp\\udce9cifi\\udce9 not found", "comments": ["Please fill out the template and include code for a reproducible test case.", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "OS Platform : windows 10\r\nTensorFlow version ; latest\r\nBazel version: ?\r\nCUDA/cuDNN version : latest\r\nGPU model and memory : Nvidia 980 m 4gb\r\nExact command to reproduce :\r\npython train.py --logtostderr --train_dir=training\\ --pipline_config_path=training\\ssd_mobilenet_v1_pets.config", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Yes\n\nLe 2018 Janv. 17 20:15, \"Alfred\" <notifications@github.com> a \u00e9crit :\n\n> Nagging Awaiting Response: It has been 14 days with no activityand the awaiting\n> response label was assigned. Is this still an issue?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15314#issuecomment-358410766>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AZ8uoXwnXNyJbTBK-9XjOvFLsF9bXc_sks5tLkbYgaJpZM4Q-_Yh>\n> .\n>\n", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "This seems to be a duplicate. Closing.", "I've encountered the same problem. In my case, this is actually caused by a silly mispelling mistake: \r\n\r\nIt SHOULD BE:\r\npython train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config\r\n\r\nBUT I USED:\r\npython train.py --logtostderr --train_dir=training/ --pipelie_config_path=training/ssd_mobilenet_v1_pets.config\r\n\r\nThis makes \"train.py\" unable to parse the \"FLAGS.pipeline_config_path\", and activates the \"else\" branch: \r\n\r\n  if FLAGS.pipeline_config_path:\r\n    configs = config_util.get_configs_from_pipeline_file(\r\n        FLAGS.pipeline_config_path)\r\n    if FLAGS.task == 0:\r\n      tf.gfile.Copy(FLAGS.pipeline_config_path,\r\n                    os.path.join(FLAGS.train_dir, 'pipeline.config'),\r\n                    overwrite=True)\r\n  else:\r\n    configs = config_util.get_configs_from_multiple_files(\r\n        model_config_path=FLAGS.model_config_path,\r\n        train_config_path=FLAGS.train_config_path,\r\n        train_input_config_path=FLAGS.input_config_path)\r\n    if FLAGS.task == 0:\r\n      for name, config in [('model.config', FLAGS.model_config_path),\r\n                           ('train.config', FLAGS.train_config_path),\r\n                           ('input.config', FLAGS.input_config_path)]:\r\n        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\r\n                      overwrite=True)\r\n"]}, {"number": 15313, "title": "Fixing typo", "body": "", "comments": ["Can one of the admins verify this patch?"]}]