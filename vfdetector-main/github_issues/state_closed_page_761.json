[{"number": 30728, "title": "AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'", "body": "Tensorflow Version: 1.14.0\r\npython3.6\r\nNum of GPU's : 3\r\n\r\n--- Sample keras code to reproduce this error ---\r\n```\r\nimport tensorflow as tf\r\nfrom keras.applications import Xception\r\nfrom keras.utils import multi_gpu_model\r\nimport numpy as np\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nmodel = Xception(weights=None,\r\n                     input_shape=(height, width, 3),\r\n                     classes=num_classes)\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nprint(gpus)\r\nparallel_model = multi_gpu_model(model, gpus=2)\r\n```\r\n\r\n\r\nError Message:\r\n```\r\n\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\ndevice_string:  /device:GPU:0\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/multi_gpu_utils.py\", line 227, in multi_gpu_model\r\n    outputs = model(inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 457, in __call__\r\n    output = self.call(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line 564, in call\r\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line 721, in run_internal_graph\r\n    layer.call(computed_tensor, **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/normalization.py\", line 185, in call\r\n    epsilon=self.epsilon)\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1858, in normalize_batch_in_training\r\n    if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 291, in _has_nchw_support\r\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 266, in _is_current_explicit_device\r\n    device = _get_current_tf_device()\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 247, in _get_current_tf_device\r\n    g._apply_device_functions(op)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 4581, in _apply_device_functions\r\n    op._set_device_from_string(device_string)\r\nAttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'\r\n(arg: 2) \r\n\r\n```", "comments": ["Solved, It's a bug in tensorflow 1.14.0\r\nWhen I downgraded to 1.13.1, it's back to normal :-/\r\nI haven't figure out why 1.14.0 though. If someone solves this, it will help other idiots like me who after upgrading to TF 1.14 , unwittingly trained on a single gpu (instead of multi by default)", "Same Problem Here", "Any news regarding that problem?", "Hi @robieta, seems you recently made changes to _TfDeviceCaptureOp, would you mind to take a look?\r\nThanks.", "If it helps, I got the same error message with another traceback.\r\n\r\nAttributeErrorTraceback (most recent call last)\r\n<ipython-input-26-8f80d72756c9> in <module>()\r\n----> 1 model = multi_gpu_model(model,gpus=2)\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/utils/training_utils.pyc in multi_gpu_model(model, gpus)\r\n    173                 # Apply model on slice\r\n    174                 # (creating a model replica on the target device).\r\n--> 175                 outputs = model(inputs)\r\n    176                 if not isinstance(outputs, list):\r\n    177                     outputs = [outputs]\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/base_layer.pyc in __call__(self, inputs, **kwargs)\r\n    455             # Actually call the layer,\r\n    456             # collecting output(s), mask(s), and shape(s).\r\n--> 457             output = self.call(inputs, **kwargs)\r\n    458             output_mask = self.compute_mask(inputs, previous_mask)\r\n    459 \r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/network.pyc in call(self, inputs, mask)\r\n    562             return self._output_tensor_cache[cache_key]\r\n    563         else:\r\n--> 564             output_tensors, _, _ = self.run_internal_graph(inputs, masks)\r\n    565             return output_tensors\r\n    566 \r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/engine/network.pyc in run_internal_graph(self, inputs, masks)\r\n    719                                     kwargs['mask'] = computed_mask\r\n    720                             output_tensors = to_list(\r\n--> 721                                 layer.call(computed_tensor, **kwargs))\r\n    722                             output_masks = layer.compute_mask(computed_tensor,\r\n    723                                                               computed_mask)\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/layers/normalization.pyc in call(self, inputs, training)\r\n    183         normed_training, mean, variance = K.normalize_batch_in_training(\r\n    184             inputs, self.gamma, self.beta, reduction_axes,\r\n--> 185             epsilon=self.epsilon)\r\n    186 \r\n    187         if K.backend() != 'cntk':\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon)\r\n   1856     \"\"\"\r\n   1857     if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\r\n-> 1858         if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\r\n   1859             return _broadcast_normalize_batch_in_training(x, gamma, beta,\r\n   1860                                                           reduction_axes,\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in _has_nchw_support()\r\n    289         bool: if the current scope device placement would support nchw\r\n    290     \"\"\"\r\n--> 291     explicitly_on_cpu = _is_current_explicit_device('CPU')\r\n    292     gpus_available = len(_get_available_gpus()) > 0\r\n    293     return (not explicitly_on_cpu and gpus_available)\r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in _is_current_explicit_device(device_type)\r\n    264     if device_type not in ['CPU', 'GPU']:\r\n    265         raise ValueError('`device_type` should be either \"CPU\" or \"GPU\".')\r\n--> 266     device = _get_current_tf_device()\r\n    267     return (device is not None and device.device_type == device_type.upper())\r\n    268 \r\n\r\n/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in _get_current_tf_device()\r\n    245     g = tf.get_default_graph()\r\n    246     op = _TfDeviceCaptureOp()\r\n--> 247     g._apply_device_functions(op)\r\n    248     return op.device\r\n    249 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in _apply_device_functions(self, op)\r\n   4579       # strings, since identity checks are faster than equality checks.\r\n   4580       if device_string is not prior_device_string:\r\n-> 4581         op._set_device_from_string(device_string)\r\n   4582         prior_device_string = device_string\r\n   4583     op._device_code_locations = self._snapshot_device_function_stack_metadata()\r\n\r\nAttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'", "As a workaround, can you try `tf.distribute.MirroredStrategy()`? This is the recommended way going forward for multi-gpu training", "Any update on this issues. I am still facing the issue when using multi gpu..", "Any updates on this issue? This bug is preventing me from upgrading to tf1.14.", "I'm having the same issue, downgrading to 1.13.1 solved it for me, please fix.", "Downgrading to 1.13.1 worked for me as well!\r\n\r\nMake sure when you downgrade, you downgrade other `tensorflow` packages that you have installed:\r\nif python 2:\r\n```\r\npip install tensorflow==1.13.1\r\npip install tensorflow-gpu==1.13.1\r\n```\r\nIf python 3:\r\n```\r\npip3 install tensorflow==1.13.1\r\npip3 install tensorflow-gpu==1.13.1\r\n```", "There is also another way that results in same issue.\r\nIt does not even require multigpu model. \r\nIt crashes at any choice of device, with a way that is still official for TensorFlow, in docummentation and tutorials like https://www.tensorflow.org/guide/using_gpu :\r\n\r\n`with tf.device('/cpu:0'): \r\n[any Keras code that compiles a model]`\r\n\r\nIt will result in error with the following traceback:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"/home/karol/Repozytoria/dnn_trayleveldetection/train.py\", line 234, in <module>\r\n>     train(from_preprocessed_dir=True, from_pretrained=start_from_previously_exported)\r\n>   File \"/home/karol/Repozytoria/dnn_trayleveldetection/train.py\", line 192, in train\r\n>     model = initalize_model(True)\r\n>   File \"/home/karol/Repozytoria/dnn_trayleveldetection/train.py\", line 42, in initalize_model\r\n>     models = model_func(img_rows, img_cols, classes, trainable)\r\n>   File \"/home/karol/Repozytoria/dnn_trayleveldetection/models.py\", line 243, in UltraTinyModel\r\n>     model.add(BatchNormalization())\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/engine/sequential.py\", line 181, in add\r\n>     output_tensor = layer(self.outputs[0])\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\r\n>     output = self.call(inputs, **kwargs)\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/layers/normalization.py\", line 185, in call\r\n>     epsilon=self.epsilon)\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1858, in normalize_batch_in_training\r\n>     if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 291, in _has_nchw_support\r\n>     explicitly_on_cpu = _is_current_explicit_device('CPU')\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 266, in _is_current_explicit_device\r\n>     device = _get_current_tf_device()\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 247, in _get_current_tf_device\r\n>     g._apply_device_functions(op)\r\n>   File \"/home/karol/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4581, in _apply_device_functions\r\n>     op._set_device_from_string(device_string)\r\n> AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'", "@sephethus @ashkan-software This error is caused by keras, see the fix [here](https://github.com/keras-team/keras/pull/13255)", "@tuanzhangCS I installed keras from the master branch that has the PR you linked but I still get this error (downgrading tf and tf-gpu to 1.13.1 solved the issue for me):\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"run_cropmask.py\", line 287, in <module>\r\n    mode=\"training\", config=config, model_dir=args.logs\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/cropmask/mrcnn/model.py\", line 2025, in __init__\r\n    self.keras_model = self.build(mode=mode, config=config)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/cropmask/mrcnn/model.py\", line 2345, in build\r\n    model = ParallelModel(model, config.GPU_COUNT)\r\n  File \"/data/home/ryan/work/CropMask_RCNN/cropmask/mrcnn/parallel_model.py\", line 33, in __init__\r\n    merged_outputs = self.make_parallel(keras_model, gpu_count)\r\n  File \"/data/home/ryan/work/CropMask_RCNN/cropmask/mrcnn/parallel_model.py\", line 79, in make_parallel\r\n    outputs = inner_model(inputs)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 457, in __call__\r\n    output = self.call(inputs, **kwargs)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/engine/network.py\", line 564, in call\r\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/engine/network.py\", line 721, in run_internal_graph\r\n    layer.call(computed_tensor, **kwargs))\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/cropmask/mrcnn/model.py\", line 71, in call\r\n    return super(self.__class__, self).call(inputs, training=training)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/layers/normalization.py\", line 185, in call\r\n    epsilon=self.epsilon)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 1858, in normalize_batch_in_training\r\n    if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 291, in _has_nchw_support\r\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 266, in _is_current_explicit_device\r\n    device = _get_current_tf_device()\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 247, in _get_current_tf_device\r\n    g._apply_device_functions(op)\r\n  File \"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 4581, in _apply_device_functions\r\n    op._set_device_from_string(device_string)\r\nAttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'\r\n\r\n```", "**@rbavery**  You can open the file ***\"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\"*** and check if there is the fix there. \r\nThe reason for this error is that *\"class  _TfDeviceCaptureOp\"* which declared in *\"keras/backend/tensorflow_backend.py\"* has no function *'_set_device_from_string'*, so we can just add it.\r\nSo I think your package of keras doesn't have the change of this fix PR. My way is merge the code by myself, only need to add three lines code all. It runs well.\r\nwhy your keras doesn't have this fix, I guess you install keras by pip? ", "Indeed. The fix is in for keras-team/keras, but conda/pip installs won't pick it up until the next keras release. @fchollet Do you think it's worth making a 2.2.6? (I'm not sure how far out 2.3.0 is, and if this is breaking enough to warrant an intermediate release.)", "Does it get fixed on TF 2.0?", "With the release of keras-team/keras 2.3.0, this should be fixed in both keras and tf.keras.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30728\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30728\">No</a>\n", "> **@rbavery** You can open the file _**\"/data/anaconda/envs/cropmask/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\"**_ and check if there is the fix there.\r\n> The reason for this error is that _\"class _TfDeviceCaptureOp\"_ which declared in _\"keras/backend/tensorflow_backend.py\"_ has no function _'_set_device_from_string'_, so we can just add it.\r\n> So I think your package of keras doesn't have the change of this fix PR. My way is merge the code by myself, only need to add three lines code all. It runs well.\r\n> why your keras doesn't have this fix, I guess you install keras by pip?\r\n\r\nname \"tfdev\" is not defined? where is the tfdev?", "@sunanlin13174 Have you added `from tensorflow.python.framework import device as tfdev` ? Make sure you added every line in **robieta**'s commit. By the way, the last version of keras still doesn't work? ", "> @sunanlin13174 Have you added `from tensorflow.python.framework import device as tfdev` ? Make sure you added every line in **robieta**'s commit. By the way, the last version of keras still doesn't work?\r\n\r\nthanks very much,i upgraded keras to 2.3.0,and the issue solved. but i meet a new issue: \"no model name control_flow_ops\",so i modified keras.backend.__init__.py,add a code \"from .load_backend import control_flow_ops\" , but error:\"cannot import name 'control_flow_ops' from 'keras.backend.load_backend' , tesorflow-gpu==1.14.0 , do you have a solution? thanks for reply!", "> \r\n> \r\n> > @sunanlin13174 Have you added `from tensorflow.python.framework import device as tfdev` ? Make sure you added every line in **robieta**'s commit. By the way, the last version of keras still doesn't work?\r\n> \r\n> thanks very much,i upgraded keras to 2.3.0,and the issue solved. but i meet a new issue: \"no model name control_flow_ops\",so i modified keras.backend.**init**.py,add a code \"from .load_backend import control_flow_ops\" , but error:\"cannot import name 'control_flow_ops' from 'keras.backend.load_backend' , tesorflow-gpu==1.14.0 , do you have a solution? thanks for reply!\r\n\r\nKeras doesn't support `control_flow_ops` now. So, you need use it from tensorflow directly.", "yes,i got it ,thanks\r\n\r\n\r\n\r\n\r\n------------------&nbsp;\u539f\u59cb\u90ae\u4ef6&nbsp;------------------\r\n\u53d1\u4ef6\u4eba: \"tuanzhangCS\"<notifications@github.com&gt;; \r\n\u53d1\u9001\u65f6\u95f4: 2019\u5e7410\u670828\u65e5(\u661f\u671f\u4e00) \u665a\u4e0a8:36\r\n\u6536\u4ef6\u4eba: \"tensorflow/tensorflow\"<tensorflow@noreply.github.com&gt;; \r\n\u6284\u9001: \"\u68a7\u6850\"<1317477457@qq.com&gt;; \"Mention\"<mention@noreply.github.com&gt;; \r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] AttributeError: &#39;_TfDeviceCaptureOp&#39; object has no attribute &#39;_set_device_from_string&#39; (#30728)\r\n\r\n\r\n\r\n  \r\n@sunanlin13174 Have you added from tensorflow.python.framework import device as tfdev ? Make sure you added every line in robieta's commit. By the way, the last version of keras still doesn't work?\r\n  \r\nthanks very much,i upgraded keras to 2.3.0,and the issue solved. but i meet a new issue: \"no model name control_flow_ops\",so i modified keras.backend.init.py,add a code \"from .load_backend import control_flow_ops\" , but error:\"cannot import name 'control_flow_ops' from 'keras.backend.load_backend' , tesorflow-gpu==1.14.0 , do you have a solution? thanks for reply!\r\n  \r\nKeras doesn't support control_flow_ops now. So, you need use it from tensorflow directly.\r\n \r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub, or unsubscribe."]}, {"number": 30727, "title": "TOCO unable to convert unsupported operation using --allow_custom_ops", "body": "\r\n\r\n**System information**\r\n- Have I written custom code **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) **PIXEL 2 api 27**\r\n- TensorFlow installed from (source or binary): **Binary (pip installed)**\r\n- TensorFlow version (use command below): **tensorflow=='1.6.0-rc1'**\r\n- Python version:**3.68**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **10.0/7/4**\r\n- GPU model and memory:**GTX 1060 6GB, 16 GB RAM**\r\n\r\n\r\n\r\n@aquariusjay I am trying to convert mobilenet_v2 model trained on pascal voc dataset (https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md).\r\n\r\nI want to infer with 1024x1024 resolution therefore I exported model with following commands.\r\n\r\n` python export_model.py \\\r\n--checkpoint_path model/model.ckpt-30000 \\\r\n--export_path ./frozen_inference_graph.pb \\\r\n--model_variant=\"mobilenet_v2\" \\\r\n--num_classes=21 \\\r\n--crop_size=1024 \\\r\n--crop_size=1024 \\\r\n--inference_scales=1.0\r\n`\r\n\r\n\r\nAnd then I convert model to tflite using toco command.\r\n\r\n`toco --graph_def_file=/home/abdullah/models-master/research   /frozen_casted.pb --input_format=TENSORFLOW_GRAPHDEF                                                         \r\n--output_format=TFLITE  \r\n--output_file=deeplabv3_mnv2_pascal_trainval.tflite   \r\n--inference_type=FLOAT --inference_input_type=QUANTIZED_UINT8\r\n--input_arrays=ImageTensor \r\n--output_arrays=SemanticPredictions\r\n--input_shapes=1,1024,1024,3 --default_ranges_min=0 \r\n--default_ranges_max=255 --allow_custom_ops  \r\n--std_dev_values=128 --mean_values=1\r\n`\r\n\r\nAnd then model is converted to tflite without errors :\r\n`\r\n    2019-07-16 00:28:18.188009: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Equal\r\n2019-07-16 00:28:18.188052: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Equal\r\n2019-07-16 00:28:18.188067: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: LogicalOr\r\n2019-07-16 00:28:18.188093: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Unpack\r\n2019-07-16 00:28:18.188134: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: LogicalAnd\r\n2019-07-16 00:28:18.192256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: ResizeNearestNeighbor\r\n2019-07-16 00:28:18.203603: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 813 operators, 1237 arrays (0 quantized)\r\n2019-07-16 00:28:18.232795: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 801 operators, 1215 arrays (0 quantized)\r\n2019-07-16 00:28:18.269909: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 801 operators, 1215 arrays (0 quantized)\r\n2019-07-16 00:28:18.293777: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 132 operators, 325 arrays (0 quantized)\r\n2019-07-16 00:28:18.296414: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 132 operators, 325 arrays (0 quantized)\r\n2019-07-16 00:28:18.298905: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 28311552 bytes, theoretical optimal value: 25165824 bytes.\r\n2019-07-16 00:28:18.299732: W tensorflow/contrib/lite/toco/tflite/operator.cc:661] Ignoring unsupported attribute type with key '_output_shapes'\r\n2019-07-16 00:28:18.299743: W tensorflow/contrib/lite/toco/tflite/operator.cc:661] Ignoring unsupported attribute type with key 'T'\r\n2019-07-16 00:28:18.299946: W tensorflow/contrib/lite/toco/tflite/operator.cc:661] Ignoring unsupported attribute type with key 'T'\r\n2019-07-16 00:28:18.299956: W tensorflow/contrib/lite/toco/tflite/operator.cc:661] Ignoring unsupported attribute type with key '_output_shapes'\r\n`\r\n\r\n\r\nBut when I run the model on tflite it gives the following error.\r\n\r\n    java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find           \r\n    custom op for name 'ExpandDims' with version 1 Registration failed.\r\n\r\nFollowing are the details of environment.\r\n\r\n    For conversion I used tensorflow tensorflow=='1.6.0-rc1'\r\n\r\n    And tflite implementation in build.gradle is implementation 'org.tensorflow:tensorflow-lite:+'\r\n\r\nI don't know where I am failing, please help me.\r\n\r\n", "comments": ["If you want to quantize the model, can you try post-training integer quantization? See instruction here:\r\nhttps://medium.com/tensorflow/tensorflow-model-optimization-toolkit-post-training-integer-quantization-b4964a1ea9ba", "@mabdullahrafique ,\r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v2.6 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30727\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30727\">No</a>\n"]}, {"number": 30726, "title": "cudaGetDevice() failed after upgrading to v 1.14, downgraded back to 1.12 still having issue", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.12\r\n- **Python version**:3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:9.0\r\n- **GPU model and memory**:Tesla K80 and ?\r\n- **Exact command to reproduce**:model_main.py\r\n\r\n\r\n### Describe the problem\r\nI am running on AWS instance and upgraded to tensorflow 1.14 to build arm7 tflite runtime wheel for a pi.  That is completed and works.  I am now trying to retrain my model on my AWS instance and am getting the cudaGetDevice() failed error.  I have now downgraded back to tensorflow 1.12 to try and fix and get the same issue.  I have upgraded and downgraded nvidia drivers and nvidia-smi command works.  Below is the traceback error.\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/sc2.2/models/research/object_detection/model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/ubuntu/sc2.2/models/research/object_detection/model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 610, in run\r\n    return self.run_local()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1241, in _train_model_default\r\n    saving_listeners)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1468, in _train_with_estimator_spec\r\n    log_step_count_steps=log_step_count_steps) as mon_sess:\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 504, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1112, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 800, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 566, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\", line 288, in prepare_session\r\n    config=config)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\", line 185, in _restore_checkpoint\r\n    sess = session.Session(self._target, graph=self._graph, config=config)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1551, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 676, in __init__\r\n    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)\r\ntensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version\r\n", "comments": ["@tfoxkustudent ,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@tfoxkustudent I had the same issue recently and purging old nvidia drivers and installing them again helped.\r\nCheck this for solution: https://stackoverflow.com/questions/41409842/ubuntu-16-04-cuda-8-cuda-driver-version-is-insufficient-for-cuda-runtime-vers", "@anush-o .  the file I run is /models/research/object_detection/model_main.py\r\n\r\n\"\"\"Binary to run train and evaluation on object detection model.\"\"\"\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom absl import flags\r\n\r\nimport tensorflow as tf\r\n\r\nfrom object_detection import model_hparams\r\nfrom object_detection import model_lib\r\n\r\nflags.DEFINE_string(\r\n    'model_dir', None, 'Path to output model directory '\r\n    'where event and checkpoint files will be written.')\r\nflags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\r\n                    'file.')\r\nflags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\r\nflags.DEFINE_boolean('eval_training_data', False,\r\n                     'If training data should be evaluated for this job. Note '\r\n                     'that one call only use this in eval-only mode, and '\r\n                     '`checkpoint_dir` must be supplied.')\r\nflags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\r\n                     'every n eval input examples, where n is provided.')\r\nflags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\r\n                     'one of every n train input examples for evaluation, '\r\n                     'where n is provided. This is only used if '\r\n                     '`eval_training_data` is True.')\r\nflags.DEFINE_string(\r\n    'hparams_overrides', None, 'Hyperparameter overrides, '\r\n    'represented as a string containing comma-separated '\r\n    'hparam_name=value pairs.')\r\nflags.DEFINE_string(\r\n    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\r\n    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\r\n    'writing resulting metrics to `model_dir`.')\r\nflags.DEFINE_boolean(\r\n    'run_once', False, 'If running in eval-only mode, whether to run just '\r\n    'one round of eval vs running continuously (default).'\r\n)\r\nFLAGS = flags.FLAGS\r\n\r\n\r\ndef main(unused_argv):\r\n  flags.mark_flag_as_required('model_dir')\r\n  flags.mark_flag_as_required('pipeline_config_path')\r\n  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,save_checkpoints_secs=30)\r\n\r\n  train_and_eval_dict = model_lib.create_estimator_and_inputs(\r\n      run_config=config,\r\n      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\r\n      pipeline_config_path=FLAGS.pipeline_config_path,\r\n      train_steps=FLAGS.num_train_steps,\r\n      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\r\n      sample_1_of_n_eval_on_train_examples=(\r\n          FLAGS.sample_1_of_n_eval_on_train_examples))\r\n  estimator = train_and_eval_dict['estimator']\r\n  train_input_fn = train_and_eval_dict['train_input_fn']\r\n  eval_input_fns = train_and_eval_dict['eval_input_fns']\r\n  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\r\n  predict_input_fn = train_and_eval_dict['predict_input_fn']\r\n  train_steps = train_and_eval_dict['train_steps']\r\n\r\n  if FLAGS.checkpoint_dir:\r\n    if FLAGS.eval_training_data:\r\n      name = 'training_data'\r\n      input_fn = eval_on_train_input_fn\r\n    else:\r\n      name = 'validation_data'\r\n      # The first eval input will be evaluated.\r\n      input_fn = eval_input_fns[0]\r\n    if FLAGS.run_once:\r\n      estimator.evaluate(input_fn,\r\n                         num_eval_steps=None,\r\n                         checkpoint_path=tf.train.latest_checkpoint(\r\n                             FLAGS.checkpoint_dir))\r\n    else:\r\n      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\r\n                                train_steps, name)\r\n  else:\r\n    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\r\n        train_input_fn,\r\n        eval_input_fns,\r\n        eval_on_train_input_fn,\r\n        predict_input_fn,\r\n        train_steps,\r\n        eval_on_train_data=False)\r\n\r\n    # Currently only a single Eval Spec is allowed.\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n\r\n\r\nif __name__ == '__main__':\r\n  tf.app.run()", "@bonlime  I have purged the nvidia drivers and have Cuda 9.0 and nvidia drivers 384 right now.  It still did not work.", "After a purge and if I used the following script exactly as it is.  Some reason it works now\r\n\r\nsudo apt-get update\r\nsudo apt-get install --no-install-recommends nvidia-384 libcuda1-384 nvidia-opencl-icd-384\r\nsudo reboot", "issue solved thank you\r\n", "Closing the issue since it is solved."]}, {"number": 30725, "title": "CIFAR-10 tutorial for multi-GPU fails because full shape isn't passed to prefetch_queue", "body": "The [CIFAR-10 Multi-GPU Tutorial](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py) has a bug in it when run from the command line. I am using Tensorflow `1.13.1` and Tensorflow-Datasets `1.0.2`. You simply need to put an explicit call to tf.reshape before passing it into the prefetch_queue to add the outer num_samples shape. I've got a quick PR that fixes this.", "comments": ["Sorry, closing since this belongs in [tensorflow/models](../../../tensorflow/models)"]}, {"number": 30724, "title": "Fix MPI configuration", "body": "The string replace operation used to set a configuration flag failed because the string to be replaced had spaced added around the `=` symbol. The changes in the configuration file are required to make the two match again.\r\n\r\nThis fixes #30440 \r\n", "comments": ["Although it would be more flexible it would not be needed in this case. The spaces around `=` is a requirement from the code formatter so I don't expect any future changes in that definition.", "Perfect. Thank you"]}, {"number": 30723, "title": "Refactor TFRecordDatasetOp and add tests", "body": "This PR refactors `TFRecordDatasetOp` and add the tests for the C++ kernel.\r\n\r\ncc: @jsimsa ", "comments": []}, {"number": 30722, "title": "TensorFlow Lite build fatal error: gtest/gtest.h: No such file or directory", "body": "**System information**\r\n- Raspberry Pi 3\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:  1.14.0\r\n\r\n**Describe the problem**\r\n\r\nWhen natively compiling TensorFlow Lite 1.14.0 in Raspberry Pi 3, I am getting the following compile error:\r\nfatal error: gtest/gtest.h: No such file or directory\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nHere is the error log:\r\narm-linux-gnueabihf-g++ -O3 -DNDEBUG -fPIC  --std=c++11 -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/../../../../../ -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/../../../../../../ -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/ -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/eigen -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/absl -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/gemmlowp -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/kernels/test_main.cc -o /home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/test_main.o\r\ntensorflow/lite/kernels/test_main.cc:17:25: fatal error: gtest/gtest.h: No such file or directory\r\n #include <gtest/gtest.h>\r\n                         ^\r\ncompilation terminated.\r\ntensorflow/lite/tools/make/Makefile:241: recipe for target '/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/test_main.o' failed\r\nmake: *** [/home/pi/tensorflow-1.14.0/tensorflow/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/lite/kernels/test_main.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\nIn file included from ./tensorflow/lite/kernels/cpu_backend_gemm.h:22:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:42,\r\n                 from tensorflow/lite/kernels/sub.cc:18:\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h: In static member function \u2018static void tflite::cpu_backend_gemm::detail::CustomGemvImpl<LhsScalar, RhsScalar, int, DstScalar, quantization_flavor>::Run(const tflite::cpu_backend_gemm::MatrixParams<LhsScalar>&, const LhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<RhsScalar>&, const RhsScalar*, const tflite::cpu_backend_gemm::MatrixParams<DstScalar>&, DstScalar*, const tflite::cpu_backend_gemm::GemmParams<int, DstScalar, quantization_flavor>&, int, int)\u2019:\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:484:13: warning: attributes at the beginning of statement are ignored [-Wattributes]\r\n             [[clang::fallthrough]];\r\n             ^\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:487:13: warning: attributes at the beginning of statement are ignored [-Wattributes]\r\n             [[clang::fallthrough]];\r\n             ^\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:490:13: warning: attributes at the beginning of statement are ignored [-Wattributes]\r\n             [[clang::fallthrough]];\r\n             ^\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:493:13: warning: attributes at the beginning of statement are ignored [-Wattributes]\r\n             [[clang::fallthrough]];\r\n             ^\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:496:13: warning: attributes at the beginning of statement are ignored [-Wattributes]\r\n             [[clang::fallthrough]];\r\n             ^\r\n./tensorflow/lite/kernels/cpu_backend_gemm_custom_gemv.h:499:13: warning: attributes at the beginning of statement are ignored [-Wattributes]\r\n             [[clang::fallthrough]];\r\n             ^\r\npi@raspberrypi:~/tensorflow $ \r\n", "comments": ["After applying fixes described in:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/29017/commits/05514a000a017dbe7db7643d084b16def9719c99\r\n\r\nand\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/29806\r\n\r\nI successfully built TensorFlow Lite 1.14.0 and 2.0.0-beta1.  Does it make sense?\r\n", "In addition to the above, in order to build aarch64 TensorFlow Lite, in the Makefile retrieved from https://github.com/tensorflow/tensorflow/issues/29806, I had to add -flax-vector-conversions and -fomit-frame-pointer to CXXFLAGS, and set BUILD_WITH_NNAPI=false (as described in https://github.com/tensorflow/tensorflow/issues/26731).\r\n\r\nAnd that is not all...\r\n\r\nIn order to cross-compile aarch64 TensorFlow Lite in Yocto environment on a Linux host PC, I had to further edit the Makefile and replace \":=\" with \"?=\" for the following macros:  TARGET, TARGET_ARCH, TARGET_TOOLCHAIN_PREFIX, CC_PREFIX, CXX, CC, AR; and replace \":=\" with \"+=\" for the following macros: CXXFLAGS, CCFLAGS, CFLAGS.\r\n\r\nAttached is the Makefile that works.\r\n[Makefile.zip](https://github.com/tensorflow/tensorflow/files/3399374/Makefile.zip)\r\n\r\n\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Wow, this has been long time ago.  Yes, go ahead and close this issue.\r\n\r\nToly Kotlarsky\r\n\r\n[Zebra_Logo_Stacked_K_small]\r\nToly Kotlarsky\r\nDistinguished Member Technical Staff, R&D\r\nZEBRA TECHNOLOGIES CORPORATION\r\n\r\nOne Zebra Plaza\r\nHoltsville, NY 11742\r\nT: +1 631 738 3068 M: +1 215 570 5782\r\ntoly.kotlarskyl@zebra.com<mailto:toly.kotlarskyl@zebra.com>\r\nwww.zebra.com<http://www.zebra.com/>\r\n\r\nFollow Zebra!\r\n[social-fb]<http://www.facebook.com/zebratechnologiesglobal>\r\n[social-tstr]<http://www.twitter.com/zebratechnology>\r\n[social-in]<https://www.linkedin.com/company/167024?trk=tyah&trkInfo=tarId:1398351214615,tas:zebra,idx:3-1-7>\r\n[social-g+]<https://plus.google.com/u/0/b/116127895496262117488/116127895496262117488/posts>\r\n[social-B]<http://blogs.zebra.com/>\r\n[social-youtube]<http://www.youtube.com/user/ZebraTechnologies>\r\n[social-zebra]<http://www.slideshare.net/ZebraTechnologies>\r\n\r\n\r\n\r\nFrom: Alfred Sorten Wolf <notifications@github.com>\r\nSent: Monday, February 01, 2021 9:04 AM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Kotlarsky, Anatoly <Toly.Kotlarsky@zebra.com>; Author <author@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] TensorFlow Lite build fatal error: gtest/gtest.h: No such file or directory (#30722)\r\n\r\n[External Email]\r\n\r\nHi There,\r\n\r\nWe are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help.\r\n\r\nThis issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_tensorflow_tensorflow_issues_30722-23issuecomment-2D770880035&d=DwMCaQ&c=Qwsh1H-X9ypOoLLEcAIltQ&r=WxGGyZq-6RODxkXOYtpiGJNyj_a2lK75fgKk7c_C0c8&m=Ha2ABP8AmIWC0YkV9TEzkoJvS7kBPbWfqI-3MWolVl0&s=PpswEVJY_FvVzCQDyS_wpqPNU8hsMNUi4jPb2k53kXY&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AK5HQ3XVD32B57QJ7E4SI4DS42YGLANCNFSM4IDZXQZA&d=DwMCaQ&c=Qwsh1H-X9ypOoLLEcAIltQ&r=WxGGyZq-6RODxkXOYtpiGJNyj_a2lK75fgKk7c_C0c8&m=Ha2ABP8AmIWC0YkV9TEzkoJvS7kBPbWfqI-3MWolVl0&s=IiHCf8jEd4dXPsanAnOzzIUA-x2qO7rE6iGKM8x6mm8&e=>.\r\n\r\n\r\n________________________________\r\n- CONFIDENTIAL-\r\n\r\nThis email and any files transmitted with it are confidential, and may also be legally privileged. If you are not the intended recipient, you may not review, use, copy, or distribute this message. If you receive this email in error, please notify the sender immediately by reply email and then delete this email.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30722\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30722\">No</a>\n"]}, {"number": 30721, "title": "TensorFlow import error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7.4 x64\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Intel core i7 6700, 16GB ram\r\n\r\n**Describe the problem**\r\nHi,\r\nI would like to import tensorflow on pycharm. I checked related posts but I think that I missed a step somewhere. Please excuse me I am new to python and may have forgotten something trivial. \r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI installed tensorflow and it succeeded, then run the following code: (I disabled unused import statements but it seems that it is still an issue).\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nprint(tf.__version__)\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n\r\nI get the following error message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Leo Picard/PycharmProjects/tensorflow/tensorflow_init.py\", line 4, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Python\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Python\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 47, in <module>\r\n    import numpy as np\r\n  File \"C:\\Python\\lib\\site-packages\\numpy\\__init__.py\", line 142, in <module>\r\n    from . import core\r\n  File \"C:\\Python\\lib\\site-packages\\numpy\\core\\__init__.py\", line 23, in <module>\r\n    WinDLL(os.path.abspath(filename))\r\n  File \"C:\\Python\\lib\\ctypes\\__init__.py\", line 364, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 193] %1 is not a valid Win32 application\r\n```\r\n", "comments": ["You may find useful the following videos: [How to use TensorFlow in PyCharm](https://www.youtube.com/watch?v=K9ypGzuP6xQ) and [De-bug your TensorFlow projects with the PyCharm IDE](https://www.youtube.com/watch?v=hYOOGstEzzM)\r\n\r\n", "@leops95 Just to confirm, did you follow the steps mentioned in the [Tensorflow](https://www.tensorflow.org/install/pip) site. Thanks!", "@gadagashwini Yes, I followed the steps of the first video and I still have the same error message. Now I have the 2.0 version, but I don't believe it's the main issue here. I am working on it and will keep you informed as soon as I find something.\r\n\r\nThanks a lot for your time and consideration towards my request !", "@leops95 Looks like you found a workaround. Can we close this issue. You can update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n ", "@gadagashwini problem solved. I had to update numpy and suppress pandas FutureWarning using\r\n\r\n```\r\nimport warnings\r\nwarnings.simplefilter(action='ignore', category=FutureWarning)\r\n\r\n```\r\n\r\nThanks again for the help !"]}, {"number": 30720, "title": "Use \"numpy >= 1.16.0, < 2.0\" to fix #25636", "body": "Tested on a windows box by not installing numpy before tensorflow like our CI does. Then indeed fix suggested in #25636 is needed\r\n\r\nCherry-picked on master, r1.14 and r1.13", "comments": []}, {"number": 30719, "title": "Use \"numpy >= 1.16.0, < 2.0\" to fix #25636", "body": "Tested on a windows box by not installing numpy before tensorflow like our CI does. Then indeed fix suggested in #25636 is needed\r\n\r\nCherry-picked on master, r1.14 and r1.13", "comments": []}, {"number": 30718, "title": "Use \"numpy >= 1.16.0, < 2.0\" to fix #25636", "body": "Tested on a windows box by not installing numpy before tensorflow like our CI does. Then indeed fix suggested in #25636 is needed\r\n\r\nCherry-picked on master, r1.14 and r1.13", "comments": []}, {"number": 30717, "title": "No Speedup or Size Savings After FP16 / INT8 with TensorRT", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): [nvidia-docker `tensor:19.02-py3` (Ubuntu 16.04)](https://docs.nvidia.com/deeplearning/sdk/tensorrt-container-release-notes/rel_19-02.html#rel_19-02)\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: Python 3.5.2\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.0.130 / 7.4.2\r\n- GPU model and memory: Tesla V100 32GB\r\n\r\n**Describe the current behavior**\r\nI am trying to optimize (decrease) the inference time and model size of my Tiny Yolov3 model. I currently have it as a frozen graph. When I run the timing and evaluation script from [here](https://github.com/tensorflow/models/blob/master/research/tensorrt/tensorrt.py), fps actually decreases as the optimizations are tried, and file sizes stay constant.\r\n\r\n**Describe the expected behavior**\r\nI expect file sizes and inference time to decrease.\r\n\r\n**Code to reproduce the issue**\r\nI used [this](https://docs.nvidia.com/deeplearning/sdk/tensorrt-container-release-notes/rel_19-02.html#rel_19-02) nvidia-docker image.\r\n\r\n[This](https://github.com/tensorflow/models/blob/master/research/tensorrt/tensorrt.py) script with a small preprocessing change:\r\n\r\n```\r\ndef resize_image(image, target_height, target_width):\r\n    image = image.resize((target_width, target_height), Image.BICUBIC).convert('RGB')\r\n    return np.array(image)\r\n\r\ndef preprocess_image(file_name, output_height=416, output_width=416,\r\n                     num_channels=3):\r\n    return resize_image(Image.open(file_name), output_height, output_width).astype('float32')\r\n```\r\n\r\nI also removed the printing of predictions, as the script is built for a classifier rather than a detector.\r\n\r\n**Other info / logs**\r\nCommand executed (image file is attached; model is [here](https://drive.google.com/file/d/1Bgj9h6TJLwedtrhnritRs9eYm_iczG4v/view)):\r\n```\r\npython timed.py --frozen_graph=tiny-yolov3_frozen.pb \\\r\n--image_file=11075842.jpg \\\r\n--native --fp32 --fp16 --int8 \\\r\n--output_dir=/workspace \\\r\n--input_node=inputs --output_node=output_boxes\r\n```\r\n```\r\n==========================\r\nnetwork: native_tiny-yolov3_frozen.pb,   batchsize 256, steps 100\r\n  fps   median: 993.1,  mean: 959.8,    uncertainty: 8.9,       jitter: 7.7\r\n  latency       median: 0.25778,        mean: 0.26986,  99th_p: 0.43523,        99th_uncertainty: 0.05783\r\n\r\n==========================\r\nnetwork: tftrt_fp32_tiny-yolov3_frozen.pb,       batchsize 256, steps 100\r\n  fps   median: 912.7,  mean: 896.3,    uncertainty: 8.2,       jitter: 4.6\r\n  latency       median: 0.28048,        mean: 0.29338,  99th_p: 0.42830,        99th_uncertainty: 0.43877\r\n\r\n==========================\r\nnetwork: tftrt_fp16_tiny-yolov3_frozen.pb,       batchsize 256, steps 100\r\n  fps   median: 823.5,  mean: 831.9,    uncertainty: 8.4,       jitter: 96.2\r\n  latency       median: 0.31087,        mean: 0.31129,  99th_p: 0.43070,        99th_uncertainty: 0.07565\r\n\r\n==========================\r\nnetwork: tftrt_int8_tiny-yolov3_frozen.pb,       batchsize 256, steps 100\r\n  fps   median: 803.3,  mean: 820.6,    uncertainty: 9.9,       jitter: 19.9\r\n  latency       median: 0.31867,        mean: 0.31814,  99th_p: 0.60985,        99th_uncertainty: 0.01011\r\n```", "comments": ["Hi @nseidl, is it possible for you to provide the `tiny-yolov3` model mentioned above for further investigation?", "> **Other info / logs**\r\n> Command executed (image file is attached; model is [here](https://drive.google.com/file/d/1Bgj9h6TJLwedtrhnritRs9eYm_iczG4v/view)):\r\n\r\nYou can download the `tiny-volov3` model, as the frozen graph `tiny-yolov3_frozen.pb`.", "Thanks @nseidl, I think the problem is with 1.14 and we're investigating. Also @bananabowl.\r\n\r\nMeanwhile, if you try with tf-nightly-gpu it should work, please let me know if it doesn't.", "@aaroey I just tried with:\r\n\r\n- `NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0`\r\n- the same [nvidia-docker `tensor:19.02-py3` (Ubuntu 16.04)](https://docs.nvidia.com/deeplearning/sdk/tensorrt-container-release-notes/rel_19-02.html#rel_19-02)\r\n- `tf-nightly-gpu`\r\n\r\nI've attached the [do.py](https://github.com/tensorflow/tensorflow/files/3419042/do.py.txt) script that I execute with the following command:\r\n```\r\npython do.py --frozen_graph=tiny-yolov3_frozen.pb \\\r\n--image_file=</path/to/any/image/here> \\\r\n--native --fp32 --fp16 \\\r\n--output_dir=/workspace \\\r\n--input_node=inputs --output_node=output_boxes\r\n```\r\n\r\nI ran this twice to get two different `log.txt`:\r\n\r\n```\r\n==========================\r\nnetwork: native_tiny-yolov3_frozen.pb,   batchsize 128, steps 100\r\n  fps   median: 815.2,  mean: 808.7,    uncertainty: 4.9,       jitter: 9.6\r\n  latency       median: 0.15702,        mean: 0.15896,  99th_p: 0.21183,        99th_uncertainty: 0.03145\r\n\r\n==========================\r\nnetwork: tftrt_fp32_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 659.8,  mean: 660.3,    uncertainty: 5.0,       jitter: 38.6\r\n  latency       median: 0.19398,        mean: 0.19549,  99th_p: 0.27653,        99th_uncertainty: 0.06498\r\n\r\n==========================\r\nnetwork: tftrt_fp16_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 874.4,  mean: 896.2,    uncertainty: 6.2,       jitter: 5.6\r\n  latency       median: 0.14639,        mean: 0.14350,  99th_p: 0.17826,        99th_uncertainty: 0.01251\r\n```\r\n\r\n```\r\n==========================\r\nnetwork: native_tiny-yolov3_frozen.pb,   batchsize 128, steps 100\r\n  fps   median: 816.2,  mean: 809.3,    uncertainty: 3.2,       jitter: 2.9\r\n  latency       median: 0.15683,        mean: 0.15846,  99th_p: 0.20266,        99th_uncertainty: 0.02407\r\n\r\n==========================\r\nnetwork: tftrt_fp32_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 659.8,  mean: 656.4,    uncertainty: 2.3,       jitter: 1.8\r\n  latency       median: 0.19399,        mean: 0.19531,  99th_p: 0.24172,        99th_uncertainty: 0.06146\r\n\r\n==========================\r\nnetwork: tftrt_fp16_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 912.5,  mean: 911.9,    uncertainty: 0.4,       jitter: 2.8\r\n  latency       median: 0.14028,        mean: 0.14037,  99th_p: 0.14132,        99th_uncertainty: 0.00180\r\n```\r\n\r\nAs you can see, there's a slow down going from native -> tftrt_fp32, but the fastest is (as expected) tftrt_fp16. \r\n\r\n**1. Why is there a slowdown from native -> tftrt_fp32?**\r\n\r\nAdditionally, the original `tiny-yolov3_frozen.pb` is ~35MB in size. `tftrt_fp16_tiny-yolov3_frozen.pb` is ~45MB in size, and `tftrt_fp32_tiny-yolov3_frozen.pb` is ~69MB in size.\r\n\r\n**2. Are the increased graph file sizes for both the tftrt_fp32 and tftrt_fp16 expected?**", "For the slowdown from native->trt_fp32, @pooyadavoodi \r\n\r\nFor the increased graph size, that is expected. The problem is currently the converted graph has two copies of the weights, but we're fixing it in #30789. ", "Just tried `int8` and there is an error:\r\n```\r\npython do.py --frozen_graph=tiny-yolov3_frozen.pb --image_file=/path/to/image --int8 --output_dir=/workspace --input_node=inputs --output_node=output_boxes\r\n```\r\n\r\n```\r\n...\r\n2019-07-22 20:14:47.521952: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:37] DefaultLogger Tensor DataType is determined at build time for tensors not marked as input or output.\r\n2019-07-22 20:14:47.622752: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:740] Starting calibration thread on device 0, Calibration Resource @ 0x7f7738007050\r\n2019-07-22 20:14:47.623222: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:37] DefaultLogger Tensor DataType is determined at build time for tensors not marked as input or output.\r\n2019-07-22 20:14:47.658028: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:740] Starting calibration thread on device 0, Calibration Resource @ 0x7f77380154f0\r\n2019-07-22 20:14:47.658515: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:37] DefaultLogger Tensor DataType is determined at build time for tensors not marked as input or output.\r\n2019-07-22 20:18:39.690851: I tensorflow/compiler/tf2tensorrt/utils/calibration_resource.cc:27] Destroying Calibration Resource \r\n Calibrator = 0\r\n Builder    = 0\r\n Engine     = 0\r\n Logger     = 0x7f773000bc38\r\n Thread     = 0x7f7730018ad0\r\n\r\n2019-07-22 20:18:46.833018: I tensorflow/compiler/tf2tensorrt/utils/calibration_resource.cc:27] Destroying Calibration Resource \r\n Calibrator = 0\r\n Builder    = 0\r\n Engine     = 0\r\n Logger     = 0x7f773011ec58\r\n Thread     = 0x7f7730071b80\r\n\r\n2019-07-22 20:18:50.594933: I tensorflow/compiler/tf2tensorrt/utils/calibration_resource.cc:27] Destroying Calibration Resource \r\n Calibrator = 0\r\n Builder    = 0\r\n Engine     = 0\r\n Logger     = 0x7f77302819c8\r\n Thread     = 0x7f77302b2520\r\n\r\n2019-07-22 20:18:59.329510: I tensorflow/compiler/tf2tensorrt/utils/calibration_resource.cc:27] Destroying Calibration Resource \r\n Calibrator = 0\r\n Builder    = 0\r\n Engine     = 0\r\n Logger     = 0x7f7730cb5d28\r\n Thread     = 0x7f77302bd5f0\r\n\r\n2019-07-22 20:19:00.279089: I tensorflow/compiler/tf2tensorrt/utils/calibration_resource.cc:27] Destroying Calibration Resource \r\n Calibrator = 0\r\n Builder    = 0\r\n Engine     = 0\r\n Logger     = 0x7f7738015568\r\n Thread     = 0x7f77380153f0\r\n\r\npure virtual method called\r\nterminate called without an active exception\r\nAborted (core dumped)\r\n```", "@nseidl Could you post the full log you get from TF-TRT (FP16 and INT8)?\r\nPlease try it with verbose logging as explained here: https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#verbose \r\n\r\nPlease try it with nvidia container 19.07 which has 1.14 in it.\r\nThere might be regressions in the nightly builds.", "> @nseidl Could you post the full log you get from TF-TRT (FP16 and INT8)?\r\n> Please try it with verbose logging as explained here: https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#verbose\r\n> \r\n> Please try it with nvidia container 19.07 which has 1.14 in it.\r\n> There might be regressions in the nightly builds.\r\n\r\nNvidia container 19.07 has cuda 10.1, which as far as I know is incompatible with TF 1.14.0.\r\n\r\nBut, I tried a clean 19.02 container with `tensorflow-gpu==1.14.0`, and observe no speedup at all on either model.  I think this is because no TRTEngineOps are getting created.\r\n\r\n```\r\nRunning INT8 graph\r\nI0802 00:53:22.479997 140615879628544 trt_convert.py:575] Linked TensorRT version: (0, 0, 0)\r\nI0802 00:53:22.480141 140615879628544 trt_convert.py:576] Loaded TensorRT version: (0, 0, 0)\r\nI0802 00:53:22.480309 140615879628544 trt_convert.py:597] Running against TensorRT version 0.0.0\r\n2019-08-02 00:53:23.598903: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2019-08-02 00:53:23.599366: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2019-08-02 00:53:23.600403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\r\npciBusID: 0000:3b:00.0\r\n2019-08-02 00:53:23.600485: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-02 00:53:23.600497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-08-02 00:53:23.600509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-08-02 00:53:23.600521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-08-02 00:53:23.600531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-08-02 00:53:23.600542: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-08-02 00:53:23.600553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-08-02 00:53:23.601804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-08-02 00:53:23.601836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-08-02 00:53:23.601843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-08-02 00:53:23.601849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-08-02 00:53:23.603427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16240 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capa\r\nbility: 7.0)\r\n2019-08-02 00:53:26.795786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: tf_graph\r\n2019-08-02 00:53:26.795820: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 848 nodes (-483), 963 edges (-485), time = 1410.06201ms.\r\n2019-08-02 00:53:26.795908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   layout: Graph size after: 865 nodes (17), 979 edges (16), time = 350.479ms.\r\n2019-08-02 00:53:26.795921: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 858 nodes (-7), 979 edges (0), time = 859.111ms.\r\n2019-08-02 00:53:32.132584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\r\npciBusID: 0000:3b:00.0\r\n2019-08-02 00:53:32.132682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-02 00:53:32.132713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-08-02 00:53:32.132727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-08-02 00:53:32.132739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-08-02 00:53:32.132750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-08-02 00:53:32.132761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-08-02 00:53:32.132774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-08-02 00:53:32.134133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-08-02 00:53:32.134175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-08-02 00:53:32.134183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-08-02 00:53:32.134189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-08-02 00:53:32.135805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16240 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute cap$bility: 7.0)\r\n2019-08-02 00:53:36.359543: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: The graph is already optimized by layout optimizer.\r\nI0802 00:53:46.876585 140615879628544 do.py:122] Starting execution\r\n2019-08-02 00:53:51.250421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\r\npciBusID: 0000:3b:00.0\r\n2019-08-02 00:53:51.250522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-02 00:53:51.250535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-08-02 00:53:51.250548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-08-02 00:53:51.250560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-08-02 00:53:51.250569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-08-02 00:53:51.250582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-08-02 00:53:51.250594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-08-02 00:53:51.252089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-08-02 00:53:51.252127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-08-02 00:53:51.252135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-08-02 00:53:51.252142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-08-02 00:53:51.253800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16240 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute cap$bility: 7.0)\r\nI0802 00:53:51.253948 140615879628544 do.py:141] Starting Warmup cycle\r\n2019-08-02 00:53:55.477931: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: The graph is already optimized by layout optimizer.\r\nI0802 00:54:07.796527 140615879628544 do.py:146] Starting timing.\r\nI0802 00:55:26.767084 140615879628544 do.py:153] Timing loop done!\r\n```\r\n\r\n```\r\n==========================\r\nnetwork: native_tiny-yolov3_frozen.pb,   batchsize 128, steps 100\r\n  fps   median: 820.8,  mean: 802.9,    uncertainty: 5.2,       jitter: 2.6\r\n  latency       median: 0.15594,        mean: 0.16036,  99th_p: 0.23999,        99th_uncertainty: 0.06786\r\n\r\n==========================\r\nnetwork: tftrt_fp32_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 823.7,  mean: 813.5,    uncertainty: 5.9,       jitter: 1.9\r\n  latency       median: 0.15539,        mean: 0.15867,  99th_p: 0.27463,        99th_uncertainty: 0.09189\r\n\r\n==========================\r\nnetwork: tftrt_fp16_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 822.3,  mean: 805.1,    uncertainty: 4.7,       jitter: 4.9\r\n  latency       median: 0.15567,        mean: 0.15982,  99th_p: 0.22045,        99th_uncertainty: 0.09074\r\n\r\n==========================\r\nnetwork: tftrt_int8_tiny-yolov3_frozen.pb,       batchsize 128, steps 100\r\n  fps   median: 824.2,  mean: 824.0,    uncertainty: 0.2,       jitter: 1.1\r\n  latency       median: 0.15530,        mean: 0.15534,  99th_p: 0.15649,        99th_uncertainty: 0.00074\r\n\r\n==========================\r\nnetwork: native_big-yolov3_frozen.pb,    batchsize 128, steps 100\r\n  fps   median: 162.8,  mean: 160.8,    uncertainty: 0.6,       jitter: 3.7\r\n  latency       median: 0.78606,        mean: 0.79734,  99th_p: 0.97108,        99th_uncertainty: 0.11392\r\n\r\n==========================\r\nnetwork: tftrt_fp32_big-yolov3_frozen.pb,        batchsize 128, steps 100\r\n  fps   median: 164.9,  mean: 163.7,    uncertainty: 0.4,       jitter: 1.0\r\n  latency       median: 0.77605,        mean: 0.78252,  99th_p: 0.89290,        99th_uncertainty: 0.09504\r\n\r\n==========================\r\nnetwork: tftrt_fp16_big-yolov3_frozen.pb,        batchsize 128, steps 100\r\n  fps   median: 165.1,  mean: 164.0,    uncertainty: 0.3,       jitter: 0.8\r\n  latency       median: 0.77537,        mean: 0.78063,  99th_p: 0.83099,        99th_uncertainty: 0.07721\r\n\r\n==========================\r\nnetwork: tftrt_int8_big-yolov3_frozen.pb,        batchsize 128, steps 100\r\n  fps   median: 165.4,  mean: 163.3,    uncertainty: 1.0,       jitter: 0.2\r\n  latency       median: 0.77405,        mean: 0.78970,  99th_p: 0.98406,        99th_uncertainty: 0.51370\r\n\r\n```", "NVIDIA container 19.07 is compatible with TF 1.14.\r\nYou wouldn't need to install anything like TensorRT or CUDNN. \r\n", "> NVIDIA container 19.07 is compatible with TF 1.14.\r\n> You wouldn't need to install anything like TensorRT or CUDNN.\r\n\r\n@pooyadavoodi `tensorflow-gpu==1.14.0` expects CUDA 10.0.x, whereas the container comes with CUDA 10.1.168 \r\n\r\n```\r\n2019-08-05 14:20:24.954346: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2019-08-05 14:20:24.954436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2019-08-05 14:20:24.954501: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2019-08-05 14:20:24.954564: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2019-08-05 14:20:24.954627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2019-08-05 14:20:24.954690: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n```", "> > NVIDIA container 19.07 is compatible with TF 1.14.\r\n> > You wouldn't need to install anything like TensorRT or CUDNN.\r\n> \r\n> @pooyadavoodi `tensorflow-gpu==1.14.0` expects CUDA 10.0.x, whereas the container comes with CUDA 10.1.168\r\n> \r\n> ```\r\n> 2019-08-05 14:20:24.954346: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> 2019-08-05 14:20:24.954436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> 2019-08-05 14:20:24.954501: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> 2019-08-05 14:20:24.954564: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> 2019-08-05 14:20:24.954627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> 2019-08-05 14:20:24.954690: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> ```\r\n\r\nYou don't need to install tensorflow inside the container. We have already built and installed tensorflow for you inside that container. It's ready to use.", "> You don't need to install tensorflow inside the container. We have already built and installed tensorflow for you inside that container. It's ready to use.\r\n\r\nYep, I was incorrect. I installed the python dependencies by running `/opt/tensorrt/python/python_setup.sh` (as directed by the container, upon booting up), and it seems to install `tensorflow==1.14.0` from locally. However, how would I install `tensorflow-gpu==1.14.0` from locally?", "> I installed the python dependencies by running `/opt/tensorrt/python/python_setup.sh` (as directed by the container, upon booting up), and it seems to install `tensorflow==1.14.0` from locally. However, how would I install `tensorflow-gpu==1.14.0` from locally?\r\n\r\nCould you post the log of this?\r\nI just tried this I didn't see that the container boot telling to run `python_setup.sh`.\r\n\r\nYou don't need to run  `/opt/tensorrt/python/python_setup.sh`.\r\n", "Closing as a duplicate of https://github.com/tensorflow/tensorflow/issues/31039", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30717\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30717\">No</a>\n", "> Closing as a duplicate of #31039\r\n\r\n@pooyadavoodi \r\n\r\nHi, I have same problem with TF-TRT. Is that means that using TF-TRT based on TensorRT 4 or 5 will get model with twice of size, and slower speed of inference? Is that using higher version of TensorRT is the only option for this situation?\r\n\r\nI tried TF-TRT base on TF1.12+TRT4 and TF1.15+TRT5, they got same results (larger .pb model and slowdown after INT8 quantization).\r\n\r\nI also tried TensorRT4 only (using import tensorrt as trt), and the results seem reasonable (small model in .plan format and faster speed).\r\n\r\nWhere can I download the TF1.14 with TF-TRT module? I know the pip install tensorflow-gpu==1.14 will get a TF without TF-TRT module, and I don't want to download a whole container from Nvidia-GPU-Cloud.\r\n\r\nOne more thing, I noticed that the TF1.14 needs less memory while doing inference than other version of TF. For example, only 29MB memory for MobileNetV1 with TF1.14 (pb file was provided by TF official github repository), 300+MB with TF1.15, and ~1.4GB with TF1.12/1.13/1.8/1.9 (even I set gpu_options.allow_growth = True). Can you tell me why?"]}, {"number": 30716, "title": "Provide Raspberry Pi #aarch64 cross-compile instructions", "body": "**System information**\r\n- TensorFlow version (you are using): 1.13.1\r\n- Are you willing to contribute it (Yes/No): yes, at least as a tester\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThere is no pre-build binary for Raspberry Pi / ARM and the instructions to build from scratch [here](https://www.tensorflow.org/install/source_rpi#build_from_source). However, there is nothing for any kind of SBC (like Raspberry Pi, ODroid, Pine64, etc) with a aarch64 architecture. \r\n\r\nI cannot use the Python wheel. I need the C library to bind to a different language. \r\n\r\n**Will this change the current api? How?**\r\n\r\nNo. \r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone using a SBC with a aarch64 OS. \r\n\r\n", "comments": ["Haven't tried this myself, but you can [find here](https://www.tensorflow.org/install/pip) how to install using pip directly on the Raspberry Pi  ", "That would only work for installing the Python wheel. I need the C library to bind via FFI to other languages (like Go, Rust, etc)", "Not sure about 1.13.1, For 1.14 or master branch, Something like \r\n```\r\nbazel --host_jvm_args=-Xms128m --host_jvm_args=-Xmx2048m \\\r\nbuild --config opt --local_resources 1024,1,1 \\\r\ntensorflow/tools/lib_package:libtensorflow\r\n```\r\nshould just work. I think I upstreamed necessary patches for\r\n```\r\nbazel --host_jvm_args=-Xms128m --host_jvm_args=-Xmx2048m \\\r\nbuild --config opt --local_resources 1024,1,1 \\\r\ntensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nRaspbian 32-bit is a bit complicated, because for RPI 3, an AAarch64 platform, it runs aarch32 (armv7-a) kernel,  armv6 user-level binaries, and compilers/toolchains configured to armv6.\r\n", "Hi @freedomtan \r\nThanks for your response. But there is something I am not sure I understand. The link I pasted above (in my original post) is a way for *cross compiling* for Raspberry Pi. Doing something as simple as:\r\n\r\n          tensorflow/tools/ci_build/ci_build.sh PI \\\r\n          tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n\r\nIf you see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/pi/build_raspberry_pi.sh) you can see all the magic. Cross compiling is much easier and faster than compiling on the Pi. \r\n\r\nI have many images running 64 bits OS on a Pi 3 and 4 (Armiban, Ubuntu Server 18.04, etc)... In addition, an aarch64 build would also help other similar SBC like Pine64, Odriod etc..\r\n\r\nWhat I was proposing is a similar `build_raspberry_pi.sh` but that would allow me to cross-compile for aarch64. \r\n\r\nThoughts?", "Yes, cross-compiling usually is much faster, esp. for a fresh build. Easier, I don't think so. As I said, the environments before RPi 4 is quite complex.", "Thanks @freedomtan for all your help.\r\nI finally took the time to [write down everything I found during my attempt to get TensorFlow C library compiled for Raspberry Pi](https://dev.to/martinezpeck/challenge-accepted-build-tensorflow-c-binding-for-raspberry-pi-in-2019-4f89). In that tutorial, I point back to this issue in case any progress is done.\r\nThank you", "I added an AArch64 toolchain to bazel in #38399 which should make cross-compiling a lot easier. It would be great if the PR could get a review.", "There are commands to build Python PIP wheel for aarch64.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30716\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30716\">No</a>\n", "Oh we need a guide to build full Tensorflow package. Let me check it.", "You can build TF Python wheel for aarch64.\r\nhttps://www.tensorflow.org/install/source_rpi#python-3.8-64bit", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30716\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30716\">No</a>\n", "> Hi @freedomtan\r\n> Thanks for your response. But there is something I am not sure I understand. The link I pasted above (in my original post) is a way for _cross compiling_ for Raspberry Pi. Doing something as simple as:\r\n> \r\n> ```\r\n>       tensorflow/tools/ci_build/ci_build.sh PI \\\r\n>       tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n> ```\r\n> \r\n> If you see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/pi/build_raspberry_pi.sh) you can see all the magic. Cross compiling is much easier and faster than compiling on the Pi.\r\n> \r\n> I have many images running 64 bits OS on a Pi 3 and 4 (Armiban, Ubuntu Server 18.04, etc)... In addition, an aarch64 build would also help other similar SBC like Pine64, Odriod etc..\r\n> \r\n> What I was proposing is a similar `build_raspberry_pi.sh` but that would allow me to cross-compile for aarch64.\r\n> \r\n> Thoughts?\r\n\r\nHow can i cross compile TF for ODROID? This script work for odroid xu4?"]}, {"number": 30714, "title": "Running inference on Coral TPU stick results in Segmentation fault", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Docker image tensorflow/tensorflow:gpu-latest\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 2.7.15+\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce RTX 2080 Ti\r\n\r\nI want to deploy a simple tflite model on a machine with an ARM processor and the Coral TPU Stick, but run into problems and inconsistencies during the process. Due to the procedure being quite long, I decided to post the whole process, so you track every step that I made. Overall goal is to fit a function of the form `f(x) = 2x - 1`.\r\n\r\n**1. Train a model with quantization aware training**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nprint(tf.__version__)\r\n\r\ntrain_input = np.array([ -1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\r\ntrain_truth = np.array([ -3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\r\n\r\ndef build_keras_model():\r\n\treturn keras.models.Sequential([\r\n\t\tkeras.layers.Dense(units=1, input_shape=[1]),\r\n\t])\r\n\r\n### train the model\r\ntrain_graph = tf.Graph()\r\ntrain_sess = tf.Session(graph=train_graph)\r\n\r\nkeras.backend.set_session(train_sess)\r\n\r\nwith train_graph.as_default():\r\n\tkeras.backend.set_learning_phase(1)\r\n\ttrain_model = build_keras_model()\r\n\r\n\ttf.contrib.quantize.create_training_graph(input_graph=train_graph, quant_delay=100)\r\n\ttrain_sess.run(tf.global_variables_initializer())\r\n\r\n\ttrain_model.compile(\r\n\t\toptimizer='sgd',\r\n\t\tloss='mean_squared_error'\r\n\t)\r\n\ttrain_model.fit(train_input, train_truth, epochs=250)\r\n\r\n\tsaver = tf.train.Saver()\r\n\tsaver.save(train_sess, 'linear.ckpt')\r\n```\r\nThis produces the checkpoint. Next, I created an eval graph and loaded the checkpoint.\r\n\r\n**2. Create the eval graph and freeze the model**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\ndef build_keras_model():\r\n\treturn keras.models.Sequential([\r\n\t\tkeras.layers.Dense(units=1, input_shape=[1]),\r\n\t])\r\n\r\n# eval\r\neval_graph = tf.Graph()\r\neval_sess = tf.Session(graph=eval_graph)\r\n\r\nkeras.backend.set_session(eval_sess)\r\n\r\nwith eval_graph.as_default():\r\n\tkeras.backend.set_learning_phase(0)\r\n\teval_model = build_keras_model()\r\n\r\n\ttf.contrib.quantize.create_eval_graph(input_graph=eval_graph)\r\n\r\n\teval_graph_def = eval_graph.as_graph_def()\r\n\tsaver = tf.train.Saver()\r\n\tsaver.restore(eval_sess, 'linear.ckpt')\r\n\r\n\tfrozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n\t\teval_sess,\r\n\t\teval_graph_def,\r\n\t\t[eval_model.output.op.name]\r\n\t)\r\n\r\n\twith open('frozen_model.pb', 'wb') as f:\r\n\t\tf.write(frozen_graph_def.SerializeToString())\r\n```\r\nI resorted to use the python API for freezing it because the command line tool throws errors. Executing this, I get a protocol buffer called `frozen_model.pb`.\r\n\r\n**3. Convert the protocol buffer into a tflite model**\r\n```\r\ntflite_convert \\\r\n--output_file=model.tflite \\\r\n--graph_def_file=frozen_model.pb \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_arrays=dense_input \\\r\n--output_arrays=dense/BiasAdd \\\r\n--mean_values=0 \\\r\n--std_dev_values=255 \\\r\n--default_ranges_min=-128 \\\r\n--default_ranges_max=127\r\n```\r\nResorting the the command line tool, this produces a tflite model. Although I am not sure how to determine good values for mean, std_dev and the default ranges, the conversion seems to work. I end up with a model, that I was able to load and interpret with the Python API. Apparently, everything has worked as expected.\r\n\r\n**4. Use the edgetpu_compiler to create a tflite file that utilizes the TPU stick**\r\n\r\n`edgetpu_compiler model.tflite`\r\n\r\nThis command creates a file called `model_edgetpu.tflite`. No errors, I even get a log file stating that everything worked as expected.\r\n\r\n**5. Transferring everything to the ARM machine, running the interpreter there**\r\n\r\nI tried to do inference on the target system, using the following C++ snippet to create an interpreter as described on the Coral site.\r\n\r\n```\r\n#include <stdio.h>\r\n#include \"tensorflow/lite/interpreter.h\"\r\n#include \"tensorflow/lite/kernels/register.h\"\r\n#include \"tensorflow/lite/model.h\"\r\n#include \"tensorflow/lite/tools/gen_op_registration.h\"\r\n#include \"edgetpu.h\"\r\n\r\nint main(){\r\n\r\n    // load model\r\n    std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(\"model_edgetpu.tflite\");\r\n\r\n    if(!model){\r\n        printf(\"Failed to mmap model\\n\");\r\n        exit(0);\r\n    }\r\n\r\n    // create TPU context handle\r\n    edgetpu::EdgeTpuContext* edgetpu_context = edgetpu::EdgeTpuManager::GetSingleton()->NewEdgeTpuContext().release();\r\n\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n    resolver.AddCustom(edgetpu::kCustomOp, edgetpu::RegisterCustomOp());\r\n\r\n    // Build the interpreter\r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n\r\n    if (tflite::InterpreterBuilder(*model, resolver)(&interpreter) != kTfLiteOk){\r\n            printf(\"Failed to build interpreter.\");\r\n    }\r\n\r\n    interpreter->SetExternalContext(kTfLiteEdgeTpuContext, edgetpu_context);\r\n    interpreter->SetNumThreads(1);\r\n\r\n    // Allocate memory\r\n    if(interpreter->AllocateTensors() != kTfLiteOk){\r\n            printf(\"Failed to allocate tensors.\");\r\n    }\r\n\r\n    // Prepare input(s)\r\n    float a = 0.0;\r\n    interpreter->typed_input_tensor<float>(0)[0] = a;\r\n\r\n    // Invoke the interpreter\r\n    interpreter->Invoke();\r\n\r\n    // Get output(s)\r\n    float* output = interpreter->typed_output_tensor<float>(0);\r\n\r\n    // Should print -1.0\r\n    printf(\"Result is: %f\\n\", *output);\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\nAfter compiling my executable without any errors, I get an Segmentation fault:\r\n```\r\nroot@localhost:/demo# ./tpu_demo \r\nINFO: Initialized TensorFlow Lite runtime.\r\nSegmentation fault\r\n```\r\n\r\nUntil this point, no errors have occured during the whole process. So I guess something went wrong during the creation of the tflite model. I also noticed that the non-edge_compiler version of the the tflite model also results in a Segmentation fault on the ARM system, even though I was able to use with the Python API.\r\n\r\nAny help is appreciated! Thanks.", "comments": ["Update: the problem seems to be the conversion process from the frozen model to tflite model. For better control, I switched to the Python API. Using the setup with inference type FLOAT, the model is convertible and deployable.\r\n\r\nMy code for conversion:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = 'frozen_model.pb'\r\ninputs = [\"dense_input\"]\r\noutputs = [\"dense/BiasAdd\"]\r\n\r\nsess = tf.Session()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, inputs, outputs)\r\nconverter.inference_type = tf.lite.constants.FLOAT\r\ninput_arrays = converter.get_input_arrays()\r\n\r\nconverter.quantized_input_stats = {input_arrays[0]: (0., 1.)} # mean, std_dev\r\n\r\ntflite_model = converter.convert()\r\n\r\nopen('py_converted_model.tflite', 'wb').write(tflite_model)\r\n```\r\n\r\nIt seems the frozen graph is alright, and something goes wrong during the conversion with quantization enabled. Consider the code which produces a tflite model, that is convertible via the edge_compiler, but fails when loaded.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = 'frozen_model.pb'\r\ninputs = [\"dense_input\"]\r\noutputs = [\"dense/BiasAdd\"]\r\n\r\nsess = tf.Session()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, inputs, outputs)\r\nconverter.inference_type = tf.lite.constants.QUANTIZED_UINT8\r\ninput_arrays = converter.get_input_arrays()\r\n\r\nconverter.allow_custom_ops = True\r\nconverter.quantized_input_stats = {input_arrays[0]: (0., 1.)} # mean, std_dev\r\nconverter.default_ranges_stats = (-128, 127)\r\n\r\ntflite_model = converter.convert()\r\n\r\nopen('py_converted_model.tflite', 'wb').write(tflite_model)\r\n```\r\n\r\nLoading the model with the C++ API, I get an error with a little more output than in the original question:\r\n\r\n\r\n```\r\nroot@localhost:/demo# ./tpu_demo py_converted_model_edgetpu.tflite \r\nINFO: Initialized TensorFlow Lite runtime.\r\nERROR: Failed to prepare for TPU. generic::failed_precondition: Custom op already assigned to a different TPU.\r\nERROR: Node number 0 (edgetpu-custom-op) failed to prepare.\r\n\r\nSegmentation fault\r\n```", "@liyunlu0618 \r\nCould you or somebody else confirm the correctness of this workflow? If it is a tensorflow issue, I could stop debugging my code and actually help figuring out the real problem.\r\n\r\nThanks!", "I have tried to reproduce this error with tf 2.0.0-beta1. Unfortunately, it is indeed reproducable, speaking that I can create a model, load and do inference with it via the Python interpreter API. But as soon as I utilize the edgetpu_compiler to create a model for an ARM platform, I get a Seg Fault (again). Here the code to reproduce this:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\ntrain_x = np.array([ [-4.0], [-3.0], [-2.0], [-1.0], [0.0], [1.0], [2.0], [3.0], [4.0], [5.0]], dtype=np.float32)\r\ntrain_y = np.array([ -9.0, -7.0, -5.0, -3.0, -1.0, 1.0, 3.0, 5.0, 7.0, 9.0], dtype=np.float32)\r\n\r\ntest_x = np.array([[4.5]], dtype=np.float32)\r\n\r\ndef build_model():\r\n\r\n\tmodel = keras.models.Sequential()\r\n\tmodel.add(keras.layers.Dense(1, input_shape=(1,)))\r\n\r\n\treturn model\r\n\r\n###\r\n### TRAINING\r\n###\r\n\r\nmodel = build_model()\r\nmodel.compile(optimizer='sgd',\r\n\t\t  \t  loss='mean_squared_error',\r\n)\r\n\r\nkeras_file = 'linear.h5'\r\nmodel.fit(train_x, train_y, epochs=150)\r\nkeras.models.save_model(model, keras_file)\r\n\r\n###\r\n### CONVERSION\r\n###\r\n\r\nif (tf.__version__ == '2.0.0-beta1'):\r\n\tconverter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\nelse:\r\n\traise NotImplementedError('Converter not implemented for this tf version')\r\n\r\ndef representative_dataset_gen():\r\n\tfor i in range(len(train_x)):\r\n\t\tyield [train_x[i:i+1]]\r\n\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_file_name = 'converted_linearmodel_tpu_' + str(tf.__version__) + '.tflite'\r\n\r\ntflite_model = converter.convert()\r\nopen(tflite_file_name, 'wb').write(tflite_model)\r\n\r\n###\r\n### INFERENCE FOR TESTING\r\n###\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_file_name)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_detail = interpreter.get_input_details()[0]\r\noutput_detail = interpreter.get_output_details()[0]\r\n\r\ndef quantize(real_value):\r\n\tstd, mean = input_detail['quantization']\r\n\treturn (real_value / std + mean).astype(np.uint8)\r\n\r\ndef dequantize(quant_value):\r\n\tstd, mean = output_detail['quantization']\r\n\treturn (std * (quant_value - mean)).astype(np.float32)\r\n\r\nsample_input = quantize(test_x[0]).reshape(input_detail['shape'])\r\n\r\ninterpreter.set_tensor(input_detail['index'], sample_input)\r\ninterpreter.invoke()\r\n\r\npred_original_model = model.predict(test_x[0])\r\npred_quantized_model = interpreter.get_tensor(output_detail['index'])\r\n\r\nprint(\"Pred Original : \", pred_original_model)\r\nprint(\"Pred Quantized : \", dequantize(pred_quantized_model[0].reshape(output_detail['shape'])))\r\n```\r\n\r\nThe output of this script on my machine is:\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nPred Original :  [[8.042535]]\r\nPred Quantized :  [[8.030863]]\r\n```\r\nSo obviously, the model has been quantized properly and gives reasonable results. Converting this model, I get the following output:\r\n```\r\nuser@localhost:~/tf/tensorflow2_beta$ edgetpu_compiler converted_linearmodel_tpu_2.0.0-beta1.tflite \r\nEdge TPU Compiler version 1.0.249710469\r\nINFO: Initialized TensorFlow Lite runtime.\r\n\r\nModel compiled successfully in 6 ms.\r\n\r\nInput model: converted_linearmodel_tpu_2.0.0-beta1.tflite\r\nInput size: 1.08KiB\r\nOutput model: converted_linearmodel_tpu_2.0.0-beta1_edgetpu.tflite\r\nOutput size: 32.52KiB\r\nOn-chip memory available for caching model parameters: 8.02MiB\r\nOn-chip memory used for caching model parameters: 512.00B\r\nOff-chip memory used for streaming uncached model parameters: 0.00B\r\nNumber of Edge TPU subgraphs: 1\r\nTotal number of operations: 3\r\nOperation log: converted_linearmodel_tpu_2.0.0-beta1_edgetpu.log\r\nSee the operation log file for individual operation details.\r\n```\r\nWith the conversion being successful, it seems the problems lies within the interpreter written in C++ (as described under 5. in my original question). When invoked, the executable produces the error:\r\n\r\n```\r\nroot@localhost:/demo# ./tpu_demo converted_linearmodel_tpu_2.0.0-beta1_edgetpu.tflite \r\nINFO: Initialized TensorFlow Lite runtime.\r\nERROR: Failed to prepare for TPU. generic::failed_precondition: Custom op already assigned to a different TPU.\r\nERROR: Node number 0 (edgetpu-custom-op) failed to prepare.\r\n\r\nSegmentation fault\r\n```\r\nCan you guys provide support what is going wrong here? Thanks!", "The problem seems to be the function that allocates memory for the tensors. The function call \r\n\r\n`interpreter->AllocateTensors()`\r\n\r\nreturns 1, e.g. an error. Upon looking at the file `tensorflow/tensorflow/lite/interpreter.cc` the error originates from primary_subgraph(), but I wasn't able to figure out what causes the Seg Fault:\r\n\r\n```\r\nTfLiteStatus Interpreter::AllocateTensors() {\r\n  return primary_subgraph().AllocateTensors();\r\n}\r\n```", "> I have tried to reproduce this error with tf 2.0.0-beta1. Unfortunately, it is indeed reproducable, speaking that I can create a model, load and do inference with it via the Python interpreter API. But as soon as I utilize the edgetpu_compiler to create a model for an ARM platform, I get a Seg Fault (again). Here the code to reproduce this:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> from tensorflow import keras\r\n> import numpy as np\r\n> \r\n> train_x = np.array([ [-4.0], [-3.0], [-2.0], [-1.0], [0.0], [1.0], [2.0], [3.0], [4.0], [5.0]], dtype=np.float32)\r\n> train_y = np.array([ -9.0, -7.0, -5.0, -3.0, -1.0, 1.0, 3.0, 5.0, 7.0, 9.0], dtype=np.float32)\r\n> \r\n> test_x = np.array([[4.5]], dtype=np.float32)\r\n> \r\n> def build_model():\r\n> \r\n> \tmodel = keras.models.Sequential()\r\n> \tmodel.add(keras.layers.Dense(1, input_shape=(1,)))\r\n> \r\n> \treturn model\r\n> \r\n> ###\r\n> ### TRAINING\r\n> ###\r\n> \r\n> model = build_model()\r\n> model.compile(optimizer='sgd',\r\n> \t\t  \t  loss='mean_squared_error',\r\n> )\r\n> \r\n> keras_file = 'linear.h5'\r\n> model.fit(train_x, train_y, epochs=150)\r\n> keras.models.save_model(model, keras_file)\r\n> \r\n> ###\r\n> ### CONVERSION\r\n> ###\r\n> \r\n> if (tf.__version__ == '2.0.0-beta1'):\r\n> \tconverter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\n> else:\r\n> \traise NotImplementedError('Converter not implemented for this tf version')\r\n> \r\n> def representative_dataset_gen():\r\n> \tfor i in range(len(train_x)):\r\n> \t\tyield [train_x[i:i+1]]\r\n> \r\n> converter.representative_dataset = representative_dataset_gen\r\n> converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n> converter.inference_input_type = tf.uint8\r\n> converter.inference_output_type = tf.uint8\r\n> converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n> \r\n> tflite_file_name = 'converted_linearmodel_tpu_' + str(tf.__version__) + '.tflite'\r\n> \r\n> tflite_model = converter.convert()\r\n> open(tflite_file_name, 'wb').write(tflite_model)\r\n> \r\n> ###\r\n> ### INFERENCE FOR TESTING\r\n> ###\r\n> \r\n> interpreter = tf.lite.Interpreter(model_path=tflite_file_name)\r\n> interpreter.allocate_tensors()\r\n> \r\n> input_detail = interpreter.get_input_details()[0]\r\n> output_detail = interpreter.get_output_details()[0]\r\n> \r\n> def quantize(real_value):\r\n> \tstd, mean = input_detail['quantization']\r\n> \treturn (real_value / std + mean).astype(np.uint8)\r\n> \r\n> def dequantize(quant_value):\r\n> \tstd, mean = output_detail['quantization']\r\n> \treturn (std * (quant_value - mean)).astype(np.float32)\r\n> \r\n> sample_input = quantize(test_x[0]).reshape(input_detail['shape'])\r\n> \r\n> interpreter.set_tensor(input_detail['index'], sample_input)\r\n> interpreter.invoke()\r\n> \r\n> pred_original_model = model.predict(test_x[0])\r\n> pred_quantized_model = interpreter.get_tensor(output_detail['index'])\r\n> \r\n> print(\"Pred Original : \", pred_original_model)\r\n> print(\"Pred Quantized : \", dequantize(pred_quantized_model[0].reshape(output_detail['shape'])))\r\n> ```\r\n> \r\n> The output of this script on my machine is:\r\n> \r\n> ```\r\n> INFO: Initialized TensorFlow Lite runtime.\r\n> Pred Original :  [[8.042535]]\r\n> Pred Quantized :  [[8.030863]]\r\n> ```\r\n> \r\n> So obviously, the model has been quantized properly and gives reasonable results. Converting this model, I get the following output:\r\n> \r\n> ```\r\n> user@localhost:~/tf/tensorflow2_beta$ edgetpu_compiler converted_linearmodel_tpu_2.0.0-beta1.tflite \r\n> Edge TPU Compiler version 1.0.249710469\r\n> INFO: Initialized TensorFlow Lite runtime.\r\n> \r\n> Model compiled successfully in 6 ms.\r\n> \r\n> Input model: converted_linearmodel_tpu_2.0.0-beta1.tflite\r\n> Input size: 1.08KiB\r\n> Output model: converted_linearmodel_tpu_2.0.0-beta1_edgetpu.tflite\r\n> Output size: 32.52KiB\r\n> On-chip memory available for caching model parameters: 8.02MiB\r\n> On-chip memory used for caching model parameters: 512.00B\r\n> Off-chip memory used for streaming uncached model parameters: 0.00B\r\n> Number of Edge TPU subgraphs: 1\r\n> Total number of operations: 3\r\n> Operation log: converted_linearmodel_tpu_2.0.0-beta1_edgetpu.log\r\n> See the operation log file for individual operation details.\r\n> ```\r\n> \r\n> With the conversion being successful, it seems the problems lies within the interpreter written in C++ (as described under 5. in my original question). When invoked, the executable produces the error:\r\n> \r\n> ```\r\n> root@localhost:/demo# ./tpu_demo converted_linearmodel_tpu_2.0.0-beta1_edgetpu.tflite \r\n> INFO: Initialized TensorFlow Lite runtime.\r\n> ERROR: Failed to prepare for TPU. generic::failed_precondition: Custom op already assigned to a different TPU.\r\n> ERROR: Node number 0 (edgetpu-custom-op) failed to prepare.\r\n> \r\n> Segmentation fault\r\n> ```\r\n> \r\n> Can you guys provide support what is going wrong here? Thanks!\r\n\r\nCan you provide the log file after running edgetpu_compiler? \r\nAnd check how much is TPU compatible? It will give a detailed report. \r\n\r\nNote: There is a *.log file created with partials of your tflite model name added with suffix edgetpu*\r\n\r\nex : <tflite_model_name>_edgetpu.log ", "@vibhatha \r\nSure, take a look:\r\n\r\n```\r\nEdge TPU Compiler version 1.0.249710469\r\nInput: converted_linearmodel_tpu_2.0.0-beta1.tflite\r\nOutput: converted_linearmodel_tpu_2.0.0-beta1_edgetpu.tflite\r\n\r\nOperator                       Count      Status\r\n\r\nFULLY_CONNECTED                1          Mapped to Edge TPU\r\nQUANTIZE                       2          Mapped to Edge TPU\r\n```\r\nThanks!", "It seems. Everything is good. \r\n\r\nCan u load the tflite model to the interpreter and check what is the expected input shape?\r\nAnd make sure what you try to infer (input for inference) has the same shape?\r\n", "@vibhatha \r\nI did not find any possibility to inspect my model. What I can show you is the point, where my exe dies:\r\n\r\n```\r\n#include <stdio.h>\r\n#include \"tensorflow/lite/interpreter.h\"\r\n#include \"tensorflow/lite/kernels/register.h\"\r\n#include \"tensorflow/lite/model.h\"\r\n#include \"tensorflow/lite/tools/gen_op_registration.h\"\r\n#include \"edgetpu.h\"\r\n\r\nint main(){\r\n\r\n    // load model\r\n    std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(\"model_edgetpu.tflite\");\r\n\r\n    if(!model){\r\n        printf(\"Failed to mmap model\\n\");\r\n        exit(0);\r\n    }\r\n\r\n    // create TPU context handle\r\n    edgetpu::EdgeTpuContext* edgetpu_context = edgetpu::EdgeTpuManager::GetSingleton()->NewEdgeTpuContext().release();\r\n\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n    resolver.AddCustom(edgetpu::kCustomOp, edgetpu::RegisterCustomOp());\r\n\r\n    // Build the interpreter\r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n\r\n    if (tflite::InterpreterBuilder(*model, resolver)(&interpreter) != kTfLiteOk){\r\n            printf(\"Failed to build interpreter.\");\r\n    }\r\n\r\n    interpreter->SetExternalContext(kTfLiteEdgeTpuContext, edgetpu_context);\r\n    interpreter->SetNumThreads(1);\r\n\r\n    // ########### MALLOC FAILS AND RETURNS 1 ############\r\n    // Allocate memory\r\n    if(interpreter->AllocateTensors() != kTfLiteOk){\r\n            printf(\"Failed to allocate tensors.\");\r\n    }\r\n    // ###################################################\r\n\r\n    // Prepare input(s)\r\n    float a = 0.0;\r\n\r\n    // ################ THIS LINE CAUSES THE SEG FAULT ###################\r\n    interpreter->typed_input_tensor<float>(0)[0] = a;\r\n    // ###################################################################\r\n\r\n    // Invoke the interpreter\r\n    interpreter->Invoke();\r\n\r\n    // Get output(s)\r\n    float* output = interpreter->typed_output_tensor<float>(0);\r\n\r\n    // Should print -1.0\r\n    printf(\"Result is: %f\\n\", *output);\r\n\r\n    return 0;\r\n}\r\n```\r\nI guess that the second line tries to write to a place that could not be allocated beforehand.", "`\r\ntflite_fname = \"path_to_tflite_model\"\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_fname)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_detail = interpreter.get_input_details()[0]\r\noutput_detail = interpreter.get_output_details()[0]\r\n\r\nprint(\"Input Details : \", input_detail)\r\n print(\"Output Details : \", output_detail)\r\n\r\ndef quantize(real_value):\r\n      std, mean = input_detail['quantization']\r\n      return (real_value / std + mean).astype(np.uint8)\r\n`\r\n\r\nCheck these details and see if your input array has the right shape? ", "@DocDriven \r\n`            test = xtest[i] # from your testing dataset\r\n            test_label = ytest[i] # from your testing dataset\r\n            sample_input = quantize(test).reshape(input_detail['shape'])\r\n            interpreter.set_tensor(input_detail['index'], sample_input)\r\n            interpreter.invoke()\r\n`           \r\nYou need to call corresponding C++ endpoints. \r\n\r\nAre you doing it like this?  ", "@vibhatha\r\nI was finally able to track down the cause of the Seg Faults. For some odd reason, typed_output_tensor and typed_input_tensor members do NOT work. They did however, when not using the TPU.\r\n\r\nInstead, simply use typed_tensor for setting the inputs and getting the outputs.\r\n\r\nOne last issue remains, however: I have to manually quantize and dequantize inputs and outputs. In Python, it is easy to retrieve std and mean. But is there a similar option in the C++ API?\r\n\r\nAnyway, thank you for helping me greatly!", "@DocDriven \r\n\r\nIt should be something similar. C++ may take a few more lines. But I think it won't be an issue. \r\nGlad it works now. ", "this example was helpful for me. \r\n```\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n```\r\nwas missing from this discussion:\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations\r\n\r\nwithout these two lines, the tflite model will convert and write. But edgetpu_compile will segfault with no information.\r\n", "@DocDriven Are you still facing issues.\r\nCan you please provide an update ?\r\n\r\nThanks ", "@karimnosseir \r\nI have fixed this for my current model. As mentioned before, the problem was the C++ API. I had to use `typed_tensor` for inputs and outputs, otherwise it doesn't work. \r\n\r\nI will close this now as my problem was resolved, but it might be a good idea to mention this somewhere in the official documentation in the troubleshooting section."]}, {"number": 30713, "title": "Gradient tape with tf.math.reduce_euclidean_norm disconnects", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary (Conda)\r\n- TensorFlow version (use command below): 2.0.0b1                  \r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A (Running on CPU)\r\n\r\n\r\n**Describe the current behavior**\r\nUsing GradientTape to track the gradients using tf.math.reduce_euclidean_norm directly the gradient disconnects and returns 'None'.\r\n\r\n**Describe the expected behavior**\r\nI expect a gradient to be returned. If I decompose the function into the three constituent sequential operators (square the elements, sum them [reducing the dimension] and square rooting the resulting tensor) I get the gradient connecting up as expected.\r\n\r\n**Code to reproduce the issue**\r\nimport tensorflow as tf\r\n\r\nx = tf.constant([3.0,1.2,17,0])\r\n\r\n\r\n''' Calculate euclidian distance of an nD vector by tf implementation'''\r\nwith tf.GradientTape() as t2:\r\n  t2.watch(x)\r\n  z2 = tf.math.reduce_euclidean_norm(x, axis = -1)\r\n\r\ndz2_dx = t2.gradient(z2,x)\r\nprint(\"z: {}, \\nGradients: {}\".format(z2, dz2_dx))\r\n\r\n\r\n''' Calculate euclidian distance of an nD vector by decomposed operations'''\r\nwith tf.GradientTape() as t:\r\n  t.watch(x)\r\n  x_sq = tf.math.square(x)\r\n  x_sum_sq = tf.math.reduce_sum(x_sq, axis = 0)\r\n  z = tf.math.sqrt(x_sum_sq)\r\n\r\ndz_dx = t.gradient(z, x)\r\nprint(\"z: {}, \\nGradients: {}\".format(z, dz_dx))\r\n\r\n\r\n\r\n**Other info / logs**\r\nThe example code gives:\r\nz: 17.30433464050293, \r\nGradients: None\r\nz: 17.30433464050293, \r\nGradients: [0.17336696 0.06934679 0.9824128  0.        ]\r\n\r\nWith the reduce_euclidean_distance() operator the gradient is dropped.", "comments": ["I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Thanks!", "FYI, It's just not implemented yet https://github.com/tensorflow/tensorflow/blob/c9443f07d2a5a5febcbaa415e27f871553661036/tensorflow/python/ops/math_grad.py#L53\r\n\r\nI think this could be confusing to users as it returns `None` without any explanation.  This is a simple example but for a complex real-world numerical script, it could take good amount of time figuring out which part was the problem.\r\n\r\nWould it make sense to have a notion of \"not implemented\" which raises an exception or prints an error/warning message instead of current `ops.NotDifferentiale`?", "That is a very serious bug. ops.NotDifferentiable is to be used only on purpose when an operation is not differentiable at all; for operations which are differentiable you do get an exception if you neither register a gradient nor mark it as notdifferentiable.\r\n\r\nHowever at this point removing this annotation would likely break existing code, so we should fix this by implementing the gradient. Can you take a stab at it, @kkimdev ?", "sg, started.", "Should be fixed on the master branch https://github.com/tensorflow/tensorflow/commit/f2d7bc27a00f2ee08335c00782f98af0d04a08e2", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30713\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30713\">No</a>\n"]}, {"number": 30712, "title": "Duplicate variables for models whose layers share weights", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14 and 2\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10/7\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n\r\nImagine you extend the tf.keras.layers.Layer with the class MyLayer, which is a wrapper for the tf.keras.layers.Dense layer class (this class extension could also be a Model, but that's not important).\r\n\r\nNow imagine you instantiate a Dense layer `dense` (w/ no bias) and initialize two independent MyLayer instances `dense1` and `dense2` using `dense`...\r\n\r\nNow, we extend the Model class to take two MyLayer instances on init. We do this because we want to use dense1 and dense2 to perform different tasks but we want their weights to be shared (in a realistic example, MyLayer would be split into MyLayer1 and MyLayer2, which would perform different operations on `call` but would both depend on `dense`). We run data through our model pipeline and compute a loss, gathering gradients by using either the GradientTape or keras optimizers. However, when we gather and apply gradients with respect to Model.trainable_variables, even though our model has one unique weight, the kernel for `dense`, Model.trainable_variables will return two variables, and the gradients will be calculated and thus applied twice, which I would say is a bug, insofar as it's unexpected.\r\n\r\n**Describe the expected behavior**\r\n\r\nModels whose layers have shared/tied weights should not return duplicate weights when accessing the trainable_variables property. A super simple work-around is to call list(set(model.trainable_variables)) but the real issue is the unexpected behavior: \"Why would I ever think that model.trainable_variables would return duplicates of the same variable ?!\" \r\n\r\nThe two calls to test in the code below should have the same output.\r\n\r\n**Code to reproduce the issue**\r\n`\r\ncode\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n\r\n    tf.enable_eager_execution()\r\n\r\n    class MyDense(tf.keras.layers.Layer):\r\n      def __init__(self, dense, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.dense = dense\r\n      def call(self, inputs):\r\n        return self.dense(inputs)\r\n\r\n    class MyModel(tf.keras.Model):\r\n      def __init__(self, dense1, dense2, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.dense1 = dense1\r\n        self.dense2 = dense2\r\n      def call(self, inputs):\r\n        return self.dense1(inputs) + self.dense2(inputs)\r\n\r\n    def test(unique):\r\n      x = tf.ones(shape=(10, 5))\r\n      y = tf.ones(shape=(10, 1)) + 2\r\n\r\n      dense = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.constant(0.2), use_bias=False)\r\n      dense1 = MyDense(dense)\r\n      dense2 = MyDense(dense)\r\n      model = MyModel(dense1, dense2)\r\n\r\n      adam = tf.keras.optimizers.Adam(0.001)\r\n\r\n      with tf.GradientTape() as tape:\r\n        y_hat = model(x)\r\n        loss = tf.keras.losses.mse(y, y_hat)\r\n        variables = model.trainable_variables if unique else list(set(model.trainable_variables))\r\n        print(f\"# trainable variables: {len(variables)}\")\r\n\r\n        pre_weight = variables[0][0]\r\n\r\n        grads = tape.gradient(loss, variables)\r\n        adam.apply_gradients(list(zip(grads, variables)))\r\n\r\n        post_weight = variables[0][0]\r\n\r\n        return post_weight - pre_weight\r\n\r\n    ex1 = test(True)\r\n    print(ex1)\r\n    print(\"\\n+=+=+=+=\\n\")\r\n    ex2 = test(False)\r\n    print(ex2)\r\n\r\n`\r\n\r\n", "comments": ["Unnoticed, this effectively acts as a multiplier on the learning rate for all shared weights, which leads to instability during training. Depending on the implementation of the the gradient computation for GradientTape and the keras optimizers, this would also mean a reduction in time and memory costs.\r\n\r\nTo motivate my request, consider an end-to-end encoder (categorical sequence to latent representation) and end-to-end decoder (latent representation to softmax distribution) which share embedding weights to A) embed the initial sequence and B) to project the output onto the vocabulary space. If the encoder and decoder are packaged into a tf.keras.Model extender, the embedding weights will be duplicated in the returned model.trainable_variables.", "I am able to reproduce the issue on Colab with Tensorflow 1.14.0. Please take a look at gist of [Colab](https://colab.research.google.com/drive/1SYo3S-Pt3OroErtbiJbw4CkqkVgd9oA_).Thanks!", "I could reproduce the issue With TF 2.0.0.beta1. Please have a look at gist of [Colab](https://colab.research.google.com/drive/1lgmEHNnn_A9Xjqrlh2v9OtXMpliN23Bc).Thanks!", "Is there a clean solution to this? Experiencing the same weight sharing double-gradients bug with my ELECTRA model.\r\n\r\nUsing `vars = list(set(vars))` inside a tf.function gives the error: `TypeError: Variable is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.`\r\n\r\nI tried `vars = list({var.experimental_ref(): var for var in vars}.values())`, but that feels hacky.", "@ymodak What is the status on this issue? And the label TF 1.14 has been replaced with TF 2.0, does that mean the issue will not be resolved for TF1.14?\r\n\r\nIs it generally the case that, if model.trainable_weights() returns a list with duplicates, the gradient is calculated twice w.r.t. the duplicates? \r\n\r\nOr are there checks under-the-hood that Keras performs, in order to remove them? Namely, in my autoencoder I am experiencing exactly this issue, where the trainable weights (kernels of dense layer) of the encoder appear multiple times in this list. ", "Was able to replicate the issue with TF v2.5 ,please find the [gist ](https://colab.research.google.com/gist/mohantym/690e34aaab9e3374801dd3e1c5aeb4bd/30712.ipynb#scrollTo=c_Oq_mrNojUX)here ..Thanks!", "Hi There,\r\n\r\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \r\n\r\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30712\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30712\">No</a>\n"]}, {"number": 30711, "title": "Keras custom metrics raises error when update_state returns an op.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI am trying to build a custom metric for Keras, which worked with tensorflow 1.12. Now after upgrading to python 1.14 I get the error shown below.  I am returning the result of tf.group in the update_state method of the metric which is of course an Op. What puzzles me is that `tensorflow.python.keras.utils.metric_utils.update_confusion_matrix_variables` which is used by many of the other builtin metrics like Precision, does the exact same thing. To make sure that the error is not caused by my own implementation I copied the implementation of tf.keras.metrics.Precision into my own file and tried to run it. It get the same error, however when I substitute this \"custom\" metric with the builtin, it works. The code to reproduce this is shown below.\r\n\r\n*Describe the expected behavior**\r\nThe custom metric should work as expected.\r\n\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.metrics import Metric\r\nfrom tensorflow.python.keras.utils import metrics_utils\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.ops import init_ops\r\nimport numpy as np\r\nfrom tensorflow.python.keras.utils.generic_utils import to_list\r\n\r\n\r\nclass Precision(Metric):\r\n    \"\"\"This is a 1:1 copy of the code in tensorflow.python.keras.metrics.\"\"\"\r\n    def __init__(self,\r\n                 thresholds=None,\r\n                 top_k=None,\r\n                 class_id=None,\r\n                 name=None,\r\n                 dtype=None):\r\n\r\n        super(Precision, self).__init__(name=name, dtype=dtype)\r\n        self.init_thresholds = thresholds\r\n        self.top_k = top_k\r\n        self.class_id = class_id\r\n\r\n        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF\r\n        self.thresholds = metrics_utils.parse_init_thresholds(\r\n            thresholds, default_threshold=default_threshold)\r\n        self.true_positives = self.add_weight(\r\n            'true_positives',\r\n            shape=(len(self.thresholds),),\r\n            initializer=init_ops.zeros_initializer)\r\n        self.false_positives = self.add_weight(\r\n            'false_positives',\r\n            shape=(len(self.thresholds),),\r\n            initializer=init_ops.zeros_initializer)\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        return metrics_utils.update_confusion_matrix_variables({\r\n            metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\r\n            metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives},\r\n            y_true,\r\n            y_pred,\r\n            thresholds=self.thresholds,\r\n            top_k=self.top_k,\r\n            class_id=self.class_id,\r\n            sample_weight=sample_weight)\r\n\r\n    def result(self):\r\n        result = math_ops.div_no_nan(\r\n            self.true_positives,\r\n            self.true_positives + self.false_positives)\r\n        return result[0] if len(self.thresholds) == 1 else result\r\n\r\n    def reset_states(self):\r\n        num_thresholds = len(to_list(self.thresholds))\r\n        K.batch_set_value(\r\n            [(v, np.zeros((num_thresholds,))) for v in self.variables])\r\n\r\n    def get_config(self):\r\n        config = {\r\n            'thresholds': self.init_thresholds,\r\n            'top_k': self.top_k,\r\n            'class_id': self.class_id\r\n        }\r\n        base_config = super(Precision, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n\r\n\r\nif __name__ == '__main__':\r\n    x = tf.keras.Input((10,))\r\n    y_hat = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n    model = tf.keras.models.Model(inputs=[x], outputs=[y_hat])\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.SGD(0.01),\r\n        loss='binary_crossentropy',\r\n        metrics=[Precision()])\r\n    # However the builtin metric works:\r\n    # model.compile(\r\n    #     optimizer=tf.keras.optimizers.SGD(0.01),\r\n    #     loss='binary_crossentropy',\r\n    #     metrics=[tf.keras.metrics.Precision()])\r\n\r\n    X = np.random.uniform(-1, 1, size=(100, 10)).astype(np.float32)\r\n    y = np.random.choice([0, 1], size=(100,)).astype(np.float32)\r\n    model.fit(X, y)\r\n\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 676, in convert\r\n    x = ops.convert_to_tensor_or_composite(x)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1479, in convert_to_tensor_or_composite\r\n    value=value, dtype=dtype, name=name, as_ref=False)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1518, in internal_convert_to_tensor_or_composite\r\n    accept_composite_tensors=True)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1224, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 6696, in _operation_conversion_error\r\n    (op.name, dtype, name, as_ref))\r\nTypeError: Can't convert Operation 'group_deps' to Tensor (target dtype=None, name=None, as_ref=False)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"metrics_bug.py\", line 75, in <module>\r\n    metrics=[Precision()])\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 330, in compile\r\n    masks=self._prepare_output_masks())\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2170, in _handle_metrics\r\n    target, output, output_mask))\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2118, in _handle_per_output_metrics\r\n    mask)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2094, in _call_metric_fn\r\n    strategy=self._distribution_strategy)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 1054, in call_replica_local_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 873, in call_metric_function\r\n    return metric_fn(y_true, y_pred, sample_weight=weights)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py\", line 170, in __call__\r\n    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/metrics_utils.py\", line 73, in decorated\r\n    update_op = update_state_fn(*args, **kwargs)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 414, in __call__\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 357, in _initialize\r\n    *args, **kwds))\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1349, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1652, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1545, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 720, in func_graph_from_py_func\r\n    expand_composites=True)\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 515, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 515, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 682, in convert\r\n    (str(python_func), type(x)))\r\nTypeError: To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of <function Function._defun_with_scope.<locals>.wrapped_fn at 0xb34ec5d08>, found return value of type <class 'tensorflow.python.framework.ops.Operation'>, which is not a Tensor.\r\n```\r\n\r\n", "comments": ["Same error in my custom metric on yesterday nightly build of tf-2.0 ", "@dekromp ,\r\nI tried reproducing the issue with TF 1.14 and i didn't get any error.\r\nplease take a look at Gist of [Colab link](https://colab.research.google.com/drive/1BUqCQgo2nuH9VQZyn4m1K6-1ANqLVWcA) .Thanks!", "> @dekromp ,\r\n> I tried reproducing the issue with TF 1.14 and i didn't get any error.\r\n> please take a look at Gist of [Colab link](https://colab.research.google.com/drive/1BUqCQgo2nuH9VQZyn4m1K6-1ANqLVWcA) .Thanks!\r\n\r\nYour link is private.", "@anush-o \r\nHi anush-o, thanks for looking into this. I made a small error in my code example above (which I fixed now). The code was still using `tf.keras.metrics.Precision` instead of `Precision` (Sorry for that). You should be able to reproduce the error now. In the meantime I tried the above snippet on another computer (Ubuntu 16.04) with a fresh conda environment and get the same error.", "I was able to replicate the issue with TF version 1.14. Thanks!", "@dekromp You can remove return statements and group ops from custom metrics. It is not required. Built in metrics have a different requirement because of an issue with TPUs. Once that is fixed we will remove the return from update_state from built-in metrics as well.\r\n\r\nThank you!", "@pavithrasv \r\nThat did the trick. Thanks for helping out.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30711\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30711\">No</a>\n"]}, {"number": 30710, "title": "No way to generate HTML docs from source", "body": "## Description of issue (what needs changing):\r\n\r\nAccording to https://github.com/tensorflow/tensorflow/issues/1574 there was no (open source) way to generate HTML docs from the TensorFlow source code in March of 2016. Is that still the case? I haven't been able to find any way to generate HTML docs from the source.\r\n\r\nGenerating offline HTML docs is useful for having access to offline docs [without having to scrape www.tensorflow.org](https://github.com/ppwwyyxx/dash-docset-tensorflow).", "comments": ["Apparently this is expected behavior as the generation is done by closed source infrastructure, but the generated HTML is published in the docs repo in the release branches, so for example, for 1.14, it's here: https://github.com/tensorflow/docs/tree/r1.14/site/en/api_docs\r\n\r\nClosing as this solves my problem."]}, {"number": 30709, "title": "Final fixes for the patch release", "body": "", "comments": []}, {"number": 30708, "title": "fix the issue when doing tf.Cast operation", "body": "Fix the issue: https://github.com/tensorflow/tensorflow/issues/30691", "comments": []}, {"number": 30707, "title": "fix the issue in Cast operation", "body": "Fix the issue: https://github.com/tensorflow/tensorflow/issues/30691  and  https://github.com/tensorflow/tensorflow/issues/30215\r\n\r\nWhen doing cast tensor into uint64(uint32) type ( and tensor's elements num is greater than 4. Note that there are some conditions to trigger this code)\r\nThe code would fill the values into the int64_val(int_val) field instead of uint64_val(uint32_val) or tensor_content field in the message TensorProto.\r\nso when reading the tensor, it would read uint64_val(uint32_val) field in the message TensorProto which by default is 0.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30707) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot \r\nI signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30707) for more info**.\n\n<!-- ok -->", "@rmlarsen @rthadur Sorry to interrupt, But any comments? ", "Thanks @rthadur , any comments @ezhulenev  @rmlarsen", "I see the error message:  import/copybara \u2014 An error happened while migrating the change\r\nWhere can I check the details? @rthadur @ezhulenev  @tensorflow-copybara", "@Leslie-Fang its working now , thank you ", "> @Leslie-Fang its working now , thank you\r\n\r\n@rthadur Great, thank you.\r\nIs there any one or robot would help me to click the merge button?"]}, {"number": 30706, "title": "HistogramFixedWidth in TFLite ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.0beta\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. \r\n\r\nIf those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). \r\n\r\nOtherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). \r\n\r\nHere is a list of operators for which you will need custom implementations: HistogramFixedWidth.\r\n```\r\n\r\nCode to reproduce:\r\n\r\n```\r\nnbins = 5\r\nvalue_range = [0.0, 5.0]\r\nnew_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\r\n\r\nroot = tf.train.Checkpoint()\r\nroot.nbins = tf.Variable(nbins)\r\nroot.value_range = tf.Variable(value_range)\r\nroot.f = tf.function(lambda x: tf.histogram_fixed_width(x, root.value_range, nbins=root.nbins))\r\n\r\ninput_data = tf.convert_to_tensor(new_values)\r\nconcrete_func = root.f.get_concrete_function(input_data)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\ntflite_model = converter.convert()\r\n```", "comments": ["Please reference [this question](https://www.tensorflow.org/lite/guide/faq#why_are_some_operations_not_implemented_in_tensorflow_lite) in the TFLite FAQ on how to handle unsupported operations.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30706\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30706\">No</a>\n"]}, {"number": 30705, "title": "./bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory", "body": "Hi guys.\r\ni built Bazel from scratch from here:\r\nhttps://docs.bazel.build/versions/master/install-compile-source.html\r\n\r\nNow i want to run \r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\nand then lite my model.but when i run it this error appears:\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory\r\n\r\nbut i have bazel-bin\r\n\r\n\r\nCan any one help me please?", "comments": ["@Davari393,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.Thanks!", "Closing due to lack of recent activity.Thanks!"]}, {"number": 30704, "title": "Deprecated apis updated in GAN examples", "body": "", "comments": []}, {"number": 30703, "title": "Compiling 1.14 with MPI support", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Centos 6.9\r\n- \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14\r\n- Python version: 3.6.5\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source):0.25.2\r\n- GCC/Compiler version (if compiling from source): 4.9,3\r\n- CUDA/cuDNN version:10.0.130/7\r\n- GPU model and memory: cuda\r\n\r\n\r\n\r\nCompiling with MPI support gives the following build errors:\r\nINFO: From Compiling tensorflow/contrib/mpi_collectives/kernels/ring.cu.cc:\r\nexternal/com_google_absl/absl/strings/string_view.h(495): warning: expression has no effect\r\ntensorflow/contrib/mpi_collectives/kernels/ring.cu.cc(109): error: identifier \"CudaLaunchKernel\" is undefined\r\ntensorflow/contrib/mpi_collectives/kernels/ring.cu.cc(110): error: identifier \"CudaLaunchKernel\" is undefined\r\ntensorflow/contrib/mpi_collectives/kernels/ring.cu.cc(111): error: identifier \"CudaLaunchKernel\" is undefined\r\n3 errors detected in the compilation of \"/tmp/tmpxft_00038d5b_00000000-6_ring.cu.cpp1.ii\".\r\n\r\nStandard ./configure but answer yes to MPI support\r\n\r\n\r\nCompiles fine without MPI. Have tried with both openmpi/3.1.3 and cuda enabled openmpi/3.1.3\r\n\r\n", "comments": ["@berniekirby Please provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "Well, it's slightly complicated as it's a cluster system that is near the end of it's life (Centos6).\r\nEssentially we 'module load' the versions of software we need:\r\nmodule load cuda/10.0.130 java gcc/4.9.3 python/3.6.5 bazel/0.25.2 binutils openmpi-gcc/3.1.3\r\n\r\nThen just run ./configure \r\n./configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.25.2- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/local/python/3.6.5/bin/python]:\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/python/3.6.5/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/python/3.6.5/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]:\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nCould not find any cuda.h matching version '' in any subdirectory:\r\n        ''\r\n        'include'\r\n        'include/cuda'\r\n        'include/*-linux-gnu'\r\n        'extras/CUPTI/include'\r\n        'include/cuda/CUPTI'\r\nof:\r\n        '/lib'\r\n        '/lib/i686/nosegneg'\r\n        '/lib64'\r\n        '/opt/ibutils/lib64'\r\n        '/opt/illumina/bsfs'\r\n        '/opt/mellanox/fca/lib'\r\n        '/opt/mellanox/libibprof/lib'\r\n        '/opt/mellanox/mxm/lib'\r\n        '/usr'\r\n        '/usr/lib'\r\n        '/usr/lib64'\r\n        '/usr/lib64/R/lib'\r\n        '/usr/lib64/atlas'\r\n        '/usr/lib64/llvm'\r\n        '/usr/lib64/mysql'\r\n        '/usr/lib64/nx'\r\n        '/usr/lib64/qt-3.3/lib'\r\n        '/usr/lib64/tcl8.5'\r\n        '/usr/lib64/xulrunner'\r\n        '/usr/local/cuda'\r\nAsking for detailed CUDA configuration...\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]:\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]:\r\n\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: 2.3\r\n\r\n\r\nPlease specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /usr/local/cuda/10.0.130\r\n\r\n\r\nFound CUDA 10.0 in:\r\n    /usr/local/cuda/10.0.130/lib64\r\n    /usr/local/cuda/10.0.130/include\r\nFound cuDNN 7 in:\r\n    /usr/local/cuda/10.0.130/lib64\r\n    /usr/local/cuda/10.0.130/include\r\nFound NCCL 2 in:\r\n    /usr/local/cuda/10.0.130/lib64\r\n    /usr/local/cuda/10.0.130/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]:\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]:\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/local/gcc/4.9.3/bin/gcc]:\r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: y\r\nMPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\nNow build:\r\nbazel build --linkopt=-lrt --verbose_failures --jobs=8 -c opt --copt=-fabi-version=6 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nAfter much output the build fails with the above given errors.", "I think this is a related issue:\r\nhttps://github.com/tensorflow/tensorflow/issues/26610\r\n\r\nAs far as I know, MPI with TF is community supported.", "It looks to me as though tensorflow/contrib/mpi_collectives/kernels/ring.cu.cc needs to somehow via #includes get the definition of CudaLaunchKernel from somewhere.\r\nIt's apparently defined in /tensorflow/core/util/gpu_kernel_helper.h\r\nIt's to convoluted for me to figure all that out so I'll just leave it.\r\n\r\nIf it's community supported, then I suppose we'll just have to wait.\r\n\r\nThank you for your time.", "I will work on a fix. ", "@byronyi Any updates on this? I'm hitting the same problem...", "I got this working by adding \r\n#include \"tensorflow/core/util/gpu_kernel_helper.h\"\r\nto line 23 of \r\ntensorflow/contrib/mpi_collectives/kernels/ring.cu.cc\r\nStill testing everything, but seems to be working so far.", "I can confirm that adding an `include` statement for `tensorflow/core/util/gpu_kernel_helper.h` fixed the reported issue, thanks for sharing @johnbensnyder!", "Fixed by https://github.com/tensorflow/tensorflow/pull/29673", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30703\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30703\">No</a>\n"]}, {"number": 30702, "title": "Variation in Tensorflow execution latency", "body": "**System information:**\r\n\r\nNeural Network: \tLeNet 300-100\r\nTarget Platform: \tXEON PLATINUM 8000 SERIES - AMAZON AWS EC2 C5 INSTANCE\r\nSupports:  A\t\tVX-512, 72 Cores, 2-4 Threads; Up to 2 Instance Cores and 2 vCPUs\r\nBaseline Framework: \tTensorFlow (AWS Image Version)\r\nAMI ID: \t\tDeep Learning AMI (Ubuntu) Version 23.1 (ami-07262a45de118922e)\r\nPython version:\t\tp27\r\n\r\n\r\n**Describe the problem:**\r\n\r\n\t\t\tTo collect baseline results for TensorFlow model of lenet_300_100 ( Find the Accuracy and inference latency). By using MNIST dataset with a batch size of 16 and full(10000) number of batches.\r\n\r\nAnalysis Tensorflow inference runtime results, There is inconsistent on subsequent sessions. Please review the attached \u201cref_times\u201d for  inconsistent runtime for various batches.\r\n![Runtime](https://user-images.githubusercontent.com/51189885/61205763-943e4380-a70e-11e9-8ead-568ddd829416.png)\r\n[ref_times.txt](https://github.com/tensorflow/tensorflow/files/3391578/ref_times.txt)\r\nPlease review the following logs and advice on this.\r\n\r\n**Source code / logs:**\r\n\r\n**Time session source code:**\r\n\r\nwith tf.Session(graph=graph, config=config) as sess:\r\n    curr_batch = 0\r\n    warm_up = 5\r\n    for i in range(warm_up):\r\n        sess.run(output, feed_dict={input_: zeros})\r\n    while True:\r\n        batch = input_reader.receive_batch()\r\n        if batch is None:\r\n            break\r\n        start = monotonic.monotonic()\r\n        pred = sess.run(output, feed_dict={input_: batch})\r\n        sys.stderr.write('Batch Inference Time(s): {}\\n'.format(\r\n            monotonic.monotonic() - start))\r\n        output_writer.output_send(pred)\r\n\r\nPlease let know need another details? Please review all and advice me on this. \r\n\r\n", "comments": ["@VinothInspirit ,\r\n\r\nPlease provide us TF version and also the complete code being used so that we can replicate the issue from our end.Thanks!       ", "Thanks for your response.\r\nI have pasted the complete source code for your evaluation, Results of evaluation time text file to understand the inconsistency inference time \r\nAnd TF version : 1.13.1.\r\nPlease review and advice me on this\r\n[Results_ref_times.txt](https://github.com/tensorflow/tensorflow/files/3401386/Results_ref_times.txt)\r\n\r\n\r\n`\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[2]:\r\n\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport sys\r\nfrom scipy.io import savemat\r\nimport matplotlib.pyplot as plt\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\n\r\n\r\n# In[3]:\r\n\r\n\r\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n\r\n\r\n# In[107]:\r\n\r\n\r\noutput_graph =  \"./lenet-300.pb\"\r\n\r\n\r\n# In[41]:\r\n\r\n\r\n# Parameters\r\nlearning_rate_ini = 0.001\r\ntraining_epochs = 2\r\nbatch_size = 16\r\ndisplay_step = 1\r\nnum_batches = 100\r\n\r\n\r\n# In[33]:\r\n\r\n\r\n# Network Parameters\r\nn_hidden_1 = 300  # 1st layer num features\r\nn_hidden_2 = 100  # 2nd layer num features\r\nn_classes = 10  # MNIST total classes (0-9 digits)\r\n\r\n\r\n# In[34]:\r\n\r\n\r\n# tf Graph input\r\ntf.reset_default_graph()\r\nwith tf.name_scope(\"input_tensor\"):\r\n    x = tf.placeholder(\"float\", [None, 784])\r\nwith tf.name_scope(\"label_tensor\"):\r\n    y = tf.placeholder(\"float\", [None, n_classes])\r\n\r\n\r\n# In[35]:\r\n\r\n\r\n# Create model\r\ndef model(_X, _W, _biases):\r\n    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _W['fc1']), _biases['fc1']))  # Hidden layer with RELU activation\r\n    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _W['fc2']), _biases['fc2']))      # Hidden layer with RELU activation\r\n    with tf.name_scope(\"predictions\"):\r\n        pred = tf.matmul(layer_2, _W['out']) + _biases['out']\r\n    return pred\r\n\r\n\r\n# In[36]:\r\n\r\n\r\n# Store layers weight & bias\r\nW = {\r\n    'fc1': tf.Variable(tf.random_normal([784, n_hidden_1], stddev=0.01)),\r\n    'fc2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=0.01)),\r\n    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=0.01))\r\n}\r\n\r\n\r\nbiases = {\r\n    'fc1': tf.Variable(tf.random_normal([n_hidden_1], stddev=0.01)),\r\n    'fc2': tf.Variable(tf.random_normal([n_hidden_2], stddev=0.01)),\r\n    'out': tf.Variable(tf.random_normal([n_classes], stddev=0.01))\r\n}\r\n\r\n\r\n# In[37]:\r\n\r\n\r\nimport time\r\n\r\n\r\n# In[42]:\r\n\r\n\r\nif(1):\r\n    # Construct model\r\n    pred = model(x, W, biases)\r\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))  # Softmax loss\r\n    cost = loss\r\n    optimizer = tf.train.AdamOptimizer(learning_rate_ini, beta1=0.9, beta2=0.999,\r\n            epsilon=1e-08, use_locking=False).minimize(cost)\r\n    # Test model\r\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\r\n    # Calculate accuracy\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n    # Initializing the variables\r\n    init = tf.initialize_all_variables()\r\n    # Run model\r\n    accuracy_total = None\r\n    config = tf.ConfigProto(device_count={'GPU': 0})\r\n    config.log_device_placement = True\r\n    with tf.Session(config=config) as sess:\r\n        sess.run(init)\r\n        # Training cycle\r\n        for epoch in range(training_epochs):\r\n            avg_loss = 0.\r\n            total_batch = int(mnist.train.num_examples/batch_size)\r\n            # Loop over all batches\r\n            for i in range(total_batch):\r\n                batch_x, batch_y = mnist.train.next_batch(batch_size)\r\n                # Run optimization op (backprop) and cost op (to get loss value)\r\n                accuracy_total, predictions,_, l = sess.run([accuracy,pred, optimizer, loss], \r\n                                                            feed_dict={x: batch_x,\r\n                                                              y: batch_y})\r\n                # Compute average loss\r\n                avg_loss += l / total_batch\r\n            # Display logs per epoch step\r\n            if epoch % display_step == 0:\r\n                print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\",                     \"{:.9f}\".format(avg_loss))\r\n        print(\"Optimization Finished!\")\r\n        print(\"Accuracy : \", accuracy_total)\r\n        for i in range(num_batches):\r\n            batch_x, batch_y = mnist.test.next_batch(batch_size)\r\n            start_time = time.time()\r\n            val_acc = accuracy.eval({x: batch_x , y: batch_y})\r\n            print(\"Evaluation time batch {} : {}\".format(i+1, time.time()-start_time))\r\n            print(\"Validation Acc : {}\".format(val_acc))\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n\r\n\r\n`", "@VinothInspirit,\r\nWhen i tried executing the last section of the code i faced the following `error RuntimeError: Attempted to use a closed Session`.Kindly help us to reproduce the issue.Thanks!\r\n", "```\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport sys\r\nfrom scipy.io import savemat\r\nimport matplotlib.pyplot as plt\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\n\r\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n\r\n\r\noutput_graph =  \"./lenet-300.pb\"\r\n\r\n\r\n\r\n\r\n# Parameters\r\nlearning_rate_ini = 0.001\r\ntraining_epochs = 2\r\nbatch_size = 16\r\ndisplay_step = 1\r\nnum_batches = 100\r\n\r\n\r\n\r\n# Network Parameters\r\nn_hidden_1 = 300  # 1st layer num features\r\nn_hidden_2 = 100  # 2nd layer num features\r\nn_classes = 10  # MNIST total classes (0-9 digits)\r\n\r\n\r\n\r\n# tf Graph input\r\ntf.reset_default_graph()\r\nwith tf.name_scope(\"input_tensor\"):\r\n    x = tf.placeholder(\"float\", [None, 784])\r\nwith tf.name_scope(\"label_tensor\"):\r\n    y = tf.placeholder(\"float\", [None, n_classes])\r\n\r\n\r\n\r\n\r\n# Create model\r\ndef model(_X, _W, _biases):\r\n    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _W['fc1']), _biases['fc1']))  # Hidden layer with RELU activation\r\n    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _W['fc2']), _biases['fc2']))      # Hidden layer with RELU activation\r\n    with tf.name_scope(\"predictions\"):\r\n        pred = tf.matmul(layer_2, _W['out']) + _biases['out']\r\n    return pred\r\n\r\n\r\n\r\n# Store layers weight & bias\r\nW = {\r\n    'fc1': tf.Variable(tf.random_normal([784, n_hidden_1], stddev=0.01)),\r\n    'fc2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=0.01)),\r\n    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=0.01))\r\n}\r\n\r\n\r\nbiases = {\r\n    'fc1': tf.Variable(tf.random_normal([n_hidden_1], stddev=0.01)),\r\n    'fc2': tf.Variable(tf.random_normal([n_hidden_2], stddev=0.01)),\r\n    'out': tf.Variable(tf.random_normal([n_classes], stddev=0.01))\r\n}\r\n\r\n\r\nimport time\r\n\r\n\r\n\r\n\r\nif(1):\r\n    # Construct model\r\n    pred = model(x, W, biases)\r\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))  # Softmax loss\r\n    cost = loss\r\n    optimizer = tf.train.AdamOptimizer(learning_rate_ini, beta1=0.9, beta2=0.999,\r\n            epsilon=1e-08, use_locking=False).minimize(cost)\r\n    # Test model\r\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\r\n    # Calculate accuracy\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n    # Initializing the variables\r\n    init = tf.initialize_all_variables()\r\n    # Run model\r\n    accuracy_total = None\r\n    config = tf.ConfigProto(device_count={'GPU': 0})\r\n    config.log_device_placement = True\r\n    with tf.Session(config=config) as sess:\r\n        sess.run(init)\r\n        # Training cycle\r\n        for epoch in range(training_epochs):\r\n            avg_loss = 0.\r\n            total_batch = int(mnist.train.num_examples/batch_size)\r\n            # Loop over all batches\r\n            for i in range(total_batch):\r\n                batch_x, batch_y = mnist.train.next_batch(batch_size)\r\n                # Run optimization op (backprop) and cost op (to get loss value)\r\n                accuracy_total, predictions,_, l = sess.run([accuracy,pred, optimizer, loss], \r\n                                                            feed_dict={x: batch_x,\r\n                                                              y: batch_y})\r\n                # Compute average loss\r\n                avg_loss += l / total_batch\r\n            # Display logs per epoch step\r\n            if epoch % display_step == 0:\r\n                print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\",                     \"{:.9f}\".format(avg_loss))\r\n        print(\"Optimization Finished!\")\r\n        print(\"Accuracy : \", accuracy_total)\r\n        for i in range(num_batches):\r\n            batch_x, batch_y = mnist.test.next_batch(batch_size)\r\n            start_time = time.time()\r\n            val_acc = accuracy.eval({x: batch_x , y: batch_y})\r\n            print(\"Evaluation time batch {} : {}\".format(i+1, time.time()-start_time))\r\n            print(\"Validation Acc : {}\".format(val_acc))\r\n\r\n```", "I've pasted the indented code. This should work.", "@azaks2 do you know off the top of your head what could cause this?", "@azaks2 replied offline:\r\n\r\n1. A profile would be nice\r\n2. We do not generally encourage inference via python, so python gc comes to mind\r\n3 We overlap with the computation of next_batch", "\r\nReg:2. We do not generally encourage inference via python, so python gc comes to mind\r\nVinothInspirit: **What then would be the tf prescribed way of running(and measuring) inferences?**\r\nReg:3. We overlap with the computation of next_batch\r\nVinothInspirit: **We give the inputs here using feed_dict, not by a pipeline, so I'm not sure if sess.run(...) would still overlap with next_batch.**", "1. For inference take a look at [https://www.tensorflow.org/tfx/guide/serving](url)\r\nOne important part is that the process will turn variables into constants.\r\n2. According to the timeline (comparing slow and fast sess.run) it seems most of the diff comes from the MatMul op. I am not 100% sure but using taskset to run the script (taskset 0x1 python ...) improved the variance for my runs.\r\n\r\nslow inference\r\n![image](https://user-images.githubusercontent.com/53194144/61839822-e33d5480-ae43-11e9-90c0-bf267c7e3edd.png)\r\n\r\nfast inference\r\n\r\n![image](https://user-images.githubusercontent.com/53194144/61839867-0cf67b80-ae44-11e9-9a12-29b6e60bf929.png)\r\n\r\nto get timeline\r\nval_acc = sess.run([accuracy],\r\n                               feed_dict={x: batch_x , y: batch_y},\r\n                               options=tf.RunOptions(trace_level=tf.RunOptions.SOFTWARE_TRACE),                                                                                                                                                                                                                                                              \r\n                               run_metadata=run_metadata)  \r\n...\r\ntl = timeline.Timeline(run_metadata.step_stats)                                                                                                                                                                                                                                                                                                  \r\nctf = tl.generate_chrome_trace_format()                                                                                                                                                                                                                                                                                                          \r\nwith open(str(i)+'timeline.json', 'w') as f:                                                                                                                                                                                                                                                                                                     \r\n    f.write(ctf) \r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30702\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30702\">No</a>\n"]}, {"number": 30701, "title": "build tensorflow failed with bazel on windows", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win7 X64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:2.0\r\n- Python version:3.7\r\n- Installed using virtualenv? pip? conda?:conda\r\n- Bazel version (if compiling from source):0.25.1\r\n- GCC/Compiler version (if compiling from source):no\r\n- CUDA/cuDNN version:no\r\n- GPU model and memory:no\r\n\r\n\r\n\r\n**Describe the problem**\r\nI try to build C++ lib and dll file with Bazel, as the following steps:\r\n1. run \"python configure.py\", and set up options.\r\n2.run \"bazel build --config=opt //tensorflow/tools/lib_package:libtensorflow\"\r\nIt throw errors:\r\n```\r\n\"Loading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nINFO: An error occurred during the fetch of repository 'io_bazel_rules_docker'\r\nINFO: Call stack for the definition of repository 'io_bazel_rules_docker':\r\n - C:/users/administrator/_bazel_administrator/zfk46uyn/external/bazel_toolchain\r\ns/repositories/repositories.bzl:37:9\r\n - D:/tensorflow/tensorflow/WORKSPACE:29:1\r\nERROR: error loading package '': Encountered error while reading extension file\r\n'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//reposi\r\ntories': Traceback (most recent call last):\r\n        File \"C:/users/administrator/_bazel_administrator/zfk46uyn/external/baze\r\nl_tools/tools/build_defs/repo/git.bzl\", line 234\r\n                _clone_or_update(ctx)\r\n        File \"C:/users/administrator/_bazel_administrator/zfk46uyn/external/baze\r\nl_tools/tools/build_defs/repo/git.bzl\", line 74, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning io_bazel_rules_docker:\r\n+ cd C:/users/administrator/_bazel_administrator/zfk46uyn/external\r\n+ rm -rf C:/users/administrator/_bazel_administrator/zfk46uyn/external/io_bazel_\r\nrules_docker C:/users/administrator/_bazel_administrator/zfk46uyn/external/io_ba\r\nzel_rules_docker\"\r\n```\r\n\r\nThanks for the help!\r\n", "comments": ["Just to verify did you get chance to follow instructions from [TensorFlow](https://www.tensorflow.org/install/source_windows) website .Please, let us know. Thanks!", "I have seen similar issues these days if I did not have `msys` installed or the environment variable `BAZEL_SH` not set up correctly. Did you install bazel as described here and completed all the steps? https://docs.bazel.build/versions/master/install-windows.html", "```\r\nINFO: An error occurred during the fetch of repository 'gif_archive'\r\nINFO: An error occurred during the fetch of repository 'lmdb'\r\nINFO: An error occurred during the fetch of repository 'grpc'\r\nINFO: An error occurred during the fetch of repository 'snappy'\r\nINFO: An error occurred during the fetch of repository 'zlib_archive'\r\nINFO: An error occurred during the fetch of repository 'curl'\r\n```\r\nThese errors point to issues downloading dependencies. Do you happen to be behind a firewall?"]}, {"number": 30700, "title": "training become too slow", "body": "I`m working on:\r\nWindows 10,\r\n64 bit,\r\nAnaconda3 version 5.3.0 \r\npython 3.6.8,\r\ntensorflow version 1.10.0\r\n\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 30699, "title": "Performance slowdown in Non-AVX targets with default build options", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No custom code written. \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not mobile. Slowdown seen on both windows PC and NI Linux Real Time OS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.14-RC0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): 4.7\r\n- CUDA/cuDNN version: NA. Not building with CUDA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n\r\nThe performance of TF 1.14-RC0 is more than 3 time slower compared to TF 1.8 binaries. We are using a standard SSD mobile net model for loading and running. \r\n\r\nWe used same build options for TF 1.8 and TF 1.14-RC0. So I believe there is some change in default build options that is affecting the performance on Non-AVX targets. (Please refer 'Steps Followed' for build options used) \r\n\r\n**Steps Followed**\r\n\r\nWe are building with all default settings except with following changes: \r\n- we set 'march' optimization flag empty. we do not want to optimize for native system. (In 1.8, we did not set 'march' optimization flag)\r\n- we say NO to XLA JIT support.\r\n\r\nWe tried following command to build :\r\n\r\n1) bazel build --config=opt //tensorflow:tensorflow\r\n2) bazel build --config=opt --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka --config=nonccl //tensorflow:tensorflow\r\n\r\n\r\n", "comments": ["In case someone else runs into this issue, I have found a way to correct the slowdowns introduced with 1.14. MKL-DNN was turned on by default in 1.14 which was causing slowdowns in non-AVX machines. Disabling it corrected the slowdowns for me. \r\n\r\n\"Turn on MKL-DNN contraction kernels by default. MKL-DNN dynamically dispatches the best kernel implementation based on CPU vector architecture. To disable them, build with --define=tensorflow_mkldnn_contraction_kernel=0.\""]}, {"number": 30698, "title": "[LITE]concat_embeddings to concatenate_embeddings, todo change updated", "body": "A TODO updated, Rename CONCAT_EMBEDDINGS to CONCATENATE_EMBEDDINGS\r\n\r\n`  // TODO(aselle): Consider rename to CONCATENATE_EMBEDDINGS\t\r\n`\r\n", "comments": ["Can one of the admins verify this patch?", "@siju-samuel Could you please resolve the conflicts? Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}]