[{"number": 1780, "title": "refactor learning rate related code for the optimizers", "body": "This is one step forward to solve #313. It's overshot to use multiple optimizers just for different learning rate.\n\nControl the learning rate on the root class of the optimizers.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "I'm conflicted -- the optimizer interface is too narrow as it is, and learning rate is not necessarily universal (although arguably it is for the optimizers we actually support). @rmlarsen, an opinion?\n", "We might want  to implement other optimizers where the concept of \"learning rate\" does not make sense (such as second order methods), so I find moving it to the base class is not the right design.\n", "Gotta.\n"]}, {"number": 1779, "title": "Request: dynamic RNN in bidirectional_rnn()", "body": "The bidirectional_rnn() is not taking the advantages of dynamic_rnn(), it runs into memory issues for even moderate length of time steps. I guess this should be really easy to implement, but a really big help for people using the bidirectional version.\n\nThanks!\n\nJiajie  \n", "comments": ["I see why this is not implemented yet, reverse the inputs is nasty with current code .... \n", "It seems that `tf.reverse_sequence` now works with partly unknown shape.\nIs anybody working on this?\n", "@ebrevdo: Should I leave this one assigned to you? \n", "Sure, I'll review the PR.\n", "This has been submitted.\n"]}, {"number": 1778, "title": "error during buile tensorflow_demo", "body": "I installed tensorflow from sources. convolution.py works well\nbut when I try to build android demo apk, I got the build error\nIt is looking for libz.so.1. which package include it?\n### Environment info\n\nOperating System: 14.04.1-Ubuntu\n\nI installed from sources\n### Steps to reproduce\n1. in WORKSPACE\n   android_sdk_repository(\n   name = \"androidsdk\",\n   api_level = 21,\n   build_tools_version = \"21.0.1\",\n   path = \"../../Android/android-sdk-linux/\",\n   )\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path = \"../../Android/android-ndk-r10e/\",\n    api_level=21)\n\n2.bazel build //tensorflow/examples/android:tensorflow_demo\n\n3.error message is like this\nException in thread \"main\" Error: Failed to run command:\n        bazel-out/host/bin/external/androidsdk/aapt_binary s -i /tmp/android_resources_tmp451471447479393920/tmp-deduplicated/tensorflow/examples/android/res/drawable-hdpi/ic_action_info.png -o /tmp/android_resources_tmp451471447479393920/merged_resources/drawable-hdpi-v4/ic_action_info.png\nError Code:\n        127\nOutput:\n        bazel-out/host/bin/external/androidsdk/aapt_binary.runfiles/external/androidsdk/build-tools/21.0.1/aapt: error while loading shared libraries: libz.so.1: cannot open shared object file: No such file or directory\n### What have you tried?\n\n1.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["same error with SDK 23.0.1\n", "Are you running a 32 or 64 bit OS?\n\nHere are some suggestions for a user who experienced a similar error: http://stackoverflow.com/questions/17020298/android-sdks-build-tools-17-0-0-aapt-error-while-loading-shared-libraries-libz\n", "Closing due to inactivity. Please reopen if issue persists.\n"]}, {"number": 1777, "title": "Add footnote about dropout in MNIST tutorial for expert", "body": "Add footnote about dropout in MNIST tutorial for expert, this is to replace #1710 \n@Sohl-Dickstein ,please check this, thanks\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please.\n", "Nice, looks good!\n", "Thanks for the catch and the fix @fayeshine!\n"]}, {"number": 1776, "title": "Fix Typo in TF Mechanics 101 Tutorial", "body": "In the section of Inputs and Placeholders, the IMAGE_PIXELS should be mnist.IMAGE_PIXELS\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1775, "title": "Remove `as` for `import` in tests", "body": "They are redundant here.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1774, "title": "Bazel build fails /usr/lib/tensorflow/tensorflow/cc/BUILD:28:1", "body": "Ubuntu 15.10\ncuda v 7.5\npython v 2.7\njdk8\ngcc 4.9\n980Ti\n\nInstalling from source: \nb0774e1b473494dc4e2434ae20295a9fdf433867\n\nERROR: /usr/lib/tensorflow/tensorflow/cc/BUILD:28:1: Linking of rule '//tensorflow/cc:ops/state_ops_gen_cc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command\n  (cd /root/.cache/bazel/_bazel_root/e14db5a97cb9042cd7bbcf71326995ef/tensorflow && \\\n  exec env - \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/cc/ops/state_ops_gen_cc '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64' -Lbazel-out/host/bin/_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64 bazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a -Wl,-whole-archive bazel-out/host/bin/tensorflow/core/libstate_ops_op_lib.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/host/bin/tensorflow/core/libframework_internal.lo -Wl,-no-whole-archive bazel-out/host/bin/tensorflow/core/liblib_internal.a bazel-out/host/bin/external/jpeg_archive/libjpeg.a bazel-out/host/bin/external/png_archive/libpng.a bazel-out/host/bin/external/re2/libre2.a bazel-out/host/bin/tensorflow/core/libprotos_all_cc.a bazel-out/host/bin/google/protobuf/libprotobuf.a bazel-out/host/bin/google/protobuf/libprotobuf_lite.a -lcudart -lm -ldl -lm -ldl -lz -pthread -lpthread -Wl,-rpath,third_party/gpus/cuda/lib64 -lstdc++ -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nbazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a(cc_op_gen.o): In function `std::string* tensorflow::internal::Check_EQImpl<tensorflow::Status, tensorflow::Status>(tensorflow::Status const&, tensorflow::Status const&, char const*)':\ncc_op_gen.cc:(.text._ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc[_ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc]+0x2d): undefined reference to`tensorflow::Status::ToString() const'\ncc_op_gen.cc:(.text._ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc[_ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc]+0x38): undefined reference to `tensorflow::Status::ToString() const'\nbazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a(cc_op_gen.o): In function`tensorflow::(anonymous namespace)::WriteCCOp(tensorflow::OpDef const&, tensorflow::WritableFile_, tensorflow::WritableFile_)':\ncc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0x8b9): undefined reference to `tensorflow::Status::ToString() const'\ncc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0x8d2): undefined reference to`tensorflow::Status::ToString() const'\ncc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0xc15): undefined reference to `tensorflow::Status::ToString() const'\nbazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a(cc_op_gen.o):cc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0xc2e): more undefined references to`tensorflow::Status::ToString() const' follow\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(attr_value_util.o): In function `tensorflow::(anonymous namespace)::SummarizeTensor(tensorflow::TensorProto const&)':\nattr_value_util.cc:(.text._ZN10tensorflow12_GLOBAL__N_115SummarizeTensorERKNS_11TensorProtoE+0x65): undefined reference to`google::protobuf::Message::ShortDebugString() const'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(attr_value_util.o): In function `tensorflow::ParseAttrValue(tensorflow::StringPiece, tensorflow::StringPiece, tensorflow::AttrValue*)':\nattr_value_util.cc:(.text._ZN10tensorflow14ParseAttrValueENS_11StringPieceES0_PNS_9AttrValueE+0x207): undefined reference to`google::protobuf::TextFormat::ParseFromString(std::string const&, google::protobuf::Message_)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(attr_value_util.o): In function `tensorflow::SummarizeAttrValue(tensorflow::AttrValue const&)':\nattr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0x3f4): undefined reference to`google::protobuf::internal::empty_string_'\nattr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0x4d8): undefined reference to `google::protobuf::internal::NameOfEnum(google::protobuf::EnumDescriptor const_, int)'\nattr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0x54c): undefined reference to `google::protobuf::internal::empty_string_'\nattr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0xda9): undefined reference to `google::protobuf::internal::NameOfEnum(google::protobuf::EnumDescriptor const*, int)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o): In function`tensorflow::OpRegistry::Register(tensorflow::OpDef const&)':\nop.cc:(.text._ZN10tensorflow10OpRegistry8RegisterERKNS_5OpDefE+0x91): undefined reference to `tensorflow::Status::ToString() const'\nop.cc:(.text._ZN10tensorflow10OpRegistry8RegisterERKNS_5OpDefE+0xaa): undefined reference to`tensorflow::Status::ToString() const'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o): In function `tensorflow::OpRegistry::CallDeferred() const [clone .part.129]':\nop.cc:(.text._ZNK10tensorflow10OpRegistry12CallDeferredEv.part.129+0x159): undefined reference to`tensorflow::Status::ToString() const'\nop.cc:(.text._ZNK10tensorflow10OpRegistry12CallDeferredEv.part.129+0x168): undefined reference to `tensorflow::Status::ToString() const'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o): In function`tensorflow::OpRegistry::LookUp(std::string const&, tensorflow::Status*) const':\nop.cc:(.text._ZNK10tensorflow10OpRegistry6LookUpERKSsPNS_6StatusE+0x110): undefined reference to `tensorflow::Status::ToString() const'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o):op.cc:(.text._ZNK10tensorflow10OpRegistry6LookUpERKSsPNS_6StatusE+0x129): more undefined references to`tensorflow::Status::ToString() const' follow\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o): In function `tensorflow::OpDefBuilder::OpDefBuilder(tensorflow::StringPiece)':\nop_def_builder.cc:(.text._ZN10tensorflow12OpDefBuilderC2ENS_11StringPieceE+0xd4): undefined reference to`google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o): In function `tensorflow::(anonymous namespace)::FinalizeAttr(tensorflow::StringPiece, tensorflow::OpDef*, std::vector<std::string, std::allocator<std::string> >*)':\nop_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_112FinalizeAttrENS_11StringPieceEPNS_5OpDefEPSt6vectorISsSaISsEE+0x32d): undefined reference to`google::protobuf::internal::empty_string_'\nop_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_112FinalizeAttrENS_11StringPieceEPNS_5OpDefEPSt6vectorISsSaISsEE+0x5ff): undefined reference to `google::protobuf::internal::empty_string_'\nop_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_112FinalizeAttrENS_11StringPieceEPNS_5OpDefEPSt6vectorISsSaISsEE+0xc06): undefined reference to `google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o): In function `tensorflow::(anonymous namespace)::FinalizeInputOrOutput(tensorflow::StringPiece, bool, tensorflow::OpDef*, std::vector<std::string, std::allocator<std::string> >*)':\nop_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_121FinalizeInputOrOutputENS_11StringPieceEbPNS_5OpDefEPSt6vectorISsSaISsEE+0x36a): undefined reference to`google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o):op_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_121FinalizeInputOrOutputENS_11StringPieceEbPNS_5OpDefEPSt6vectorISsSaISsEE+0xaee): more undefined references to `google::protobuf::internal::empty_string_' follow\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `void tensorflow::errors::AppendToMessage<char const*, std::string, char const*, std::string, char const*>(tensorflow::Status*, char const*, std::string, char const*, std::string, char const*)':\nop_def_util.cc:(.text._ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_SsS3_EEEvPNS_6StatusEDpT_[_ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_SsS3_EEEvPNS_6StatusEDpT_]+0x208): undefined reference to`tensorflow::Status::empty_string()'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `void tensorflow::errors::AppendToMessage<char const*, std::string, char const*>(tensorflow::Status*, char const*, std::string, char const*)':\nop_def_util.cc:(.text._ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_EEEvPNS_6StatusEDpT_[_ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_EEEvPNS_6StatusEDpT_]+0x201): undefined reference to`tensorflow::Status::empty_string()'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `tensorflow::ValidateAttrValue(tensorflow::AttrValue const&, tensorflow::OpDef_AttrDef const&)':\nop_def_util.cc:(.text._ZN10tensorflow17ValidateAttrValueERKNS_9AttrValueERKNS_13OpDef_AttrDefE+0x472): undefined reference to`google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `tensorflow::ValidateArg(tensorflow::OpDef_ArgDef const&, tensorflow::OpDef const&, bool, std::set<std::string, std::less<std::string>, std::allocator<std::string> >*)':\nop_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x15e): undefined reference to`google::protobuf::Message::ShortDebugString() const'\nop_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x1c9): undefined reference to `google::protobuf::Message::ShortDebugString() const'\nop_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x247): undefined reference to`google::protobuf::Message::ShortDebugString() const'\nop_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x285): undefined reference to `google::protobuf::Message::ShortDebugString() const'\nop_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x393): undefined reference to`google::protobuf::Message::ShortDebugString() const'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o):op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x539): more undefined references to `google::protobuf::Message::ShortDebugString() const' follow\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(tensor.o): In function`tensorflow::(anonymous namespace)::BufferBase::FillAllocationDescription(tensorflow::AllocationDescription*) const':\ntensor.cc:(.text._ZNK10tensorflow12_GLOBAL__N_110BufferBase25FillAllocationDescriptionEPNS_21AllocationDescriptionE+0x40): undefined reference to `google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::OutputToLog(google::protobuf::Message const&)':\nlog_memory.cc:(.text._ZN10tensorflow9LogMemory11OutputToLogERKN6google8protobuf7MessageE+0x52): undefined reference to`google::protobuf::TextFormat::Printer::PrintToString(google::protobuf::Message const&, std::string*) const'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::RecordTensorAllocation(std::string const&, long long, tensorflow::Tensor const&)':\nlog_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x27): undefined reference to`google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::RecordTensorDeallocation(long long, std::string const&)':\nlog_memory.cc:(.text._ZN10tensorflow9LogMemory24RecordTensorDeallocationExRKSs+0x22): undefined reference to`google::protobuf::internal::empty_string_'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_kernel.o): In function `tensorflow::ValidateKernelRegistrations(tensorflow::OpRegistryInterface const&)':\nop_kernel.cc:(.text._ZN10tensorflow27ValidateKernelRegistrationsERKNS_19OpRegistryInterfaceE+0x2b7): undefined reference to`google::protobuf::Message::ShortDebugString() const'\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n", "comments": ["Is protobuf installed already, and which version? \n", "No reply in a month. Close?\n", "Yup, closing due to inactivity,  re-open if more information is available.\n", "sorry i know longer am using the machine this came up on so I can't give more info\n"]}, {"number": 1773, "title": "Upstream changes for April 4th", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 1772, "title": "tensorflow extremely slow on GPU", "body": "MNIST example and CIFAR10 example run very slow on GPU, much slower than posted benchmarks for my specs (2 titan X).  GPU utilization very low when running these models.  Loading 20k images for CIFAR10 takes more than 10 mins\n### Environment info\n\nOperating System: Ubuntu 15.04, CUDA 7.5, cuDNN 3, gcc 4.9, numpy 1.7\n1. Which pip package you installed.\n   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   tensorflow 0.6\n### What have you tried?\n1. reinstalling from source using bazel but problem persists\n### Logs or other output that would be helpful\n\nimage/cifar10$ python cifar10_train.py\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nDownloading cifar-10-binary.tar.gz 100.0%\nSuccessfully downloaded cifar-10-binary.tar.gz 170052171 bytes.\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2405\npciBusID 0000:09:00.0\nTotal memory: 12.00GiB\nFree memory: 11.21GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2155\npciBusID 0000:06:00.0\nTotal memory: 12.00GiB\nFree memory: 11.10GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.54GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb0d900000 extends to 0xdb057b99a\n2016-04-04 11:00:46.190354: step 0, loss = 4.68 (0.1 examples/sec; 870.357 sec/batch)\n2016-04-04 11:01:41.540616: step 10, loss = 4.66 (31.8 examples/sec; 4.029 sec/batch)\n\npython convolutional.py\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2405\npciBusID 0000:09:00.0\nTotal memory: 12.00GiB\nFree memory: 11.23GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2155\npciBusID 0000:06:00.0\nTotal memory: 12.00GiB\nFree memory: 11.12GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.56GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb0d900000 extends to 0xdb1a08b34\nInitialized!\nStep 0 (epoch 0.00), 10.2 ms\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\nStep 100 (epoch 0.12), 417.7 ms\nMinibatch loss: 3.282, learning rate: 0.010000\nMinibatch error: 6.2%\nValidation error: 7.0%\nStep 200 (epoch 0.23), 392.7 ms\nMinibatch loss: 3.482, learning rate: 0.010000\nMinibatch error: 14.1%\nValidation error: 3.6%\n", "comments": ["You seem to still have 0.6 installed somewhere (output of tensorflow.version), can you make sure you have 0.7.1?\n", "I reinstalled 0.7.1 and the lib in the site-packages folder of my venv looks right.  The output of tensorflow.version is 0.7.1.  Still having the same runtime profiles.  Thanks for you response.\n", "It is possible that TensorFlow is choosing a bad placement of operators across your two GPUs, and slowing things down by copying data between the GPUs. Would you try restricting to a single GPU:\n\n```\nconfig = tf.ConfigProto(device_count={'GPU': 1})\nwith tf.Session(config=config) ...\n```\n\nand see if things get faster?\n", "I tried that and still seeing the same behavior.  \n", "FYI 0.7.1 requires cudnn r4, not v3, so I'm not sure how your system is working at all.\n", "ok, let me update to cudnn r4\n", "Still seeing the same issue after updating to cudnn 4.  \n\nI turned on log device placement and saw a bunch of tasks getting placed on cpu, is this normal?\n\n[cifar10_log.txt](https://github.com/tensorflow/tensorflow/files/212198/cifar10_log.txt)\n", "I was just running into a similar issue running CUDA 7.5 with CuDNN 5.0 along with the newest drivers from Nvidia (Also Titan X, CentOS 7).  I uninstalled all of that, installed CUDA 7.0 and let it install the prepackaged driver included, and CuDNN 2.0 and it fixed the issue for me.\n\nEdit: CuDNN v2.0\n", "I am experiencing a similar issue. GPU very slow but completely utilized (more so than with a working version). Running Ubuntu 14.04, tensorflow 0.8.0rc0 (installed via pip) with CUDA 7.5 and cuDNN 4 on a Titan X. I had the exact same issue with tf 0.7.1 and downgrading to CUDA 7.0 resolved the problem. I also realized the GPU is going into some kind of throttled state: nvidia-smi -q reports \"HW Slowdown: active\" and performance state P2. I tried increasing maximum power limit via nvidia-smi to no avail. I also tried many different driver versions, the problem stayed the same (although some versions report a reason of Clocks Throttle Reason \"Unknown: active\"). \n", "@elmar-haussmann I also saw the HW Slowdown message when running CUDA 7.5 and cuDNN 5.  I'm running in P2 even after resolving the slowdown issue.\n", "@kmitchner : right, same for me, \"P2\" seems to be normal, and I apparently didn't pay attention to it beforehand. \n\nIt seems the problem has to do with cuDNN. At least I now have a version running tf 0.8, CUDA 7.5 and cuDNN 2.0 (not sure if that's even supported, but at least it's working again). It's really very strange since that can't be a rare configuration (Linux, TITAN X, CUDA 7.5, cuDNN 4) so either I must have done something wrong or there is a subtle compatibility issue/bug with any of the involved software (NVIDIA driver, cuDNN, CUDA, tensorflow).\n", "Is use of CUDA 7.0 (rather than 7.5) the recommended interim solution to this issue?\n", "@yazabaza : it seems cuDNN 2.0 solved the problem for both @kmitchner and me. I am running CUDA 7.5 and he is running CUDA 7.0. Let us know what solves the problem for you.\n\nI don't think there will be a recommended interim solution as long as the underlying problem hasn't been identified.\n", "Unfortunately, I don't think we have enough information to diagnose this issue, so I'm going to close.  Please comment if better information appears, or file a separate issue.\n"]}, {"number": 1771, "title": "Go API", "body": "Hello,\nDuring the last weeks I have been working on this implementation of the Go API. **This is still a work in progress**, I'm doing this PR just to show what I'm working on and to get feedback.\n\nI forked from https://github.com/tmc/tensorflow/tree/go_bindings where the bindings was implemented by Travis Cline. This Go library allows to interact with the tensors in an easy way from Go being able to create, populate and retrieve the content from the tensors. This library also provides the API for Graph generation from Go, create sessions, run this graphs and so on. The goal is to achieve the same functionality provided by the C++ API.\n\nIn order to show how the API works, I updated the label_image example with an implementation using the [Go API](https://github.com/alonsovidales/tensorflow/tree/go_bindings_tensors/tensorflow/examples/label_image_go) and I also updated the [tutorial](https://github.com/alonsovidales/tensorflow/blob/go_bindings_tensors/tensorflow/g3doc/tutorials/image_recognition/index.md#usage-with-the-go-api)\n\nI'm trying to keep all the code covered with tests, I still have to cover some corner cases and functionality like the data type recognition for the graph, etc.\nBy the moment the supported Tensor data types are:\n- TF_FLOAT\n- TF_DOUBLE\n- TF_INT32\n- TF_UINT8\n- TF_UINT32\n- TF_INT16\n- TF_INT8\n- TF_STRING\n- TF_INT64\n- TF_BOOL\n  I'm planing to add support for TF_QINT\\* TF_BFLOAT16 and TF_COMPLEX soon.\n\nI have some doubts:\n- Would it be better to add the API docu as md in tensorflow/g3doc/ , or just with GoDoc it would be enough? Having the docu on the MarkDown files could be better for the people without too much experience on Go, but having the docu on GoDocs is going to be updated in an easiest way and the Go developers are more used to read the documentation on GoDoc format. We can also keep it in both places, or just add a link from the MarkDown docu to GoDoc.\n- In order to get the definition for all the available operations I'm loading this info from tensorflow/core/ops/ops.pbtxt . The problem is that I'm doing this [cp of the file from go gen](https://github.com/alonsovidales/tensorflow/blob/go_bindings_tensors/tensorflow/go/gen.go#L3). I think that this problem could be approached on three different ways:\n  - 1. Converting ops.pbtxt into a .go file: converting the content into a constant string we don't need to move this file, this option will remove this dependency, but if the file changes it will requiere to regenerate the libs that shouldn't be too much problem, we could even generate Go code for each operation so we don't need to parse the file and it would improve the performance.\n  - 2. Using something like the TF_GetOpList function used by Python in order to retrieve this info from the C++ API. This would add more dependencies from the Go to the C++ API, that is not a mayor issue but will requiere to prepare a new method or modify the original since TF_GetOpList depends on the Python libs.\n  - 3. As I'm doing right now, just copying the file. At least for a first iteration this could be a good option since it makes more easy to work with the code.\n- Regarding to the installation, I'm not sure if keep using \\\"go generate\\\" or Bazel, Go generate is more or less the standar for Go projects, but Bazel is what TensorFlow is using. I think that I'm going to change to Bazel so I can avoid things like [bazel from Go](https://github.com/alonsovidales/tensorflow/blob/go_bindings_tensors/tensorflow/go/gen.go#L1) but I'm not sure if this is the best approach.\n\nI would be really grateful if you could please take a look at the code and let me know your thoughts, what I'm missing, how can I improve it, etc.\n\nThanks!\n\nRelated ticket: #10 \n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "@tmc are you ok with this PR?\n", "@tmc, @dave-andersen, please take a look. \n\nI think high level documentation should live in contrib/go/g3doc, we're working on glue to integrate such docs into the website.\n\nWe can look into generating markdown from godoc, maybe? I don't know the first thing about go, or godoc, so stop me if this is stupid. Our publishing to website pipeline goes via md, so that would be easiest, probably, assuming we want to have documentation for the go part on tensorflow.org.\n", "Hi @martinwicke , I'll prepare the docu generation using godocdown, I've never used this project before but it seems to be easy to define a template to keep a similar to the one you are using, so the generation can be automatised in an easy way :)\nI'll work on that today after work and also on the Variables generation.\n", "I'd like to get @tmc approval first before we go too far.\n", "ok, I've sent an e-mail to @tmc yesterday, perhaps he is not getting the GitHub notifications.\n", "Can one of the admins verify this patch?\n", "I added a template to generate automatically the documentation as MarkDown using godoc. The files inside contrib/go/g3doc are being generated from the comments on the source code using 'go generate'.\n\nI also added the example_test.go with some usage examples for the most important methods.\nThe index.md is the only one that is not being automatically generated since it also contains more complex examples, installation and so on, this is: [README.md](https://github.com/alonsovidales/tensorflow/blob/go_bindings_tensors/tensorflow/contrib/go/README.md)\n", "@tmc can you chime in and OK this?\n", "Because @tmc has signed the CLA, I approve this import of his patch with modification.  Could you go ahead and sign the CLA also, Alonso?\n\nI'm fine leaving the docs in godoc format (confirmed with @martinwicke ) or as .md, since this will be in contrib/ for the time being.\n\nReviewing now.\n", "Hi @dave-andersen I already singed the CLA. The docs are now in MarkDown and godoc, I added a template [here](https://github.com/alonsovidales/tensorflow/tree/go_bindings_tensors/tensorflow/contrib/go/godoc_tmpl) to generate the documentation from the source code comments in MarkDown, the result is [here](https://github.com/alonsovidales/tensorflow/tree/go_bindings_tensors/tensorflow/contrib/go/g3doc). Run `go generate` creates this MarkDown.\n", "Cool re CLA.  @googlebot signed.  (let's see if that works to get the status updated. :)\n", "A quick global pass through comments to make sure they're all terminated with a period would be good in  example_test.go.  It's a bit inconsistent.\n", "I think that the problem with the CLA comes from the @tmc commits, I've sent time ago the 'I signed it!'. The @tmc commits have 'Error CLAs are signed, but unable to verify author consent'\n", "@martinwicke - can you bring your expertise to bear on this CLA problem? :)\n", "Thanks @dave-andersen for the code review! :)\nI've modified the code according to the comments.\n\nI'm currently working on allocating the content of the '/usr/local/tensorlow/ops.pbtxt' file inside the Go code. I think that with this modification this could be more or less ready for this first iteration. If I have time this week I'll try to add the code to save & restore Variables from disk like tf.train.Saver does.\n", "Want to pop in and say this looks very exciting.  Thanks for working on it!\n", "Sorry about going AWOL on this, I've been very busy. Really happy to see the progress here. I'm reviewing now (and fixed up my google CLA settings).\n", "@alonsovidales I've done an initial pass and have some style nits, looks like @dave-andersen is on the case too. This is looking great but let's be very careful with the api we expose.\n", "Done with comments - thanks for putting up with the flood of them combined with the fairly painful github comment mechanism. :)\n", "(btw, I agree with tmc about being careful with the API.  From the TensorFlow team perspective, this is in \"contrib\", so we're allowed to change it at will, but if people start using it seriously, it'll become implicitly harder to change.  Once the nits are addressed I'll take a final peek from a bigger picture API perspective and then we should be good to go.\n\nI'm more concerned _for now_ about the serving API, because I think that's the most obviously clear match for Go+TF, but your image recognition example shows a very nice reason for having some graph construction integrated with the Go code as well -- though that could also be baked into the Inception graph.)\n", "Wow, what a code review! :) Thanks a lot @dave-andersen , @tmc ! This is maybe one of the best code reviews I had in the last years \uff61^\u203f^\uff61\nI'm going to sleep, that in Netherlands is a bit late. I went through almost all the comments but I still have to finish:\n- Add: NewGraphFromReader\n- Use a template for the getTensorFromGraph input string in order to avoid this redundancy\n- C++ Code review\n- Apply fixes to: tensorflow/g3doc/tutorials/image_recognition/index.md\n\nAnd I want to go through all the code once again to be sure that I'm not forgetting anything, I hope I can have all ready for next week :)\n", "I have been working during this weekend on fixing the code based on the feedback from the code reviews.\nThis is the changelog of what has been modified:\n- Fixed typos, test messages, etc.\n- Replaced t.Error + t.FailNow by t.Fatal\n- Replaced most of the naked returns\n- Removed some duplicated code from the test suite removing redundant tests and adding some templates.\n- Modified AsBool, AsFloat32, \u2026 by Bool, Float32, \u2026\n- Replaced NewGraphFromText and LoadGraphFromFile by NewGraphFromReader\n- Replaced the DataType Dt\\* by DT*\n- Added auto-generation of the probobuf files as also the ops definition file\n- Replaced example image by:  tensorflow/./examples/label_image/data/grace_hopper.jpg and removed the Ceres image from the repo\n- TensorInt -> TensorInterface\n\nPending questions:\n- Should we use the DT\\* as prefix for DataTypes?\n- Should we remove the TensorInterface, or add interfaces for Session, Graph, etc? I think that is better to add the interfaces to make more easy the definition of Mocks for testing proposals.\n- Why the dimensions of a Tensor are represented as a matrix instead of using a vector?\n- Should we add GetValInt32, GetValFloat64, etc as helpers for the current GetVal method?\n- Sould we add/remove some methods to the API?, I think that for a first iteration is enugh, it could be nice to have other stuff implemented like the [tf.train.Saver](https://www.tensorflow.org/versions/r0.8/api_docs/python/state_ops.html#Saver) but this could be added in a future.\n\nI think that could be a good idea if we send an e-mail to some groups like golang-nuts@googlegroups.com or discuss@tensorflow.org to try to get more feedback, what do you think?\n\n@dave-andersen @vrv @tmc\n", "There are still a number of named returns that IMO need justification.\n", "@tmc I just replaced the remaining naked returns :)\nI'm only leaving this two:\n- https://github.com/tensorflow/tensorflow/pull/1771/files#diff-6ecada9bdae40f6b8d2258c71de75c99R653\n- https://github.com/tensorflow/tensorflow/pull/1771/files#diff-6ecada9bdae40f6b8d2258c71de75c99R661\n\nFor this two particular cases is obvious that the idea is to return just the error and there are multiple params to be returned.\n", "I'm not convinced these named result parameters are helpful:\n\n``` go\n    func NewGraphFromReader(reader io.Reader, asText bool) (gr *Graph, err error)\n    func (gr *Graph) Constant(name string, data interface{}) (op *GraphNode, err error)\n    func (gr *Graph) Op(opName string, name string, input []*GraphNode, device string, attrs map[string]interface{}) (node *GraphNode, err error)\n```\n\nvs\n\n``` go\n    func NewGraphFromReader(reader io.Reader, asText bool) (*Graph, error)\n    func (gr *Graph) Constant(name string, data interface{}) (*GraphNode, error)\n    func (gr *Graph) Op(opName string, name string, input []*GraphNode, device string, attrs map[string]interface{}) (*GraphNode, error)\n```\n", "Re questions about adding more to the API:  I'd strongly suggest against it.  There's a lot in here already, and I think it would be useful to get it in to contrib/ and let people play around with it to get experience with what's really wanted.  If everyone starts screaming that they need saver, it's easy to add later - but harder to remove if we add it now.\n", "(btw, thanks and congrats for fixing all of those things so quickly.  I'm taking another look now.)\n", "Sorry for the last minute comments. The PR can benefit from some other styling hints but it is so massive that it is hard to review. I see that we gradually can improve even if there are issues left open on the initial commit.\n", "@rakyll Thanks a lot for the review I'm working on your feedback right now, you spotted some important issues that I didn't see before. Thanks (\u2022\u203f\u2022)\n", "The last modifications applied are:\n- Modified 'd by 'i' on GetVal\n- Exported properties on errors\n- Fixed comment sentences on type Error\\* struct { \u2026 }\n- Replaced Str by ByteSlices on Tensor\n- Added \u2019s\u2019 at the end of the Tensor methods to retrieve the data like Int64 -> Int64s, Float64 -> Float64s, ...\n- Removed TensorInterface\n\nPending questions:\n- Should we maintain the asText parameter on the NewGraphFromReader function, or split this function in two?\n\nI'll also try to do the \u201cgo get\u201d, and if that doesn\u2019t works I'll try to fix it and if it is not possible, I'm going to add a Install section on README.md to explain how to clone the repo, execute go generate...\n", "I think we should pull this in as soon as these comments are done and we know there's a way to build & run the tests.  The one thing I'd ask is that you put a comment in the example imagenet program that says this isn't really the right way to do it - pending a way to modify the graphdef, it's much more efficient to directly couple the input and recognition path so that the image doesn't get copied back to python/CPU between the steps. :)\n", "Fixed the problems with the GetVal and also the typos :)\n\nBy build and run the tests do you mean the \"go get\"?, I'll try to review that part tomorrow, I'm going to sleep now :)\n\n``` sh\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow/tensorflow/contrib/go (go_bindings_tensors) go test\n# github.com/tensorflow/tensorflow/tensorflow/contrib/go\nPASS\nok      github.com/tensorflow/tensorflow/tensorflow/contrib/go  0.453s\n```\n\nBy the imagenet example, do you mean [this one](https://github.com/alonsovidales/tensorflow/blob/go_bindings_tensors/tensorflow/examples/label_image_go/main.go)?, it is a copy of the [C++ API tuto](https://www.tensorflow.org/versions/r0.7/tutorials/image_recognition/index.html#usage-with-the-c-api) but using Go. It is using a [file_reader](https://github.com/alonsovidales/tensorflow/blob/go_bindings_tensors/tensorflow/examples/label_image_go/main.go#L77) that reads and process the image when the graph is executed, I'm only providing the path to grab the image, all the magic occurs during the graph execution.\n", "Hah!  So it is - thanks.  It turns out that I don't like our API example program, then, but that's not your problem in the slightest.  _grins_  Fine to leave it as-is.\n", "I have been trying to prepare the package to be go-gettable but since the *.pb.go files have to be generated, is not possible to do it with a simple \"go get\". The good news are that go get clones the repository using the --recurse-submodules, so with just a \"go get\" we have all the code in place to execute the \"go generate\".\nI've added the section \"Installation\" to the README.md with an only one necessary command to get the package:\n\n``` sh\n$ TF_REPO=github.com/tensorflow/tensorflow/tensorflow/contrib/go/;go get $TF_REPO || (go generate $TF_REPO && go get $TF_REPO)\n```\n\nBasically, the command tries to do the \"go get\", if it success doesn't continue, but this only can happen an odd situation where the package was previously installed. If the go get returns an error, since the code is already in place, it executes the \"go generate\" to compile the shared libraries, generate the .pb.go files and prepare all the other stuff leaving all ready to install the package with the last \"go get\".\nI tested this solution and it works:\n\n``` sh\n\u279c ~/go-src/src/github.com rm -rf tensorflow/tensorflow/\n\u279c ~/go-src/src/github.com rm -rf tensorflow\n\u279c ~/go-src/src/github.com ln -s alonsovidales tensorflow\n\u279c ~/go-src/src/github.com TF_REPO_AUX=github.com/alonsovidales/tensorflow/tensorflow/contrib/go/; TF_REPO=github.com/tensorflow/tensorflow/tensorflow/contrib/go/;go get $TF_REPO_AUX || (go generate $TF_REPO && go get $TF_REPO)\npackage github.com/alonsovidales/tensorflow/tensorflow/contrib/go: cannot find package \"github.com/alonsovidales/tensorflow/tensorflow/contrib/go\" in any of:\n    /usr/local/go/src/github.com/alonsovidales/tensorflow/tensorflow/contrib/go (from $GOROOT)\n    /home/avidales/go-src/src/github.com/alonsovidales/tensorflow/tensorflow/contrib/go (from $GOPATH)\ncan't load package: package github.com/tensorflow/tensorflow/tensorflow/contrib/go: cannot find package \"github.com/tensorflow/tensorflow/tensorflow/contrib/go\" in any of:\n    /usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/contrib/go (from $GOROOT)\n    /home/avidales/go-src/src/github.com/tensorflow/tensorflow/tensorflow/contrib/go (from $GOPATH)\n\u279c ~/go-src/src/github.com cd tensorflow/tensorflow/\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (master) git checkout go_bindings_tensors\nBranch go_bindings_tensors set up to track remote branch go_bindings_tensors from origin.\nSwitched to a new branch 'go_bindings_tensors'\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (go_bindings_tensors) TF_REPO_AUX=github.com/alonsovidales/tensorflow/tensorflow/contrib/go/; TF_REPO=github.com/tensorflow/tensorflow/tensorflow/contrib/go/;go get $TF_REPO_AUX || (go generate $TF_REPO && go get $TF_REPO)\n../../alonsovidales/tensorflow/tensorflow/contrib/go/graph.go:11:2: no buildable Go source files in /home/avidales/go-src/src/github.com/tensorflow/tensorflow/tensorflow/contrib/go/proto\n.......\n(...)\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (go_bindings_tensors) cd tensorflow/contrib/go/\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow/tensorflow/contrib/go (go_bindings_tensors) go test\nPASS\nok      github.com/tensorflow/tensorflow/tensorflow/contrib/go  0.499s\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow/tensorflow/contrib/go (go_bindings_tensors) cd ../../../\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (go_bindings_tensors) mkdir tensorflow/examples/label_image_go/data/\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (go_bindings_tensors) wget https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip -O tensorflow/examples/label_image_go/data/inception_dec_2015.zip\n--2016-04-20 20:55:14--  https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4013:c01::80, 74.125.136.128\nConnecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4013:c01::80|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 88631107 (85M) [application/zip]\nSaving to: \u2018tensorflow/examples/label_image_go/data/inception_dec_2015.zip\u2019\n\n100%[==========================================================>] 88,631,107   716KB/s   in 1m 51s\n\n2016-04-20 20:57:05 (781 KB/s) - \u2018tensorflow/examples/label_image_go/data/inception_dec_2015.zip\u2019 saved [88631107/88631107]\n\n\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (go_bindings_tensors) unzip tensorflow/examples/label_image_go/data/inception_dec_2015.zip -d tensorflow/examples/label_image_go/data/\nArchive:  tensorflow/examples/label_image_go/data/inception_dec_2015.zip\n  inflating: tensorflow/examples/label_image_go/data/imagenet_comp_graph_label_strings.txt\n  inflating: tensorflow/examples/label_image_go/data/LICENSE\n  inflating: tensorflow/examples/label_image_go/data/tensorflow_inception_graph.pb\n\n\u279c ~/go-src/src/github.com/tensorflow/tensorflow (go_bindings_tensors) go run ./tensorflow/examples/label_image_go/main.go ./tensorflow/examples/label_image/data/grace_hopper.jpg\nmilitary uniform : 0.6472986\nsuit : 0.04771947\nacademic gown : 0.02324065\nbow tie : 0.015735544\nbolo tie : 0.01450234\n```\n\nI had to do some tricks since it is still under my github account and not in the master branch, but it has to work with the line in the README.md after merge the PR.\n\nI also modified the code according to the last comments, fixed typos and relocated the Err\\* types :)\n", "Curious to see what this does to Jenkins - will it break the build or be happy?\n@tensorflow-jenkins test this please.\n", "Last major thing that needs to be addressed:\n  (a)  Is the build / install solution satisfactory and can it be improved?  (I'll look @ this next);\n  (b)  We need to get the tests integrated to the point where jenkins auto-runs them as part of the overall test framework.  I'm going to need to dig into how this works with bazel/blaze unless @rakyll is willing to help clue me in on integrating bazel's stuff with go's testing.\n", "I'm unclear on how to get the github bot to like my CLA status, any thoughts there @dave-andersen ?\n", "I think that for the **a** point we have some things that can be improved:\n1. Include the .pb.go files, so we can do the go get directly. But @vrv mentioned that on other APIs the protobuf files are being generated from bazel, I agree with him, put this files on the repo is not a good idea since we would need to maintain them updated, if we generate them during the install process we only need to check if the Go code keeps working on mayor updates. Perhaps we could integrate all the process using Bazel instead of go get and go generate, but I'm not really sure about how to do this nor if the result would be better than the proposed process.\n2. I had to do [this](https://github.com/tensorflow/tensorflow/pull/1771/files#diff-a080565cf0a14f4c35a129e9ab6881cfR15) in order to place the shared library because, I don't know why, even with [this ld flag](https://github.com/tensorflow/tensorflow/pull/1771/files#diff-35661cd888164ff2c91156ebaf138ed3R3) it was not working. I think that is not possible to do it in any other way since the route on that line is relative, but I'm not really sure about this, I don't have too much experience working with cgo. I think that this is not a mayor issue, but it would be nice to don't require sudo during the install process.\n\nRegarding to the point **b**, let me know if I can help, I could prepare the script to install and run the tests, but more or less with:\n\n``` sh\n$ TF_REPO=github.com/tensorflow/tensorflow/tensorflow/contrib/go/;go get $TF_REPO || (go generate $TF_REPO && go get $TF_REPO)\n$ go test github.com/tensorflow/tensorflow/tensorflow/contrib/go/\n```\n\ncould be enough.\n", "@tmc - try @ googlebot I'm okay with these changes\n", "@googlebot I'm okay with these changes\n", "> I have been trying to prepare the package to be go-gettable but since the *.pb.go files have to be generated,\n\nWhat about checking the generated go files in? In the Google Cloud API packages, that's what we do (e.g. https://github.com/GoogleCloudPlatform/gcloud-golang/tree/master/bigtable/internal/cluster_data_proto).\n", "> I have been trying to prepare the package to be go-gettable but since the *.pb.go files have to be generated,\n> \n> > What about checking the generated go files in? In the Google Cloud API packages, that's what we do (e.g. https://github.com/GoogleCloudPlatform/gcloud-golang/tree/master/bigtable/internal/cluster_data_proto).\n\nIt seems that on TensorFlow, the generated files are not being included in the repo, @vrv comments that [here](https://github.com/tensorflow/tensorflow/pull/1771#dis cussion-diff-59974641R1). In my opinion I think that checking the *.pb.go files would be better since we remove the necessity of having installed protobuf before invoke the `go generate`, but even checking the *.ph.go files we can't get rid of the `go generate` since we still need to compile the shared libraries. It would be great if `go get` would be able to execute the  `go generate` before, but this is not possible :'(\n", "+1 to committing the generated files.  I checked with some of the other go folk here, and they're of the very strong opinion that if it's going to go in our repo, it needs to be entirely buildable with `go get`.\n\nWhich shared libraries do you need to compile?  We could make those part of the tensorflow C++ build and then you just need to find them.  cgo supports some ways to do this;  I'm not sure with the way you've set it up.\n", "The shared libraries are the libtensorflow.so that are being compiled and relocated [here](https://github.com/tensorflow/tensorflow/pull/1771/files#diff-a080565cf0a14f4c35a129e9ab6881cfR14).\nIf you already have this libraries on your system, you don't need to do this (I'm not sure if when you install the Python version the libs are being placed on the ld library path).\nI'll try to find a way to do a direct `go get` today, perhaps, if you have the python version already installed, we can just add the .pb.go .\n", "I have been trying to figure out how to do the `go get` directly, but I think that is not going to be possible.\nWhat the Python libs are doing is placing the shared libraries inside the package, so we can't access them:\n\n``` sh\n\u279c ~/kaggle/state_farm sudo find / | grep tensorflow | grep -v avidales | grep \"\\.so\"\n/usr/local/lib/python2.7/dist-packages/tensorflow/core/libtensorflow_framework.so\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n```\n\nAnd if we need to compile the libs, we are going to need to invoke in any way the `bazel build //tensorflow:libtensorflow.so`.\nI can only see two possible options:\n1. Instead of using `go get`, use bazel to install the libraries. Bazel had added support for Go on the last versions, but this option will requiere to clone the repo and execute bazel manually.\n2. Use the `go get || (go generate && go get)` proposed initially. This is an ugly solution, but it works and is easy to execute.\n\n@rakyll @tmc @vrv , Do you see any way to make this go-gettable?\n", "I've opened a [request](https://github.com/golang/go/issues/15536) to propose a way to execute the `go generate` during the `go get` and also to be sure that there is no way to do it with the current `go get` implementation.\nIt seems that it is going to be impossible to have a go-gettable package since we have to compile the C++ libraries and `go get` will never be able to execute the generate or Bazel in any other way.\nI can only see the previously mentioned two options, use Bazel for the compilation and installation or the `go get || (go generate && go get)`. I prefer the second option since it is just a command and is more `go` like.\nWe could move forward with the `go get || (go generate && go get)` option and see if someone comes up with a better idea.\n\nWhat do you think?\n", "I know very little about go, so that sounds fine, but a go expert should probably chime in here.  In some future world we'll hopefully have shared library distributions of the C++ core that doesn't require building during go get, and then this can probably be cleaned up.\n", "+1 to commit the generate files. Doing a go generate automatically when a user does go get opens so many risks and vulnerabilities that it will never be accepted. \nThe go library should only depend on having a valid tensorflow lib installed and reachable by the linker and then the local build phase will generate the wrapper. \n", "Thinking about what @Mistobaan has commented, that would be a better option, we can specify on the README.md how to compile using bazel and install the libraries, execute the go get and that's it. This makes more sense since the `go generate` will not be necessary and we are not doing any magic without the users knowledge.\n\nThe pros are:\n1. The developer is the one who will install the libs and he will be aware of what he is doing.\n2. It is multi-platform, since right now we are placing the libs on `/usr/lib`, on the docu we are going to specify \"your ld library path\".\n3. It makes the package go-gettable.\n\nCons:\n1. It makes necessary to manually clone the repo, execute bazel and copy the `.so`, the other option is just copy and paste that line. But this shouldn't be a problem for a developer.\n\nI'm going to update the docu today and remove the library generation.\n", "Whoops, that response was made to some stuff way in the past. Sorry. Deleting since it's irrelevant.\n", "I concur - go gettable is critical, and making someone manually install tensorflow in a special way first is probably a reasonable cost.  LMK once that's there and I'll test out the workflow also.\n", "@dave-andersen I already modified the README.md to specify how to compile and install the libs and the gen.go to remove that: https://github.com/tensorflow/tensorflow/pull/1771/commits/942760424141d0f5a930982d5e78aaeb05869488 \nNow the go generate is not necessary and the package is go-gettable if you install the libs before :)\n", "I forgot to mention, you have to do the `go get` of: `github.com/alonsovidales/tensorflow/tensorflow/contrib/go` instead of the go get from the tensorflow repository since the code is still not merged.\nAfter do the go get you are going to get back an error because the code is not in the right path, now you have to do:\n\n``` sh\n$ cd $GOPATH/src/github.com/alonsovidales/tensorflow\n$ git checkout go_bindings_tensors\n$ ln -s $GOPATH/src/github.com/alonsovidales $GOPATH/src/github.com/tensorflow \n```\n\nand try the go get again with the final path:\n\n``` sh\n$ go get github.com/tensorflow/tensorflow/tensorflow/contrib/go\n```\n\nAfter merge the code it has to work as it is specified on the README.md file.\n", "So what's the status of this? Is reviewing done and ready?\n", "@vrv , I think that the code review is done (if nothing else pops up). During the last weeks we have been trying to find the best way to make the package go-gettable and finally we decided to go with a way where, after build and install the shared library, the developers can use `go get` to install the package. This workflow is documented on the README.md fie, so this part is almost closed. @dave-andersen have to test the workflow and is all is ok, I think that we would be be ready to go! :)\n", "@vrv @martinwicke - I'm OK accepting this into contrib within a branch.  It's going to need build changes to get it to work with Jenkins and internally, so I think this is the best approach to continue the momentum -- it'll be available to the community to play with, and we can then start poking at what's going to be required within both tensorflow and this PR to simplify the build and install process.\n\n(I don't know the mechanism for getting that working, so I'll let one of you take it from here. :)\n\nAlonso, thanks for your patience with this!\n", "Ok. I made an appropriately named brach (go branch, go!), can you redo the PR against said branch? I will then merge it onto there.\n\nThanks again for all the effort.\n", "@martinwicke Awesome, thanks a lot :) I just created a [new PR](https://github.com/tensorflow/tensorflow/pull/2479) against the `go` branch, but it seems that the `go` branch is a bit outdated, is that the correct one?\n", "Thanks! #2479 is merged. I updated go before merging. \n", "Super, thanks a lot! \ud83d\udc4d \n"]}, {"number": 1770, "title": "Fix a missing pylint whitelist item in ci_sanity", "body": "Also removed an obsolete TODO item.\n", "comments": ["@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n"]}, {"number": 1769, "title": "Bazel build Android shared object libtensorflow_demo.so fails with jni.h not found", "body": "I'm trying to build a .so of the Tensorflow Android lib in order to include in the build process of an existing app. Bazel is able to build the full apk fine, but it's having trouble when I tell it to only build the .so, complaining that jni.h is not found.\n### Environment info\n\nOperating System:\n\nUbuntu 14.04 x64\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed:\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n1. The output from python -c \"import tensorflow; print(tensorflow.**version**)\":\n   0.7.1\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1.  bazel build //tensorflow/examples/android:libtensorflow_demo.so\n2. You get the error message: \n\nERROR: /Code/tensorflow/tensorflow/examples/android/BUILD:12:1: C++ compilation of rule '//tensorflow/examples/android:libtensorflow_demo.so' failed: namespace-sandbox failed: error executing command /home/user/.cache/bazel/_bazel_user/460c757144c1d801a3560f7277d7643a/tensorflow/_bin/namespace-sandbox ... (remaining 63 argument(s) skipped).\nIn file included from tensorflow/examples/android/jni/jni_utils.cc:16:0:\n./tensorflow/examples/android/jni/jni_utils.h:19:17: fatal error: jni.h: No such file or directory\n #include <jni.h>\n                 ^\ncompilation terminated.\n### What have you tried?\n1. Running bazel build //tensorflow/examples/android:tensorflow_demo does in fact work correctly.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["I'm no expert on Bazel, but I assume it's because that it is using an android toolchain when the root target is an android_binary target. Could I make bazel somehow use this same toolchain for just compiling the cc_binary target?\n", "Unfortunately it's not very obvious how to build standalone Android in Bazel. There's an example command in the comments for //tensorflow/core:android_tensorflow_lib.  Here it is for reference (adapted for libtensorflow_demo.so):\n\nbazel build -c opt tensorflow/examples/android/libtensorflow_demo.so \\\n --crosstool_top=//external:android/crosstool \\\n --cpu=armeabi-v7a \\\n --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\n\nKeep in mind that the link flags for libtensorflow_demo.so will by default strip out anything not explicitly exported by the library.\n\nedit: fixed crosstool_top so as not to confuse future visitors\n", "Thanks for the comment but I'm still getting the error:\n\nERROR: /home/ling/Code/tensorflow/tools/defaults/BUILD:11:1: no such package 'third_party/java/android/android_ndk_linux/toolchains': BUILD file not found on package path and referenced by '//tools/defaults:crosstool'.\n\nI tried copying the NDK manually into that location but it seems there is no Bazel BUILD file for it.\n\nAlso two other questions:\n1. Is it possible to have my native code be outside the Tensorflow directory, and just refer to it remotely?\n2. Can Bazel be set to output object files .o or static libraries .a instead of shared libraries?\n\nThanks for your help!\n", "Sorry, I mixed up my build commands. Here's one I just verified to work with a fixed crosstool_top param.\n\nbazel build -c opt tensorflow/examples/android:libtensorflow_demo.so \\\n--crosstool_top=//external:android/crosstool \\\n--cpu=armeabi-v7a \\\n--host_crosstool_top=@bazel_tools//tools/cpp:toolchain\n1. You can certainly have other targets depend on Tensorflow, or have Tensorflow depend on other targets. Or do you mean depending on TF from outside of Bazel? That's also possible, if you have the precompiled static library and the header paths configured appropriately.\n2. You can build a static library by removing the alwayslink=1 attributes from the //tensorflow/core:android_tensorflow_lib(_lite) targets and building those. If you want the examples/android/jni code as well I think you could experiment with a \"-static\" linkopt, or alternatively turn that lib into a cc_library.\n", "Closing due to lack of activity; please reopen if still seeing issues.\n", "@andrewharp  \nHi, I tried you build command, and it works works with tensorflow v0.6.0 codes.\nBut when I run it with the master codes, I got the error:\n\n**ERROR: /home/gece/.cache/bazel/_bazel_gece/1caf8a34a8f0c8f7d976c36c83fa823a/external/protobuf/BUILD:73:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: false failed: error executing command /bin/false -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/bytestream.pic.d ... (remaining 26 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/examples/android:libtensorflow_demo.so failed to build\nUse --verbose_failures to see the command lines of failed build steps.**\n\nThis is the output with '--verbose_failures'\n\n**ERROR: /home/gece/.cache/bazel/_bazel_gece/1caf8a34a8f0c8f7d976c36c83fa823a/external/protobuf/BUILD:73:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: false failed: error executing command \n  (cd /home/gece/.cache/bazel/_bazel_gece/1caf8a34a8f0c8f7d976c36c83fa823a/execroot/tensorflow && \\\n  exec env - \\\n    LD_LIBRARY_PATH=/home/gece/Workspace/torch/install/lib:/home/gece/Workspace/torch/install/lib:/usr/local/cuda-7.5/lib64: \\\n    PATH=/home/gece/Workspace/torch/install/bin:/home/gece/Workspace/torch/install/bin:/usr/local/cuda-7.5/bin:/home/gece/anaconda2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\n  /bin/false -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/bytestream.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/bytestream.pic.o' -fPIC -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -c external/protobuf/src/google/protobuf/stubs/bytestream.cc -o bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/bytestream.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/examples/android:libtensorflow_demo.so failed to build**\n", "@drcege I got exactly same error, you got any solution for this?", "Have you [set up your WORKSPACE file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md#edit-workspace) yet? This build error is typical when the NDK is not installed and configured there.", "@sandeeptengale  Sorry,  I cannot help you. I have not worked with the code for a while.", "Thank you guys, now its working for me, I have not used the proper version of NDK I guess, as mentioned in the comment of workspace file, I replaced my NDK with 12b version it started working perfectly for me", "i've already updated git submodules recursively on my macbook.  i am on master branch. But i am getting an error on building with bazel. Here is my workspace file changes:\r\n\r\n```\r\n# Uncomment and update the paths in these entries to build the Android demo.\r\nandroid_sdk_repository(\r\n    name = \"androidsdk\",\r\n    api_level = 23,\r\n    # Ensure that you have the build_tools_version below installed in the\r\n    # SDK manager as it updates periodically.\r\n    build_tools_version = \"25.0.2\",\r\n#    # Replace with path to Android SDK on your system\r\n    path = \"/Users/j2emanue/Library/Android/sdk\",\r\n)\r\n#\r\n# Android NDK r12b is recommended (higher may cause issues with Bazel)\r\nandroid_ndk_repository(\r\n    name=\"androidndk\",\r\n    path=\"/Users/j2emanue/Downloads/android-ndk-r12b\",\r\n#    # This needs to be 14 or higher to compile TensorFlow.\r\n#    # Note that the NDK version is not the API level.\r\n    api_level=14)\r\n```\r\n\r\nfor the api_level in the android_ndk_repository closure i tried 23, 14, 21 . im not sure what to put there ?  on my pc i have android api 23 sdk already installed.  \r\n\r\nhere is the build error i get:\r\n\r\n`ERROR: /private/var/tmp/_bazel_j2emanue/b0092c80c1dd2ccd3bd26061f20bf823/external/protobuf/BUILD:113:1: C++ compilation of rule '@protobuf//:protobuf' failed: Process exited with status 71 [sandboxed].\r\nsandbox-exec: external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-gcc: No such file or directory\r\nUse --strategy=CppCompile=standalone to disable sandboxing for the failing actions.\r\nTarget //tensorflow/examples/android:tensorflow_demo failed to build`\r\n\r\n\r\nand if i use verbose reporting here is the error i get and the command used:\r\n\r\n`bazel build  --verbose_failures -c  opt --local_resources 2048,0.5,1.0 //tensorflow/examples/android:tensorflow_demo`\r\n\r\nerror:\r\n\r\n```\r\nERROR: /private/var/tmp/_bazel_j2emanue/b0092c80c1dd2ccd3bd26061f20bf823/external/protobuf/BUILD:113:1: C++ compilation of rule '@protobuf//:protobuf' failed: arm-linux-androideabi-gcc failed: error executing command\r\n  (exec env - \\\r\n    PATH='/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/j2emanue/Library/Android/sdk/platform-tools/:\r\n/Users/j2emanue/Downloads/android-ndk-r12b/:\r\n/Users/j2emanue/Library/Android/sdk/build-tools/25.0.2/' \\\r\n    TMPDIR=/var/folders/q7/m2l4qpf11mqf2wjr24_jxrhc0000gn/T/ \\\r\n  external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes -fno-canonical-system-headers '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/extension_set_heavy.d '-frandom-seed=bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/extension_set_heavy.o' -iquote external/protobuf -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function '--sysroot=external/androidndk/ndk/platforms/android-14/arch-arm' -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/include -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/include-fixed -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -c external/protobuf/src/google/protobuf/extension_set_heavy.cc -o bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/extension_set_heavy.o)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox.\r\nsandbox-exec: external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-gcc: No such file or directory\r\nUse --strategy=CppCompile=standalone to disable sandboxing for the failing actions.\r\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\r\nINFO: Elapsed time: 181.225s, Critical Path: 168.96s\r\n```\r\n\r\n\r\nHow can i resolve this ? ", "@j2emanue Bazel isn't able to find your ndk. Check your paths, dirrctory permissions, and perhaps disable sandboxed building?", "@andrewharp what api_level should i put in there. im using 12b ndk ? i have api 23 installed on my pc can i use 23 for the ndk api level then ?", "@j2emanue The NDK API level doesn't really matter, it just determines which headers are used to build. 14 and higher is fine. Your problem is that Bazel can't even find the compiler.", "thanks @andrewharp  seem to be working now. i actually had the wrong NDK installed. i was using the linux version instead of darwin for mac. Also when i was setting the path i was using enter key to separate the entries. they should all be on one line.  looks good now. ", "Hello! I had tried building the `libtensorflow_inference.so` file using the following -\r\n`bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=arm64-v8a`\r\nAs you can see I have changed the `--cpu` argument to `arm64-v8a` and the command above is generating the desired `libtensorflow_inference.so` file, which I have copied in my Android Project directory in `src/main/jniLibs/arm64-v8a/`.\r\n\r\nBut, upon running building the project on a device, it's throwing the following error -\r\n`\r\n05-10 11:29:00.421 14215-14254/com.example.zeus.objectdetection E/AndroidRuntime: FATAL EXCEPTION: pool-1-thread-1\r\n                                                                                  Process: com.example.zeus.objectdetection, PID: 14215\r\n                                                                                  Theme: themes:{default=overlay:system, iconPack:system, fontPkg:system, com.android.systemui=overlay:system, com.android.systemui.navbar=overlay:system}\r\n                                                                                  java.lang.RuntimeException: Error Initializing TensorFlow\r\n                                                                                      at com.example.zeus.objectdetection.MainActivity$2.run(MainActivity.java:91)\r\n                                                                                      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\r\n                                                                                      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\r\n                                                                                      at java.lang.Thread.run(Thread.java:818)\r\n                                                                                   Caused by: java.lang.RuntimeException: Native TF methods not found; check that the correct native libraries are present in the APK.\r\n                                                                                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:68)\r\n                                                                                      at com.example.zeus.objectdetection.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:52)\r\n                                                                                      at com.example.zeus.objectdetection.MainActivity$2.run(MainActivity.java:80)\r\n                                                                                      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\u00a0\r\n                                                                                      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\u00a0\r\n                                                                                      at java.lang.Thread.run(Thread.java:818)\u00a0\r\n`\r\n\r\nCan anyone please tell me what might be the problem?", "Just to confirm, you're running this on an arm64-v8a device? What's the output of unzip -v tensorflow_demo.apk?", "Thank you for the reply @andrewharp. I don't exactly know that. I am running it on One Plus One. On this device building with `armeabi-v7a` worked just fine. I was just trying out the above to understand what it means.\r\n\r\n What is the meaning of this device architecture thing? Can you please send me some links where I can read about it?", "arm64-v8a is a higher-performing 64-bit variant of the ARM architecture that only a subset of armeabi-v7a compatible devices support. If you add both to your apk your device will pick the highest compatible target available, but if you only add arm64-v8a and your device doesn't support it you may get error messages like the above.\r\n\r\nYou can see what .so libs are packaged in your apk with `unzip -v tensorflow_demo.apk`", "Hi @andrewharp , I was trying to build the libtensorflow_inference.so file, following this [tutorial](https://www.skcript.com/svr/realtime-object-and-face-detection-in-android-using-tensorflow-object-detection-api/). \r\n\r\nI'm on\r\n- Windows 10\r\n- Installed the latest version of Bazel using `choco install bazel` with cmd\r\n- NDK r14b version\r\n- JDK 8 updated with Android Studio\r\n\r\nWhen I was trying to build .so file with \r\n```\r\nbazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so \r\n  --crosstool_top=//external:android/crosstool\r\n  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\n  --cpu=armeabi-v7a --verbose_failures\r\n```\r\n\r\nI had this error:\r\nERROR: C:/users/user/appdata/local/temp/_bazel_user/xbt4cnkp/external/protobuf_archive/BUILD:265:1: Executing genrule @protobuf_archive//:generate_js_well_known_types_embed failed (Exit -1). Note: Remote connection/protocol failed with: execution failed: bash.exe failed: error executing command\r\n  cd C:/users/user/appdata/local/temp/_bazel_user/xbt4cnkp/execroot/org_tensorflow\r\n  SET PATH=C:\\tools\\msys64\\usr\\bin;C:\\tools\\msys64\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\libnvvp;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\iCLS Client\\;C:\\Program Files\\Intel\\iCLS Client\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\Windows Live\\Shared;C:\\Program Files\\nodejs\\;C:\\Program Files\\MATLAB\\R2016b\\bin;C:\\Program Files\\ibm\\gsk8\\lib64;C:\\Program Files (x86)\\ibm\\gsk8\\lib;C:\\PROGRA~1\\IBM\\SQLLIB\\BIN;C:\\PROGRA~1\\IBM\\SQLLIB\\FUNCTION;C:\\PROGRA~1\\IBM\\SQLLIB\\SAMPLES\\REPL;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Users\\User\\.dnx\\bin;C:\\Program Files\\Microsoft DNX\\Dnvm\\;C:\\Program Files (x86)\\Windows Kits\\8.1\\Windows Performance Toolkit\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\OpenVPN\\bin;C:\\Program Files\\PuTTY\\;C:\\Program Files\\Java\\jdk1.7.0_79\\bin;C:\\Users\\User\\Anaconda3\\envs\\py36;C:\\Python27;C:\\Users\\User\\Anaconda3\\Scripts;C:\\Users\\User\\Anaconda3\\Library\\bin;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Roaming\\npm;C:\\Program Files (x86)\\CodeBlocks\\MinGW\\bin;C:\\Program Files\\Docker Toolbox;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\extras\\CUPTI\\libx64;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\lib\\x64;C:\\ProgramData\\chocolatey\\bin\r\n  C:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/protobuf_archive/js_embed.exe external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/any.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/struct.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/timestamp.js > bazel-out/host/genfiles/external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types_embed.cc\r\nAction failed to execute: java.io.IOException: ERROR: src/main/native/windows/processes-jni.cc(239): CreateProcessW(\"C:\\tools\\msys64\\usr\\bin\\bash.exe\" -c \"source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/protobuf_archive/js_embed.exe external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/any.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/struct.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/timestamp.js > bazel-out/host/genfiles/external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types_embed.cc\"): The system cannot find the file specified.\r\n\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 232.602s, Critical Path: 15.31s\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\nI have been trying with other version of bazel and NDK, but still can't build the file. Can you help me look into it?\r\n\r\nThanks in advance.", "Same issue I am facing not able to proceed further. Help required", "@Vrishod are you on Windows too? Feel free to find me, I will help.", "Yes I am on Windows. Help me in this regard", "You can get the .so and .jar files that are required to build the apps from http://ci.tensorflow.org/view/Nightly/job/nightly-android/\r\n1. Click on the Last stable build\r\n2. Artifact\r\n3. Download all files in the zip, then you are ready with .so and .jar, place them in the correct places and you are done.", "Thanks a lot @chingjunehao ..."]}, {"number": 1768, "title": "Show responsible nodes when ValueError: No gradients provided for any variable", "body": "The error message \n\n```\nValueError: No gradients provided for any variable\n```\n\nIs not particularly informative and it would be nice to see if there is a node preventing the gradient calculation (ie Gradient Cannot be calculated for `Cast` or `ResizeBilinear` operation) or if there is simply no connection (the variable is not connected to the loss function in any way.)\n\nBoth of the following issues dealt with this and debugging would be easier if the error message was more explicit. \n- Shows a specific example where the Inception network has nodes which are not differentiable: https://github.com/tensorflow/tensorflow/issues/1758\n- A more obscure but related issue: https://github.com/tensorflow/tensorflow/issues/1511\n", "comments": ["I looked into the code base for when that error is raised and the only place is in the optimizer.py code that was referenced in #1758 which does show the nodes responsible.  I'm closing this because the uninformative error message is not reproducible.  Feel free to reopen if you can provide more details.\n", "The error in optimizer.py prints the Variable object, which is shown as e.g. `<tensorflow.python.ops.variables.Variable object at 0x7ff7ed095350>`, not very informative. It should probably display `Variable.name`.\n", "I agree with rlrs. I have no easy way to know which variables are causing the failure.\n", "I agree. This error `No gradients provided for any variable` is not informative. Would be ideal to show the node that caused the error.\n\nHere's what I'm trying to do\n\n```\n  # logits is the output of a forward-pass\n  positive_indices = tf.greater(logits[:, 0], 0.0)\n  positive_returns = tf.select(positive_indices, train_labels_node, -train_labels_node)\n  loss = 1.0 - tf.reduce_sum(positive_returns) / BATCH_SIZE\n\n  optimizer = tf.train.MomentumOptimizer(learning_rate,\n                                         0.9).minimize(loss,\n                                                       global_step=batch)\n```\n", "I agree. This error No gradients provided for any variable is not informative. Would be ideal to show the node that caused the error.\r\n\r\n"]}, {"number": 1767, "title": "Adaptive neural network optimized for solving specific issue", "body": "Hey!\n\nFrom Kolmogorov theorem we can accept that neural network is able to represent any function, but it is unknown what should be the specific configuration of the network.\n\nTensorFlow has a lot of helpful parts (behind scenes back prop, learning rate decay, gradient optimizers etc), but the topology of the network (how many layers and neurons) is currently arbitrary and the best solution is found by manual testing.\n\nWould it make sense to have auto of the box some kind of  \"find the best solution for my classification problem\"? Just adding layers, neurons and autoencoders to find the best solution? \n\nGenetic programming of neural network. Plugin & play black box would be awesome? :)\n", "comments": ["A limited version of this is called hyperparameter optimization. You can check out projects like spearmint (https://github.com/JasperSnoek/spearmint). In general, it's a far off research problem. \n\nI'm closing this issue since it's not a well-defined feature request. Better support for hyperparameter tuning is planned.\n"]}, {"number": 1766, "title": "Multi-dimensional argmax and one-hot", "body": "This is a feature request, unless someone can show me how the following might be done with the current API.\n\nSay I have a tensor WxHxD, and I want to keep only the largest element in each WxH slice, setting the rest to zero. These indices could be obtained in numpy by doing something like\n`(row,col) = np.unravel_index(A.argmax(), A.shape)`\non each slice WxH slice A.\nCollecting the D row and column indices, I could create a boolean mask using advanced indexing\n`mask[rows,cols, range(D)] = 1`\nThen, an elementwise multiplication between the WxHxD tensor and the mask gives the desired tensor.\n", "comments": ["This should be possible using reshape, argmax, one_hot, reshape, cwise_mul. If you need help with the exact invocation, stackoverflow is probably a better place.\n"]}, {"number": 1765, "title": "Update TF 101 Tutorial to match recent code", "body": "This patch updates two portions of the TensorFlow 101 tutorial:\n\nThe first change updates the Loss section to match the changes made in\n5c5b29adda87f6fb, which switched from manually creating 1-hot labels to\nusing `tf.nn.sparse_softmax_cross_entropy_with_logits()`\n\nThe second removes a reference to the non-existent `get_data()`\nfunction.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks!\n"]}, {"number": 1764, "title": "Add missing parenthesis in description", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1763, "title": "image processing functions should not convert dtypes unless necessary (e.g. resize/crop/transpose/rotate, ...)", "body": "### Environment info\n\nOperating System: OSX\n\nIf installed from binary pip package, provide:\n1. package: tensorflow\n2. version: 0.7.1\n### Steps to reproduce\n\nPerform a resize action on a decoded jpeg before passing it to convert_image_dtype with a target of float32.  The values will still be in the range 0-255 rather than 0-1.\n\nThis line works as expected\ntf.image.convert_image_dtype(tf.image.decode_jpeg(value, channels=3), tf.float32)\nThis line doesn't(values in the tensor are still 0-255 rather than 0-1)\ntf.image.convert_image_dtype(tf.resize_images(tf.image.decode_jpeg(value, channels=3), x, y), tf.float32)\n### What have you tried?\n1. Changing the order as described above works.\n", "comments": ["Yes, this is a bug. Either a Python wrapper or the op kernel for the different resize methods should perform conversion if necessary.\n", "I might take a shot at this then, should I be fixing this on the python side of things, or should I be patching the c++ code instead?\n", "jhspaybar, I believe that you should fix this on the python side of things.\n", "IMO, the bug here is not actually that it doesn't scale the range. The bug is that range scaling depends on the input type. I will go out on a limb and say that _a lot_ of people get bit by this, and there are a lot of subpar models out there as a result. Some models are able to train around the lack of rescaling, some suffer an accuracy loss, especially if some kind of range-dependent mean centering and stddev normalization is introduced later in the chain.\r\n\r\nHere's a scenario we encountered: a preliminary version of our data augmentation code used nearest neighbor interpolation, which does not convert dtype when resampling. We would resample, crop, do a few other things, and then feed everything into convert_image_dtype(). At that time we actually inspected the output of convert_image_dtype() and verified it was doing the scaling.\r\n\r\nThen, one of our researchers changed to bilinear resizing earlier in the chain (which _does_ convert dtype to float32, but does not rescale to [0-1.0)). This led to convert_image_dtype() being essentially a no-op, and much head scratching regarding why our model wasn't performing as well as it should.\r\n\r\nLong rage, opaque magic like this is bad design.\r\n\r\nGiven that backward compat is an issue, at this point I think the most robust solution seems to be to permanently deprecate convert_image_dtype() and recommend that people use cast() and saturate_cast() instead, and handle range rescaling separately.", "In the presence of HDR images, scaling unconditionally to 0-1 for float inputs is not a good idea. What would you scale by? If a previous transformation incidentally left you with float data not in the range 0-1 (say, because you increased brightness by 10%), would you divide by 255? By the max?\r\n\r\nI disagree that this is a bug. Dealing with types in image processing is always annoying, especially in the presence of int8/uint8 anywhere in the pipeline. `convert_image_dtype` is a conversion function, not a scaling function. It converts between images encoded as fixed point images stored as integers and images encoded as floating point. It says as much in the docstring.\r\n\r\nThere is, however, a bug in rescale_image, which should return the same dtype it ingested (preferred), or convert the dtype appropriately. This is different from the behavior of other image processing ops, who take care to return the same dtype they got. Sadly, here we do have the backwards compatibility problem, but I would say that this function should be deprecated in favor of a safe alternative. We could start by emitting a warning if it gets non-float input.", "But by the same argument, to make the behavior predictable and non-magical, you now have to guarantee transparency into types all the way along the chain. I don't see how that'd be feasible from API design standpoint, short of requiring dtype specifications for all ops so that they assert if they see the type they didn't expect. That seems onerous.\r\n\r\nAs things are today, _any_ op that converts image dtype without range rescaling will _silently_ mess up the assumption that convert_image_dtype() will do your rescaling for you. And they all can't really do range rescaling automatically upon dtype conversion, because they don't know they are processing image data per se.\r\n\r\nBesides, how many people deal with HDR vs just plain JPEG? I bet not very many. And it's incredibly easy right now for the majority of TF users to get screwed by this. I bet most people don't even know about this unintended, but likely behavior, hence my extended comment above.\r\n\r\nI guess another, easier recommendation for folks who care about correctness of their computations would be to convert to float32 right after `decode_*()` op. But that will further slow down data augmentation, which is already quite a bit slower than e.g. Torch/PyTorch.", "We have made a choice to consider image data encoded as integer types to be fixed-point data. As you say, you could go the other way. Both have issues: Mostly, our image pipelines work in float, which is slower. On the other hand, if we computed things in uint8 (or int16, or int32) we'd be dealing with overflows and underflows in the middle of processing pipelines, and you'd probably see a lot more poor results because of that.\r\n\r\nThe fundamental problem is that some ops take the image values at face value (resize_image) when converting dtypes, while most don't (HSV2RGB, etc.). We cannot change much about the behavior because of compatibility constraints, but we can add an argument to resize_image to make it not convert to float and work in its input dtype only (there's no reason for it to convert to float).", "That sounds much better than the present situation, especially if the new parameter is prominently mentioned in the documentation. \r\n\r\nArguably, changing the dtype during rescaling (as well as in the composite op `tf.image.crop_and_resize()`) is the most aggravating problem with the status quo, because short of casting back to uint8_t again there's no way to avoid float for the parts of the pipeline that, strictly speaking, do not need float. For performance reasons, resize is typically done right after decode. \r\n\r\nAt a high level, I don't want to use any float32 until I _have_ to be in float32, i.e. in our case until after we do resize, crop, and flip (and, when implemented, rotate and shear as well -- these need not convert to float either). It certainly would be great if I could maintain compact uint8_t representation for as long as I can.\r\n\r\nIMO this problem is more important than it might appear. I can tell you that for us inability to do data augmentation quickly enough nearly killed TF as a viable option. Our more demanding training pipelines currently use PyTorch for data augmentation, a solution which, as an engineer, makes me cringe, but hey, it runs at nearly twice the speed doing the same thing.\r\n\r\nThere are a number of open issues in the issue tracker to that end, and being more frugal with cycles could help speed things up.", "I have changed the title of this to reflect that. I think this is an excellent feature request. The constraints are that we cannot change existing behavior, but adding a `maintain_dtype=False` arg and prominent documentation would be good.", "@martinwicke Have your thoughts evolved?", "No, still a good idea, and still a lot of work, and in some cases, hard to get right.", "This is really confusing, it appears that convert_image_dtype converts individual values from [0,255] to [0,1] range ONLY if the original type is int8 which unfortunately if the tensor is resized prior does not works because now the values are [0.0,255.0] ? \r\n\r\nIs this interpretation correct? \r\n\r\nI think convert_image_dtype documentation needs to be more explicit about this, I encountered this bug/issue when using a VGG model created by someone else which expected values in range (0,1).", "I believe convert_image_dtype scales the values iff it converts between an integer type to a float type. Integer types are assumed to be fixed point numbers, so (int8)(255) == (float)(1.0). It also expects float values to contain \"normalized\" images which contain numbers in the range [0,1).\r\n\r\nSo yes, if your original contains float values in the [0.0, 255.0) range, you have to rescale.\r\n\r\nIf there's a deficiency in the documentation, it would be good to make this more explicit.", "I've suffered the consequences of this unexpected value scaling during image type conversion also.\r\nI believe a better function name is urged. Maybe we could consider name it as `convert_image_dtype_with_scaling` .", "The docstring says: \r\n\r\n  Images that are represented using floating point values are expected to have\r\n  values in the range [0,1). Image data stored in integer data types are\r\n  expected to have values in the range `[0,MAX]`, where `MAX` is the largest\r\n  positive representable number for the data type.\r\n\r\n  This op converts between data types, scaling the values appropriately before\r\n  casting.\r\n\r\nIf you have suggestions on how it could be improved, I'd welcome a PR.", "Note that we cannot rename the function because that would break compatibility. We could make an alias, but in my opinion that would just add more confusion.", "I understand that the current docs has already tell the truth of it. I would suggest adding a optional parameter named `normalize=False`. Then, by default, `convert_image_dtype_with_scaling ` won't do the magic that is not in its name. And people can still expect to use this feature if they set `normalize=True`. I understand your point that there are image processing related hypothesis here about the `float` type. But I don't think it's a good idea to assume everyone agrees on that. ", "We could introduce a new parameter (though not with a behavior changing\ndefault), but wouldn't you simply use a regular cast if that's the behavior\nyou want? The purpose of this function is to manage conversion between the\ncommon representations of image values. And those are fixed point encoded\nvalues stored in integers and floating point values as described in the\ndocstring.\n\nEvery library dealing with images has to agree internally on a standard,\nand this is the one in TensorFlow (and btw., other libraries such as OpenGL\nhave as well, including the conversion rules).\n\nI understand that there may be images in other representations out there\n(in particular, floating point images with a 0..255 range), these need to\nbe scaled before they will work with TensorFlow functions.\n", "So, assuming I decode a jpeg image from the raw file stream, the first function I can think of about image type conversion is `convert_image_dtype`. I don't think people will think of `cast` in the first place since it's too general.\r\nI still think it's the name that hints people this is only about `dtype` which I think should be amended by parameters.  \r\n\r\nAbout the common standard in TensorFlow, I agree with your point. \r\n\r\nAs you have mentioned, there are different standards with different scale. My point here is that Float32 conversion and unit8 conversion at least should have the same behaviour. Both scaled or both not scaled. ", "Your image from decode is likely uint8. If you need float, you should use\nconvert_image_dtype. If you use cast, you'll get a float image scaled\n0..255, which isn't what you want, it won't work with a lot of TensorFlow's\nimage processing functions.\n\nNote that you can of course also leave the image as uint8, especially for\noperations such as cropping and transpose there's no harm in doing that in\nuint8.\n", "Yes, just like you said, the ambiguity lies in that my image from decode may or may not be uint8, which will cause a problem when considering the scaling issues. ", "But at least decode_jpeg will always return uint8. You should.always know\nthe dtype of.your input, as far as I know. How do you end up with an image\nfor which this is unknown?\n", "During optimization of our computing graph, we accidentally put an tf.float32 placeholder before the  conversion. I wouldn't say it's unknown. It definitely could be avoided in our side.", "Same issue.\r\n\r\n@martinwicke Do you have a plan to fix the issue? I think it's better to add a `range` argument for `convert_image_dtype()`.  Would you mind me make a PR for that?", "What would be the behavior of that argument? The target range? The input range? Do you need both?\r\n\r\nI agree that It is not ideal that range and dtype are coupled. I am however wary of introducing additional complexity here. How would an additional argument have helped here?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I'll close this issue. Please reopen if you have a concrete suggestion for improving the API.", "I just ran into this issue, which is a very long-standing bug that presents even these days (TF 1.13.x and 2.0). I strongly suggest it should be fixed (with some breaking changes in behavior) at TF 2.0, and the issue remain open. I will come up with a suggestion for improving API soon."]}, {"number": 1762, "title": "issue #1760 fixed", "body": "this fixes issue #1760 \n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins: test this please\n\n(Thanks!)\n"]}, {"number": 1761, "title": "Upstream changes from internal for April 2nd weekend", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 1760, "title": "TypeError in random.sample(np.array()), word2vec_basic.py with Python3.5", "body": "### Environment info\n\nOperating System:\nMacOS10.10.5 (14F1713)\n1. Which pip package you installed.\n    pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl\n   \n   git clone https://github.com/tensorflow/tensorflow\n   git checkout r0.7\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n    0.7.1\n3. `numpy.version.full_version`\n   \n     Out[4]: '1.11.0'\n   \n   _Installed as described above with  pip3_, running script from commit `263d00d`\n### Steps to reproduce\n\n```\n  python3 tensorflow/examples/tutorials/word2vec/word2vec_basic.py\n```\n### What have you tried?\n1. This simple example fails:\n    random.sample(np.arange(1000), 60)\n\nit looks like it relates to [this numpy issue](https://github.com/numpy/numpy/issues/2776)\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n```\nFound and verified text8.zip\nData size 17005207\nMost common words (+UNK) [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]\nSample data [5240, 3084, 12, 6, 195, 2, 3135, 46, 59, 156]\n3084 -> 5240\nb'originated' -> b'anarchism'\n3084 -> 12\nb'originated' -> b'as'\n12 -> 6\nb'as' -> b'a'\n12 -> 3084\nb'as' -> b'originated'\n6 -> 12\nb'a' -> b'as'\n6 -> 195\nb'a' -> b'term'\n195 -> 2\nb'term' -> b'of'\n195 -> 6\nb'term' -> b'a'\nTraceback (most recent call last):\n  File \"tensorflow/examples/tutorials/word2vec/word2vec_basic.py\", line 131, in <module>\n    valid_examples = np.array(random.sample(np.arange(valid_window), valid_size))\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/random.py\", line 311, in sample\n    raise TypeError(\"Population must be a sequence or set.  For dicts, use list(d).\")\nTypeError: Population must be a sequence or set.  For dicts, use list(d).\n```\n", "comments": ["Fix: line 131:\nbefore \n\n```\n valid_examples = np.array(random.sample(np.arange(valid_window), valid_size))\n```\n\nafter\n\n```\n valid_examples = np.array(random.sample(range(valid_window), valid_size))\n```\n", "Cool, thanks!  Do you want to send us a PR?\n", "Yes I will\n", "Thanks!\n"]}, {"number": 1759, "title": "[WIP] CuDNN Batch Normalization Op", "body": "This pull request is a WIP for adding a cudnn batchnorm op that works on NCHW data layout. Others and myself (https://github.com/tensorflow/tensorflow/issues/1502) have noticed very poor performance. Currently, the code is very rough and is just enough to do performance evaluations.\n\nCode used to create the following numbers can be found here (https://gist.github.com/lukemetz/bdb58d2f006b64fe234cb04f7f0e8185). I tested 3 variations: current batch norm implementation plus moments in NHWC (tf_NHWC), current batch norm implementation and moments in NCHW (tf_NCHW), and my proposed op in NCHW format (cudnn_NCHW). All tests done were done on a 980, and the number listed is time taken for 100 iterations computing forward and backward passes.\n\n| Shape | tf_NHWC | tf_NCHW | cudnn_NCHW | percent faster tf_NHWC | percent faster tf_NCWH |\n| --- | --- | --- | --- | --- | --- |\n| (32, 8, 8, 32) | 125.5 ms | 196.8 ms | 85.6 ms | 47% | 130% |\n| (128, 4, 4, 32) | 133.4 ms | 171.7 ms | 77.1 ms | 73% | 123% |\n| (256, 16, 16, 32) | 648.7 ms | 4624.5 ms | 388.6 ms | 67% | 1090% |\n| (128, 64, 64, 32) | 4900.5 ms | 37107.5 ms | 3011.5 ms | 63 % | 1132% |\n| (128, 128, 128, 32) | 19087.1 ms | 171175.2 ms | 11815.6 ms | 62% | 1349% |\n\n(Note:  in my experience it is faster to transpose batchnorm transpose instead of using NCHW moments and batchnorm.)\n\nWhen testing on an largish net on a single GPU, there are also performance improvements. My test network is an 8 layer residual-like network on 32x32 images with batchsize 128. \n\nNCHW batchnorm and HCHW convs: approximately 2700 examples a second. \n\nNHWC with Tensorflow implementation and NHWC convs: approximately 1900 examples a second. \n\n(Note: this difference is in large part to do with using NCHW convolutions with no transposes, but this was not possible before a fast NCHW batchnorm.)\n\nThe one odd thing I have encountered is that performance takes a hit when using multiple GPUs with data parallelism. . . It is actually slower than using a single GPU. If anybody has an idea as to why, or solutions, I would love to know. To my knowledge each GPU has one cuda stream so the cudnn locks shouldn't interfere with each other ???\n\nIf the concept behind this PR looks good, let me know. I wanted to share results early but there is a still a lot to do in terms of cleanup/standardization, error checking, testing, and documentation as well as a front end python api.\n\nThanks, all. Any comments appreciated.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Awesome!  At a high level these numbers sound great to me, but we can't really take too much of a look until the CLA is signed.  If this makes sense, we'd be happy to work with you to get these changes in.\n\n@vincentvanhoucke @zheng-xq @benoitsteiner as an early heads up.\n", "Thanks for the help!\nI signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "This looks very good from my POV. @vrv how do we handle stream executor changes like this?\n", "I think we now just accept them and we'll figure out how to backport them to the open source stream executor.  Unfortunately the best person to review this change is @zheng-xq who is out of the office this week and next.  I could offer style / tests suggestions, but I'd rather do that only after the high level review has been done.\n", "Did you try using cudnn for NHWC (by adding a transpose, for example) as well? It will be very helpful if cudnn can beat the current kernel in both cases.\n", "@ppwwyyxx I have not yet. There is some special code to do fast NHWC -> NCHW used in their convolutions I need to add. My guess is that it will be comparable speeds but a well designed fused kernel with no transposes should always do the best.\n", "@zheng-xq did you have a chance to look at this?\n", "@lukemetz, thank you for the contribution!\n\nI've put in my first round of comments. We can go through more details later. \n", "Thank you for the comments @zheng-xq. When I can find time I will fix and add where necessary and will ping back.\n", "Hi @lukemetz, any updates?\n", "Work / life has been a bit hectic lately. Sorry for the long delay.\nI think I addressed all of the comments as well as added a few tests.\n\nWhat still needs to be done (possibly not this PR):\n1.) Adding support for inference.\n2.) fully connected (2D) batch normalization -- should this be a separate op? If not, what should be done with data_format?\n\nLet me know what else needs to be fixed and thanks for the help.\n@vrv @zheng-xq\n", "So I recompliled from source based on the pull request.\nSeveral problems with the code:\n1. `tf.nn.batch_norm_training` only returns `output` while the docstring says it returns `output`, `mean` and `inv_var`. Also several typos in the docstring\n2. Shape info is lost on the three variables mentioned above after `batch_norm_training`; had to manually set the shape afterwards\n3. Seems to be sensitive against small epsilon. Something as \"big\" as 1e-5 gives cudnn launch error\n4. This one is important: **gives OOM error** after fixed number of executions. On my 980 Ti, the test code in OP stops at `i=81` in the warmup when I set `shape = [128, 32, 32, 128]`\n", "Also, I had to manually normalize the input using the returned `mean` and `inv_var` to make the back pass work. Simply using `batch_norm_training` will lead to the correct `output` but the gradients aren't actually back propagated past the BN layer. Can anyone confirm this?\n", "Thanks for trying this out @metap. Sorry things didn't go so well. I guess I was a little to hasty in my latest update...\n1. Yep forgot to update doc string and will proof.\n2. noted and will fix.\n3. cudnn only supports large-ish (1e-4) epsilon. There should be check for this in the op but as to the actual value that is out of my control.\n4. Not sure what is going on here. My guess is my miss use of the temporary memory allocator when allocating temp variables for running_mean and running_inv_var. I will look into it.\n\nFinally, about the gradients, I thought I had a test in place to ensure that they were correct. I guess I assumed that there gradient testing utilities were a bit too magical. Are the gradients incorrect or are they just Nones?\n", "The gradients computed via `tf.gradients()` are actually correct as in the test file in OP, but they aren't being back propagated further down to earlier layers in actual networks. (I get zero gradients past a BN layer)\n", "Could `tensorflow/core/kernels/cudnn_batchnorm_op.cc` line 393 to 395 be related to 4? I don't see it being used after allocation\n", "That is certainly wrong / shouldn't be there. Good catch. It might fix the issue?\n", "Yeah removing the three lines fixed 4. The gradient issue is still unfixed, unfortunately\n", "@lukemetz, thank you very much for the code improvement! It is awesome to hear about the performance gain. \n\nThere are a few comments at the bottom. Some of them are regarding the interface of this op. Because TensorFlow promises backward compatibility on TF core, it is difficult to change the op interface once the code is in TF core. \n\nOn the other hand, we would like to merge in this code as soon as possible so more people can benefit and help improve. How about checking the same code into TF contrib for now? I think we would be able to merge with very little modifications. And after we iron out the details, the TF team will help integrate the change back into the TF core. \n\nDetailed comments: \n1. Lack of CPU implementation. \n2. We do not want a separate training and inference op. The same op should check whether \"save_mean\" and \"saved_inv_var\" are actually used before picking the \"training\" and \"inference\" version. \n3. We don't want stream-executor to allocate any memory. TensorFlow has a much more efficient memory management system. So this should be done through ScratchAllocator. \n4. Ongoing discussion whether to expose the running mean and average, and measure the performance impact. \n5. We need to test more common shapes to verify the results. \n", "By the way the same API function `cudnnBatchNormalizationForwardTraining` uses running var in CuDNN 5004 but running **inv** var in CuDNN 4007.\n", "Thanks for the comments @zheng-xq. I will move the ops and kernels to contrib and make updates there. Correct me if I am wrong, but there is no stream executor equivalent in contrib?\n\nGood catch @metap. I think I will just move to V5 then.\n", "@lukemetz, unfortunately, there is no contrib equivalent of stream_executor. However, since your change is mostly addition, so that should be fine. \n\nAlso there are a lot of people still using V4, so we should make sure both are functionally correct. TensorFlow in general makes sure at least two versions are supported. \n", "@lukemetz any updates?\n", "Any progress?\n", "I am very sorry I haven't had time to work on this. I am in the midst of finishing one job and moving across country to start a new one (at Google). As a result I have had very little free time to devote to this. I will try to find some time to make the updates soon.\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "In the process of moving to contrib I ran into an issue with dynamic library loading that I am unsure how to fix. It appears my shared library is trying to register stream executor plugins that have already been registered. Is it something todo with the deps? (https://github.com/tensorflow/tensorflow/pull/1759/files#diff-246fc971a7ed6b0336891e4933f47651R15)\n\n```\nE tensorflow/stream_executor/cuda/cuda_blas.cc:2275] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:2128] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nF tensorflow/stream_executor/cuda/cuda_platform.cc:180] Check failed: ::perftools::gputools::port::Status::OK() == (MultiPlatformManager::RegisterPlatform(std::move(platform))) (OK vs. Internal: platform is already registered with name: \"CUDA\")\nAborted (core dumped)\n```\n\nThanks for the help.\n", "Not sure what the status of this is, but presumably it's almost ready now?  We don't get notifications when you push commits, unfortunately.\n", "What is the status of this?\n", "Closing -- we're going to hopefully handle this internally -- it requires some fairly sophisticated changes to do this in a clean way, from what I've been told, since you want to do different things when you know the output during training is used or not.\n", "What is the expected time frame for this to be integrated?\n"]}, {"number": 1758, "title": "Network Surgery: Changing Inputs in existing networks", "body": "I am trying to modify an existing graph (inception) loaded using the standard approach \n\n```\nwith gfile.FastGFile(os.path.join(\n      model_dir, 'classify_image_graph_def.pb'), 'r') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    _ = tf.import_graph_def(graph_def, name='')\n```\n\nThe nodes are accessible using the `get_tensor_by_name` method. Here I try to replace the input to `Cast` (which is `DecodeJpeg`) with a `tf.Variable` with the same contents (allowing it to be used for optimization)\n\n```\nold_cast_node = sess.graph.get_tensor_by_name('Cast:0')\nold_image_input = old_cast_node.op.inputs[0]\ntf_new_image = tf.Variable(old_image_input.eval())\nold_cast_node.op.inputs[0] = tf_new_image\n```\n\nResults in this error\n\n```\nTypeError: '_InputList' object does not support item assignment\n```\n\nCan the inputlist of an op be modified in any other way?\n", "comments": ["The [`tf.import_graph_def()`](https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#import_graph_def) function provides the only (supported) way to perform this surgery, via the optional `input_map` argument.\n\nLet's say you want to replace the tensor `\"DecodeJpeg:0\"` with your new variable. You would do something like the following:\n\n``` python\ngraph_def = ...\ntf_new_image = tf.constant(...)\n_ = tf.import_graph_def(graph_def, input_map={\"DecodeJpeg:0\": tf_new_image})\n```\n", "Thanks I had briefly tried this before with both `DecodeJpeg:0` and the following node `Cast:0`, but it wasn't able to calculate the gradients\n\nLoading the network works fine\n\n```\nwith gfile.FastGFile(os.path.join(\n  my_model_dir, 'classify_image_graph_def.pb'), 'r') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    tf_new_image = tf.Variable(image_arr.astype(np.float32))\n    _ = tf.import_graph_def(graph_def, name='', input_map={\"Cast:0\": tf_new_image})\n    c_graph = graph_def\n```\n\nBut trying to have the optimizer change the input to improve the output (making the image more panda-like) did not work\n\n```\nppanda = np.zeros(predictions.shape,np.float32)\nppanda[0,169] = 1 # perfect panda\ntf_ppanda = tf.constant(ppanda)\nsoftmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\npanda_loss = tf.nn.softmax_cross_entropy_with_logits(softmax_tensor, tf_ppanda)\noptimizer = tf.train.GradientDescentOptimizer(0.05).minimize(panda_loss)\n```\n\nSaying the gradient is not computable\n\n```\nValueError: No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x117c33c90>), (None, <tensorflow.python.ops.variables.Variable object at 0x140965f90>), (None, <tensorflow.python.ops.variables.Variable object at 0x13b59ff10>))\n```\n\nEven explicitly listing the variable in `var_list` didn't fix the issue\n\n```\noptimizer = tf.train.GradientDescentOptimizer(0.05).minimize(panda_loss, var_list = [tf_new_image])\n```\n\nresulting in \n\n```\nValueError: No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x13b59ff10>),)\n```\n\nMy final attempt was to explicitly pull it from the graph \n\n```\ntf_input_image = sess.graph.get_tensor_by_name('Cast:0')\noptimizer = tf.train.GradientDescentOptimizer(0.05).minimize(panda_loss, var_list = [tf_input_image])\n```\n\nResulting in the expected Type mismatch\n\n```\nTypeError: Argument is not a tf.Variable: Tensor(\"Cast:0\", shape=(100, 100, 3), dtype=float32)\n```\n", "I found the problem, one of the operators after DecodeJpeg is not differentiable (or at least not implemented in TF) so the gradient cannot be computed.\n\nPresumably Cast or Resize, but I haven't checked. Starting at Sub:0 works fine though\n\n```\nTensor(\"Sub:0\", shape=(1, 299, 299, 3), dtype=float32)\nTensor(\"ResizeBilinear:0\", shape=(1, 299, 299, 3), dtype=float32)\nTensor(\"ExpandDims:0\", shape=(1, ?, ?, 3), dtype=float32)\nTensor(\"Cast:0\", shape=(?, ?, 3), dtype=float32)\n```\n", "@mrry Hi, I have a model for image recognition, it needs 2 tensors input (one is the input image tensor, and the other is a binary FLAG to determine whether to perform training/testing)\nHowever, when implemented in C++, these 2 tensor input caused me a lot of troubles!\nSo I 'm wondering if there are any methods that can help me modify the input(I only need the image input tensor, and the FLAG can be set to constant, since I only want to do inference in C++). And I don't want to retrain the model again...\nCould you give me some advice on this problem? \nThanks a lot!\n", "@TianweiXing: Can you post this as a question on Stack Overflow? We're using it to track problems that are not bugs or feature requests.\n", "Regarding using `tf.import_graph_def` it doesn't import savers  or variables right - only the op structure of graph?\r\nIn case I would need to reuse part of someone else network and change something - I would have to manually create savers/loaders to load variable values into that loaded (and modifed network)?\r\n\r\nI'm trying to make tf library of \"model parts\" however I'm strugling since not single way of saving models is suitable for it.\r\n\r\nEDIT:\r\nI think i would make sense to allow the same modification using `import_meta_graph `", "Since, it took me way too much time to find it - and it may help someone - it turns out that `import_meta_graph` passes all additional arguments to the underlying `import_scoped_meta_graph` which **has** the `input_map` argument and utilizes when it gets to it's calling of `import_graph`. So, **yes** you can have modify graph while loading with `import_meta_graph`!", "Will this replace all inputs up to that point?  I have an input pipeline scoped under \"input\".  I was hoping I could use input_map; but needed to target just a specific section of the graph for inference.  I want to basically just delete the 'input' scope of the graph and replace the input for the Conv1 op to have the new input...", "How are you supposed to do this with c++? I don't see anything similar.", "@thejonan Is it possible to import a trained model, say inception v3 which only accepts 3-channel images and modify the first convolutional layer to accept an n-channel image stack?", "Just a FYI, I just checked modification on \"Cast:0\" is not working. "]}, {"number": 1757, "title": "Running out of memory, even on small network", "body": "Operating System: Ubuntu 14.04 on a PC\nPip Installation: 64-bit, GPU-enabled, Version 0.7.1\n\n---\n\nMy issue is that Tensor Flow is running out of memory when building my network, even though based on my calculations, there should easily be sufficient room on my GPU.\n\nBelow is a minimal example of my code, which is based on the Tensor Flow MNIST tutorial. The network is a two-layer fully-connected network, and the number of nodes in the hidden layer is defined by the variable `n`. The size of the training minibatch is 1. Here is my code:\n\n```\nn = 23000\n\nmnist = read_data_sets('MINST_Data', one_hot=True)\nsession = tf.InteractiveSession()\nx = tf.placeholder(tf.float32, [None, 784])\nW1 = tf.Variable(tf.truncated_normal([784, n], stddev=0.1))\nb1 = tf.Variable(tf.constant(0.1, shape=[n]))\nnn1 = tf.matmul(x, W1) + b1\nW2 = tf.Variable(tf.truncated_normal([n, 10], stddev=0.1))\nb2 = tf.Variable(tf.constant(0.1, shape=[10]))\nnn2 = tf.matmul(nn1, W2) + b2\ny = tf.nn.softmax(nn2)\ny_ = tf.placeholder(tf.float32, [None, 10])\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\nfor i in range(1000):\n  batch_xs, batch_ys = mnist.train.next_batch(1)\n  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n```\n\nNow, if `n <= 22000`, then the network runs fine. However, if `n >= 23000`, I get the following error:\n\n```\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n```\n\nHowever, according to my calculations, there should not be a problem with the memory. The number of parameters in the network is as follows:\n\n```\nFirst layer weights: 784 * n\nFirst layer biases: n\nSecond layer weights: 10 * n\nSecond layer biases: 10\nTotal: 795n + 10\n```\n\nSo with `n = 23000`, and using `float32` data, the total memory required for the network should therefore be 73.1 MB.\n\nNow, my graphics card is the NVIDIA GeForce GTX 780 Ti, which has 3072 MB of memory. After finding my graphics card, Tensor Flow prints out the following:\n\n```\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\n```\n\nSo, there should be around 2.32 GB memory available, which is far greater than the 73.1 MB calculated above. The minibatch size is 1, so this has minimal effect. Why am I getting this error?\n\n---\n\nI have also now tried this on my laptop, which has an NVIDIA GeForce GTX 880M GPU. Here, Tensor Flow reads out `Free memory: 7.60GiB`. Running the same code as above, it gives me a memory error at around `n = 700,000`, which is equivalent to 2.2 GB. This makes a bit more sense, and is significantly higher than the point at which my PC code breaks. However, it is still puzzling to me why it does not break closer to the 7.6 GB mark.\n\n---\n\nThe full output from Tensor Flow whilst running the above code on my PC, with `n = 23000`, is:\n\n```\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 780 Ti\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0455\npciBusID 0000:01:00.0\nTotal memory: 3.00GiB\nFree memory: 2.32GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 2.03GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb04720000 extends to 0xb86295000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (524288):    Total Chunks: 2, Chunks in use: 0 819.0KiB allocated for chunks. 390.6KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (134217728):     Total Chunks: 1, Chunks in use: 0 68.79MiB allocated for chunks. 29.91MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (536870912):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1073741824):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2147483648):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4294967296):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:450] Bin for 877.38MiB was 1.00GiB, Chunk State: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d239400 of size 80128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d24cd00 of size 438528\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a302800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15d58800 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15e39200 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c16b00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c61500 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736d00 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8100 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c4ad00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736a00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7900 of size 400128\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720200 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736c00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7600 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3300 of size 1810570496\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1c0c00 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c00300 of size 92160\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb11781700 of size 72128000\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77e00 of size 920064\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:468]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 16 Chunks of size 256 totalling 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 80128 totalling 78.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 92160 totalling 450.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 400128 totalling 390.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 438528 totalling 428.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 4 Chunks of size 920064 totalling 3.51MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 72128000 totalling 343.93MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 1810570496 totalling 1.69GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 2.03GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state\nW tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x50f40e0 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: Cast/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_96_Cast\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 232, in <module>\n    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 315, in run\n    return self._run(None, fetches, feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 511, in _run\n    feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _do_run\n    target_list)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 586, in _do_call\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,23000]\n     [[Node: add = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MatMul, Variable_1/read)]]\n     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_97_range_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'add', defined at:\n  File \"/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py\", line 215, in <module>\n    nn1 = tf.matmul(x, W1) + b1\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 468, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 44, in add\n    return _op_def_lib.apply_op(\"Add\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n```\n", "comments": ["\"Resource exhausted: OOM when allocating tensor with shape[10000,23000]\"\n\nDo you use a batch_size 10000?   Or the error came from the 10000 test images?\n\nUse small batch size such as 128. \n\nHope it helps you\n", "Thanks for your reply. No, I use a batch size of 1 here, just for debugging; it seems that the error is nothing to do with the training batch, and more to do with reserving room for the weights.\n\nThe batch size is defined in the line `batch_xs, batch_ys = mnist.train.next_batch(1)`\n\nI'm a little confused where the tensor with `shape[10000,23000]` comes from... The weights in the first layer should be [724,23000], and in the second layer they should be [23000,10].\n\nEven still, it seems strange that this relatively small network, with a batch size of 1, will cause a memory issue....\n", "1) https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/graph_metrics.py might help you figure out some stats about your model\n\n2) For training you're also going to need to account for the memory used by gradient update tensors -- graph_metrics.py should help you a little.\n\nIt's definitely possible we're using more memory than we ideally could, but we're going to need more data to understand where we can improve.\n", "You are probably encountering an all to common problem with Tensors secretly conspiring to broadcast. I don't know where 10000 comes from, but the fact that you have a sudden large matrix where you expected only long vectors is typical. \n\nI will close this issue for now. Please comment if you have more evidence for an actual bug. Or create a new issue if you uncover something else.\n", "definitely the same problem.  What does secretly conspiring to broadcast mean and would you mind telling us the fix?", "See here for more information on broadcasting: \r\nhttps://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html", "I am having the same problem with models/lenet model on a NVIDIA P100 (16 GB). ", "With tf version 1.0.1 you can use https://github.com/yaroslavvb/memory_util to see what tensors are being allocated/deallocated. One source of memory surprise is storage needed for intermediate activations. For instance, if you have tensor, and then do 2*tensor, it may end up storing both \"tensor\" and \"2*tensor\" in memory since both quantities are needed to do (unoptimized) backpropagation", "Thanks for suggestion. In my case, I was restoring the model (multiple times) and it was creating the problem. Now, it is solved. ", "@ahmetkucuk  I am having the same \"resource exhausted\" problem. Could you please explain more elaborately how did you solve the problem?", "@ahmetkucuk I am getting similar OOM error on GPU and I see I am also restoring model multiple times during training to evaluate on dev set. How did you fix this?", "I am facing the same issue. Batch size is set at 1. Could you please explain how you've resolved this?", "tf.GPUOptions(per_process_gpu_memory_fraction=1) This had caused my problem", "I have the same problem I am using  GeForce RTX 2080 and i only able to train small data set on batch size of 8?  can any one help me ?", "same problem. I have GeForce GTX 1070 Ti 8GB.  batch_size 1, num_classes 1, 100 images. Did anyone fix this issue?", "For future reference: Switching to Tensorflow 2 without changing other parts of the code can result in this behavior.\r\nWhen I was getting this error earlier  today (with plenty of memory left), it's because I pulled Tensorflow 2, when the code was intended for Tensorflow 1.14.  Switching to the proper TF version made the OOM errors go away and the code trains well. \r\nIn fact, earlier today I was getting OOM even for batch_size=1, now I can go up to batch_size=16. \r\n(will have to update other parts of the code later!) "]}, {"number": 1756, "title": "Ran out of memory trying to allocate.....", "body": "Operating System: Ubuntu 14.04\nTensor Flow: 0.7.1 (install with pip, 64-bit GPU version)\n\nMy issue is that Tensor Flow is telling me that it has run out of memory when constructing my Convolutional Neural Network. However, according to my calculations, my network should be able to fit well within the memory of my GPU.\n\nHere is my network structure:\n\n> ```\n> Input image: 256x256, one channel\n> Convolutional layer 1: 48 filters of size 11x11, max pool with 4x4 kernel and 4x4 stride\n> Convolutional layer 2: 128 filters of size 5x5, max pool with 2x2 kernel and 2x2 stride\n> Convolutional layer 3: 128 filters of size 3x3, no max pool\n> Fully-connected layer 4: 128 * 32 * 32 input nodes and 1024 output nodes\n> Fully-connected layer 5: 1024 input nodes and 10 output nodes\n> ```\n\nSo, according to my calculations, the number of parameters are as follows:\n\n> ```\n> Convolutional layer 1: 48 * 11 * 11 + 48 = 5,856\n> Convolutional layer 2: 128 * 48 * 5 * 5 + 128 = 153,728\n> Convolutional layer 3: 128 * 128 * 3 * 3 + 128 = 147,584\n> Fully-connected layer 4: 128 * 64 * 64 * 1024 + 1024 = 536,871,936\n> Fully-connected layer 5: 10 * 1024 + 10 = 10,250\n> \n> \n> Total:  537,189,354 (~ 2150 MB with float32 data)\n> ```\n\nAnd the memory required (number of nodes) to store one image on the network is:\n\n> ```\n> Input: 256 * 256 = 65,536\n> Convolutional layer 1: 48 * 256 * 256 = 3,145,728\n> Convolutional layer 2: 128 * 64 * 64 = 524,288\n> Convolutional layer 3: 128 * 32 * 32 = 131,072\n> Fully-connected layer 4: 1024\n> Fully-connected layer 5: 10\n> \n> Total:  3,802,122 (~ 1.52 MB with float32 data)\n> ```\n\nSo the shared parameters require 2150 MB of memory, and each image requires 1.52 MB of memory.\n\nNow, my graphics card is the NVIDA GeForce GTX 780 Ti, which has 3072 MB of memory. However, when I run the above network, even with a training minibatch size of 1, I get the following error form Tensor Flow:\n\n> ```\n> Ran out of memory trying to allocate 600.0KiB.\n> Compute status: Resource exhausted: OOM when allocating tensor with shape[5,5,48,128]\n> ```\n\nWhy am I getting this error? According to my calculations, the weights for the network should be able to fit on my GPU, even without any training images.\n\n---\n\nThe full output from Tensor Flow can be found here: https://jpst.it/GKtY\n", "comments": []}, {"number": 1755, "title": "anaconda environment: install of protobuf library does not work ", "body": "Hello,\nI tried to install the special package of protobuf as proposed in [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#protobuf-library-related-issues). I get errors \n### Environment info\n\nOperating System: MAC OSX Yosemite 10.10.5 (14F1713)\n\nIf installed from binary pip package, provide:\n1. I use anaconda environment\n2. created environment like \"conda create -n tf python=2.7\"\n3. activated environment with \"source activate tf\"\n4. installed easy_setup with \"sudo -H curl https://bootstrap.pypa.io/ez_setup.py -o - | python\"\n5. installed tensorflow with \"sudo -H pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl\"\n6. tested if I can import tensorflow from python. OK, no problem\n7. installed protobuf by \"pip install --upgrade https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp27-none-any.whl\"\n8. tested again if I can import tensorflow in python. NOK\n\nterminal showed\nFile \"/Users/peterhirt/anaconda/envs/tf1/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 46, in <module>\n    from google.protobuf.pyext import _message\nImportError: dlopen(/Users/peterhirt/anaconda/envs/tf1/lib/python2.7/site-packages/google/protobuf/pyext/_message.so, 2): Library not loaded: /usr/local/lib/libprotobuf.10.dylib\n  Referenced from: /Users/peterhirt/anaconda/envs/tf1/lib/python2.7/site-packages/google/protobuf/pyext/_message.so\n  Reason: image not found\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n\nRepeated above flow twice in newly created envs to see if problem repeatable, yes ;-(\n\nthanks for the help\n", "comments": ["I encounter the same issue on OS X 10.10\n", "I have the same problem using `virtualenv` on El Cap as well.\n\nAs far as I can tell this issue is caused by the custom protobuf binary not containing the C++  implementations as claimed in the [instructions](https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#common-problems). I have not been able to find `libprotobuf.10.dylib` in any of the locations pip installs packages to.\n", "I was able to resolve this issue by getting the [C++ release](https://github.com/google/protobuf/releases/download/v3.0.0-beta-2/protobuf-cpp-3.0.0-beta-2.zip) of protobuf 3.0.0 from the release [page](https://github.com/google/protobuf/releases/tag/v3.0.0-beta-2) and building it locally by: \n\n```\n./configure\nmake \nmake install\n```\n\non my machine with El Cap and Xcode 7.3 installed, this went without a hitch and produced `libprotobuf.10.dylib` (among other things) under `/usr/local/lib` resolving the error when importing tensorflow in Python. \n\nI don't know if this problem is widespread but it's probably a good idea to update the instructions [here](https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#common-problems)\n", "Sorry for the late response. But yes, you need libprotobuf installed on your machine for the C++ extension in the python package to work. I will update the instructions to reflect that.\n", "Closed due to inactivity.\n"]}, {"number": 1754, "title": "fix cuda warning", "body": "I see this error message when compiling with nvcc 7.5 \n", "comments": ["Can one of the admins verify this patch?\n", "Please verify that this doesn't break nvcc 7.0 and we'll re-open, thanks!\n"]}, {"number": 1753, "title": "correcting bottleneck residual function", "body": "As described in He _et al._ [1] the first 1x1 convolution inside the bottleneck architecture reduces the dimension to save FLOPs. Hence the correct number of filters is `block.bottleneck_size` instead of `block.num_filters`.\n\n<img width=\"1081\" alt=\"06cf6894-d197-11e5-8f2f-33d48c225961 2\" src=\"https://cloud.githubusercontent.com/assets/1241240/14230730/5db7a902-f931-11e5-826a-3074cbd85618.png\">\n\n[1] http://arxiv.org/pdf/1512.03385.pdf\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please.\n", "Thanks, good catch!\n"]}, {"number": 1752, "title": "Refactor skflow", "body": "So far:\n- Moved ConfigAddon -> RunConfig and capture more about run (tf_master and tf_random_seed).\n- Switched skflow trainer to use layers/optimizers and removed Trainer classes\n- Switch to gfile for file operations.\n- Move creation of placeholders into DataFeeders\n- Correcting / enabling examples.\n", "comments": ["@tensorflow-jenkins test this please.\n", "Jenkins, test this please.\n", "@martinwicke @vrv Okay to merge? We need the changes to fix the pylit sanity errors. \n", "There were changes so we have to re-test.\n\n@tensorflow-jenkins test this please\n"]}, {"number": 1751, "title": "master branch building problem", "body": "when using bazel (0.20 or 0.21 or master) to build tensorflow master branch, the process get stalled on Analyzing....\n", "comments": ["It seems to work in our tests. Can you provide more information? Is this still an issue?\n", "Closing for now, please comment with more information if it's still an issue.\n", "Trigger last updated\n"]}]