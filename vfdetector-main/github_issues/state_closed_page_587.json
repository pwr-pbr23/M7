[{"number": 36068, "title": "Fix incorrect code example in assert_shapes docstring", "body": "The docstring of `tf.debugging.assert_shapes()` includes a code example, but this example isn't valid python. This PR fixes the docstring code example to the correct syntax.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36068) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 36067, "title": "saved_model_cli breaks nightly packages", "body": "Our in-house nightly builds were broken since 2020-01-16 when auditwheel tries to repair my nightly packages. The reason under the hood seems to be an incorrect link from the recent change of adding XLA support to `saved_model_cli` in 9959c04433623e0b7ebf6248e0f75bc7a24bd7cb.\r\n\r\nInstall the latest nightly, and navigate to the directory of `tensorflow_core/compiler/aot`:\r\n\r\n```\r\n$ ldd _pywrap_tfcompile.so\r\n\tlinux-vdso.so.1 (0x00007ffc5e064000)\r\n\tlibtensorflow_framework.so.2 => /usr/local/lib/python3.7/dist-packages/tensorflow_core/compiler/aot/./../../libtensorflow_framework.so.2 (0x00007fa798bba000)\r\n\t_pywrap_tensorflow_internal.so => not found\r\n\tlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fa798b77000)\r\n\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fa798b56000)\r\n\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fa7989d1000)\r\n\tlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007fa79884d000)\r\n\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fa798833000)\r\n\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fa798672000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x00007fa79afbc000)\r\n\tlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fa798668000)\r\n```\r\n\r\nObviously it links to `_pywrap_tensorflow_internal.so` but it is not found with the relative path.\r\n\r\nPS: we are using auditwheel==3.0.0 to produce manylinux2014 builds, but the official tf-nightly uses an older version which fails to catch this.\r\n\r\nPPS: directly using `saved_model_cli` does not give this error as `_pywrap_tensorflow_internal.so` seems to be preloaded. But I am pretty sure this is a bug that we need to fix.\r\n\r\nPing @ebrevdo @mihaimaruseac.", "comments": ["The reason seems to be that `tf_python_pybind_extension` should only be used for packages in `//tensorflow/python/...` but it is used in `//tensorflow/compiler/..` in this case.\r\n\r\nPing @av8ramit to double check.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorflow.bzl#L2573-L2577.", "I think we can move pywrap_tfcompile to python/", "I have a solution; gonna get it through internal reviews and then will ping you when it's available.", "@byronyi let me know if this doesn't work for you."]}, {"number": 36066, "title": "Add TEST code for int16 Ops: {SPLIT, SQUEEZE, RESHAPE, EXPAND_DIMS}", "body": "This PR is one of steps to extend TFLite to support symmetric 16-bit activations.\r\n \r\nIn this PR we introduce tests for INT16 operators list below:\r\n  - SPLIT\r\n  - SQUEEZE\r\n  - RESHAPE\r\n  - EXPAND_DIMS", "comments": ["Hi @suharshs @jdduke\r\nCould you please review this?\r\n\r\nAs discussed, this is relative to INT16 reference kernel reference function.\r\nI group this 4 Ops together, since we only changed TEST for INT16.\r\nThanks!", "rebased on master to resolve conflict."]}, {"number": 36065, "title": "tf.keras MobileNetV2 with weights=None fails to train", "body": "**System information**\r\n- Google Colab notebook\r\n- TensorFlow version: 2.1.0-rc1\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0.130\r\n- GPU model and memory: Tesla T4 12 GB\r\n\r\n**Describe the current behavior**\r\nBased on the tutorial: https://www.tensorflow.org/tutorials/images/transfer_learning#format_the_data\r\n\r\nStart running the cells inside the notebook of the tutorial.\r\n\r\n _#Create the base model from the pre-trained model MobileNet V2_\r\n```\r\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\r\n                                               include_top=False,\r\n                                               weights=None)\r\n\r\nbase_model.trainable = True\r\n```\r\nThen trained the model for 10 epochs, with the parameters specified in the tutorial, but the validation loss does not go down, the accuracy remains stuck. \r\n\r\nThe results of training:\r\n`Epoch 1/10\r\n582/582 [==============================] - 87s 149ms/step - loss: 0.6606 - accuracy: 0.5788 - val_loss: 0.6953 - val_accuracy: 0.5216\r\nEpoch 2/10\r\n582/582 [==============================] - 80s 138ms/step - loss: 0.6157 - accuracy: 0.6425 - val_loss: 0.7064 - val_accuracy: 0.5216\r\nEpoch 3/10\r\n582/582 [==============================] - 81s 139ms/step - loss: 0.5765 - accuracy: 0.6769 - val_loss: 0.7014 - val_accuracy: 0.5216\r\nEpoch 4/10\r\n582/582 [==============================] - 81s 139ms/step - loss: 0.5378 - accuracy: 0.7143 - val_loss: 0.7488 - val_accuracy: 0.4784\r\nEpoch 5/10\r\n582/582 [==============================] - 81s 139ms/step - loss: 0.5072 - accuracy: 0.7368 - val_loss: 0.8380 - val_accuracy: 0.4784\r\nEpoch 6/10\r\n582/582 [==============================] - 80s 138ms/step - loss: 0.4777 - accuracy: 0.7601 - val_loss: 0.9534 - val_accuracy: 0.4784\r\nEpoch 7/10\r\n582/582 [==============================] - 81s 138ms/step - loss: 0.4354 - accuracy: 0.7894 - val_loss: 1.0138 - val_accuracy: 0.4784\r\nEpoch 8/10\r\n582/582 [==============================] - 81s 138ms/step - loss: 0.3937 - accuracy: 0.8110 - val_loss: 1.2038 - val_accuracy: 0.4784\r\nEpoch 9/10\r\n582/582 [==============================] - 80s 138ms/step - loss: 0.3593 - accuracy: 0.8288 - val_loss: 1.7442 - val_accuracy: 0.4784\r\nEpoch 10/10\r\n582/582 [==============================] - 81s 139ms/step - loss: 0.3166 - accuracy: 0.8547 - val_loss: 1.6888 - val_accuracy: 0.4784`\r\n\r\n![image](https://user-images.githubusercontent.com/60096583/72727499-ba4c1100-3b93-11ea-818e-531f342382d8.png)\r\n\r\n**Describe the expected behavior**\r\nIf MobileNet V1 is used instead, with the same weight initialization and same training parameters, the results are the following:\r\n\r\n`Epoch 1/10\r\n582/582 [==============================] - 74s 126ms/step - loss: 0.6596 - accuracy: 0.5840 - val_loss: 0.7098 - val_accuracy: 0.5216\r\nEpoch 2/10\r\n582/582 [==============================] - 70s 120ms/step - loss: 0.6310 - accuracy: 0.6248 - val_loss: 0.6099 - val_accuracy: 0.6483\r\nEpoch 3/10\r\n582/582 [==============================] - 71s 122ms/step - loss: 0.6102 - accuracy: 0.6479 - val_loss: 0.6191 - val_accuracy: 0.6858\r\nEpoch 4/10\r\n582/582 [==============================] - 70s 121ms/step - loss: 0.5850 - accuracy: 0.6729 - val_loss: 0.5983 - val_accuracy: 0.6634\r\nEpoch 5/10\r\n582/582 [==============================] - 71s 122ms/step - loss: 0.5620 - accuracy: 0.6954 - val_loss: 0.6043 - val_accuracy: 0.6573\r\nEpoch 6/10\r\n582/582 [==============================] - 71s 122ms/step - loss: 0.5383 - accuracy: 0.7128 - val_loss: 0.5575 - val_accuracy: 0.6935\r\nEpoch 7/10\r\n582/582 [==============================] - 71s 122ms/step - loss: 0.5179 - accuracy: 0.7291 - val_loss: 0.6238 - val_accuracy: 0.7220\r\nEpoch 8/10\r\n582/582 [==============================] - 70s 121ms/step - loss: 0.4906 - accuracy: 0.7491 - val_loss: 0.5965 - val_accuracy: 0.6905\r\nEpoch 9/10\r\n582/582 [==============================] - 70s 121ms/step - loss: 0.4636 - accuracy: 0.7711 - val_loss: 0.5580 - val_accuracy: 0.7310\r\nEpoch 10/10\r\n582/582 [==============================] - 70s 120ms/step - loss: 0.4292 - accuracy: 0.7894 - val_loss: 0.5737 - val_accuracy: 0.7233`\r\n\r\n![image](https://user-images.githubusercontent.com/60096583/72729377-b3bf9880-3b97-11ea-93d4-2c14c4ea7348.png)\r\n\r\nIn this case, the loss and the accuracy are going into the right direction\r\n\r\n**Code to reproduce the issue**\r\nOpened the Google Colab notebook, run all the cells up to section named _Create the base model from the pre-trained convnets_. Modified the cell first cell under this heading to the following:\r\n`IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\r\n\r\n _#Create the base model from the pre-trained model MobileNet V2_\r\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\r\n                                               include_top=False,\r\n                                               #weights='imagenet')\r\n                                               weights=None)\r\n\r\nbase_model.trainable = True\r\n`\r\nThen proceed by running the following cells inside the notebook, which create the classification head:\r\n`global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\nfeature_batch_average = global_average_layer(feature_batch)\r\nprint(feature_batch_average.shape)\r\n\r\nprediction_layer = keras.layers.Dense(1)\r\nprediction_batch = prediction_layer(feature_batch_average)\r\nprint(prediction_batch.shape)\r\n\r\nmodel = tf.keras.Sequential([\r\n  base_model,\r\n  global_average_layer,\r\n  prediction_layer\r\n])\r\n`\r\nCompile the model as in the tutorial, with the same parameters:\r\n`base_learning_rate = 0.0001\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\r\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])`\r\n\r\nThen train the model. The initial loss is 0.69 and initial accuracy is 0.51:\r\n`num_train, num_val, num_test = (\r\n  metadata.splits['train'].num_examples*weight/10\r\n  for weight in SPLIT_WEIGHTS\r\n)\r\n\r\ninitial_epochs = 10\r\nsteps_per_epoch = round(num_train)//BATCH_SIZE\r\nvalidation_steps=20\r\n\r\nloss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\r\n\r\nhistory = model.fit(train_batches,\r\n                    epochs=initial_epochs,\r\n                    validation_data=validation_batches)\r\n`\r\n", "comments": ["@dbacea \r\n\r\nI have tried on colab with TF version 2.1 and was able to reproduce the issue. However i am not seeing  MobileNet V1 in tf.keras.applications. I tried with MobileNet in keras.applications and i am seeing same accuracy and validation loss as MobileNet V2.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/71d30be58171e937d8ec496dc246664c/untitled576.ipynb). Thanks!", "@ravikyram \r\n\r\nI used also the MobileNet (which is the architecture of MobileNet V1) from keras-applications, same as you did in the gist you provided. In the gist you provided, for the MobileNet code you forgot to go through several steps. After the cell that contains:\r\n\r\n`global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\nfeature_batch_average = global_average_layer(feature_batch)\r\nprint(feature_batch_average.shape)`\r\n\r\nYou should then insert and run the following code before fitting the model:\r\n`prediction_layer = keras.layers.Dense(1)\r\nprediction_batch = prediction_layer(feature_batch_average)\r\nprint(prediction_batch.shape)\r\n\r\nmodel = tf.keras.Sequential([\r\nbase_model,\r\nglobal_average_layer,\r\nprediction_layer\r\n])\r\n\r\nbase_learning_rate = 0.0001\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\r\nloss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\nmetrics=['accuracy'])`\r\n\r\nBy going through this steps, you will be able to reproduce the values recorded by me for the MobileNet V1.", "I have tried on colab with TF version 2.1.0-rc2 and was able to reproduce the issue.Please, find the for MobileNetV2 [gist ](https://colab.sandbox.google.com/gist/ravikyram/c884c558e88b6214bf44c2b4728d25b1/untitled576.ipynb)and MobileNet [gist](https://colab.sandbox.google.com/gist/ravikyram/0d87b4b027dcfbad75f54e9df084d673/untitled580.ipynb). Thanks!", "@dbacea The tutorial was to demonstrate transfer learning approach where pretrained weights are used. In that case, `num_train=18609` and `num_val =2326` are sufficient as the number of trainable params are only 1,281. But, in your case, trainable params are 2,225,153 but the `num_train` and `num_val` are of same size. In order to get better val_accuracy, increase number of epochs from 10 to 30 and change validation steps also. After those changes, I am noticing val_accuracy of ~76.68%. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/1c1ae50209b4b2a3929d52921d9f8627/untitled576.ipynb).\r\n\r\n```\r\nEpoch 22/30\r\n582/582 [==============================] - 80s 137ms/step - loss: 0.0777 - accuracy: 0.9684 - val_loss: 1.1010 - val_accuracy: 0.7668\r\n```\r\n\r\nI am closing this issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36065\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36065\">No</a>\n", "I have tried MobileNet V1, MobileNet V2 and ResNet backbone to train the same classification model with weights=None. Only MobileNet V2's validation loss and accuray does not go down.\r\nFinally I figured out that the reason is the default momentum of batch normalization layer of MobileNet V2 is 0.999 which is too large. In pytorch it is default set to 0.9 and in tensorflow2 is default  set to 0.99. After changing batch norm momentum to 0.99, the model works. ", "@AirBobby do you mind showing how you changed this value from the existing MobileNetV2 model class? Nice find btw, quite tricky to solve.", "I solved my issue using @AirBobby's comment, as follows.\r\n\r\n```\r\nfor layer in mobilenet_model.layers:\r\n    if type(layer)==type(tf.keras.layers.BatchNormalization()):\r\n        layer.momentum=0.9\r\n```\r\n", "Issue persists on TF2.8, and setting `momentum=0.9` seems to solve the issue. But this should be fixed within TensorFlow."]}, {"number": 36064, "title": "Custom C++ operator compilation error with Tensorflow 2.1", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5.32\r\n- GPU model and memory: NVIDIA Quadro M2000 4GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nCompilation error in tensorblockv2.h (see log below) when building a custom C++ operator for Tensorflow 2.1 on Microsoft Visual Studio 2017. Note that the same custom operator compiles without any error for Tensorflow 2.0, this issue is specific to Tensorflow 2.1.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(736): warning C4346: 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>::Kind': dependent name is not a type\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(736): note: prefix with 'typename' to indicate a type\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(842): note: see reference to class template instantiation 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>' being compiled\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(736): error C2061: syntax error: identifier 'Kind'\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(745): warning C4346: 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>::Kind': dependent name is not a type\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(745): note: prefix with 'typename' to indicate a type\r\n1>e:\\programfiles\\anaconda3\\envs\\tensorflow2_python36\\lib\\site-packages\\tensorflow_core\\include\\unsupported\\eigen\\cxx11\\src\\tensor\\tensorblockv2.h(745): error C2061: syntax error: identifier 'Kind'\r\n```\r\n\r\n\r\n", "comments": ["Would you like to show your custom operator source code and its compilation process? It would be better if there was test code.", "Thank you for your interest in my issue, but the problem seems to be explicitely due to the compilation of this tensorblockv2.h header and not to my custom operator themselves.\r\nAll of my custom operators used to compile fine with Tensorflow 2.0 and with Tensorflow 2.1 none of them (including a simple identity test operator) compile, with the same error in the tensorblockv2 header.", "Comparable issue here; also in TensorBlock.h; Win10 x64; TF2.1; seems to have something to do with Eigen library? Should we include our own version somehow? Following anyway\r\n\r\n\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1028): error C2061: syntax error: identifier 'Kind'\r\n\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1134): note: see reference to class template instantiation 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>' being compiled\r\n\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\cxx11\\src/Tensor/TensorBlock.h(1037): error C2061: syntax error: identifier 'Kind'\r\n", "I have the same error in my macOS Catalina v10.15.2.\r\nHave you tried to build the Tensorflow Lite for iOS using `build_ios_universal.sh`?\r\nIn that case, I suggest you build it using bazel instead.\r\nTake a look on this link: https://www.tensorflow.org/lite/guide/build_ios", "No. Building on Win10 x64 using Bazel and TF2.1, no XLA, CUDA, and the likes, CPU only. No custom operators. Both master and r2.1 versions do not build. Tried VS2017 and VS2019.", "Any news on this issue? Unfortunately, we are unable to switch to TF 2.1 if we are not able to build our custom operators anymore.", "Sorry for missing this issue so far.\r\n@yifeif is our custom ops expert. Yifei, any ideas on this one?", "Any update on this issue?", "Any update ?", "I had the similar problems with TF2.1 and Eigen (_tensorblockv2.h_ file from _unsupported_ module).\r\n\r\nYou can upgrade your compiler to VS 2019 or in older versions you could put the keyword **typename** to all places where the errors come from, for example:\r\n\r\n`template <StridedLinearBufferCopy::Kind kind>`\r\n\r\nshould be replaced by\r\n\r\n`template <typename StridedLinearBufferCopy::Kind kind>`\r\n\r\n**Kind** is dependent name, so it should be preceded by **typename**.\r\n", "+1 on what @07rafix said, we did [switched to VS2019](https://github.com/tensorflow/tensorflow/issues/35036#issuecomment-565611549) when building TF 2.1. Would you mind give that a try @Lillypucien?", "Both solutions given by @07rafix indeed work, thanks. \r\nBy the way, I had another issue while building my custom operators: files located in \"tensorflow_core/include/tensorflow_core/core\" still have includes to \"tensorflow/core\",  which doesn't exist anymore.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36064\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36064\">No</a>\n", "The solution using VS2019 worked for me. However, be sure to remove 'MSVC v* - VS 2015 C++ build tools' among the individual components."]}, {"number": 36063, "title": "Request for tflite using Android NDK documentaion", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n\r\n## URL(s) with the issue: https://groups.google.com/a/tensorflow.org/d/msg/discuss/sye03udicMI/sDr6MQvIDAAJ\r\n\r\n## Description of issue (what needs changing): No resources anywhere about tflite usage using Android NDK.\r\n\r\n### Clear description\r\nI have a .tflite model which involves lots of post processing. \r\nAfter following https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_c  I have written the code in cpp and tested on linux and adb shell.\r\n\r\nNow I want to use this code in the sample Android apk .(https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android)\r\n\r\nIs there any documentation/sample usage of tflite cpp in Android? \r\nI have only found this(https://github.com/zimenglyu/TFLiteExample) but not able to follow this :(\r\n\r\nAny help would be desperately appreciated.\r\n", "comments": ["Found this tf_world's tflite with cpp demo::\r\nhttps://github.com/infil00p/tf_world\r\nWill follow it and update.", "@sanrahul Are you raising a PR to update the docs? When you raise a PR, just mention it here so that we will close after it gets merged. Thanks!"]}, {"number": 36062, "title": "Request example for object detection  on Tensorflow >= 2.0 in CPP", "body": "Hello,\r\nI want to use Tensorflow frozen models in c++. I did find examples on CPP in Tensorflow < 2.0:\r\nhttps://github.com/CasiaFan/tensorflow_cpp_object_detection_web_server\r\n\r\nWhere could I get an simple SSD object detection on CPP in Tensorflow >= 2.0 ?\r\n  \r\n\r\n**System information** : Ubuntu 18.04\r\n- TensorFlow version (you are using): 2.0 \r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n", "comments": ["It can be a good idea to raise this issue on [tensorflow/models](https://github.com/tensorflow/models/issues) repo.\r\nSince we have https://github.com/tensorflow/models/tree/master/research/object_detection hosted there. Thanks!"]}, {"number": 36061, "title": "Segmentation fault error when running Makefile", "body": "@tensorflow/micro\r\n\r\n- Host OS Platform and Distribution: Windows 10\r\n- TensorFlow installed using \"git clone https://github.com/tensorflow/tensorflow.git\"\r\n- Tensorflow version: 2.1.0\r\n- Target platform: Laptop\r\n\r\nHello, I'm following the tutorial provided on the book \"TinyML - Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers\". The aim is to run the \"hello world\" test. The problem is that I got a \"Segmentation fault\" error when I run the command:\r\n\r\nmingw32-make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test\r\n\r\nIn the following I attach a screenshot of the error:\r\n![Immagine](https://user-images.githubusercontent.com/59959289/72727161-87e9e600-3b8a-11ea-8fe5-b8f994d61ab5.png)\r\n\r\nHow can I fix this issue?\r\n", "comments": ["I obtained more info and it seems to be related to C++ issue:\r\n\r\n warning: ISO C++ forbids converting a string constant to 'va_list' {aka 'char*'} [-Wwrite-strings]\r\n\r\nI attach the picture. How can I fix that?\r\n\r\n![Immagine](https://user-images.githubusercontent.com/59959289/72738466-ecfd0600-3ba1-11ea-8d93-90412d382935.png)\r\n\r\nAbove I was using mingw32 as compiler.\r\nI tried also with cygwin64 (downloaded all the Devel package) using the make command and converting the file:\r\n\r\ntensorflow\\lite\\micro\\testing\\test_linux_binary.sh\r\ntensorflow\\lite\\micro\\tools\\make\\download_and_extract\r\n\r\nby using the dos2unix command (this has been required to avoid the \" '\\r':command not found\" error. But when running:\r\nmake -f tensorflow\\lite\\micro\\tools\\make\\Makefile test_hello_world_test\r\nI again obtain the previous ISO C++ warning, and then I obtain the following error:\r\n\r\n![Immagine](https://user-images.githubusercontent.com/59959289/72811900-da95d180-3c60-11ea-9358-55e3f2a299a1.png)\r\n\r\n", "Waiting for someone to answer, I tried a trivial solution. I modified the file micro_test.h at line 95. I removed the %s and I only used \"Testing\" as argument. Now I have not errors, and what I see is this:\r\n\r\n![Immagine](https://user-images.githubusercontent.com/59959289/72979016-bc061680-3dd7-11ea-88b2-5961ca56e98f.png)\r\n\r\nCan I consider that as the test was successfully passed?  If so, it seems clear that the problem is related to the %s format which is incompatible with the *char in C++.  So, how can I fix that?", "@AntonioDeVita it looks like the issue is fixed indeed after you remove the %s sign. This issue does not occur in Linux whether you keep the %s sign or not, and so we never encountered this issue before.\r\n\r\nThank you for reporting this and providing us with a possible fix. We'll look into this issue and fix this on our end."]}, {"number": 36060, "title": "[TFLite int16] 16-bit support for reference kernels: MAX/MIN and PACK/UNPACK", "body": "This PR is one of steps to extend 8-bit quantization to support symmetric 16-bit activations.\r\n\r\nEach activation is of type int16 and symmetric around zero. The weight tensor precision remains at 8-bit signed values. The bias is set to int64 precision.\r\n\r\nIn this PR we introduce implementation and tests for MAXIMUM/MINIMUM kernel reference functions and for PACK/UNPACK kernel reference functions.\r\nThe specification of these operators:\r\n\r\nMAXIMUM \r\n\u202f Input 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Output 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f   restriction: Input and outputs must all have same scale \r\n \r\nMINIMUM \r\n\u202f Input 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Output 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f   restriction: Input and outputs must all have same scale \r\n\r\nUNPACK \r\n\u202f Input 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Outputs 0-N: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f   restriction: Input and outputs must all have same scale ", "comments": ["Hi @suharshs , Could you please review this PR with a set of 16-bit reference kernels ? Thanks!", "Here are internal failures , can you please check.\r\n\r\nthird_party/tensorflow/lite/kernels/test_util.cc:329\r\nExpected equality of these values:\r\n  CountPartitionsDelegatedTo(interpreter_.get(), TestNnApiDelegate())\r\n    Which is: 0\r\n  1\r\nExpecting operation to be accelerated but cannot find a partition associated to the NNAPI delegate\r\nthird_party/tensorflow/lite/kernels/test_util.cc:329\r\nExpected equality of these values:\r\n  CountPartitionsDelegatedTo(interpreter_.get(), TestNnApiDelegate())\r\n    Which is: 0\r\n  1\r\nExpecting operation to be accelerated but cannot find a partition associated to the NNAPI delegate", "Many of our delegates key off of the operator version to know whether it's supported. Are we updating the op versioning for these new 16-bit kernels?", "@jdduke No, I don't do this.", "@jdduke About the versioning: \r\nWe introduced a new input/output type for operators. Do we need to update version for them and change the function GetMinimumRuntimeVersionForModel ?\r\nWe could change GetBuiltinOperatorVersion() function to return a special version that indicates that our input/output is 16-bit. Does it make sense ?\r\n\r\nI am not sure how to proceed here. I really appreciate your help what to do with these failures.\r\nThanks!", "Right, having the updated op version should help resolve some of the internal test failures we're seeing.\r\n\r\nTo do this, you can add [logic in GetBuiltinOperatorVersion to detect the input/output types](https://github.com/tensorflow/tensorflow/blob/306dee4096e97520b1218d78c23b1a72941a9508/tensorflow/lite/tools/versioning/op_version.cc), and use an incremented version, update the op version to TFlite version mapping [here](https://github.com/tensorflow/tensorflow/blob/306dee4096e97520b1218d78c23b1a72941a9508/tensorflow/lite/toco/tflite/op_version.cc), and then update the max version where the builtin is registered [here](https://github.com/tensorflow/tensorflow/blob/306dee4096e97520b1218d78c23b1a72941a9508/tensorflow/lite/kernels/register.cc#L43). \r\n\r\nI realize this process is fairly tedious, we're hoping to remove some of the boilerplate, but for now that's the general pattern.", "@jdduke Hi Jared ! Thanks. I updated as you suggested.\r\nI have a couple of quesions:\r\n1. Can I reproduce tests that failed in my environment ? What is a bazel task to run these tests ? Do I need pull external dependencies ?\r\n2. We have a set of 16x8 kernels merged without versioning. Do we need to update versioning for all 16x8 kernels that have been merged or under review ?\r\n3. Do we need to add tests for versioning ? I see [op_version_test](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/versioning/op_version_test.cc), for example. \r\n4. General question: Is this versioning applied when we change syntax of the operator, algorithm inside ?\r\nThanks !", "Hi @jdduke, Could you please review this PR ?", "Hi @jdduke, Could you please re-approve this PR ? There was a merge conflict and I had to resolve it. Thanks! ", "Hi @rthadur , Sorry to bother you, but it looks that this PR has stuck as well. \r\nIs it something internally ? \r\nThanks!", "On which version of TensorFlow is this working??"]}, {"number": 36059, "title": "Cannot convert between a TensorFlowLite buffer with 1392640 bytes and a Java Buffer with 4177920 bytes.", "body": "I am using Tensorflow.Lite.Support function for Inference of a model that takes two input and gives output in the form of Image. The first input is an RGB image whereas the second image is a single-channel image.When I run the application for inference I get the error that is:\r\n\r\n**Cannot convert between a TensorFlowLite buffer with 1392640 bytes and a Java Buffer with 4177920 bytes.**\r\n\r\nI have attached my code snippet below:\r\n```\r\nprotected void onCreate(Bundle savedInstanceState) {\r\n        super.onCreate(savedInstanceState);\r\n        setContentView(R.layout.activity_main);\r\n        Toolbar toolbar = findViewById(R.id.toolbar);\r\n        setSupportActionBar(toolbar);\r\n\r\n        FloatingActionButton fab = findViewById(R.id.fab);\r\n        fab.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View view) {\r\n                Snackbar.make(view, \"Replace with your own action\", Snackbar.LENGTH_LONG)\r\n                        .setAction(\"Action\", null).show();\r\n            }\r\n        });\r\n\r\n        try {\r\n            tflite = new Interpreter(loadModelFile(MainActivity.this, \"converted_model.tflite\"));\r\n\r\n\r\n            Bitmap Image = getBitmapFromAsset(this,\"001.png\");\r\n            Bitmap Mask = getBitmapFromAsset(this,\"tmp_mask.png\");\r\n\r\n            int imageTensorIndex = 0;\r\n            int[] imageShape = tflite.getInputTensor(imageTensorIndex).shape(); // {1, height, width, 3}\r\n            int imageSizeY = imageShape[1];\r\n            int imageSizeX = imageShape[2];\r\n            DataType imageDataType = tflite.getInputTensor(imageTensorIndex).dataType();\r\n\r\n            TensorImage inputImageBuffer = new TensorImage(imageDataType);\r\n            inputImageBuffer.load(Image);\r\n\r\n            int imageTensorIndex1 = 1;\r\n            int[] imageShape1 = tflite.getInputTensor(imageTensorIndex1).shape(); // {1, height, width, 3}\r\n            int imageSizeY1 = imageShape1[1];\r\n            int imageSizeX1 = imageShape1[2];\r\n            DataType imageDataType1 = tflite.getInputTensor(imageTensorIndex1).dataType();\r\n\r\n            TensorImage inputImageBuffer1 = new TensorImage(imageDataType1);\r\n            inputImageBuffer1.load(Mask);\r\n\r\n\r\n            int OutputTensorIndex = 0;\r\n            int[] OutputShape =\r\n                    tflite.getOutputTensor(OutputTensorIndex).shape(); // {1, NUM_CLASSES}\r\n            DataType OutputDataType = tflite.getOutputTensor(OutputTensorIndex).dataType();\r\n\r\n            TensorBuffer outputBuffer = TensorBuffer.createFixedSize(OutputShape, OutputDataType);\r\n\r\n            Object[] Inputs = {inputImageBuffer.getBuffer(),inputImageBuffer1.getBuffer()};\r\n\r\n            Map<Integer, Object> outputs = new HashMap<>();\r\n            outputs.put(0,outputBuffer);\r\n            tflite.runForMultipleInputsOutputs(Inputs, outputs);\r\n\r\n            Toast.makeText(this,\"Working\",Toast.LENGTH_LONG).show();\r\n  \r\n        } catch (IOException e) {\r\n            Toast.makeText(this,\"Failed\",Toast.LENGTH_LONG).show();\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n```", "comments": ["The detailed error log is:\r\n\r\n```\r\n2020-01-21 11:59:21.375 12800-12800/? E/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.example.inpainting, PID: 12800\r\n    java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.inpainting/com.example.inpainting.MainActivity}: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1392640 bytes and a Java Buffer with 4177920 bytes.\r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2817)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2892)\r\n        at android.app.ActivityThread.-wrap11(Unknown Source:0)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1593)\r\n        at android.os.Handler.dispatchMessage(Handler.java:105)\r\n        at android.os.Looper.loop(Looper.java:164)\r\n        at android.app.ActivityThread.main(ActivityThread.java:6541)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)\r\n     Caused by: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1392640 bytes and a Java Buffer with 4177920 bytes.\r\n        at org.tensorflow.lite.Tensor.throwIfShapeIsIncompatible(Tensor.java:332)\r\n        at org.tensorflow.lite.Tensor.throwIfDataIsIncompatible(Tensor.java:305)\r\n        at org.tensorflow.lite.Tensor.setTo(Tensor.java:123)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:148)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:296)\r\n        at com.example.inpainting.MainActivity.onCreate(MainActivity.java:119)\r\n        at android.app.Activity.performCreate(Activity.java:6975)\r\n        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1213)\r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2770)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2892)\u00a0\r\n        at android.app.ActivityThread.-wrap11(Unknown Source:0)\u00a0\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1593)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:105)\u00a0\r\n        at android.os.Looper.loop(Looper.java:164)\u00a0\r\n        at android.app.ActivityThread.main(ActivityThread.java:6541)\u00a0\r\n        at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n        at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)\u00a0\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)\u00a0\r\n```", "@ravikyram @ymodak any update?", "@nauyan  I'm also facing same issue. Did you resolve this issue ?\r\n", "@Ehtasha No not yet.", "@nauyan Any update for this issue?", "@Dark-Monk Nope", "@Dark-Monk  @nauyan \r\n\r\nIf you are using ` runSegmentationOnBinary ` method then replace bellow lines\r\n\r\nReplace bellow line \r\n`var convertedBytes = Uint8List(1 * inputSize * inputSize * 3);` \r\n\r\nwith \r\n`var convertedBytes = Uint8List(4 * 1 * inputSize * inputSize * 3);`", "@Ehtasha I am using Java instead of kotlin seconldy I am using **runForMultipleInputsOutputs**", "Okey I'm integrating this using Flutter and binary function is available there.\r\n\r\nBut is java also multiple with 4 where you specify the image size.\r\nAbove inputSize represent the image dimention.\r\n\r\n`(4 * 1 * 128* 128 * 3)`\r\n", "@Ehtasha Can you please point out where should I make changes in the above code?", "@Ehtasha ... Appreciate the help but I am already doing this and even tried this (1 * inputSize * inputSize * 3) for Quantized model but didn't worked. I am actually using  the sample app with my custom model created via firebase console Auto ML. The sample app works for its detect model.\r\n\r\n`int numBytesPerChannel;\r\nif (isQuantized) {\r\n  numBytesPerChannel = 1; // Quantized\r\n} else {\r\n  numBytesPerChannel = 4; // Floating point\r\n}\r\nd.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);`", "@Dark-Monk I am have tried the same but doesn't work", "@nauyan  \r\nI'm integrating my model in flutter app using tflite plugin not in android native.\r\n\r\nIn flutter binary method is available.\r\n\r\nI will try to implement this in android also and then update if this work there.", "@Ehtasha sure that would be nice.", "any update? Would like to know what change need to be made in order to run inference on grayscale image.", "@nauyan Apologies for the delay in response. Is this still an issue?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I had the same problem and found a solution.\r\nInspect your model using Netron. View model properties using `View -> Model Properties`.\r\nIf, for inputs, you have individual elements, see their type. It will look something like this:\r\n`type:float32[1,1]`\r\nThis implies that each input is 1 array of 1 element which can be represented with a ByteBuffer in JAVA.\r\nSo, say you have a list of 10 inputs, each showing `type:float32[1,1]`, then your `input` object would look like this: \r\n<pre>\r\nObject[] input = new Object[10];\r\nfor (int i = 0; i < 10; i++) {\r\n            ByteBuffer temp = ByteBuffer.allocateDirect(4); // Allocate with size of float\r\n            temp.putFloat(inputData[i]); // May be an array containing actual values\r\n            input[i] = temp;\r\n }\r\n</pre>\r\nMy output, according to Netron looked like this:\r\n`type:float32[1,1]`\r\nSo, in JAVA, it would be:\r\n<pre>\r\nByteBuffer identity = ByteBuffer.allocateDirect(4);\r\nMap<Integer, Object> output = new TreeMap<>();\r\noutput.put(0, identity);\r\n</pre>\r\n\r\nSince these qualify as multiple inputs, you will have to use:\r\n<code>interpreter.runForMultipleInputsOutputs(input, output);</code>\r\n\r\nHope this helps", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36059\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36059\">No</a>\n"]}, {"number": 36058, "title": "[TFLite int16] Added 16/8 bit support to kernel operator CONCAT", "body": "This PR is one of steps to extend 8-bit quantization to support symmetric 16-bit activations.\r\n\r\nEach activation is of type int16 and symmetric around zero. The weight tensor precision remains at 8-bit signed values. The bias is set to int64 precision.\r\n\r\nIn this PR we introduce implementation and tests for CONCAT kernel reference function.\r\nThe specification of this operator:\r\n\r\nCONCATENATION \r\n\u202f Input ...: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f Output 0: \r\n\u202f \u202f data_type \u202f: int16 \r\n\u202f \u202f range \u202f \u202f \u202f: [-32768, 32767] \r\n\u202f \u202f granularity: per-tensor, zero_point=0 \r\n\u202f restriction: Input and outputs must all have same scale", "comments": ["@suharshs Could you please take a look at this PR ? Thanks a lot!", "@suharshs Could you please take a look at this PR again ? I corrected it according to your comment."]}, {"number": 36057, "title": "Execution platform: @bazel_tools//platforms:host_platform: bash failed: error executing command", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04.3\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.x\r\n- Python version: 3.8.1\r\n- Installed using virtualenv? pip? conda?: pip \r\n- Bazel version (if compiling from source): 0.26.1 with \r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: 10.2 / 7.6.5\r\n- TensorRT: 7.0.0\r\n- GPU model and memory: compute capability 5.2 \r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n```console\r\nERROR: ....../tensorflow/python/BUILD:7692:1: Executing genrule //tensorflow/python:framework/fast_tensor_util.pyx_cython_translation failed (Profiling timer expired): bash failed: error executing command \r\n  (cd ~/.cache/bazel/_bazel_longervision/90066176d51f3058b5ce7c4e1b3a40d7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 \\\r\n    LD_LIBRARY_PATH=/opt/Qt/Current/gcc_64/lib:/opt/Qt/Current/gcc_64/plugins/platforms:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib:/lib:/lib64:/lib/x86_64-linux-gnu:/opt/intel/compilers_and_libraries/linux/daal/lib/intel64:/opt/intel/compilers_and_libraries/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries/linux/mkl/lib/intel64:/opt/intel/compilers_and_libraries/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries/linux/mpi/intel64/lib/release:/opt/intel/compilers_and_libraries/linux/tbb/lib/intel64/gcc4.7:/opt/intel/compilers_and_libraries/linux/lib/intel64:/opt/intel/openvino/inference_engine/lib/intel64:/usr/local/cuda/targets/x86_64-linux/lib:/opt/mcu/arduino/lib:/usr/lib/jvm/default-java/lib: \\\r\n    PATH=~/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/opt/Qt/Current/gcc_64/bin:/opt/intel/compilers_and_libraries/linux/daal/bin:/opt/intel/compilers_and_libraries/linux/ipp/bin:/opt/intel/compilers_and_libraries/linux/mkl/bin:/opt/intel/compilers_and_libraries/linux/mpi/intel64/bin:/opt/intel/compilers_and_libraries/linux/tbb/bin:/opt/intel/compilers_and_libraries/linux/bin:/usr/local/cuda/bin:/usr/local/cuda/samples/bin/x86_64/linux/release:/opt/node/bin:/usr/lib/jvm/default-java/bin \\\r\n    PYTHONPATH=~/.local/lib/python3.8/site-packages:/usr/lib/python3.8/site-packages:/usr/local/lib/python3.8/site-packages:/usr/lib/python3/dist-packages \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=~/.local/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=5.2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_TENSORRT=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; PYTHONHASHSEED=0 bazel-out/host/bin/external/cython/cython_binary --cplus tensorflow/python/framework/fast_tensor_util.pyx --output-file bazel-out/k8-opt/bin/tensorflow/python/framework/fast_tensor_util.cpp')\r\nExecution platform: @bazel_tools//platforms:host_platform: bash failed: error executing command \r\n  (cd ~/.cache/bazel/_bazel_longervision/90066176d51f3058b5ce7c4e1b3a40d7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 \\\r\n    LD_LIBRARY_PATH=/opt/Qt/Current/gcc_64/lib:/opt/Qt/Current/gcc_64/plugins/platforms:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib:/lib:/lib64:/lib/x86_64-linux-gnu:/opt/intel/compilers_and_libraries/linux/daal/lib/intel64:/opt/intel/compilers_and_libraries/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries/linux/mkl/lib/intel64:/opt/intel/compilers_and_libraries/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries/linux/mpi/intel64/lib/release:/opt/intel/compilers_and_libraries/linux/tbb/lib/intel64/gcc4.7:/opt/intel/compilers_and_libraries/linux/lib/intel64:/opt/intel/openvino/inference_engine/lib/intel64:/usr/local/cuda/targets/x86_64-linux/lib:/opt/mcu/arduino/lib:/usr/lib/jvm/default-java/lib: \\\r\n    PATH=~/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/opt/Qt/Current/gcc_64/bin:/opt/intel/compilers_and_libraries/linux/daal/bin:/opt/intel/compilers_and_libraries/linux/ipp/bin:/opt/intel/compilers_and_libraries/linux/mkl/bin:/opt/intel/compilers_and_libraries/linux/mpi/intel64/bin:/opt/intel/compilers_and_libraries/linux/tbb/bin:/opt/intel/compilers_and_libraries/linux/bin:/usr/local/cuda/bin:/usr/local/cuda/samples/bin/x86_64/linux/release:/opt/node/bin:/usr/lib/jvm/default-java/bin \\\r\n    PYTHONPATH=~/.local/lib/python3.8/site-packages:/usr/lib/python3.8/site-packages:/usr/local/lib/python3.8/site-packages:/usr/lib/python3/dist-packages \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=~/.local/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=5.2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_TENSORRT=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; PYTHONHASHSEED=0 bazel-out/host/bin/external/cython/cython_binary --cplus tensorflow/python/framework/fast_tensor_util.pyx --output-file bazel-out/k8-opt/bin/tensorflow/python/framework/fast_tensor_util.cpp')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n/bin/bash: line 1:  2347 Profiling timer expired PYTHONHASHSEED=0 bazel-out/host/bin/external/cython/cython_binary --cplus tensorflow/python/framework/fast_tensor_util.pyx --output-file bazel-out/k8-opt/bin/tensorflow/python/framework/fast_tensor_util.cpp\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 374.150s, Critical Path: 84.85s\r\nINFO: 1334 processes: 1334 local.\r\nFAILED: Build did NOT complete successfully\r\n\u279c  tensorflow git:(master) \u2717 \r\n```\r\n", "comments": ["@jiapei100,\r\nLooks like you are using Python 3.8, Tensorflow is only supported till Python 3.7 as of now.\r\nPlease refer to [this](https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-571074915) comment for further information. Thanks!", "@jiapei100,\r\nAny updates regarding this issue? Thanks!", "Still problematic..\r\n\r\nI'm now using bazel 0.26.1, with a modified tensorflow according to : https://github.com/tensorflow/tensorflow/issues/35584\r\n\r\n\r\n```console\r\nINFO: From ProtoCompile tensorflow/python/framework/cpp_shape_inference.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nERROR: ....../tensorflow/core/util/BUILD:338:1: Executing genrule //tensorflow/core/util:version_info_gen failed (Profiling timer expired): bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n/bin/bash: line 1: 11745 Profiling timer expired bazel-out/host/bin/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref \"bazel-out/k8-opt/bin/tensorflow/core/util/version_info.cc\" --git_tag_override=${GIT_TAG_OVERRIDE:-}\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 78.994s, Critical Path: 13.68s\r\nINFO: 231 processes: 231 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@jiapei100,\r\nMay I know which version of Python you are using?", "@amahendrakar \r\n\r\n```console\r\n\u279c  \u2717 python --version\r\nPython 3.8.1\r\n```", "python 3.8 support for  TF binaries is in progress.\r\nTo know more see https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-571074915\r\nYou need to switch back to Python version 3.4\u20133.7.\r\nhttps://www.tensorflow.org/install/pip?lang=python3#system-requirements\r\nWe will update this [thread](https://github.com/tensorflow/tensorflow/issues/33374) when python 3.8 is up. Thanks!", "TensorFlow 2.2 pip packages now support Python 3.8\r\nSee https://pypi.org/project/tensorflow/2.2.0/#files\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36057\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36057\">No</a>\n"]}, {"number": 36056, "title": "Add usage example to pad_to_bounding_box", "body": "", "comments": ["I removed the 0's. Thanks for the tip. I actually think keeping the output is better because I copied it directly from the terminal so it's the output same other users will get. If you still think it's better to remove it, please say so and I'll do it.", "Done.", "Good \ud83d\udc4d ", "Thanks!", "@mihaimaruseac is there anything else that needs to be changed?"]}, {"number": 36055, "title": "TFLite Android Model Benchmark Tool -- results not showing up in adb logcat", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- Mobile device: Pixel 3\r\n- TensorFlow installed from: source\r\n- TensorFlow version: From master branch, commit hash 69ac54d92de18ca18f9a110d6dd464aeb1116342. Compiled tensorflow with `./configure` and then `bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package`.\r\n- Python version: 3.6\r\n- Installed using: conda\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): 7.4, and compiling with c++14 flag\r\n- CUDA/cuDNN version: not using gpu for this experiment\r\n- GPU model and memory: not using gpu for this experiment\r\n- TFLite model that I am trying to benchmark: `mobilenet_v1_0.25_192_quant.tflite` from [this page](https://www.tensorflow.org/lite/guide/hosted_models). Note that I do have some more exotic models that I'd like to benchmark, but I am starting with an off-the-shelf model from an official tensorflow page.\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am trying to benchmark the speed of a tflite model on a pixel 3. \r\n\r\nOn an ubuntu computer, with a Pixel 3 in developer mode connected via USB, I followed steps 1 to 5 in **[this readme](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark/android/README.md)**. I did not get a single error message. When I get to step 4, I get the following output:\r\n\r\n```\r\nStopping: org.tensorflow.lite.benchmark\r\nStarting: Intent { cmp=org.tensorflow.lite.benchmark/.BenchmarkModelActivity (has extras) }\r\n```\r\n\r\nWhile running step 4, I have an other terminal window open with `adb logcat` running. Unfortunately, the phrase `Average inference` doesn't show up in the `logcat` output, and the only relevant thing in `logcat` is `01-19 23:30:20.449  1357  3307 I ActivityTaskManager: START u0 {flg=0x10000000 cmp=org.tensorflow.lite.benchmark/.BenchmarkModelActivity (has extras)} from uid 2000`, but there are no latency numbers showing up in `logcat`. \r\n\r\nAny idea what I am doing wrong, and what's preventing the latency numbers from showing up in `logcat`?", "comments": ["@multiverse-tf can you take a look?", "I spent some more time on this. Originally, I was using the newest versions of all the android stuff (NDK, SDK, build tools). I changed my NDK to version 14b and SDK to API level 21. For the android build tools, I am using version 29.0.2, which is what I was using before, too.\r\n\r\nWhen I was doing this yesterday, I didn't really understand how the `WORKSPACE` file and its various dependencies work, so I changed to these NDK and SDK versions by rebuilding tensorflow and using the interactive thing in `tensorflow/configure` to setup my `WORKSPACE` with these specific NDK and SDK versions. Now, I see that I can fiddle with NDK and SDK versions using `tensorflow/.tf_configure.bazelrc`. I see 2 situations:\r\n- There are some NDK + SDK variants where the benchmark runs, but no useful data shows up in `adb logcat` -- see above. I don't know if this is a silent failure or something else.\r\n- There are situations such as the one below. The situation below tends to happen with older NDK + SDK configs, e.g. with NDK version 14 and SDK API level 21.\r\n\r\nNow,  in the [readme](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/benchmark/android/README.md) that I was originally following, I only get to step 1 (previously I got to step 5 without errors, but with some sort of silent failure). Now, at step 1, when I compile `android:benchmark_model`, I get the following error:\r\n```\r\ntensorflow/tensorflow/lite/experimental/ruy/BUILD:245:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:detect_arm' failed (Exit 1)\r\ntensorflow/lite/experimental/ruy/detect_arm.cc:59:10: error: use of undeclared identifier 'getauxval'\r\n  return getauxval(AT_HWCAP) & kLocalHwcapAsimddp;\r\n         ^\r\n1 error generated.\r\nTarget //tensorflow/lite/tools/benchmark/android:benchmark_model failed to build\r\n```\r\nI searched the tensorflow github issues for 'getauxval' and I didn't find a single hit. \r\n\r\nThis is all odd, because I would think that, since `tensorflow/lite/experimental/ruy/detect_arm.cc` has the line `#include <sys/auxv.h>`, that `getauxval` would be defined. Also, I don't really understand how the android cross-compilation works, e.g. when building on linux, where is it looking for the android `sys` headers?", "I have some problem ,change android config\uff08to default\uff09, fix it ", "Does someone have any updates here? I'm getting the same error", "> Does someone have any updates here? I'm getting the same error\r\n\r\nWhich TFLite version did you use? Could you try out a more recent version? The RUY path mentioned in the original comment implies it's a pretty old TFLite version. RUY was moved out of TFLite to its own independent repo in April, 2020.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36055\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36055\">No</a>\n", "Any updataes on this issue? ", "Such weird problem.. Is there any way one can debug?"]}, {"number": 36054, "title": "Failed build on windows wtih MKL", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1 master branch, git rev-parse HEAD : 6bc6e8df2c515c229735c4bd85b7ff5084dfccef\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): msvc 2019\r\n- CUDA/cuDNN version: disabled\r\n- GPU model and memory: \r\n\r\nconfigure: No XLA/Cuda/RocM, no \"disable Eigen strong inline\"\r\noptimization flags: -O2 -fp:fast -Ob3\r\n\r\napplied patch from https://github.com/tensorflow/tensorflow/issues/25213#issuecomment-501564390\r\n\r\nbuild command:\r\n`bazel --output_base=C:\\Lib\\.bazel\\tf-noavx-mkl build --jobs 6 --config=mkl --config=monolithic --config=opt --config=v2 //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nbuild error:\r\n```\r\nERROR: F:/lib/tensorflow/tensorflow/BUILD:868:1: Executing genrule //tensorflow:tf_python_api_gen_v2 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\K13\\tf-noavx\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\K13\\tf-noavx\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\tools\\api\\generator\\create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"\\\\?\\F:\\Temp\\Bazel.runfiles_ejm1kz55\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\K13\\tf-noavx\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\K13\\tf-noavx\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n```", "comments": ["@Korsar13 Did you happen to build successfully without mkl flag?", "> @Korsar13 Did you happen to build successfully without mkl flag?\r\n\r\n@preethivenkatesh Yes", "> @preethivenkatesh Yes\r\n\r\n@Korsar13,\r\nThis this still an issue?\r\n\r\nCould you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36054\">No</a>\n"]}, {"number": 36053, "title": "Add a usage example for tf.is_tensor", "body": "Added a usage example for tf.is_tensor. \r\n\r\nTested on local machine with python3 ./tf_doctest.py --file=../../python/framework/tensor_util.py", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36053) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36053) for more info**.\n\n<!-- ok -->"]}, {"number": 36052, "title": "[grappler]:optimize_expression", "body": "Minor optimization.", "comments": []}, {"number": 36051, "title": "Optimize expression", "body": "Minor expression optimization: A || (!A && B) <=> A || B", "comments": []}, {"number": 36050, "title": "[lite] fix ConvBuffer1x1 check", "body": "", "comments": ["Can you review this as well ? Thank you."]}, {"number": 36049, "title": "Add Usage Example to tf.math.log_sigmoid", "body": "Added a usage example to tf.math.log_sigmoid", "comments": ["@malder08 thank you, it is failing doctest can you please check here for [logs](https://source.cloud.google.com/results/invocations/3012f368-334d-4b14-89f1-6c96e19860ab/targets/%2F%2Ftensorflow%2Ftools%2Fdocs:tf_doctest/tests).\r\n\r\nPlease run the doctest locally as mentioned here in the [contributor guidelines](https://www.tensorflow.org/community/contribute/docs_ref).", "Ok that makes sense, thanks. My most recent commit removed the second example and changed the values in the tensor to be more significant.", "@malder08 \r\n\r\nCan you please check build failures? Thanks!", "@malder08 gentle ping", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!", "So sorry for the late response, I seem to have missed the first ping. I've been having some trouble getting the lab test to work on my computer so I can try to see the error to fix. When I am able to get that working I'll reopen the pull request. Again, sorry and thanks!"]}, {"number": 36048, "title": "tf.keras.losses.MeanSquaredError doesnt support scalar inputs", "body": "I am using tensorflow version 2.2.0-dev20200119. tf.keras.losses.MeanSquaredError can't handle input scalar values properly. The following code can reproduce the problem.\r\n\r\n```python\r\n#!/usr/bin/python3\r\nimport tensorflow as tf;\r\ntf.keras.losses.MeanSquaredError()(1,0);\r\n```\r\n", "comments": ["Was able to reproduce the issue with TF 2.1.0 and 2.2.0-dev20200119. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/02862816fff21cc0cb9737852b051ac6/36048.ipynb). Thanks!", "Hi @breadbread1984, the labels and predictions are expected to be at least 2D for the metric: https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanSquaredError?version=nightly#update_state\r\n\r\ny_true: Ground truth values. shape = [batch_size, d0, .. dN].\r\ny_pred: The predicted values. shape = [batch_size, d0, .. dN].", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36048\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36048\">No</a>\n"]}, {"number": 36047, "title": "Third attempt at fixing the release builds", "body": "\r\nRemove builds which are not used.\r\n\r\nInstall estimator and tensorboard at their latest", "comments": []}, {"number": 36046, "title": "Third attempt at fixing the release builds", "body": "Remove v2 behavior as this is v1 branch.\r\n\r\nRemove builds which are not used.\r\n\r\nInstall estimator and tensorboard at their latest", "comments": []}, {"number": 36045, "title": "Using TensorFlow backend. ERROR:root:Internal Python error in the inspect module.", "body": "**TensorFlow isn't working - Please help**\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-88d96843a926>\", line 1, in <module>\r\n    import keras\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-88d96843a926>\", line 1, in <module>\r\n    import keras\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-88d96843a926>\", line 1, in <module>\r\n    import keras\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2037, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1418, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1318, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Program Files\\Python37\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-88d96843a926>\", line 1, in <module>\r\n    import keras\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2037, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1418, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1318, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\nC:\\Program Files\\Python37\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\nC:\\Program Files\\Python37\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2033                         # in the engines. This should return a list of strings.\r\n-> 2034                         stb = value._render_traceback_()\r\n   2035                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3334             if result is not None:\r\n   3335                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3336             self.showtraceback(running_compiled_code=True)\r\n   3337         else:\r\n   3338             outflag = False\r\n\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2035                     except Exception:\r\n   2036                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2037                                             value, tb, tb_offset=tb_offset)\r\n   2038 \r\n   2039                     self._showtraceback(etype, value, stb)\r\n\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1416             self.tb = tb\r\n   1417         return FormattedTB.structured_traceback(\r\n-> 1418             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1419 \r\n   1420 \r\n\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1316             # Verbose modes need a full traceback\r\n   1317             return VerboseTB.structured_traceback(\r\n-> 1318                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1319             )\r\n   1320         elif mode == 'Minimal':\r\n\r\nc:\\users\\f174s322\\pycharmprojects\\nn_trial run\\trial_1_jan_19_2020\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1184         exception = self.get_parts_of_chained_exception(evalue)\r\n   1185         if exception:\r\n-> 1186             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1187             etype, evalue, etb = exception\r\n   1188         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "I'm using Windows 10 64bit and I installed Tensorflow and all other libraries through 'pip'. \r\nTensorflow v2.1.0\r\n\r\nCommand:\r\nfrom sklearn import preprocessing\r\nmin_max_scaler = preprocessing.MinMaxScaler()\r\nX_scale = min_max_scaler.fit_transform(X)\r\n", "@FSyed2 \r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements). Can you try Installing the latest version of Microsoft Visual C++ from this [link ](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads). Please check issue #35749 for reference. Please, let us know how it progress.Thanks!", "@FSyed2 \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36045\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36045\">No</a>\n", "I solved this issue by downloading and installing \r\n\"Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019\". It worked for me.\r\n\r\nPre-requisite: Python + Jupyter notebook + tensorflow installation already done\r\n\r\nYou get this error when you \"import tensorflow\"\r\n\r\nFollow the below steps:\r\n\r\nStep 1: Download \"Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 - community edition\"\r\n\r\nStep 2: Select \"Python Workload\" while installing Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019\r\n\r\nStep 3: Restart your computer once\r\n\r\nStep 4: That's it now open Jupyter notebook and \"import tensorflow\" and the error will not occur  ", "Step 1: Create a new conda environment where we will install our modules to built our models\r\nStep 2: Open Anaconda Prompt (Run as Administrator)\r\nconda create --name deeplearning\r\nStep 3: Activate the conda environment that we just created use\r\nactivate deeplearning\r\nStep 4: Install Keras\r\nconda install -c anaconda keras\r\nStep 5: Install Jupyter \r\nconda install jupyter #very important if you work on Jupyter Notebook\r\nStep 6: Update tensorflow\r\npip install --ignore-installed --upgrade tensorflow==2.0\r\nStep 7: Install following \r\nconda install spyder #very important if you work on spyder\r\nconda install matplotlib\r\nconda install pandas"]}, {"number": 36044, "title": "Simple keras model, Model.fit() does not learn unless experimental_run_tf_function=False at compile", "body": "**System information**\r\n- Windos 10, 64 Bit\r\n- TensorFlow installed from pip\r\n- TensorFlow version: v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nSimple Model (see below), compiles without error. It is used in a reinforcement scenario, i.e. iterations of `predict()` and `fit()` calls to iteratively train the model. \r\nCurrently the model does not seem to improve with calls to `fit()` unless `compile()` was called with `compile(..., experimental_run_tf_function = False)`. \r\n\r\n**Describe the expected behavior**\r\n\r\nModel should train equally well whether `experimental_run_tf_function = False` was passed to `model.compile()` or not.\r\n\r\n**Code to reproduce the issue**\r\n\r\nExample code can be found at [https://github.com/fcarsten/tic-tac-toe/blob/tf-2.1-issue/test_nn_q_tf2.py]( https://github.com/fcarsten/tic-tac-toe/blob/tf-2.1-issue/test_nn_q_tf2.py) - need to check out the whole branch as it uses other code from this repository. \r\n\r\nEither run as is `run_test(True)` to see failing, or `run_test(False)` to see how it should run. \r\n\r\nWhen running as expected \"Player 1 win %\" should increase and end up over 80%, usually somewhere around 90%. When not running as expected, \"Player 1 win %\" will randomly meander up and down.\r\n\r\nThe model is defined in File SimpleNNQPlayerTF2.py line 29 ff:\r\n```\r\ninput_layer = tf.keras.Input(shape=(BOARD_SIZE * 3,))\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 9, activation='relu')(input_layer)\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 100, activation='relu')(x)\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 9, activation='relu')(x)\r\nq_values = tf.keras.layers.Dense(BOARD_SIZE, activation=None, name='q_values')(x)\r\nprobabilities = tf.keras.layers.Softmax(name='probabilities')(q_values)\r\n\r\nself.model = tf.keras.Model(inputs=input_layer, outputs=[probabilities, q_values])\r\nif run_tf_function:\r\n    self.model.compile(optimizer='adam', loss = [None, tf.keras.losses.MeanSquaredError()])\r\nelse:\r\n    self.model.compile(optimizer='adam', loss = [None, tf.keras.losses.MeanSquaredError()], experimental_run_tf_function = False)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nWhile the model is a very simple sequential model, note that it has 2 output layers and the training target layer is not the final layer in the model. Not sure this makes any difference, \r\n", "comments": ["@fcarsten \r\n\r\nLooks like code is incomplete. Request you to share colab link or simple stand alone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "Colab link as requested: [https://colab.research.google.com/drive/1rS0RLOL7zMh3hDC4bAwAPGjI6qCXdNEy](https://colab.research.google.com/drive/1rS0RLOL7zMh3hDC4bAwAPGjI6qCXdNEy)", "@fcarsten Not sure what is the root-cause of the issue. I changed order of final two lines of your code from Sequence #1: `run_test(True) then run_test(False)` to Sequence #2: `run_test(False) then run_test(True). The results are very different than what you noticed with the Sequence #1. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/04c083b0839571ce2c80f41949256254/tensorflow-issue-36044.ipynb). Thanks!", "@jvishnuvardhan Looking at your gist, it looks like you are using a different version of TF than me. \r\n\r\nYours is `2.2.0-dev20200121` whereas mine was `v2.1.0-rc2-17-ge5bf8de410 2.1.0`. \r\n\r\nLooking at the latest source code it seems that the work-around flag I use to make it work is no longer supported in `2.2.0-dev20200121`, so it is always failing now.\r\n\r\n\r\nv2.1.0-rc2-17-ge5bf8de410 2.1.0:\r\ntraining.py#compile():\r\n```\r\n...\r\n303:    self._experimental_run_tf_function = kwargs.pop(\r\n             'experimental_run_tf_function', True)\r\n...\r\n```\r\n\r\nno longer exists in 2.2.0-dev20200121.\r\n\r\nSo, the problem is still there, just my workaround no longer works. (which from my point of view is kind of worse ;-) )\r\n...\r\n\r\n ", "Running `fit()` with `verbose=1` shows the difference in behavior even more.\r\n\r\nWith `experimental_run_tf_function = False` the loss decreases slowly but consistently. Without however the loss actually increases until it stabilizes around 400-500:\r\n\r\n```\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 71ms/sample - loss: 0.0484 - q_values_loss: 0.0484\r\nTrain on 4 samples\r\n\r\n4/4 [==============================] - 0s 3ms/sample - loss: 0.1187 - q_values_loss: 0.1187\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 0.3707 - q_values_loss: 0.3707\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 1.4076 - q_values_loss: 1.4076\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 2.3861 - q_values_loss: 2.3861\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 4.5628 - q_values_loss: 4.5628\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 10.1721 - q_values_loss: 10.1721\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 17.7317 - q_values_loss: 17.7317\r\nTrain on 4 samples\r\n\r\n4/4 [==============================] - 0s 2ms/sample - loss: 27.7600 - q_values_loss: 27.7600\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 35.3489 - q_values_loss: 35.3489\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 4ms/sample - loss: 50.9869 - q_values_loss: 50.9869\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 58.2381 - q_values_loss: 58.2381\r\nTrain on 5 samples\r\n\r\n[...]\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 310.6920 - q_values_loss: 310.6920\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 323.8771 - q_values_loss: 323.8771\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 341.6482 - q_values_loss: 341.6482\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 338.4795 - q_values_loss: 338.4795\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 321.3784 - q_values_loss: 321.3784\r\nTrain on 4 samples\r\n\r\n4/4 [==============================] - 0s 2ms/sample - loss: 334.4857 - q_values_loss: 334.4857\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 410.9324 - q_values_loss: 410.9324\r\nTrain on 3 samples\r\n\r\n3/3 [==============================] - 0s 3ms/sample - loss: 394.3834 - q_values_loss: 394.3834\r\nTrain on 4 samples\r\n\r\n4/4 [==============================] - 0s 2ms/sample - loss: 410.5582 - q_values_loss: 410.5582\r\nTrain on 4 samples\r\n\r\n4/4 [==============================] - 0s 2ms/sample - loss: 412.2753 - q_values_loss: 412.2753\r\nTrain on 5 samples\r\n\r\n5/5 [==============================] - 0s 2ms/sample - loss: 410.8856 - q_values_loss: 410.8856\r\n```\r\n\r\n\r\n", "@pavithrasv I think I found a way to show the different behaviour in TensorFlow nightly by using `with tf.Graph().as_default():` instead of the `experimental_run_tf_function` argument:\r\n\r\n[https://colab.research.google.com/drive/1clvvsr9i0Tvt8o3vyy8N3FSdSdX5-Se6](https://colab.research.google.com/drive/1clvvsr9i0Tvt8o3vyy8N3FSdSdX5-Se6)\r\n\r\nI also added a TensorBoard visualization of the loss behaviour. Orange is with eager on and Blue with eager off (both on log scale):\r\n\r\n![image](https://user-images.githubusercontent.com/554786/73318752-7d1c0900-428e-11ea-8e61-00d1ffb566e6.png)\r\n\r\nNote: Both runs have the same number of iterations, the Blue line is only shorter because execution time is much faster with eager off.", "I think I narrowed the problem further down. The current code is basically:\r\n```\r\ninput_layer = tf.keras.Input(shape=(BOARD_SIZE * 3,))\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 9, activation='relu')(input_layer)\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 100, activation='relu')(x)\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 9, activation='relu')(x)\r\nq_values = tf.keras.layers.Dense(BOARD_SIZE, activation=None, name='q_values')(x)\r\nprobabilities = tf.keras.layers.Softmax(name='probabilities')(q_values)\r\n\r\nself.model = tf.keras.Model(inputs=input_layer, outputs=[probabilities, q_values])\r\nself.model.compile(optimizer='adam', loss = [None, tf.keras.losses.MeanSquaredError()])\r\n```\r\n\r\nand training happens with:\r\n```\r\nres = self.model.fit(np_inputs, {'q_values': np_targets}, verbose=0)\r\n```\r\n\r\nThis works with eager mode off, but does not work with eager mode enabled.\r\n\r\nIf I change the code slightly by changing the order of the ouputs and loss arguments:\r\n\r\n```\r\ninput_layer = tf.keras.Input(shape=(BOARD_SIZE * 3,))\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 9, activation='relu')(input_layer)\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 100, activation='relu')(x)\r\nx = tf.keras.layers.Dense(BOARD_SIZE * 3 * 9, activation='relu')(x)\r\nq_values = tf.keras.layers.Dense(BOARD_SIZE, activation=None, name='q_values')(x)\r\nprobabilities = tf.keras.layers.Softmax(name='probabilities')(q_values)\r\n\r\nself.model = tf.keras.Model(inputs=input_layer, outputs=[q_values, probabilities])\r\nself.model.compile(optimizer='adam', loss = [tf.keras.losses.MeanSquaredError(), None])\r\n```\r\n\r\nthis now seems to work in both version (although still much slower with eager mode enabled).\r\n\r\nOne potential explanation might be that the order of `loss` functions with eager mode disabled is the same as the order of the specified `outputs` in the `Model` constructor, but for some reason with eager mode enabled the order of `loss` functions is matching the order they appear in the graph. Not sure if that's the case, but it would explain the observed behaviour.", "@pavithrasv I dug around a bit more and I think this is the point where things go pear-shaped:\r\n\r\ntraining_eager.py#_model_loss(), currently around line 147:\r\n```\r\n[...]\r\n    loss_fns = [\r\n        loss_fn for loss_fn in model.loss_functions if loss_fn is not None\r\n    ]\r\n[...]\r\n```\r\nthis removes `None` entries from the list of loss functions. However the corresponding outputs are not removed from the `outs` list. This results in the lists becoming un-aligned and all subsequent loss computations using the wrong outputs to apply the loss function to.", "Thank you @fcarsten for taking a look. We are doing a bunch of code refactoring internally and i think this use case in eager will be fixed as part of that. Will update this thread after I know when it is fixed in a tf-nightly release.", "@fcarsten Looks like this was resolved. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/412bf7495d33e61fde09ee6736c01d83/tensorflow-issue-36044.ipynb). \r\n\r\n\r\n```\r\nrun_test(True)\r\n\r\n\r\nAfter 100 game we have draws: 6, Player 1 wins: 87, and Player 2 wins: 7.\r\nWhich gives percentages of draws: 6.00%, Player 1 wins: 87.00%, and Player 2 wins:  7.00%\r\nAfter 100 game we have draws: 8, Player 1 wins: 82, and Player 2 wins: 10.\r\nWhich gives percentages of draws: 8.00%, Player 1 wins: 82.00%, and Player 2 wins:  10.00%\r\nAfter 100 game we have draws: 9, Player 1 wins: 83, and Player 2 wins: 8.\r\nWhich gives percentages of draws: 9.00%, Player 1 wins: 83.00%, and Player 2 wins:  8.00%\r\nAfter 100 game we have draws: 9, Player 1 wins: 82, and Player 2 wins: 9.\r\nWhich gives percentages of draws: 9.00%, Player 1 wins: 82.00%, and Player 2 wins:  9.00%\r\nAfter 100 game we have draws: 4, Player 1 wins: 87, and Player 2 wins: 9.\r\nWhich gives percentages of draws: 4.00%, Player 1 wins: 87.00%, and Player 2 wins:  9.00%\r\nAfter 100 game we have draws: 5, Player 1 wins: 87, and Player 2 wins: 8.\r\nWhich gives percentages of draws: 5.00%, Player 1 wins: 87.00%, and Player 2 wins:  8.00%\r\nAfter 100 game we have draws: 3, Player 1 wins: 91, and Player 2 wins: 6.\r\nWhich gives percentages of draws: 3.00%, Player 1 wins: 91.00%, and Player 2 wins:  6.00%\r\nAfter 100 game we have draws: 6, Player 1 wins: 85, and Player 2 wins: 9.\r\nWhich gives percentages of draws: 6.00%, Player 1 wins: 85.00%, and Player 2 wins:  9.00%\r\nAfter 100 game we have draws: 1, Player 1 wins: 93, and Player 2 wins: 6.\r\nWhich gives percentages of draws: 1.00%, Player 1 wins: 93.00%, and Player 2 wins:  6.00%\r\nAfter 100 game we have draws: 5, Player 1 wins: 92, and Player 2 wins: 3.\r\nWhich gives percentages of draws: 5.00%, Player 1 wins: 92.00%, and Player 2 wins:  3.00%\r\n```\r\n\r\n![With_ZTRUE](https://user-images.githubusercontent.com/46058173/119066927-c3bad880-b995-11eb-9b1d-def7be79ff0d.png)\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks, looks good. I'm snowed under at the moment, so can't immediately validate but happy to close it based on @jvishnuvardhan results. Can always reopen if evidence to the contrary emerges.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36044\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36044\">No</a>\n"]}, {"number": 36043, "title": "Add usage example for tf.image.transpose", "body": "", "comments": ["Thanks for the quick review! I copied that text from another method, and fixed those too.", "@rickwierenga looks good. There wasn't any need of thanking me anyway u are welcome  :) ", "@Mbah-Javis, could you please approve the changes via code review so GitHub knows it's been reviewed? Thanks.", "> @Mbah-Javis, could you please approve the changes via code review so GitHub knows it's been reviewed? Thanks.\r\n\r\nI would have love too but lets wait for the admins to take a look at it first hope u understand \ud83d\udc4d ", "Please open against `master` branch, not against a release branch", "Hadn't seen that, I'm sorry. `master` already has a usage example for `transpose`, so I'm adding a usage example for `pad_to_bounding_box` instead. See https://github.com/tensorflow/tensorflow/pull/36056."]}, {"number": 36042, "title": "NotImplementedError in conv2 when i use in tf.distribute.experimental.CentralStorageStrategy() for multi gpus in tf2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):\r\n- TensorFlow installed from conda install tensorflow.\r\n- TensorFlow version : 2.0.0\r\n- Python version: Python 3.7.6 \r\n- GCC/Compiler version (if compiling from source): gcc version 7.4.0\r\n- CUDA/cuDNN version: CUDA Version 10.1.243\r\n- GPU model and memory: 4 gpus of Tesla V100-SXM2-16Gb\r\n\r\n**Describe the current behavior**\r\nI used in `tf.distribute.experimental.CentralStorageStrategy()` for use all the gpus in my computer\r\n I run the following code and got `NotImplementedError`\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Conv2D, Input\r\n\r\nstrategy = tf.distribute.experimental.CentralStorageStrategy()\r\nwith strategy.scope():\r\n    Xi = np.zeros((2,1,1,396))\r\n    Pi = Input(shape=(1,1,4), name = 'input_layer_preamble')\r\n    Pd = Conv2D(int(Xi.shape[3]//Pi.shape[3]), (1, 1), padding='same', data_format='channels_first', use_bias=False)(Pi)\r\n```\r\n \r\n\r\n\r\n**Describe the current behavior**\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2712, in variable_creator_scope\r\n    yield\r\n  File \"tf2_nulty_gpus.py\", line 9, in <module>\r\n    Pd = Conv2D(int(Xi.shape[3]//Pi.shape[3]), (1, 1), padding='same', data_format='channels_first', use_bias=False)(Pi)\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 817, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2141, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 165, in build\r\n    dtype=self.dtype)\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2311, in __setattr__\r\n    if val.trainable:\r\n  File \"/home/ubuntu/anaconda3/envs/my_tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 477, in trainable\r\n    raise NotImplementedError\r\nNotImplementedError\r\n```", "comments": ["When implementing CentralStorageStrategy, I am also encountering this error.\r\nThis is from a docker built today using tensorflow/tensorflow:latest-gpu-py3-jupyter after calling Conv2D from tensorflow.keras.layers.\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    746           # Build layer if applicable (if the `build` method has been\r\n    747           # overridden).\r\n--> 748           self._maybe_build(inputs)\r\n    749           cast_inputs = self._maybe_cast_inputs(inputs)\r\n    750 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   2114         # operations.\r\n   2115         with tf_utils.maybe_init_scope(self):\r\n-> 2116           self.build(input_shapes)\r\n   2117       # We must set self.built since user defined build functions are not\r\n   2118       # constrained to set self.built.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py in build(self, input_shape)\r\n    156         constraint=self.kernel_constraint,\r\n    157         trainable=True,\r\n--> 158         dtype=self.dtype)\r\n    159     if self.use_bias:\r\n    160       self.bias = self.add_weight(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py in __setattr__(self, name, value)\r\n   2294       self._maybe_create_attribute('_trainable_weights', [])\r\n   2295       self._maybe_create_attribute('_non_trainable_weights', [])\r\n-> 2296       if val.trainable:\r\n   2297         if any(val is w for w in self._trainable_weights):\r\n   2298           continue\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py in trainable(self)\r\n    478   @property\r\n    479   def trainable(self):\r\n--> 480     raise NotImplementedError\r\n    481 \r\n    482   @property\r\n\r\nNotImplementedError: \r\n```\r\n\r\nIs there a known workaround?", "Solution: use tf.distribute.MirroredStrategy() for multiple-GPUs", "This solution isn't good, when I used in MirroredStrategy I got this error:\r\n\r\n`2020-02-23 20:57:18.371348: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 47520000000 exceeds 10% of system memory.\r\n`\r\n\r\nwhat can I do to fix this error? ", "I have the same issue. I can easily use MirroredStrategy, but with CentralStorageStrategy I get the same error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 3, in <module>\r\n  File \"/home/dinis/msc-thesis/Code/February/VGG16/vgg16.py\", line 27, in vgg16\r\n    activation=activations[0])\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\", line 178, in add\r\n    layer(x)\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 817, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2141, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 165, in build\r\n    dtype=self.dtype)\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2311, in __setattr__\r\n    if val.trainable:\r\n  File \"/home/dinis/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 477, in trainable\r\n    raise NotImplementedError\r\nNotImplementedError\r\n```\r\n", "Hi @14asaf, this was indeed a bug that I believe has now been fixed. If you are still facing problems, please update the thread with reproducible code as I'm not seeing any problems when running the code sample you've provided in TF 2.2 with 2 GPUs. ", "Thank you for the answer,\r\n\r\nNow I use in TF2.2 and I I managed  with the problem of  MirroredStrategy.\r\n\r\nI converted the data to float16 and now I have enough memory space in the Ram.", "Closing this issue now since there was a fix. But feel free to reopen if you think it needs further discussion.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36042\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36042\">No</a>\n"]}, {"number": 36041, "title": "Fix release builds pt2", "body": "Had a typo on `pip install` where I included a `-y` flag but that does not exist.\r\n\r\nAlso, we need to filter out the tests that depend on `contrib`. We already did on the presubmits but we forgot to do on the release.", "comments": []}, {"number": 36040, "title": "Fix release builds pt2", "body": "Had a typo on `pip install` where I included a `-y` flag but that does not exist.\r\n\r\nAlso, we need to filter out the tests that depend on `contrib`. We already did on the presubmits but we forgot to do on the release.", "comments": []}, {"number": 36039, "title": "ADD NEW DOCUMENTATION ON HOW TO INTERACT WITH ASTRONOMY WITH ANIMATION ?", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n\r\n\r\n\r\n## Description of issue (what needs changing):\r\nWe need a new documentation to interact with astronomy.\r\n### Clear description\r\n\r\nLike we think astronomical animation is good for research. We need a new documentaion how to interact with Phoebe or with other by Tensorflow .\r\n\r\n\r\n", "comments": ["https://github.com/phoebe-project ? \r\n\r\nThis request is a little too specific. We can't have a doc showing how to make TensorFlow work with every piece of software out there, we have docs for how to use standard data types like CSV files, NumPy arrays or Pandas Dataframes. Those probably have everything you need.  "]}]