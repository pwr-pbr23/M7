[{"number": 21793, "title": "Images come without keras", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["There doesn't seem to be any content here."]}, {"number": 21792, "title": "Can't connect to docker as remote interpreter when running on a remote machine", "body": "I am using the container on a remote machine\r\n\r\nWhen I run regular python on it, I use pycharm to run ssh interpreter, it syncs the needed directories and runs the wanted scripts and works great, \r\n\r\nI need the docker to somehow expose it's filesystem and interpreter on a host's port and connect to it via pycharm remote interpreter (from another machine) \r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21791, "title": "can't connect to container as remote interpreter when running container on remote machine", "body": "I am working with a remote machine, \r\n\r\nAnd using pycharm to run remote interpreter\r\n\r\nI need the docker to somehow expose the python interpreter via a host's port so I can connect to it, sync directories and run python scripts", "comments": []}, {"number": 21790, "title": "decorate sparse_categorical_accuracy with  tf_export decorator", "body": "according to [Issue21735](https://github.com/tensorflow/tensorflow/issues/21735#issue-352151121), it may be a mistake that only `sparse_categorical_accuracy` is NOT decorated by `tf_export` and result in explicit import i.e. `from tensorflow.keras.metrics import sparse_categorical_crossentropy`.", "comments": ["You will likely need to regenerate the golden API files to reflect the new symbol being added. We are assuming the API review will be done by @fchollet .", "@josh11b  May you tell me how to regenerate **golden API files**? I solely edit local source code for now", "Try running: tensorflow/tools/api/tests/api_compatibility_test it should fail and give instructions on how to rerun it to regenerate the golden files.", "@josh11b \r\nThanks \r\nthere is NO `api_compatibility_test.py` because installed by pypi. \r\nWhat should i do?\r\n", "We are looking into making the error message you get when we run the API compatibility test in our CI copyable, so you'd be able to just manually update the golden files. I see how this would be useful especially for small changes like this.\r\n\r\nWould you mind if I redo this change? That'll be the simplest way to get it done.", "@martinwicke Sure, go right ahead"]}, {"number": 21789, "title": "Fix sparse updates for optimizers using DecoupledWeightDecay.", "body": "As mentioned by @yym-ustc in the original pull request #17438, there was a bug in the sparse update.\r\nPing @alextp who reviewed #17438.", "comments": ["I don't think the keras test failures are related to this pull request?", "They are unrelated; we need to retry\n\nOn Wed, Aug 22, 2018 at 12:44 PM Phil <notifications@github.com> wrote:\n\n> I don't think the keras test failures are related to this pull request?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/21789#issuecomment-415154805>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxW8rFHIY96rS04XK2a0YHxBaRBj6ks5uTbSigaJpZM4WHPW2>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 21788, "title": "tf.keras.utils.multi_gpu_model does use only one GPU", "body": "Tensorflow 1.10\r\nDocker container 1.10.0-gpu-py3 from https://hub.docker.com/r/tensorflow/tensorflow/\r\nI think this is a bug. I expect tf.keras.utils.multi_gpu_model to use multiple GPUs. However with the following example it uses only 1 (checking with nvidia-smi):\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications import Xception\r\nfrom tensorflow.keras.utils import multi_gpu_model\r\nimport numpy as np\r\n\r\nnum_samples = 32\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nwith tf.device('/cpu:0'):\r\n    model = Xception(weights=None,input_shape=(height, width, 3),classes=num_classes)\r\n\r\n# Replicates the model on 2 GPUs.\r\n# This assumes that your machine has 2 available GPUs.\r\nparallel_model = multi_gpu_model(model, gpus=2)\r\nparallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n# Generate dummy data.\r\nx = np.random.random((num_samples, height, width, 3)).astype(np.float32)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(x)\r\ndataset = dataset.batch(32)\r\ndataset = dataset.repeat()\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nbatch = iterator.get_next()\r\n\r\ny = parallel_model(batch)\r\n\r\nsess = tf.keras.backend.get_session()\r\nwhile True:\r\n    try:\r\n        result = sess.run(y)\r\n        print(result.shape)\r\n    except tf.errors.OutOfRangeError:\r\n        break\r\n```\r\n\r\n\r\n\r\n\r\n\r\nSee also https://stackoverflow.com/questions/51962659/tf-keras-utils-multi-gpu-model-does-use-only-one-gpu\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@robieta what do you think?", "Testing again with tensorflow/tensorflow:1.12.0-rc2-gpu-py3\r\n\r\nThis issue is not solved yet, still only 1 GPU is used.\r\n\r\nOutput of nvidia-smi looks like this:\r\n![screenshot from 2018-11-01 12-54-49](https://user-images.githubusercontent.com/464378/47850572-fe5bc600-ddd5-11e8-8829-fee5bd227fc4.png)\r\n", "I replaced the last section of your code\r\n```\r\niterator = dataset.make_one_shot_iterator()\r\nbatch = iterator.get_next()\r\n\r\ny = parallel_model(batch)\r\n\r\nsess = tf.keras.backend.get_session()\r\nwhile True:\r\n    try:\r\n        result = sess.run(y)\r\n        print(result.shape)\r\n    except tf.errors.OutOfRangeError:\r\n        break\r\n```\r\n\r\nwith\r\n\r\n```\r\nparallel_model.fit(dataset, steps_per_epoch=1000)\r\n```\r\n\r\nAnd it parallelized as expected.", "I'm still getting this problem,even at the begining before the actual computing. The memory usage of one GPU is higher than the others. What could be the cause of this problem? @robieta Thank you.\r\n![image](https://user-images.githubusercontent.com/30249811/60592533-6a625400-9dd3-11e9-83b7-ff8b44f9aa79.png)\r\n", "I have the same problem,", "I have the same issue.", "any solution for it ? i cant use tf.distribute.Strategy because i use fit_generator, and disable eager mode dont help too", "Same issue. "]}, {"number": 21787, "title": "tflite runs much slower than tfmobile ...", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu14.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Xiaomi 8\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0 / 7.1\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nI test performance of tf-mobile, tf-lite, tf-mobile-int8, tf-lite-int8 on android, and I find that the speed of tf-lite is much slower than tf-mobile.\r\n\r\n1. I use `freeze_graph` to generate `A.pb` file from `checkpoint` for testing tf-mobile performance.\r\n\r\n2. I use `toco_convert` to convert `A.pb` file to `A.tflite` file for for testing tf-lite performance.\r\n\r\n3. I use `transform_graph` to get quantitative `AQ.pb` file from `A.pb` file for testing tf-mobile int8 performance.\r\n\r\n4. I train a model with the same architecture by adding the line `tf.contrib.quantize.create_training_graph()`  and get the `checkpoint` file. Then I replace the line with `tf.contrib.quantize.create_eval_graph()` to generate the `A.pbtxt` file, and use `checkpoint` file and `A.pbtxt` file to get `A8.pb` with fake quantization nodes. Finally, I use `toco_convert` to get the `A8.tflite` file.\r\n\r\n5. I test the performance with these 4 files on android, each runs several times for inference on the same image, and the result is listed below:\r\n\r\ntf-mobile:           357ms per image\r\ntf-mobile int8:    356ms per image\r\ntf-lite:                 844ms per image\r\ntf-lite int8;          571ms per image\r\n\r\n**I wonder why tf-lite is much slower than tf-mobile.**\r\n\r\nPS: the model architecture only contains: CONV+BN+RELU, RESHAPE, FULLY-CONTECT ops.\r\n\r\nThe features shape from CONV+BN+RELU is [B,T,C], then I reshape it to [-1,C] and go on to the fc layer, then reshape the out with shape [B*T,K] to [B,T,K], which is the final result I expected.\r\n\r\n**I wonder is the reshape op the brings the worse performance ?**\r\n\r\n**Thank you very much ...**\r\n\r\n", "comments": ["@aselle Could you please take a look ?", "@jiarenyf which version of TFLite are you using, can you use the [benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/benchmark) to profile. If you are using an older version of TFLite then there was a severe regression in Conv: issue #15554 which has been fixed. TFLite performance on most models is better than tf-mobile. \r\nAlso can you include a model with the bug, I can help in debugging the performance issues.", " @shashishekhar \r\n\r\nI use `org.tensorflow:tensorflow-lite:1.10.0`\r\n\r\nI can share you the 4 files I mentioned above, all are generated with random variables.\r\n\r\nhttps://share.weiyun.com/5FXn1pe\r\n\r\nThank you.\r\n\r\n", "@jiarenyf : Thanks, I ran a few preliminary benchmarks using the [benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/benchmark), on Pixel 2 TFLite \r\ncnn+ctc8.tflite was \r\nnum_threads= 1, average: 258.86 ms\r\nnum_threads = 4: average: 105 ms.\r\n\r\nI compiled with arm64, how are you benchmarking, are you building arm64 for TFLite?.\r\n\r\nLooking at the numbers for floating point, looks like the Fully connected op takes some time, I doubt reshape op is slower.\r\nOne other thing to note, Tensorflow mobile benchmark by default uses multiple threads, whereas TFLite uses a single thread. Make sure you are explicitly passing the number of threads for both benchmarks.", "@shashishekhar Thanks.\r\n\r\nI use the benchmark tool to test performance tf-mobile and tf-lite on `desktop`. And the performance of the tf-mobile and tf-lite are recoded in `benchmark_on_mobile.txt` and `benchmark_on_lite.txt`.\r\n\r\n```\r\n../../benchmark_model \\\r\n  --graph='./cnn+ctc.pb' \\\r\n  --input_layer='images_placeholder' \\\r\n  --input_layer_shape='1,48,480,1' \\\r\n  --input_layer_type='float' \\\r\n  --output_layer='Reshape_1' \\\r\n  --num_threads=4\r\n```\r\n\r\n[benchmark_on_mobile.txt](https://github.com/tensorflow/tensorflow/files/2334382/benchmark_on_mobile.txt)\r\n\r\n```\r\n../../benchmark_model_tflite \\\r\n  --graph='./cnn+ctc.tflite' \\\r\n  --input_layer='images_placeholder' \\\r\n  --input_layer_shape='1,48,480,1' \\\r\n  --num_threads=4\r\n```\r\n\r\n[benchmark_on_lite.txt](https://github.com/tensorflow/tensorflow/files/2334381/benchmark_on_lite.txt)\r\n\r\nI wonder:\r\n\r\n1. In the `benchmark_on_lite.txt` there is `8 conv2d + 1 DEPTHWISE_CONV_2D`, while in `benchmark_on_mobile.txt` there is `9 conv2d`. I use the `pb` file to generate the `tflite` file, so why the network architecture is different ?\r\n\r\n2. In the `benchmark_on_mobile.txt`, `Conv2D` takes `305ms` and `MatMul` takes `36ms`, while in the `benchmark_on_tflite.txt`,  `Conv2D` takes `377ms` and `fully-connected` takes `382ms`. Why the time of `fc-layer` is different ?\r\n\r\nAll the files are provided here: [All the files: *.txt, *.pb, *.tflie](https://share.weiyun.com/5t3ZFCX)\r\n\r\nThank you.\r\n", "@jiarenyf : Thank you for the report, I am looking into the differences.\r\nNote: for desktop TFLite doesn't have optimized kernels but for mobile there are neon optimized kernels. \r\nAlso since the graph is converted, the operations are not entirely the same.\r\n\r\nI am looking into why there maybe a difference between performance difference here and TFLite is accidentally taking a slow path.", "@shashishekhar Do you have any idea about the performance difference between tf-mobile and tf-lite ?", "@jiarenyf : Sorry I didn't get time to investigate this, will try to update the bug sometime in coming weeks.", "It also happens to me. Using a float model, the inference time in tfmobile is 50-60ms while in tensorfloe lite, it reaches 80-110ms. ", "What is the exact command you're using to build `benchmark_model_tflite`? Be sure to include `-c opt --config=android_armt64` in your build command.", "I'm able to reproduce the issue. We will track this internally and report back after we investigate further.", "@andrehentz \r\n\r\nHey, do you have any progress with the issue ?", "We have an internal fix which dramatically improves performance (~2-3x), however, we're still running it through some accuracy/validation testing. It's unlikely the fix will land in the next week or two (due to holidays), but expect something concrete in early January.", "@jdduke Sounds good! Looking forward for the fix :)", "@jdduke Any idea on timings the fix? Thanks!", "@jdduke Is the fix already available in the tflite-nightle:0.0 version?", "It's not quite there, expect an update in the next week or two. Thanks for your patience.", "We're in the process of upstreaming the fix to Eigen, stay tuned.", "@jdduke Thanks for the fix, waiting for it. I am on the 'edge' of releasing app and faster inference would be really helpful. But I cannot wait week or more so I need to decide. I just wanted to ask if you have any further information, when the new release will be public? Thank you very much!", "@jdduke Are there any updates on the fix? Thank you!", "Apologies for the delay, I've been out for the past several weeks. Commit 161c500 should improve performance for TFLite's fully_connected operator, bringing it in line with TensorFlow(mobile).", "As for TRANSPOSE_CONV ops, TFLite is still much slower than TFMobile unfortunately. \r\nWould you like to check my benchmark report #26736 ?", "Thanks for the report, we'll take a look on that issue."]}, {"number": 21786, "title": "MirroredStrategy error with Object detection retraining", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Not on Mobile device\r\n- **TensorFlow installed from (source or binary)**: Built from source using branch 'v1.9.0-0-g25c197e'\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: Build label: 0.15.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: Cuda version:9.1 cuDNN version:7.1.2\r\n- **GPU model and memory**: 4 x GRID K520, Memory: 3.94GiB\r\n- **Exact command to reproduce**:\r\npython object_detection/model_main.py \\\r\n    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\r\n    --model_dir=${MODEL_DIR} \\\r\n    --num_train_steps=${NUM_TRAIN_STEPS} \\\r\n    --num_eval_steps=${NUM_EVAL_STEPS} \\\r\n    --alsologtostderr\r\n\r\nFollowing is the code change I made to https://github.com/tensorflow/models/blob/master/research/object_detection/model_main.py\r\n\r\n```\r\ndef main(unused_argv):\r\n  flags.mark_flag_as_required('model_dir')\r\n  flags.mark_flag_as_required('pipeline_config_path')\r\n\r\n  distribution = tf.contrib.distribute.MirroredStrategy()\r\n  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,train_distribute=distribution)\r\n```\r\n\r\n### Describe the problem\r\nI am retraining ssd_mobilenet_v1_coco and following the steps as per https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md\r\n\r\nI am able to run the retraining using OneDeviceStrategy and None distribution.\r\nHowever when using MirroredStrategy I get the following error:\r\n\r\n```2018-08-22 06:49:29.272903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-22 06:49:29.273436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GRID K520 major: 3 minor: 0 memoryClockRate(GHz): 0.797\r\npciBusID: 0000:00:03.0\r\ntotalMemory: 3.94GiB freeMemory: 3.90GiB\r\n2018-08-22 06:49:29.309479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-22 06:49:29.310018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 1 with properties: \r\nname: GRID K520 major: 3 minor: 0 memoryClockRate(GHz): 0.797\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 3.94GiB freeMemory: 3.90GiB\r\n2018-08-22 06:49:29.343433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-22 06:49:29.343977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 2 with properties: \r\nname: GRID K520 major: 3 minor: 0 memoryClockRate(GHz): 0.797\r\npciBusID: 0000:00:05.0\r\ntotalMemory: 3.94GiB freeMemory: 3.90GiB\r\n2018-08-22 06:49:29.379652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-22 06:49:29.380222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 3 with properties: \r\nname: GRID K520 major: 3 minor: 0 memoryClockRate(GHz): 0.797\r\npciBusID: 0000:00:06.0\r\ntotalMemory: 3.94GiB freeMemory: 3.90GiB\r\n2018-08-22 06:49:29.380429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1, 2, 3\r\n2018-08-22 06:49:30.617246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-22 06:49:30.617312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 2 3 \r\n2018-08-22 06:49:30.617327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N N N N \r\n2018-08-22 06:49:30.617345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N N N N \r\n2018-08-22 06:49:30.617360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   N N N N \r\n2018-08-22 06:49:30.617371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   N N N N \r\n2018-08-22 06:49:30.617926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3648 MB memory) -> physical GPU (device: 0, name: GRID K520, pci bus id: 0000:00:03.0, compute capability: 3.0)\r\n2018-08-22 06:49:30.653271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3648 MB memory) -> physical GPU (device: 1, name: GRID K520, pci bus id: 0000:00:04.0, compute capability: 3.0)\r\n2018-08-22 06:49:30.689029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 3648 MB memory) -> physical GPU (device: 2, name: GRID K520, pci bus id: 0000:00:05.0, compute capability: 3.0)\r\n2018-08-22 06:49:30.724507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 3648 MB memory) -> physical GPU (device: 3, name: GRID K520, pci bus id: 0000:00:06.0, compute capability: 3.0)\r\nWARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f679afa32f0>) includes params argument, but params are not passed to Estimator.\r\n2018-08-22 06:49:30.781121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1, 2, 3\r\n2018-08-22 06:49:30.781362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-22 06:49:30.781389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 2 3 \r\n2018-08-22 06:49:30.781409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N N N N \r\n2018-08-22 06:49:30.781424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N N N N \r\n2018-08-22 06:49:30.781442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   N N N N \r\n2018-08-22 06:49:30.781458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   N N N N \r\n2018-08-22 06:49:30.781801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/device:GPU:0 with 3648 MB memory) -> physical GPU (device: 0, name: GRID K520, pci bus id: 0000:00:03.0, compute capability: 3.0)\r\n2018-08-22 06:49:30.781913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/device:GPU:1 with 3648 MB memory) -> physical GPU (device: 1, name: GRID K520, pci bus id: 0000:00:04.0, compute capability: 3.0)\r\n2018-08-22 06:49:30.781999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/device:GPU:2 with 3648 MB memory) -> physical GPU (device: 2, name: GRID K520, pci bus id: 0000:00:05.0, compute capability: 3.0)\r\n2018-08-22 06:49:30.782122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/device:GPU:3 with 3648 MB memory) -> physical GPU (device: 3, name: GRID K520, pci bus id: 0000:00:06.0, compute capability: 3.0)\r\nWARNING:tensorflow:num_readers has been reduced to 2 to match input file shards.\r\nWARNING:tensorflow:From /home/ubuntu/tensorflow/models/research/object_detection/core/preprocessor.py:1205: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the `axis` argument instead\r\nTraceback (most recent call last):\r\n  File \"object_detection/model_main.py\", line 106, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"object_detection/model_main.py\", line 102, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 447, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 531, in run\r\n    return self.run_local()\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\", line 669, in run_local\r\n    hooks=train_hooks)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 366, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1117, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1160, in _train_model_distributed\r\n    self.config)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 794, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 269, in _call_for_each_tower\r\n    coord.join(threads)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 479, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1107, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/home/ubuntu/tensorflow/models/research/object_detection/model_lib.py\", line 252, in model_fn\r\n    preprocessed_images, features[fields.InputDataFields.true_image_shape])\r\n  File \"/home/ubuntu/tensorflow/models/research/object_detection/meta_architectures/ssd_meta_arch.py\", line 514, in predict\r\n    preprocessed_inputs)\r\n  File \"/home/ubuntu/tensorflow/models/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py\", line 126, in extract_features\r\n    scope=scope)\r\n  File \"/home/ubuntu/tensorflow/models/research/slim/nets/mobilenet_v1.py\", line 284, in mobilenet_v1_base\r\n    scope=end_point)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 2798, in separable_convolution2d\r\n    collections=weights_collections)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 297, in model_variable\r\n    use_resource=use_resource)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 252, in variable\r\n    use_resource=use_resource)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1328, in get_variable\r\n    constraint=constraint)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1090, in get_variable\r\n    constraint=constraint)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 427, in get_variable\r\n    return custom_getter(**custom_getter_kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1734, in wrapped_custom_getter\r\n    *args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1744, in layer_variable_getter\r\n    return _model_variable_getter(getter, *args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1735, in _model_variable_getter\r\n    use_resource=use_resource)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 297, in model_variable\r\n    use_resource=use_resource)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 252, in variable\r\n    use_resource=use_resource)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 599, in disable_partitioned_variables\r\n    return getter(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\r\n    use_resource=use_resource, constraint=constraint)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 806, in _get_single_variable\r\n    with ops.colocate_with(v):\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4219, in _colocate_with_for_gradient\r\n    with self.colocate_with(op, ignore_existing):\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/contextlib.py\", line 81, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4272, in colocate_with\r\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1268, in internal_convert_to_tensor_or_indexed_slices\r\n    value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1107, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/values.py\", line 245, in _tensor_conversion\r\n    assert not as_ref\r\nAssertionError\r\n```\r\nI also switched the gpu using OneDeviceStrategy to any of the 4 available GPU without a problem.\r\nI run into the problem only when using MirroredStrategy. Reproducibility 100%", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I updated the issue to reflect the details. Let me know if you need more details.", "This issue has been fixed in TF v1.11. Can you try updating TensorFlow and retrying this example? Thanks!", "Nagging Assignee @anj-s: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing this bug since it should be fixed. \r\nPlease reopen if you run into this issue again. ", "I am still running into the problem on Tensorflow version 1.11.0\r\nAttaching the Error Log. \r\n[TF_MirroredStrategy_error.txt](https://github.com/tensorflow/tensorflow/files/2512393/TF_MirroredStrategy_error.txt)\r\n I am retraining Mobilenet v2 SSD model on AWS2.8 which has 4 GPUS.\r\n", "Also have a similar problem (faster_rcnn_resnet50 instead of mobilenet), and using Tensorflow 1.12.0."]}, {"number": 21785, "title": "Tensorflow and Opencv in C++", "body": "Hello,\r\n\r\nI just buy a Tensorflow and OpenCV application in C++ in Ubuntu. As soon as I add a Tensorflow object in my program I can't read images from the VideoCapture. The sended images are all black.\r\n\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: IUbuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: I use Tensorflow 1.5 source to generate the 2 so files\r\n- **TensorFlow version (use command below)**: 1.5 (source\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) \r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n------------------------\r\n\r\n\r\n\r\nI don't really understand why Tensorflow so file change the behaviors of OpenCV.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nExact command to reproduce\nMobile device", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21784, "title": "register gpu kernel for div_no_nan", "body": "This is a follow up PR for #21621.", "comments": ["@asimshankar @drpngx @martinwicke Could you take a look? Thanks.", "```\r\nValueError: The use_gpu value used to get the cached session is different than the one that was used to create the session. Maybe create a new session with self.session()\r\n```", "Thank you, @drpngx . So will cache_session raise ValueError if use_gpu?", "I initial thought it was due to this PR change in `_test.py`, but it was in some other test  in keras, so I think it was unrelated.", "Oh, I see :-)"]}, {"number": 21783, "title": "add num_steps to TrainSpec", "body": "The TrainSpec currently does not support training for a fixed number of steps. This is rather inconvenient for continuous training. For example, if we have a model which trains incrementally every day with `./train.py --steps=1000`, the model won't train in the second day because we set the max_steps in the TrainSpec.\r\n\r\nDue to the way how `train_and_evaluate` runs training and evaluation, it is also impossible to stop the training using the `StopAtStepHook`, which does support `num_steps`. Therefore I felt it is best to add a `num_steps` argument to the `TrainSpec`.", "comments": ["I think this is a difference between the workflow you are using vs the the workflow this API is designed for. \r\n\r\nispir@ might provide more thoughts here. \r\n\r\nBut typically, the daily incremental training is achieved in the following way:\r\n1. Train the model for day 1\r\n2. For day 2, start a new model_dir, set the warning starting in Estimator constructor to continue from day 1 checkpoint and start the training from empty model_dir. \r\n3. For day 3, a new model_dir and warn start he Estimator with day 2's ckpt.\r\n\r\nThis is production reliable approach. But it seems your workflow is different. \r\n\r\nOn top of my head, the problem with your approach is as follows:\r\n1. Say if you intend to train the model for 1000 steps every day. And you are at 20000 now in total.\r\n2. During the training in day N, at step 200500 (so half of the steps planned for that day), if the job gets crashed or restarted, which happens, after restarting, your job will train another 1000 steps due to the incremental configuration, and now it is beyond your goal. This is the design for max_steps. ", "Nagging Assignee @akshaym: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I see. Thank you for the clarification! Closing this."]}, {"number": 21781, "title": "add num_steps to TrainSpec", "body": "The TrainSpec currently does not support training for a fixed number of steps. This is rather inconvenient for continuous training. For example, if we have a model which trains incrementally every day with `./train.py --steps=1000`, the model won't train in the second day because we set the max_steps in the TrainSpec.\r\n\r\nDue to the way how `train_and_evaluate` runs training and evaluation, it is also impossible to stop the training using the `StopAtStepHook`, which does support `num_steps`. Therefore I felt it is best to add a `num_steps` argument to the `TrainSpec`.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 21780, "title": "Update Bazel NDK revision compatibility", "body": "Updated Bazel compatible Android NDK version. I also tried to re-word the docs to require less revision in the future. \r\nDemo app on Bazel 0.16.1 + NDK16 compiled without issue as a sanity check. \r\n\r\nThis should close https://github.com/tensorflow/tensorflow/issues/18000\r\nAnnouncement of Bazel NDK16 compatibility: https://github.com/bazelbuild/bazel/issues/4068#issuecomment-370068345", "comments": ["@seanpmorgan do you know which nkd version does tf.contrib.makefile support ?", "@zh794390558 Sorry, I do not. My suggestion would be to start with NDK 16 or 17 and work your way down in empirical tests.", "@seanpmorgan Thanks for your opinion.", "This PR is stale (for example configure.py supports NDK up to 18, though the READMEs are still behind.) Closing PR"]}, {"number": 21779, "title": "Tensorflow C++ build the tensorflow.dll failed", "body": "when i use cmake to compile the tensorflow.dll ,it shows a lot of error and the the number of the *.vcxproj is 266 but I just success only 43. Here is my configuration:\r\n python:3.5.2\r\ncuda:none \r\ncudnn:none\r\ntensorflow:1.8.0 \r\nvs\uff1a2015 \r\nswig:3.0.12 \r\nGit\uff1a2.18 \r\ncmake:3.10.2 \r\n\r\n![default](https://user-images.githubusercontent.com/36782510/44437048-d9cfba80-a5ea-11e8-8b0a-98bb6f912ad1.png)\r\n\r\nthe error list\uff1a\r\nE:\\Win_TF\\tensorflow-master\\tensorflow/c/c_api.h(1113): warning C4190: \u201cTF_NewWhile\u201d\u6709\u6307\u5b9a\u7684 C \u94fe\u63a5\uff0c\u4f46\u8fd4\u56de\u4e86\u4e0e C \u4e0d\u517c\u5bb9\u7684 UDT\u201cTF_WhileParams\u201d (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_graph.cc)\r\n43>  E:\\Win_TF\\tensorflow-master\\tensorflow/c/c_api.h(1069): note: \u53c2\u89c1\u201cTF_WhileParams\u201d\u7684\u58f0\u660e (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_graph.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_code.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\tfprof_options.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\tfprof_options.cc)\r\n43>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\tfprof_options.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\tfprof_options.cc)\r\n43>  tfprof_node.cc\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\advisor\\internal_checker_runner_dummy.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\advisor\\internal_checker_runner_dummy.cc)\r\n43>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\advisor\\internal_checker_runner_dummy.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\advisor\\internal_checker_runner_dummy.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_code.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_code.cc)\r\n43>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_code.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\profiler\\internal\\tfprof_code.cc)\r\n43>E:\\Win_TF\\tensorflow-master\\tensorflow/core/util/saved_tensor_slice_util.h(113): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\r\n...............\r\n.........\r\n.............\r\n232>------ \u5df2\u542f\u52a8\u751f\u6210: \u9879\u76ee: contrib_image_ops_gen_python, \u914d\u7f6e: Release x64 ------\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_nd_op_cpu_impl_7.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/kernels/gather_nd_op_cpu_impl.h(139): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_nd_op_cpu_impl_7.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\generate_vocab_remapping_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\generate_vocab_remapping_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\generate_vocab_remapping_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\gather_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\generate_vocab_remapping_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\guarantee_const_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\guarantee_const_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\guarantee_const_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\generate_vocab_remapping_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\guarantee_const_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\guarantee_const_op.cc)\r\n167>  histogram_op.cc\r\n167>  host_constant_op.cc\r\n167>  i_remote_fused_graph_ops_definitions.cc\r\n167>  identity_n_op.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\histogram_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\histogram_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\histogram_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\histogram_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\histogram_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\host_constant_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\host_constant_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\host_constant_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\i_remote_fused_graph_ops_definitions.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\i_remote_fused_graph_ops_definitions.cc)\r\n\r\n..........\r\n\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_instance_norm.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_instance_norm.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_matmul_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_matmul_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_matmul_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_mul_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_mul_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_mul_op.cc)\r\n242>LINK : fatal error LNK1181: \u65e0\u6cd5\u6253\u5f00\u8f93\u5165\u6587\u4ef6\u201cE:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_op_gen.obj\u201d\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_matmul_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_mul_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_matmul_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_mul_op.cc)\r\n245>------ \u5df2\u542f\u52a8\u751f\u6210: \u9879\u76ee: contrib_layers_sparse_feature_cross_ops_gen_python, \u914d\u7f6e: Release x64 ------\r\n167>  quantized_reshape_op.cc\r\n167>  quantized_resize_bilinear_op.cc\r\n167>  queue_base.cc\r\n244>LINK : fatal error LNK1181: \u65e0\u6cd5\u6253\u5f00\u8f93\u5165\u6587\u4ef6\u201cE:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_op_gen.obj\u201d\r\n246>------ \u5df2\u542f\u52a8\u751f\u6210: \u9879\u76ee: tf_contrib_reduce_slice_ops_ops, \u914d\u7f6e: Release x64 ------\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_pooling_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_pooling_ops.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_pooling_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_pooling_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_pooling_ops.cc)\r\n167>  queue_op.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_reshape_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_reshape_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_reshape_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_reshape_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_reshape_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_resize_bilinear_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_resize_bilinear_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_resize_bilinear_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_resize_bilinear_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\quantized_resize_bilinear_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_base.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_base.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_base.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_base.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_base.cc)\r\n167>  queue_ops.cc\r\n167>  random_crop_op.cc\r\n167>  random_op.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_op.cc)\r\n167>  random_poisson_op.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_ops.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\queue_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_crop_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_crop_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_crop_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_crop_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_crop_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_op.cc)\r\n246>  reduce_slice_ops.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_op.cc)\r\n167>  random_shuffle_op.cc\r\n167>  random_shuffle_queue_op.cc\r\n167>  range_sampler.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\range_sampler.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_poisson_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_poisson_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_poisson_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_poisson_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_poisson_op.cc)\r\n167>  reader_ops.cc\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_op.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_op.cc)\r\n246>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570\r\n246>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported\r\n246>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570\r\n246>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c\r\n246>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_queue_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\random_shuffle_queue_op.cc)\r\n\r\n......................\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\reverse_op.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\resource_variable_ops.cc)\r\n167>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\resource_variable_ops.cc)\r\n167>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\core\\kernels\\resource_variable_ops.cc)\r\n...................\r\n263>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0\r\n260>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\periodic_resample\\ops\\array_ops.cc)\r\n260>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\periodic_resample\\ops\\array_ops.cc)\r\n260>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\periodic_resample\\ops\\array_ops.cc)\r\n260>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\periodic_resample\\ops\\array_ops.cc)\r\n261>cl : \u547d\u4ee4\u884c warning D9025: \u6b63\u5728\u91cd\u5199\u201c/DTF_COMPILE_LIBRARY\u201d(\u7528\u201c/UTF_COMPILE_LIBRARY\u201d)\r\n261>  hyperplane_lsh_probes.cc\r\n264>------ \u5df2\u542f\u52a8\u751f\u6210: \u9879\u76ee: _beam_search_ops, \u914d\u7f6e: Release x64 ------\r\n261>cl : \u547d\u4ee4\u884c warning D9025: \u6b63\u5728\u91cd\u5199\u201c/DTF_COMPILE_LIBRARY\u201d(\u7528\u201c/UTF_COMPILE_LIBRARY\u201d)\r\n261>  nearest_neighbor_ops.cc\r\n263>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported\r\n263>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570\r\n263>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c\r\n263>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570\r\n261>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\nearest_neighbor\\kernels\\hyperplane_lsh_probes.cc)\r\n261>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\nearest_neighbor\\kernels\\hyperplane_lsh_probes.cc)\r\n261>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\nearest_neighbor\\kernels\\hyperplane_lsh_probes.cc)\r\n261>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\nearest_neighbor\\kernels\\hyperplane_lsh_probes.cc)\r\n261>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0 (\u7f16\u8bd1\u6e90\u6587\u4ef6 E:\\Win_TF\\tensorflow-master\\tensorflow\\contrib\\nearest_neighbor\\kernels\\hyperplane_lsh_probes.cc)\r\n264>cl : \u547d\u4ee4\u884c warning D9025: \u6b63\u5728\u91cd\u5199\u201c/DTF_COMPILE_LIBRARY\u201d(\u7528\u201c/UTF_COMPILE_LIBRARY\u201d)\r\n264>  beam_search_ops.cc\r\n264>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/tensor_types.h(105): error C2899: \u4e0d\u80fd\u5728\u6a21\u677f\u58f0\u660e\u4e4b\u5916\u4f7f\u7528\u7c7b\u578b\u540d\u79f0\r\n264>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C4579: 'tensorflow::Variant::in_place': in-class initialization for type 'const tensorflow::Variant::in_place_t' is not yet implemented; static member will remain uninitialized at runtime but use in constant-expressions is supported\r\n264>E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): error C2131: \u8868\u8fbe\u5f0f\u7684\u8ba1\u7b97\u7ed3\u679c\u4e0d\u662f\u5e38\u6570\r\n264>  E:\\Win_TF\\tensorflow-master\\tensorflow/core/framework/variant.h(284): note: \u56e0\u4e3a\u8fd4\u56de\u4e34\u65f6\u9879\u6216\u5bf9\u5176\u7684\u5f15\u7528\u7684\u5730\u5740\u5bfc\u81f4\u4e86\u6545\u969c\r\n264>E:\\Win_TF\\tensorflow-master\\tensorflow/core/lib/gtl/array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570\r\n265>------ \u5df2\u542f\u52a8\u751f\u6210: \u9879\u76ee: ALL_BUILD, \u914d\u7f6e: Release x64 ------\r\n========== \u751f\u6210: \u6210\u529f 42 \u4e2a\uff0c\u5931\u8d25 223 \u4e2a\uff0c\u6700\u65b0 0 \u4e2a\uff0c\u8df3\u8fc7 0 \u4e2a ==========\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "System information:\r\nOS Platform and Distribution-> win8.1\r\nTensorFlow installed from->source\r\nTensorFlow version->1.9\r\nBazel version->none\r\nCUDA/cuDNN version->No\r\nGPU model and memory->No\r\nExact command to reproduce->No\r\nMobile device->none", "Nagging Assignee @rohan100jain: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The CMake build is no longer supported. Please see the instructions for building using Bazel:\r\n\r\nhttps://www.tensorflow.org/install/source_windows", "@sannyhi -  It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. Thank you for your cooperation.\r\n", "Closing this issue due to staleness.\r\nPlease use the latest version of TensorFlow and build again. Feel free to open a [new issue](https://github.com/tensorflow/tensorflow/issues/new/choose) if the problem still persists. Thanks!"]}, {"number": 21778, "title": "tf.keras.estimator.model_to_estimator ignores layer reuse for Sequential models", "body": "### System information\r\n- **Have I written custom code**: yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **Mobile device**: N/A\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: 1.10.0\r\n- **Python version**: 3.6\r\n- **Bazel version**: N/A\r\n- **GCC/Compiler version**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: `python my_custom_script.py`\r\n\r\n**Overview:**\r\n\r\nIf a model is created using `tf.keras.models.Sequential` with reuse of some layers (including those that are parameterless) then the estimator created from `tf.keras.estimator.model_to_estimator` may contain a different model from the original Keras model.\r\n\r\nThis also may produce an error of shape mismatch in case that the `tf.keras.estimator.model_to_estimator` is called after fitting the Sequential model. \r\n\r\n**Simple example:**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nmax_pool = tf.keras.layers.MaxPooling2D(2)\r\nmodel = tf.keras.Sequential([\r\n    max_pool,\r\n    max_pool,\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\r\n\r\nX, y = np.zeros((32, 8, 8, 1)), np.ones((32,))\r\nmodel.fit(X, y)\r\n\r\ntf.keras.estimator.model_to_estimator(keras_model=model)\r\n```\r\n**The error produced:**\r\n```\r\n...\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\", line 847, in assert_is_compatible_with\r\n    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\nValueError: Shapes (16, 1) and (4, 1) are incompatible\r\n```\r\n\r\n\r\n**Explanation:**\r\n\r\nThe mismatch happens because `tf.keras.estimator.model_to_estimator` traverses `model.layers` which has a single entry of max pooling. Therefore, instead of making 2 max pooling operations it performs a single one which results in **16** outputs after `tf.keras.layers.Flatten()` instead of **4** that was intended initially.\r\n\r\nIf `model.fit` is not called then `tf.keras.estimator.model_to_estimator` does not produce any errors which is actually more concerning since it may be not obvious that the new model is different from the initial Sequential model.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Done", "@fchollet @pavithrasv @anj-s @tanzhenyu  - mind taking a look?", "@artkorenev Can you try this with the latest tf-nightly? This should have been fixed with the following change: https://github.com/tensorflow/tensorflow/commit/42b61fbd380a7b6c3912e5a91ff09738ace7073c#diff-2afc7c6acfd68474e1e8c56718431276\r\n\r\nThank you,\r\nPavithra", "I used the build `1.11.0-dev20180824` and now creating the estimator doesn't produce any errors.\r\nHowever, if I run `estimator.train` (or `estimator.predict`) then the underlying `model_fn` function fails.\r\n\r\n**The exception:** \r\n```\r\nTraceback (most recent call last):\r\n  File \"~/my_custom_script.py\", line 26, in <module>\r\n    print(estimator.train(input_fn=input_fn, steps=1))\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1183, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1213, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1171, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/keras.py\", line 213, in model_fn\r\n    labels)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/keras.py\", line 188, in _clone_and_build_model\r\n    in_place_reset=(not keras_model._is_graph_network))\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/models.py\", line 441, in clone_and_build_model\r\n    _in_place_subclassed_model_reset(clone)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/models.py\", line 316, in _in_place_subclassed_model_reset\r\n    name = layers_to_names[layer]\r\nKeyError: <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fae4b685c88>\r\n```\r\n\r\n**The slightly updated code example to reproduce the bug:**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nmax_pool = tf.keras.layers.MaxPooling2D(2)\r\nmodel = tf.keras.Sequential([\r\n    max_pool,\r\n    max_pool,\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\nmodel.compile(optimizer=tf.train.AdamOptimizer(), loss='binary_crossentropy')\r\n\r\nX, y = np.zeros((32, 8, 8, 1)), np.ones((32, 1))\r\nmodel.fit(X, y)\r\n\r\nestimator = tf.keras.estimator.model_to_estimator(keras_model=model)\r\n\r\ninput_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x=X,\r\n    y=y,\r\n    batch_size=32,\r\n    num_epochs=1,\r\n    shuffle=False\r\n)\r\n\r\nestimator.train(input_fn=input_fn, steps=1)\r\n```\r\n\r\nI also tried this on a model created from Functional API and it works fine without any errors", "I had the same error. So, I try to add `input_shape` argument into the first layer of my model, the problem was resolved.\r\n\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n        tf.keras.layers.Conv2D(\r\n            input_shape=(IMAGE_SIZE, IMAGE_SIZE, IMAGE_DEPTH),\r\n            filters=96, kernel_size=11, strides=4, padding='valid'),\r\n        tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='valid'),\r\n        tf.keras.layers.Conv2D(filters=256, kernel_size=5, strides=1, padding='same'),\r\n        tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='valid'),\r\n        tf.keras.layers.Conv2D(filters=384, kernel_size=3, strides=1, padding='same'),\r\n        tf.keras.layers.Conv2D(filters=384, kernel_size=3, strides=1, padding='same'),\r\n        tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same'),\r\n        tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='valid'),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(units=4096),\r\n        tf.keras.layers.Dense(units=4096),\r\n        tf.keras.layers.Dense(units=num_classes),\r\n    ])\r\n```\r\n", "Looks like there is an alternative solution to this. Closing it."]}, {"number": 21777, "title": "many configure script options do nothing", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n      N/A - issue is with TF build itself\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n      Have tried MacOS, Centos7\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n      N/A\r\n- **TensorFlow installed from (source or binary)**:\r\n      source\r\n- **TensorFlow version (use command below)**:\r\n      ./configure\r\n- **Python version**:\r\n      Have tried py 2.7, 3.6\r\n- **Bazel version (if compiling from source)**:\r\n      Have tried 1.4, 1.5, 1.8, 1.9\r\n- **GCC/Compiler version (if compiling from source)**:\r\n      N/A\r\n- **CUDA/cuDNN version**:\r\n      N/A\r\n- **GPU model and memory**:\r\n      N/A\r\n- **Exact command to reproduce**:\r\n      ./configure\r\n--\r\n\r\n\r\nThere appears to be a bug when running tensorflow's configure script prior to building with bazel.\r\nMany of the yes/no questions result in identical configuration files being written out, no matter what the user may answer.   This can be verified by:\r\n\r\n1. ensure a completely clean git repo via: git clean -xdf\r\n2. run the configure script, answer No to the question \"Do you wish to build TensorFlow with Google Cloud Platform support?\", or many of the other similar questions.\r\n3. check which files have changed via: git status --ignored\r\n4. observe contents of generated .tf_configure.bazelrc  \r\n5. ensure a completely clean git repo via: git clean -xdf\r\n6. run the configure script, give the opposite answer as given in #2\r\n7. observe that the contents of .tf_configure.bazelrc are the same as in #4 \r\n8. :(\r\n\r\nI have tried this on macos and centos7, with checkouts of TF 1.4, 1.5, 1.8, 1.9...\r\n\r\n```\r\njkeller@L127.local:~/mio/tensorflow$ git checkout v1.8.0\r\nHEAD is now at 93bc2e2072... Merge pull request #18928 from tensorflow/release-patch-4-1\r\njkeller@L127.local:~/mio/tensorflow$ git clean -xdf\r\njkeller@L127.local:~/mio/tensorflow$ git status --ignored\r\nHEAD detached at v1.8.0\r\nnothing to commit, working tree clean\r\njkeller@L127.local:~/mio/tensorflow$ ./configure \r\nYou have bazel 0.13.0 installed.\r\nPlease specify the location of python. [Default is /usr/local/opt/python/bin/python3.6]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/Cellar/python/3.6.4_3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/Cellar/python/3.6.4_3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: N\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: N\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: N\r\nNo Amazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: N\r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: N\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: N\r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: N\r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\nClang will not be downloaded.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: N\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\nConfiguration finished\r\njkeller@L127.local:~/mio/tensorflow$ cat .tf_configure.bazelrc \r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/local/opt/python/bin/python3.6\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/Cellar/python/3.6.4_3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\"\r\nbuild --force_python=py3\r\nbuild --host_force_python=py3\r\nbuild --python_path=\"/usr/local/opt/python/bin/python3.6\"\r\nbuild:gcp --define with_gcp_support=true\r\nbuild:hdfs --define with_hdfs_support=true\r\nbuild:s3 --define with_s3_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"0\"\r\nbuild --action_env TF_DOWNLOAD_CLANG=\"0\"\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\r\nbuild --host_copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\r\njkeller@L127.local:~/mio/tensorflow$ git status --ignored\r\nHEAD detached at v1.8.0\r\nIgnored files:\r\n  (use \"git add -f <file>...\" to include in what will be committed)\r\n\r\n\t.bazelrc\r\n\t.tf_configure.bazelrc\r\n\ttools/python_bin_path.sh\r\n\r\nnothing to commit, working tree clean\r\njkeller@L127.local:~/mio/tensorflow$\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Added template info.", "Sorry, was on vacation. This definitely doesnt sound good and Ill look into later this week. Thanks for reporting this issue!", "Nagging Assignees @yifeif, @case540: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Lots of these configs were moved out of the configure.py script. There are now more Bazel --config options specified in...\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tools/bazel.rc\r\n...that you can use. I think this issue is now obsolete."]}, {"number": 21776, "title": "Testing with Dockerfile numpy version downgraded.", "body": "", "comments": []}, {"number": 21775, "title": "Suddenly OOM (GPU has free memory)", "body": "", "comments": []}, {"number": 21774, "title": "Use if_ngraph to exclude ngraph licence rules in default build.", "body": "", "comments": []}, {"number": 21773, "title": "Update the version 1.10.1 patch release.", "body": "", "comments": []}, {"number": 21772, "title": "dataloss error tf.records at random times", "body": "OS Platform and Distribution --> Ubuntu - 18.04.1\r\nTensorFlow installed from --> using pip\r\nTensorFlow version --> 1.8.0\r\nBazel version --> don't know \r\nCUDA/cuDNN version --> cuda 9\r\nGPU model and memory --> nvidia Titan XP 12GB\r\n\r\n\r\nI am stuck at a very strange issue for a long time. This is my problem - \r\nI have a tfrecords file (name = \"Input.tfrecords\") from which I read data and then I do some modifcation to the data and store it to another tfrecords file (name = \"Output.tfrecods\") . Below is the code snippet --\r\n\r\n    tf.reset_default_graph()\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    \r\n    \r\n    def _bytes_feature(value):\r\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n    \r\n    \r\n    def _str_feature(value):\r\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode('utf-8')]))\r\n    \r\n    \r\n    def _float_feature(value):\r\n        return tf.train.Feature(float_list=tf.train.FloatList(value=value.reshape(-1)))\r\n    \r\n    \r\n    def _int64_feature(value):\r\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n    \r\n    \r\n    def som_function(FLAGS):\r\n        with tf.Graph().as_default() as g:\r\n    \r\n            tfr_writer = tf.python_io.TFRecordWriter(FLAGS.Output_tfrdatafile)\r\n    \r\n            dataset = tf.data.TFRecordDataset(FLAGS.Input_tfrdatafile)\r\n    \r\n            dataset = dataset.map(lambda x: reader.initial_parser(x, FLAGS.HEIGHT, FLAGS.WIDTH))\r\n    \r\n            dataset = dataset.batch(FLAGS.BATCH_SIZE)\r\n            iterator = dataset.make_one_shot_iterator()\r\n    \r\n            images, original_ig, img_name = iterator.get_next()\r\n    \r\n    \r\n            org_batch = tf.Variable(tf.random_normal([FLAGS.BATCH_SIZE, FLAGS.HEIGHT, FLAGS.WIDTH, 3]), trainable=False)\r\n            initial = tf.Variable(tf.random_normal([FLAGS.BATCH_SIZE, FLAGS.HEIGHT, FLAGS.WIDTH, 3]))\r\n            org_batch_assign_op = org_batch.assign(original_ig)\r\n    \r\n            initial_assign_op = initial.assign(images)\r\n    \r\n            total_loss = #someloss function\r\n    \r\n    \r\n    \r\n            train_op = tf.train.MomentumOptimizer(FLAGS.LEARNING_RATE, momentum=0.95, use_nesterov=True,\r\n                                                  name=\"non_paraopt_SGD\").minimize(total_loss,\r\n                                                                                   global_step=global_step)\r\n    \r\n    \r\n            init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n    \r\n            with tf.Session(config=config) as sess:\r\n                sess.run(init_op)\r\n                start_time = time.time()\r\n                batches_count = 0\r\n                while True:\r\n                    try:\r\n                        _, _, image_names = sess.run([initial_assign_op,org_batch_assign_op,  img_name])\r\n    \r\n                        //some code that updates initial variable\r\n    \r\n                        org_batch = tf.cast(org_batch, tf.uint8)\r\n                        image_t, org_image_t = sess.run([initial, org_batch])\r\n    \r\n                        if not FLAGS.addNetworklose:\r\n                            lambda_val = np.zeros(image_t.shape).astype(np.float32)\r\n    \r\n                        for i in range(image_t.shape[0]):\r\n                            filename = str(image_names[i], 'utf-8')\r\n    \r\n                            example = tf.train.Example(features=tf.train.Features(feature={\r\n                                    'file_name': _str_feature(filename),\r\n                                    'float_image': _float_feature(image_t[i] + reader.mean_pixel),\r\n                                    'image_raw': _bytes_feature(org_image_t[i].tostring()),\r\n                                    'lambda_image': _float_feature(lambda_val[i])\r\n                                }))\r\n                            tfr_writer.write(example.SerializeToString())\r\n    \r\n                        batches_count = batches_count + 1\r\n                    except tf.errors.OutOfRangeError:\r\n                        print(\"final time elspased\", (time.time() - start_time))\r\n                        print('Done doing non paramteric part')\r\n                        break\r\n    \r\n                tfr_writer.close()\r\n\r\n\r\nI always succesfully creats the  \"Output.tfrecods\".But whenever I read the file  \"Output.tfrecods\"file, I randomly get the **Dataloss Error**. This is where I am trying to read the Output.tfrecods file.\r\n```\r\ndef start_training(FLAGS):\r\n    tf.reset_default_graph()\r\n    run_id = FLAGS.MODEL_NAME if FLAGS.MODEL_NAME else str(uuid.uuid4())\r\n\r\n    if not os.path.exists(FLAGS.summary_path):\r\n        os.makedirs(FLAGS.summary_path)\r\n\r\n    model_path = '%s/%s' % (FLAGS.MODEL_DIR, run_id)\r\n    if not os.path.exists(model_path):\r\n        os.makedirs(model_path)\r\n\r\n    training_dataset = tf.data.TFRecordDataset(FLAGS.Training_tfrdatafile)\r\n    training_dataset = training_dataset.map(lambda x: reader.lambda_parser(x, FLAGS.HEIGHT, FLAGS.WIDTH))\r\n\r\n    training_dataset = training_dataset.batch(FLAGS.BATCH_SIZE)\r\n    min_queue_examples = int(FLAGS.EPOCHS * 0.4)\r\n    training_dataset = training_dataset.shuffle(buffer_size=min_queue_examples + 3 * FLAGS.BATCH_SIZE)\r\n\r\n    validation_dataset = tf.data.TFRecordDataset(FLAGS.Validation_tfrdatafile)\r\n    validation_dataset = validation_dataset.map(lambda x: reader.lambda_parser(x, FLAGS.HEIGHT, FLAGS.WIDTH))\r\n    validation_dataset = validation_dataset.batch(FLAGS.VAL_BATCH_SIZE)\r\n    \r\n    iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\r\n                                               training_dataset.output_shapes)\r\n\r\n    training_init_op = iterator.make_initializer(training_dataset)\r\n    validation_init_op = iterator.make_initializer(validation_dataset)\r\n\r\n    target_ig, images, img_name, _ = iterator.get_next()\r\n\r\n    ae_inputs = tf.placeholder(tf.float32, (None, FLAGS.HEIGHT, FLAGS.WIDTH, 3),\r\n                               name='auto_input')  # input to the network (MNIST images)\r\n    target = tf.placeholder(tf.float32, (None, FLAGS.HEIGHT, FLAGS.WIDTH, 3),\r\n                            name='target')\r\n\r\n    ae_output = model.net(ae_inputs, training=True)\r\n\r\n    learning_rate = tf.placeholder(tf.float32, shape=[], name='learning_rate')\r\n    img_loss = tf.nn.l2_loss((target - ae_output), name='img_l2loss') / tf.to_float(size2)\r\n\r\n    tv_loss = total_variation_loss(ae_output, FLAGS.HEIGHT, FLAGS.WIDTH)\r\n    loss = img_loss + 200.0 * tv_loss\r\n\r\n    global_step = tf.Variable(FLAGS.gs_val, name=\"p_global_step\", trainable=False)\r\n\r\n    \r\n    train_op = tf.train.AdamOptimizer(learning_rate, name=\"p_trainopt\").minimize(loss, global_step=global_step)\r\n    \r\n    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n    return_lr = FLAGS.LEARNING_RATE\r\n\r\n    with tf.Session(config=config) as sess:\r\n        \r\n        saver = tf.train.Saver(tf.trainable_variables())\r\n        if FLAGS.ModelFromName:\r\n            file = FLAGS.MODEL_FILENAME\r\n        else:\r\n            file = tf.train.latest_checkpoint(model_path)\r\n        # file = model_path + '/' + FLAGS.MODEL_FILENAME\r\n\r\n        sess.run(init_op)\r\n        if file:\r\n            print('Restoring model from {}'.format(file))\r\n            saver.restore(sess, file)\r\n\r\n        start_time = time.time()\r\n        start_ti = time.time()\r\n        acc_loss = []\r\n        vgg_pl_loss = []\r\n        img_pl_loss = []\r\n        cl_pl_loss = []\r\n        sl_pl_loss = []\r\n        fl_pl_loss = []\r\n\r\n        cont_los_FF = 0\r\n        stl_los_FF = 0\r\n\r\n        total_batches = FLAGS.TOTALINPUT // FLAGS.BATCH_SIZE\r\n        val_batches = FLAGS.TOTALVAL // FLAGS.VAL_BATCH_SIZE\r\n        print('the value of total batches is: ', total_batches)\r\n        for ep_count in range(FLAGS.EPOCHS):\r\n            sess.run(training_init_op)\r\n            count = 1\r\n            st_t = time.time()\r\n            # if ep_count+1 <= FLAGS.EPOCHS  or ep_count == 0:\r\n            while True:\r\n                try:\r\n                    ig_b, tg_b = sess.run([images, target_ig])\r\n\r\n                    _, loss_t,img_l2_t, step = sess.run([train_op, loss, img_loss],feed_dict={ae_inputs: ig_b,\r\n                                                                                           target: tg_b,\r\n                                                                                           learning_rate: FLAGS.LEARNING_RATE})\r\n                                                                                \r\n                    count = count + 1\r\n                except tf.errors.OutOfRangeError:\r\n                    print(\"final time elspased\", (time.time() - st_t))\r\n                    #  print('Done doing non paramteric part')\r\n                    break\r\n\r\n            print('Number of epochs done= ', (ep_count + 1))\r\n            if (ep_count + 1) % FLAGS.chanelr == 0:\r\n                print('the value of count is: ', count)\r\n                FLAGS.LEARNING_RATE = FLAGS.LEARNING_RATE / FLAGS.div\r\n                print('learning rate now: ', FLAGS.LEARNING_RATE)\r\n                return_lr = FLAGS.LEARNING_RATE\r\n\r\n        print(step, loss_t, elapsed_time)\r\n        saver.save(sess, model_path + '/style-model', global_step=step)\r\n        nameofmodel = model_path + '/style-model-' + str(step)\r\n        print(\"final time elspased\", (time.time() - start_ti))\r\n        print('Done training -- epoch limit reached')\r\n\r\n    return step, return_lr, nameofmodel\r\n```\r\n\r\n\r\n\r\n\r\nI have to restart my system and re-run the above code for 5-6 times and then it works fine. And when I run the same code on a different linux machine its work fine all the time. I really don't know what is the issue here.\r\n\r\nThanks in advance. Please comment if need more explanation from my side. \r\n\r\nHere is the stack trace\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 775087002\r\n         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,256,256,3], [?,256,256,3], [?], [?,256,256,3]], output_types=[DT_FLOAT, DT_FLOAT, DT_STRI\r\nNG, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"Maincreateall.py\", line 240, in <module>\r\n    main()\r\n  File \"Maincreateall.py\", line 194, in main\r\n    opts_para[\"gs_val\"], nameofmodel = tm.train_model(opts_para)\r\n  File \"/home/suryabhan/Desktop/New_NST_MAC/teststuff.py\", line 465, in train_model\r\n    gs,_,nameofmodel = start_training(FLAGS)\r\n  File \"/home/suryabhan/Desktop/New_NST_MAC/teststuff.py\", line 277, in start_training\r\n    ig_b, tg_b = sess.run([images, target_ig])\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.DataLossError: corrupted record at 775087002\r\n         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,256,256,3], [?,256,256,3], [?], [?,256,256,3]], output_types=[DT_FLOAT, DT_FLOAT, DT_STRI\r\nNG, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n\r\nCaused by op 'IteratorGetNext', defined at:\r\n  File \"Maincreateall.py\", line 240, in <module>\r\n    main()\r\n  File \"Maincreateall.py\", line 194, in main\r\n    opts_para[\"gs_val\"], nameofmodel = tm.train_model(opts_para)\r\n  File \"/home/suryabhan/Desktop/New_NST_MAC/teststuff.py\", line 465, in train_model\r\n    gs,_,nameofmodel = start_training(FLAGS)\r\n  File \"/home/suryabhan/Desktop/New_NST_MAC/teststuff.py\", line 137, in start_training\r\n    target_ig, images, img_name,_ = iterator.get_next()\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 370, in get_next\r\n    name=name)), self._output_types,\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1466, in iterator_get_next\r\n    output_shapes=output_shapes, name=name)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"/home/suryabhan/anaconda3/envs/nn_env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nDataLossError (see above for traceback): corrupted record at 775087002\r\n         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,256,256,3], [?,256,256,3], [?], [?,256,256,3]], output_types=[DT_FLOAT, DT_FLOAT, DT_STRI\r\nNG, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n```\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I have udated the information ", "Thanks @Suryabhan90 -- can you provide the stack trace for the error you are seeing?", "I have updated the information", "I have the exact same problem, can I ask what CPU you are using?", "@stillwalker1234  Here are the CPU details - \r\nmodel name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  2\r\nCore(s) per socket:  4\r\nSocket(s):           1\r\nNUMA node(s):        1", "What does record 775087002 look like in the file? Can you reproduce the error by just reading the file, and remove all the actual training above? That will help isolate the problem.", "@karmel I have another file which just reads the data when I read the file through it. Yes it gives the error of \"Dataloss\" as expected but when type the command \r\n\r\n> sudo sh -c \"sync; echo 1 > /proc/sys/vm/drop_caches\"\r\n\r\nIt works fine after that. But after a while, the error comes back with a different record.\r\nBtw --> \r\nThe record is of following type - \r\n tf.train.Example(features=tf.train.Features(feature={\r\n                                'file_name': _str_feature(filename),\r\n                                'float_image': _float_feature(image_t[i] + reader.mean_pixel),\r\n                                'image_raw': _bytes_feature(org_image_t[i].tostring()),\r\n                                'lambda_image': _float_feature(lambda_val[i])\r\n                            }))\r\nfile_name is just a string \r\nfloat_image is a 256x256x3 float matrix \r\nimage_raw is a  256x256x3 byte matrix \r\nlambda_image is a 256x256x3 float matrix ", "\nThat is exactly the same error i have (and the same temporary fix). Curruption happens in memory.\n\n________________________________\nFrom: Suryabhan90 <notifications@github.com>\nSent: Tuesday, August 28, 2018 8:19:30 PM\nTo: tensorflow/tensorflow\nCc: stillwalker1234; Mention\nSubject: Re: [tensorflow/tensorflow] dataloss error tf.records at random times (#21772)\n\n\n@karmel<https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fkarmel&data=02%7C01%7C%7C5e0a32f4af65455113c008d60d12cf5b%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636710771764721352&sdata=mYewoTll9Kw8RUHIc5X64iUk1kgX008Nf2J7pBe%2BPGc%3D&reserved=0> I have another file which just reads the data when I read the file through it. Yes it gives the error of \"Dataloss\" as expected but when type the command\n\nsudo sh -c \"sync; echo 1 > /proc/sys/vm/drop_caches\"\n\nIt works fine after that. But after a while, the error comes back with a different record.\nBtw -->\nThe record is of following type -\ntf.train.Example(features=tf.train.Features(feature={\n'file_name': _str_feature(filename),\n'float_image': _float_feature(image_t[i] + reader.mean_pixel),\n'image_raw': _bytes_feature(org_image_t[i].tostring()),\n'lambda_image': _float_feature(lambda_val[i])\n}))\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F21772%23issuecomment-416688102&data=02%7C01%7C%7C5e0a32f4af65455113c008d60d12cf5b%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636710771764721352&sdata=29tkHkSbSj%2B4FcGAVVm9Pj4ENDSIdMsspcLN2jFPog4%3D&reserved=0>, or mute the thread<https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAISpV-vQjda4caIfl9-4TlFg9OjLIZwvks5uVYmygaJpZM4WGkzl&data=02%7C01%7C%7C5e0a32f4af65455113c008d60d12cf5b%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636710771764721352&sdata=gvBXsSgRCGTDen%2F58EVDXquH5297jjWAnB%2FPpV3ULUY%3D&reserved=0>.\n", "Unfortunately, this is very hard for us to replicate. Is there any way you can produce a minimal example that we can replicate on our side?", "Experiencing the same issue, posted at `tesnsorflow/models` https://github.com/tensorflow/models/issues/6053\r\n\r\nDo you use docker by any chance? I wonder if this is related\r\n\r\n@karmel since OP is not replying, I think the setup I posted could considered the minimally reproducable. ", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "Yep", "I am having this same issue."]}, {"number": 21771, "title": "/usr/local", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 21770, "title": "Rename the artifact IDs for TensorFlow ecosystem jars", "body": "Rename the artifact IDs for the TensorFlow ecosystem jars to tensorflow-hadoop and tensorflow-spark-connector in response to discussion in https://github.com/tensorflow/ecosystem/pull/87\r\n\r\n@asimshankar Please let me if you would like me to make any changes.", "comments": []}, {"number": 21769, "title": "Cannot set name of tf.keras.models", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora Linux 27\r\n- **TensorFlow installed from (source or binary)**: Binary wheel\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6\r\n- **Keras version**: 2.2.0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below\r\n- **Mobile device**: N/A\r\n\r\n### Describe the problem\r\n\r\nThe name of models created with the embedded version of Keras cannot be changed, as seen in the example. Raises an Attribute error. The same works with the standalone Keras library.\r\n\r\n### Source code / logs\r\n```\r\nEMBEDDED = True\r\nif EMBEDDED:\r\n    from tensorflow.keras.layers import Input, Dense\r\n    from tensorflow.keras.models import Model\r\nelse:\r\n    from keras.layers import Input, Dense\r\n    from keras.models import Model\r\n\r\ninp = Input((32,))\r\nx = Dense(1)(inp)\r\nmodel = Model(inp, x)\r\nmodel.name = 'mymodel'\r\n```\r\nSetting EMBEDDED to False it uses the independent Keras library, and it works.\r\n\r\nHere is the full traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/david/.PyCharm2018.2/config/scratches/scratch_17.py\", line 13, in <module>\r\n    model.name = 'mymodel'\r\n  File \"/home/david/.virtualenvs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 432, in __setattr__\r\n    super(Network, self).__setattr__(name, value)\r\nAttributeError: can't set attribute\r\n```", "comments": ["Does the workaround work for you `model = Model(inp, x, name='mymodel')`?", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@facaiy it does! Still, it would be nice to have the same API capabilities.", "ping @fchollet what do you think?", "You can change the name using a similar way: `model._name = 'mymodel'`. Note that there is a \"protected\" variable `._name` as well as `.name`. So if you change the `.name`, they conflict.", "@nkcr7 Ah, so `.name` is a property that's why we cannot modify it. Actually I like the idea: it's better to make `name` immutable in tf.keras than that's in keras.\r\n\r\n@Dapid Hi, how do you think about @nkcr7 's workaround ? ", "I am OK either way, but I think both APIs should be synchronised.", "Nagging Assignee @facaiy: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'll close the issue,  and please feel free to reopen it if necessary :-) ", "I have the same Problem\r\n\r\n`for layer in model1.layers[:-1]:\r\n    layer.name = layer.name + '_encoder'`\r\n\r\nif I use keras it works, if I use tensorflow.keras I get the same error", "I can't figure out how to fix this.  This is my code:\r\n\r\n```\r\ndef crossover_rnn(model_1, model_2):\r\n    \"\"\"\r\n    Executes crossover for the RNN in the GA for 2 models, modifying the first model\r\n    :param model_1:\r\n    :param model_2:\r\n    :return:\r\n    \"\"\"\r\n    # new_model = copy.copy(model_1)\r\n    new_model = model_1\r\n\r\n    # Probabilty of models depending on their RMSE test score\r\n    # Lower RMSE score has higher prob\r\n    test_score_total = model_1.test_score + model_2.test_score\r\n    model_1_prob = 1 - (model_1.test_score / test_score_total)\r\n    model_2_prob = 1 - model_1_prob\r\n    # Probabilities of each item for each model (all items have same probabilities)\r\n    model_1_prob_item = model_1_prob / (len(model_1.layers) - 2)\r\n    model_2_prob_item = model_2_prob / (len(model_2.layers) - 2)\r\n\r\n    # Number of layers of new generation depend on probability of each model\r\n    num_layers_new_gen = int(model_1_prob * (len(model_1.layers) - 1) + model_2_prob * (len(model_2.layers) - 1))\r\n\r\n    # Create list of int with positions of the layers of both models.\r\n    cross_layers_pos = []\r\n    # Create list of weights\r\n    attention_weights = []\r\n    # Add positions of layers for model 1. Input and ouput layer are not added.\r\n    for i in range(2, len(model_1.layers)):\r\n        mod_item = type('', (), {})()\r\n        mod_item.pos = i\r\n        mod_item.model = 1\r\n        cross_layers_pos.append(mod_item)\r\n        attention_weights.append(model_1_prob_item)\r\n\r\n    # Add positions of layers for model 2. Input and ouput layer are not added.\r\n    for i in range(2, len(model_2.layers)):\r\n        mod_item = type('', (), {})()\r\n        mod_item.pos = i\r\n        mod_item.model = 2\r\n        cross_layers_pos.append(mod_item)\r\n        attention_weights.append(model_2_prob_item)\r\n\r\n    collect_gc()\r\n\r\n    # If new num of layers are larger than the num crossover layers, keep num of crossover layers\r\n    if num_layers_new_gen > len(cross_layers_pos):\r\n        num_layers_new_gen = len(cross_layers_pos)\r\n\r\n    # Randomly choose num_layers_new_gen layers of the new list\r\n    cross_layers_pos = list(np.random.choice(cross_layers_pos, size=num_layers_new_gen, replace=False,\r\n                                             p=attention_weights))\r\n\r\n    # Add both group of hidden layers to new group of layers using previously chosen layer positions of models\r\n    cross_layers = []\r\n    for i in range(len(cross_layers_pos)):\r\n        mod_item = cross_layers_pos[i]\r\n        if mod_item.model == 1:\r\n            cross_layers.append(model_1.layers[mod_item.pos])\r\n        else:\r\n            cross_layers.append(model_2.layers[mod_item.pos])\r\n\r\n    collect_gc()\r\n\r\n    # Add input layer randomly from parent 1 or parent 2\r\n    bit_random = random.randint(0, 1)\r\n    if bit_random == 0:\r\n        cross_layers.insert(0, model_1.layers[0])\r\n    else:\r\n        cross_layers.insert(0, model_2.layers[0])\r\n\r\n    bit_random = random.randint(0, 1)\r\n    if bit_random == 0:\r\n        cross_layers.append(model_1.layers[len(model_1.layers) - 1])\r\n    else:\r\n        cross_layers.append(model_2.layers[len(model_2.layers) - 1])\r\n\r\n    # Set new layers\r\n    new_model.layers = cross_layers\r\n\r\n    return new_model\r\n```\r\n\r\nI get the error: \r\n\r\n  File \"Ensemble.py\", line 263, in crossover_rnn\r\n    new_model.layers = cross_layers\r\n  File \"C:\\Users\\Noa\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\network.py\", line 316, in __setattr__\r\n    super(Network, self).__setattr__(name, value)\r\nAttributeError: can't set attribute\r\n\r\nCan anyone tell me how to fix this?  \r\n", "I'm using tensorflow 1.13.1 with keras 2.2.4", "I have the same issue. Cannot set layer name with tensor flow backend", "you can try :\r\n`layer.__class__.name='othername'`"]}, {"number": 21768, "title": "Fixed mode in load_inputs_from_input_arg_string", "body": "NPY files are binary and should be opened with mode \"rb\".", "comments": ["Nagging Assignee @akshaym: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@yifeif could you kindly have a look at this PR? If it is merged, the next TF release would have `save_model_cli` working on Python 3."]}, {"number": 21767, "title": "`MirrorStrategy` is not working with `tf.estimator.DNNClassifier`", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nChanged from `models/samples/core/get_started/premade_estimator.py`\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.64\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nNo\r\n- **TensorFlow installed from (source or binary)**:\r\nCompile from source 1.10\r\n- **TensorFlow version (use command below)**:\r\n1.10\r\n- **Python version**:\r\n2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n0.16.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4.0\r\n- **CUDA/cuDNN version**:\r\n9.1\r\n- **GPU model and memory**:\r\n2 x TITAN Xp/12GB\r\n- **Exact command to reproduce**:\r\n`python premade_estimator.py`\r\n\r\n### Describe the problem\r\nI try to use `MirrorStrategy` to parallel `premade_estimator.py`. The  code is below. I made two changes:\r\n(1) I make a fake input_fn to build (features, labels) from random values.\r\n(2) I add two lines to use `MirrorStrategy` when initializing the `conf` when building `estimator`.\r\n\r\nIt woks fine if I do not use `MirrosStrategy`(without (2)), but fails as following logs output.\r\n\r\nBTW: I also tried the original input_fn, reported the same errors.\r\n\r\nAppreciate the help\r\n\r\n### Source code / logs\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\nimport iris_data\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--batch_size', default=32, type=int, help='batch size')\r\nparser.add_argument('--train_steps', default=1000, type=int,\r\n                    help='number of training steps')\r\n\r\nCSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\r\n                    'PetalLength', 'PetalWidth', 'Species']\r\n\r\ndef train_input_fn_fake(features_name, batch_size):\r\n    features_len = len(features_name)\r\n    data_len = 10000\r\n    features = tf.random_uniform([data_len, features_len], minval=0, maxval=1, dtype=tf.float32)\r\n    labels = tf.random_uniform([data_len, 1], minval=0, maxval=2, dtype=tf.int32)\r\n    def map_dnn_input(features, labels):\r\n        features = tf.split(features, features_len)\r\n        features = dict(zip(features_name, features))\r\n        return features, labels\r\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels)).map(map_dnn_input)\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n    return dataset\r\n\r\n\r\n\r\ndef main(argv):\r\n    args = parser.parse_args(argv[1:])\r\n\r\n    # Feature columns describe how to use the input.\r\n    my_feature_columns = []\r\n    my_features = []\r\n    for key in CSV_COLUMN_NAMES:\r\n        my_features.append(key)\r\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n\r\n\r\n    # configure multi gpu\r\n    distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\r\n    config = tf.estimator.RunConfig(train_distribute=distribution)\r\n\r\n    # Build 2 hidden layer DNN with 10, 10 units respectively.\r\n    classifier = tf.estimator.DNNClassifier(\r\n        feature_columns=my_feature_columns,\r\n        # Two hidden layers of 10 nodes each\r\n        hidden_units=[100, 100],\r\n        # The model must choose between 3 classes.\r\n        n_classes=3,\r\n        # Config\r\n        config = config\r\n        )\r\n\r\n    # Train the Model.\r\n    classifier.train(\r\n        input_fn=lambda:train_input_fn_fake(my_features,\r\n                                            args.batch_size),\r\n        steps=args.train_steps,\r\n        )\r\n\r\n    \r\nif __name__ == '__main__':\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run(main)\r\n```\r\n\r\n\r\n\r\nLog output:\r\n```\r\n\r\n2018-08-21 12:27:58.645341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Found device 0 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 11.91GiB freeMemory: 10.62GiB\r\n2018-08-21 12:27:58.874232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Found device 1 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.74GiB\r\n2018-08-21 12:27:58.875049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0, 1\r\n2018-08-21 12:27:59.303516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-21 12:27:59.303548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0 1 \r\n2018-08-21 12:27:59.303553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N Y \r\n2018-08-21 12:27:59.303557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 1:   Y N \r\n2018-08-21 12:27:59.303931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/device:GPU:0 with 10261 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-08-21 12:27:59.405388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/device:GPU:1 with 11361 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\nINFO:tensorflow:Configured nccl all-reduce.\r\n2018-08-21 12:27:59.555447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0, 1\r\n2018-08-21 12:27:59.555515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-21 12:27:59.555524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0 1 \r\n2018-08-21 12:27:59.555530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N Y \r\n2018-08-21 12:27:59.555535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 1:   Y N \r\n2018-08-21 12:27:59.555693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10261 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-08-21 12:27:59.555813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11361 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Calling model_fn.\r\nWARNING:tensorflow:Partitioned variables are disabled when using DistributionStrategy.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:batch_all_reduce invoked for batches size = 6 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:Error reported to Coordinator: \r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 175, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 660, in _distributed_apply\r\n    self._create_slots(var_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/adagrad.py\", line 73, in _create_slots\r\n    with ops.colocate_with(v):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4080, in _colocate_with_for_gradient\r\n    with self.colocate_with(op, ignore_existing):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4132, in colocate_with\r\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1285, in internal_convert_to_tensor_or_indexed_slices\r\n    value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1124, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 445, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\nTraceback (most recent call last):\r\n  File \"premade_estimator.py\", line 84, in <module>\r\n    tf.app.run(main)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"premade_estimator.py\", line 78, in main\r\n    steps=args.train_steps,\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 343, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1166, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1294, in _train_model_distributed\r\n    self.config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/distribute.py\", line 857, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 418, in _call_for_each_tower\r\n    return _call_for_each_tower(self, fn, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 181, in _call_for_each_tower\r\n    coord.join(threads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 175, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 660, in _distributed_apply\r\n    self._create_slots(var_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/adagrad.py\", line 73, in _create_slots\r\n    with ops.colocate_with(v):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4080, in _colocate_with_for_gradient\r\n    with self.colocate_with(op, ignore_existing):\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 4132, in colocate_with\r\n    op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1285, in internal_convert_to_tensor_or_indexed_slices\r\n    value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1124, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/values.py\", line 445, in _tensor_conversion_mirrored\r\n    assert not as_ref\r\nAssertionError\r\n\r\n```", "comments": ["cc @ispirmustafa the authority on this issue.", "I got the same errors when training using `MirroredStrategy`.", "I got the same error when training using `MirroredStrategy` with `AdamOptimizer` and `AdagradOptimizer`", "@yncxcw The issue with AdagradOptimizer should be fixed now. Can you try running your model again with the latest TensorFlow code? Thanks!\r\n\r\n@olel-may I am not able to reproduce the issue with the AdamOptimizer. Do you have a standalone snippet of code which reproduces this issue? \r\n\r\n", "Why I still get this error? Do I need to renew the Tensorflow?", "@AmberCheng What version of TensorFlow are you using? Can you try with the latest version? If you still get this error, can you post a snippet of code that reproduces the issue?", "> @AmberCheng What version of TensorFlow are you using? Can you try with the latest version? If you still get this error, can you post a snippet of code that reproduces the issue?\r\n\r\nYep, I have installed the Tensorflow 1.11, and there is no more this problem. Thank you~~~", "This issue should be fixed now. Please reopen this if you still encounter this error. Thanks!"]}, {"number": 21766, "title": "Fix compilation failure with RDMA+GDR", "body": "\r\nThis fix tries to address the issue raised in #21696 where\r\ntensorflow failed to compile when both RDMA and GDR are on.\r\nThe issue is that the memory allocator of GDR used the same\r\nname as RDMA.\r\n\r\nThis fix fixes #21696.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@byronyi: thoughts?", "@yongtang @poxvoculi LGTM"]}, {"number": 21764, "title": "Fixed broken link to Estimators page ", "body": "Broken link on https://www.tensorflow.org/guide/saved_model", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "signed CLA", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 21763, "title": "`padding='causal'` is in document but cannot be used with `tf.keras.layers.Conv1D`", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nI use docker tensorflow/tensorflow:1.10.0-devel-gpu-py3\r\n- **TensorFlow version (use command below)**:\r\n1.10.0\r\n- **Python version**:\r\nPython 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\nsee my gist below\r\n\r\n### Describe the problem\r\nIn the [document](https://www.tensorflow.org/versions/r1.10/api_docs/python/tf/keras/layers/Conv1D), we can use `causal` option for  `padding`. But `causal` option causes error in r1.10. We should remove `causal` from the document or support `causal`. There are related issues, #14933, #15000 and #15037. But all of them are closed. I think they should be reopen.\r\n\r\n### Source code / logs\r\nhttps://gist.github.com/dhgrs/ca552f5804ddfb4db9669f9189eba76f\r\n", "comments": ["Nagging Assignee @drpngx: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is fixed now in the latest nightly version, please ```pip install tf-nightly``` (or ```pip install tf-nightly-gpu``` for GPU support)"]}, {"number": 21762, "title": "\"not all arguments converted during string formatting\" in rnn_cell_impl", "body": "I believe there's a mistake in the ```BasicLSTMCell.build``` method:\r\n\r\n```python\r\nraise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\"\r\n                       % inputs_shape)\r\n```\r\nwill be called with inputs_shape being a tuple and % formatting will interpret this tuple as multiple formatting arguments. Can we change it to\r\n\r\n```python\r\nraise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\"\r\n                       % (inputs_shape,))\r\n```\r\n?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@melkonyan Would you mind to create a PR for the proposed fix?", "@melkonyan Your contribution would be very welcome.", "Ok, I'll create a PR"]}]