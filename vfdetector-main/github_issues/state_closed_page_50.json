[{"number": 53855, "title": "2.8.0 cherry-pick request: Update tensorboard dependencies for 2.8.0 release.", "body": "Update tensorboard dependencies for 2.8.0 release.\r\n\r\nNote that the cherry-pick did not run cleanly since the way tensorboard dependencies are specified has changed in master. I had to effectively reimplement the changes.\r\n\r\nPiperOrigin-RevId: 423335453\r\nChange-Id: Ie098101340c9f4a1348bd2b29b3e0093415c9ab9", "comments": []}, {"number": 53854, "title": "Properly initialize data_ member of MklDnnShape", "body": "As MklShapeData is a C-style struct, it does not get initialized without `{}`.\r\nIn our case msan reports error in hardly related place. `-fsanitize-memory-track-origins=2` helps to find out the actual reason:\r\n\r\n> Uninitialized value was created by an allocation of 'output_mkl_shape' in the stack frame of function '_ZN10tensorflow9MklAddNOpIN5Eigen16ThreadPoolDeviceEfE7ComputeEPNS_15OpKernelContextE'\r\n\r\n(that is `tensorflow::MklAddNOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*)`)", "comments": []}, {"number": 53853, "title": "[MLIR][LMHLO-Affine] Add PadOp lowering from lmhlo to Affine + Add verifier for lmhlo.Pad op", "body": "This PR adds two commits :-\r\n\r\n**Commit 1:**\r\n-- Adds verifier for lmhlo.Pad op which checks :- \r\n   1. Output and operand rank matches.\r\n   2. Padding configurations are provided for each dimension.\r\n   3. Padding configurations when applied to operand lead to the provided\r\n       output shape.\r\n\r\n**Commit 2:**\r\n-- Adds lowering of PadOp from lmhlo -> Affine as a part of `lhlo-legalize-to-affine` pass.\r\n-- The limitation of the implementation is that it expects interior padding to be 0\r\n   and edge padding to be >= 0.\r\n\r\nSigned-off-by: Abhishek Varma <abhishek.varma@polymagelabs.com>", "comments": ["Hi @joker-eph \r\nI've addressed your review comments. You may re-review now.", "The build failure seems unrelated (Python version mismatch).\r\n\r\nCC: @joker-eph ", "Hi @joker-eph \r\n\r\nThe build failures look unrelated to me. Can you please look into it?"]}, {"number": 53852, "title": "no interface provided to set 'max_num_snapshots' when profile memory", "body": "When using the tensorflow profiler for memory footprint analysis, the profiler keeps up to 1000 snapshots. This default value limits us to more detailed memory analysis. I would like to know why this default value is set to 1000.\r\n\r\nThe relevant code is as follows\uff1a\r\nhttps://github.com/tensorflow/tensorflow/blob/f0df570aa30f962f58aedf6d111e017c7345431b/tensorflow/core/profiler/convert/xplane_to_memory_profile.h#L30\r\nhttps://github.com/tensorflow/tensorflow/blob/f0df570aa30f962f58aedf6d111e017c7345431b/tensorflow/core/profiler/convert/xplane_to_memory_profile.cc#L550\r\n\r\nTF version\uff1aTF 2.7\r\nHow to reproduce: Strictly speaking, this is not a bug.\r\n\r\nLooking forward to reply.", "comments": ["Hi @tomusfri ! \r\nCould you please update the [template](https://github.com/tensorflow/tensorflow/issues/new/choose) too as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53851, "title": "[Metric] get shape of a tensor for custom metric", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): conda-forge\r\n- TensorFlow version (use command below): 2.6.2\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.2 / 7.6.5.32\r\n- GPU model and memory: GTX 1080Ti\r\n\r\n**Describe the current behavior**\r\n\r\nI am implementing a custom metric for `tf.keras` which need to extract the batch dimension of input tensor `x.shape[0]` during `model.fit(...)` but it raises:\r\n\r\n```\r\n(None, None)\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 81, in <module>\r\n    main()\r\n  File \"train.py\", line 71, in main\r\n    use_multiprocessing=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 760, in _initialize\r\n    *args, **kwds))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3066, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3308, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 668, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 994, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\r\n        return step_function(self, iterator)\r\n    /AgeGenderMask/metrics/age_mae.py:36 update_state  *\r\n        self.count.assign_add(y_true.shape[0])\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:857 assign_add  **\r\n        ops.convert_to_tensor(delta, dtype=self.dtype),\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\r\n        return func(*args, **kwargs)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\r\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:346 _constant_tensor_conversion_function\r\n        return constant(v, dtype=dtype, name=name)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:272 constant\r\n        allow_broadcast=True)\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:290 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:445 make_tensor_proto\r\n        raise ValueError(\"None values not supported.\")\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nAs mentioned above.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nclass CustomMetric(keras.metrics.Metric):\r\n    def __init__(self, name: Optional[str] = None) -> None:\r\n        super().__init__(name=name)\r\n        self.total = self.add_weight(\"total\", initializer=\"zero\")\r\n        self.count = self.add_weight(\"count\", initializer=\"zero\")\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None) -> None:\r\n        self.total.assign_add(tf.reduce_sum(y_pred))\r\n        print(y_true.shape[0]) # Cannot extract tensor's shape\r\n        self.count.assign_add(y_true.shape[0])\r\n\r\n    def result(self) -> tf.Tensor:\r\n        return tf.math.divide_no_nan(self.total, self.count)\r\n\r\n    def reset_state(self) -> None:\r\n        self.total.assign(0)\r\n        self.count.assign(0)\r\n```\r\n", "comments": ["@hoangtnm \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "@sushreebarsa this [issue](https://github.com/keras-team/keras/issues/15932) was solved on [keras repo](https://github.com/keras-team/keras/issues/15932). thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53851\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53851\">No</a>\n"]}, {"number": 53850, "title": "Update bleach to 4.1.0", "body": null, "comments": ["@devendrasoni18 ,\r\nThis is not related to tensorflow. Please take a look at this [link](https://anaconda.org/anaconda/bleach) which provides more information.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 53849, "title": "Is there a direct way to add Flex delegate to options in Android Tensorflow Lite 2.5 on C API ?", "body": "I'm trying to use tflite 2.5 and  a tflite model converted from tensorflow model and I need to use flex delegate  in android on a native level C api.\r\n\r\nThere is a method in c header lite\\c\\c_api.h\r\n\r\nTFL_CAPI_EXPORT extern void TfLiteInterpreterOptionsAddDelegate(\r\n    TfLiteInterpreterOptions* options, TfLiteDelegate* delegate);\r\n\r\nBut: there is no api for creating TfLiteDelegate object.\r\n\r\nIs it possible to use this TfLiteInterpreterOptionsAddDelegate method or  is this method just a prank?\r\n\r\nI need an api for creating flex TfLiteDelegate  object and If such a method exitsts, where is it?\r\n", "comments": ["Hi @sachinprasadhs ! Could you please look at this query?", "@karimnosseir could you help take a look? Thanks!", "@fatihkiralioglu \r\nYou can use TfLiteInterpreterOptionsAddDelegate for sure. How to get TfLiteDelegate ? TfLite delegates expose C API functions to create TfLiteDelegate instances\r\nexample, \r\n[GPU](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/delegate.h#L153) \r\n[XNNPACK](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/xnnpack_delegate.h#L50)\r\n[Hexagon](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/hexagon/hexagon_delegate.h#L96)\r\n\r\nFor Flex Delegate, you don't need to add it as long as you're using TFLite which already built with TF Select support - see [here](https://www.tensorflow.org/lite/guide/ops_select#android_aar) for android build that links Flex.\r\nWe apply it automatically underneath.\r\n\r\nLet me know if you have more questions.\r\n\r\nThanks", "Closing. Please feel free to reopen if you have other questions/issues.\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53849\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53849\">No</a>\n"]}, {"number": 53848, "title": "[oneDNN] optimized implementation for eigen LeakyRelu", "body": "This change provides significant improvement in performance for BF16 Eigen LeakyRelu. \r\nFor a 3d unet model, I see 12-15% gain.", "comments": ["@rohan100jain : Can you please review this PR? AMD build failure seems not related to this change.", "Hi @rohan100jain  : can you please review? Please let me know if there is anything required from my side. Thanks.", "@cantonios is the Eigen expert and can review this code. ", "@gaurides do you have the benchmark numbers for this change?", "@cantonios  Here is the comparison. Let me know if you want to look at the raw numbers.\r\n<html xmlns:v=\"urn:schemas-microsoft-com:vml\"\r\nxmlns:o=\"urn:schemas-microsoft-com:office:office\"\r\nxmlns:x=\"urn:schemas-microsoft-com:office:excel\"\r\nxmlns=\"http://www.w3.org/TR/REC-html40\">\r\n\r\n<head>\r\n\r\n<meta name=ProgId content=Excel.Sheet>\r\n<meta name=Generator content=\"Microsoft Excel 15\">\r\n<link id=Main-File rel=Main-File\r\nhref=\"file:///C:/Users/gaurides/AppData/Local/Temp/msohtmlclip1/01/clip.htm\">\r\n<link rel=File-List\r\nhref=\"file:///C:/Users/gaurides/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml\">\r\n<style>\r\n<!--table\r\n\t{mso-displayed-decimal-separator:\"\\.\";\r\n\tmso-displayed-thousand-separator:\"\\,\";}\r\n@page\r\n\t{margin:.75in .7in .75in .7in;\r\n\tmso-header-margin:.3in;\r\n\tmso-footer-margin:.3in;}\r\ntr\r\n\t{mso-height-source:auto;}\r\ncol\r\n\t{mso-width-source:auto;}\r\nbr\r\n\t{mso-data-placement:same-cell;}\r\ntd\r\n\t{padding-top:1px;\r\n\tpadding-right:1px;\r\n\tpadding-left:1px;\r\n\tmso-ignore:padding;\r\n\tcolor:black;\r\n\tfont-size:11.0pt;\r\n\tfont-weight:400;\r\n\tfont-style:normal;\r\n\ttext-decoration:none;\r\n\tfont-family:Calibri, sans-serif;\r\n\tmso-font-charset:0;\r\n\tmso-number-format:General;\r\n\ttext-align:general;\r\n\tvertical-align:bottom;\r\n\tborder:none;\r\n\tmso-background-source:auto;\r\n\tmso-pattern:auto;\r\n\tmso-protection:locked visible;\r\n\twhite-space:nowrap;\r\n\tmso-rotate:0;}\r\n.xl65\r\n\t{border-top:.5pt solid windowtext;\r\n\tborder-right:none;\r\n\tborder-bottom:none;\r\n\tborder-left:none;}\r\n.xl66\r\n\t{text-align:center;}\r\n.xl67\r\n\t{text-align:center;\r\n\tborder-top:.5pt solid windowtext;\r\n\tborder-right:none;\r\n\tborder-bottom:none;\r\n\tborder-left:none;}\r\n.xl68\r\n\t{font-weight:700;}\r\n.xl69\r\n\t{font-weight:700;\r\n\ttext-align:center;}\r\n-->\r\n</style>\r\n</head>\r\n\r\n<body link=\"#0563C1\" vlink=\"#954F72\">\r\n\r\n\r\n\r\nTest | ratio (new functor / old   functor)\r\n-- | --\r\nBM_cpu_LeakyRelu_DT_FLOAT/4096/real_time | 3.28537657\r\nBM_cpu_LeakyRelu_DT_FLOAT/8192/real_time | 1.790122575\r\nBM_cpu_LeakyRelu_DT_FLOAT/16384/real_time | 16.91255174\r\nBM_cpu_LeakyRelu_DT_FLOAT/24576/real_time | 1.005399109\r\nBM_cpu_LeakyRelu_DT_FLOAT/32768/real_time | 0.824908123\r\nBM_cpu_LeakyRelu_DT_FLOAT/49152/real_time | 1.019139325\r\nBM_cpu_LeakyRelu_DT_FLOAT/65536/real_time | 0.994447326\r\nBM_cpu_LeakyRelu_DT_FLOAT/98304/real_time | 0.982746662\r\nBM_cpu_LeakyRelu_DT_FLOAT/131072/real_time | 1.009672919\r\nBM_cpu_LeakyRelu_DT_FLOAT/196608/real_time | 0.966436371\r\nBM_cpu_LeakyRelu_DT_FLOAT/262144/real_time | 0.933957754\r\nBM_cpu_LeakyRelu_DT_FLOAT/524288/real_time | 1.003808748\r\nBM_cpu_LeakyRelu_DT_FLOAT/1048576/real_time | 0.969492904\r\nBM_cpu_LeakyRelu_DT_FLOAT/2097152/real_time | 0.742704991\r\nBM_cpu_LeakyRelu_DT_FLOAT/4194304/real_time | 0.915348558\r\nBM_cpu_LeakyRelu_DT_FLOAT/16777216/real_time | 0.875608084\r\nBM_cpu_LeakyRelu_DT_FLOAT/33554432/real_time | 1.002409155\r\nBM_cpu_LeakyRelu_DT_FLOAT/67108864/real_time | 1.010080935\r\nBM_cpu_LeakyRelu_DT_FLOAT/134217728/real_time | 1.005245793\r\nBM_cpu_LeakyRelu_DT_FLOAT/268435456/real_time | 0.996029937\r\nBM_cpu_LeakyRelu_DT_FLOAT/536870912/real_time | 1.000283819\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/4096/real_time | 2.344641727\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/8192/real_time | 3.328354997\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/16384/real_time | 0.965280883\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/24576/real_time | 0.877250291\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/32768/real_time | 0.959357464\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/49152/real_time | 0.860162176\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/65536/real_time | 2.067295868\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/98304/real_time | 1.953031524\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/131072/real_time | 2.11268343\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/196608/real_time | 1.573662098\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/262144/real_time | 1.065975921\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/524288/real_time | 1.224479246\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/1048576/real_time | 1.124058409\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/2097152/real_time | 0.761576635\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/4194304/real_time | 0.843122039\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/16777216/real_time | 1.191268866\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/33554432/real_time | 0.825884773\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/67108864/real_time | 1.05395473\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/134217728/real_time | 1.117124518\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/268435456/real_time | 1.209399775\r\nBM_cpu_LeakyRelu_DT_BFLOAT16/536870912/real_time | 1.220502986\r\n\r\n\r\n\r\n</body>\r\n\r\n</html>\r\n", "The improvement for larger sizes benefits the performance in models like 3d unet ", "@gaurides how stable is the improvement in larger sizes?  It's hard to say from those benchmarks... it seems to go up and down, and could be within noise.  The issue with benchmarking an op like this with such large sizes is that they are mostly memory bound.", "@gaurides Can you please check @cantonios's comments and keep us posted ? Thanks!", "> @gaurides how stable is the improvement in larger sizes? It's hard to say from those benchmarks... it seems to go up and down, and could be within noise. The issue with benchmarking an op like this with such large sizes is that they are mostly memory bound.\r\n\r\n@cantonios : I have seen some variation, but the improvement is mostly consistent. Especially when testing with the model, we have observed it to be consistent.", "Hi @gbaned @cantonios : just submitted a commit with the review rework. Sorry for the delay", "@gaurides Gentle ping as the branch cut is coming soon.", "> Improvements seem to be more stable on my machine. Which model are you testing, and do you have approximate performance impact there?\r\n\r\nHI @cantonios : i am testing on a 3d unet model. and With just this change i see 30-40% improvement.", ">  i am testing on a 3d unet model. and With just this change i see 30-40% improvement.\r\n\r\nCan you put this detail in the PR description so we have more context in the commit history?\r\n\r\n", "> > i am testing on a 3d unet model. and With just this change i see 30-40% improvement.\r\n> \r\n> Can you put this detail in the PR description so we have more context in the commit history?\r\n\r\nI am reconfirming improvement numbers, I accidentally had 1 other change as well.", "> > > i am testing on a 3d unet model. and With just this change i see 30-40% improvement.\r\n> > \r\n> > \r\n> > Can you put this detail in the PR description so we have more context in the commit history?\r\n> \r\n> I am reconfirming improvement numbers, I accidentally had 1 other change as well.\r\n\r\n@cantonios I see about 12-15% improvement in the model performance with this change."]}, {"number": 53847, "title": "Add release note about deterministic selection of conv algos", "body": "This PR is for the r2.8 branch. It updates the v2.8 release notes based on the #53826 cherry-pick from @reedwm.", "comments": ["@mihaimaruseac, please could you confirm that the release branch `RELEASE.md` always gets merged back into the master branch after final release? In other words, it's not necessary to submit a matching pull request against the master branch.", "> @mihaimaruseac, please could you confirm that the release branch `RELEASE.md` always gets merged back into the master branch after final release? In other words, it's not necessary to submit a matching pull request against the master branch.\r\n\r\nThat is correct. Once the branch is cut, we edit the release notes on the branch (I need to make this edit PR before final) and then merge back into master"]}, {"number": 53846, "title": "tf.data.experimental.sample_from_datasets non-deterministic in multi-gpu. ", "body": "See https://github.com/NVIDIA/framework-determinism/issues/39\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Does not apply\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory:", "comments": ["@duncanriach ", "@reedwm, bringing your attention to this potential issue for the 2.8 release.\r\n\r\n@yanniskar, I see that you're using version 2.4.1; are you able to see if this issue exists in the 2.8.0-rc0 pre-release (e.g. by using the `tensorflow/tensorflow:2.8.0rc0-gpu` docker image or `pip install tensorflow==2.8.0rc0`)? This issue may have been fixed since 2.4.", "Agree with @duncanriach that you should try on 2.8.0rc0. I'm not sure why this would be nondeterministic on TF 2.4, but it's possible this was fixed since then.", "@yanniskar Could you please try with  TF v2.8.0rc0 and let us know the outcome? Please refer to the  above comments as well. Thanks!", "Thanks for the response @sushreebarsa @duncanriach. I need to use the tensorflow version my org is on. Thus, I cannot upgrade to 2.8 to test this as my org does not support cloud training on that tensorflow version. If it is hard for you guys to verify this in 2.8, I can look into a workaround for testing my code in 2.8. Given other work priorities, it might take me some time before I am able to do this though.", "@yanniskar, if you cannot confirm that this issue is not present in the latest version of TensorFlow, then we cannot either, because we do not have access to the code you're running in order to run it on the latest version ourselves.\r\n\r\nAnother way to move this issue forward is for you to attempt to provide a self-contained reproducer, a simple piece of code that you can run and also share with us. That way, we can look at exactly what you're looking at, observe it on version 2.4.1, test if it's still present on the latest version, and then be able to potentially debug it. There are too many variables in these systems to be able to debug something that we cannot examine.\r\n\r\nThe following reproducer code demonstrates the kind of minimal example that could be provided to reproduce the observed multi-device (distributed) nondeterminism. This example distributes the dataset to both the GPU and CPU, with the two-element batch being split into one element per device. For this kind of problem (probably related to dataset distribution between devices), I doubt it matters what kind of devices are used.\r\n\r\nThe intention should be to recreate the basic configuration as accurately and minimally as possible. For example, it would probably be important to capture the distribution strategy used and when and how the dataset(s) are distributed (such as before or after applying sample_from_datasets).\r\n\r\nWith determinism, the devices should print the same sequence of values on each run, as they currently do in this example.\r\n\r\nThe following code can be run and modified in a copy of [this colab notebook](https://colab.research.google.com/drive/1oi8Q5PATXeyQvDE088fb7_-bBtgwvriU?usp=sharing).\r\n\r\n```python\r\ndataset1 = tf.data.Dataset.from_tensor_slices([[10, 11], [12, 13], [14, 15], [16, 17]])\r\ndataset2 = tf.data.Dataset.from_tensor_slices([[21, 22], [23, 24], [25, 26], [27, 28]])\r\nsample_dataset = tf.data.experimental.sample_from_datasets(\r\n  [dataset1, dataset2], weights=[0.5, 0.5], seed=43)\r\n\r\nmy_strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"CPU:0\"])\r\nwith my_strategy.scope():\r\n  @tf.function\r\n  def distribute_train_epoch(dataset):\r\n    for x in dataset:\r\n      my_strategy.run(print, args=(x,))\r\n \r\n  dist_dataset = my_strategy.experimental_distribute_dataset(sample_dataset)\r\n\r\nfor _ in range(2):\r\n  print(\"------------------\")\r\n  distribute_train_epoch(dist_dataset)\r\n```\r\n\r\nOutput:\r\n```\r\n------------------\r\n[10]\r\n[11]\r\n[21]\r\n[22]\r\n[23]\r\n[24]\r\n[12]\r\n[13]\r\n[25]\r\n[26]\r\n[14]\r\n[15]\r\n[27]\r\n[28]\r\n[16]\r\n[17]\r\n------------------\r\n[10]\r\n[11]\r\n[21]\r\n[22]\r\n[23]\r\n[24]\r\n[12]\r\n[13]\r\n[25]\r\n[26]\r\n[14]\r\n[15]\r\n[27]\r\n[28]\r\n[16]\r\n[17]\r\n```", "@yanniskar, are you using XLA (e.g. `@tf.function(jit_compile=True)`)?", "when the dataset contains 1000 to millions , its non deterministic. we noticed similar problem with tf 2.7 version.\r\n", "Hi @kabilan6,\r\n\r\nThanks for that. For clarity, please confirm or refute the following four points:\r\n\r\n1. You have a model that trains deterministically on a single GPU.\r\n2. When you use more than one GPU (including only two GPUs), you get nondeterminism.\r\n3. You're using `tf.data.experimental.sample_from_datasets`.\r\n4. When you remove only `tf.data.experimental.sample_from_datasets`, the nondeterminism goes away.\r\n5. The newest version of TensorFlow that you have reproduced this issue on is 2.7.\r\n\r\nPlease answer the following question:\r\n\r\nAre you using XLA (e.g. `@tf.function(jit_compile=True)`)?", "Hello, this deterministic issue is there across and not specific to tf.data.experimental.sample_from_datasets. Please refer a similar issue which i created \r\nhttps://github.com/tensorflow/tensorflow/issues/54259.\r\n\r\nPlease find below my response\r\n\r\nYou have a model that trains deterministically on a single GPU. - amn't sure about training but i guess its not related to training.\r\nWhen you use more than one GPU (including only two GPUs), you get nondeterminism. -- > i noticed nondeterminism with single or multiGPU (my example used batch function)\r\nYou're using tf.data.experimental.sample_from_datasets.--> no, i used experimental_distribute_dataset\r\nWhen you remove only tf.data.experimental.sample_from_datasets, the nondeterminism goes away. --> I still noticed issue i guess its tied to tf.data.batch\r\nThe newest version of TensorFlow that you have reproduced this issue on is 2.7. --> yes for my usecase i noticed it with 2.7version", "Okay, @kabilan6. From looking at your answers, I'm almost certain that you're dealing with a different issue because (1) your issue occurs with a single GPU and (2) you're not using sample_from_datasets. Thanks for opening #54259.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@duncanriach sorry for going radio silent for two weeks. Work has really picked up lately so I have not had time to come back to this. Here are my responses to your comments in order:\r\n1. I will try to reproduce the issue using a self-contained reproducer like you suggested. I will also do this using the latest Tensorflow version. Once I do that, I will report my findings back in this thread.\r\n2. As far as I know, I am not using XLA. For more context, I am using a simple keras model.fit training loop with mirrored strategy for this problem.\r\n\r\nHow does that plan sound? Lmk if you want more info on the XLA matter.", "Sounds great. Thanks, @yanniskar.", "\u60a8\u597d\uff0c\u6211\u662f\u7f8a\u5cfb\u9704\uff0c\u6211\u5df2\u7ecf\u6536\u5230\u60a8\u7684\u90ae\u4ef6\uff0c\u8c22\u8c22", "@yanniskar, Did you try @duncanriach workaround. \r\nAnd Please let us know if this is still an issue. Thanks!", "> @yanniskar, Did you try @duncanriach workaround. And Please let us know if this is still an issue. Thanks!\r\n\r\nNo luck unfortunately. Work has really picked up so I have not had time to investigate this due to competing priorities and this not being a blocking issue for development. Feel free to close this issue and I will circle back once I find some time (probably on my next PTO) to run the investigation I proposed. I don't think it is fair considering this an active issue given I have not verified it on the latest version of Tensorflow.", "Thanks for confirming @yanniskar.\r\nIf you face same issue on latest version please feel free to reopen. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53846\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53846\">No</a>\n"]}, {"number": 53843, "title": "Unify the Cudnn Execution Plan Runner", "body": "This PR tries to remove the `CudnnConvRunner` and `CudnnFusedConvRunner`, since both the runners (for unfused and fused conv respectively) actually share the same execution path: build op graph -> get execution plans -> allocate workspace -> prepare input/output data -> execute the plan. This execution path is also true for other Cudnn supported ops. So, this PR tries to move all these through the improved `CudnnExecutionPlanRunner`. \r\n\r\nThis PR can also help the integration of the new ops from Cudnn in the future. That way, for newly added ops, we just need to (1) prepare a `GetXXXGraph()` to build the op graph (2) add a `XXXSignature` to mark the new inputs/outputs.\r\n\r\ncc. @nluehr ", "comments": ["@awpr, can you review?", "Thanks, I like this direction of simplifying cuDNN frontend runners into one template -- just a few small style things to comment on.", "Thanks for the comments. I have committed the new change. PTAL.  @awpr ", "It seems the PR has been hanging for a while. I see some tests fail but they seem unrelated to the PR. Can you help check? @awpr @jurahul ", "Looks like it needs some changes to internal code that uses the runners.  Should be pretty minimal changes; I can probably get to it tomorrow."]}, {"number": 53842, "title": "Shape issues in tf.keras.metrics.SparseTopKCategoricalAccuracy with multiple dimensions (previously #36985)", "body": "Might not be a bug could be my application. But if that is the case I feel the documentation should be edited as from reading those functionality seems to be similar.\r\n\r\nWhen I run this:\r\n```\r\ntarget = tf.constant([[1,1,2,0,0,0],[1,1,2,2,0,0]])\r\npredict = tf.constant([[[0,1,0],\r\n                       [0,1,0],\r\n                       [0,0,1],\r\n                       [0,1,0],\r\n                       [1,0,0],\r\n                       [1,0,0]],\r\n                       [[0,1,0],\r\n                        [0,1,0],\r\n                        [0,0,1],\r\n                        [0,0,1],\r\n                        [0,1,0],\r\n                        [0,1,1000]]], dtype=tf.float32)\r\n\r\n\r\nprint(tf.shape(target))\r\nprint(tf.shape(predict))\r\n\r\nmask = tf.math.logical_not(tf.math.equal(target, 0))\r\n\r\nmask = tf.cast(mask, dtype=tf.int64)\r\n\r\n\r\nloss = tf.keras.losses.SparseCategoricalCrossentropy(\r\n        from_logits=True)\r\nloss(target, predict, sample_weight=mask)\r\n```\r\n```\r\ntf.Tensor([2 6], shape=(2,), dtype=int32)\r\ntf.Tensor([2 6 3], shape=(3,), dtype=int32)\r\n<tf.Tensor: shape=(), dtype=float32, numpy=0.3216761>\r\n```\r\nWorks as expected. But when I try it for TopKAccuracy I get this:\r\n```\r\nm = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1)\r\nm.update_state(target, predict, sample_weight=mask)\r\nm.result.numpy()\r\nInvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 6 [Op:Squeeze]\r\n```\r\n\r\nIn the documentation, both of them have the same definitions for y_true, y_pred and sample_weight. So not sure why the applications seem different here.\r\n\r\nThis may be my misuse, but not clear regardless. Any help would be appreciated.", "comments": ["@dfossl \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Sounds good!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53842\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53842\">No</a>\n"]}, {"number": 53841, "title": "[ROCM] pass `HIP_PLATFORM` to bazel", "body": "We need to pass HIP_PLATFORM to bazel. Authored by @deven-amd ", "comments": []}, {"number": 53840, "title": "Cherrypick \"Add missing file for Windows Python 3.10 GPU build.\"", "body": null, "comments": []}, {"number": 53839, "title": "Disable test that fails on MacOS.", "body": null, "comments": []}, {"number": 53837, "title": "Post Training Quantization doesn't work for tf.divide and tf.negative in TF 2.7", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installation: from pip\r\n- TensorFlow library: 2.7.0 (and 2.6.2 for reference)\r\n\r\n### 2. Code\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom pathlib import Path\r\n\r\nrun_negative = True\r\nif run_negative:\r\n    model_file = '/tmp/debug_layers/neg_model_' + tf.__version__.replace('.', '_')\r\nelse:\r\n    model_file = '/tmp/debug_layers/divide_2inputs_model_' + tf.__version__.replace('.', '_')\r\n\r\n_in = tf.keras.layers.Input((4, 4))\r\nout = tf.negative(_in) if run_negative else tf.divide(tf.keras.layers.ReLU()(_in), _in)\r\nm = tf.keras.models.Model(inputs=_in, outputs=out)\r\n\r\n_input = np.random.normal(size=(1, 4, 4))\r\noutput = m(_input)\r\n\r\n\r\ndef representative_dataset():\r\n    for _ in range(100):\r\n        d = np.random.normal(size=_input.shape).astype(np.float32)\r\n        yield [d]\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(m)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset\r\ntflite_quant_model = converter.convert()\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\r\ninterpreter.allocate_tensors()\r\nfor t in interpreter.get_tensor_details():\r\n    print(t['name'])\r\n\r\n# Path(model_file + '.tflite').write_bytes(tflite_quant_model)\r\n# m.save(model_file + '.h5')\r\n\r\n```\r\n\r\n### 3. Failure after conversion\r\nConversion passes succesfuly.\r\nIn TF 2.7 the converted network isn't quantized, but in TF 2.6.2 the network is quantized correctly.\r\n\r\noutput for TF 2.6.2:\r\n```\r\ninput_1\r\ntfl.quantize\r\ntfl.dequantize\r\nIdentity1\r\ntfl.quantize1\r\nIdentity\r\n```\r\n\r\noutput for TF 2.7.0:\r\n```\r\nserving_default_input_1:0\r\nPartitionedCall:0\r\n```\r\n\r\nThe output of TF 2.7 is missing the Quantize-Dequantize nodes", "comments": ["@elad-c ,\r\nI was facing different error while trying to execute the mentioned code.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/5c564ad20442e852738e6334130d3539/untitled196.ipynb).", "I've removed the last 2 lines which cuased the exception. I used them to save the models to disk and later open them with netron. It should work now", "for example, here's a Tensorflow model:\r\n![image](https://user-images.githubusercontent.com/78862769/150987102-356984f8-1fd6-4744-8b5f-8503b7d94c1c.png)\r\n\r\nThis is the output of the converter with TensorFlow 2.6.2:\r\n![image](https://user-images.githubusercontent.com/78862769/150987397-c616f33d-ad9e-4e00-ba56-e655fec3a82a.png)\r\n\r\nand this is the converter's output with TensorFlow 2.7.0:\r\n![image](https://user-images.githubusercontent.com/78862769/150987539-b599ae94-076c-41fd-8c9a-54d1739ee8e6.png)\r\n\r\n\r\n", "@elad-c ,\r\nI was able to execute the mentioned code in colab.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/5a47376c85dcde718d39da37c44c669e/untitled200.ipynb).Can you please provide the colab gist where you are facing issue.It helps to debug the issue.Thanks!", "Editted the code to print the difference in outputs. The difference matches the plots of the networks I added in the previous comment.", "@elad-c ,\r\nWith the updated code also i was not able to get the output which you are mentioned.Please find the [gist](https://colab.research.google.com/gist/tilakrayal/04c382d1732fb640f665a0378f96cc37/untitled209.ipynb).", "Looks like you got exactly the output I got (for TF 2.7.0)\r\n```\r\nserving_default_input_1:0\r\nPartitionedCall:0\r\n```\r\n\r\nWhen I changed the gist to install TF 2.6.3, I got:\r\n```\r\ninput_1\r\ntfl.quantize\r\ntfl.dequantize\r\nIdentity1\r\ntfl.quantize1\r\nIdentity\r\n\r\n```\r\n\r\nNote the TF 2.6.3 quantized the network (tfl.qantize, tfl.dequantize), and TF 2.7.0 did not. That is the bug I reported in this issue", "@Saduf2019 ,\r\nI was able to reproduce the issue in tf v2.7 and nightly, where in v2.5 the code executed as expected.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/cf4465c60aaffff832199da58b0e555b/53837.ipynb).", "Hi @elad-c !I am able to get an integer quantized model by setting the **converter.inference_input_type** and **converter.inference_ouput_type** to tf.uint8. \r\n![image](https://user-images.githubusercontent.com/86464649/161972282-5a48aef4-0fcc-4917-8ed4-8f3ce81b085a.png)\r\nAttaching [gist](https://colab.sandbox.google.com/gist/mohantym/c6a7c9bd298eb498c7133f6f5c5799e7/53837.ipynb#scrollTo=InHZ_CW0aCFP) and relevant [thread ](https://www.tensorflow.org/lite/performance/post_training_integer_quant)for reference.    Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53837\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53837\">No</a>\n"]}, {"number": 53836, "title": "ValueError: Failed to find data adapter that can handle input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10\r\n- TensorFlow installed from (source or binary):pip\r\n- TensorFlow version (use command below):2.5.0\r\n- Python version:3.7.11\r\n- CUDA/cuDNN version:11.2\r\n- GPU model and memory: rtx3060 laptop 6g\r\n\r\nproblem:\r\n```\r\nTraceback (most recent call last):\r\n  File \"E:/python/cloud_remove_keras/train_models/train_resnet.py\", line 42, in <module>\r\n    callbacks=[cp_callback])  # Pass callback to training\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\training.py\", line 1122, in fit\r\n    steps_per_execution=self._steps_per_execution)\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1348, in get_data_handler\r\n    return DataHandler(*args, **kwargs)\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1136, in __init__\r\n    adapter_cls = select_data_adapter(x, y)\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 978, in select_data_adapter\r\n    _type_name(x), _type_name(y)))\r\nValueError: Failed to find data adapter that can handle input: <class 'data_generator.DataGenerator'>, <class 'NoneType'>\r\n```\r\nnetworks:\r\n```\r\nimport keras.backend as K\r\nfrom keras.layers import Conv2D, Activation, Lambda, Add\r\nfrom keras.models import Model, Input\r\nfrom tensorflow.keras.utils import plot_model\r\n\r\nK.set_image_data_format('channels_first')\r\n\r\n\r\ndef resBlock(input_l, feature_size, kernel_size, scale=0.1):\r\n    \"\"\"Definition of Residual Block to be repeated in body of network.\"\"\"\r\n    tmp = Conv2D(feature_size, kernel_size, kernel_initializer='he_uniform', padding='same')(input_l)\r\n    tmp = Activation('relu')(tmp)\r\n    tmp = Conv2D(feature_size, kernel_size, kernel_initializer='he_uniform', padding='same')(tmp)\r\n\r\n    tmp = Lambda(lambda x: x * scale)(tmp)\r\n\r\n    return Add()([input_l, tmp])\r\n\r\n\r\ndef res_net(input_shape=(3, 512, 512),\r\n                  num_layers=32,\r\n                  feature_size=256):\r\n    \"\"\"Definition of network structure. \"\"\"\r\n\r\n    # define dimensions\r\n    input = Input(shape=input_shape)\r\n\r\n    x = input\r\n\r\n    # Treat the concatenation\r\n    x = Conv2D(feature_size, (3, 3), kernel_initializer='he_uniform', padding='same')(x)\r\n    x = Activation('relu')(x)\r\n\r\n    # main body of network as succession of resblocks\r\n    for i in range(num_layers):\r\n        x = resBlock(x, feature_size, kernel_size=[3, 3])\r\n\r\n    # One more convolution\r\n    x = Conv2D(input_shape[0], (3, 3), kernel_initializer='he_uniform', padding='same')(x)\r\n\r\n    # Add first layer (long skip connection)\r\n    x = Add()([x, input])\r\n\r\n    model = Model(inputs=input, outputs=x)\r\n\r\n    return model\r\n```\r\ndata generator:\r\n```\r\nimport numpy as np\r\nimport os\r\nfrom tensorflow.keras.utils import Sequence\r\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n\r\n\r\nclass DataGenerator(Sequence):\r\n    def __init__(self, infile_path, batch_size, ratio, train_available):\r\n        super(DataGenerator, self).__init__()\r\n\r\n        self.infile_path = infile_path\r\n        self.batch_size = batch_size\r\n        self.ratio = ratio\r\n        self.train_available = train_available\r\n\r\n        self.cloud_path = os.path.join(infile_path, 'cloudy_image')\r\n        self.ground_path = os.path.join(infile_path, 'ground_truth')\r\n        # \u6240\u6709\u6587\u4ef6\u5217\u8868\uff0c\u5728 cloudy \u548c ground truth \u6587\u4ef6\u5939\u4e2d\u6587\u4ef6\u540d\u79f0\u662f\u4e00\u6837\u7684\r\n        self.file_list = os.listdir(self.ground_path)\r\n        # \u6253\u4e71\u987a\u5e8f\r\n        np.random.shuffle(self.file_list)\r\n        # \u5206\u5272\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\r\n        n_train = int(ratio * len(self.file_list))\r\n\r\n        self.train_file_list = self.file_list[:n_train]\r\n        self.test_file_list = self.file_list[n_train:]\r\n\r\n        # \u5c06\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6587\u4ef6\u4fdd\u5b58\u5230\u6587\u4ef6\u4e2d\r\n        # np.savetxt(os.path.join(infile_path, 'train_file_list.txt'), np.array(self.train_file_list), fmt='%s')\r\n        # np.savetxt(os.path.join(infile_path, 'test_file_list.txt'), np.array(self.test_file_list), fmt='%s')\r\n\r\n    def __len__(self):\r\n        if self.train_available:\r\n            return int(np.floor(len(self.train_file_list) / self.batch_size))\r\n        else:\r\n            return int(np.floor(len(self.test_file_list) / self.batch_size))\r\n\r\n    def __getitem__(self, index):\r\n        if self.train_available:\r\n            file_list = self.train_file_list[index * self.batch_size:(index + 1) * self.batch_size]\r\n            batch_x = [np.transpose(img_to_array(load_img(os.path.join(self.cloud_path, file_name)))/255.0, [2, 0, 1]) for file_name in file_list]\r\n            batch_y = [np.transpose(img_to_array(load_img(os.path.join(self.ground_path, file_name)))/255.0, [2, 0, 1]) for file_name in file_list]\r\n\r\n            return np.array(batch_x), np.array(batch_y)\r\n\r\n        else:\r\n            file_list = self.test_file_list[index * self.batch_size:(index + 1) * self.batch_size]\r\n            batch_x = [np.transpose(img_to_array(load_img(os.path.join(self.cloud_path, file_name)))/255.0, [2, 0, 1]) for file_name in file_list]\r\n            batch_y = [np.transpose(img_to_array(load_img(os.path.join(self.ground_path, file_name))) / 255.0, [2, 0, 1]) for file_name in file_list]\r\n            return np.array(batch_x), np.array(batch_y)\r\n```\r\ntrain code:\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n\r\nfrom data_generator import DataGenerator\r\nfrom networks.resnet import res_net\r\n\r\n\r\nparams = {\r\n    'infile_path': r\"E:\\python\\cloud_removal\\data\\RICE_DATASET\\RICE2\",\r\n    'batch_size': 32,\r\n    'ratio': 0.8,\r\n    'train_available': True\r\n}\r\ntrain_Gen = DataGenerator(**params)\r\n\r\nparams = {\r\n    'infile_path': r\"E:\\python\\cloud_removal\\data\\RICE_DATASET\\RICE2\",\r\n    'batch_size': 32,\r\n    'ratio': 0.8,\r\n    'train_available': False\r\n}\r\nval_Gen = DataGenerator(**params)\r\n\r\nmodel = res_net()\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\ncheckpoint_path = \"train_models/resnet/cp.ckpt\"\r\ncheckpoint_dir = os.path.dirname(checkpoint_path)\r\n\r\n# Create a callback that saves the model's weights\r\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n                                                 save_weights_only=True,\r\n                                                 verbose=1)\r\n\r\n# Train the model with the new callback\r\nmodel.fit(x=train_Gen,\r\n          validation_data=val_Gen,\r\n          epochs=10,\r\n          callbacks=[cp_callback])  # Pass callback to training\r\n\r\nmodel.save('train_models/resnet')\r\n```", "comments": ["Hi @wjyts1999 ! I did not have the relevant dataset. Can you try one of following \r\n1. convert involved dataset to numpy arrays.\r\n2. use tf.keras instead of keras. \r\nAttaching relevant thread for [reference](https://stackoverflow.com/questions/57874436/tensorflow-data-adapter-error-valueerror-failed-to-find-data-adapter-that-can) .Thanks.", "@mohantym thank you very much", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53836\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53836\">No</a>\n"]}, {"number": 53835, "title": "Failed to find data adapter that can handle input: ", "body": "Hi, I am getting the error while writing the code:\r\n```\r\nTraceback (most recent call last):\r\n  File \"E:/python/cloud_remove_keras/train_models/train_resnet.py\", line 42, in <module>\r\n    callbacks=[cp_callback])  # Pass callback to training\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\training.py\", line 1122, in fit\r\n    steps_per_execution=self._steps_per_execution)\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1348, in get_data_handler\r\n    return DataHandler(*args, **kwargs)\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1136, in __init__\r\n    adapter_cls = select_data_adapter(x, y)\r\n  File \"D:\\anaconda3\\envs\\PyGIS\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 978, in select_data_adapter\r\n    _type_name(x), _type_name(y)))\r\nValueError: Failed to find data adapter that can handle input: <class 'data_generator.DataGenerator'>, <class 'NoneType'>\r\n```\r\nBelow is the data generator I have defined\uff1a\r\n```\r\nimport numpy as np\r\nimport os\r\nfrom tensorflow.keras.utils import Sequence\r\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n\r\n\r\nclass DataGenerator(Sequence):\r\n    def __init__(self, infile_path, batch_size, ratio, train_available):\r\n        super(DataGenerator, self).__init__()\r\n\r\n        self.infile_path = infile_path\r\n        self.batch_size = batch_size\r\n        self.ratio = ratio\r\n        self.train_available = train_available\r\n\r\n        self.cloud_path = os.path.join(infile_path, 'cloudy_image')\r\n        self.ground_path = os.path.join(infile_path, 'ground_truth')\r\n        # \u6240\u6709\u6587\u4ef6\u5217\u8868\uff0c\u5728 cloudy \u548c ground truth \u6587\u4ef6\u5939\u4e2d\u6587\u4ef6\u540d\u79f0\u662f\u4e00\u6837\u7684\r\n        self.file_list = os.listdir(self.ground_path)\r\n        # \u6253\u4e71\u987a\u5e8f\r\n        np.random.shuffle(self.file_list)\r\n        # \u5206\u5272\u8bad\u7ec3\u6570\u636e\u548c\u6d4b\u8bd5\u6570\u636e\r\n        n_train = int(ratio * len(self.file_list))\r\n\r\n        self.train_file_list = self.file_list[:n_train]\r\n        self.test_file_list = self.file_list[n_train:]\r\n\r\n        # \u5c06\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6587\u4ef6\u4fdd\u5b58\u5230\u6587\u4ef6\u4e2d\r\n        # np.savetxt(os.path.join(infile_path, 'train_file_list.txt'), np.array(self.train_file_list), fmt='%s')\r\n        # np.savetxt(os.path.join(infile_path, 'test_file_list.txt'), np.array(self.test_file_list), fmt='%s')\r\n\r\n    def __len__(self):\r\n        if self.train_available:\r\n            return int(np.floor(len(self.train_file_list) / self.batch_size))\r\n        else:\r\n            return int(np.floor(len(self.test_file_list) / self.batch_size))\r\n\r\n    def __getitem__(self, index):\r\n        if self.train_available:\r\n            file_list = self.train_file_list[index * self.batch_size:(index + 1) * self.batch_size]\r\n            batch_x = [np.transpose(img_to_array(load_img(os.path.join(self.cloud_path, file_name)))/255.0, [2, 0, 1]) for file_name in file_list]\r\n            batch_y = [np.transpose(img_to_array(load_img(os.path.join(self.ground_path, file_name)))/255.0, [2, 0, 1]) for file_name in file_list]\r\n\r\n            return np.array(batch_x), np.array(batch_y)\r\n\r\n        else:\r\n            file_list = self.test_file_list[index * self.batch_size:(index + 1) * self.batch_size]\r\n            batch_x = [np.transpose(img_to_array(load_img(os.path.join(self.cloud_path, file_name)))/255.0, [2, 0, 1]) for file_name in file_list]\r\n            batch_y = [np.transpose(img_to_array(load_img(os.path.join(self.ground_path, file_name))) / 255.0, [2, 0, 1]) for file_name in file_list]\r\n            return np.array(batch_x), np.array(batch_y)\r\n```\r\nThe code when training the model is as follows\uff1a\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n\r\nfrom data_generator import DataGenerator\r\nfrom networks.resnet import res_net\r\n\r\n\r\nparams = {\r\n    'infile_path': r\"E:\\python\\cloud_removal\\data\\RICE_DATASET\\RICE2\",\r\n    'batch_size': 32,\r\n    'ratio': 0.8,\r\n    'train_available': True\r\n}\r\ntrain_Gen = DataGenerator(**params)\r\n\r\nparams = {\r\n    'infile_path': r\"E:\\python\\cloud_removal\\data\\RICE_DATASET\\RICE2\",\r\n    'batch_size': 32,\r\n    'ratio': 0.8,\r\n    'train_available': False\r\n}\r\nval_Gen = DataGenerator(**params)\r\n\r\nmodel = res_net()\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\ncheckpoint_path = \"train_models/resnet/cp.ckpt\"\r\ncheckpoint_dir = os.path.dirname(checkpoint_path)\r\n\r\n# Create a callback that saves the model's weights\r\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n                                                 save_weights_only=True,\r\n                                                 verbose=1)\r\n\r\n# Train the model with the new callback\r\nmodel.fit(x=train_Gen,\r\n          validation_data=val_Gen,\r\n          epochs=10,\r\n          callbacks=[cp_callback])  # Pass callback to training\r\n\r\nmodel.save('train_models/resnet')\r\n```\r\nThe answer I found on stackoverflow didn't work for me, the data type returned by the data generator was already numpy.\r\nthe version of my tensorflow is 2.5.0.", "comments": ["@wjyts1999 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "i submit a new issue @sushreebarsa "]}, {"number": 53834, "title": "wierd behavior while running the inference on 2 different deep learning models(pb graphs) at the same", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.0.130/ 7.6.5\r\n- GPU model and memory: Nvidia GeForce GTX 1080 Ti - 11GB\r\n\r\n\r\n**Describe the current behavior**\r\nI am trying to run 2 tensorflow models by loading the 2 different pb graphs. \r\n\r\nHowever I also see that when I a load the 2 models together, the 2nd session is getting the values of the first session. \r\nI am suspecting that as the both models have input_1 layer as their first layer in their graph, this could be somehow creating a \r\nproblem when they are loaded at the same time. \r\n\r\nI have included 2 experiments to prove the same. \r\n\r\nExperiment 1 -> When I am running the `run_SS_model.py` file, below is the output for my first and last layer\r\n![image](https://user-images.githubusercontent.com/26414662/150339116-86d34a10-05c5-409d-9488-92b869f4850c.png)\r\n\r\nExperiment 2 -> When I am running the `run_two_models.py` file, note that the dimensions of the first layer is overwritten\r\nto the dimensions of the 2nd pb graph.\r\n![image](https://user-images.githubusercontent.com/26414662/150339999-ef45a12e-a057-410d-8bd3-61ed0bcb6f4e.png)\r\n\r\n\r\n**Describe the expected behavior**\r\n2 Models should be executed without any problem.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nGist -> https://github.com/sachinkmohan/run_obj_det_sem_seg\r\nPlease also find the conda environment YAML file in the same gist.\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\n```\r\n2022-01-20 13:35:05.120904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2022-01-20 13:35:05.120917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2022-01-20 13:35:05.120928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2022-01-20 13:35:05.120939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2022-01-20 13:35:05.120950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2022-01-20 13:35:05.120961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2022-01-20 13:35:05.120972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2022-01-20 13:35:05.121015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-20 13:35:05.121129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-20 13:35:05.121209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2022-01-20 13:35:05.121229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-20 13:35:05.121237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2022-01-20 13:35:05.121243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2022-01-20 13:35:05.121302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-20 13:35:05.121419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-20 13:35:05.121505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9927 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTensor(\"input_1:0\", shape=(?, 300, 480, 3), dtype=float32)\r\nTensor(\"predictions/concat:0\", shape=(?, ?, 18), dtype=float32)\r\nTensor-2 Tensor(\"input_1:0\", shape=(?, 300, 480, 3), dtype=float32)\r\nTensor(\"sigmoid/Sigmoid:0\", shape=(?, ?, ?, 1), dtype=float32)\r\n2022-01-20 13:35:06.200969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2022-01-20 13:35:06.690120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\nError in model_SS\r\nNone\r\nTraceback (most recent call last):\r\n  File \"/home/mohan/git/run_obj_det_sem_seg/run_two_models.py\", line 17, in <module>\r\n    cv2.imshow('prediction mask',b)\r\ncv2.error: OpenCV(4.5.5) /io/opencv/modules/highgui/src/window.cpp:1000: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n", "comments": ["@sachinkmohan ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to latest stable v2.7 and let us know if you are facing same issue.", "I tested this against TF 2.7 now, but I am still getting the same error. Please refer the screenshot. I have updated my [gist](https://github.com/sachinkmohan/run_obj_det_sem_seg)\r\n\r\nPlease follow the README.md file to replicate the same in TF2.7 environment.\r\n\r\n![TF2 7 bug](https://user-images.githubusercontent.com/26414662/150641722-525b60b2-d501-4bf1-aaa4-03545ef4b665.png)\r\n", "@sachinkmohan ,\r\nSorry for the delay response.This issue is more suitable for TensorFlow Models repo. Please post it on Tensorflow Models repo from [here](https://github.com/tensorflow/models/issues/new/choose). Thanks!", "@tilakrayal Thanks for the response! But these models I tested are not part of tensorflow models repo. These are the 2 repositories I used. These code are build using tensorflow. \r\n\r\n- For Obj Detection - https://github.com/pierluigiferrari/ssd_keras\r\n- Semantic Segmentation - https://github.com/qubvel/segmentation_models\r\n\r\nPlease advice!", "The code provided is fairly complex hence it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro? That will allow us to determine the source of the issue easily. Thanks!", "Quite disappointed despite providing so much information. You may close this. Hope you fix this bug sometime in the future. ", "@chunduriv ,\r\nWhile executing the given code in colab, i was facing different error and  noticed session is being crashed.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/16f3ccd62f8b78bcc2e57746e847a423/untitled233.ipynb).", "@sachinkmohan Looks like one of the graph was set as a default graph and the code is using that graph (instead of second graph). If the two graphs are not intended to be interacting with each other then you can create them under two different scope and perform the tasks. Please check [this SO](https://stackoverflow.com/questions/46617667/how-to-run-multiple-graphs-in-a-session-tensorflow-api#:~:text=The%20second%20option%20is%20to,are%20no%20connections%20between%20them.) answer. Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53834\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53834\">No</a>\n"]}, {"number": 53833, "title": "Using learning-rate decay schedule with Keras (transfer learning with RESNET) generates unsupported operand error 'ExponentialDecay'", "body": "\r\n** System information **\r\n\r\n- custom code\r\n- Ubuntu 20.4\r\n- TF installed from binary\r\n- TF / Keras 2.7.0\r\n- Python 3.8.12\r\n- no GPU\r\n\r\n** Current Behavior **\r\n\r\nTraining a Network to classify images, The network is based on RESNET152V2 + some new layers. We train last 19 layers of RESNET + the new added layers\r\n(data is XRAY dataset from Kaggle)\r\nUsing a learning-rate decay schedule, the training crashes with an error 'unsupported operand error'\r\n\r\nTypeError: unsupported operand type(s) for *: 'ExponentialDecay' and 'int'\r\n\r\n** Standalone code to reproduce the issue **\r\n\r\n[link to notebook](https://github.com/castorgit/AI-course-2021/blob/main/Group_Project/ResNet152V%20error.ipynb)\r\n\r\n\r\n", "comments": ["Hi @castorgit ! \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "Thanks I'll do!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53833\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53833\">No</a>\n"]}, {"number": 53832, "title": "Remove FunctionPass, use OperationPass<FuncOp> instead", "body": null, "comments": []}, {"number": 53831, "title": "`AutoGraph could not transform <function <lambda> at ...> ... Please report this to the TensorFlow team.`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): script\u00a0to reproduce below\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 5.10.91, NixOS, 21.11 (Porcupine)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): nixpkgs\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.9.9\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nConsider the following quick script:\r\n```py\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nprint(tf.__version__)\r\nprint(tfds.__version__)\r\nds = tfds.load(\"mnist\", split=\"train\", as_supervised=True)\r\n# Normalize 0-255 pixel values to 0.0-1.0\r\nds = ds.map(lambda image, label:\r\n            (tf.cast(image, tf.float32) / 255.0, tf.one_hot(label, depth=10)))\r\n```\r\nbased off of the example in the tensorflow-datasets docs [here](https://www.tensorflow.org/datasets/performances).\r\n\r\nRunning this code, I get the following:\r\n```\r\n[nix-shell:~/dev/research/lottery]$ AUTOGRAPH_VERBOSITY=10 python mnist_basic.py \r\n2.7.0\r\n4.4.0+nightly\r\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f63dfc5e310> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Constant constructor takes either 0 or 2 positional arguments\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f63dfc5e310> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Constant constructor takes either 0 or 2 positional arguments\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n```\r\n\r\nHere's my shell.nix to reproduce the exact same setup:\r\n```nix\r\nlet\r\n  # Last updated: 1/17/2022. Check for new commits at status.nixos.org.\r\n  pkgs = import (fetchTarball (\"https://github.com/NixOS/nixpkgs/archive/bc59ba15b64d0a0ee1d1764f18b4f3480d2c3e5a.tar.gz\")) { };\r\nin\r\npkgs.mkShell {\r\n  buildInputs = with pkgs; [\r\n    python3\r\n    python3Packages.flax\r\n    python3Packages.ipython\r\n    python3Packages.jax\r\n    (python3Packages.jaxlib.override { cudaSupport = true; })\r\n    python3Packages.matplotlib\r\n    python3Packages.tensorflow\r\n    python3Packages.tensorflow-datasets\r\n    python3Packages.tqdm\r\n    python3Packages.wandb\r\n    yapf\r\n  ];\r\n}\r\n```\r\n**Describe the expected behavior**\r\nThe example code to run as expected without any warnings.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing): n/a\r\n\r\n**Standalone code to reproduce the issue**\r\nSee above.\r\n\r\n**Other info / logs** \r\nMy entire setup should be reproducible from the shell.nix file above. I'm running on an m5.large EC2 instance (x86_64-linux).", "comments": ["@samuela I tried to replicate the issue on colab using TF v2.7.0 , tf-nightly(2.9.0-dev20220119) and didn't face the error reported in tf-nightly. This issue seems to be fixed in tf-nightly .Could you please have a look at the gist [here](https://colab.research.google.com/gist/sushreebarsa/f0e232d8b61478b16f25342bf549d91e/53831.ipynb#scrollTo=sOwjnRpTtE9R) and confirm the same ?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53831\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53831\">No</a>\n"]}, {"number": 53830, "title": "Is there plan to support rust?", "body": null, "comments": ["@zhucan ,\r\nCan you please take a look at this [link](https://github.com/tensorflow/rust) which delivers the information.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53829, "title": "`tf.sparse.sparse_dense_matmul` lack support for mixed bfloat16 and float32", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\na = tf.random.uniform([207, 768], dtype=tf.bfloat16)\r\nb = tf.random.uniform([768, 3072], dtype=tf.float32)\r\n\r\nc = tf.linalg.matmul(a,b)\r\nprint(c.shape) # (207, 3072)\r\na_sp = tf.sparse.from_dense(a)\r\nb_sp = tf.sparse.from_dense(b)\r\nc_sp = tf.sparse.sparse_dense_matmul(a_sp, b) # InvalidArgumentError\r\n```\r\n\r\n**Describe the current behavior**\r\n`tf.sparse.sparse_dense_matmul` cannot accept a tensor of type `bfloat16` and a tensor of type `float32`. However, `tf.linalg.matmul` do support this. \r\nFor the above code snippet, the error message is:\r\n```\r\nInvalidArgumentError: cannot compute SparseTensorDenseMatMul as input #3(zero-based) was expected to be a bfloat16 tensor but is a float tensor [Op:SparseTensorDenseMatMul]\r\n```\r\n\r\n**Describe the expected behavior**\r\nAccording to the document for `tf.sparse.sparse_dense_matmul`, it is equivalent to `tf.linalg.matmul` (but for sparse tensors), so `tf.sparse.sparse_dense_matmul` should also support such mixed precision inputs.\r\n", "comments": ["Hi @ArrowIntoTheSky ! As per [document](https://www.tensorflow.org/api_docs/python/tf/sparse/sparse_dense_matmul#args), a_sp and b should be of same dtype. Attaching resolved [gist](https://colab.sandbox.google.com/gist/mohantym/e5713e436ba00f6f30f345e7f28cb747/github_53829.ipynb) for reference. Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53829\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53829\">No</a>\n"]}, {"number": 53827, "title": "ImportError: cannot import name 'StructureCoder' from 'tensorflow.python.saved_model.nested_structure_coder'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10 Enterprise\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary via pip\r\n- TensorFlow version: 2.7.0 (have tried with several versions, 2.6.0, 2.6.2, 2.8.0\r\n- Python version: 3.8.8\r\n- Installed using virtualenv? pip? conda?: yes, venv + pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nUsing jupyter notebook,  `import tensorflow as tf`  results in the following error: \r\n\r\nImportError: cannot import name 'StructureCoder' from 'tensorflow.python.saved_model.nested_structure_coder' (C:\\path\\to\\folder)\r\n\r\nI've tried various iterations of uninstalling and re-installing tensorflow, restarting kernels, etc.   Same error. \r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`import tensorflow as tf`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@nhenscheid ,\r\nCan you please try to install  the latest stable tf v2.7 and let us know if still it is issue.Also please check this [link](https://github.com/tensorflow/tensorflow/commit/6c67b530dc40cdaf66ddf5d8f5d05c9e3046766f) once.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53827\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53827\">No</a>\n"]}, {"number": 53826, "title": "2.8-rc2 cherry-pick request: Fix issue where convolutions were not deterministic.", "body": "This fixes an issue where enabling op determinism with `tf.config.experimental.enable_op_determinism` did not make convolutions deterministic. Commit ced762bd4986dfad83ccf6d57e4e4fa3e47bd3fe is cherry-picked.", "comments": ["Hi @reedwm, are you planning to add this fix to the release notes (along with a note about the OOM bug you discovered)? I can make a PR for it, if you like.", "Good idea, can you create a PR? We might not be able to cherry-pick it in time, but it's not a huge deal if we don't.", "Okay, I'll do it. In the r2.8 branch, the most recent tag was v2.8.0-rc0. We usually go through rc0, rc1, and rc2 pre-releases before the final release. Are we skipping rc1 and rc2 for v2.8.0?", "> We usually go through rc0, rc1, and rc2 pre-releases before the final release. Are we skipping rc1 and rc2 for v2.8.0?\r\n\r\nNot sure, but @mihaimaruseac approved the release notes PR so it should make it into 2.8.\r\n\r\nIt would be a good idea to also create a PR for the master branch, but there's no rush for this.", "> It would be a good idea to also create a PR for the master branch\r\n\r\nI'm pretty sure that the release branch `RELEASE.md` always gets merged back into the master branch after final release."]}, {"number": 53825, "title": "Added information on validation TF on Windows Subsystem for Linux 2 (\u2026", "body": "\u2026aka WSL 2) for both GPUs and CPUs.\r\n\r\nAdded information on validation TF on Windows Subsystem for Linux 2 (aka WSL 2) for both GPUs and CPUs.", "comments": []}, {"number": 53824, "title": "[MHLO:Linalg] Dummy slice tensor for torchIndexSelect", "body": "Add dummy tensor with shape of slice for torchIndexSelectOp.\r\nTo enable fusion with reduction op down the line.", "comments": []}, {"number": 53823, "title": "[ROCm] Turn off SwapConvOperands on ROCm gpu", "body": "The following upstream commit turns on SwapConvOperands on gpu, and this does not yet work on the ROCm platform\r\n\r\ntensorflow@43abc0f\r\n\r\nUnit Test Failures\r\n```\r\n//tensorflow/compiler/xla/service/gpu/tests:swap_conv_operands_test      FAILED in 3 out of 3 in 18.6s\r\n//tensorflow/compiler/xla/tests:convolution_test_gpu                     FAILED in 3 out of 3 in 67.8s\r\n//tensorflow/compiler/xla/tests:convolution_test_gpu_alternative_layout_gpu FAILED in 3 out of 3 in 63.1s\r\n//tensorflow/compiler/xla/tests:convolution_variants_test_gpu            FAILED in 3 out of 3 in 11.5s\r\n```\r\n\r\nThis commit\r\n* disables the feature on ROCm to get the unit tests working again\r\n* adds a `no_rocm` tag to the new unit test that was added to specifically test the SwapConvOperands feature", "comments": ["@deven-amd  FYI", "The AMD ROCm CI fail here to be fixed in: ~~https://github.com/tensorflow/tensorflow/pull/54227~~  https://github.com/tensorflow/tensorflow/pull/54093"]}, {"number": 53822, "title": "tf.config.LogicalDeviceConfiguration memory_limit does not really work ?", "body": "**System information**\r\n- Custom code \r\n- Linux Ubuntu 20.04 (tested also 18.04)\r\n- Computer (not mobile device) \r\n- TensorFlow installed from pip install:\r\n- TensorFlow version 2.7 (tested also 2.4,2.5,2.6,2.8)\r\n- Python version: 3.7 (tested also 3.8)\r\n- Bazel version (if compiling from source): unbuntu 20.04 no self compil\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2.2/8.2.0.1 \r\n- GPU model and memory: NVIDIA RTX3090 24GB (tested also RTX2060 anX GTX1660) Driver 460.x\r\n\r\nHello I successfully ran the profiler tool on ma classification model to profile the maximum memory usage. Because I want to use different CNN on a same GPU. But I'm really baffled by the results of the profiler. Let me explain  \r\n\r\nI have a NVIDIA RTX3090 with 24GB memory so for my small CNN I set 512 memory limit in my code before all use with this code :  \r\n` tf.config.set_logical_device_configuration(gpus[0],[tf.config.LogicalDeviceConfiguration(memory_limit=512)])`\r\n\r\n\r\nIt seems to work because of the tensorflow logs\r\n`2022-01-19 16:24:13.615890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with **512 MB memory:**  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6`\r\n\r\nNvidia-smi shows that GPU use 419MiB are used\r\n![smi first](https://user-images.githubusercontent.com/35316806/150172707-7ff0eef5-6feb-4915-9662-724b16356254.png)\r\n\r\nThen I start a batch to make the inference on the classification model with batch size = 1\r\nand tensorboard shows that the model use about 100MiB\r\n![tensorboard](https://user-images.githubusercontent.com/35316806/150173173-823b1989-6174-4b99-a9aa-5fe272ba9b6e.png)\r\n\r\nso theoretically I could have set a small memory limit (under 512) but .. here is the real use of the memory given by Nvidia-smi is 1869MiB !\r\n![nvidiaamemoryused](https://user-images.githubusercontent.com/35316806/150173725-d1d8943d-9518-43b2-9607-ef0acfcbc3ec.png)\r\n\r\nI tested the code in Tensorflow 2.4,2.5,2.6,2.7 and 2.8. With different CUDA CUDNN but it is the same. Memory limit seems to be applied at Tensorflow level but not at the real GPU memory ( Nvidia level ).\r\nDid I miss something ? It would be very usefull to be able to manage the memory of a model !", "comments": ["@fitoule \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "Sorry I have added it on the first post", "@fitoule \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "Ok I've created a notebook that you can download and execute\r\nhttps://github.com/fitoule/tensorflow_gpu_memory-/blob/main/DemoMemoryIssue.ipynb", "@Saduf2019 Was able to replicate the issue on colab using TF [v2.6.0](https://colab.research.google.com/gist/sushreebarsa/cbd73983fec67d8b01c7121967bd5d32/53822-tf-2-6.ipynb),[2.7.0](https://colab.research.google.com/gist/sushreebarsa/3560712e22b6cb42ccf55890559dd189/53822.ipynb#scrollTo=DbMAqcBq8EN_) and [tf-nightly](https://colab.research.google.com/gist/sushreebarsa/44a183a9e0f7da664a62b4fe716b7518/53822.ipynb#scrollTo=831bjfFS-cYi) ,please find the attached gists for reference.Thanks!", "I made further investigations. Actually the command line works but documentation is not enough clear. on my test when I set memory_limit=200. \r\nA) When I Call import tensorflow => NVIDIA memory allocated is 423MiB\r\nB) When I Call the code with memory limit => NVIDIA memory allocated is 423+200=623MiB\r\nC) When a first inference is called then TensorFlow add a C part memory 938MiB (+423+200)  Total =  1561 MiB\r\n\r\nSo I understand that A+C is a constant that is needed by TensorFlow and the memory_limit affects only the B part. I tested on many different model.\r\nA+B depends on the driver or GPU HW.\r\n\r\nSo now it's clear for me. But finally documentation could mention this because see for a low model about 100MiB I need 1.5GB ram, it 's confusing.\r\n\r\n\r\n", "@fitoule Could you please confirm if this issue still persists ?\r\nPlease move this issue to  closed status if it is resolved for you.\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53822\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53822\">No</a>\n"]}]