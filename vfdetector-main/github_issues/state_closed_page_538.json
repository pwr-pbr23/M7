[{"number": 37590, "title": "#AttributeError: 'ImageDataGenerator' object has no attribute 'shape'", "body": "Hi everyone I am still getting used to using Keras. When I run the code below I get an error:\r\n**AttributeError: 'ImageDataGenerator' object has no attribute 'shape'**\r\nI haven't found any answer online even on stack overflow. Any help will be appreciated.\r\n\r\n\r\nimport os\r\nimport random\r\nimport cv2\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom sklearn.model_selection import train_test_split\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom functools import partial\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom time import time\r\n\r\npath = os.path.join(os.getcwd(), 'histopathologic-cancer-detection')\r\npath_totrain = os.path.join(path, 'train')\r\npath_tolabels = os.path.join(path, 'train_labels.csv')\r\nfiles = np.asarray(os.listdir(path_totrain))\r\nimage_paths = np.asarray([os.path.join(path_totrain, pic)\r\n                          for pic in os.listdir(path_totrain)])\r\n\r\n\r\ndef rest_graph(seed=42):\r\n    tf.compat.v1.reset_default_graph()\r\n    tf.keras.backend.clear_session()\r\n    tf.compat.v1.set_random_seed(seed)\r\n    np.random.seed(seed)\r\n\r\n\r\ndef read_pic(X):\r\n    img = cv2.imread(X)\r\n    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n    return rgb_img\r\n\r\n\r\nrest_graph()\r\n\r\ndf_labels = pd.read_csv(path_tolabels, usecols=['label'])\r\nlabels = df_labels.values\r\npositive_indices = list(df_labels[df_labels.label == 1].index)\r\nnegative_indices = list(df_labels[df_labels.label == 0].index)\r\nsize = len(files)\r\n\r\n#Distribution of data\r\nper_pos, per_neg = len(positive_indices)/size, len(negative_indices)/size\r\ndf_labels.hist()\r\nplt.show()\r\n\r\n#visualisation of pictures\r\nran_neg_ind = random.sample(negative_indices, 4)\r\nran_pos_ind = random.sample(positive_indices, 4)\r\nran_positive_pics = files[ran_pos_ind]\r\nran_negative_pics = files[ran_neg_ind]\r\nPathRanPosPics = [os.path.join(path_totrain, pic) for pic in ran_positive_pics]\r\nPathRanNegPics = [os.path.join(path_totrain, pic) for pic in ran_negative_pics]\r\n\r\nfig, axs = plt.subplots(2, 4, figsize=[15, 4])\r\nfig.suptitle('Histopathologic scans of lymph node', fontweight='bold')\r\nfor i in range(4):\r\n    axs[0, i].imshow(read_pic(PathRanNegPics[i]))\r\n    axs[0, i].set_title('Positive Example', fontweight='bold')\r\n\r\n    axs[1, i].imshow(read_pic(PathRanNegPics[i]))\r\n    axs[1, i].set_title('Negative Example', fontweight='bold')\r\nplt.show()\r\n\r\narr = np.c_[image_paths, labels]\r\ntrain_df = pd.DataFrame(arr, columns=['Image', 'label'])\r\n\r\n\r\n#Splitting data into train and test set\r\ntrain_set, valid_set = train_test_split(train_df, test_size=0.2)\r\n\r\nDatagen = ImageDataGenerator(rescale=1./255)\r\ntrain_gen = Datagen.flow_from_dataframe(train_set, directory=None, x_col='Image',\r\n                                        y_col='label', \r\n                                        target_size=(96, 96),\r\n                                        batch_size=128, class_mode='binary')\r\nvalDatgen = ImageDataGenerator(rescale=1./255)\r\nval_gen = valDatgen.flow_from_dataframe(valid_set, x_col='Image', y_col='label',\r\n                                        target_size=(96, 96), batch_size=128,\r\n                                        class_mode='binary')\r\n\r\n#creating model\r\nDefaultconv2D = partial(keras.layers.Conv2D, kernel_size=3,\r\n                        strides=1, padding='SAME', use_bias=False)\r\n\r\n\r\nclass ResidualUnit(keras.layers.Layer):\r\n    def __init__(self, filters, strides, activation='relu', **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.activation = keras.activations.get(activation)\r\n        self.main_layers = [\r\n            Defaultconv2D(filters=filters, strides=strides),\r\n            keras.layers.BatchNormalization(),\r\n            self.activation,\r\n            Defaultconv2D(filters=filters),\r\n            keras.layers.BatchNormalization()\r\n        ]\r\n\r\n        self.skip_layer = []\r\n        if strides > 1:\r\n            self.skip_layer = [\r\n                Defaultconv2D(filters=filters, kernel_size=1, strides=strides),\r\n                keras.layers.BatchNormalization()\r\n            ]\r\n\r\n    def call(self, inputs, **kwargs):\r\n        z = inputs\r\n        for layer in self.main_layers:\r\n            z = layer(z)\r\n        skip_z = inputs\r\n        for layer in self.skip_layer:\r\n            skip_z = layer(skip_z)\r\n        return self.activation(z + skip_z)\r\n\r\nmodel = keras.Sequential()\r\nmodel.add(Defaultconv2D(filters=32, activation='relu', input_shape=[96, 96, 3]))\r\nmodel.add(Defaultconv2D(filters=32, activation='relu'))\r\nmodel.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding='SAME'))\r\nprev_filter = 32\r\nfor filters in [64]*5 + [128]*6 + [256]*4:\r\n    strides = 1 if prev_filter == filters else 2\r\n    model.add(ResidualUnit(filters=filters, strides=strides))\r\n    prev_filter = filters\r\nmodel.add(keras.layers.GlobalAvgPool2D())\r\nmodel.add(keras.layers.Flatten())\r\nmodel.add(keras.layers.Dense(1, activation='softmax'))\r\nprint(model.summary())\r\nmodel.compile(optimizer='Adam', loss='binary_crossentropy',\r\n                        metrics=['accuracy'])\r\nhistory = model.fit_generator(train_gen, epochs=10, validation_data=valDatgen)\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@FritzPeleke , Can you please provide the simple standalone code with proper indentation or colab link to reproduce the issue in our environment. It helps us in understanding the issue faster. Thanks!", "Hi @khimraj, \r\nsorry I am not a skilled programmer and neither skilled at posting issues on GitHub.\r\nHere is a colab link. Hopefully it is okay\r\nhttps://gist.github.com/FritzPeleke/d0fc1fe638dc3c7a89eb0e303f19f9e9", "@FritzPeleke,\r\nOn running the above gist, I got an error stating `FileNotFoundError: [Errno 2] No such file or directory: '/content/histopathologic-cancer-detection/train'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/b42d5ea5cb8b7c46d8346c24934a669d/37590.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code along with the supporting files and also the TensorFlow version you are using. Thanks!", "Hi @amahendrakar, I finally realized the problem was me passing valDatgen to validation_data instead of passing val_gen :). \r\nThanks for the time "]}, {"number": 37589, "title": "exit bashrc if not running interactively", "body": "Addresses issue #30495; enables sftp access to container. The added line of code is already present in the `~/.bashrc` upon building the docker container. However, the `/etc/bash.bashrc` file does not contain this, and thus does not currently allow sftp access.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37589) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37589) for more info**.\n\n<!-- ok -->"]}, {"number": 37588, "title": "Fixing issue with EarlyStopping not working after CustomCallback", "body": "When a CustomCallback uses internally model.predict or model.evaluate as part of on_epoch_end, for instance, to track a custom evaluation on an test dataset, model.stop_training is reset to False even if it was previously set to True by Early Stopping. And then the training does not stop. Current workaround is putting EarlyStopping as the last callback of the list.\r\n\r\nCheck this colab with the full example: https://colab.research.google.com/drive/1lw943Ggwkp_wvGxVX-5XqaEJ5qXmrHlA\r\n\r\nThis patch fixes this by checking first if stop_training exists, and only if it doesn't, it initializes it to False. \r\nFixes #37587", "comments": ["Please open against master branch, not against r2.1", "You will have to create a new one, unfortunately it cannot be automatically be forwarded to be on top of master", "OK, I'll do... but master does not have yet `keras/engine/training_v2.py`. Updating only `callbacks.py` would be an incomplete solution. How should I proceed? (I'm new to this)", "BTW, Why could it be that `training_v2.py` is not on the master branch? I use tf from docker image tag latest-gpu-py3-jupyter and tf.__version__ is 2.1.0. Is master still in 1.15?\r\n", "Whenever we do a new release, we cut the branch from master. So, for example, for the upcoming 2.2 release, we cut `r2.2` from master. Then on the branch we only get cherrypicks needed to unblock the release and a few commits to change version numbers and release notes and that is all.\r\n\r\nIf we do a patch release (within support window, 1 year usually, 3 years for long term support releases), then we accept other patches. Note that we usually do patch releases only for security issues.\r\n\r\nIn this case, since the issue this fixes is also raised by you, first thing to do would be to test if it also reproduces in master. If it does, then the PR should be opened against master (and hopefully merged as a cherry-pick before the final releases for 2.2).\r\n\r\nIf it does not reproduce in master, then the suggestion is to wait for the 2.2 release, which should have the issue fixed (if you can, please check that the issue is not happening in `tensorflow==2.2.0-rc0` which was released last week).\r\n\r\nIf you still want to fix this for 2.1 (and only for 2.1; it is fixed in master and 2.2 already), then we can reopen this PR but it will not get merged until we get a requirement to do a patch release against 2.1 (for security purposes mostly). Since 2.1 is LTS, this might mean this PR could stay open for 3 years before merging. If we don't do any patch release during this time, we will close the PR without merging.\r\n\r\nThe missing file on master could mean that the code got moved around (we are doing some keras refactorings at the time). The git history should tell you what happened with the file.\r\n\r\nTo summarize, I would:\r\n1. test the issue against `tensorflow==2.2.0-rc0`. If it is solved, nothing to do\r\n2. test the issue against master. Either build from source or install `tf-nightly`. If it is solved, but 1. above failed then we should do a cherry-pick of the fixing commit. If it fails, then we should recreate this against master.\r\n3. decide if you want to patch 2.1, waiting until a patch release process starts. If yes, then I will reopen the PR (if master works) or I would suggest fixing master and then doing a cherry-pick PR instead (as that keeps a pointer in git history)", "Excelent! It's clear and understood. I'll check if patch is still necesary and resubmit if needed. Thank you very much for your explanation!", "Can confirm the issue is solved on v2.2. Thanks for your thorough explanation, it was very useful to me. Hope to be able to contribute in the future!"]}, {"number": 37587, "title": "EarlyStopping Callback not working with Multiple Callbacks", "body": "**System information** \r\n- Have I written custom code  \r\n- OS Platform and Distribution: *Google Colab*\r\n- TensorFlow version: *2.1.0*\r\n- Keras: *2.2.4-tf*\r\n- Python version: *3* \r\n- CUDA/cuDNN version: No GPU but happens also with it\r\n\r\n**Describe the current behavior**\r\nWhen a CustomCallback  uses `model.predict` or `model.evaluate` as part of `on_epoch_end`,  to for example, track a custom evaluation metric on an test dataset, `model.stop_training` is reset to False even if it was previously set to True by Early Stopping. Training does not stop. Current workaround is putting EarlyStopping as the last callback of the list.\r\n\r\n**Describe the expected behavior**\r\nRegardless the order in which callbacks are called, if one of the sets the model to stop training it should stop even if a later callback resets the stop flag.\r\n\r\n**Standalone code to reproduce the issue** \r\nCheck this colab with the full example: https://colab.research.google.com/drive/1lw943Ggwkp_wvGxVX-5XqaEJ5qXmrHlA\r\n\r\nIn short:\r\n```\r\nclass MyCallback(keras.callbacks.Callback):\r\n    def __init__(self, test_data):\r\n        super(MyCallback, self).__init__()\r\n        self.test_data = test_data\r\n\r\n    def on_epoch_end(self, epoch, logs=None):\r\n        print(f\"\\n--------- pre-predict stop_training={self.model.stop_training}\\n\")\r\n        #The problem is in the prediction: if commented ES works fine\r\n        predictions = self.model.predict(self.test_data.batch(512))\r\n        print(f\"\\n--------- post-predict stop_training={self.model.stop_training}\\n\")\r\n```\r\n```\r\nes = keras.callbacks.EarlyStopping(patience=2)\r\nmyc = MyCallback(test_data)\r\n\r\n#This causes EarlyStop not to stop\r\nmy_callbacks = [es, myc]\r\n#Either of these works fine\r\n#my_callbacks = [myc, es]\r\n#my_callbacks = [es]\r\n...\r\nmodel.fit(train_data.batch(512),\r\n          validation_data=validation_data.batch(512),\r\n          epochs=100,\r\n          callbacks=my_callbacks,\r\n          verbose=1)\r\n```\r\n\r\nThis issue is refered also in the keras repository: https://github.com/keras-team/keras/issues/13381\r\n\r\nSome thoughts: I'm not sure if the correct solution would be to discourage the use of predict or evaluate inside a training loop since there may be some other side effects of running one of those to the model.\r\n\r\nAnyway, I'm opening the issue and submitting a pull request to fix this.\r\n", "comments": ["I am able to reproduce the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/756228eeeca347ffa8f4a40cd662d7f1/untitled457.ipynb). Thanks!", "As suggested on the [pull request](https://github.com/tensorflow/tensorflow/pull/37588) it's now fixed on v2.2rc0 and current master. Closing the issue. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37587\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37587\">No</a>\n"]}, {"number": 37586, "title": "[Intel MKL] Fixing a bug in MKL Concat op", "body": "This fix also needs to be cherry-picked into r2.2 branch. Please let me know if I need to create a separate PR for that. ", "comments": []}, {"number": 37585, "title": "Improve preprocessing text docs", "body": "Added docstrings from the original keras_preprocessing repo to provide better readability of docs. Also included examples to help demonstrate how each function can be used.", "comments": ["@jaketae Can you please check build failures. Thanks!", "In particular, the error that needs fixing looks like\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/keras_dnn_correctness_test.runfiles/org_tensorflow/tensorflow/python/keras/distribute/keras_dnn_correctness_test.py\", line 27, in <module>\r\n    from tensorflow.python.keras.distribute import keras_correctness_test_base\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/keras_dnn_correctness_test.runfiles/org_tensorflow/tensorflow/python/keras/distribute/keras_correctness_test_base.py\", line 36, in <module>\r\n    from tensorflow.python.keras.preprocessing import sequence\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/keras_dnn_correctness_test.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py\", line 28, in <module>\r\n    from tensorflow.python.keras.preprocessing import text\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/keras_dnn_correctness_test.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/text.py\", line 58, in <module>\r\n    @keras_export('tf.keras.preprocessing.text.one_hot')\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/keras_dnn_correctness_test.runfiles/org_tensorflow/tensorflow/python/util/tf_export.py\", line 281, in __init__\r\n    self._validate_symbol_names()\r\n  File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/python/keras/distribute/keras_dnn_correctness_test.runfiles/org_tensorflow/tensorflow/python/util/tf_export.py\", line 308, in _validate_symbol_names\r\n    'Can only export symbols under package name of component. '\r\ntensorflow.python.util.tf_export.InvalidSymbolNameError: Can only export symbols under package name of component. e.g. tensorflow_estimator must export all symbols under tf.estimator\r\n```", "Let's try replacing `keras_export` with `tf_export`", "@mihaimaruseac Thank you for the heads up. I reviewed my previous commit and realized that this line might be the cause of the problem: \r\n```python\r\n@keras_export('tf.keras.preprocessing.text.one_hot')\r\n```\r\nI've fixed this line to be `@keras_export('keras...')` and got rid of the `tf` part. If this doesn't fix the issue, then I will try applying `@tf_export` instead. Thanks again!", "That seems to have solved the first issue but now there is another one\r\n\r\n```\r\nException raised:\r\n    Traceback (most recent call last):\r\n      File \"/usr/lib/python3.6/doctest.py\", line 1330, in __run\r\n        compileflags, 1), test.globs)\r\n      File \"<doctest tensorflow.python.keras.preprocessing.text.one_hot[1]>\", line 1, in <module>\r\n        tf.keras.preprocessing.text.one_hot(text, 20)\r\n      File \"/b/f/w/bazel-out/k8-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/text.py\", line 86, in one_hot\r\n        return text.one_hot(\r\n    AttributeError: 'str' object has no attribute 'one_hot'\r\n```", "@mihaimaruseac I see. Do you think this is caused by the fact that `text` is both a parameter of the function as well as the name of the module we are importing from (`from keras_preprocessing import text`)? ", "It's likely", "@mihaimaruseac I am considering two possibilities:\r\n\r\n- Changing the function parameter to something like `input_text` instead of `text` to resolve build error\r\n- Migrating `keras_preprocessing` to the TF repo entirely\r\n\r\nThe first option seems more reasonable, but if the long-term goal is to reduce dependency on Keras exports, maybe we can consider the latter as well. At any rate, the two options are not mutually exclusive, so I guess we could first come up with an alternate name for the parameter (is `input_text` permissible?) and work on the migration part later?", "Let's go with the first approach for now as keras tries to separate from TF.\r\n\r\nAlso, I just realized this might also need an API review from the API owners. But let's get the test green first and then I'll add the proper labels", "@mihaimaruseac I've replaced `text` with `input_text`; hopefully this will resolve the conflict with Keras imports. Thank you for the continuous input.\r\n\r\n--------------------\r\nEDIT: A build failure occurred due to the following example in the docstring:\r\n```python\r\nFailed example:\r\n    tf.keras.preprocessing.text.one_hot(sample_text, 20)\r\nExpected:\r\n    [4, 18, 1, 15, 17]\r\nGot:\r\n    [1, 1, 8, 12, 17]\r\n```\r\nThis error is in a sense unavoidable since the `hashing_trick` function does not always generate the same result. Hence, I pushed a commit erasing this example.", "Hello,  @jaketae @mihaimaruseac , therefore, is the problem because that \u201dtext\u201c is conflict with module name?", "> Hello, @jaketae @mihaimaruseac , therefore, is the problem because that \u201dtext\u201c is conflict with module name?\r\n\r\nHi @zjzh, yes, I believe that was the problem if I recall correctly. "]}, {"number": 37584, "title": "tf.linalg.triangular_solve segfaults instead of broadcasting", "body": "**System information** \r\n- Have I written custom code: no\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: pip install tensorflow\r\n- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: 3.7.6\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.linalg.triangular_solve` segfaults when the shapes don't match *and* tf.linalg.triangular_solve hasn't been run before (if it has successfully been run before, it raises an InvalidArgumentError instead).\r\n\r\n**Describe the expected behavior**\r\n\r\nNot to segfault. Ideally, to broadcast!\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nshape1 = (3, 3)\r\nshape2 = (1, 3, 3)\r\n\r\n# works either way around\r\nif np.random.rand() < 0.5: shape1, shape2 = shape2, shape1\r\n\r\nLA = tf.convert_to_tensor(np.tril(np.random.randn(*shape1)))\r\nB = tf.convert_to_tensor(np.random.randn(*shape2))\r\n\r\nsegfault = True\r\nif segfault:\r\n    tf.linalg.triangular_solve(LA, B, lower=True)  # segfaults\r\nelse:\r\n    tf.linalg.triangular_solve(tf.squeeze(LA), tf.squeeze(B), lower=True)  # works fine\r\n    tf.linalg.triangular_solve(LA, B, lower=True)  # raises InvalidArgumentError\r\n```\r\n\r\nMay be related to #25391", "comments": ["@st--,\r\nI was able to reproduce the issue with [TF2.1](https://colab.research.google.com/gist/amahendrakar/ace0caf3affea5614171a8697624988c/37584.ipynb). However, the issues seems to be fixed in [TF-nightly](https://colab.research.google.com/gist/amahendrakar/d09075d35701e82c6b2a0cf06b3efbc4/37584-tf-nightly.ipynb). Please check the attached gist. Thanks!", "Any updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37584\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37584\">No</a>\n"]}, {"number": 37583, "title": "Added drop_first feature to to_categorical", "body": "Pandas offers a `drop_first` argument as part of its [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function, which is comparable to TensorFlow's `to_categorical`. `drop_first` allows users to drop the first column of their one-hot vectorized binary matrix, since the first dimension can be considered a form of extraneous information. Added this feature into the current version of `to_categorical`, alongside an example in the docstring.", "comments": ["Why will the first dimension be considered extraneous information? I think this needs to be clarified in the docstring.\r\n\r\nIsn't this better done by slicing the output tensor?", "@alextp Any one of the generated columns is extraneous because its values can automatically be inferred from the rest of the columns. Therefore, dropping a column incurs zero loss of information. Links to relevant SO posts [here](https://datascience.stackexchange.com/questions/27957/why-do-we-need-to-discard-one-dummy-variable/27993#27993) and [here](https://datascience.stackexchange.com/questions/28353/always-drop-the-first-column-after-performing-one-hot-encoding).\r\n\r\nI can see how slicing can be used (and indeed that is how `drop_first` is implemented in this PR). But other frameworks like Pandas offer this functionality by default, so I thought it would be a useful addition to the TF API. I can improve the docs if you think that would be necessary! Thanks for the input.", "(for @tensorflow/api-owners )\r\nWe would like to keep the API surface small and since this can be achieved with a combination of existing APIs. We would like to keep things like this outside core TF in external libraries."]}, {"number": 37582, "title": "Update version numbers for TensorFlow 2.2.0-rc1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 2 -> 2\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.2.0-rc0\" found in source directory \n\"tensorflow/\". Good.\nWARNING: Below are potentially instances of lingering old version string \n\"2.2.0rc0\" in source directory \"tensorflow/\" that are not updated by this \nscript. Please check them manually!\ntensorflow/tools/pip_package/setup.py:65:2.2.0rc0\n```", "comments": []}, {"number": 37581, "title": "tf.keras.Model.fit() training fails, custom training loop succeeds for identical model, optimizer, and loss function", "body": "### System information \r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nYes, but can reproduce with (almost) stock example script\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMacOS Mojave and CentOS 7\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n\r\n- **TensorFlow version (use command below)**:\r\nv2.1.0-rc2-17-ge5bf8de 2.1.0\r\n\r\n- **Python version**:\r\n3.7.4\r\n\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n\r\n- **CUDA/cuDNN version**:\r\n10.1, but have also validated on CPU\r\n\r\n- **GPU model and memory**:\r\nGeForce RTX 2080TI\r\n\r\n- **Exact command to reproduce**:\r\nSee script below.\r\n\r\n### Describe the problem\r\nWhen training the same model with the same data, loss function, and optimizer, significantly different performance is obtained when using the built in training loops from tf.keras.Model.fit() versus implementing the training loop manually. This is clear by comparing the output of these two cases for the VAE example code provided at [Writing custom layers and models](https://www.tensorflow.org/guide/keras/custom_layers_and_models), which is reproduced below with minimal alterations. The issue becomes more clear when using a BinaryCrossentropy loss rather than MSE loss, and I have also reproduced it with custom loss functions. Obviously, the ability of users to detect the bug will depend on the data, loss function, optimizer, and extent of training. However, it should be possible to obtain the same performance between a simple custom training loop and the fit() method, as advertised in the documentation at the link above. Additionally, it is concerning that the recommended option (i.e. the fit() method) performs more poorly to the alternative, even with many more iterations (I have tried many, many iterations). Perhaps the fit() method is implementing additional loss terms not easily exposed to the user that are modifying the optimization landscape and subsequently the convergence behavior? The results are robust across multiple runs and (presumably) different random number seeds.\r\n\r\n### Source code / logs\r\nA script to reproduce is provided, making use of the dsprites data set through tensorflow_datasets. This example is likely not minimal, but it consistently reproduces the bug. Image reproductions with the trained VAE models are also included for the two training cases\r\n\r\n```python\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nimport tensorflow_datasets as tfds\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nclass Sampling(layers.Layer):\r\n  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\r\n\r\n  def call(self, inputs):\r\n    z_mean, z_log_var = inputs\r\n    batch = tf.shape(z_mean)[0]\r\n    dim = tf.shape(z_mean)[1]\r\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\r\n    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\r\n\r\n\r\nclass Encoder(layers.Layer):\r\n  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\r\n\r\n  def __init__(self,\r\n               latent_dim=32,\r\n               intermediate_dim=64,\r\n               name='encoder',\r\n               **kwargs):\r\n    super(Encoder, self).__init__(name=name, **kwargs)\r\n    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\r\n    self.dense_mean = layers.Dense(latent_dim)\r\n    self.dense_log_var = layers.Dense(latent_dim)\r\n    self.sampling = Sampling()\r\n\r\n  def call(self, inputs):\r\n    x = self.dense_proj(inputs)\r\n    z_mean = self.dense_mean(x)\r\n    z_log_var = self.dense_log_var(x)\r\n    z = self.sampling((z_mean, z_log_var))\r\n    return z_mean, z_log_var, z\r\n\r\n\r\nclass Decoder(layers.Layer):\r\n  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\r\n\r\n  def __init__(self,\r\n               original_dim,\r\n               intermediate_dim=64,\r\n               name='decoder',\r\n               **kwargs):\r\n    super(Decoder, self).__init__(name=name, **kwargs)\r\n    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\r\n    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\r\n\r\n  def call(self, inputs):\r\n    x = self.dense_proj(inputs)\r\n    return self.dense_output(x)\r\n\r\n\r\nclass VariationalAutoEncoder(tf.keras.Model):\r\n  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\r\n\r\n  def __init__(self,\r\n               original_dim,\r\n               intermediate_dim=64,\r\n               latent_dim=32,\r\n               name='autoencoder',\r\n               **kwargs):\r\n    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\r\n    self.original_dim = original_dim\r\n    self.encoder = Encoder(latent_dim=latent_dim,\r\n                           intermediate_dim=intermediate_dim)\r\n    self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\r\n\r\n  def call(self, inputs):\r\n    z_mean, z_log_var, z = self.encoder(inputs)\r\n    reconstructed = self.decoder(z)\r\n    # Add KL divergence regularization loss.\r\n    kl_loss = - 0.5 * tf.reduce_mean(\r\n        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\r\n    self.add_loss(kl_loss)\r\n    return reconstructed\r\n\r\n\r\ndef plotRecons(model, dat, savePlot=None):\r\n  \"\"\"Plots reconstructions of provided images.\r\n  \"\"\"\r\n  fig, ax = plt.subplots(len(list(dat)), 2)\r\n  for i, im in enumerate(dat):\r\n    ax[i,0].imshow(im[:,:,0], cmap='gray_r', vmin=0.0, vmax=1.0)\r\n    thisrecon = model(tf.cast(tf.reshape(im, (1,4096)), 'float32'))\r\n    thisrecon = np.reshape(thisrecon, (64,64))\r\n    randomIm = np.random.random(thisrecon.shape)\r\n    #thisrecon = np.array((thisrecon > randomIm), dtype=int)\r\n    ax[i,1].imshow(thisrecon, cmap='gray_r', vmin=0.0, vmax=1.0)\r\n    ax[i,0].tick_params(axis='both', which='both',\r\n                        left=False, right=False, bottom=False, top=False,\r\n                        labelleft=False, labelbottom=False,\r\n                        labelright=False, labeltop=False)\r\n    ax[i,1].tick_params(axis='both', which='both',\r\n                        left=False, right=False, bottom=False, top=False,\r\n                        labelleft=False, labelbottom=False,\r\n                        labelright=False, labeltop=False)\r\n\r\n  fig.tight_layout()\r\n  if savePlot is not None:\r\n    fig.savefig(savePlot)\r\n  plt.show()\r\n\r\n\r\ndef trainCustom(train_dataset, epochs=2, original_dim=4096):\r\n  vae = VariationalAutoEncoder(original_dim, 64, 32)\r\n  \r\n  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n  #loss_fn = tf.keras.losses.MeanSquaredError()\r\n  loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False,\r\n                                               reduction=tf.keras.losses.Reduction.SUM)\r\n\r\n  # Iterate over epochs.\r\n  for epoch in range(epochs):\r\n    print('Start of epoch %d' % (epoch,))\r\n  \r\n    # Iterate over the batches of the dataset.\r\n    for step, x_batch_train in enumerate(train_dataset):\r\n      with tf.GradientTape() as tape:\r\n        reconstructed = vae(x_batch_train)\r\n        # Compute reconstruction loss\r\n        loss = loss_fn(x_batch_train, reconstructed)\r\n        loss += sum(vae.losses)  # Add KLD regularization loss\r\n  \r\n      grads = tape.gradient(loss, vae.trainable_weights)\r\n      optimizer.apply_gradients(zip(grads, vae.trainable_weights))\r\n  \r\n      if step % 1000 == 0:\r\n        print('step %s: mean loss = %s' % (step, loss))\r\n  \r\n  return vae\r\n\r\n\r\ndef trainBuiltIn(train_dataset, epochs=2, original_dim=4096):\r\n  vae = VariationalAutoEncoder(original_dim, 64, 32)\r\n  \r\n  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n  \r\n  vae.compile(optimizer, #loss=tf.keras.losses.MeanSquaredError())\r\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False,\r\n                                                      reduction=tf.keras.losses.Reduction.SUM))\r\n\r\n  zipdata = tf.data.Dataset.zip((train_dataset, train_dataset))\r\n\r\n  vae.fit(zipdata, epochs=epochs)\r\n\r\n  return vae\r\n\r\n\r\ndef main():\r\n\r\n  def flatImFromDict(adict):\r\n    return tf.squeeze(tf.reshape(tf.cast(adict['image'], 'float32'), (-1, 4096)))\r\n\r\n  trainDataRaw = tfds.load(\"dsprites\", split=\"train\")\r\n  trainData = trainDataRaw.map(flatImFromDict)\r\n  trainData = trainData.shuffle(buffer_size=64).batch(64, drop_remainder=True)\r\n  plotData = [tf.cast(adict['image'], 'float32') for i, adict in enumerate(trainDataRaw) if i<5]\r\n\r\n  #First test custom, well-controlled loop\r\n  vaeCustom = trainCustom(trainData, epochs=2)\r\n  plotRecons(vaeCustom, plotData, savePlot='recons_custom.png')\r\n\r\n  #Next look at build in loops with fit function\r\n  vaeBuiltIn = trainBuiltIn(trainData, epochs=2)\r\n  plotRecons(vaeBuiltIn, plotData, savePlot='recons_built-in.png')\r\n\r\n\r\nif __name__==\"__main__\":\r\n  main()\r\n\r\n```\r\n\r\n![recons_built-in_CrossEntropy](https://user-images.githubusercontent.com/7297977/76646659-b7d1bc00-6531-11ea-9e4d-8d280531121a.png)\r\n![recons_custom_CrossEntropy](https://user-images.githubusercontent.com/7297977/76646661-b86a5280-6531-11ea-916a-4ae20c4b78a8.png)\r\n", "comments": ["i have replicated this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/06c139856a5a70086b953dd7ba1cd558/37581.ipynb)\r\n", "Has there been any progress on this?  Or an explanation?  I would be satisfied with just updating the documentation and discussion at the link I provided in order to convey why differences occur with the different training routines.  If the loss function with the fit() method is by default modified in some way, the user should be notified of this.", "Hi @JIMonroe,\r\n\r\nThere's a subtle bug in your code.\r\n\r\n```\r\nzipdata = tf.data.Dataset.zip((train_dataset, train_dataset))\r\n```\r\n\r\nShould be:\r\n\r\n```\r\nzipdata = train_dataset.map(lambda x: (x,x))\r\n```\r\n\r\nIn the `zip` the two copies were getting independent shuffles.\r\n\r\nThis sort of thing's always easier to spot if you minmize the example.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37581\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37581\">No</a>\n", "Great, thanks!  Totally makes sense if you're zipping together two iterators."]}, {"number": 37579, "title": "[r2.2:Cherrypick]Export fill mode for image_projective_transform", "body": "PiperOrigin-RevId: 300652382\nChange-Id: I762197f7dfbd545445db7b3b330d463f5f66d856", "comments": []}, {"number": 37578, "title": "Fixes to `Wrapper.get_config` and `Wrapper.from_config`.", "body": "This PR aims at solving two light issues I identified with the `tf.keras.layers.Wrapper` class.\r\n\r\nThis has been tested on both TensorFlow 2.1.0 and 2.2.0-rc0 for Python 3.6.9, both installed using `pip` on a Linux 64-bits system.\r\n\r\n#### 1. Serialization through `get_config`.\r\n\r\n**Issue**: The dict output by `Wrapper.get_config()` is designed to contain the config of the wrapped layer, in a format similar to that output by keras serialization utilities. However, the identifier of that layer (its `class_name`) is currently manually gathered within the `get_config`, which results in bugs such as  custom layers set for registration (using `tf.keras.utils.register_keras_serializable`) not being given their proper identifier.\r\n\r\n**Fix**: I propose to replace the manual creation of the `layer` entry within the returned configuration by a direct call to `serialize_keras_object`.\r\n\r\n**Minimal example**:\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.keras.utils.register_keras_serializable(package='test')\r\nclass CustomLayer(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        return inputs\r\n\r\nwrapper = tf.keras.layers.Wrapper(CustomLayer())\r\nconfig = wrapper.get_config()\r\ntf.keras.layers.Wrapper.from_config(config)\r\n```\r\nWhen run before the fix, this fails on the last line, raising `ValueError: Unknown layer: CustomLayer`.\r\nWhen run after the fix, this runs successfully.\r\n\r\n#### 2. Instantiation through `from_config`.\r\n\r\n**Issue**: Contrary to what the source code suggests, `Wrapper.from_config` has side effects on the provided config dictionary; in short, it pops out its `layer` sub-dict.\r\n\r\n**Fix**: Instead of calling `config.copy()`, I suggest using `copy.deepcopy(config)` before popping out the `layer` sub-dict of the (deep copy of the) input config dictionary.\r\n\r\n**Minimal example**:\r\n```python\r\nimport tensorflow as tf\r\n\r\ndense = tf.keras.layers.Dense(32)\r\nwrapper = tf.keras.layers.Wrapper(dense)\r\nconfig = wrapper.get_config()\r\nassert 'layer' in config, 'before wrapper instantiation'\r\ntf.keras.layers.Wrapper.from_config(config)\r\nassert 'layer' in config, 'after wrapper instantiation'\r\n```\r\nWhen run before the fix, the second assertion fails due to the side effect.\r\nWhen run after the fix, this runs successfully.", "comments": ["It seems that the test is failing wrt deepcopy:\r\n\r\nhttps://source.cloud.google.com/results/invocations/2e5f1424-87f0-4826-93b2-d3936a6caa51/targets/%2F%2Ftensorflow%2Fpython%2Fkeras%2Flayers:wrappers_test/tests\r\n", "@qlzh727 Thank you for the review.\r\n\r\nI see what went wrong; in the `Bidirectional` wrapper, the (optional) `backward_layer` is being de-serialized within the overridden part of `from_config`, thus the `config` passed to the super method contains an instantiated layer, which `deepcopy` does not know how to handle.\r\n\r\nI see two ways to handle this:\r\n\r\n0. Replace the `super().from_config` call in `Bidirectional.from_config` with direct re-instantiation of the forward layer and constructor call. This way there is no secondary deepcopy call and the bug does not arise - but not calling the super method and duplicating some of its lines of code may feel improper.\r\n\r\n1. Add a `parse_config` method to `Wrapper` that takes care of everything save for the deepcopy, and have `from_config` run the latter before delegating to the former. But this feels like a painful hack to avoid one bug...\r\n\r\nI will push a commit implementing solution zero, but let me know if you would rather adopt another way of handling this.", "I tested locally that all tests from `wrapper_test.py` pass with the last commit.\r\n(edit: I force pushed a correction of said commit, removing a useless line of code)\r\n\r\nOn the side, I realized custom layers used as backward layer were not properly serialized either; I thus also made a minor modification to `Bidirectional.get_config`."]}, {"number": 37576, "title": "Add Octave Convolution Layers to tensorflow keras layers", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n**System information**\r\n- TensorFlow version (you are using): TF 2.1\r\n- Are you willing to contribute it (Yes/No): Yes. And the code change is ready.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n_Feature:_\r\n[Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution](http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Drop_an_Octave_Reducing_Spatial_Redundancy_in_Convolutional_Neural_Networks_ICCV_2019_paper.pdf)\r\n\r\n_Main idea:_\r\nDecompose the feature maps of the convolutional layers into features of different spatial frequencies which will enlarge the receptive field and reduce the FLOPs and memory cost.\r\n\r\nAdd an implementation of octave convolution layers (OctConv1D, OctConv2D, OctConv3D) and octave transposed convolution layers (OctConv2DTranspose, OctConv3DTranspose) that inherit from an abstract OctConv layer which, in turn, inherits from tf.keras.layers.Layer (same hierarchy as the already existing convolutional layers).\r\nAn octave_add function that takes as input the output of an OctConvND layer (list of two tensors one for  high frequencies and the other for low frequencies) and a tf.keras.layer like Dropout, MaxpoolingND, etc which will be applied on the inputs. The output is the list of the two resulting tensors\r\n\r\nThe backbone of the implementation is based on the following [github repository](https://github.com/CyberZHG/keras-octave-conv) (MIT and \"Anti 996\" licensed) by @CyberZHG\r\n\r\nThe original code has been substantially modified:\r\n - migration from keras to tf.keras\r\n - implementation of an abstract OctaveConv layer to emulate the hierarchy of the already existing Conv layers in TensorFlow\r\n - implementation of the 3D octave convolution layer OctConv3D and the transposed octave convolution layers OctConv2DTranspose, OctConv3DTranspose\r\n - bug fixes (for instance, in the original implementation setting the trainable attribute of the octave convolution layers to False wouldn't freeze the learnable weights)\r\n\r\n_Sample use case of the layers OctConvLayers:_\r\n\r\n```\r\nl1 = Input(shape=(28,28, 1))\r\nl2 = OctaveConv2D(32, (3, 3), activation='relu', low_freq_ratio=0.25)(l1_input) # takes a single input tensor and outputs a list of 2 output tensors (low_freq_ratio > 0)\r\nl3 = octave_add(l2, MaxPooling2D(pool_size=(2, 2)))\r\nl4 = octave_add(l3, Dropout(0.2))\r\nl5 = OctaveConv2D(32, (3, 3), activation='relu', low_freq_ratio=0)(l4) # takes a list of 2 tensors and outputs a tensor (low_freq_ratio = 0)\r\nl6 = Flatten()(l5) # l5 is a tensor so no need to use octave_add\r\n```\r\n\r\n_Current Behavior:_\r\nCurrently tensorflow doesn't have any implementation of the octave convolution layers.\r\n\r\n_Why we need this api:_\r\nThe \"vanilla\" ConvND/ConvNDTranpose layers can be directly replaced by the OctConvND/OctConvNDTranspose layers and simple experiments that will be provided show that models using octave convolutions consistently give better performances than their vanilla versions.\r\nAlso, using octave convolutions will reduce the FLOPs and the memory cost.\r\n\r\n**Will this change the current api? How?**\r\nNo, it won't change the current api.\r\nIt will add 6 new classes to tf.keras.layers (1 abstract, 3 OctConvND and 2 OctConvNDTranspose)\r\n\r\n**Who will benefit with this feature?**\r\nTensorFlow users who are seeking to improve the performances and computational costs of their model with a direct replacement of the vanilla convolutions without any adjustments in the network architecture.\r\n\r\n**Any Other info.**", "comments": ["Thanks,i will look into this matter soon\r\n", "Hi @maxkaustav, thank you for your input!\r\nHowever, as I stated in the issue, I already had made an implementation of the octave convolutions.\r\nI was waiting to see if the tensorflow team was interested by it.\r\nI have now made the Pull Request (PR #38154 ) with my implementation of the features so I invite you and the tensorflow team to look at it.\r\n\r\nI've seen in your PR (#38052 ) that you have adapted the [initial implementation](https://github.com/CyberZHG/keras-octave-conv) by CyberZHG. \r\nHowever, it is missing the implementation of the 3D version and the 2D and 3D transpose versions and your layers don't follow the hierarchy of the tf.keras.Conv layers.\r\nIt also has some bugs (for instance, setting the trainable attribute of the octave convolution layers won't freeze the weights) that were there from the initial implementation.", "/cc @nikitamaia Can we move this in progress or close it with the related PR.", "@amascia,\r\nSorry for the delayed response. Since the [PR corresponding to this issue](https://github.com/tensorflow/addons/pull/1782) is **`Closed`**, with the comment,\r\n\r\n> Closing as this is being broken up into more managable PRs for review.\r\n\r\ncan you please confirm if this **`Feature`** is still relevant? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 37575, "title": "Keras model fit with class_weight fails on TPU but not on GPU", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: Colab\r\n- TensorFlow installed from (source or\r\nbinary): Colab\r\n- TensorFlow version (use command below): 2.x in Colab\r\n- Python version: Colab\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: Colab\r\n- GPU model and memory: Colab\r\n\r\n**Describe the current behavior**\r\nIf I use the `class_weight` argument during model.fit(...) with a TPU, I get the following error:\r\n![image](https://user-images.githubusercontent.com/36116534/76622564-07b08300-6532-11ea-81a3-2027161014dc.png)\r\n\r\nIf I change the runtime type to GPU, the model fits fine.  \r\n\r\n**Describe the expected behavior**\r\nDefining  `class_weight` on TPU should not fail if it works on the GPU.\r\n", "comments": ["@chris-clem \r\n\r\nCould you please share a simple stand alone code for us to replicate the issue faced by you.\r\n\r\nAlso please refer to these [link1](https://github.com/tensorflow/tpu/issues/236) and [link2](https://stackoverflow.com/questions/52906186/keras-tpu-compilation-failure-detected-unsupported-operations) if it helps you resolve the issue as per the error shared.", "Yes, there you go: https://colab.research.google.com/drive/1beNMk03qGfGpcXwpHVLTnuGBTKQVREyV. It runs with GPU backend, but not with TPU.", "@chris-clem \r\nWe will not be able to replicate the issue unless all dependencies are shared, please find  [the gist](https://colab.sandbox.google.com/gist/Saduf2019/50d630ae9c408686b9aafc0a3873ff44/untitled95.ipynb) of error faced by us.", "The error in your gist comes from using Tensorflow version 1.15.0, right? I use 2.1.0. \r\nI created two gists:\r\n- one with GPU backend: [keras-class-weight-gpu.ipynb](https://colab.research.google.com/gist/chris-clem/e6bf2a9b2b0da56a903b598eda80275c/keras-class-weight-gpu.ipynb)\r\n- one with TPU backend: [keras-class-weight-tpu.ipynb](https://colab.research.google.com/gist/chris-clem/0c6644195fee5d944e80f04a3fd1b428/keras-class-weight-tpu.ipynb)\r\n\r\nThe GPU notebook runs in Colab, the TPU one throws this error:\r\n![image](https://user-images.githubusercontent.com/36116534/76951693-5aac8080-690c-11ea-9b92-9597e08f2c0d.png)", "Is there any update on this?", "I think this problem occurs only if class weight is input is a dictionary. If it's input as list it runs.", "@chris-clem This was resolved with `tf-nightly` even for TPU. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/93e24a5043b797e0f47b641b5ead2723/keras-class-weight-tpu.ipynb). Thanks\r\n\r\nPlease verify it and close the issue if this was resolved for you. Thanks!", "@chris-clem Can you please verify once and close the issue if this was resolved for you. Thanks!", "Sorry for the delay. Yes it works, thank you!\r\n\r\nAm 08.04.2020 um 03:01 schrieb Vishnuvardhan Janapati <notifications@github.com>:\r\n\r\n\ufeff\r\n\r\n@chris-clem<https://github.com/chris-clem> Can you please verify once and close the issue if this was resolved for you. Thanks!\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/37575#issuecomment-610693845>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AITRQNQMRRICDWBAQ37YSRTRLPEGZANCNFSM4LHCXIMA>.\r\n", "Closing this issue as this was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37575\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37575\">No</a>\n"]}, {"number": 37574, "title": "Added description for call() in tf.keras.layers.Layer", "body": "Fixes #36757 temporarily till the functionality on `kwargs` is added.\r\n@mihaimaruseac - Please review.", "comments": ["@mihaimaruseac , Changed description. Please review."]}, {"number": 37572, "title": "cc_toolchain_suite '@androidndk//:toolchain-libcpp' does not contain a toolchain for cpu 'k8'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Source\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 2.0.0\r\n\r\n**Describe the problem**\r\nI was trying to build tensorflow [camera demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#building-the-demo-with-tensorflow-from-source) application using bazel.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1.) I cloned the repo using.\r\n`git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\n` \r\n\r\n2.) Downloaded ndk [14b, 20b ](https://developer.android.com/ndk/downloads/older_releases.html#ndk-14b-downloads)(tried both)\r\n\r\n3.) Build android-sdk 26.0.1\r\n\r\n4.) configured `./WORKSPACE` using `./configure` and specified above mentioned ndk and sdk paths. Also, I specified API levels to their default values.\r\n\r\n5.) Then I tried \r\n\r\n`bazel build --cxxopt='--std=c++11' -c opt //tensorflow/examples/android:tensorflow_demo\r\n`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nERROR: \r\n\r\n`/home/unreal/.cache/bazel/_bazel_unreal/6de5222c143ce19677cab557a9a28cd8/external/androidndk/BUILD.bazel:41:1: in cc_toolchain_suite rule @androidndk//:toolchain-libcpp: cc_toolchain_suite '@androidndk//:toolchain-libcpp' does not contain a toolchain for cpu 'k8'\r\nERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted: Analysis of target '@androidndk//:toolchain-libcpp' failed; build aborted\r\nINFO: Elapsed time: 2.946s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (107 packages loaded, 8813 targets configured)`\r\n\r\nIt seems like I am missing something for ndk bundle that I downloaded. [Here](https://docs.bazel.build/versions/master/android-ndk.html#integration-with-platforms-and-toolchains) there is something `register_toolchains(\"@androidndk//:all\")` in WORKSPACE, but I don't know what I am missing. \r\n", "comments": ["Potential duplicate #24124", "I solved this by adding the commend of building tflite `--fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a \r\n  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain` [https://www.tensorflow.org/lite/guide/android](here) \r\nmy bazel version is 2.0.0, with sdk 23 and ndk r17c", "@komejisatori  is right. If you want to build fat APK, you need to provide --fat_apk_cpu, --host_crosstool_top options.\r\nIf you want to build a specific target arch (for example ARM64), then you just need to provide a proper \"--config\" option.\r\nBut this is not enough. It seems that some code require C++14 support.\r\nI've verified the following command works for me.\r\n\r\n```bash\r\nbazel build --cxxopt='--std=c++14' --config=android_arm64 -c opt //tensorflow/examples/android:tensorflow_demo\r\n```", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37572\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37572\">No</a>\n", "I think between bazel versions, the default value of --config has changed. Earlier I have seen armeabi for mediapipe project but now its picking up my work station's platform. Probably similar issue in tensorflow as well. komejisatori's comment above fixed my build in mediapipe as well."]}, {"number": 37571, "title": "Two errors were raised when using mirrored strategy.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): using conda\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: 10.1.243 / 7.6.5\r\n- GPU model and memory: Tesla T4 16GB\r\n\r\n\r\n```\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: Dec_VAE_VDraw_Var/Identity:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n...\r\n_SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'Dec_VAE_VDraw_Var/Identity:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'Dec_VAE_VDraw_Mean/Identity:0' shape=(None, 128) dtype=float32>]\r\n\r\n```\r\nreproducible notebook files:\r\nhttps://drive.google.com/file/d/1DzES68HT3-7dlrpH6oo13Q9MgybdjcGm/view?usp=sharing\r\n\r\nWhen i didn't use mirrored strategy and added experimental_tf_function = False as an argument to model.compile, the errors were not raised.\r\n\r\nIt would be glad if you would help me to solve this errors.\r\n\r\n\r\n", "comments": ["Would it be possible to create a small Colab notebook that reproduces the issue?", "> Would it be possible to create a small Colab notebook that reproduces the issue?\r\n\r\n@ccrusius \r\nI know that google colab does not support multiple gpus. Does mirrored strategy work on one gpu?", "Hi @Crispy13, yes you can run MirroredStrategy with one GPU in colab and for this scenario I think we should be able to reproduce the error. If you are still facing this issue, please provide a colab notebook so we can help troubleshoot.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37571\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37571\">No</a>\n"]}, {"number": 37570, "title": "Load a TF model from memory, not file (C/C++)", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No): Yes, if possible.\r\n- C/C++ interface.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nWe'd like to load model data from memory without file access.\r\n\r\nWe're using TF in a satellite data processing system. One of the requirements dictates that file access is not allowed, we can only load from memory. Of course the model is stored somewhere, but that is very much outside the parts we can reach from where we run, we can only receive the bytestream of that file in a memory block.\r\n\r\nTo meet this requirement, we privately patched version 1.12.0 of TF. Because we like living on the edge, we're also using the C++ (unstable) interface, so we're tied rather hard to this version at the moment. We realise that implementation of this feature request will require changes to our code, but will also make it a lot easier to move to the current version, especially now that the C interface seems to be stable (although statements in different parts on the site are inconsistent).\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis would be an _addition_ to the current interface. I don't see how the external interfaces would need to change, although internally the file loaders may want to use this new interface. \r\n\r\n**Who will benefit with this feature?**\r\n\r\nBesides us, this may also be useful for the Java interface, as apache interfaces usually don't like files either. \r\n\r\n**Any Other info.**\r\n\r\nNone.", "comments": ["Any update about this feature ?", "This is the first response I received.\r\n\r\nBest,\r\n\r\nMaarten\r\n\r\nThis message is short because it was sent from my iPhone. Everything is well with me otherwise.\r\n\r\nOp 10 aug. 2020 om 11:27 heeft Ibrahim Soliman <notifications@github.com> het volgende geschreven:\r\n\r\n\ufeff\r\n\r\nAny update about this feature ?\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/37570#issuecomment-671252578>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ACDMTHYKK6D2T22AFXIHXNTR764QDANCNFSM4LHAPYZA>.\r\n", "Considering the changes introduced in tensorflow 2.0.0, specially focusing in `SavedModel` format, I don't think google/tensorflow team has any intention to go towards this direction but the opposite one.\r\n\r\nFrom my experience, it is possible to create a model with tensorflow 2.x, save it using the `compat.v1` API - `tf.compat.v1.saved_model.save` - and convert it to a protobuf using the `freeze_model` scripts. Then, you'll be able to load this protobuf into memory while using the existing tensorflow C API to load a model from a protobuf.", "> Considering the changes introduced in tensorflow 2.0.0, specially focusing in `SavedModel` format, I don't think google/tensorflow team has any intention to go towards this direction but the opposite one.\r\n\r\nThis is unfortunate, as EUMETSAT is moving in a direction where direct file access is prohibited. \r\n\r\n> From my experience, it is possible to create a model with tensorflow 2.x, save it using the `compat.v1` API - `tf.compat.v1.saved_model.save` - and convert it to a protobuf using the `freeze_model` scripts. Then, you'll be able to load this protobuf into memory while using the existing tensorflow C API to load a model from a protobuf.\r\n\r\nForgive me, I may be a little dense here. Are you referring to the C API in version 2 here? As in: using the C API may be a way out to using a stock library, using a stable API, and still meet the requirements set by EUMETSAT?", "> Forgive me, I may be a little dense here. Are you referring to the C API in version 2 here? As in: using the C API may be a way out to using a stock library, using a stable API, and still meet the requirements set by EUMETSAT?\r\n\r\nYes, our team managed to do so with the Tensorflow 2.1.0 C API. Concretely, you can find functions as [TF_GraphImportGraphDef](https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/c/c_api.cc#L1804) in order to load a graph from a graph_def (your protobuf).\r\n\r\n", "Thank you, this opens a way out for us.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 37569, "title": "error while converting from custom SSD_mobilenet to TFLITE", "body": "**System information**\r\n- OS Platform : windows 10\r\n- TensorFlow installed from : anazonda tf-14\r\n\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n```\r\n\r\nusing the file : \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/tflite_convert.py\r\n\r\nand command as : python tflite_convert.py --graph_def_file=D:\\models\\research\\object_detection\\ava_tflite\\tflite_graph.pb --output_file=D:\\models\\research\\object_detection\\ava_tflite\\tf_output --output_format=TFLITE --input_arrays=normalized_input_image_tensor --input_shapes=1,600,600,3 --inference_type=FLOAT --output_arrays=\"TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\" --allow_customs_ops=False\r\n\r\n\r\n\r\nERROR OUTPUT: \r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tfgpu14\\Scripts\\toco_from_protos-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tfgpu14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tfgpu14\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tfgpu14\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tfgpu14\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tfgpu14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n", "comments": ["@deep28vish Can you please provide a standalone code to reproduce the error? Thanks!", "@deep28vish Can you please provide a standalone code to reproduce the error? Thanks!", "Closing due to lack of recent activity. Please feel free to reopen when you have requested information. Thanks!"]}, {"number": 37568, "title": "ValueError: Cannot use 'loss/head_conv_0_0' as input to 'Merge_2/MergeSummary' because 'loss/head_conv_0_0' is in a while loop", "body": "I try to create my own neural network with several outputs (it follows that there are several target vectors); these target vectors dynamically change during training and depend on the predictions of the neural network. I wrote about this neural network earlier in #37468.\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution: Debian GNU/Linux 9.11 (stretch)\r\n- TensorFlow version: 2.1.0\r\n\r\nThe program works fine when I run it on CPU. But when running on TPU, it prints an error:\r\n`ValueError: Cannot use 'loss/head_conv_0_0' as input to 'Merge_2/MergeSummary' because 'loss/head_conv_0_0' is in a while loop. See info log for more details.`\r\n\r\nWhat could be the reason of the error?\r\n\r\nHere is the complete code:\r\n```\r\nimport tensorflow.compat.v1 as tf\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Conv2D, Activation, Input, BatchNormalization, Layer\r\nfrom tensorflow.core.protobuf import rewriter_config_pb2\r\nimport numpy as np\r\nimport tensorflow_datasets as tfds\r\n\r\nheight = 5\r\nwidth = 5\r\nuse_tpu = True\r\ntrain_batch_size = 8 * 8 if use_tpu else 1\r\nsteps = 20000\r\nlearning_rate = 1e-4\r\niterations_per_loop = 100\r\nlog_step_count_steps = 100\r\nuse_async_checkpointing = False\r\nif use_async_checkpointing:\r\n    save_checkpoints_steps = None\r\nelse:\r\n    save_checkpoints_steps = max(500, iterations_per_loop)\r\nmodel_dir=\"gs://my_storage/model\"\r\ndata_dir=\"gs://my_storage/datasets\"\r\ntpu = \"grpc://10.3.101.2:8470\"\r\ngcp_project = \"my_project\"\r\ntpu_zone = \"us-central1\"\r\n\r\nif use_tpu:\r\n    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n                                tpu, zone=tpu_zone, project=gcp_project)\r\n    master = tpu_cluster_resolver.get_master()\r\nelse:\r\n    tpu_cluster_resolver = None\r\n    master = None\r\n\r\nclass Conv2d:\r\n    def __init__(self, x, filters, kernel_size, name, strides=(1, 1), padding='same', activation='relu', reuse=True):\r\n        with tf.variable_scope(name, reuse=reuse):\r\n            self.name = name\r\n            self.x = Conv2D(filters, kernel_size, strides=strides, padding=padding, name=name)(x)\r\n            bn_name = name + '_bn'\r\n            self.x = BatchNormalization(scale=False,\r\n                                        name=bn_name)(self.x)\r\n            ac_name = name + '_ac'\r\n            self.x = Activation(activation=activation, name=ac_name)(self.x)\r\n\r\nclass OutputLayer(Layer):\r\n    def __init__(self, name, **kwargs):\r\n        super(OutputLayer, self).__init__(name=name, **kwargs)\r\n\r\n    def call(self, inputs):\r\n        return inputs\r\n\r\ndef make_input_fn(dataset_fn, params):\r\n\r\n    def input_fn(params):\r\n        x_train = dataset_fn()[0][\"train\"]\r\n        batch_size = params[\"batch_size\"]\r\n        y_true = tf.random.uniform(\r\n                    shape=(8*batch_size, 32*32*8,), minval=0.0, maxval=1.0, dtype=tf.dtypes.float32, seed=7777)\r\n\r\n        def preprocess(x, y):\r\n            x = tf.cast(x, tf.float32) * (1. / 255)\r\n            labels_dic = {}\r\n            for h in range(height):\r\n                for w in range(width):\r\n                    labels_dic[\"head_conv_{}_{}\".format(h, w)] = y_true\r\n            return x, labels_dic\r\n\r\n        dataset = (x_train\r\n                    .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n                    .repeat()\r\n                    .shuffle(128, seed=7777, reshuffle_each_iteration=True)\r\n                    .batch(8*batch_size, drop_remainder=True)\r\n                    .prefetch(-1))\r\n        return dataset\r\n\r\n    return input_fn\r\n\r\ndef get_model(features, input_shape, reuse):\r\n    with tf.variable_scope('model', reuse=reuse):\r\n        inputs = Input(shape=input_shape)\r\n        seqs = []\r\n        n_filters = 8\r\n        for h in range(height):\r\n            seq = []\r\n            for w in range(width):\r\n                if seq == []:\r\n                   if h==0 and w==0: \r\n                        seq.append(Conv2d(inputs, n_filters, (3, 3), name=\"conv_{}_{}\".format(h, w), reuse=reuse))\r\n                   else:\r\n                        seq.append(Conv2d(seqs[-1][0].x, n_filters, (3, 3), name=\"conv_{}_{}\".format(h, w), reuse=reuse))\r\n                else:\r\n                    seq.append(Conv2d(seq[-1].x, n_filters, (3, 3), name=\"conv_{}_{}\".format(h, w), reuse=reuse))\r\n            seqs.append(seq)\r\n        tmp = np.array([x for x in [seq for seq in seqs]]).ravel()\r\n        outputs = []\r\n        heads = []\r\n        for x in tmp:\r\n            outputs.append(OutputLayer(name=\"output_\"+x.name)(x.x))\r\n            heads.append(tf.estimator.RegressionHead(label_dimension=32*32*8, name=\"head_\"+x.name))\r\n\r\n        model = Model(inputs=inputs, outputs=outputs)\r\n        head = tf.estimator.MultiHead(heads)\r\n        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n        metrics = ['accuracy']\r\n        model.compile(loss='mean_squared_error',\r\n                          optimizer=opt,\r\n                          metrics=metrics)\r\n        model.summary()\r\n    return model, head\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    batch_size = 8 * params['batch_size']\r\n\r\n    model, head = get_model(features, params['input_shape'], reuse=False)\r\n    logits_train = model(features)\r\n    logits_train_dic = {}\r\n    i = 0\r\n    for h in range(height):\r\n        for w in range(width):\r\n            logits_train[i] = tf.reshape(logits_train[i], (batch_size, 32*32*8,))\r\n            logits_train_dic[\"head_conv_{}_{}\".format(h, w)] = logits_train[i]\r\n            i += 1\r\n    pred_classes = tf.argmax(logits_train, axis=1)\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.tpu.TPUEstimatorSpec(mode, predictions=pred_classes)\r\n\r\n    new_labels = {}\r\n    for key in labels:\r\n        new_labels[key] = labels[key][0]\r\n    loss = 0.0\r\n    for key in logits_train_dic:\r\n        logit_train = logits_train_dic[key]\r\n        loss += tf.square(labels[key]-logit_train)\r\n    loss_op = tf.reduce_mean(loss)\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\r\n    if params['use_tpu']:\r\n        optimizer = tf.tpu.CrossShardOptimizer(optimizer)\r\n    train_op_fn = lambda loss_op: optimizer.minimize(\r\n                                  loss_op,\r\n                                  global_step=tf.train.get_global_step())\r\n                \r\n    estim_specs = head.create_estimator_spec(\r\n                  features={\"x\": features},\r\n                  labels=new_labels,\r\n                  mode=mode,\r\n                  logits=logits_train_dic,\r\n                  train_op_fn=train_op_fn)\r\n    return estim_specs\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\ntf.disable_v2_behavior()\r\n\r\ndataset_fn = lambda: tfds.load(\r\n            name='cifar10',\r\n            with_info=True,\r\n            as_supervised=True,\r\n            try_gcs=True,\r\n            data_dir=data_dir)\r\ninfo = dataset_fn()[1]\r\nn_samples = info.splits['train'].get_proto().statistics.num_examples\r\nn_classes = info.features['label'].num_classes\r\ntrain_shape = info.features['image'].shape\r\ntf.config.set_soft_device_placement(True)\r\n\r\nconfig = tf.estimator.tpu.RunConfig(\r\n              master=master,\r\n              model_dir=model_dir,\r\n              save_checkpoints_steps=save_checkpoints_steps,\r\n              log_step_count_steps=log_step_count_steps,\r\n              session_config=tf.ConfigProto(\r\n                  graph_options=tf.GraphOptions(\r\n                      rewrite_options=rewriter_config_pb2.RewriterConfig(\r\n                          disable_meta_optimizer=True))),\r\n              tpu_config=tf.estimator.tpu.TPUConfig(\r\n                  iterations_per_loop=iterations_per_loop,\r\n                  per_host_input_for_training=tf.estimator.tpu.InputPipelineConfig\r\n                  .PER_HOST_V2))\r\n\r\nparams = {\r\n    'use_tpu': use_tpu,\r\n    'input_shape': train_shape,\r\n    'learning_rate': learning_rate\r\n}\r\n\r\nmodel = tf.estimator.tpu.TPUEstimator(\r\n          model_fn, use_tpu=use_tpu,\r\n          config=config,\r\n          train_batch_size=train_batch_size,\r\n          params=params)\r\nmodel.train(make_input_fn(dataset_fn, params), steps=steps)\r\n```", "comments": ["Was able to reproduce the issue. Please find the Gist [here](https://colab.research.google.com/gist/amahendrakar/77b37716b04a184076e576998f730814/37568-tpu.ipynb). Thanks!", "OK, so how to solve this issue?", "So this error is due to the use of summaries. You have a few options:\r\n1. Disable summaries.\r\n2. Pass summaries through host_call in TPUEstimatorSpec. The function that you specify there will be run on the host CPU.\r\nYou can see examples of this in the github.com/tensorflow/tpu repository.\r\n3. Alternatively we now support running CPU computations in the middle of the TPU computation. You need to set:\r\n`tf.config.set_soft_device_placement(True)`\r\nBut you also need to switch to the new summaries in TF2 instead of the compat.v1 version.", "Thank you! I solved the problem by replacing\r\n```\r\nestim_specs = head.create_estimator_spec(\r\n                  features={\"x\": features},\r\n                  labels=new_labels,\r\n                  mode=mode,\r\n                  logits=logits_train_dic,\r\n                  train_op_fn=train_op_fn)\r\n```\r\nto\r\n```\r\nestim_specs = tf.estimator.tpu.TPUEstimatorSpec(\r\n                  mode=mode, loss=loss_op, train_op=train_op_fn(loss_op))\r\n```\r\nAnd I also had to implement a neural network using `tensorflow.nn`, since using `Keras` on TPU the program did not work. With `tensorflow.nn`, a neural network is trained.\r\n\r\nTo display scalars (loss, learning rate, etc.) in TensorBoard, I added, as you advised, `host_call` in `TPUEstimatorSpec` from the example.\r\n\r\nEverything works great!", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37568\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37568\">No</a>\n"]}, {"number": 37566, "title": "Do not densify sparse gradients in LossScaleOptimizer", "body": "The method `get_unscaled_gradients` is currently converting sparse gradients to dense gradients. We can avoid this implicit conversion to save on memory.", "comments": ["Thanks for the PR!"]}, {"number": 37565, "title": "Added code for preprocessing of YUV images before feeding yuv_to_rgb", "body": "Fixes [#37067](https://github.com/tensorflow/tensorflow/issues/37067).\r\n@lamberta , @mihaimaruseac - Please review this PR.", "comments": ["Though it would be great if we can also make the example code be a doctest", "Replaced yub with yuv everywhere and trying to merge from internal to external", "I believe that both the implementation and documentation for the YUV conversions are incorrect.\r\n\r\n1. The YUV specification comes from https://en.wikipedia.org/wiki/Rec._601 and sets a range of:\r\n\r\ny: [0,1]\r\nu: -0.436 to + 0.436\r\nv: -0.615 to + 0.615\r\n\r\nThe kernels in the TF source allow the U value to go beyond the specified range:\r\n\r\ny: [0,1]\r\nu: -0.43601035 to + 0.43601035\r\nv: -0.61497538 to + 0.61497538\r\n\r\n2. The documentation has confused people on stack exchange by saying U and V need to be in the range [-0.5, 0.5]. I don't believe this documentation is accurate. \r\n\r\n3. The YUV/RGB conversion listed is for a linear RGB. Almost any image a TF developer would deal with will have sRGB gamma correction. The comparable standard for gamma corrected sRGB is YCbCr. That standard appears to be designed to support 24 bit color (8 bits per channel [0,255]). \r\n\r\nA reasonable approach might be to deprecate the YUV conversions in favor of YCbCr.\r\n\r\nhttps://web.archive.org/web/20180423091842/http://www.equasys.de/colorconversion.html\r\n", "Thanks, @yaoshiang-masterfulai \r\nCan you please file a separate issue since your comment touches on the docs and the implementation? ", "Could you point me to documentation on how to file issues and contribute? ", "Probably this is a good starting point https://help.github.com/en/github/collaborating-with-issues-and-pull-requests Since this is not something specific to TF, google can provide more links", "@yaoshiang-masterfulai The TF contributor guide is here: https://www.tensorflow.org/community/contribute\r\nAnd the docs live in the [tensorflow/docs](https://github.com/tensorflow/docs) repo. Thanks"]}, {"number": 37562, "title": "Successful installation message but still not able to import tensorflow", "body": "<em>Traceback (most recent call last):\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-616800c633ce>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Praveen.prakash\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.</em>", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@praveenprakashupadhyay,\r\nCould you please check [this](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) comment on a similar issue and let us know if it helps. Thanks!", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37562\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37562\">No</a>\n"]}, {"number": 37561, "title": "When using MirroredStrategy, the training process is stuck", "body": "**System information** \r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: 2x1080 Ti\r\n- Tensorflow version: 2.2.0\r\n\r\n**Describe the current behavior**\r\nI built a CRNN model for recognize the text, a CNN-RNN-CTC model, it work well without tf.distribute.Strategy, but when I follow the guide to move the creation and compiling of Keras model inside strategy.scope, It does not start distributed training like the guide. here is the output:\r\n```\r\n2020-03-13 06:19:04.839700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-03-13 06:19:04.874256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-03-13 06:19:04.875077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-03-13 06:19:04.875273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-03-13 06:19:04.876811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-03-13 06:19:04.878155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-03-13 06:19:04.878383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-03-13 06:19:04.879998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-03-13 06:19:04.881014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-03-13 06:19:04.884664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-03-13 06:19:04.887439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\r\n2020-03-13 06:19:04.887722: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-03-13 06:19:04.892905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3598110000 Hz\r\n2020-03-13 06:19:04.893743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1224000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-03-13 06:19:04.893784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-03-13 06:19:05.147750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59b91e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-03-13 06:19:05.147778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2020-03-13 06:19:05.147788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2020-03-13 06:19:05.150073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-03-13 06:19:05.150888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-03-13 06:19:05.150926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-03-13 06:19:05.150943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-03-13 06:19:05.150958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-03-13 06:19:05.150972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-03-13 06:19:05.150986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-03-13 06:19:05.151000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-03-13 06:19:05.151015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-03-13 06:19:05.154118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\r\n2020-03-13 06:19:05.154160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-03-13 06:19:05.156174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-03-13 06:19:05.156195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 \r\n2020-03-13 06:19:05.156206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y \r\n2020-03-13 06:19:05.156214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N \r\n2020-03-13 06:19:05.158304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9569 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-03-13 06:19:05.159295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10369 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nEpoch 1/5\r\n```\r\nThe training process seems to be interrupted without any output, but the program runs out of graphics card memory and the program does not exit.\r\n\r\n**Describe the expected behavior**\r\nStart training just like without distributed strategy.\r\n\r\n**Standalone code to reproduce the issue** \r\nThe full code can be view [here](https://github.com/FLming/CRNN.tf2)\r\n", "comments": ["Could you try tf.experimental.output_all_intermediates(True)?\r\n\r\nIt would be also easier if you can provide a smaller reproduction.", "The code is available in [CRNN.tf2](https://github.com/FLming/CRNN.tf2), To reproduce this error, clone it, add MirroredStrategy to train.py, then run it with example data by:\r\n```bash\r\npython train.py -ta example/annotation.txt -tf example -va example/annotation.txt -vf example -t example/table.txt\r\n```\r\nThe training process will stuck in first epoch.\r\n```\r\n...\r\nEpoch 1/30\r\n```\r\nI tried adding drop_remainder=True to Dataset.batch function, still stuck.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37561\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37561\">No</a>\n", "This problem still exists, I can't find a way to solve it. There are no errors, and the GPU is not calculating, but it takes up GPU memory.", "@FLming Can you please try adding `steps_per_epoch` and `validation_steps` to `model.fit` and then test whether the error persists or not? Thanks!", "I set `steps_per_epoch` to `number of training samples // batch size` and `validation_steps` to `number of val samples // batch size`, the problem still exists.", "One more thing, although it\u2019s a digression. Once I used DepthwiseConv2D to build the model, the same thing happened, there was no progress bar, no error, and the output was only \r\n```\r\n...\r\nEpoch 1/x\r\n```\r\nBy chance I switched the program from GPU to CPU, the error raised, that said `current implementation only supports equal length strides in the row and column dimensions`. Follow this tip, the program worked on GPU.\r\nWill tensorflow lose some output prompts when running on the GPU?", "@FLming Code that is running on CPU and GPU are similar but they are little different from implementation side so that the GPU accelerators are optimally used.  \r\n\r\nIf this is resolved for you, then please close the issue. Thanks! ", "@jvishnuvardhan No, the problem still exists. The above is another problem that `DepthwiseConv2D` is't support different stride setting, and on GPU, the prompt doesn't appear.", "Things have progressed. \r\n1. I removed custom `Metric` class in model.fit, the distributed training works normally, but why? \r\n2. Compile with custom metric class, set validation_data to None, still stuck.\r\n\r\nHere is the definition, this class will compare two sparse tensors and calculate how many equal rows\r\n```\r\nclass WordAccuracy(keras.metrics.Metric):\r\n    \"\"\"\r\n    Calculate the word accuracy between y_true and y_pred.\r\n    \"\"\"\r\n    def __init__(self, name='word_accuracy', **kwargs):\r\n        super().__init__(name=name, **kwargs)\r\n        self.total = self.add_weight(name='total', dtype=tf.int32, \r\n                                     initializer=tf.zeros_initializer())\r\n        self.count = self.add_weight(name='count', dtype=tf.int32, \r\n                                     initializer=tf.zeros_initializer())\r\n                \r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        \"\"\"\r\n        Maybe have more fast implementation.\r\n        \"\"\"\r\n        b = tf.shape(y_true)[0]\r\n        max_width = tf.maximum(tf.shape(y_true)[1], tf.shape(y_pred)[1])\r\n        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])        \r\n        decoded, _ = tf.nn.ctc_greedy_decoder(\r\n            inputs=tf.transpose(y_pred, perm=[1, 0, 2]),\r\n            sequence_length=logit_length)\r\n        y_true = tf.sparse.reset_shape(y_true, [b, max_width])\r\n        y_pred = tf.sparse.reset_shape(decoded[0], [b, max_width])\r\n        y_true = tf.sparse.to_dense(y_true, default_value=-1)\r\n        y_pred = tf.sparse.to_dense(y_pred, default_value=-1)\r\n        y_true = tf.cast(y_true, tf.int32)\r\n        y_pred = tf.cast(y_pred, tf.int32)\r\n        values = tf.math.reduce_any(tf.math.not_equal(y_true, y_pred), axis=1)\r\n        values = tf.cast(values, tf.int32)\r\n        values = tf.reduce_sum(values)\r\n        self.total.assign_add(b)\r\n        self.count.assign_add(b - values)\r\n\r\n    def result(self):\r\n        return self.count / self.total\r\n\r\n    def reset_states(self):\r\n        self.count.assign(0)\r\n        self.total.assign(0)\r\n```", "I found the reason, that is because I use dtype=tf.int32 in self.add_weight function.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37561\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37561\">No</a>\n", "> I found the reason, that is because I use dtype=tf.int32 in self.add_weight function.\r\n@FLming can you please share your experience how you found the root cause?", "Comment and run, step by step, narrow the scope.\n\n> \u5728 2020\u5e7410\u67088\u65e5\uff0c\u4e0b\u53485:48\uff0cBoggis30 <notifications@github.com> \u5199\u9053\uff1a\n> \n> \ufeff\n> I found the reason, that is because I use dtype=tf.int32 in self.add_weight function.\n> @FLming can you please share your experience how you found the root cause?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or unsubscribe.\n", "Just a little sharing about this incident. Most of the problem take place by the loss and metric after running a step.\r\nMake sure custom loss match this requirement for 2.x version:\r\n`If using tf.keras.losses classes (as in the example below), the loss reduction needs to be explicitly specified to be one of NONE or SUM. AUTO and SUM_OVER_BATCH_SIZE are disallowed when used with tf.distribute.Strategy. AUTO is disallowed because the user should explicitly think about what reduction they want to make sure it is correct in the distributed case. SUM_OVER_BATCH_SIZE is disallowed because currently it would only divide by per replica batch size, and leave the dividing by number of replicas to the user, which might be easy to miss. So instead we ask the user do the reduction themselves explicitly.`"]}, {"number": 37560, "title": "[tensorrt] add missing dependency to make it build", "body": "resolve https://github.com/tensorflow/tensorflow/issues/37523", "comments": []}, {"number": 37559, "title": "TF_FORCE_GPU_ALLOW_GROWTH=false Triggers cuDNN Error", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No, using tutorial classification example**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Manjaro (kernel 5.4.18)**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): **conda binary**\r\n- TensorFlow version (use command below): **2.1.0**\r\n- Python version: **3.7.6**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: **CUDA 10.1 / cuDNN 7.6.5**\r\n- GPU model and memory: **RTX 2070, 8GB**\r\n\r\n**Describe the current behavior**\r\n\r\nClassification fail to train if `TF_FORCE_GPU_ALLOW_GROWTH` not set to true. It raises: \r\n\r\n`tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`\r\n\r\nI suspect cuDNN is asking for more memory after Tensorflow has already allocated all available memory. An easy but hacky fix is to set `TF_FORCE_GPU_ALLOW_GROWTH` to true by default and asking users to set it to false when they need max performance. It makes sense to ensure that the model would always run rather than ensuring that it would run with max efficiency. However, we should address this issue from the core. \r\n\r\n**Describe the expected behavior**\r\n\r\nModel would train like when `TF_FORCE_GPU_ALLOW_GROWTH` is set to true. \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nRun classification.ipynb on [the tutorial](https://www.tensorflow.org/tutorials/images/classification) without setting `TF_FORCE_GPU_ALLOW_GROWTH`. \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\n[error_log.txt](https://github.com/tensorflow/tensorflow/files/4328031/log.txt)\r\n", "comments": ["Both of these issues are fundamentally caused by this bug, and the comments I quoted are setting allow_growth to solve it:\r\nhttps://github.com/tensorflow/tensorflow/issues/9489#issuecomment-562394257\r\nhttps://github.com/tensorflow/tensorflow/issues/24496#issuecomment-598145988\r\n\r\nWe can mark those issues as duplicates and focus on this issue. ", "@6etacat \r\nCould you please share the tensorflow version in which the error is faced.", "@Saduf2019 Updated. ", "Does setting the env var `TF_DEVICE_MIN_SYS_MEMORY_IN_MB` to to a high value (say 1000) fix the issue?  If yes, can you try finding the smallest value for this env var that works?  Once you have that figure, we can incorporate it into TensorFlow.\r\n\r\nCC @nluehr ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37559\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37559\">No</a>\n"]}, {"number": 37558, "title": "change tf.image.decode_image to tf.io.decode_image", "body": "tf.image.decode_image to tf.io.decode_image for API migration and consistency which include decode_ jpeg, decode_gif, and decode_png.\r\nPlease see https://www.tensorflow.org/api_docs/python/tf/io/decode_image", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/37558\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n You'll be able to see Jupyter notebook diff and discuss changes. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.", "Afaik, `tf.io.decode_image` is currently just an alias for `tf.image.decode_image`. But since the later might get removed in the future, it's ok to replace usage with the more consistent alias.", "Oh...Sorry, I accidentally dismissed mihaimaruseac's review approval and added four more commits to this PR during the experiment with vscode pull request extension. Any way I can withdraw these four changes...", "`git rebase` and then `git push -f`. But it seems copybara merged some of the PR, so closing this and let's create another one to fix", "@mihaimaruseac Thank you. I will create another one later."]}, {"number": 37557, "title": "tf.image.decode_image to tf.io.decode_image", "body": "tf.image.decode_image to tf.io.decode_image for API migration and consistency.", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/37557\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n You'll be able to see Jupyter notebook diff and discuss changes. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.", "Will send a combined PR"]}, {"number": 37556, "title": "TF 2 equivalent for report_tensor_allocations_upon_oom", "body": "What is the TensorFlow 2 equivalent for `report_tensor_allocations_upon_oom` discribed here: https://github.com/tensorflow/tensorflow/issues/17076\r\n\r\nHow would I use this in eager mode with keras?", "comments": ["This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "@sarthfrey-db Did you ever figure out a solution for this? I searched stack overflow and it's just too noisy with lots of random copy-paste output for `report_tensor_allocations_upon_oom` and nothing relevant I can find for tf2/keras.", "+xiangrui since Sarth is done with the internship\n\nOn Fri, Aug 14, 2020, 8:44 PM Mike Martin <notifications@github.com> wrote:\n\n> @sarthfrey-db <https://github.com/sarthfrey-db> Did you ever figure out a\n> solution for this? I searched stack overflow and it's just too noisy with\n> lots of random copy-paste output for report_tensor_allocations_upon_oom\n> and nothing relevant I can find for tf2/keras.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37556#issuecomment-674342990>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AOG3KVBU4D3MVD6W3QJBNRDSAYAARANCNFSM4LGYDALA>\n> .\n>\n", "@ravikyram this should definitely be a feature request. this setting used to be configured as part of session.run but with the switch to eager, keras does not expose the session run arguments anymore.", "Fwiw I've put this up as [a question on SO](https://stackoverflow.com/q/64197155/39590)", "If anyone cares for it, the mentioned question currently has a bounty on it, thanks to a kind person. The bounty expires in 3 days time. Still hoping for an answer :)", "Can we re-open this? This hasn't been solved."]}, {"number": 37555, "title": "Running CI tests locally for Python 3 files", "body": "**System information**\r\n- Platform: Ubuntu 18.04 on WSL2 \r\n- TensorFlow version: source master@f8396d00c2572845774cce4b737858f264e015b6\r\n- Bazel version (if compiling from source): running CPU Docker container, says 2.0\r\n\r\n\r\n\r\n**Describe the problem**\r\nI'm trying to run CI tests locally. I'm having Python 2/3 issues. I'm using `tensorflow/tensorflow/python/autograph/pyct/static_analysis/` for testing since it has tests (ex `liveness_py3_test.py`) that use Python 3 syntax and have a properly configured `BUILD`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\ntensorflow/tools/ci_build/ci_build.sh CPU bazel test --jobs=1 --ram_utilization_factor 30 -- //tensorflow/python/autograph/pyct/static_analysis/... \r\n```\r\n```\r\nFile \"tensorflow/bazel-ci_build-cache/.../tensorflow/python/autograph/pyct/static_analysis/liveness_py3_test.runfiles/org_tensorflow/tensorflow/python/autograph/pyct/static_analysis/liveness_py3_test.py\", line 39                                                                                     \r\n\r\nnonlocal nonlocal_a                                                                                                                                                                                                             \r\n                  ^                                                                                                                                                                                       \r\n\r\nSyntaxError: invalid syntax \r\n```\r\n\r\n\r\n**Any other info / logs**\r\n```\r\nTF_BUILD_INFO = {container_type: \"cpu\", command: \"bazel test --jobs=1 --ram_utilization_factor 30 -- //tensorflow/python/autograph/pyct/static_analysis/...\", source_HEAD: \"f8396d00c2572845774cce4b737858f264e015b6\", source_remote_origin: \"https://github.com/adriangb/tensorflow.git\", OS: \"Linux\", kernel: \"4.19.84-microsoft-standard\", architecture: \"x86_64\", Bazel_version: \"Build label: 2.0.0\", Java_version: \"1.8.0_242\", Python_version: \"2.7.12\", gpp_version: \"g++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\"}\r\n```\r\n\r\nIt seems to me that running CI tests via Docker as per [`CONTRIBUTING.md`](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md) is not choosing the Python version correctly. Looking at CI logs, there are other flags being passed such as `--python_path=/usr/bin/python3`.\r\n\r\nI'm not sure if this is a bug or `CONTRIBUTING.md` has not been updated for Python 3 transition. If the latter, what invocation options are necessary to get local CI via Docker to behave as the online CI does?", "comments": ["So we no longer use ci_build.sh for presubmits. We use the [following scripts](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build/presubmit) on a Docker container created by [this GPU dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/Dockerfile.rbe.cuda10.1-cudnn7-ubuntu16.04-manylinux2010).  [This file](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md) is outdated. Sorry about that. We will update it soon.", "Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37555\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37555\">No</a>\n"]}]