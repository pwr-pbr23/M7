[{"number": 22709, "title": "[Cloud TPU] `dot` with non-standard layout operands produces incorrect output", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.11\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nWe are seeing incorrect answers from VGG19 from Cloud TPUs using the Julia frontend (VGG19 source here: https://github.com/FluxML/Metalhead.jl/blob/master/src/vgg19.jl). The Julia frontend generates XLA and submits it to the Cloud TPU using xrt. Reducing the test case, we find that there seems to be a problem with the `dot` operation when operating on arrays of non-standard data layout (julia is column major by default so tends to encounter this more, although the Julia->XLA compiler pass heuristically changes the layout of inputs/outputs when targeting TPUs to avoid padding if profitable). Example output showing the problem:\r\n\r\n```\r\njulia> W\u2032\u2032 = XRTArray(sess, W\u2032)\r\n10\u00d710 XRTArray{Float32,(10, 10),2}:\r\n  0.0117621   -0.0111235    0.0105805   -0.00403011   -0.00355716  -0.00718089  -0.0134884    -0.00459831    0.0197616    -0.00417151\r\n -0.00695795  -0.00393374   0.0090458   -0.00566363    0.0121302    0.00420088  -0.00750095    0.000967382   0.0220296     0.00428639\r\n -0.00687687  -0.00229628  -0.007712    -0.00997357   -0.00680831   0.00262956   0.000473469  -0.00876678   -0.011446     -0.00720634\r\n  0.00530032   0.00782367  -0.00427682   0.00691867   -0.00343559   0.00912634  -0.0111816    -0.00729117    0.00522226   -0.00822838\r\n -0.00600947  -0.00683288  -0.0122932    0.000471149  -0.00142788   0.0201943    0.000141306   0.0052818     0.00387177   -0.00254829\r\n  0.00345886   0.0106005   -3.07181e-5   0.0217212     0.00135223  -0.00411474   0.00345068   -0.00515104    0.00140949   -0.0132586\r\n -0.00233608  -0.0117845   -0.00938103   0.0190475    -0.00731929  -0.00104086  -0.0144478     0.00959422    0.00774611   -0.00810476\r\n -0.00620138  -0.00673539  -0.00782188   0.00821768    0.00439068   0.00334791  -0.00190924   -0.00682392   -0.00805664    0.0150204\r\n -0.00116647  -0.00305227   0.00475127   9.85245e-7    0.0024828    0.013036     0.00340338   -0.00387893    0.000677002   0.00680005\r\n -0.00499851   0.0115887   -0.00762315   0.0148181     0.0112692    0.00543651   0.0137934    -0.00666574    0.00736139    0.00202298\r\n\r\njulia> x\u2032\u2032 = XRTArray(sess, x\u2032)\r\n10\u00d71 XRTArray{Float32,(10, 1),2}:\r\n 0.0\r\n 6.706906\r\n 0.0\r\n 0.0\r\n 2.0117874\r\n 0.0\r\n 0.0\r\n 0.0\r\n 0.0\r\n 0.0\r\n\r\njulia> W\u2032\u2032 * x\u2032\u2032\r\n10\u00d71 XRTArray{Float32,(10, 1),2}:\r\n -0.081760176\r\n  0.0\r\n  0.0\r\n  0.0\r\n  0.0\r\n  0.0\r\n  0.0\r\n  0.0\r\n  0.0\r\n  0.0\r\n```\r\n\r\nThe first value is correct, the rest of them are not (however I do believe I've seen cases where the first value was incorrect but non-zero also) - for python folks remember that `*` is matrix multiply in Julia. Dumping the XLA generated during the above session, we get:\r\n\r\n```\r\nENTRY comp {\r\n  comp0_parameter0 = f32[10,10]{0,1} parameter(0)\r\n  comp0_parameter1 = f32[10,1]{0,1} parameter(1)\r\n  ROOT comp0_dot3 = f32[10,1]{0,1} dot(comp0_parameter0, comp0_parameter1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\r\n}\r\n```\r\n\r\nNotice in particular the layout being `{0,1}` rather than the standard `{1,0}`. If I change the above mentioned layout heuristic to prefer the XLA standard layout, the issue disappears. The issue also disappears if the RHS is a plain vector, i.e. `f32[10]{0}` rather than `f32[10,1]{0,1}`. Further note that this issue was reduced from a case where the `dot` was not the final operation, but the zeros it generated nonetheless propagated. To me that would indicate that the output values are being written to the wrong place by the `dot` operation (as opposed to being a problem with the way that xrt retrieves the data from the device for example).\r\n\r\n@michaelisard remarked that this sounded like a padding issue.\r\ncc @eliben ", "comments": ["@Keno I encountered a similar issue recently. Do you relayout the XLA result to the default layout? Doing it fixed the problem for me: https://github.com/tensorflow/tensorflow/blob/8ac087482f7224273fb6697a66191b2661e86477/tensorflow/compiler/xla/literal.h#L260", "Yes, as I mentioned, things work fine with the standard layout. However, we are using non-standard layout for memory efficiency to avoid excessive padding on the TPU, so changing all layout is not feasible.", "However, if you have an internal reproducer already, maybe you can share that with @meheffernan and @michaelisard who were planning to look into this.", "This is now verified fixed at the current version though not pushed to a public release yet, so closing."]}, {"number": 22708, "title": "1.12-0 cherry-pick request: Fix MacOS builds.", "body": "PiperOrigin-RevId: 215653797", "comments": []}, {"number": 22707, "title": "1.12-rc0 cherry-pick request: Reduce batch sizes for some eager tests to prevert OOMs in OSS runs", "body": "PiperOrigin-RevId: 215651413", "comments": []}, {"number": 22706, "title": "CUDA 10", "body": "**Edited:** 17-DEC-2018 Nightly builds are CUDA 10\r\n**Edited:** 27-NOV-2018 Added 1.12 FINAL builds.\r\n**Edited:** 29-OCT-2018 Added 1.12 RC2 builds.\r\n**Edited:** 17-OCT-2018 Added 1.12 RC1 builds.\r\n\r\n\r\n## **Nightly Builds are now CUDA 10 as of 16-DEC-2018**\r\n\r\n\r\n\r\n- [**DONE**] CUDA 10 in the nightly builds mid-DEC 2018 if testing goes well\r\n- CUDA 10 in official in mid-JAN-2019 as TF 1.13.\r\n\r\n[Install instructions for CUDA 10](https://github.com/tensorflow/docs/pull/249) for a fresh system that should also work on an existing system if using `apt-get`.\r\n\r\nTensorFlow will be upgrading to `CUDA 10` as soon as possible.  As of TF 1.11 building TensorFlow from source works just fine with `CUDA 10` and possibly even before.  There is nothing special needed other than all of the `CUDA`, `cuDNN`, `NCCL` (optional), and `TensorRT` (optional) libraries.  If people have some builds feel free to link them here (Keep in mind if you download them to decided what risk you want to take based on the source.) as well as any issues.  Also` NCCL` is now open source again and soon will be back to being automatically downloaded by `bazel` and included in the binary.\r\n\r\n`CUDA 10` would likely go into TF 1.13, which is not scheduled.  I will update this post as I have more info to share.  I hope to flip nightly builds to CUDA 10 in November but the TF 1.13 release will likely push to early Jan.\r\n\r\nI and some really cool people below made some binaries (even windows, see comments below) to help people out along with my really [bad \"instructions\"](https://github.com/tfboyd/tf-tools/blob/master/install/cuda_10.md).  I suspect the instructions linked in the comments below are better.\r\n\r\nLibraries used (rough list, similar to what I listed above)\r\n  * Ubuntu 16.04 LTS on GCE from base Google Cloud Ubuntu image.\r\n  * Python 2.7 because that is how I roll and someday I will change.\r\n  * Install 410+ driver using apt-get\r\n  * CUDA 10.0.130 from .tgz install (do not install the driver)\r\n  * cuDNN-10.0 v7.3.0.29 rom tgz install\r\n  * nccl 2.3.4 for CUDA 10 (I am not sure it matters I have mixed them up before)\r\n  * TensorRT-5.0.0 for CUDA 10 cudnn 7.3 (TensorRT 5 was not stated as supported by Tensorflow when \r\n  * Compute Capability: 3.7,5.2,6.0,6.1,7.0 \r\n\r\n_**TF 1.12.0 FINAL**_\r\n\r\n**Python 2.7 (Ubuntu 16.04)**\r\n   * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0.a6d8ffa.AVX2.CUDA10-cp27-cp27mu-linux_x86_64.whl)\r\n\r\n**Python 3.5 (Ubuntu 16.04)**\r\n   * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0.a6d8ffa.AVX2.CUDA10-cp35-cp35m-linux_x86_64.whl)\r\n\r\n**Dockerfiles**\r\nThese are partial files and the apt-get commands should work on non-Docker systems as well assuming you have the NVIDIA apt-get repositories which should be the same as listed on [tf.org](https://www.tensorflow.org/install/gpu).\r\n   * [Devel](https://github.com/tfboyd/tensorflow/blob/cuda_10_dockerfile/tensorflow/tools/dockerfiles/partials/nvidia-devel.partial.Dockerfile)  Confirmed by building TensorFlow at 1.12RC0.\r\n  * [Runtime](https://github.com/tfboyd/tensorflow/blob/cuda_10_dockerfile/tensorflow/tools/dockerfiles/partials/nvidia.partial.Dockerfile)\r\n", "comments": ["I've built tf 1.12.0rc0 with all the latest, test well except this silly warning\r\n\r\n*** WARNING *** You are using ptxas 10.0.145, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\r\n\r\nYou do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.\r\n\r\nseems no problem for now\r\n\r\n\r\nonly thing left is python 3.7, which I haven't tried yet", "Could we expect CUDA10+python3.7 prebuilt images from 1.13rc0?", "@alanpurple   Ahh I had not tried CUDA 10 with XLA yet, it is now compiled in by default.  Great feedback I will pass the warning on to the team (b/117268529), looks like they might have a slight error in their version checker.  As far as Python versions that is not under my authority (even a little).  @gunan owns that part of the matrix.", "@tfboyd Hey could you kindly share the .whl of tensorflow 1.11 with,\r\n\r\n    CUDA 10.0.130_410.48\r\n    cuDNN 7.3.0.29 for CUDA 10\r\n    I was not able to build the same. I have a rtx 2080 with ubuntu 16.04. Thanks in advance\r\n", "**Updated 10-15-2018:** Moved my builds into the original comment to make the thread shorter. \r\n\r\n**Updated 10-10-2018:**  Build is under way. For python 2.7 and compute 3.7,5.2,6.0,6.1,7.0  (normally only do 6.0 and 7.0 so I tried to think about what all of you might want)", "Just wrote [instruction](https://medium.com/@vitali.usau/install-cuda-10-0-cudnn-7-3-and-build-tensorflow-gpu-from-source-on-ubuntu-18-04-3daf720b83fe) how to build TF from scratch. Maybe somebody found it useful\r\n", "Here is my new tutorial for Building Tensorflow 1.12 + CUDA 10.0 + CUDNN 7.3.1 + NCCL 2.3.5 + bazel-0.17.2 https://www.python36.com/how-to-install-tensorflow-gpu-with-cuda-10-0-for-python-on-ubuntu/, you will also get prebuilt wheel at last.", "Thanks @arunmandal53 for taking the time to write the tutorial. However, I need to install Tensorflow in the Python installation that is under my home account rather than  installing Tensorflow on Python that comes with Ubuntu. I think that I need to wait until Tensorflow releases a version that can be installed using pip and is compatible with CUDA 10 (and cuDNN)", "[Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + NCCL 2.3.5 + python 3.6 +Ubuntu](https://drive.google.com/file/d/1QV7fBi5ZpTm02N1_QbyEhT6v80B6Zffg/view?usp=sharing)", "@ivan-marroquin  Incase you did not know you can install any .whl file anywhere you want.  You can use the .whl packages I created or the ones @arunmandal53  has done which covers Python 3.6.  Pretty nice selectoin :-).  I might also not understand you issue but you can do this:\r\n\r\n`pip install http://path to whatever you want`\r\nor\r\n`pip install /local/path/to/whl`\r\n\r\nYou do not have to count on pypi and --user would also work and installing in a virtual env.\r\n", "@tfboyd thanks for the clarification. And thanks to all of you for a such impressive help! i will give a try as soon as possible\r\n", "@everyone thanks for spilling all the bits and bytes. I have built the TF with all my requirements and successfully running the tests for 5days now :)", "[Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + python 3.6 + Windows](https://drive.google.com/open?id=1jnxaTTrxyfMvEExhEiraSZI7urUwr_tR)", "Here is my new tutorial  on building Tensorflow 1.12 + CUDA 10.0 + CUDNN 7.3.1 + + Bazel 0.17.2 on Windows. https://www.python36.com/how-to-install-tensorflow-gpu-with-cuda-10-0-for-python-on-windows/ . ", "> [Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + NCCL 2.3.5 + python 3.6 +Ubuntu](https://drive.google.com/file/d/1QV7fBi5ZpTm02N1_QbyEhT6v80B6Zffg/view?usp=sharing)\r\n\r\n@arunmandal53 \r\ndo you have tensorflow whl for windows 10?\r\nthanks\r\n\r\nWhen i install the cuda 10 and tensorflow-gpu 1.11.0 with rtx 2080, it went to the error \"ImportError: DLL load failed:\" \r\nI tryied to use cuda 9.2 with unoffical tensorflow-gpu whl and it successed! \r\nBut it failed with cuda 10, so i wonder if anyone has a compiled tensorflow-gpu whl \uff1f\r\nThanks\r\n\r\ncuda 10.0\r\ncudnn 7.3.1\r\ntensorflow-gpu 1.11.0\r\nrtx 2080\r\n![image](https://user-images.githubusercontent.com/20239172/47078616-43a8c100-d236-11e8-85dc-e0036876f903.png)\r\n", "You will find whl links above.", "Detailed tutorial just in case :)\r\n\r\nhttps://medium.com/@saitejadommeti/building-tensorflow-gpu-from-source-for-rtx-2080-96fed102fcca", "Ubuntu 18.04 - CUDA 10.0 - libcudnn 7.3.1 + Python 3.6\r\nI have tried the various wheel packages but it coredumps. :(\r\n\r\nI'm trying bazel now, but it's pain in the ass... just to have the last version of cuda. :(\r\n\r\n**EDIT:**\r\nI have built it nicely by following these steps \ud83d\udc4d \r\nhttps://www.python36.com/how-to-install-tensorflow-gpu-with-cuda-10-0-for-python-on-ubuntu/\r\n\r\nThere was a problem in bazel and to build tf I needed to put the --batch option\r\n`bazel --batch build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`", "Here is a windows build tensorflow 1.12.0, CUDA 10, cuDNN 7.3.1, RTX2080TI (feature level 7.5).\r\n[tensorflow-1.12.0-cp36-cp36m-win_amd64.whl](https://app.box.com/s/joflprv5unbtqy2a972iyvtdovdsbovw)\r\none above in the comment I'm not sure what the CUDA feature level is, so I build a new one.", "are nightlies cuda 10 at the moment?\r\n\r\nedit: nope.", "Here is a ubuntu 18.10 build (kernal 4.18), tensorflow r1.12 branch, python 3.6, CUDA 10.0, cuDNN 7.4.1.5, NCCL 2.3.7, tensorRT 5.0, compute capability 7.5, 6.1, for my RTX 2080 TI.\r\n[tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl](https://app.box.com/s/jcw8uq6jannpg4myzighl166bq1zg07e)\r\n", "@lahwran  We are in the process of making the nightly builds CUDA 10.  Some may have flipped already.  I will update over the next few days in this comment and the original post at the top.  \r\n\r\nMy current ETA is end of November to move all nightlies to CUDA 10.  There was a short informal meeting this morning.  We are also working on a \"bleeding-edge\"(need a better name) pip build that will move a lot faster for GPU upgrades but will likely just be linux only and Python 3.6 or 3.7 (which I believe I have seen people working on).  \r\n", "> [Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + NCCL 2.3.5 + python 3.6 +Ubuntu](https://drive.google.com/file/d/1QV7fBi5ZpTm02N1_QbyEhT6v80B6Zffg/view?usp=sharing)\r\n\r\nwas of great help and worked", "Hi,\r\n\r\nCould you publish the compile options and compiler version you used? I tried to compile the tensorflow myself, but found that the training throughput is slower that what you provide? I'm trying to figure out what's the difference?\r\n\r\nThanks", "Hey,\r\nlook at my link. I created an project. Download the file! It works fine!\r\n\r\nhttps://github.com/Lxnus/tensorflow_r1.12_cuda_10", "Took my 15 days to followup, sorry.  This is the timeline I am seeing right now:\r\n\r\n- CUDA 10 in the nightly builds mid-DEC if testing goes well\r\n- CUDA 10 in official in mid-JAN due to the holiday break I would guess TF 1.13 (1.12 is out already)\r\n\r\nI am adding this to the original post above as well.\r\n", "> Took my 15 days to followup, sorry. This is the timeline I am seeing right now:\r\n> \r\n> * CUDA 10 in the nightly builds mid-DEC if testing goes well\r\n> * CUDA 10 in official in mid-JAN due to the holiday break I would guess TF 1.13 (1.12 is out already)\r\n> \r\n> I am adding this to the original post above as well.\r\n\r\nHope everything goes well and TF 1.13 supporting CUDA 10 appears as soon as possible. Because of the version issue, I can't install TensoFlow on my computer.", "> [Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + NCCL 2.3.5 + python 3.6 +Ubuntu](https://drive.google.com/file/d/1QV7fBi5ZpTm02N1_QbyEhT6v80B6Zffg/view?usp=sharing)\r\n\r\nHi Arun @arunmandal53 \r\n\r\nI tried to install the .whl you provided, but encountered a problem like this:\r\n\r\n Ignoring visible gpu device (device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5) with Cuda compute capability 3.5. The minimum required Cuda capability is 5.0.\r\n\r\nI understand my GPU is too old, but is there any method to solve this problem?", "> Here is a ubuntu 18.10 build (kernal 4.18), tensorflow r1.12 branch, python 3.6, CUDA 10.0, cuDNN 7.4.1.5, NCCL 2.3.7, tensorRT 5.0, compute capability 7.5, 6.1, for my RTX 2080 TI.\r\n> [tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl](https://app.box.com/s/jcw8uq6jannpg4myzighl166bq1zg07e)\r\n\r\n@MingyaoLiu Were you able to install CUDA 10 on Ubuntu 18.10 ? Did you use 18.04 deb package? ", "> > Here is a ubuntu 18.10 build (kernal 4.18), tensorflow r1.12 branch, python 3.6, CUDA 10.0, cuDNN 7.4.1.5, NCCL 2.3.7, tensorRT 5.0, compute capability 7.5, 6.1, for my RTX 2080 TI.\r\n> > [tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl](https://app.box.com/s/jcw8uq6jannpg4myzighl166bq1zg07e)\r\n> \r\n> @MingyaoLiu Were you able to install CUDA 10 on Ubuntu 18.10 ? Did you use 18.04 deb package?\r\n\r\nYes. If i remember correctly i manually installed with cuda 10 for 18.04 run file. Deb may not work?", "> > > Here is a ubuntu 18.10 build (kernal 4.18), tensorflow r1.12 branch, python 3.6, CUDA 10.0, cuDNN 7.4.1.5, NCCL 2.3.7, tensorRT 5.0, compute capability 7.5, 6.1, for my RTX 2080 TI.\r\n> > > [tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl](https://app.box.com/s/jcw8uq6jannpg4myzighl166bq1zg07e)\r\n> > \r\n> > \r\n> > @MingyaoLiu Were you able to install CUDA 10 on Ubuntu 18.10 ? Did you use 18.04 deb package?\r\n> \r\n> Yes. If i remember correctly i manually installed with cuda 10 for 18.04 run file. Deb may not work?\r\n\r\nHi @MingyaoLiu ,\r\nCan you share the .whl file you compiled? \r\nBecause my GPU's compute capability is 3.5 . But the .whl file provided by @arunmandal53 requires 5.0, so it doesn't work on my computer.\r\n", "> [Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + python 3.6 + Windows](https://drive.google.com/open?id=1jnxaTTrxyfMvEExhEiraSZI7urUwr_tR)\r\n\r\nWhat compute level?\r\nCan you please share how you make the file? When I tried I did not succeed :(", "> Here is a windows build tensorflow 1.12.0, CUDA 10, cuDNN 7.3.1, RTX2080TI (feature level 7.5).\r\n> [tensorflow-1.12.0-cp36-cp36m-win_amd64.whl](https://app.box.com/s/joflprv5unbtqy2a972iyvtdovdsbovw)\r\n> one above in the comment I'm not sure what the CUDA feature level is, so I build a new one.\r\n\r\nCan you please share how you make the file? When I tried I did not succeed :(\r\nI need the file with compute level 7...", "When I try to build TF at AWS P3 V100 Tesla instance it runs 4000/6000 and then fails? What can I do to fix it?\r\n\r\n.\\tensorflow/core/kernels/mirror_pad_op_cpu_impl.h(31): note: see reference to class template instantiation 'tensorflow:\r\n:functor::MirrorPad<tensorflow::CpuDevice,tensorflow::int64,tensorflow::int64,5>' being compiled\r\nERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:3568:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:so\r\nftsign_op_gpu':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/softsign_op_gp\r\nu.cu.cc':\r\n  'C:/users/administrator/appdata/local/temp/nvcc_inter_files_tmp_dir/softsign_op_gpu.cu.cudafe1.stub.c'\r\n  'C:/users/administrator/appdata/local/temp/nvcc_inter_files_tmp_dir/softsign_op_gpu.cu.fatbin.c'\r\nc:\\users\\administrator\\_bazel_administrator\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\eigen\\src/Core/util/\r\nMemory.h(164): warning: calling a __host__ function from a __host__ __device__ function is not allowed\r\n\r\n\r\nlater it ends with...\r\n\r\n\r\nc:\\users\\administrator\\_bazel_administrator\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\sr\r\nc/SpecialFunctions/SpecialFunctionsImpl.h(712): warning: missing return statement at end of non-void function \"Eigen::in\r\nternal::igamma_series_impl<Scalar, mode>::run [with Scalar=double, mode=Eigen::internal::SAMPLE_DERIVATIVE]\"\r\n          detected during:\r\n            instantiation of \"Scalar Eigen::internal::igamma_series_impl<Scalar, mode>::run(Scalar, Scalar) [with Scalar\r\n=double, mode=Eigen::internal::SAMPLE_DERIVATIVE]\"\r\n(863): here\r\n            instantiation of \"Scalar Eigen::internal::igamma_generic_impl<Scalar, mode>::run(Scalar, Scalar) [with Scala\r\nr=double, mode=Eigen::internal::SAMPLE_DERIVATIVE]\"\r\n(2108): here\r\n            instantiation of \"Eigen::internal::gamma_sample_der_alpha_retval<Eigen::internal::global_math_functions_filt\r\nering_base<Scalar, void>::type>::type Eigen::numext::gamma_sample_der_alpha(const Scalar &, const Scalar &) [with Scalar\r\n=double]\"\r\nc:\\users\\administrator\\_bazel_administrator\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\eigen\\sr\r\nc/SpecialFunctions/arch/CUDA/CudaSpecialFunctions.h(154): here\r\n\r\nc:\\users\\administrator\\_bazel_administrator\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\eigen\\src/Core/Array\r\nWrapper.h(94): warning: __declspec attributes ignored\r\n\r\nexternal/com_google_absl\\absl/strings/string_view.h(496): warning: expression has no effect\r\n\r\nexternal/protobuf_archive/src\\google/protobuf/arena_impl.h(55): warning: integer conversion resulted in a change of sign\r\n\r\nexternal/protobuf_archive/src\\google/protobuf/arena_impl.h(309): warning: integer conversion resulted in a change of sig\r\nn\r\n\r\nexternal/protobuf_archive/src\\google/protobuf/arena_impl.h(310): warning: integer conversion resulted in a change of sig\r\nn\r\n\r\nexternal/protobuf_archive/src\\google/protobuf/map.h(1025): warning: invalid friend declaration\r\n\r\nhost_defines.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA rel\r\nease.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1100.301s, Critical Path: 135.78s\r\nINFO: 2335 processes: 2335 local.\r\nFAILED: Build did NOT complete successfully\r\nPS C:\\tensorflow>", "> **Edited:** 27-NOV-2018 Added 1.12 FINAL builds.\r\n> **Edited:** 29-OCT-2018 Added 1.12 RC2 builds.\r\n> **Edited:** 17-OCT-2018 Added 1.12 RC1 builds.\r\n> \r\n> * CUDA 10 in the nightly builds mid-DEC 2018 if testing goes well\r\n> * CUDA 10 in official in mid-JAN-2019 due to the holiday break and code freezes.  I would guess TF 1.13 (1.12 is out already)\r\n> \r\n> TensorFlow will be upgrading to `CUDA 10` as soon as possible. As of TF 1.11 building TensorFlow from source works just fine with `CUDA 10` and possibly even before. There is nothing special needed other than all of the `CUDA`, `cuDNN`, `NCCL` (optional), and `TensorRT` (optional) libraries. If people have some builds feel free to link them here (Keep in mind if you download them to decided what risk you want to take based on the source.) as well as any issues. Also` NCCL` is now open source again and soon will be back to being automatically downloaded by `bazel` and included in the binary.\r\n> \r\n> `CUDA 10` would likely go into TF 1.13, which is not scheduled. I will update this post as I have more info to share. I hope to flip nightly builds to CUDA 10 in November but the TF 1.13 release will likely push to early Jan.\r\n> \r\n> I and some really cool people below made some binaries (even windows, see comments below) to help people out along with my really [bad \"instructions\"](https://github.com/tfboyd/tf-tools/blob/master/install/cuda_10.md). I suspect the instructions linked in the comments below are better.\r\n> \r\n> Libraries used (rough list, similar to what I listed above)\r\n> \r\n> * Ubuntu 16.04 LTS on GCE from base Google Cloud Ubuntu image.\r\n> * Python 2.7 because that is how I roll and someday I will change.\r\n> * Install 410+ driver using apt-get\r\n> * CUDA 10.0.130 from .tgz install (do not install the driver)\r\n> * cuDNN-10.0 v7.3.0.29 rom tgz install\r\n> * nccl 2.3.4 for CUDA 10 (I am not sure it matters I have mixed them up before)\r\n> * TensorRT-5.0.0 for CUDA 10 cudnn 7.3 (TensorRT 5 was not stated as supported by Tensorflow when\r\n> * Compute Capability: 3.7,5.2,6.0,6.1,7.0\r\n> \r\n> _**TF 1.12.0 FINAL**_\r\n> \r\n> **Python 2.7 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0.a6d8ffa.AVX2.CUDA10-cp27-cp27mu-linux_x86_64.whl)\r\n> \r\n> **Python 3.5 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0.a6d8ffa.AVX2.CUDA10-cp35-cp35m-linux_x86_64.whl)\r\n> \r\n> _**TF 1.12.0 RC2**_\r\n> \r\n> **Python 2.7 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc2.748435b.AVX2.CUDA10-cp27-cp27mu-linux_x86_64.whl)\r\n> \r\n> **Python 3.5 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc2.748435b.AVX2.CUDA10-cp35-cp35m-linux_x86_64.whl)\r\n> \r\n> _**TF 1.12.0 RC1**_\r\n> \r\n> **Python 2.7 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc1.7b08198.AVX2.CUDA10-cp27-cp27mu-linux_x86_64.whl)\r\n> \r\n> **Python 3.5 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc1.7b08198.AVX.CUDA10-cp35-cp35m-linux_x86_64.whl)\r\n> \r\n> _**TF 1.12.0 RC0**_\r\n> \r\n> **Python 2.7 (Ubuntu 16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc0.1a6dea3.AVX2-cp27-cp27mu-linux_x86_64.whl)\r\n> * [AVX + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc0.1a6dea3.AVX-cp27-cp27mu-linux_x86_64.whl)\r\n> \r\n> **Python 3.5 (Ubuntu16.04)**\r\n> \r\n> * [AVX2 + CUDA 10](https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0rc0.1a6dea3.AVX2-cp35-cp35m-linux_x86_64.whl)\r\n> \r\n> **Dockerfiles**\r\n> These are partial files and the apt-get commands should work on non-Docker systems as well assuming you have the NVIDIA apt-get repositories which should be the same as listed on [tf.org](https://www.tensorflow.org/install/gpu).\r\n> \r\n> * [Devel](https://github.com/tfboyd/tensorflow/blob/cuda_10_dockerfile/tensorflow/tools/dockerfiles/partials/nvidia-devel.partial.Dockerfile)  Confirmed by building TensorFlow at 1.12RC0.\r\n> * [Runtime](https://github.com/tfboyd/tensorflow/blob/cuda_10_dockerfile/tensorflow/tools/dockerfiles/partials/nvidia.partial.Dockerfile)\r\n\r\nHi Toby, how's your testing going?\r\nIs CUDA 10 supported by nightly builds now?", "Should be fixed (partially at least) by 29b8d495c3d3cbd13eed86f542586c1bd1597e46.", "@alifare \r\n\r\nNightly builds are now CUDA 10.  I tested via the Docker images from dockerhub.  I did not test Windows as that is something I have yet to use (sorry) for ML. This happened on Friday so there may still be some issues as we roll it out.  Let me know if you run into any problems.  We also moved to NCCL from source so you no longer need to install NCCL to use it.  \r\n\r\nMore info in the new few weeks, I do not know if we will do an official RC before the year ends but 1.13 is likely to go final mid/end-JAN and it 100% has CUDA 10 and cuDNN 7.4 (you could always update this by just adding a new binary).  \r\n", "> @alifare\r\n> \r\n> Nightly builds are now CUDA 10. I tested via the Docker images from dockerhub. I did not test Windows as that is something I have yet to use (sorry) for ML. This happened on Friday so there may still be some issues as we roll it out. Let me know if you run into any problems. We also moved to NCCL from source so you no longer need to install NCCL to use it.\r\n> \r\n> More info in the new few weeks, I do not know if we will do an official RC before the year ends but 1.13 is likely to go final mid/end-JAN and it 100% has CUDA 10 and cuDNN 7.4 (you could always update this by just adding a new binary).\r\n\r\nThank a lot @tfboyd \r\nI installed the nightly builds yesterday and I am testing it with sample codes now. Everyting seems to be going well now. I will let you know if I find any probelm in future.", "Well, if this root is good, how do i incorporate it into my system?", "> @tfboyd Hey could you kindly share the .whl of tensorflow 1.11 with,\r\n> \r\n> ```\r\n> CUDA 10.0.130_410.48\r\n> cuDNN 7.3.0.29 for CUDA 10\r\n> I was not able to build the same. I have a rtx 2080 with ubuntu 16.04. Thanks in advance\r\n> ```\r\n\r\nMe too.\r\nIs there any info?", "> [Tensorflow 1.12 whl for CUDA 10.0 + CUDNN 7.3.1 + NCCL 2.3.5 + python 3.6 +Ubuntu](https://drive.google.com/file/d/1QV7fBi5ZpTm02N1_QbyEhT6v80B6Zffg/view?usp=sharing)\r\n\r\nIs this official?", "> > @alifare\r\n> > Nightly builds are now CUDA 10. I tested via the Docker images from dockerhub. I did not test Windows as that is something I have yet to use (sorry) for ML. This happened on Friday so there may still be some issues as we roll it out. Let me know if you run into any problems. We also moved to NCCL from source so you no longer need to install NCCL to use it.\r\n> > More info in the new few weeks, I do not know if we will do an official RC before the year ends but 1.13 is likely to go final mid/end-JAN and it 100% has CUDA 10 and cuDNN 7.4 (you could always update this by just adding a new binary).\r\n> \r\n> Thank a lot @tfboyd\r\n> I installed the nightly builds yesterday and I am testing it with sample codes now. Everyting seems to be going well now. I will let you know if I find any probelm in future.\r\n\r\nThank you guys, it also works for me as well with a 1080 ti", "I installed the nightly docker image which works in general but I get an error message when trying to fit a keras.layers.Conv1D layer on my GPU (RTX 2070)\r\n\r\n> UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\r\nIs cuDNN installed on the tensorflow nightly containers?  Or is this the wrong question!", "my GPU : RTX 2070\r\nUbuntu 16.04\r\nPython 3.5.2\r\nNvidia Driver 410.78\r\nCUDA - 10.0.130\r\ncuDNN-10.0 - 7.4.2.24 \r\nTensorRT-5.0.0 \r\nCompute Capability: 7.5\r\n\r\n<a href=\"https://drive.google.com/open?id=19NkEV3I1Oye_Ia65w0Iu1foOccbVRP7l\">tensorflow-1.13.0rc0-cp35-cp35m-linux_x86_64</a>\r\n\r\n\r\n", "Tried some wheels in https://github.com/tensorflow/tensorflow/issues/22706#issuecomment-447706296,\r\nI keep getting such error when using tensorRT int8 inference:\r\n```\r\n2019-01-11 01:54:24.555172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2019-01-11 01:54:25.902674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-01-11 01:54:25.902717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2019-01-11 01:54:25.902726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2019-01-11 01:54:25.924944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3035 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2019-01-11 01:54:30.056922: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:502] import/InceptionResnetV1/my_trt_op_0 Constructing a new engine with batch size 32\r\n\r\n=================================================================\r\n**2019-01-11 01:54:30.361891: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger ../builder/cudnnBuilder2.cpp (1508) - Misc Error in buildEngine: -1 (Could not find tensor (Unnamed ITensor* 3) in tensorScales.)\r\n2019-01-11 01:54:30.424656: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger ../builder/cudnnBuilder2.cpp (1508) - Misc Error in buildEngine: -1 (Could not find tensor (Unnamed ITensor* 3) in tensorScales.)\r\n2019-01-11 01:54:30.425290: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:516] Engine creation for batch size 32 failed Internal: Failed to build TensorRT engine\r\n2019-01-11 01:54:30.425308: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:287] Engine retrieval for batch size 1 failed. \r\n=================================================================\r\n```\r\nAlso I built a wheel based on nvidia tensorflow docker 18.12(py27), the same error.\r\n\r\nDoes anyone run into this error and solve it? ", "> my GPU : RTX 2070\r\n> Ubuntu 16.04\r\n> Python 3.5.2\r\n> Nvidia Driver 410.78\r\n> CUDA - 10.0.130\r\n> cuDNN-10.0 - 7.4.2.24\r\n> TensorRT-5.0.0\r\n> Compute Capability: 7.5\r\n> \r\n> [tensorflow-1.13.0rc0-cp35-cp35m-linux_x86_64](https://drive.google.com/open?id=19NkEV3I1Oye_Ia65w0Iu1foOccbVRP7l)\r\n\r\nDoes it include nccl 2.3.7? I have installed nccl but TF cannot find it.", "> Tried some wheels in [#22706 (comment)](https://github.com/tensorflow/tensorflow/issues/22706#issuecomment-447706296),\r\n> I keep getting such error when using tensorRT int8 inference:\r\n> \r\n> ```\r\n> 2019-01-11 01:54:24.555172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n> 2019-01-11 01:54:25.902674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-01-11 01:54:25.902717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n> 2019-01-11 01:54:25.902726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n> 2019-01-11 01:54:25.924944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3035 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n> 2019-01-11 01:54:30.056922: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:502] import/InceptionResnetV1/my_trt_op_0 Constructing a new engine with batch size 32\r\n> \r\n> =================================================================\r\n> **2019-01-11 01:54:30.361891: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger ../builder/cudnnBuilder2.cpp (1508) - Misc Error in buildEngine: -1 (Could not find tensor (Unnamed ITensor* 3) in tensorScales.)\r\n> 2019-01-11 01:54:30.424656: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger ../builder/cudnnBuilder2.cpp (1508) - Misc Error in buildEngine: -1 (Could not find tensor (Unnamed ITensor* 3) in tensorScales.)\r\n> 2019-01-11 01:54:30.425290: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:516] Engine creation for batch size 32 failed Internal: Failed to build TensorRT engine\r\n> 2019-01-11 01:54:30.425308: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:287] Engine retrieval for batch size 1 failed. \r\n> =================================================================\r\n> ```\r\n> Also I built a wheel based on nvidia tensorflow docker 18.12(py27), the same error.\r\n> \r\n> Does anyone run into this error and solve it?\r\n\r\nPerhaps you haven't run calibration which is required for INT8 unless you manually insert dynamic ranges. https://docs.nvidia.com/deeplearning/dgx/integrate-tf-trt/index.html#tutorial-tftrt-int8\r\n\r\nAlso I think you are using an old TF (perhaps 1.12?) because we have renamed `my_trt_op` to `TRTOpEngine`.", "@pooyadavoodi Thanks for responding!!\r\n1. It's a calibrated graph running correctly in [Nvidia TensorFlow docker 18.12](https://docs.nvidia.com/deeplearning/dgx/tensorflow-release-notes/rel_18.12.html#rel_18.12). Got this error when trying to run on TensorFlow generated from source as mentioned.\r\n2. Yes, I'm using tensorflow r1.12 just for matching the docker, will give a try on r1.13.\r\n3. Noticed that some nccl related files miss in all tried tensorflow compared to nvidia docker version:\r\n```\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nccl_ops.py\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nccl_ops.py\r\n...\r\n```", "> Took my 15 days to followup, sorry. This is the timeline I am seeing right now:\r\n> \r\n> * CUDA 10 in the nightly builds mid-DEC if testing goes well\r\n> * CUDA 10 in official in mid-JAN due to the holiday break I would guess TF 1.13 (1.12 is out already)\r\n> \r\n> I am adding this to the original post above as well.\r\n\r\nAre there any updates on 1.13 release date? ", "Hey,\r\nmaybe look at my CUDA 10 build for Tensorflow. It works fine. I habe a GTX 2080, 64GB RAM. I have no problems to work with this build.\r\n\r\nhttps://github.com/Lxnus/tensorflow_r1.12_cuda_10", "Hi all,\r\n\r\nI've [managed to get this working](https://medium.com/@noel_kennedy/how-to-use-half-precision-float16-when-training-on-rtx-cards-with-tensorflow-keras-d4033d59f9e4) and haven't experienced any issues for a while.  \r\n\r\nTLDR: Install CUDA 10, build Tensorflow locally.  Once this is running you need to tell TF to use float16 and adjust the epsilon or you will get NaN during training. \r\n\r\n\r\n```\r\nimport keras.backend as K\r\n\r\ndtype='float16'\r\nK.set_floatx(dtype)\r\n\r\n# default is 1e-7 which is too small for float16.  Without adjusting the epsilon, we will get NaN predictions because of divide by zero\r\nK.set_epsilon(1e-4) \r\n```\r\n\r\n", "I've managed to build it in **Ubuntu 18.04**, with **Python 3.6**, **Cuda 10.0**, **cudnn 7.4.2**. GPU model RTX 2080Ti. Here is the .whl:\r\n[tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl](https://drive.google.com/file/d/1AVSg2o_sruO_DYuVD3BK6RiXYpi8c0I-)\r\nI used `-march=native` optimization flag, and my CPU is Xeon X5680 that supports SSE4.2 instruction set extensions. Not sure whether this leads to some incompatibility issues with other CPU models. Good luck.\r\n", "Hi @tfboyd , I have the same question as @tydlwav , any updates on the 1.13 release? I am coding in R using Keras and using the RTX 2080. Really looking forward to this release.", "rc0 is already out:\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v1.13.0-rc0\r\n\r\nAll our nightlies also have cuda 10 support for a while now.", "> I've built tf 1.12.0rc0 with all the latest, test well except this silly warning\r\n> \r\n> *** WARNING *** You are using ptxas 10.0.145, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\r\n> \r\n> You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.\r\n> \r\n> seems no problem for now\r\n> \r\n> only thing left is python 3.7, which I haven't tried yet\r\n\r\n*** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\r\n\r\nI am facing this issue for Tensorflow==2.7.0 in ubuntu20.04. Please let me know how did you solve your issue."]}, {"number": 22705, "title": "1.12-rc0 cherry-pick request: Fix ci_parameterized_build to pass environment variables to tests.", "body": "This is particularly important when using --run_under with\r\nparallel_gpu_execute, since the envvars control the execution.\r\n\r\nPiperOrigin-RevId: 215637931", "comments": []}, {"number": 22704, "title": "1.12-rc0 cherry-pick request: Disable XLA for Android builds.", "body": "PiperOrigin-RevId: 215605865", "comments": []}, {"number": 22703, "title": "tensorflow-gpu being ruined by matplotlib", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: gpu-1.10.0-hf154084_0\r\n- **Python version**: 3.6.6-hc3d631a_0\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: 1070\r\n- **Exact command to reproduce**:\r\nconda create --name test python=3.6.6 tensorflow-gpu spyder pandas\r\nsource activate test\r\n-- problem starts here\r\nconda install matplotlib\r\nspyder\r\nimport tensorflow.contrib.training as training\r\n- **Versions**:spyder=3.3.1, pandas=0.23.4, matplotlib=3.0.0\r\n\r\n### Describe the problem\r\nTensorflow-gpu works fine (import tensorflow.contrib.training as training executes without errors) until the installation of matplotlib. After that \"import tensorflow.contrib.training as training\" gives this error:\r\n\r\n    import tensorflow.contrib.training as training\r\n    Traceback (most recent call last):\r\n    \r\n      File \"/home/nikolay/anaconda3/envs/test/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\r\n        exec(code_obj, self.user_global_ns, self.user_ns)\r\n    \r\n      File \"<ipython-input-1-f7e526cc11b2>\", line 1, in <module>\r\n        import tensorflow.contrib.training as training\r\n    \r\n      File \"/home/nikolay/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/contrib/__init__.py\", line 48, in <module>\r\n        from tensorflow.contrib import image\r\n    \r\n      File \"/home/nikolay/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/contrib/image/__init__.py\", line 70, in <module>\r\n        from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms\r\n    \r\n      File \"/home/nikolay/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py\", line 27, in <module>\r\n        \"_single_image_random_dot_stereograms.so\"))\r\n    \r\n      File \"/home/nikolay/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/contrib/util/loader.py\", line 56, in load_op_library\r\n        ret = load_library.load_op_library(path)\r\n    \r\n      File \"/home/nikolay/anaconda3/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\", line 73, in load_op_library\r\n        exec(wrappers, module.__dict__)\r\n    \r\n      File \"<string>\", line 27\r\n        def single_image_random_dot_stereograms(depth_values, hidden_surface_removal=True, convergence_dots_size=8, dots_per_inch=72, eye_separation=2,5, mu=0,333299994, normalize=True, normalize_max=-100, normalize_min=100, border_level=0, number_colors=256, output_image_shape=[1024, 768, 1], output_data_window=[1022, 757], name=None):\r\n                                                                                                                                                       ^\r\n    SyntaxError: invalid syntax\r\n\r\nif it matters, here is what matplotlib installation looks like:\r\n\r\n    (test) xxx@xxx:~$ conda install matplotlib\r\n    Solving environment: done\r\n    \r\n    ## Package Plan ##\r\n    \r\n      environment location: /home/xxx/anaconda3/envs/test\r\n    \r\n      added / updated specs: \r\n        - matplotlib\r\n    \r\n    \r\n    The following NEW packages will be INSTALLED:\r\n    \r\n        cycler:     0.10.0-py36_0       \r\n        kiwisolver: 1.0.1-py36hf484d3e_0\r\n        matplotlib: 3.0.0-py36h5429711_0\r\n    \r\n    Proceed ([y]/n)? y\r\n    \r\n    Preparing transaction: done\r\n    Verifying transaction: done\r\n    Executing transaction: done\r\n", "comments": ["Neither it is ok after installing tensorflow-gpu via pip:\r\n\r\n    conda create --name test python=3.6.6 setuptools=39.1.0 pip=18.0 spyder\r\n    conda activate test\r\n    pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.11.0-cp36-cp36m-linux_x86_64.whl\r\n    pip install matplotlib\r\n    spyder\r\n    import tensorflow.contrib.training as training\r\n\r\nBUT, everything works fine if i use console python:\r\n\r\n    source activate test\r\n    python\r\n    import tensorflow.contrib.training as training", "I also get this error while trying to use the **tf.contrib.gan.eval.sliced_wasserstein_distance** function.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/local/schellsn/Projects/edaml/code/trunk/ignored/wasserstein.py\", line 53, in main\r\n    init_emd_tensorflow(dummy.ravel().shape)\r\n  File \"/local/schellsn/Projects/edaml/code/trunk/ignored/wasserstein.py\", line 27, in init_emd_tensorflow\r\n    TF_EMD_DIST = tf.contrib.gan.eval.sliced_wasserstein_distance(\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\r\n    module = self._load()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 42, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/usr/lib64/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/__init__.py\", line 49, in <module>\r\n    from tensorflow.contrib import image\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/image/__init__.py\", line 70, in <module>\r\n    from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py\", line 27, in <module>\r\n    \"_single_image_random_dot_stereograms.so\"))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/util/loader.py\", line 56, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\", line 73, in load_op_library\r\n    exec(wrappers, module.__dict__)\r\n  File \"<string>\", line 28\r\n    def single_image_random_dot_stereograms(depth_values, hidden_surface_removal=True, convergence_dots_size=8, dots_per_inch=72, eye_separation=2,5, mu=0,333299994, normalize=True, normalize_max=-100, normalize_min=100, border_level=0, number_colors=256, output_image_shape=[1024, 768, 1], output_data_window=[1022, 757], name=None):\r\n                                                                                                                                                   ^\r\nSyntaxError: invalid syntax\r\n\r\n```\r\n\r\nI use a build-from-source version of Tensorflow v1.11.0 with CUDA 10.0 and cuDNN 7.3.1", "Nagging Assignee @suharshs: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Apparently its an IDE related issue. Closing this issue since its not a TF related bug/feature request. Feel free to reopen this issue if the problem still persists by providing additional information.\r\n@SteScheller Please open a new issue to report your problem and provide all the information asked by the template. Thanks!"]}, {"number": 22702, "title": "1.12-rc0 cherry-pick request: Change hierarchical_tree_broadcaster_test from small to medium.", "body": "PiperOrigin-RevId: 215607769", "comments": []}, {"number": 22701, "title": "tf.while_loop ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Colab\r\n- **TensorFlow installed from (source or binary)**: Colab\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: Colab\r\n- **GCC/Compiler version (if compiling from source)**: Colab\r\n- **CUDA/cuDNN version**: Colab\r\n- **GPU model and memory**: Colab\r\n- **Exact command to reproduce**: Colab\r\n\r\n### Describe the problem\r\nThe `tf.while_loop` no longer works. I have also checked the code from the official [documentation](https://www.tensorflow.org/api_docs/python/tf/while_loop).\r\nI ran away from the eager mode issues and I found myself writing nonsense code:\r\n`tf.cond`\r\n`tf.while_loop`\r\n`tf.Print`\r\n`tf.gather`\r\n`tf.scatter_update`\r\n\r\nAt the end of the day, nothing works properly neither the graph mode nor the eager one.\r\n\r\n\r\n### Source code\r\n```\r\nimport tensorflow as tf\r\n\r\nn = 10000\r\nx = tf.constant(list(range(n)))\r\nc = lambda i, x: i < n\r\nb = lambda i, x: (tf.Print(i + 1, [i]), tf.Print(x + 1, [i], \"x:\"))\r\ni, out = tf.while_loop(c, b, (0, x))\r\nwith tf.Session() as sess:\r\n    print(sess.run(i))  # prints [0] ... [9999]\r\n\r\n    # The following line may increment the counter and x in parallel.\r\n    # The counter thread may get ahead of the other thread, but not the\r\n    # other way around. So you may see things like\r\n    # [9996] x:[9987]\r\n    # meaning that the counter thread is on iteration 9996,\r\n    # while the other thread is on iteration 9987\r\n    print(sess.run(out).shape)\r\n```\r\n\r\n### logs\r\nInvalidArgumentErrorTraceback (most recent call last)\r\n<ipython-input-21-a546eb31055a> in <module>()\r\n      7 i, out = tf.while_loop(c, b, (0, x))\r\n      8 with tf.Session() as sess:\r\n----> 9     print(sess.run(i))  # prints [0] ... [9999]\r\n     10 \r\n     11     # The following line may increment the counter and x in parallel.\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    885     try:\r\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 887                          run_metadata_ptr)\r\n    888       if run_metadata:\r\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1109       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1110                              feed_dict_tensor, options, run_metadata)\r\n   1111     else:\r\n   1112       results = []\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1284     if handle is None:\r\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1286                            run_metadata)\r\n   1287     else:\r\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n   1306           self._config.experimental.client_handles_error_formatting):\r\n   1307         message = error_interpolation.interpolate(message, self._graph)\r\n-> 1308       raise type(e)(node_def, op, message)\r\n   1309 \r\n   1310   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Input 1 of node while/Merge_3 was passed float from while/NextIteration_3:0 incompatible with expected int32.\r\n", "comments": ["@martinwicke are you sure that the version 1.11 is a stable one?\r\nIt doesn't seem to be.", "I am really disappointed. Lots and lots of bugs.", "![1003-15 04 34](https://user-images.githubusercontent.com/1381301/46442207-ade14200-c71d-11e8-914a-e51e6263ab5a.png)\r\n\r\nOpened a colab and run your code. It works just fine.", "How come?\r\n![image](https://user-images.githubusercontent.com/10966954/46442736-f70bb300-c76a-11e8-92c8-538e2b14647b.png)\r\n\r\n\r\n", "@nairouz, please paste the full trace for the error (and include the `tf.VERSION` output as well) -- the truncated picture isn't useful to find the problem.", "@martinwicke I restarted the notebook and now it is working.\r\nI don't know why this happened. I m sorry for the trouble.\r\n\r\nThis is the full trace:\r\n\r\nInvalidArgumentErrorTraceback (most recent call last)\r\nin ()\r\n7 i, out = tf.while_loop(c, b, (0, x))\r\n8 with tf.Session() as sess:\r\n----> 9 print(sess.run(i)) # prints [0] ... [9999]\r\n10\r\n11 # The following line may increment the counter and x in parallel.\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n885 try:\r\n886 result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 887 run_metadata_ptr)\r\n888 if run_metadata:\r\n889 proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n1108 if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n1109 results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1110 feed_dict_tensor, options, run_metadata)\r\n1111 else:\r\n1112 results = []\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n1284 if handle is None:\r\n1285 return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1286 run_metadata)\r\n1287 else:\r\n1288 return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n1306 self._config.experimental.client_handles_error_formatting):\r\n1307 message = error_interpolation.interpolate(message, self._graph)\r\n-> 1308 raise type(e)(node_def, op, message)\r\n1309\r\n1310 def _extend_graph(self):\r\n\r\nInvalidArgumentError: Input 1 of node while/Merge_3 was passed float from while/NextIteration_3:0 incompatible with expected int32."]}, {"number": 22700, "title": "1.12-1 cherry-pick request: Fix TfLiteTensor invalidation issue when using the Java API", "body": "Fix an issue where the Java Tensor class would hold a reference\r\nto an invalidated TfLiteTensor instance. This issue was manifest\r\nin certain models that add temporary tensors during execution.\r\n\r\nPiperOrigin-RevId: 215582842\r\n\r\nThis CL is critical for 1.12 as there are several clients who were\r\nimpacted by the regression in 1.11 and are blocked on a stable fix.", "comments": ["Jared, can you take a look at the  clang-format error:\r\n```\r\n--- a/tensorflow/contrib/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java\r\n+++ b/tensorflow/contrib/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java\r\n@@ -269,9 +269,8 @@ final class NativeInterpreterWrapper implements AutoCloseable {\r\n     }\r\n     Tensor inputTensor = inputTensors[index];\r\n     if (inputTensor == null) {\r\n-      inputTensor =\r\n-          inputTensors[index] =\r\n-              Tensor.fromIndex(interpreterHandle, getInputTensorIndex(interpreterHandle, index));\r\n+      inputTensor = inputTensors[index] =\r\n+          Tensor.fromIndex(interpreterHandle, getInputTensorIndex(interpreterHandle, index));\r\n     }\r\n     return inputTensor;\r\n   }\r\n@@ -292,9 +291,8 @@ final class NativeInterpreterWrapper implements AutoCloseable {\r\n     }\r\n     Tensor outputTensor = outputTensors[index];\r\n     if (outputTensor == null) {\r\n-      outputTensor =\r\n-          outputTensors[index] =\r\n-              Tensor.fromIndex(interpreterHandle, getOutputTensorIndex(interpreterHandle, index));\r\n+      outputTensor = outputTensors[index] =\r\n+          Tensor.fromIndex(interpreterHandle, getOutputTensorIndex(interpreterHandle, index));\r\n     }\r\n     return outputTensor;\r\n   }\r\n```\r\n", "Hmm, this is a straight cherry-pick and matches code already in master? Do we have to fix the clang failures to land?\r\n\r\nI can clean it up in master, but would prefer not to fix the (existing) style issue with the cherry-pick."]}, {"number": 22699, "title": "tensorflow 1.11.0 on Windows: No OpKernel was registered to support Op 'SparseMatMul' ", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64bit\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Run the test: //py_test_dir/tensorflow/python/keras:local_test\r\n\r\nYou can obtain the TensorFlow version with\r\n```\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nb'v1.11.0-rc2-4-gc19e29306c' 1.11.0\r\n```\r\n### Describe the problem\r\n```\r\npython tensorflow\\python\\keras\\layers\\local_test.py\r\nC:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\r\n  return _inspect.getargspec(target)\r\nERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected1d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 63, in test_locallyconnected_1d\r\n    input_shape=(num_samples, num_steps, input_dim))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nE.ERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 147, in test_locallyconnected_2d\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nEERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_2_1/SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 175, in test_locallyconnected_2d_channels_first\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nE.C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4435: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\r\n  xs.append(reshape(inputs[slices], (1, -1, feature_dim)))\r\nERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nCaused by op 'SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 260, in test_locallyconnected_implementation\r\n    out_2 = model_2.call(inputs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 232, in call\r\n    inputs, training=training, mask=mask)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 250, in _call_and_compute_mask\r\n    x = layer.call(x, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nE..\r\n======================================================================\r\nERROR: test_locallyconnected_1d (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 63, in test_locallyconnected_1d\r\n    input_shape=(num_samples, num_steps, input_dim))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 121, in layer_test\r\n    actual_output = model.predict(input_data)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1766, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2939, in __call__\r\n    session = get_session()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 465, in get_session\r\n    _initialize_variables(session)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 719, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected1d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 63, in test_locallyconnected_1d\r\n    input_shape=(num_samples, num_steps, input_dim))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\n\r\n======================================================================\r\nERROR: test_locallyconnected_2d (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 147, in test_locallyconnected_2d\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 121, in layer_test\r\n    actual_output = model.predict(input_data)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1766, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2939, in __call__\r\n    session = get_session()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 465, in get_session\r\n    _initialize_variables(session)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 719, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 147, in test_locallyconnected_2d\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\n\r\n======================================================================\r\nERROR: test_locallyconnected_2d_channels_first (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 175, in test_locallyconnected_2d_channels_first\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 121, in layer_test\r\n    actual_output = model.predict(input_data)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1766, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2939, in __call__\r\n    session = get_session()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 465, in get_session\r\n    _initialize_variables(session)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 719, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_2_1/SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 175, in test_locallyconnected_2d_channels_first\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\n\r\n======================================================================\r\nERROR: test_locallyconnected_implementation (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 262, in test_locallyconnected_implementation\r\n    rtol=1e-5, atol=1e-5)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1489, in assertAllCloseAccordingToType\r\n    a = self._GetNdArray(a)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1323, in _GetNdArray\r\n    a = self.evaluate(a)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1035, in evaluate\r\n    return sess.run(tensors)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nCaused by op 'SparseMatMul', defined at:\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow\\python\\keras\\layers\\local_test.py\", line 260, in test_locallyconnected_implementation\r\n    out_2 = model_2.call(inputs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 232, in call\r\n    inputs, training=training, mask=mask)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 250, in _call_and_compute_mask\r\n    x = layer.call(x, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ci\\tensorflow-base_1538579912447\\work\\test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\n\r\n----------------------------------------------------------------------\r\nRan 8 tests in 7.794s\r\n\r\nFAILED (errors=4)\r\n```\r\n", "comments": ["@nehaljwani `SparseMatMul` should be registered for CPU. What was the command you used? ", "@wt-huang I have already shared the command (on a local clone of tensorflow):\r\n```\r\npython tensorflow\\python\\keras\\layers\\local_test.py \r\n```\r\nI am using python 3.6 and installed tensorflow using pip on Windows.", "@nehaljwani I was able to run the above local_test.py without running into errors. Please check your TensorFlow installation on Windows 10, you can follow the installation guide [here](https://www.tensorflow.org/install/source_windows)\r\n\r\n\r\n", "@wt-huang These are the steps I followed (In a brand new Windows 10 VM):\r\n\r\n1. Download and install python3.6.6 to C:\\Users\\nwani\\Downloads\\py366\r\n2. Download and install VS2015 runtime\r\n3. Install tensorflow:\r\n```\r\nC:\\Users\\Wani\\Downloads\\py366>python -m pip  install tensorflow\r\nCollecting tensorflow\r\n  Downloading https://files.pythonhosted.org/packages/c1/e1/a5693a158f3867417d7b50bd0514c83304706242fae74463705b8c373777/tensorflow-1.11.0-cp36-cp36m-win_amd64.whl (46.9MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 46.9MB 453kB/s\r\nCollecting absl-py>=0.1.6 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/16/db/cce5331638138c178dd1d5fb69f3f55eb3787a12efd9177177ae203e847f/absl-py-0.5.0.tar.gz (90kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 5.2MB/s\r\nRequirement already satisfied: setuptools<=39.1.0 in c:\\users\\wani\\downloads\\py366\\lib\\site-packages (from tensorflow) (39.0.1)\r\nCollecting astor>=0.6.0 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\r\nCollecting termcolor>=1.1.0 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\r\nCollecting numpy>=1.13.3 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/15/7b/162a54ef1827fa9324d0610a526ab68b3c76c30b928c437df8c1d39bda86/numpy-1.15.2-cp36-none-win_amd64.whl (13.5MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13.5MB 1.3MB/s\r\nCollecting tensorboard<1.12.0,>=1.11.0 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.0MB 2.7MB/s\r\nCollecting grpcio>=1.8.6 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/0e/13/43a98e233716f1d9846ca65322b065443af5ea1aed5f631e240d231174c0/grpcio-1.15.0-cp36-cp36m-win_amd64.whl (1.5MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.5MB 2.8MB/s\r\nCollecting protobuf>=3.6.0 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/e8/df/d606d07cff0fc8d22abcc54006c0247002d11a7f2d218eb008d48e76851d/protobuf-3.6.1-cp36-cp36m-win_amd64.whl (1.1MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.1MB 2.8MB/s\r\nCollecting keras-applications>=1.0.5 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB ...\r\nCollecting wheel>=0.26 (from tensorflow)\r\n  Using cached https://files.pythonhosted.org/packages/fc/e9/05316a1eec70c2bfc1c823a259546475bd7636ba6d27ec80575da523bc34/wheel-0.32.1-py2.py3-none-any.whl\r\nCollecting keras-preprocessing>=1.0.3 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\r\nCollecting gast>=0.2.0 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\r\nCollecting six>=1.10.0 (from tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\r\nCollecting markdown>=2.6.8 (from tensorboard<1.12.0,>=1.11.0->tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 6.8MB/s\r\nCollecting werkzeug>=0.11.10 (from tensorboard<1.12.0,>=1.11.0->tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 464kB/s\r\nCollecting h5py (from keras-applications>=1.0.5->tensorflow)\r\n  Downloading https://files.pythonhosted.org/packages/12/6c/00c38c5ce9322f1cc421d93217c44739646a106c61859622eccc297a5c05/h5py-2.8.0-cp36-cp36m-win_amd64.whl (2.3MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.3MB 3.0MB/s\r\nInstalling collected packages: six, absl-py, astor, termcolor, numpy, markdown, wheel, protobuf, werkzeug, grpcio, tensorboard, h5py, keras-applications, keras-preprocessing, gast, tensorflow\r\n  Running setup.py install for absl-py ... done\r\n  Running setup.py install for termcolor ... done\r\n  The script markdown_py.exe is installed in 'C:\\Users\\Wani\\Downloads\\py366\\Scripts' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\r\n  The script wheel.exe is installed in 'C:\\Users\\Wani\\Downloads\\py366\\Scripts' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\r\n  The script tensorboard.exe is installed in 'C:\\Users\\Wani\\Downloads\\py366\\Scripts' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\r\n  Running setup.py install for gast ... done\r\n  The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\Wani\\Downloads\\py366\\Scripts' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\r\nSuccessfully installed absl-py-0.5.0 astor-0.7.1 gast-0.2.0 grpcio-1.15.0 h5py-2.8.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 markdown-3.0.1 numpy-1.15.2 protobuf-3.6.1 six-1.11.0 tensorboard-1.11.0 tensorflow-1.11.0 termcolor-1.1.0 werkzeug-0.14.1 wheel-0.32.1\r\nYou are using pip version 10.0.1, however version 18.1 is available.\r\nYou should consider upgrading via the 'python -m pip install --upgrade pip' command.\r\n```\r\n4. Get the source code:\r\n```\r\nC:\\Users\\Wani\\Downloads\\py366>curl -LO https://github.com/tensorflow/tensorflow/archive/v1.11.0.tar.gz\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   130    0   130    0     0     65      0 --:--:--  0:00:02 --:--:--    45\r\n100 23.8M    0 23.8M    0     0  1879k      0 --:--:--  0:00:13 --:--:-- 3481k\r\n\r\nC:\\Users\\Wani\\Downloads\\py366>python -m tarfile -e v1.11.0.tar.gz\r\n```\r\n5. Try to run the file:\r\n```\r\nC:\\Users\\Wani\\Downloads\\py366>python tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\r\n2018-10-19 11:26:48.465821: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nC:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\r\n  return _inspect.getargspec(target)\r\nERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected1d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 63, in test_locallyconnected_1d\r\n    input_shape=(num_samples, num_steps, input_dim))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nE.ERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 147, in test_locallyconnected_2d\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nEERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_2_1/SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 175, in test_locallyconnected_2d_channels_first\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nE.C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4435: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\r\n  xs.append(reshape(inputs[slices], (1, -1, feature_dim)))\r\nERROR:tensorflow:No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nCaused by op 'SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 260, in test_locallyconnected_implementation\r\n    out_2 = model_2.call(inputs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 232, in call\r\n    inputs, training=training, mask=mask)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 250, in _call_and_compute_mask\r\n    x = layer.call(x, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nE..\r\n======================================================================\r\nERROR: test_locallyconnected_1d (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 63, in test_locallyconnected_1d\r\n    input_shape=(num_samples, num_steps, input_dim))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 121, in layer_test\r\n    actual_output = model.predict(input_data)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1766, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2939, in __call__\r\n    session = get_session()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 465, in get_session\r\n    _initialize_variables(session)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 719, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected1d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 63, in test_locallyconnected_1d\r\n    input_shape=(num_samples, num_steps, input_dim))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected1d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected1d_1_1/Reshape, locally_connected1d_1_1/Reshape_1)]]\r\n\r\n\r\n======================================================================\r\nERROR: test_locallyconnected_2d (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 147, in test_locallyconnected_2d\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 121, in layer_test\r\n    actual_output = model.predict(input_data)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1766, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2939, in __call__\r\n    session = get_session()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 465, in get_session\r\n    _initialize_variables(session)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 719, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_1_1/SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 147, in test_locallyconnected_2d\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_1_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_1_1/Reshape, locally_connected2d_1_1/Reshape_1)]]\r\n\r\n\r\n======================================================================\r\nERROR: test_locallyconnected_2d_channels_first (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 175, in test_locallyconnected_2d_channels_first\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 121, in layer_test\r\n    actual_output = model.predict(input_data)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1766, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2939, in __call__\r\n    session = get_session()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 465, in get_session\r\n    _initialize_variables(session)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 719, in _initialize_variables\r\n    [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\nCaused by op 'locally_connected2d_2_1/SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 175, in test_locallyconnected_2d_channels_first\r\n    input_shape=(num_samples, num_row, num_col, stack_size))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\testing_utils.py\", line 107, in layer_test\r\n    y = layer(x)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 535, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node locally_connected2d_2_1/SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](locally_connected2d_2_1/Reshape, locally_connected2d_2_1/Reshape_1)]]\r\n\r\n\r\n======================================================================\r\nERROR: test_locallyconnected_implementation (__main__.LocallyConnectedLayersTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1275, in _run_fn\r\n    self._extend_graph()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1312, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 262, in test_locallyconnected_implementation\r\n    rtol=1e-5, atol=1e-5)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1489, in assertAllCloseAccordingToType\r\n    a = self._GetNdArray(a)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1323, in _GetNdArray\r\n    a = self.evaluate(a)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1035, in evaluate\r\n    return sess.run(tensors)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 877, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\nCaused by op 'SparseMatMul', defined at:\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 451, in <module>\r\n    test.main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\test.py\", line 64, in main\r\n    return _googletest.main(argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 100, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\benchmark.py\", line 344, in benchmarks_main\r\n    true_main()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 99, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\platform\\googletest.py\", line 70, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\main.py\", line 256, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\runner.py\", line 176, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 84, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\suite.py\", line 122, in run\r\n    test(result)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 653, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\unittest\\case.py\", line 605, in run\r\n    testMethod()\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 776, in decorated\r\n    f(self, **kwargs)\r\n  File \"tensorflow-1.11.0\\tensorflow\\python\\keras\\layers\\local_test.py\", line 260, in test_locallyconnected_implementation\r\n    out_2 = model_2.call(inputs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 232, in call\r\n    inputs, training=training, mask=mask)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 250, in _call_and_compute_mask\r\n    x = layer.call(x, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 247, in call\r\n    self.compute_output_shape(inputs.shape))\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py\", line 701, in local_conv_matmul\r\n    output_flat = K.math_ops.sparse_matmul(inputs_flat, kernel, b_is_sparse=True)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 7887, in sparse_mat_mul\r\n    b_is_sparse=b_is_sparse, name=name)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Wani\\Downloads\\py366\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SparseMatMul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n         [[{{node SparseMatMul}} = SparseMatMul[Ta=DT_FLOAT, Tb=DT_FLOAT, a_is_sparse=false, b_is_sparse=true, transpose_a=false, transpose_b=false](Reshape_33, Reshape_34)]]\r\n\r\n\r\n----------------------------------------------------------------------\r\nRan 8 tests in 5.641s\r\n\r\nFAILED (errors=4)\r\n```", "@nehaljwani It looks like some of the required packages are missing. Could you install the latest TensorFlow version? Also, make sure to follow the instructions I mentioned above and report any errors here.", "Closing as this is resolved, free to reopen if problem persists.", "@wt-huang I can reproduce the same error with the exact same steps with v1.12.0\r\n\r\nPlease re-open this issue, as I don't seem to have permissions to do so.", "I also have the same issue on Windows 10 64bit.  I have tried with v1.12.0-gpu, tf-nightly 1.13.0.dev20181128, tf-nightly-gpu 1.13.0.dev20181127 and built from source with gpu enabled from git commit 567c0692de but all have no registered kernels for SparseMatMul.", "@wt-huang Could we please re-open this issue? TF Addons is experiencing the same issue on our newly added windows builds. This is occurring when using `tf-nightly`\r\n\r\nAlso could you expand on this:\r\n> It looks like some of the required packages are missing."]}, {"number": 22698, "title": "missing tf.keras.utils.OrderedEnqueuer in the builded tensorflow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: no cuda\r\n- **GPU model and memory**: no GPU\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI have recently added a PR https://github.com/tensorflow/tensorflow/pull/19183 that was supposed to add a possibility to use OrderedEnqueuer directly as `tf.keras.utils.OrderedEnqueuer`, but I have noticed that this actually did not help and that the `tensorflow.python.keras.utils.__init__.py` is actually not used and there is insted generated some other file created by `tensorflow/python/tools/api/generator/create_python_api.py`.\r\n\r\n```\r\n# This file is MACHINE GENERATED! Do not edit.\r\n# Generated by: tensorflow/python/tools/api/generator/create_python_api.py script.\r\n\"\"\"Keras utilities.\r\n\"\"\"\r\n\r\nfrom __future__ import print_function\r\n\r\nfrom tensorflow.python.keras.activations import deserialize_keras_object\r\nfrom tensorflow.python.keras.callbacks import Progbar\r\nfrom tensorflow.python.keras.callbacks import Sequence\r\nfrom tensorflow.python.keras.constraints import serialize_keras_object\r\nfrom tensorflow.python.keras.datasets.boston_housing import get_file\r\nfrom tensorflow.python.keras.engine.training_generator import GeneratorEnqueuer\r\nfrom tensorflow.python.keras.models import CustomObjectScope\r\nfrom tensorflow.python.keras.utils import HDF5Matrix\r\nfrom tensorflow.python.keras.utils import SequenceEnqueuer\r\nfrom tensorflow.python.keras.utils import convert_all_kernels_in_model\r\nfrom tensorflow.python.keras.utils import custom_object_scope\r\nfrom tensorflow.python.keras.utils import get_custom_objects\r\nfrom tensorflow.python.keras.utils import multi_gpu_model\r\nfrom tensorflow.python.keras.utils import normalize\r\nfrom tensorflow.python.keras.utils import plot_model\r\nfrom tensorflow.python.keras.utils import to_categorical\r\n\r\ndel print_function\r\n``` \r\n\r\n### My question:\r\nCould someone point me to some resource where I can find some guide of how is `tensorflow.keras.utils.__init__.py` being generated?\r\nWhat might possibly be the problem that it isn't propagated from `tensorflow.python.keras.utils.__init__.py` to `tensorflow.keras.utils.__init__.py` in the pre-build tensorlow-package?\r\n\r\nI'm not sure how much is this related, but I went through `tensorflow/tensorflow/tools/api/golden/v1` and `tensorflow/tensorflow/tools/api/golden/v2` and it looks like there is `OrderedEnqueuer` in both folders.\r\n\r\nIs there any other place where I have to set that `OrderedEnqueuer` should be generated in `tensorflow.keras.utils.__init__.py`. I was thinking also about https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/BUILD file, but I'm not sure how it works.\r\n\r\nThank you in advance for pointing me to some relevant resources.", "comments": ["**update:**\r\nWhen I install tensorflow as `pip install tf-nightly` then API appears to be correctly generated.\r\n\r\nIs there some other process used for generating tf-nightly packages and new tensorflow stable versions?", "Problem solved and explained in https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/J3GYiKkQ-uI"]}, {"number": 22697, "title": "Keras Mobilenet not loading after save", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n    - Yes, though very basic\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n    - Mac OSX 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n    - N/A\r\n- **TensorFlow installed from (source or binary)**:\r\n    - pip install tf-nightly\r\n- **TensorFlow version (use command below)**:\r\n    - v1.9.0-rc2-4942-g19b2383cc0 1.12.0-dev20180929\r\n- **Python version**:\r\n    - 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n    - N/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\n    - N/A\r\n- **CUDA/cuDNN version**:\r\n    - N/A\r\n- **GPU model and memory**:\r\n    - N/A\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nfrom tensorflow import keras\r\nmodel = keras.applications.MobileNet()\r\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\r\nmodel.save('./model.h5')\r\nloaded_model = keras.models.load_model('./model.h5')\r\n```\r\n\r\n### Describe the problem\r\n\r\nKeras mobilenet_v1 model will not load after saving (see code sample above). An error is thrown in advanced_activations when loading a ReLU layer with a max_value parameter because the parameters are not of the expected type (float or None). They are a dict because that's how they were read from the config. The dict looks like this: {'type': 'ndarray', 'value': 6.0} but really should just be a float. This error occurs with the nightly build and also in 1.11.\r\n\r\n### Source code / logs\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"error.py\", line 5, in <module>\r\n    loaded_model = keras.models.load_model('./model.h5')\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\r\n    model = model_from_config(model_config, custom_objects=custom_objects)\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1292, in from_config\r\n    process_layer(layer_data)\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1278, in process_layer\r\n    layer = deserialize_layer(layer_data, custom_objects=custom_objects)\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 175, in deserialize_keras_object\r\n    return cls.from_config(config['config'])\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1617, in from_config\r\n    return cls(**config)\r\n  File \"tmp_env/lib/python3.6/site-packages/tensorflow/python/keras/layers/advanced_activations.py\", line 309, in __init__\r\n    if max_value is not None and max_value < 0.:\r\nTypeError: '<' not supported between instances of 'dict' and 'float'\r\n```", "comments": ["@mhwilder Hi, I understand that you are facing the similar issue with nightly build also. Can you please give a try with a lower version of tensorflow and let us know if you still face this issue.", "@harshini-gadige I just verified that I get the same error in TensorFlow version 1.11.0. I haven't tried earlier versions than that.", "@harshini-gadige @fchollet  I'm also seeing this with the `MobileNetV2` model. I see it when using the `tf.keras.load_model` with version `tf.keras.__version__ = 2.1.6-tf`. However, when using `keras.load_model` with version `keras.__version__ = 2.2.4` it loads the model properly. \r\n\r\n**Update: 10/16/18**\r\nI've actually determined that `tf.keras.models.save_model` generates models that cannot be read by either pure `keras.models.load_model` or `tf.keras.models.load_model` when working with MobileNetV1/2 based networks. \r\n\r\nHope that helps!", "hi i have the same issue can\u00b4t load my model,  i was  working whit mobilnetV2 with keras 2.2.4 version and tensorflow 1.10.0 version \u00bf do you have any solution ? \r\ni downgrade tensorflow to 1.9.0 version and still have the same problem \r\n\u00bfAny recommendation? \r\n", "This issue is still a problem but here's the workaround I've been using. It's not really the right solution, but at least my mobilenet V1 and V2 models can be reloaded. I agree with @mevatron that the problem is probably in how the model is being saved (specifically, the format used for the ReLu parameters).\r\n\r\n**Temporary Fix:**\r\nAfter the ```super()``` call in the ReLu ```init()``` function in _tensorflow/python/keras/layers/advanced\\_activations.py_ (around line 310), add the following lines of code:\r\n```\r\n    if type(max_value) is dict:\r\n        max_value = max_value['value']\r\n    if type(negative_slope) is dict:\r\n        negative_slope = negative_slope['value']\r\n    if type(threshold) is dict:\r\n        threshold = threshold['value']\r\n```", "I've had the same problem and found that since Tensorflow 1.12.0 you can [directly export Keras models to the SavedModel format](https://github.com/tensorflow/tensorflow/releases).\r\n\r\nUsing this new feature, I can successfully save and load my Mobilenet models. \r\n\r\nNote that if you save models like this, Tensorflow recommends an optimizer from `tf.train`, instead of the Keras optimizer.\r\n\r\n```\r\nimport tensorflow as tf\r\nmodel = tf.keras.applications.MobileNet()\r\nmodel.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy')\r\noutput_path = tf.contrib.saved_model.save_keras_model(model, './tmp_dir')\r\nloaded_model = tf.contrib.saved_model.load_keras_model(output_path)\r\n```", "For some purposes (for example, for using in another keras-compatible frameworks) you may want to save model exactly in hdf5 format. \r\nTo save model with ReLU layer in hdf5 format using tensorflow implementation of keras one can replace:\r\n```\r\n    config = {\r\n        'max_value': self.max_value,\r\n        'negative_slope': self.negative_slope,\r\n        'threshold': self.threshold\r\n    }\r\n```\r\nwith:\r\n```\r\n    max_value = None if self.max_value is None else float(self.max_value)\r\n    config = {\r\n        'max_value': max_value,\r\n        'negative_slope': float(self.negative_slope),\r\n        'threshold': float(self.threshold)\r\n    }\r\n```\r\nin get_config method of ReLU class in tensorflow/python/keras/layers/advanced_activations.py (around line 332).\r\nAfter that it can be loaded with keras.models.load_model.\r\n\r\nEverything works fine with native keras version=2.2.4 as @mevatron mentioned. It happens cause of difference in realisation of function get_json_type (in tensorflow/tensorflow/python/util/serialization.py and keras/keras/engine/saving.py)", "> ```\r\n> import tensorflow as tf\r\n> model = tf.keras.applications.MobileNet()\r\n> model.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy')\r\n> output_path = tf.contrib.saved_model.save_keras_model(model, './tmp_dir')\r\n> loaded_model = tf.contrib.saved_model.load_keras_model(output_path)\r\n> ```\r\n\r\nYou are a lifesaver, thank you! This worked for me with TF 1.12 and python 3.6.", "> This issue is still a problem but here's the workaround I've been using. It's not really the right solution, but at least my mobilenet V1 and V2 models can be reloaded. I agree with @mevatron that the problem is probably in how the model is being saved (specifically, the format used for the ReLu parameters).\r\n> \r\n> **Temporary Fix:**\r\n> After the `super()` call in the ReLu `init()` function in _tensorflow/python/keras/layers/advanced_activations.py_ (around line 310), add the following lines of code:\r\n> \r\n> ```\r\n>     if type(max_value) is dict:\r\n>         max_value = max_value['value']\r\n>     if type(negative_slope) is dict:\r\n>         negative_slope = negative_slope['value']\r\n>     if type(threshold) is dict:\r\n>         threshold = threshold['value']\r\n> ```\r\n\r\nThanks a lot, It started loading mobilenet_v2 models :100: \r\ncan you explain why this is not a right solution and what are the disadvantages of using it?@mhwilder", "Hi! Thanks for that wonderful temporary fix!! BTW, is there any formal fix now?", "This is still not fixed and on 1.12 and 1.13 the newly loaded model actually just produces random results if not in the session that trained the model.", "This is fixed with TF version 1.15 and in TF 2. Thanks!", "> I've had the same problem and found that since Tensorflow 1.12.0 you can [directly export Keras models to the SavedModel format](https://github.com/tensorflow/tensorflow/releases).\r\n> \r\n> Using this new feature, I can successfully save and load my Mobilenet models.\r\n> \r\n> Note that if you save models like this, Tensorflow recommends an optimizer from `tf.train`, instead of the Keras optimizer.\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> model = tf.keras.applications.MobileNet()\r\n> model.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy')\r\n> output_path = tf.contrib.saved_model.save_keras_model(model, './tmp_dir')\r\n> loaded_model = tf.contrib.saved_model.load_keras_model(output_path)\r\n> ```\r\n\r\nThanks a lot!!...You saved my life.", "Verify  if the model using token or any object to train, in the new version of tensorflow don\u00b4t have problem. My sugest , serialize the objetcs using picle like the code below . \r\n\r\nimport pickle\r\n\r\nwith open('Percentage_'+ str(percentageData) +  '/train_dataframe', \"wb\") as f:\r\n    pickle.dump(train_dataframe, f)\r\n\r\nAnd use de model.save and tf.keras.models.load_model"]}, {"number": 22696, "title": "Update README.md", "body": "Fix sentence structure", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 22695, "title": "Tensorflow C API: SessionRun() latency", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04 lts\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.16\r\n- **GCC/Compiler version (if compiling from source)**: 7.3.0\r\n- **CUDA/cuDNN version**: 9.2 / 7.3\r\n- **GPU model and memory**: Nvidia GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\n- **Exact command to reproduce**: compile and execute my code\r\n\r\n### Describe the problem\r\nScenario:\r\nVGG16 from Tensorflow C API. We would like to inference a (potentially) different number of frames for each execution of \r\nSessionRun(), To do so we are allocating a tensor that holds data for the frames to execute (dimensions n_frames x 50 x 50 x 3).\r\n\r\nObserved behavior and questions:\r\n1. for a given n_frames, e.g. n_frames = 3, executing SessionRun() n times gives a time profiling like this:\r\n~141ms\r\n~3.8ms\r\n~3.8ms\r\n....\r\n//n times\r\n\r\nWe are assuming the 1st  SessionRun() takes longer to upload the graph on GPU. Is that correct?\r\n\r\n2. if we run a pattern like this:\r\nn_frames = 3 --> call SessionRun() n times\r\nn_frames = 3 --> call SessionRun() n times\r\nn_frames = 1 --> call SessionRun() n times\r\n\r\nthe time profiling is like this:\r\n~141ms\r\n~3.8ms\r\n~3.8ms\r\n....\r\n//n times\r\n~3.8ms\r\n~3.8ms\r\n~3.8ms\r\n....\r\n//n times\r\n**~70ms**\r\n~3.8ms\r\n~3.8ms\r\n....\r\n//n times\r\n\r\nIt looks like every time the input tensor size changes, something happens and the 1st execution takes longer.\r\nQuestion:\r\nAssuming that my application scenario is n_frames = 32 is the largest size for the input tensor is there a way \r\nto \"reserve\" GPU resources to get the same inference time (~3.8ms in the example) even though the actual tensor parameter passed to SessionRun() is smaller (i.e. n_frames = 1, n_frames= 2, etc...)\r\n\r\n\r\n\r\n### Source code / logs\r\n```\r\n#include \"tensorflow/c/c_api.h\"\r\n\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <memory.h>\r\n#include <string.h>\r\n#include <assert.h>\r\n#include <vector>\r\n#include <algorithm>\r\n#include <iterator>\r\n#include <iostream>\r\n\r\n\r\nTF_Buffer* read_file(const char* file);\r\n\r\nvoid free_buffer(void* data, size_t length) {\r\n}\r\n\r\nstatic void Deallocator(void* data, size_t length, void* arg) {\r\n}\r\n\r\nint main() {\r\n  TF_Buffer* graph_def = read_file(\"data/graph.pb\");\r\n  TF_Graph* graph = TF_NewGraph();\r\n\r\n  TF_Status* status = TF_NewStatus();\r\n  TF_ImportGraphDefOptions* graph_opts = TF_NewImportGraphDefOptions();\r\n  TF_GraphImportGraphDef(graph, graph_def, graph_opts, status);\r\n  if (TF_GetCode(status) != TF_OK) {\r\n          fprintf(stderr, \"ERROR: Unable to import graph %s\", TF_Message(status));\r\n          return 1;\r\n  }\r\n  else {\r\n          fprintf(stdout, \"Successfully imported graph\\n\");\r\n  }\r\n  const int num_bytes_in = 1 * 50 * 50 * 3 * sizeof(float);\r\n  const int num_bytes_out = 1 * 2 * sizeof(float);\r\n\r\n  int64_t in_dims[] = {3, 50, 50, 3};\r\n  int64_t out_dims[] = {3, 2};\r\n\r\n  int64_t in_dims2[] = {2, 50, 50, 3};\r\n  int64_t out_dims2[] = {2, 2};\r\n\r\n  float values[3 * 50 * 50 * 3] = {0xff};\r\n  float values2[2 * 50 * 50 * 3] = {0xff};\r\n\r\n  std::vector<TF_Output> inputs;\r\n  std::vector<TF_Tensor*> input_values;\r\n  std::vector<TF_Tensor*> input_values2;\r\n\r\n  inputs.push_back({TF_GraphOperationByName(graph, \"input_1\"), 0});\r\n  input_values.push_back(TF_NewTensor(TF_FLOAT, in_dims, 4, values, num_bytes_in, &Deallocator, 0));\r\n  input_values2.push_back(TF_NewTensor(TF_FLOAT, in_dims, 4, values2, num_bytes_in, &Deallocator, 0));\r\n\r\n  std::vector<TF_Output> outputs;\r\n  outputs.push_back({TF_GraphOperationByName(graph, \"dense_3/Softmax\"), 0});\r\n\r\n  std::vector<TF_Tensor*> output_values;\r\n\r\n  output_values.push_back(TF_AllocateTensor(TF_FLOAT, out_dims, 2, num_bytes_out));\r\n  output_values.push_back(TF_AllocateTensor(TF_FLOAT, out_dims, 2, num_bytes_out));\r\n\r\n  fprintf(stdout, \"Running session...\\n\");\r\n  TF_SessionOptions* sess_opts = TF_NewSessionOptions();\r\n  TF_Session* session = TF_NewSession(graph, sess_opts, status);\r\n  assert(TF_GetCode(status) == TF_OK);\r\n\r\n  // about 140ms\r\n  TF_SessionRun(session, nullptr,\r\n                &inputs[0], &input_values[0], 1,\r\n                &outputs[0], &output_values[0], 1,\r\n                nullptr, 0, nullptr, status);\r\n  // about 3ms\r\n  TF_SessionRun(session, nullptr,\r\n                &inputs[0], &input_values[0], 1,\r\n                &outputs[0], &output_values[0], 1,\r\n                nullptr, 0, nullptr, status);\r\n  // about 3ms\r\n  TF_SessionRun(session, nullptr,\r\n                &inputs[0], &input_values[0], 1,\r\n                &outputs[0], &output_values[0], 1,\r\n                nullptr, 0, nullptr, status);\r\n\r\n  // n times...\r\n  // ...\r\n\r\n  // NOW CHANGES TENSOR DIMENSIONS ---> about 70 ms\r\n  TF_SessionRun(session, nullptr,\r\n                &inputs[0], &input_values2[0], 1,\r\n                &outputs[0], &output_values2[0], 1,\r\n                nullptr, 0, nullptr, status);\r\n\r\n  // about 3ms\r\n  TF_SessionRun(session, nullptr,\r\n                &inputs[0], &input_values2[0], 1,\r\n                &outputs[0], &output_values2[0], 1,\r\n                nullptr, 0, nullptr, status);\r\n\r\n  // n times...\r\n  // ...\r\n\r\n  TF_Code c = TF_GetCode(status);\r\n\r\n  std::cout << c << std::endl;\r\n\r\n  for(size_t i = 0; i < output_values.size(); ++i)\r\n  {\r\n      if (output_values.at(i) == nullptr)\r\n      {\r\n          std::cout << \"bad parameters\" << std::endl;\r\n      }\r\n      else\r\n      {\r\n          const auto data = static_cast<float*>(TF_TensorData(output_values.at(i)));\r\n          std::cout << ((data[1] > 0.5f) ? true : false) << std::endl;\r\n      }\r\n  }\r\n\r\n  fprintf(stdout, \"Successfully run session\\n\");\r\n\r\n  TF_CloseSession(session, status);\r\n  TF_DeleteSession(session, status);\r\n  TF_DeleteSessionOptions(sess_opts);\r\n  TF_DeleteImportGraphDefOptions(graph_opts);\r\n  TF_DeleteGraph(graph);\r\n  TF_DeleteStatus(status);\r\n  return 0;\r\n}\r\n\r\nTF_Buffer* read_file(const char* file) {\r\n  FILE *f = fopen(file, \"rb\");\r\n  fseek(f, 0, SEEK_END);\r\n  long fsize = ftell(f);\r\n  fseek(f, 0, SEEK_SET);  //same as rewind(f);\r\n\r\n  void* data = malloc(fsize);\r\n  fread(data, fsize, 1, f);\r\n  fclose(f);\r\n\r\n  TF_Buffer* buf = TF_NewBuffer();\r\n  buf->data = data;\r\n  buf->length = fsize;\r\n  buf->data_deallocator = free_buffer;\r\n  return buf;\r\n}\r\n```\r\n", "comments": ["@EnricoGiordano1992 If you are trying to make inference time the same across different `SessionRun()` even if n is smaller, could just use timer then add sleep for each session if needed, e.g. use `time.sleep()` to control the timing for each session. \r\n\r\nThe first `SessionRun()` takes longer than the subsequent ones as the program needs to pass the data.", "Closing this, feel free to reopen if problem persists."]}, {"number": 22694, "title": "r1.11 failed to build on debian", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:debian stretch\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:r1.11\r\n- **Python version**:2.7.13\r\n- **Bazel version (if compiling from source)**:0.17.2\r\n- **GCC/Compiler version (if compiling from source)**:6.3.0 20170516 (Debian 6.3.0-18+deb9u1)\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**: radeon RV370 256Mo\r\n- CPU : Ryzen 5-1600 with 8Gb\r\n- **Exact command to reproduce**: bazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\ncompilation fails.\r\nIs there a specific version of protobuf to use  ?\r\n\r\n### Source code / logs\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /media/travail/tensorflow/tensorflow/contrib/tensorrt/BUILD:124:1: Executing genrule //tensorflow/contrib/tensorrt:trt_engine_op_pygenrule failed (Exit 127)\r\nbazel-out/host/bin/tensorflow/contrib/tensorrt/gen_trt_engine_op_py_wrappers_cc: symbol lookup error: bazel-out/host/bin/tensorflow/contrib/tensorrt/gen_trt_engine_op_py_wrappers_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 231.846s, Critical Path: 52.14s\r\nINFO: 38 processes: 38 local.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["Hi, did you solve this problem? And would you like to tell me the way you solve it?", "No. Fortunately, I have an r1.8 as a rescue.", "When building from sources, it will download and build its own protobuf.\r\nAre you trying to build with GPU support?", "I installed protobuf from sources. I'll try without it to see how it goes.\r\nI enabled OpenCL with trisyscl support.", "We have not looked into building with trisycl at all. That is a configuration supported purely by the community.\r\nI am guessing the issue is isolated to that build configuration.", "Hi @theedge456 !We see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.6 version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22694\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22694\">No</a>\n"]}, {"number": 22693, "title": "Update README.md", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "Nagging Assignee @rmlarsen: It has been 61 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 22692, "title": "How to train multi-gpu on tensorflow using nccl library?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nYes\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nLocal custom build PC\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.10\r\n\r\n- **Python version**:\r\n3.5\r\n\r\n- **Bazel version (if compiling from source)**:\r\nNo\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n\r\n- **CUDA/cuDNN version**:\r\n9.0/7.2\r\n\r\n- **GPU model and memory**:\r\nTwo GTX 1080 Ti each with 11G of memory \r\n\r\n- **Exact command to reproduce**:\r\nIDK\r\n\r\n### Describe the problem:\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI was wondering if you could provide a **tutorial** on how to train a simple CNN on multiple gpus on MNIST, or Cifar dataset that also explains how to use the **nccl library**.\r\nThe only tutorials available are the following: **https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101**\r\n**http://blog.s-schoener.com/2017-12-15-parallel-tensorflow-intro/**\r\n\r\n**https://proteusmaster.urcf.drexel.edu/urcfwiki/index.php/Job_Script_Example_09_TensorFlow_MNIST_Multi-GPU-CNN**\r\nNone of which explains how to use nccl.\r\n\r\n\r\nI also search for an answer on many websites but the only one i found is this from openai in Chinese:\r\nhttp://openresearch.ai/t/nccl-efficient-tensorflow-multigpu-training/159\r\n\r\nAlthough 1/6 of the population of earth does speak Chinese, the other 5/6 does not! So i was wondering if someone in tensorflow team that knows English and perhaps Chinese could help with this issue. Thank you. I would also appreciate if you do me a favor and do not refer or pass me to stackoverflow. Thanks again.\r\n ", "comments": ["@tfboyd  I am wondering if there is a way to do this without using the estimator api. Since in estimator api there is no flexibility and one cannot use it for deep research projects.\r\n\r\nBased on the complaint I have seen about tensorflow, i guess people in the community do not have any voice and tensorflow does what it does regardless of the needs of the community. ", "From your [comment](https://github.com/tensorflow/tensorflow/issues/10723) linked below did not mention you could not use Estimator.  I understand your frustration. We spend a lot of time listening to the community and sometimes we fail to get it correct.  A lot of people want easy multi-gpu and the best way to do that was via Estimator or Keras that can then handle all the little details.  For some top researchers, mostly in performance, they would use the tf_cnn_benchmarks approaches and build from them to add custom logic to some some really neat tricks.  The issue with that is the code is hard to follow as it is a sandbox to test new ideas.  The site you linked is **not** OpenAI (Elan Musk) and while I did not take time to read it closely I think the code snippets are from tf_cnn_benchmarks.  Reasons we wrapped it:\r\n\r\n@anj-s \r\nCan you provide any info on using distribution strategies without Estimator or Keras?\r\n\r\nBest of luck finding what you need.\r\n", "@tfboyd Thank you so much for your answer. I certainly can write my code with Keras. But based on what i have read on Tensorflows latest documentation in order to be able to use all_reduce I have to go back to Estimators, which is what i would prefer to avoid. I would greatly appreciate if you can help me find a way to tune the code in **https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py** so that I could use the all_reduce functionality as well even if it might add some complicated code.\r\n\r\nThe Chinese link i shared above has the following code snippets:\r\n\r\n    def allreduce_grads(all_grads, average=True):\r\n        from tensorflow.contrib import nccl\r\n        nr_tower = len(all_grads)\r\n        if nr_tower == 1:\r\n            return all_grads\r\n        new_all_grads = []  # N x K\r\n        for grads in zip(*all_grads):\r\n            summed = nccl.all_sum(grads)\r\n\r\n            grads_for_devices = []  # K\r\n            for g in summed:\r\n                with tf.device(g.device):\r\n                    # tensorflow/benchmarks didn't average gradients\r\n                   if average:\r\n                       g = tf.multiply(g, 1.0 / nr_tower, name='allreduce_avg')\r\n                grads_for_devices.append(g)\r\n            new_all_grads.append(grads_for_devices)\r\n\r\n        # transpose to K x N\r\n        ret = list(zip(*new_all_grads))\r\n        return ret](url)", "The link is not Chinese (it's Korean).\r\n\r\nI wrote the snippet above originally in tensorpack: https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/utils.py#L140-L170.\r\nYou can probably use it for multigpu training very easily: just do `tf.gradients` on each GPU, then call this function to reduce them. It is used in [this file](https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/training.py#L240).", "The link I provided also showed Keras, it was at the top of the document I linked for you.  @ppwwyyxx  Apologies for guessing the snippets were from the benchmark code.  Big thanks for sharing as always.", "@tfboyd You can try using DistributionStrategy APIs directly and your code snippet should look something like this:\r\n  ```\r\n    with my_distribution.scope():\r\n      iterator = my_distribution.distribute_dataset(\r\n          dataset).make_one_shot_iterator()\r\n      tower_train_ops = my_distribution.call_for_each_tower(\r\n          tower_fn, iterator.get_next())\r\n      train_op = tf.group(my_distribution.unwrap(tower_train_ops))\r\n``` \r\n\r\nIf you use MirroredStrategy for distributing your model on multiple GPUs on a single machine DistributionStrategy handles aggregating gradients using allreduce. \r\n\r\nFrom the above conversation it seems like @kazemSafari wants to implement the allreduce functionality. Hence I am not sure if using DistributionStrategy API directly will help.  \r\n\r\n\r\n", "@tfboyd Thank you so much again. I saw MirroredStrategy is indeed available in Keras on its own. I will let you know if I have more questions.\r\n\r\n@anj-s Hi thank you for your explanation. I was wondering if I you could provide a simple example using MirroredStrategy say on a simple dataset like mnist with a simple one layer network that doesn't use estimator or Keras and just using tensorflow.\r\n", "@ppwwyyxx Thank you for sharing the code. Sorry about my comment. I was trying to follow the code you shared on mnist with a simple mlp:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef get_shape(tensor):\r\n    return tensor.get_shape().as_list()\r\n\r\n\r\n# Source:\r\n# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\r\ndef get_available_gpus():\r\n    \"\"\"\r\n        Returns a list of the identifiers of all visible GPUs.\r\n    \"\"\"\r\n    from tensorflow.python.client import device_lib\r\n    local_device_protos = device_lib.list_local_devices()\r\n    return [x.name for x in local_device_protos if x.device_type == 'GPU']\r\n\r\n\r\nPS_OPS = [\r\n    'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\r\n    'MutableHashTableOfTensors', 'MutableDenseHashTable'\r\n]\r\n\r\n\r\n# see https://github.com/tensorflow/tensorflow/issues/9517\r\ndef assign_to_device(device, ps_device):\r\n    \"\"\"Returns a function to place variables on the ps_device.\r\n\r\n    Args:\r\n        device: Device for everything but variables\r\n        ps_device: Device to put the variables on. Example values are /GPU:0 and /CPU:0.\r\n\r\n    If ps_device is not set then the variables will be placed on the default device.\r\n    The best device for shared varibles depends on the platform as well as the\r\n    model. Start with CPU:0 and then test GPU:0 to see if there is an\r\n    improvement.\r\n    \"\"\"\r\n    def _assign(op):\r\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\r\n        if node_def.op in PS_OPS:\r\n            return ps_device\r\n        else:\r\n            return device\r\n    return _assign\r\n\r\n\r\ndef device_options():\r\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\r\n    with tf.Session(config=config) as sess:\r\n        # your code here\r\n        pass\r\n\r\n\r\n# Source:\r\n# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101\r\ndef average_gradients(tower_grads):\r\n    \"\"\"Calculate the average gradient for each shared variable across all towers.\r\n    Note that this function provides a synchronization point across all towers.\r\n    Args:\r\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list ranges\r\n        over the devices. The inner list ranges over the different variables.\r\n    Returns:\r\n            List of pairs of (gradient, variable) where the gradient has been averaged\r\n            across all towers.\r\n    \"\"\"\r\n    average_grads = []\r\n    for grad_and_vars in zip(*tower_grads):\r\n\r\n        # Note that each grad_and_vars looks like the following:\r\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\r\n        grads = [g for g, _ in grad_and_vars]\r\n        grad = tf.reduce_mean(grads, 0)\r\n\r\n        # Keep in mind that the Variables are redundant because they are shared\r\n        # across towers. So .. we will just return the first tower's pointer to\r\n        # the Variable.\r\n        v = grad_and_vars[0][1]\r\n        grad_and_var = (grad, v)\r\n        average_grads.append(grad_and_var)\r\n    return average_grads\r\n\r\n\r\n# Source\r\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/utils.py#L140-L170\r\n#################################\r\ndef split_grad_list(grad_list):\r\n    \"\"\"\r\n    Args:\r\n        grad_list: K x N x 2\r\n    Returns:\r\n        K x N: gradients\r\n        K x N: variables\r\n    \"\"\"\r\n    g = []\r\n    v = []\r\n    for tower in grad_list:\r\n        g.append([x[0] for x in tower])\r\n        v.append([x[1] for x in tower])\r\n    print(\"g: \")\r\n    print(g)\r\n    print(\"v: \")\r\n    print(v)\r\n    return g, v\r\n\r\n\r\ndef merge_grad_list(all_grads, all_vars):\r\n    \"\"\"\r\n    Args:\r\n        all_grads (K x N): gradients\r\n        all_vars(K x N): variables\r\n    Return:\r\n        K x N x 2: list of list of (grad, var) pairs\r\n    \"\"\"\r\n    all_towers = [list(zip(gs, vs)) for gs, vs in zip(all_grads, all_vars)]\r\n    print(\"all_towers: \")\r\n    print(all_towers)\r\n    return all_towers\r\n\r\n\r\n**def allreduce_grads(all_grads, average=True):\r\n    \"\"\"\r\n    All-reduce average the gradients among K devices. Results are broadcasted to all devices.\r\n    Args:\r\n        all_grads (K x N): List of list of gradients. N is the number of variables.\r\n        average (bool): average gradients or not.\r\n    Returns:\r\n        K x N: same as input, but each grad is replaced by the average over K devices.\r\n    \"\"\"\r\n    from tensorflow.contrib import nccl\r\n    nr_tower = len(all_grads)\r\n    if nr_tower == 1:\r\n        return all_grads\r\n    new_all_grads = []  # N x K\r\n    for grads in zip(*all_grads):\r\n        print('grads:')\r\n        print(grads)\r\n        summed = nccl.all_sum(grads)\r\n\r\n        grads_for_devices = []  # K\r\n        for g in summed:\r\n            with tf.device(g.device):\r\n                # tensorflow/benchmarks didn't average gradients\r\n                if average:\r\n                    g = tf.multiply(g, 1.0 / nr_tower)\r\n            grads_for_devices.append(g)\r\n        new_all_grads.append(grads_for_devices)\r\n\r\n    # transpose to K x N\r\n    ret = list(zip(*new_all_grads))\r\n    return ret**\r\n###########################\r\n\r\n\r\n# Source\r\n# https://github.com/tensorpack/tensorpack/blob/81a4fc332eeae7e230e0736958014a0958fca822/tensorpack/graph_builder/training.py#L240\r\ndef apply_gradients(opt, grads):\r\n    devices = get_available_gpus()\r\n    # num_gpus = len(devices)\r\n    raw_devices = ['/gpu:{}'.format(k) for k in devices]\r\n    # optimizer using NCCL\r\n    train_ops = []\r\n    with tf.name_scope('apply_gradients'):\r\n        for idx, grad_and_vars in enumerate(grads):\r\n            with tf.device(raw_devices[idx]):\r\n                # apply_gradients may create variables. Make them LOCAL_VARIABLES\r\n                # with override_to_local_variable(enable=idx > 0):\r\n                train_ops.append(opt.apply_gradients(\r\n                    grad_and_vars, name='apply_grad_{}'.format(idx)))\r\n    train_op = tf.group(*train_ops, name='train_op')\r\n    return train_op\r\n\r\n\r\ndef create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\"):\r\n    devices = get_available_gpus()\r\n    num_gpus = len(devices)\r\n    # Place all ops on CPU by default\r\n    # with tf.device('/cpu:0'):\r\n    tower_grads = []\r\n    losses = []\r\n    # tf Graph input\r\n    # X = tf.placeholder(tf.float32, [None, num_input])\r\n    # Y = tf.placeholder(tf.float32, [None, num_classes])\r\n\r\n    # Split data between GPUs\r\n    X_s = tf.split(X, num_gpus)\r\n    Y_s = tf.split(Y, num_gpus)\r\n    # optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\r\n    # Get the current variable scope so we can reuse all variables we need once we get\r\n    # to the second iteration of the loop below\r\n    with tf.variable_scope(tf.get_variable_scope()) as outer_scope:\r\n        for i, id in enumerate(devices):\r\n            name = 'tower_{}'.format(i)\r\n            # Use the assign_to_device function to ensure that variables are created on the\r\n            # controller.\r\n            with tf.device(assign_to_device(id, controller)), tf.name_scope(name):\r\n\r\n                _x = X_s[i]\r\n                _y = Y_s[i]\r\n\r\n                logits = mnist_mlp(_x, input_flattened_dim, num_classes)\r\n\r\n                # Define loss and optimizer (with train logits, for dropout to take effect)\r\n                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\r\n                    logits=logits, labels=_y))\r\n\r\n                with tf.name_scope(\"compute_gradients\"):\r\n                    # `compute_gradients` returns a list of (gradient, variable) pairs\r\n                    grads = optimizer.compute_gradients(loss)\r\n                    tower_grads.append(grads)\r\n\r\n                losses.append(loss)\r\n                outer_scope.reuse_variables()\r\n\r\n    print(tower_grads[0])\r\n\r\n    all_grads, all_vars = split_grad_list(tower_grads)\r\n    all_grads = allreduce_grads(all_grads)\r\n    tower_grads = merge_grad_list(all_grads, all_vars)\r\n\r\n    train_op = apply_gradients(optimizer, tower_grads)\r\n    # return confusion_mat, equality_op, accuracy_op, train_op\r\n    return train_op\r\n\r\n\r\ndef mnist_mlp(x, input_flattened_dim, num_classes):\r\n\r\n    W = tf.get_variable(name='W1',\r\n                        shape=[input_flattened_dim, num_classes],\r\n                        initializer=tf.keras.initializers.glorot_uniform(seed=None),\r\n                        dtype=tf.float32)\r\n    b = tf.get_variable(name='b1',\r\n                        shape=[num_classes],\r\n                        initializer=tf.zeros_initializer(),\r\n                        dtype=tf.float32)\r\n    # Output layer, class prediction\r\n    logits = tf.nn.relu(tf.matmul(x, W) + b)\r\n\r\n    return logits\r\n\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nprint(x_train.shape)\r\n\r\nx_train = np.reshape(x_train, [x_train.shape[0], -1])\r\nprint(x_train.shape)\r\nprint(y_train.shape)\r\n\r\n\r\ninput_flattened_dim = 784\r\nnum_classes = 10\r\nlearning_rate = .0001\r\nmax_steps = 100\r\nbatch_size = 200\r\nX = tf.placeholder(tf.float32, [None, input_flattened_dim])\r\nY = tf.placeholder(tf.float32, [None, num_classes])\r\n\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat(None).batch(batch_size)\r\nprint(train_dataset)\r\niterator = train_dataset.make_one_shot_iterator()\r\n# extract an element\r\nnext_element = iterator.get_next()\r\n\r\n\r\noptimizer = tf.train.AdamOptimizer(learning_rate)\r\ntrain_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for i in range(max_steps):\r\n        batch_x, batch_y = sess.run(next_element)\r\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\r\n```\r\nBut I get the following error:\r\n```\r\n(60000, 28, 28)\r\n(60000, 784)\r\n(60000,)\r\n<BatchDataset shapes: ((?, 784), (?,)), types: (tf.float64, tf.uint8)>\r\n2018-10-04 17:02:35.991165: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-10-04 17:02:36.080553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-10-04 17:02:36.080933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.13GiB\r\n2018-10-04 17:02:36.154460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-10-04 17:02:36.154821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.76GiB\r\n2018-10-04 17:02:36.155558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n2018-10-04 17:02:36.480714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-04 17:02:36.480738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \r\n2018-10-04 17:02:36.480743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \r\n2018-10-04 17:02:36.480746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \r\n2018-10-04 17:02:36.480964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-10-04 17:02:36.555074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n[(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)]\r\ng: \r\n[[<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>], [<tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>]]\r\nv: \r\n[[<tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>], [<tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>]]\r\ngrads:\r\n(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>)\r\ngrads:\r\n(<tf.Tensor 'tower_0/compute_gradients/gradients/tower_0/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Tensor 'tower_1/compute_gradients/gradients/tower_1/add_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>)\r\nall_towers: \r\n[[(<tf.Tensor 'Mul:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'Mul_2:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)], [(<tf.Tensor 'Mul_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'W1:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'Mul_3:0' shape=(10,) dtype=float32>, <tf.Variable 'b1:0' shape=(10,) dtype=float32_ref>)]]\r\n2018-10-04 17:02:38.038636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1\r\n2018-10-04 17:02:38.038690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-04 17:02:38.038695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 \r\n2018-10-04 17:02:38.038699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y \r\n2018-10-04 17:02:38.038701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N \r\n2018-10-04 17:02:38.038823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-10-04 17:02:38.038988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 270, in <module>\r\n    train_op = create_parallel_optimization(X, Y, input_flattened_dim, num_classes, optimizer, controller=\"/cpu:0\")\r\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 220, in create_parallel_optimization\r\n    train_op = apply_gradients(optimizer, tower_grads)\r\n  File \"/home/kazem/PycharmProjects/Prasad/multi_gpu_example.py\", line 164, in apply_gradients\r\n    with tf.device(raw_devices[idx]):\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 59, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 4085, in device\r\n    device_function = pydev.merge_device(device_name_or_function)\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 284, in merge_device\r\n    spec = DeviceSpec.from_string(spec or \"\")\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 230, in from_string\r\n    return DeviceSpec().parse_from_string(spec)\r\n  File \"/home/kazem/tf1.10_p3/lib/python3.5/site-packages/tensorflow/python/framework/device.py\", line 165, in parse_from_string\r\n    self.device_index = int(y[1])\r\n**ValueError: invalid literal for int() with base 10:** ''\r\n```\r\n\r\nCould you provide me with a simple example of using all_reduce. Thanks again.", "Your error is from the invalid device name generated in your code at this line:\r\n```\r\n    raw_devices = ['/gpu:{}'.format(k) for k in devices]\r\n```\r\nIn your code, `devices` already contain device names therefore you should not add `/gpu:` to it.", "@ppwwyyxx Thanks. It works in the simple example. but i couldn't figure out how to use batch normalization or print accuracy. It also seems to scale poorly in performance. So I guess i have to go the route of using Keras. Thanks again.", "There are other things to do to scale in addition to using nccl. That's why there are tensorflow/benchmarks, distribution strategy (and tensorpack as well) to do the other necessary work to scale.\r\n\r\nGoing back to the original issue, I also hope to see some examples that use distribution strategy without Estimator or Keras.", "@ppwwyyxx Could provide me with some information about the things and factors i need to know to help scale up?\r\nor maybe refer me to a place where i can learn more about them and how to implement them as well. Since i was training an RGAN for a company i was interning at this summer and we found out that it is very challenging to scale up performance even though we used tfrecords. ", "Nagging Assignee @anj-s: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@kazemSafari   heads up there is an API being reviewed to give access to multi-gpu API without other wrappers.  You may want to look at it to see how it may fit your needs/wants.\r\n\r\nhttps://github.com/tensorflow/community/pull/25\r\n\r\n"]}, {"number": 22691, "title": "Fix spelling 'a estimator' to 'an estimator'", "body": "Fix vowel problem.\r\nUse 'an' instead of 'a' ", "comments": ["@Bantena Thanks for the cleanup!"]}, {"number": 22690, "title": "Improve TOCO output", "body": "Currently the output is a binary string contain `\\n` characters, making the output not very readable. This change makes renders the output as the user expects.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@benjamintanweihao hey, um, something went wrong with this. Did you merge master into your topic branch? It is trying to merge 300 commits in which is clearly wrong. Can you rebase your branch on origin/master and make sure it has no merge commits and its only one commit off master? then force push the branch to your repo and it should fix things.\r\n\r\nsomething like:\r\n```\r\ngit fetch --all\r\ngit checkout patch-2\r\ngit rebase origin/master\r\ngit log origin/master..patch-2 # verify its right\r\ngit push <your repo> patch-2 --force\r\n```", "Yup this is completely my bad. I\u2019ll fix it. \n\n> On 12 Oct 2018, at 4:30 PM, Jason Zaman <notifications@github.com> wrote:\n> \n> @benjamintanweihao hey, um, something went wrong with this. Did you merge master into your topic branch? It is trying to merge 300 commits in which is clearly wrong. Can you rebase your branch on origin/master and make sure it has no merge commits and its only one commit off master? then force push the branch to your repo and it should fix things.\n> \n> something like:\n> \n> git fetch --all\n> git checkout patch-2\n> git rebase origin/master\n> git log origin/master..patch-2 # verify its right\n> git push <your repo> patch-2 --force\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "CLAs look good, thanks!\n\n<!-- ok -->", "Nagging Assignee @rmlarsen: It has been 34 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@benjamintanweihao hey, TFLite moved out of contrib, can you update this commit again please?", "Will do it tomorrow. :)\n\n> On 27 Nov 2018, at 10:30 PM, Jason Zaman <notifications@github.com> wrote:\n> \n> @benjamintanweihao hey, TFLite moved out of contrib, can you update this commit again please?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "@benjamintanweihao are you planning to move forward with this?", "> @benjamintanweihao are you planning to move forward with this?\r\n\r\nYup. Give me a couple more days.", "Thanks. Please resolve the conflicts.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Argh. I will redo this."]}, {"number": 22689, "title": "Pass custom_objects as args in TocoConverter.from_keras_model_file", "body": "Pass `custom_objects` as an argument to `TocoConverter.from_keras_model_file()` to allow for things like custom Keras layers.", "comments": ["@benjamintanweihao could you please resolve the conflicts?", "these files have been deleted in master , closing this PR"]}, {"number": 22688, "title": "fix spelling", "body": "Fix dnn_with_layer_annotations.py 251 line.\r\nUse 'an' instead of 'a' if following word starts with a vowel sound.\r\nso I change 'a estimator' to 'an estimator'", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "I fix spelling problem", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", ".", "@Bantena could you please sign the CLA?", "@Bantena Ah, I see you sent a separate PR with the CLA signed. Thanks!"]}, {"number": 22687, "title": "Bug in tf.keras.layers.ReLU.__init__", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nwindows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nr1.11\r\n- **Python version**:\r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n0.15.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nThere is a bug in tf.keras.layers.ReLU.\\_\\_init__. When passing keyward argument max_value with value None, which is also the default value, no gradient will be backword through it. I think is caused by the following code in the \\_\\_init__ function:\r\n``` python\r\nself.max_value = K.cast_to_floatx(max_value)\r\n```\r\nWhen max_value is None, the self.max_value will be nan of type float32. The self.max_value will be used with tf.clip_by_value as the upper bound and cause no gradient, since x < nan is false for any x.  I think the self.max_value should be None when max_value is None. \r\n``` python\r\nself.max_value = K.cast_to_floatx(max_value) if max_value is not None else None\r\n```\r\n", "comments": ["@blaueck Actually this is not a bug. When max_value is set as default value None, it means that no clipping is applied. Gradient will be either 0 or 1 depending on whether x is positive or negative. There is a zero gradient issue that can cause the output to become zero. This is addressed by modified ReLU such as ELU or leaky ReLU.", "Hi @wt-huang , thanks for your reply. What I means is that tf.keras.layers.ReLU don't behave as you say. When I set max_value as a not None value, such as 5, every thing is normal. But when I set max_value as None, there is not gradient backward thought the layer. \r\nI took a look at the code and found the max_value may be the problem. tf.keras.layers.ReLU actually call tf.keras.backend.relu to do the computation. The following code show how it works (with some simplification).\r\n```python\r\n# -- code in tf.keras.layers.ReLU.__init__ --\r\n# The same as self.max_value = np.asarray(max_value, dtype='float32').\r\n# When max_value is None, self.max_value will equal NaN\r\nself.max_value = K.cast_to_floatx(max_value)\r\n\r\n\r\n# -- code in tf.keras.backend.relu --\r\n# passing self.max_value to tf.keras.backend.relu as max_value\r\n\r\nx = tf.nn.relu(x)\r\n\r\n# Since max_value is not None, the condition will eval to True\r\nif max_value is not None:\r\n    x = tf.clip_by_value(x, 0, max_value)\r\n    # When max_value is NaN: x = tf.clip_by_value(x, 0, NaN).\r\n    # This clip op cause gradient to be zero, because no number is between\r\n    # 0 and NaN?\r\n```\r\nCode to reproduce the bug:\r\n``` python\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n# a = [-0.07873772,  1.2001798 ,  0.27422413,  0.8521496 ,  1.0448941 ]\r\na = tf.random_normal([5])\r\n\r\nwith tf.GradientTape() as tape:\r\n    tape.watch(a)\r\n    # b = [0.        , 1.2001798 , 0.27422413, 0.8521496 , 1.0448941 ]\r\n    b = tf.keras.layers.ReLU()(a)\r\n# da1 = [0., 0., 0., 0., 0.]\r\nda1 = tape.gradient(b, a)\r\n\r\nwith tf.GradientTape() as tape:\r\n    tape.watch(a)\r\n    # c = [0.        , 1.2001798 , 0.27422413, 0.8521496 , 1.0448941 ]\r\n    c = tf.keras.layers.ReLU(max_value=5)(a)\r\n# da2 = [0., 1., 1., 1., 1.]\r\nda2 = tape.gradient(c, a)\r\n```", "It seems to have been fixed in master branch. I'm closing this issue.", "@blaueck Could you point to the commit where it has been fixed??", "I think the commit is 1d1ec99bd3b322ea35a2d3d0eb754589ec2fd512."]}, {"number": 22686, "title": "1.12-rc0 cherry-pick request: Allow GPU memory limit to be configurable", "body": "PiperOrigin-RevId: 215477724", "comments": ["FYI I think we all forgot that parallel_gpu_execute.sh is in OSS, and needs to be cherry-picked in order for our tests to pick it up.", "Thank you for sending the cherrypick!", "Hmm, looks like it still doesn't work in my manual testing on my own VM.  I'm trying to devise a fix now..."]}, {"number": 22685, "title": "Change the inherited classes of some dataset ops", "body": "This PR fixes the issue #22681 ", "comments": ["@jsimsa Could you help review this PR when you have time?", "The API compatibility test is failing, please following the instructions in the test output to fix the issue.", "@jsimsa I merged two commits into one, but did not see you are running the test. Could you help re-run the test?\r\n\r\n", "Nagging Assignee @rmlarsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@jsimsa @rmlarsen This PR has been `ready to pull` for 22 days. Is there anything I need to do?", "Thank you for the reminder. I will work on getting this merged today."]}, {"number": 22684, "title": "1.12-rc0 cherry-pick request: Disable the cuDNN workarounds if the version number \u2026", "body": "\u2026 is new enough to get the corresponding bugs fixed. The bugs that were work-arounded were fixed and verified.\r\n\r\nPiperOrigin-RevId: 215497418", "comments": []}, {"number": 22683, "title": "Tensorflow master", "body": "", "comments": []}, {"number": 22682, "title": "TensorRT INT8 Calibration Bug", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary (pip install tensorflow-gpu)\r\n- **TensorFlow version (use command below)**: 1.11\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0 / 7.3.0\r\n- **GPU model and memory**: Titan Xp 12G\r\n- **Exact command to reproduce**: python tf_to_trt.py\r\n\r\n### Describe the problem\r\nI trained an object detection network called AVOD (https://github.com/kujason/avod) and tried to use TensorRT to speed up inference. The model conversion seems to be successful but when I try to do the inference, it gave me this error:\r\n```\r\nInput node not found, at TensorRTInputPH_0\r\n```\r\nI believe this might be a bug. I would love to provide more info if needed. Any help would be greatly appreciated. Thanks a ton!\r\n\r\n### Source code / logs\r\nsource code (modified from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/tensorrt/test/test_tftrt.py)\r\n```\r\nimport numpy as np\r\nimport time\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import gfile\r\nfrom tensorflow.contrib import tensorrt as trt\r\nfrom tensorflow.core.protobuf import config_pb2 as cpb2\r\nfrom tensorflow.core.protobuf import rewriter_config_pb2 as rwpb2\r\nfrom tensorflow.python.client import session as csess\r\nfrom tensorflow.python.framework import constant_op as cop\r\nfrom tensorflow.python.framework import dtypes as dtypes\r\nfrom tensorflow.python.framework import importer as importer\r\nfrom tensorflow.python.framework import ops as ops\r\nfrom tensorflow.python.ops import array_ops as aops\r\nfrom tensorflow.python.ops import math_ops as mops\r\nfrom tensorflow.python.ops import nn as nn\r\nfrom tensorflow.python.ops import nn_ops as nn_ops\r\n\r\noutput_node_name = ['proposals/nms/Gather',\r\n                    'proposals/nms/Gather_1',\r\n                    'avod_nms/Gather_1',\r\n                    'avod_nms/Gather_2',\r\n                    'avod_nms/Gather_3',\r\n                    'avod_nms/Gather_4',\r\n                    'avod_nms/Gather_5']\r\nbatch_size = 1\r\nnum_anchors = 1000\r\ninput_node = {\r\n    'bev_input/bev_input_pl_batch': np.random.rand(batch_size, 700, 800, 6),\r\n    'img_input/img_input_pl_batch': np.random.rand(batch_size, 360, 1200, 3),\r\n    'pl_anchors/anchors_pl_batch': np.random.rand(batch_size, num_anchors, 6),\r\n    'pl_anchors/bev_anchor_projections/bev_anchors_norm_pl_batch': np.random.rand(batch_size, num_anchors, 4),\r\n    'pl_anchors/img_anchor_projections/img_anchors_norm_pl_batch': np.random.rand(batch_size, num_anchors, 4),\r\n    'pl_anchors/sample_info/frame_calib_p2_batch': np.random.rand(batch_size, 3, 4),\r\n    'pl_anchors/sample_info/ground_plane_batch': np.random.rand(batch_size, 4),\r\n}\r\ninput_node_name = input_node.keys()\r\n\r\ndef execute_graph(gdef):\r\n    \"\"\"Run given graphdef once.\"\"\"\r\n    print(\"executing\")\r\n    gpu_options = None\r\n    if trt.trt_convert.get_linked_tensorrt_version()[0] == 3:\r\n        gpu_options = cpb2.GPUOptions(per_process_gpu_memory_fraction=0.50)\r\n    sessconfig = cpb2.ConfigProto(gpu_options=gpu_options)\r\n    ops.reset_default_graph()\r\n    g = ops.Graph()\r\n    with g.as_default():\r\n        input_output = importer.import_graph_def(graph_def=gdef, return_elements=input_node_name + output_node_name)\r\n        inputs = [elem.outputs[0] for elem in input_output[:len(input_node_name)]]\r\n        outputs = [elem.outputs[0] for elem in input_output[len(input_node_name):]]\r\n        inputs = {ph: input_node[name] for ph, name in zip(inputs, input_node_name)}\r\n    with csess.Session(graph=g) as sess:\r\n        for i in range(100):\r\n            start = time.time()\r\n            val = sess.run(outputs, inputs)\r\n            print(time.time() - start)\r\n    return val\r\n\r\ndef get_graph_def():\r\n    #with tf.Session() as sess:\r\n    model_filename ='/home/ecli/avod/avod/data/outputs/pyramid_people_with_aug_flexible_batchsize_example/checkpoints/frozen_model.pb'\r\n    with gfile.FastGFile(model_filename, 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n    return graph_def\r\n\r\ndef get_optimized_graph(graph_def, precision='FP32'):\r\n    return trt.create_inference_graph(\r\n        input_graph_def=graph_def,\r\n        outputs=output_node_name,\r\n        max_batch_size=num_anchors,\r\n        max_workspace_size_bytes=1 << 25,\r\n        precision_mode=precision,\r\n        minimum_segment_size=2,\r\n        is_dynamic_op=False,\r\n        maximum_cached_engines=1,\r\n        cached_engine_batches=[])\r\n\r\norig_graph = get_graph_def()\r\ntrt_graph = get_optimized_graph(orig_graph, 'FP32')\r\nexecute_graph(trt_graph)                                                                                                                                                                                                                                                                                   \r\n```\r\nHere is the error log:\r\n```\r\n2018-10-02 17:55:49.128166: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\r\n2018-10-02 17:55:49.128371: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2018-10-02 17:55:49.128693: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-10-02 17:55:49.130773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:05:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.74GiB\r\n2018-10-02 17:55:49.130795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-10-02 17:55:49.797924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-02 17:55:49.797993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-10-02 17:55:49.798002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-10-02 17:55:49.798568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11334 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2018-10-02 17:55:51.736457: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:853] MULTIPLE tensorrt candidate conversion: 110\r\n2018-10-02 17:55:51.738030: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.755022: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.757490: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.759075: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.760315: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.762196: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.764472: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.767273: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.770472: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.773202: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.776177: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.779351: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.782439: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.785647: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:51.788626: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'anchor_predictor/cls_fc6_drop/dropout/', converted to graph\r\n2018-10-02 17:55:51.791576: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'anchor_predictor/cls_fc7_drop/dropout/', converted to graph\r\n2018-10-02 17:55:51.794625: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'anchor_predictor/reg_fc6_drop/dropout/', converted to graph\r\n2018-10-02 17:55:51.797658: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'anchor_predictor/reg_fc7_drop/dropout/', converted to graph\r\n2018-10-02 17:55:51.800434: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_nms/', converted to graph\r\n2018-10-02 17:55:51.803259: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_nms/bev_projection/', converted to graph\r\n2018-10-02 17:55:51.806150: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_projection/img/', converted to graph\r\n2018-10-02 17:55:51.809014: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_projection/img/', converted to graph\r\n2018-10-02 17:55:51.811796: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_projection/img/', converted to graph\r\n2018-10-02 17:55:51.814618: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_projection/img/', converted to graph\r\n2018-10-02 17:55:51.817641: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.820808: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.826062: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.830058: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.833936: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.837790: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.841412: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.844914: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.848273: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.851709: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.855383: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.858941: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.862423: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'avod_regression/', converted to graph\r\n2018-10-02 17:55:51.866003: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_bottleneck/bottleneck/', converted to graph\r\n2018-10-02 17:55:51.869569: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_bottleneck/bottleneck/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.873191: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.877027: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.881102: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.885375: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.890163: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv1/', converted to graph\r\n2018-10-02 17:55:51.894660: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.899418: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.904140: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.909035: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv2/', converted to graph\r\n2018-10-02 17:55:51.913803: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.918825: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.923751: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.929236: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:55:51.934581: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.940460: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:55:51.946734: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.953317: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:51.960702: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.968942: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/', converted to graph\r\n2018-10-02 17:55:51.982940: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:51.994039: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/', converted to graph\r\n2018-10-02 17:55:52.005718: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.017832: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.033887: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.061730: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.080736: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.098714: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.116157: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.133693: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.150575: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.166229: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.182135: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.197698: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'box_predictor/fc6/', converted to graph\r\n2018-10-02 17:55:52.215250: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'box_predictor/fc6_drop/dropout/', converted to graph\r\n2018-10-02 17:55:52.238710: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'box_predictor/fc7_drop/dropout/', converted to graph\r\n2018-10-02 17:55:52.255985: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'box_predictor/fc8_drop/dropout/', converted to graph\r\n2018-10-02 17:55:52.271427: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:55:52.285149: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_bottleneck/bottleneck/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.298792: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_input/', converted to graph\r\n2018-10-02 17:55:52.311283: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:52.325299: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:52.338964: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:52.352397: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/', converted to graph\r\n2018-10-02 17:55:52.366803: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/conv1_1/', converted to graph\r\n2018-10-02 17:55:52.380294: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/conv1_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.396706: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:52.411343: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/conv1_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.425555: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv2/', converted to graph\r\n2018-10-02 17:55:52.440216: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv2/conv2_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.456120: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:52.474117: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv2/conv2_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.490652: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:55:52.509602: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/conv3_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.528796: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:55:52.548078: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/conv3_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.575318: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:55:52.602272: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/conv3_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.631036: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv4/', converted to graph\r\n2018-10-02 17:55:52.661422: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv4/conv4_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.699411: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv4/', converted to graph\r\n2018-10-02 17:55:52.770932: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv4/conv4_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.822570: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv4/conv4_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.865223: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/pyramid_fusion1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:52.955710: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/pyramid_fusion2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.005943: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/pyramid_fusion3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.047781: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.092236: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.205154: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.241229: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.275667: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:53.329565: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:55:54.978083: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_0 creation for segment 0, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:55.126408: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_1 creation for segment 1, composed of 6 nodes succeeded.\r\n2018-10-02 17:55:55.314276: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_2 creation for segment 2, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:55.471285: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_3 creation for segment 3, composed of 6 nodes succeeded.\r\n2018-10-02 17:55:55.523551: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_4 creation for segment 4, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:55.563377: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_5 creation for segment 5, composed of 11 nodes succeeded.\r\n2018-10-02 17:55:55.599293: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_6 creation for segment 6, composed of 11 nodes succeeded.\r\n2018-10-02 17:55:55.645190: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_7 creation for segment 7, composed of 30 nodes succeeded.\r\n2018-10-02 17:55:56.167550: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_8 creation for segment 8, composed of 8 nodes succeeded.\r\n2018-10-02 17:55:56.655547: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_9 creation for segment 9, composed of 8 nodes succeeded.\r\n2018-10-02 17:55:56.781781: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_10 creation for segment 10, composed of 16 nodes succeeded.\r\n2018-10-02 17:55:56.846884: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_11 creation for segment 11, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.245480: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_12 creation for segment 12, composed of 11 nodes succeeded.\r\n2018-10-02 17:55:57.281911: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine my_trt_op_13 creation for segment 13, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:57.314901: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14 creation for segment 14, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:57.346135: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15 creation for segment 15, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:57.376888: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16 creation for segment 16, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:57.407602: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17 creation for segment 17, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:57.439721: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_nms/my_trt_op_18 creation for segment 18, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.475973: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_nms/bev_projection/my_trt_op_19 creation for segment 19, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.512484: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_projection/img/my_trt_op_20 creation for segment 20, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.551874: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_projection/img/my_trt_op_21 creation for segment 21, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.588385: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_projection/img/my_trt_op_22 creation for segment 22, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.635975: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_projection/img/my_trt_op_23 creation for segment 23, composed of 2 nodes succeeded.\r\n2018-10-02 17:55:57.705177: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_24 creation for segment 24, composed of 6 nodes succeeded.\r\n2018-10-02 17:55:57.753337: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_25 creation for segment 25, composed of 6 nodes succeeded.\r\n2018-10-02 17:55:57.801667: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_26 creation for segment 26, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:57.872030: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_27 creation for segment 27, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:57.935326: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_28 creation for segment 28, composed of 13 nodes succeeded.\r\n2018-10-02 17:55:57.984397: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_29 creation for segment 29, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:58.028066: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_30 creation for segment 30, composed of 3 nodes succeeded.\r\n2018-10-02 17:55:58.069669: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_31 creation for segment 31, composed of 3 nodes succeeded.\r\n2018-10-02 17:55:58.106058: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_32 creation for segment 32, composed of 3 nodes succeeded.\r\n2018-10-02 17:55:58.139464: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_33 creation for segment 33, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:58.171112: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_34 creation for segment 34, composed of 7 nodes succeeded.\r\n2018-10-02 17:55:58.202794: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_35 creation for segment 35, composed of 3 nodes succeeded.\r\n2018-10-02 17:55:58.234781: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine avod_regression/my_trt_op_36 creation for segment 36, composed of 3 nodes succeeded.\r\n2018-10-02 17:55:58.240744: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_bottleneck/bottleneck/my_trt_op_37 creation for segment 37, composed of 4 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_bottleneck/bottleneck/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.246462: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_bottleneck/bottleneck/BatchNorm/moments/my_trt_op_38 creation for segment 38, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_bottleneck/bottleneck/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.252287: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_39 creation for segment 39, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.258291: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_40 creation for segment 40, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.264489: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_41 creation for segment 41, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.271844: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_42 creation for segment 42, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.277734: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv1/my_trt_op_43 creation for segment 43, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.283385: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/my_trt_op_44 creation for segment 44, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.289392: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_45 creation for segment 45, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.295056: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/my_trt_op_46 creation for segment 46, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.301151: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv2/my_trt_op_47 creation for segment 47, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.306853: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/my_trt_op_48 creation for segment 48, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.313223: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_49 creation for segment 49, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.318923: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/my_trt_op_50 creation for segment 50, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.329949: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/my_trt_op_51 creation for segment 51, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.335704: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/my_trt_op_52 creation for segment 52, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.342597: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/my_trt_op_53 creation for segment 53, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.348323: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/my_trt_op_54 creation for segment 54, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.356835: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_55 creation for segment 55, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.362568: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/my_trt_op_56 creation for segment 56, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.373950: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/my_trt_op_57 creation for segment 57, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.379702: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/my_trt_op_58 creation for segment 58, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.390926: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/my_trt_op_59 creation for segment 59, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.396673: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/my_trt_op_60 creation for segment 60, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.402288: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/my_trt_op_61 creation for segment 61, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.407929: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/my_trt_op_62 creation for segment 62, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.413521: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/my_trt_op_63 creation for segment 63, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.419108: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/my_trt_op_64 creation for segment 64, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.424731: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_65 creation for segment 65, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.430337: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_66 creation for segment 66, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.438284: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_67 creation for segment 67, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.443884: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_68 creation for segment 68, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.449507: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_69 creation for segment 69, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.455066: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_70 creation for segment 70, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:58.822526: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine box_predictor/fc6/my_trt_op_71 creation for segment 71, composed of 5 nodes succeeded.\r\n2018-10-02 17:55:58.871051: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine box_predictor/fc6_drop/dropout/my_trt_op_72 creation for segment 72, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:58.920620: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine box_predictor/fc7_drop/dropout/my_trt_op_73 creation for segment 73, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:58.964147: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine box_predictor/fc8_drop/dropout/my_trt_op_74 creation for segment 74, composed of 4 nodes succeeded.\r\n2018-10-02 17:55:58.974897: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine my_trt_op_75 creation for segment 75, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_bottleneck/bottleneck/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:58.985725: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_bottleneck/bottleneck/BatchNorm/moments/my_trt_op_76 creation for segment 76, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_bottleneck/bottleneck/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.071557: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine img_input/my_trt_op_77 creation for segment 77, composed of 8 nodes succeeded.\r\n2018-10-02 17:55:59.085895: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_78 creation for segment 78, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.092811: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_79 creation for segment 79, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.101052: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_80 creation for segment 80, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.108438: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/my_trt_op_81 creation for segment 81, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.119578: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/conv1_1/my_trt_op_82 creation for segment 82, composed of 4 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.129550: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/conv1_1/BatchNorm/moments/my_trt_op_83 creation for segment 83, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.139482: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_84 creation for segment 84, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.147043: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/conv1_2/BatchNorm/moments/my_trt_op_85 creation for segment 85, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.164181: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv2/my_trt_op_86 creation for segment 86, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.174128: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv2/conv2_1/BatchNorm/moments/my_trt_op_87 creation for segment 87, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.186279: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_88 creation for segment 88, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.195722: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv2/conv2_2/BatchNorm/moments/my_trt_op_89 creation for segment 89, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.225677: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/my_trt_op_90 creation for segment 90, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.235903: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/conv3_1/BatchNorm/moments/my_trt_op_91 creation for segment 91, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.255517: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/my_trt_op_92 creation for segment 92, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.266444: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/conv3_2/BatchNorm/moments/my_trt_op_93 creation for segment 93, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.279985: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_94 creation for segment 94, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.291482: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/conv3_3/BatchNorm/moments/my_trt_op_95 creation for segment 95, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.310105: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv4/my_trt_op_96 creation for segment 96, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.316996: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv4/conv4_1/BatchNorm/moments/my_trt_op_97 creation for segment 97, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.364412: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv4/my_trt_op_98 creation for segment 98, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.373789: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv4/conv4_2/BatchNorm/moments/my_trt_op_99 creation for segment 99, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.380203: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv4/conv4_3/BatchNorm/moments/my_trt_op_100 creation for segment 100, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.389040: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/pyramid_fusion1/BatchNorm/moments/my_trt_op_101 creation for segment 101, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.411862: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/pyramid_fusion2/BatchNorm/moments/my_trt_op_102 creation for segment 102, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.421726: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/pyramid_fusion3/BatchNorm/moments/my_trt_op_103 creation for segment 103, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.432249: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_104 creation for segment 104, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.443949: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_105 creation for segment 105, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.449435: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_106 creation for segment 106, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.460761: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_107 creation for segment 107, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:55:59.471910: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_108 creation for segment 108, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:55:59.477365: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_109 creation for segment 109, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:00.141815: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:853] MULTIPLE tensorrt candidate conversion: 63\r\n2018-10-02 17:56:00.142857: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_bottleneck/bottleneck/', converted to graph\r\n2018-10-02 17:56:00.170427: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_bottleneck/bottleneck/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.195656: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.220905: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.247540: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.279776: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.310694: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv1/', converted to graph\r\n2018-10-02 17:56:00.345061: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.377090: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.409263: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.442132: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv2/', converted to graph\r\n2018-10-02 17:56:00.473882: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.505522: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.538089: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.573492: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:56:00.630581: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.674344: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:56:00.714034: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.759295: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:00.836794: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.889462: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/', converted to graph\r\n2018-10-02 17:56:00.928113: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:00.967656: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/', converted to graph\r\n2018-10-02 17:56:01.010712: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.078553: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.133705: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.176612: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.218213: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.265483: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.311145: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.356390: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.433850: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.487395: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.531475: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'bev_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.573956: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope '', converted to graph\r\n2018-10-02 17:56:01.620681: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_bottleneck/bottleneck/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.665840: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:01.711575: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:01.778189: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:01.821042: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/', converted to graph\r\n2018-10-02 17:56:01.866717: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/conv1_1/', converted to graph\r\n2018-10-02 17:56:01.909214: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/conv1_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:01.946133: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:01.999098: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv1/conv1_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.060485: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv2/', converted to graph\r\n2018-10-02 17:56:02.119455: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv2/conv2_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.168367: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:02.211278: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv2/conv2_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.251685: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:56:02.297304: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/conv3_1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.340571: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/', converted to graph\r\n2018-10-02 17:56:02.391434: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/conv3_2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.445167: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/', converted to graph\r\n2018-10-02 17:56:02.490863: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/conv3/conv3_3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.535191: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/pyramid_fusion1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.575691: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/pyramid_fusion2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.628437: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/pyramid_fusion3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.669795: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.716209: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv1/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.757055: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.798237: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv2/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.841372: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.907552: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'img_vgg_pyr/upconv3/BatchNorm/moments/', converted to graph\r\n2018-10-02 17:56:02.969336: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_bottleneck/bottleneck/my_trt_op_0 creation for segment 0, composed of 4 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_bottleneck/bottleneck/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:02.980822: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_bottleneck/bottleneck/BatchNorm/moments/my_trt_op_1 creation for segment 1, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_bottleneck/bottleneck/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:02.989601: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_2 creation for segment 2, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.010604: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_3 creation for segment 3, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.033675: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_4 creation for segment 4, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.058413: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_5 creation for segment 5, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.128939: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv1/my_trt_op_6 creation for segment 6, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.144605: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/my_trt_op_7 creation for segment 7, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.153443: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_8 creation for segment 8, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.163759: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/my_trt_op_9 creation for segment 9, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv1/conv1_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.173146: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv2/my_trt_op_10 creation for segment 10, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.203674: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/my_trt_op_11 creation for segment 11, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.211912: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_12 creation for segment 12, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.227933: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/my_trt_op_13 creation for segment 13, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv2/conv2_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.239869: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/my_trt_op_14 creation for segment 14, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.248090: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/my_trt_op_15 creation for segment 15, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.258185: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/my_trt_op_16 creation for segment 16, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.265557: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/my_trt_op_17 creation for segment 17, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.282523: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/my_trt_op_18 creation for segment 18, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.288078: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/my_trt_op_19 creation for segment 19, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv3/conv3_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.302207: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/my_trt_op_20 creation for segment 20, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.311663: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/my_trt_op_21 creation for segment 21, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.327409: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/my_trt_op_22 creation for segment 22, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.336531: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/my_trt_op_23 creation for segment 23, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.341961: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/my_trt_op_24 creation for segment 24, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/conv4/conv4_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.347354: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/my_trt_op_25 creation for segment 25, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.356055: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/my_trt_op_26 creation for segment 26, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.361473: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/my_trt_op_27 creation for segment 27, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/pyramid_fusion3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.366898: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_28 creation for segment 28, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.372328: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_29 creation for segment 29, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.377764: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_30 creation for segment 30, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.383151: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_31 creation for segment 31, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.388535: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_32 creation for segment 32, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.393864: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine bev_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_33 creation for segment 33, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atbev_vgg_pyr/upconv3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.399323: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine my_trt_op_34 creation for segment 34, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_bottleneck/bottleneck/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.404688: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_bottleneck/bottleneck/BatchNorm/moments/my_trt_op_35 creation for segment 35, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_bottleneck/bottleneck/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.410415: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_36 creation for segment 36, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.416480: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_37 creation for segment 37, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.426178: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_38 creation for segment 38, composed of 7 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.431928: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/my_trt_op_39 creation for segment 39, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.437507: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/conv1_1/my_trt_op_40 creation for segment 40, composed of 4 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.442960: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/conv1_1/BatchNorm/moments/my_trt_op_41 creation for segment 41, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.448674: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_42 creation for segment 42, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.454163: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv1/conv1_2/BatchNorm/moments/my_trt_op_43 creation for segment 43, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv1/conv1_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.460002: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv2/my_trt_op_44 creation for segment 44, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.465472: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv2/conv2_1/BatchNorm/moments/my_trt_op_45 creation for segment 45, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.471639: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_46 creation for segment 46, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.477128: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv2/conv2_2/BatchNorm/moments/my_trt_op_47 creation for segment 47, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv2/conv2_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.483727: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/my_trt_op_48 creation for segment 48, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.489220: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/conv3_1/BatchNorm/moments/my_trt_op_49 creation for segment 49, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.495857: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/my_trt_op_50 creation for segment 50, composed of 5 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.501322: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/conv3_2/BatchNorm/moments/my_trt_op_51 creation for segment 51, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.510326: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/my_trt_op_52 creation for segment 52, composed of 6 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv4/conv4_1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.515900: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/conv3/conv3_3/BatchNorm/moments/my_trt_op_53 creation for segment 53, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/conv3/conv3_3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.521290: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/pyramid_fusion1/BatchNorm/moments/my_trt_op_54 creation for segment 54, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.526716: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/pyramid_fusion2/BatchNorm/moments/my_trt_op_55 creation for segment 55, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.537755: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/pyramid_fusion3/BatchNorm/moments/my_trt_op_56 creation for segment 56, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/pyramid_fusion3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.543147: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_57 creation for segment 57, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv1/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.548554: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv1/BatchNorm/moments/my_trt_op_58 creation for segment 58, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv1/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.553972: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_59 creation for segment 59, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv2/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.559438: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv2/BatchNorm/moments/my_trt_op_60 creation for segment 60, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv2/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.564861: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_61 creation for segment 61, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv3/BatchNorm/moments/mean. Skipping...\r\n2018-10-02 17:56:03.570331: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:958] Engine img_vgg_pyr/upconv3/BatchNorm/moments/my_trt_op_62 creation for segment 62, composed of 2 nodes failed: Invalid argument: TRT cannot reduce at batch dimension, atimg_vgg_pyr/upconv3/BatchNorm/moments/variance. Skipping...\r\n2018-10-02 17:56:03.962856: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:04.062406: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:04.263895: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:04.351102: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:04.810160: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:04.903127: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:05.216729: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:05.377328: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:05.629837: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:05.741889: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:06.285153: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:06.426025: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:06.896986: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:07.005234: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:07.331087: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:07.429775: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:07.702808: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:07.843982: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:08.083679: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:08.211226: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:08.449366: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:08.540734: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:08.745183: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:08.847796: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:09.216510: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:09.316383: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:09.724700: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:09.814051: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:10.055081: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:10.137400: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:10.380309: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:10.468057: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:10.788696: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:10.915843: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:11.258064: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:11.475492: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:11.838890: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:11.967300: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:12.349391: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:12.470533: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:12.768804: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:12.892336: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:13.168478: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:13.255246: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:13.480106: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:13.605198: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:13.812729: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:13.895074: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:14.066856: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:14.142464: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:14.405436: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:14.503853: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:14.834100: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:14.971755: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:15.221326: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:15.347533: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:15.602816: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:15.716234: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:16.072528: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:16.195363: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:16.481762: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:16.616132: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:16.891134: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:16.997634: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:17.269403: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:17.402055: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:17.755220: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:17.849290: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:18.543444: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:18.673213: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:19.079337: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:19.204213: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:19.639048: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:19.743795: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:19.985325: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:20.112254: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:20.473620: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:20.611352: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:20.840764: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:20.928101: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:21.147636: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:21.249638: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:21.544871: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:21.651990: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:21.959924: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:22.066834: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:22.312655: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:22.393502: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:22.701783: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:22.803812: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:23.015327: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:23.107253: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:23.313834: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:23.425949: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:23.800021: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:23.924795: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:24.253029: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:24.412785: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:24.722232: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:24.829318: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.037879: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.113719: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.324188: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.416653: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.623164: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.731420: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:25.937949: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:26.019311: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:26.322064: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:26.416136: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:26.667155: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:26.796819: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:27.137403: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:27.263612: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:27.671781: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:27.778717: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:28.133562: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:28.258397: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:28.517705: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:28.674028: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:28.977364: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:29.139223: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:29.447015: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:29.547793: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:29.852750: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:29.964112: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:30.180069: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:30.268583: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:30.480015: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:30.575854: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:30.883435: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:30.999684: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:31.218258: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:31.310087: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:31.597708: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:31.695835: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:31.948859: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:32.076745: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:32.326095: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:32.435555: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:32.726703: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:32.869378: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:33.402936: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:33.544019: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:33.883843: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:33.990118: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:34.247859: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:34.327272: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:34.624772: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:34.712355: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:35.017296: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:35.156685: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:35.521514: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:35.625491: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:35.853263: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:35.957000: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:36.384367: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:36.485557: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:36.685878: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:36.769251: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:37.007802: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:37.112754: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:37.328329: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:37.412646: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:37.603709: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:37.682906: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:38.087271: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:38.256376: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:38.648774: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:38.762487: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:39.112597: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:39.228518: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:39.581079: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:39.750554: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:39.994712: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:40.132410: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:40.519194: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:40.649858: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-10-02 17:56:40.777227: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: tf_graph\r\n2018-10-02 17:56:40.777314: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 1856 nodes (-210), 2288 edges (-237), time = 849.462ms.\r\n2018-10-02 17:56:40.777331: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Invalid argument: Unsupported tensor size: 2\r\n2018-10-02 17:56:40.777343: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 1639 nodes (-217), 2056 edges (-232), time = 8124.63281ms.\r\n2018-10-02 17:56:40.777352: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 1639 nodes (0), 2056 edges (0), time = 167.208ms.\r\n2018-10-02 17:56:40.777366: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 1639 nodes (0), 2056 edges (0), time = 3975.28198ms.\r\n2018-10-02 17:56:40.777401: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv3/my_trt_op_50_native_segment\r\n2018-10-02 17:56:40.777445: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 130.254ms.\r\n2018-10-02 17:56:40.777472: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 59.916ms.\r\n2018-10-02 17:56:40.777482: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.611ms.\r\n2018-10-02 17:56:40.777493: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 81.438ms.\r\n2018-10-02 17:56:40.777498: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 17.863ms.\r\n2018-10-02 17:56:40.777517: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_3_native_segment\r\n2018-10-02 17:56:40.777523: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 79.581ms.\r\n2018-10-02 17:56:40.777528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 42.578ms.\r\n2018-10-02 17:56:40.777532: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 14.459ms.\r\n2018-10-02 17:56:40.777537: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 73.104ms.\r\n2018-10-02 17:56:40.777542: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 13.9ms.\r\n2018-10-02 17:56:40.777546: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv4/my_trt_op_59_native_segment\r\n2018-10-02 17:56:40.777551: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 97.347ms.\r\n2018-10-02 17:56:40.777556: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 54.02ms.\r\n2018-10-02 17:56:40.777561: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 20.284ms.\r\n2018-10-02 17:56:40.777565: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 73.974ms.\r\n2018-10-02 17:56:40.777570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.996ms.\r\n2018-10-02 17:56:40.777575: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv4/my_trt_op_22_native_segment\r\n2018-10-02 17:56:40.777580: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 114.152ms.\r\n2018-10-02 17:56:40.777584: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 66.639ms.\r\n2018-10-02 17:56:40.777589: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 23.315ms.\r\n2018-10-02 17:56:40.777594: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 137.84ms.\r\n2018-10-02 17:56:40.777598: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 26.118ms.\r\n2018-10-02 17:56:40.777603: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_25_native_segment\r\n2018-10-02 17:56:40.777608: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 8 edges (0), time = 92.864ms.\r\n2018-10-02 17:56:40.777612: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 7 nodes (0), 8 edges (0), time = 48.034ms.\r\n2018-10-02 17:56:40.777617: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 8 edges (0), time = 16.397ms.\r\n2018-10-02 17:56:40.777622: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 8 edges (0), time = 95.741ms.\r\n2018-10-02 17:56:40.777626: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 8 edges (0), time = 16.872ms.\r\n2018-10-02 17:56:40.777634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_37_native_segment\r\n2018-10-02 17:56:40.777639: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 128.588ms.\r\n2018-10-02 17:56:40.777644: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 86.13ms.\r\n2018-10-02 17:56:40.777649: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 20.842ms.\r\n2018-10-02 17:56:40.777653: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 120.321ms.\r\n2018-10-02 17:56:40.777658: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 31.859ms.\r\n2018-10-02 17:56:40.777663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_38_native_segment\r\n2018-10-02 17:56:40.777667: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 120.262ms.\r\n2018-10-02 17:56:40.777673: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 65.366ms.\r\n2018-10-02 17:56:40.777677: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 16.09ms.\r\n2018-10-02 17:56:40.777682: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 92.29ms.\r\n2018-10-02 17:56:40.777687: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 17.853ms.\r\n2018-10-02 17:56:40.777691: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_34_native_segment\r\n2018-10-02 17:56:40.777696: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 86.285ms.\r\n2018-10-02 17:56:40.777701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 48.044ms.\r\n2018-10-02 17:56:40.777706: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.753ms.\r\n2018-10-02 17:56:40.777711: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 82.209ms.\r\n2018-10-02 17:56:40.777715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.027ms.\r\n2018-10-02 17:56:40.777720: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_78_native_segment\r\n2018-10-02 17:56:40.777725: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 100.958ms.\r\n2018-10-02 17:56:40.777729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 51.425ms.\r\n2018-10-02 17:56:40.777734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 20.608ms.\r\n2018-10-02 17:56:40.777739: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 122.391ms.\r\n2018-10-02 17:56:40.777743: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 13.772ms.\r\n2018-10-02 17:56:40.777748: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv4/my_trt_op_20_native_segment\r\n2018-10-02 17:56:40.777756: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 75.488ms.\r\n2018-10-02 17:56:40.777761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 46.379ms.\r\n2018-10-02 17:56:40.777765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.234ms.\r\n2018-10-02 17:56:40.777770: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 111.487ms.\r\n2018-10-02 17:56:40.777775: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 15.929ms.\r\n2018-10-02 17:56:40.777779: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: box_predictor/fc7_drop/dropout/my_trt_op_73_native_segment\r\n2018-10-02 17:56:40.777785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 101.857ms.\r\n2018-10-02 17:56:40.777789: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 56.307ms.\r\n2018-10-02 17:56:40.777794: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 17.826ms.\r\n2018-10-02 17:56:40.777798: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 73.912ms.\r\n2018-10-02 17:56:40.777803: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 18.894ms.\r\n2018-10-02 17:56:40.777808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: box_predictor/fc6_drop/dropout/my_trt_op_72_native_segment\r\n2018-10-02 17:56:40.777812: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 79.862ms.\r\n2018-10-02 17:56:40.777817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 43.957ms.\r\n2018-10-02 17:56:40.777822: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 18.656ms.\r\n2018-10-02 17:56:40.777827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 84.13ms.\r\n2018-10-02 17:56:40.777832: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 15.831ms.\r\n2018-10-02 17:56:40.777836: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_88_native_segment\r\n2018-10-02 17:56:40.777841: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 112.088ms.\r\n2018-10-02 17:56:40.777846: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 48.561ms.\r\n2018-10-02 17:56:40.777851: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 15.32ms.\r\n2018-10-02 17:56:40.777855: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 84.949ms.\r\n2018-10-02 17:56:40.777860: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 15.206ms.\r\n2018-10-02 17:56:40.777864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv1/my_trt_op_39_native_segment\r\n2018-10-02 17:56:40.777875: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 97.002ms.\r\n2018-10-02 17:56:40.777880: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 49.334ms.\r\n2018-10-02 17:56:40.777884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.348ms.\r\n2018-10-02 17:56:40.777889: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 75.246ms.\r\n2018-10-02 17:56:40.777894: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.323ms.\r\n2018-10-02 17:56:40.777898: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_2_native_segment\r\n2018-10-02 17:56:40.777903: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 100.693ms.\r\n2018-10-02 17:56:40.777908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 7 nodes (0), 6 edges (0), time = 46.782ms.\r\n2018-10-02 17:56:40.777912: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 21.77ms.\r\n2018-10-02 17:56:40.777917: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 67.921ms.\r\n2018-10-02 17:56:40.777922: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 13.852ms.\r\n2018-10-02 17:56:40.777926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_8_native_segment\r\n2018-10-02 17:56:40.777931: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 72.786ms.\r\n2018-10-02 17:56:40.777936: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 46.438ms.\r\n2018-10-02 17:56:40.777940: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 14.778ms.\r\n2018-10-02 17:56:40.777945: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 73.322ms.\r\n2018-10-02 17:56:40.777950: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 14.568ms.\r\n2018-10-02 17:56:40.777954: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_79_native_segment\r\n2018-10-02 17:56:40.777959: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 93.484ms.\r\n2018-10-02 17:56:40.777964: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 57.016ms.\r\n2018-10-02 17:56:40.777968: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 16.567ms.\r\n2018-10-02 17:56:40.777973: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 110.085ms.\r\n2018-10-02 17:56:40.777978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 19.795ms.\r\n2018-10-02 17:56:40.777982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_8_native_segment\r\n2018-10-02 17:56:40.777990: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 10 nodes (0), 9 edges (0), time = 171.247ms.\r\n2018-10-02 17:56:40.777995: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 10 nodes (0), 9 edges (0), time = 60.652ms.\r\n2018-10-02 17:56:40.778000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 10 nodes (0), 9 edges (0), time = 15.295ms.\r\n2018-10-02 17:56:40.778005: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 10 nodes (0), 9 edges (0), time = 202.229ms.\r\n2018-10-02 17:56:40.778009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 10 nodes (0), 9 edges (0), time = 19.85ms.\r\n2018-10-02 17:56:40.778014: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14_native_segment\r\n2018-10-02 17:56:40.778019: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 125.611ms.\r\n2018-10-02 17:56:40.778024: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 71.643ms.\r\n2018-10-02 17:56:40.778028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 23.51ms.\r\n2018-10-02 17:56:40.778033: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 105.809ms.\r\n2018-10-02 17:56:40.778038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 20.109ms.\r\n2018-10-02 17:56:40.778042: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: box_predictor/fc8_drop/dropout/my_trt_op_74_native_segment\r\n2018-10-02 17:56:40.778047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 96.14ms.\r\n2018-10-02 17:56:40.778052: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 62.772ms.\r\n2018-10-02 17:56:40.778057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 20.635ms.\r\n2018-10-02 17:56:40.778061: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 100.912ms.\r\n2018-10-02 17:56:40.778066: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 19.505ms.\r\n2018-10-02 17:56:40.778071: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_7_native_segment\r\n2018-10-02 17:56:40.778076: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 42 nodes (0), 48 edges (0), time = 90.341ms.\r\n2018-10-02 17:56:40.778080: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 42 nodes (0), 48 edges (0), time = 58.895ms.\r\n2018-10-02 17:56:40.778085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 42 nodes (0), 48 edges (0), time = 23.053ms.\r\n2018-10-02 17:56:40.778090: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 42 nodes (0), 48 edges (0), time = 101.459ms.\r\n2018-10-02 17:56:40.778094: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 42 nodes (0), 48 edges (0), time = 15.277ms.\r\n2018-10-02 17:56:40.778099: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_32_native_segment\r\n2018-10-02 17:56:40.778107: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 68.565ms.\r\n2018-10-02 17:56:40.778112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 43.078ms.\r\n2018-10-02 17:56:40.778116: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 17.118ms.\r\n2018-10-02 17:56:40.778121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 69.783ms.\r\n2018-10-02 17:56:40.778125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 15.171ms.\r\n2018-10-02 17:56:40.778130: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_5_native_segment\r\n2018-10-02 17:56:40.778135: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 15 nodes (0), 15 edges (0), time = 81.789ms.\r\n2018-10-02 17:56:40.778139: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 15 nodes (0), 15 edges (0), time = 58.871ms.\r\n2018-10-02 17:56:40.778144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 15 nodes (0), 15 edges (0), time = 21.822ms.\r\n2018-10-02 17:56:40.778149: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 15 nodes (0), 15 edges (0), time = 103.572ms.\r\n2018-10-02 17:56:40.778153: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 15 nodes (0), 15 edges (0), time = 21.173ms.\r\n2018-10-02 17:56:40.778158: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_24_native_segment\r\n2018-10-02 17:56:40.778163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 8 edges (0), time = 76.028ms.\r\n2018-10-02 17:56:40.778167: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 7 nodes (0), 8 edges (0), time = 47.977ms.\r\n2018-10-02 17:56:40.778172: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 8 edges (0), time = 15.578ms.\r\n2018-10-02 17:56:40.778177: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 8 edges (0), time = 67.261ms.\r\n2018-10-02 17:56:40.778181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 8 edges (0), time = 12.204ms.\r\n2018-10-02 17:56:40.778186: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv2/my_trt_op_10_native_segment\r\n2018-10-02 17:56:40.778191: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 66.655ms.\r\n2018-10-02 17:56:40.778196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 41.333ms.\r\n2018-10-02 17:56:40.778201: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 12.683ms.\r\n2018-10-02 17:56:40.778205: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 63.096ms.\r\n2018-10-02 17:56:40.778210: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.835ms.\r\n2018-10-02 17:56:40.778215: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_4_native_segment\r\n2018-10-02 17:56:40.778222: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 94.363ms.\r\n2018-10-02 17:56:40.778227: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 49.062ms.\r\n2018-10-02 17:56:40.778232: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 15.634ms.\r\n2018-10-02 17:56:40.778237: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 83.174ms.\r\n2018-10-02 17:56:40.778242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 16.232ms.\r\n2018-10-02 17:56:40.778246: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv2/my_trt_op_47_native_segment\r\n2018-10-02 17:56:40.778251: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 114.132ms.\r\n2018-10-02 17:56:40.778256: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 69.724ms.\r\n2018-10-02 17:56:40.778261: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 22.896ms.\r\n2018-10-02 17:56:40.778265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 115.544ms.\r\n2018-10-02 17:56:40.778270: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.883ms.\r\n2018-10-02 17:56:40.778275: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_12_native_segment\r\n2018-10-02 17:56:40.778279: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 13 nodes (0), 12 edges (0), time = 99.906ms.\r\n2018-10-02 17:56:40.778284: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 19 nodes (6), 20 edges (8), time = 65.87ms.\r\n2018-10-02 17:56:40.778289: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 19 nodes (0), 20 edges (0), time = 20.68ms.\r\n2018-10-02 17:56:40.778294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 19 nodes (0), 20 edges (0), time = 105.972ms.\r\n2018-10-02 17:56:40.778299: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 19 nodes (0), 20 edges (0), time = 20.176ms.\r\n2018-10-02 17:56:40.778303: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_27_native_segment\r\n2018-10-02 17:56:40.778308: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 96.599ms.\r\n2018-10-02 17:56:40.778313: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (0), 10 edges (0), time = 58.041ms.\r\n2018-10-02 17:56:40.778317: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 19.126ms.\r\n2018-10-02 17:56:40.778322: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 94.906ms.\r\n2018-10-02 17:56:40.778327: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 19.079ms.\r\n2018-10-02 17:56:40.778331: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_55_native_segment\r\n2018-10-02 17:56:40.778339: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 108.69ms.\r\n2018-10-02 17:56:40.778344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 65.153ms.\r\n2018-10-02 17:56:40.778349: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 20.794ms.\r\n2018-10-02 17:56:40.778354: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 103.203ms.\r\n2018-10-02 17:56:40.778359: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 21.007ms.\r\n2018-10-02 17:56:40.778363: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_28_native_segment\r\n2018-10-02 17:56:40.778368: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 19 nodes (0), 20 edges (0), time = 114.885ms.\r\n2018-10-02 17:56:40.778373: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 19 nodes (0), 20 edges (0), time = 77.866ms.\r\n2018-10-02 17:56:40.778378: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 19 nodes (0), 20 edges (0), time = 23.805ms.\r\n2018-10-02 17:56:40.778383: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 19 nodes (0), 20 edges (0), time = 111.436ms.\r\n2018-10-02 17:56:40.778387: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 19 nodes (0), 20 edges (0), time = 19.458ms.\r\n2018-10-02 17:56:40.778400: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_94_native_segment\r\n2018-10-02 17:56:40.778405: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 80.543ms.\r\n2018-10-02 17:56:40.778410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 58.339ms.\r\n2018-10-02 17:56:40.778415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 19.708ms.\r\n2018-10-02 17:56:40.778419: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 87.838ms.\r\n2018-10-02 17:56:40.778424: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 16.698ms.\r\n2018-10-02 17:56:40.778429: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_30_native_segment\r\n2018-10-02 17:56:40.778433: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 121.923ms.\r\n2018-10-02 17:56:40.778438: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 47.098ms.\r\n2018-10-02 17:56:40.778443: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 24.22ms.\r\n2018-10-02 17:56:40.778448: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 108.566ms.\r\n2018-10-02 17:56:40.778452: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 23.011ms.\r\n2018-10-02 17:56:40.778457: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv3/my_trt_op_16_native_segment\r\n2018-10-02 17:56:40.778465: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 101.374ms.\r\n2018-10-02 17:56:40.778469: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 42.587ms.\r\n2018-10-02 17:56:40.778474: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.76ms.\r\n2018-10-02 17:56:40.778479: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 79.239ms.\r\n2018-10-02 17:56:40.778483: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.402ms.\r\n2018-10-02 17:56:40.778488: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_52_native_segment\r\n2018-10-02 17:56:40.778493: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 159.819ms.\r\n2018-10-02 17:56:40.778497: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 59.04ms.\r\n2018-10-02 17:56:40.778502: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 24.367ms.\r\n2018-10-02 17:56:40.778507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 105.897ms.\r\n2018-10-02 17:56:40.778512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 20.263ms.\r\n2018-10-02 17:56:40.778516: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_41_native_segment\r\n2018-10-02 17:56:40.778521: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 119.099ms.\r\n2018-10-02 17:56:40.778526: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 64.511ms.\r\n2018-10-02 17:56:40.778531: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 19.904ms.\r\n2018-10-02 17:56:40.778536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 105.488ms.\r\n2018-10-02 17:56:40.778540: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 16.375ms.\r\n2018-10-02 17:56:40.778545: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_input/my_trt_op_77_native_segment\r\n2018-10-02 17:56:40.778550: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 121.065ms.\r\n2018-10-02 17:56:40.778555: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (0), 10 edges (0), time = 49.449ms.\r\n2018-10-02 17:56:40.778559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 17.159ms.\r\n2018-10-02 17:56:40.778564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 87.813ms.\r\n2018-10-02 17:56:40.778569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 17.637ms.\r\n2018-10-02 17:56:40.778574: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_36_native_segment\r\n2018-10-02 17:56:40.778579: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 97.444ms.\r\n2018-10-02 17:56:40.778587: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 7 nodes (0), 6 edges (0), time = 56.214ms.\r\n2018-10-02 17:56:40.778591: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 19.357ms.\r\n2018-10-02 17:56:40.778596: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 108.06ms.\r\n2018-10-02 17:56:40.778601: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 16.506ms.\r\n2018-10-02 17:56:40.778605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_6_native_segment\r\n2018-10-02 17:56:40.778610: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 15 nodes (0), 15 edges (0), time = 144.376ms.\r\n2018-10-02 17:56:40.778615: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 15 nodes (0), 15 edges (0), time = 64.375ms.\r\n2018-10-02 17:56:40.778620: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 15 nodes (0), 15 edges (0), time = 23.864ms.\r\n2018-10-02 17:56:40.778624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 15 nodes (0), 15 edges (0), time = 114.696ms.\r\n2018-10-02 17:56:40.778629: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 15 nodes (0), 15 edges (0), time = 16.925ms.\r\n2018-10-02 17:56:40.778633: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_10_native_segment\r\n2018-10-02 17:56:40.778638: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 21 nodes (0), 20 edges (0), time = 88.207ms.\r\n2018-10-02 17:56:40.778643: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 21 nodes (0), 20 edges (0), time = 48.169ms.\r\n2018-10-02 17:56:40.778648: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 21 nodes (0), 20 edges (0), time = 14.026ms.\r\n2018-10-02 17:56:40.778653: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 21 nodes (0), 20 edges (0), time = 73.447ms.\r\n2018-10-02 17:56:40.778657: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 21 nodes (0), 20 edges (0), time = 14.421ms.\r\n2018-10-02 17:56:40.778662: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_34_native_segment\r\n2018-10-02 17:56:40.778666: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 97.452ms.\r\n2018-10-02 17:56:40.778671: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (0), 10 edges (0), time = 51.176ms.\r\n2018-10-02 17:56:40.778676: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 17.601ms.\r\n2018-10-02 17:56:40.778680: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 84.946ms.\r\n2018-10-02 17:56:40.778685: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 16.067ms.\r\n2018-10-02 17:56:40.778690: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv3/my_trt_op_53_native_segment\r\n2018-10-02 17:56:40.778695: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 129.842ms.\r\n2018-10-02 17:56:40.778713: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 65.908ms.\r\n2018-10-02 17:56:40.778718: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 20.821ms.\r\n2018-10-02 17:56:40.778723: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 86.942ms.\r\n2018-10-02 17:56:40.778728: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.451ms.\r\n2018-10-02 17:56:40.778732: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_bottleneck/bottleneck/my_trt_op_0_native_segment\r\n2018-10-02 17:56:40.778737: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 94.827ms.\r\n2018-10-02 17:56:40.778742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 53.676ms.\r\n2018-10-02 17:56:40.778747: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 18.177ms.\r\n2018-10-02 17:56:40.778752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 89.32ms.\r\n2018-10-02 17:56:40.778756: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 16.613ms.\r\n2018-10-02 17:56:40.778761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_36_native_segment\r\n2018-10-02 17:56:40.778765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 74.077ms.\r\n2018-10-02 17:56:40.778770: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 43.634ms.\r\n2018-10-02 17:56:40.778775: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 14.627ms.\r\n2018-10-02 17:56:40.778780: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 66.59ms.\r\n2018-10-02 17:56:40.778784: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 12.386ms.\r\n2018-10-02 17:56:40.778789: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17_native_segment\r\n2018-10-02 17:56:40.778793: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 91.361ms.\r\n2018-10-02 17:56:40.778798: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 62.223ms.\r\n2018-10-02 17:56:40.778803: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 19.545ms.\r\n2018-10-02 17:56:40.778808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 83.007ms.\r\n2018-10-02 17:56:40.778813: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 16.396ms.\r\n2018-10-02 17:56:40.778817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_84_native_segment\r\n2018-10-02 17:56:40.778822: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 88.167ms.\r\n2018-10-02 17:56:40.778830: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 45.84ms.\r\n2018-10-02 17:56:40.778835: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 13.792ms.\r\n2018-10-02 17:56:40.778840: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 78.441ms.\r\n2018-10-02 17:56:40.778845: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 13.941ms.\r\n2018-10-02 17:56:40.778849: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv2/my_trt_op_86_native_segment\r\n2018-10-02 17:56:40.778854: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 82.338ms.\r\n2018-10-02 17:56:40.778859: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 57.127ms.\r\n2018-10-02 17:56:40.778864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.181ms.\r\n2018-10-02 17:56:40.778869: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 94.345ms.\r\n2018-10-02 17:56:40.778874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.682ms.\r\n2018-10-02 17:56:40.778878: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv3/my_trt_op_90_native_segment\r\n2018-10-02 17:56:40.778883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 101.856ms.\r\n2018-10-02 17:56:40.778888: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 61.665ms.\r\n2018-10-02 17:56:40.778893: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 17.499ms.\r\n2018-10-02 17:56:40.778898: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 107.398ms.\r\n2018-10-02 17:56:40.778902: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 21.293ms.\r\n2018-10-02 17:56:40.778907: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_0_native_segment\r\n2018-10-02 17:56:40.778911: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 103.244ms.\r\n2018-10-02 17:56:40.778916: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 13 nodes (4), 12 edges (4), time = 68.954ms.\r\n2018-10-02 17:56:40.778921: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 13 nodes (0), 12 edges (0), time = 22.664ms.\r\n2018-10-02 17:56:40.778926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 13 nodes (0), 12 edges (0), time = 137.616ms.\r\n2018-10-02 17:56:40.778931: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 13 nodes (0), 12 edges (0), time = 28.718ms.\r\n2018-10-02 17:56:40.778935: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_35_native_segment\r\n2018-10-02 17:56:40.778940: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 126.762ms.\r\n2018-10-02 17:56:40.778947: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 7 nodes (0), 6 edges (0), time = 50.357ms.\r\n2018-10-02 17:56:40.778952: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 18.147ms.\r\n2018-10-02 17:56:40.778957: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 80.564ms.\r\n2018-10-02 17:56:40.778962: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 25.198ms.\r\n2018-10-02 17:56:40.778966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15_native_segment\r\n2018-10-02 17:56:40.778971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 83.305ms.\r\n2018-10-02 17:56:40.778976: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 40.139ms.\r\n2018-10-02 17:56:40.778981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 12.973ms.\r\n2018-10-02 17:56:40.778985: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 63.052ms.\r\n2018-10-02 17:56:40.778990: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 13.269ms.\r\n2018-10-02 17:56:40.778995: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv4/my_trt_op_98_native_segment\r\n2018-10-02 17:56:40.778999: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 81.518ms.\r\n2018-10-02 17:56:40.779004: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 47.497ms.\r\n2018-10-02 17:56:40.779009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.047ms.\r\n2018-10-02 17:56:40.779014: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 76.779ms.\r\n2018-10-02 17:56:40.779019: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 15.221ms.\r\n2018-10-02 17:56:40.779023: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_40_native_segment\r\n2018-10-02 17:56:40.779028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 92.461ms.\r\n2018-10-02 17:56:40.779033: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 47.376ms.\r\n2018-10-02 17:56:40.779038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 17.816ms.\r\n2018-10-02 17:56:40.779043: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 90.656ms.\r\n2018-10-02 17:56:40.779047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 14.102ms.\r\n2018-10-02 17:56:40.779052: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_bottleneck/bottleneck/my_trt_op_37_native_segment\r\n2018-10-02 17:56:40.779057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 63.86ms.\r\n2018-10-02 17:56:40.779065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 38.907ms.\r\n2018-10-02 17:56:40.779069: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 11.652ms.\r\n2018-10-02 17:56:40.779074: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 69.803ms.\r\n2018-10-02 17:56:40.779079: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 12.246ms.\r\n2018-10-02 17:56:40.779084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_18_native_segment\r\n2018-10-02 17:56:40.779089: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 69.677ms.\r\n2018-10-02 17:56:40.779093: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 48.913ms.\r\n2018-10-02 17:56:40.779098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 15.775ms.\r\n2018-10-02 17:56:40.779103: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 78.473ms.\r\n2018-10-02 17:56:40.779107: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 15.874ms.\r\n2018-10-02 17:56:40.779112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_33_native_segment\r\n2018-10-02 17:56:40.779117: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 104.174ms.\r\n2018-10-02 17:56:40.779121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (0), 10 edges (0), time = 59.715ms.\r\n2018-10-02 17:56:40.779126: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 19.682ms.\r\n2018-10-02 17:56:40.779131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 110.365ms.\r\n2018-10-02 17:56:40.779136: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 21.466ms.\r\n2018-10-02 17:56:40.779140: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_4_native_segment\r\n2018-10-02 17:56:40.779145: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 112.393ms.\r\n2018-10-02 17:56:40.779149: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 68.502ms.\r\n2018-10-02 17:56:40.779154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 20.575ms.\r\n2018-10-02 17:56:40.779159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 107.055ms.\r\n2018-10-02 17:56:40.779163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 20.598ms.\r\n2018-10-02 17:56:40.779168: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_39_native_segment\r\n2018-10-02 17:56:40.779173: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 98.208ms.\r\n2018-10-02 17:56:40.779181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 7 nodes (0), 6 edges (0), time = 71.593ms.\r\n2018-10-02 17:56:40.779195: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 16.447ms.\r\n2018-10-02 17:56:40.779200: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 90.597ms.\r\n2018-10-02 17:56:40.779204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 19.726ms.\r\n2018-10-02 17:56:40.779209: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_80_native_segment\r\n2018-10-02 17:56:40.779214: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 103.706ms.\r\n2018-10-02 17:56:40.779218: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 66.372ms.\r\n2018-10-02 17:56:40.779223: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 25.863ms.\r\n2018-10-02 17:56:40.779228: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 99.486ms.\r\n2018-10-02 17:56:40.779233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 16.206ms.\r\n2018-10-02 17:56:40.779237: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_26_native_segment\r\n2018-10-02 17:56:40.779242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 98.167ms.\r\n2018-10-02 17:56:40.779247: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (0), 10 edges (0), time = 59.385ms.\r\n2018-10-02 17:56:40.779251: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 16.568ms.\r\n2018-10-02 17:56:40.779256: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 139.949ms.\r\n2018-10-02 17:56:40.779261: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 16.402ms.\r\n2018-10-02 17:56:40.779265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: box_predictor/fc6/my_trt_op_71_native_segment\r\n2018-10-02 17:56:40.779270: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 146.346ms.\r\n2018-10-02 17:56:40.779275: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 64.568ms.\r\n2018-10-02 17:56:40.779279: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 15.238ms.\r\n2018-10-02 17:56:40.779284: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 146.288ms.\r\n2018-10-02 17:56:40.779289: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 20.676ms.\r\n2018-10-02 17:56:40.779294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv3/my_trt_op_48_native_segment\r\n2018-10-02 17:56:40.779298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 107.618ms.\r\n2018-10-02 17:56:40.779306: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 65.234ms.\r\n2018-10-02 17:56:40.779311: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 19.001ms.\r\n2018-10-02 17:56:40.779315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 82.546ms.\r\n2018-10-02 17:56:40.779320: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.445ms.\r\n2018-10-02 17:56:40.779325: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv1/conv1_1/my_trt_op_40_native_segment\r\n2018-10-02 17:56:40.779329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 85.819ms.\r\n2018-10-02 17:56:40.779334: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 50.473ms.\r\n2018-10-02 17:56:40.779339: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 16.447ms.\r\n2018-10-02 17:56:40.779343: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 94.917ms.\r\n2018-10-02 17:56:40.779348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 20.329ms.\r\n2018-10-02 17:56:40.779353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_46_native_segment\r\n2018-10-02 17:56:40.779358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 83.529ms.\r\n2018-10-02 17:56:40.779362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 50.784ms.\r\n2018-10-02 17:56:40.779367: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 14.719ms.\r\n2018-10-02 17:56:40.779372: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 74.205ms.\r\n2018-10-02 17:56:40.779377: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 14.43ms.\r\n2018-10-02 17:56:40.779381: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_12_native_segment\r\n2018-10-02 17:56:40.779387: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 83.226ms.\r\n2018-10-02 17:56:40.779391: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 50.931ms.\r\n2018-10-02 17:56:40.779396: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 17.027ms.\r\n2018-10-02 17:56:40.779401: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 79.41ms.\r\n2018-10-02 17:56:40.779405: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 16.315ms.\r\n2018-10-02 17:56:40.779410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_2_native_segment\r\n2018-10-02 17:56:40.779415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 120.436ms.\r\n2018-10-02 17:56:40.779420: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 13 nodes (4), 12 edges (4), time = 70.529ms.\r\n2018-10-02 17:56:40.779427: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 13 nodes (0), 12 edges (0), time = 21.516ms.\r\n2018-10-02 17:56:40.779432: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 13 nodes (0), 12 edges (0), time = 95.753ms.\r\n2018-10-02 17:56:40.779437: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 13 nodes (0), 12 edges (0), time = 16.356ms.\r\n2018-10-02 17:56:40.779441: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_75_native_segment\r\n2018-10-02 17:56:40.779446: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 88.041ms.\r\n2018-10-02 17:56:40.779451: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 56.761ms.\r\n2018-10-02 17:56:40.779455: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 17.758ms.\r\n2018-10-02 17:56:40.779460: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 74.758ms.\r\n2018-10-02 17:56:40.779465: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 13.811ms.\r\n2018-10-02 17:56:40.779469: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv1/my_trt_op_43_native_segment\r\n2018-10-02 17:56:40.779474: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 79.718ms.\r\n2018-10-02 17:56:40.779479: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 53.626ms.\r\n2018-10-02 17:56:40.779484: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 17.251ms.\r\n2018-10-02 17:56:40.779489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 81.104ms.\r\n2018-10-02 17:56:40.779493: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.558ms.\r\n2018-10-02 17:56:40.779498: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv1/conv1_1/my_trt_op_82_native_segment\r\n2018-10-02 17:56:40.779503: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 115.258ms.\r\n2018-10-02 17:56:40.779507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 57.456ms.\r\n2018-10-02 17:56:40.779512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 17.428ms.\r\n2018-10-02 17:56:40.779517: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 110.812ms.\r\n2018-10-02 17:56:40.779521: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 15.478ms.\r\n2018-10-02 17:56:40.779526: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv1/my_trt_op_81_native_segment\r\n2018-10-02 17:56:40.779530: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 92.83ms.\r\n2018-10-02 17:56:40.779535: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 50.043ms.\r\n2018-10-02 17:56:40.779545: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.106ms.\r\n2018-10-02 17:56:40.779550: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 93.328ms.\r\n2018-10-02 17:56:40.779555: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 22.856ms.\r\n2018-10-02 17:56:40.779559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_3_native_segment\r\n2018-10-02 17:56:40.779564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 8 nodes (0), 7 edges (0), time = 85.217ms.\r\n2018-10-02 17:56:40.779569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 12 nodes (4), 11 edges (4), time = 54.623ms.\r\n2018-10-02 17:56:40.779574: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 12 nodes (0), 11 edges (0), time = 19.887ms.\r\n2018-10-02 17:56:40.779579: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 12 nodes (0), 11 edges (0), time = 123.271ms.\r\n2018-10-02 17:56:40.779583: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 12 nodes (0), 11 edges (0), time = 24.725ms.\r\n2018-10-02 17:56:40.779588: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_29_native_segment\r\n2018-10-02 17:56:40.779593: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 141.313ms.\r\n2018-10-02 17:56:40.779597: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (0), 10 edges (0), time = 71.323ms.\r\n2018-10-02 17:56:40.779602: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 23.05ms.\r\n2018-10-02 17:56:40.779607: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 118.683ms.\r\n2018-10-02 17:56:40.779612: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 23.024ms.\r\n2018-10-02 17:56:40.779616: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: avod_regression/my_trt_op_31_native_segment\r\n2018-10-02 17:56:40.779621: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 136.501ms.\r\n2018-10-02 17:56:40.779626: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 74.682ms.\r\n2018-10-02 17:56:40.779631: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 20.389ms.\r\n2018-10-02 17:56:40.779636: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 86.831ms.\r\n2018-10-02 17:56:40.779640: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 15.856ms.\r\n2018-10-02 17:56:40.779645: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_45_native_segment\r\n2018-10-02 17:56:40.779650: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 87.749ms.\r\n2018-10-02 17:56:40.779654: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 45.413ms.\r\n2018-10-02 17:56:40.779662: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 13.229ms.\r\n2018-10-02 17:56:40.779667: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 66.453ms.\r\n2018-10-02 17:56:40.779671: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 16.001ms.\r\n2018-10-02 17:56:40.779676: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv2/my_trt_op_44_native_segment\r\n2018-10-02 17:56:40.779681: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 79.012ms.\r\n2018-10-02 17:56:40.779685: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 46.284ms.\r\n2018-10-02 17:56:40.779690: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.666ms.\r\n2018-10-02 17:56:40.779695: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 73.283ms.\r\n2018-10-02 17:56:40.779700: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 13.655ms.\r\n2018-10-02 17:56:40.779704: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_1_native_segment\r\n2018-10-02 17:56:40.779709: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 8 nodes (0), 7 edges (0), time = 90.175ms.\r\n2018-10-02 17:56:40.779714: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 12 nodes (4), 11 edges (4), time = 52.019ms.\r\n2018-10-02 17:56:40.779719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 12 nodes (0), 11 edges (0), time = 20.334ms.\r\n2018-10-02 17:56:40.779723: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 12 nodes (0), 11 edges (0), time = 119.619ms.\r\n2018-10-02 17:56:40.779728: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 12 nodes (0), 11 edges (0), time = 16.267ms.\r\n2018-10-02 17:56:40.779733: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv3/my_trt_op_92_native_segment\r\n2018-10-02 17:56:40.779738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 99.147ms.\r\n2018-10-02 17:56:40.779743: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 56.728ms.\r\n2018-10-02 17:56:40.779747: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 17.775ms.\r\n2018-10-02 17:56:40.779752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 86.698ms.\r\n2018-10-02 17:56:40.779757: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 17.552ms.\r\n2018-10-02 17:56:40.779767: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv1/my_trt_op_6_native_segment\r\n2018-10-02 17:56:40.779773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 90.597ms.\r\n2018-10-02 17:56:40.779778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 57.158ms.\r\n2018-10-02 17:56:40.779786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 19.502ms.\r\n2018-10-02 17:56:40.779791: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 84.636ms.\r\n2018-10-02 17:56:40.779796: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.075ms.\r\n2018-10-02 17:56:40.779800: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv4/my_trt_op_57_native_segment\r\n2018-10-02 17:56:40.779805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 106.961ms.\r\n2018-10-02 17:56:40.779810: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 65.187ms.\r\n2018-10-02 17:56:40.779815: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.778ms.\r\n2018-10-02 17:56:40.779819: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 83.257ms.\r\n2018-10-02 17:56:40.779824: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 16.312ms.\r\n2018-10-02 17:56:40.779829: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/conv4/my_trt_op_96_native_segment\r\n2018-10-02 17:56:40.779833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 76.479ms.\r\n2018-10-02 17:56:40.779839: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 46.597ms.\r\n2018-10-02 17:56:40.779843: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 14.137ms.\r\n2018-10-02 17:56:40.779848: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 69.406ms.\r\n2018-10-02 17:56:40.779853: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 13.234ms.\r\n2018-10-02 17:56:40.779857: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_42_native_segment\r\n2018-10-02 17:56:40.779862: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 68.474ms.\r\n2018-10-02 17:56:40.779867: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 43.52ms.\r\n2018-10-02 17:56:40.779872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 26.47ms.\r\n2018-10-02 17:56:40.779877: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 78.794ms.\r\n2018-10-02 17:56:40.779881: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 14.8ms.\r\n2018-10-02 17:56:40.779886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: img_vgg_pyr/my_trt_op_42_native_segment\r\n2018-10-02 17:56:40.779891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 85.927ms.\r\n2018-10-02 17:56:40.779895: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 43.878ms.\r\n2018-10-02 17:56:40.779903: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 13.236ms.\r\n2018-10-02 17:56:40.779908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 71.235ms.\r\n2018-10-02 17:56:40.779912: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 12.904ms.\r\n2018-10-02 17:56:40.779917: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_5_native_segment\r\n2018-10-02 17:56:40.779922: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 70.093ms.\r\n2018-10-02 17:56:40.779927: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 9 nodes (0), 8 edges (0), time = 43.777ms.\r\n2018-10-02 17:56:40.779932: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 15.261ms.\r\n2018-10-02 17:56:40.779936: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 9 nodes (0), 8 edges (0), time = 64.352ms.\r\n2018-10-02 17:56:40.779941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 9 nodes (0), 8 edges (0), time = 11.675ms.\r\n2018-10-02 17:56:40.779946: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_9_native_segment\r\n2018-10-02 17:56:40.779950: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 10 nodes (0), 9 edges (0), time = 138.978ms.\r\n2018-10-02 17:56:40.779955: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 10 nodes (0), 9 edges (0), time = 61.699ms.\r\n2018-10-02 17:56:40.779960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 10 nodes (0), 9 edges (0), time = 15.373ms.\r\n2018-10-02 17:56:40.779965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 10 nodes (0), 9 edges (0), time = 153.454ms.\r\n2018-10-02 17:56:40.779970: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 10 nodes (0), 9 edges (0), time = 24.219ms.\r\n2018-10-02 17:56:40.779974: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv3/my_trt_op_51_native_segment\r\n2018-10-02 17:56:40.779979: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 124.851ms.\r\n2018-10-02 17:56:40.779984: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 76.039ms.\r\n2018-10-02 17:56:40.779989: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 23.789ms.\r\n2018-10-02 17:56:40.779993: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 91.301ms.\r\n2018-10-02 17:56:40.779998: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 18.15ms.\r\n2018-10-02 17:56:40.780003: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16_native_segment\r\n2018-10-02 17:56:40.780008: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 103.999ms.\r\n2018-10-02 17:56:40.780013: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 58.96ms.\r\n2018-10-02 17:56:40.780018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 20.132ms.\r\n2018-10-02 17:56:40.780026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 96.461ms.\r\n2018-10-02 17:56:40.780031: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 18.506ms.\r\n2018-10-02 17:56:40.780035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: my_trt_op_13_native_segment\r\n2018-10-02 17:56:40.780040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 159.507ms.\r\n2018-10-02 17:56:40.780045: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 5 nodes (0), 4 edges (0), time = 78.108ms.\r\n2018-10-02 17:56:40.780050: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 27.84ms.\r\n2018-10-02 17:56:40.780054: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 5 nodes (0), 4 edges (0), time = 142.559ms.\r\n2018-10-02 17:56:40.780059: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 20.611ms.\r\n2018-10-02 17:56:40.780064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/my_trt_op_49_native_segment\r\n2018-10-02 17:56:40.780068: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 7 nodes (0), 6 edges (0), time = 92.86ms.\r\n2018-10-02 17:56:40.780073: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 11 nodes (4), 10 edges (4), time = 58.017ms.\r\n2018-10-02 17:56:40.780078: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 21.799ms.\r\n2018-10-02 17:56:40.780082: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 11 nodes (0), 10 edges (0), time = 115.933ms.\r\n2018-10-02 17:56:40.780087: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 11 nodes (0), 10 edges (0), time = 23.586ms.\r\n2018-10-02 17:56:40.780092: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: bev_vgg_pyr/conv3/my_trt_op_14_native_segment\r\n2018-10-02 17:56:40.780097: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 100.614ms.\r\n2018-10-02 17:56:40.780102: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 6 nodes (0), 5 edges (0), time = 71.394ms.\r\n2018-10-02 17:56:40.780106: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 22.289ms.\r\n2018-10-02 17:56:40.780111: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 107.775ms.\r\n2018-10-02 17:56:40.780116: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 6 nodes (0), 5 edges (0), time = 21.687ms.\r\nexecuting\r\n2018-10-02 17:56:43.449862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-10-02 17:56:43.450066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-02 17:56:43.450077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-10-02 17:56:43.450085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-10-02 17:56:43.450426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11334 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2018-10-02 17:56:47.919658: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:47.919799: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14\r\n2018-10-02 17:56:47.919973: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:47.920014: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16\r\n2018-10-02 17:56:47.996399: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:47.996398: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:47.996490: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17\r\n2018-10-02 17:56:47.996497: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15\r\n2018-10-02 17:56:48.276289: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.276379: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc6_drop/dropout/my_trt_op_72\r\n2018-10-02 17:56:48.321104: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.321176: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc7_drop/dropout/my_trt_op_73\r\n2018-10-02 17:56:48.364818: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.364933: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc8_drop/dropout/my_trt_op_74\r\n5.28882312775\r\n2018-10-02 17:56:48.856168: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.856186: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.856236: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14\r\n2018-10-02 17:56:48.856259: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16\r\n2018-10-02 17:56:48.856704: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.856732: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15\r\n2018-10-02 17:56:48.856766: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.856798: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17\r\n2018-10-02 17:56:48.879536: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.879587: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc6_drop/dropout/my_trt_op_72\r\n2018-10-02 17:56:48.879916: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.879950: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc7_drop/dropout/my_trt_op_73\r\n2018-10-02 17:56:48.880169: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.880187: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc8_drop/dropout/my_trt_op_74\r\n0.145184993744\r\n2018-10-02 17:56:48.977994: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.978025: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.978059: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14\r\n2018-10-02 17:56:48.978075: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16\r\n2018-10-02 17:56:48.978390: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.978406: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15\r\n2018-10-02 17:56:48.978410: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.978427: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17\r\n2018-10-02 17:56:48.993653: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.993714: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc6_drop/dropout/my_trt_op_72\r\n2018-10-02 17:56:48.993915: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.993939: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc7_drop/dropout/my_trt_op_73\r\n2018-10-02 17:56:48.994105: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:48.994121: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc8_drop/dropout/my_trt_op_74\r\n0.11088013649\r\n2018-10-02 17:56:49.091495: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.091508: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.091550: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14\r\n2018-10-02 17:56:49.091563: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16\r\n2018-10-02 17:56:49.091917: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.091935: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15\r\n2018-10-02 17:56:49.091945: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.091968: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17\r\n2018-10-02 17:56:49.105637: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.105693: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc6_drop/dropout/my_trt_op_72\r\n2018-10-02 17:56:49.105894: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.105917: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc7_drop/dropout/my_trt_op_73\r\n2018-10-02 17:56:49.106113: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.106136: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc8_drop/dropout/my_trt_op_74\r\n0.112968921661\r\n2018-10-02 17:56:49.217640: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.217641: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.217740: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc6_drop/dropout/my_trt_op_14\r\n2018-10-02 17:56:49.217756: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc6_drop/dropout/my_trt_op_16\r\n2018-10-02 17:56:49.218166: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.218185: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/cls_fc7_drop/dropout/my_trt_op_15\r\n2018-10-02 17:56:49.218238: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.218265: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/anchor_predictor/reg_fc7_drop/dropout/my_trt_op_17\r\n2018-10-02 17:56:49.233776: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.233867: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc6_drop/dropout/my_trt_op_72\r\n2018-10-02 17:56:49.234110: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.234136: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc7_drop/dropout/my_trt_op_73\r\n2018-10-02 17:56:49.234388: E tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:314] Input node not found, at TensorRTInputPH_0\r\n2018-10-02 17:56:49.234412: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:295] Failed to execute engine, retrying with native segment for import/box_predictor/fc8_drop/dropout/my_trt_op_74\r\n0.12806391716\r\n```\r\n", "comments": ["@aaroey Can you take a quick look when you have a moment?", "This seems similar to #21248, which was fixed by #22371. The fix is in master but not in 1.11. I'd like to check whether that fix solves this issue but I'm not sure how to get your model `/home/ecli/avod/avod/data/outputs/pyramid_people_with_aug_flexible_batchsize_example/checkpoints/frozen_model.pb`. Would you help to `pip install --upgrade tf-nightly-gpu` and use that to rerun your program for a quick check?\r\n\r\nThanks.", "@aaroey Thank you for your help.\r\n\r\nAfter I `pip install --upgrade tf-nightly-gpu`, the original problem was solved. However, I barely saw any speed gain for FP16.\r\n\r\nI tried to convert the model to INT8, and got the following error:\r\n```\r\n2018-10-04 13:48:44.155956: I tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:578] Starting calibration thread on device 0, Calibration Resource @ 0x7f3920000b80\r\npython: helpers.cpp:56: nvinfer1::DimsCHW nvinfer1::getCHW(const nvinfer1::Dims&): Assertion `d.nbDims >= 3' failed.\r\nfish: Job 2, \u201cpython tf_to_trt.py\u201d terminated by signal SIGABRT (Abort)\r\n```\r\nHere is part of my source code (modified from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/tensorrt/test/test_tftrt.py)\r\n```\r\n        int8_calib_gdef = trt.create_inference_graph(\r\n            input_graph_def=orig_graph,\r\n            outputs=output_node_name,\r\n            max_batch_size=1000,\r\n            max_workspace_size_bytes=1 << 25,\r\n            precision_mode=precision,\r\n            minimum_segment_size=2,\r\n            is_dynamic_op=False,\r\n            maximum_cached_engines=1)\r\n        _ = execute_calibration(int8_calib_gdef)\r\n        return trt.calib_graph_to_infer_graph(int8_calib_gdef)\r\n```\r\nSimilar issues have also been posted on NVIDIA Developer Forum [post1]( https://devtalk.nvidia.com/default/topic/1042165/assertion-d-nbdims-gt-3-failed-with-int8-mode/?offset=1) and [post2](https://devtalk.nvidia.com/default/topic/1038306/tensorrt/nvinfer1-dimschw-nvinfer1-getchw-const-nvinfer1-dims-amp-assertion-d-nbdims-gt-3-failed-/?offset=2#5286167), but it has not be solved yet. \r\n\r\nI really appreciate your help. Thanks a ton! \r\n\r\n\r\n\r\n\r\n", "@ChengshuLi by `However, I barely saw any speed gain for FP16.` are you comparing with TRT FP32?\r\n\r\nThe error `nvinfer1::DimsCHW nvinfer1::getCHW(const nvinfer1::Dims&): Assertion 'd.nbDims >= 3' failed` is caused by a known bug in the TRT 4.0 library, and TRT 5.0 should fix the problem.", "@aaroey Thanks for your reply.\r\n\r\nI tried tensorflow-native, FP32 and FP16. All three models seem to have the same inference speed.\r\n\r\n`The error nvinfer1::DimsCHW nvinfer1::getCHW(const nvinfer1::Dims&): Assertion 'd.nbDims >= 3' failed is caused by a known bug in the TRT 4.0 library, and TRT 5.0 should fix the problem.` Last time when I tried to use TRT 5.0 with TF1.11, but it complains that TF is built with TRT 4.0 and does NOT support TRT 5.0. I haven't tried your `tf-nightly-gpu` yet. Does it support TRT 5.0?\r\n\r\nThanks!\r\n", "@ChengshuLi regarding `I tried tensorflow-native, FP32 and FP16. All three models seem to have the same inference speed.` I think the main reason is that the conversion creates a lot of small TRT engines, most of which contains <=5 nodes and the largest one contains only 30 nodes. TRT prefers large engines so it can optimize it better, so it may be worthwhile to investigate why it is not the case for your graph.\r\n\r\nFor TRT5, I believed as of today it's still an RC, and TF do not release with RC libraries. We're working on testing TRT5 and once it's final version is released we'll get it into TF ASAP.\r\n\r\nThanks.", "Since the original problem is fixed, I'm closing this. Feel free to file a new one for the assertion error, which should be fixed in the next release.\r\n\r\nThanks."]}, {"number": 22681, "title": "tensorflow.python.data.ops.dataset_ops.DatasetSource", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source \r\n- **TensorFlow version (use command below)**: 1.11\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.16\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nThe abstract class [DatasetSource](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L1496) is defined for representing a dataset with no inputs. The datasets (e.g. [CsvDataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/readers.py#L513)) defined under `tensorflow/python/data/experimental/ops/readers.py` are inherited from `DatasetSource`, but these three [FixedLengthRecordDataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/readers.py#L250), [TextLineDataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/readers.py#L35), and [TFRecordDataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/readers.py#L80) in `tensorflow/python/data/ops/readers.py` are herited from [Dataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L53). In my understanding, they also need to be inherited from `DatasetSource`. If my understanding is right, I would like to submit a PR to update them.", "comments": ["@jsimsa Could you have a look at this issue?", "SGTM", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 22680, "title": "1.12-rc0 cherry-pick request: Pin wheel=0.31.1 to work around issue https://github.com/pypa/auditwheel/issues/102", "body": "Needed to fix test failures in tensorflow/ubuntu/release/cpu/pip", "comments": []}]