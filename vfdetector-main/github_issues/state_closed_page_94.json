[{"number": 52331, "title": "How to use to use TFLite model in Flask ?", "body": "I have a tflite model which accepts float32 input. Works fine if I load model each time on prediction. But for faster processing, I want to do as below. Then it's throwing an error of -\r\n\r\n****RuntimeError: There is at least 1 reference to internal data in the interpreter in the form of a NumPy array or slice. Be sure to only hold the function returned from tensor() if you are using raw data access.****\r\n\r\n```\r\n[physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)  \r\n    \r\napp = Flask(__name__,template_folder='template', static_url_path = \"/static\")\r\nCORS(app)\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=\"quant_model.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ndef generate_frames(frame):\r\n\r\n    img_face = cv2.resize(frame,(256,256))\r\n    img_face = cv2.cvtColor(img_face, cv2.COLOR_BGR2RGBA)\r\n\r\n    #converting into float32\r\n    img_face_f = (img_face/255.0).astype(np.float32)\r\n\r\n    #prediction\r\n    img_face_f = run_inference(np.expand_dims(img_face_f[:,:,:3], axis=0)) # <<< problem happens here\r\n\r\n            \r\n    final_result = (img_face_f*255).astype(np.uint8)\r\n            \r\n    ret,buffer=cv2.imencode('.jpg',final_result)\r\n\r\n    frame=buffer.tobytes()\r\n\r\n    return frame\r\n\r\n\r\n\r\ndef run_inference(image):\r\n    # perform inference and parse the outputs\r\n    interpreter.set_tensor(input_details[0]['index'], image)\r\n    interpreter.invoke()\r\n    outputs = interpreter.get_tensor(output_details[0]['index'])[0]\r\n    return outputs\r\n    \r\n    \r\nif __name__ == '__main__':\r\n    app.run(debug=True)](url)\r\n```\r\n\r\nWhy TFLite doesn\u2019t support calling like above?", "comments": ["Hi @somum! Could you look at this threads for answer [link1](https://stackoverflow.com/questions/56777704/how-to-fix-there-is-at-least-1-reference-to-internal-data-in-the-interpreter-in) ,[link2 ](https://github.com/robmarkcole/tensorflow-lite-rest-server/blob/master/tflite-server.py),[link3,](https://stackoverflow.com/questions/65945549/how-to-use-tensorflow-lite-on-a-raspberry-pi-4-without-keras)[,link4](https://stackoverflow.com/questions/54006031/tf-lite-model-test-fails-with-run-time-error) for  answer. Please post on [discuss](https://discuss.tensorflow.org/) to proceed further as there is a larger community to help you out. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52331\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52331\">No</a>\n"]}, {"number": 52329, "title": "Invalid argument error", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n\r\n- TensorFlow installed from (source or binary):\r\npip install tensorflow\r\n\r\n- TensorFlow version (use command below):\r\n2.6.0\r\n\r\n- Python version:\r\n3.7\r\n\r\n- CUDA/cuDNN version:\r\n11.3\r\n\r\n- GPU model and memory:\r\nNVIDIA 2060 SUPER, compute capability: 7.5\r\n6010MB\r\n\r\n\r\nI am trying to create a model that takes two images (one taken right after the other) and train it so that it can predict how much movement has occurred. I use a smaller model that processes one image at a time, then concatenate the two outputs in a larger model.\r\n\r\nI tried testing it and the model compiles just fine, but it crashes when I call fit() and gives me an invalid argument error.\r\n\r\n```\r\n2021-10-11 10:46:28.321065: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-10-11 10:46:29.319124: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 5. But input(1) is a vTraceback (most recent call last):\r\n2021-10-11 10:46:29.319416: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 5. But input(1) is a vTraceback (most recent call last):\r\n  File \"d:/.../Deep Sight/deep_sight.py\", line 155, in <module>\r\n    main()\r\n  File \"d:/.../Deep Sight/deep_sight.py\", line 150, in main\r\n    final_model.fit(train_data, epochs=5)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 950, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3040, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1964, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 596, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  transpose expects a vector of size 5. But input(1) is a vector of size 4\r\n         [[{{node gradient_tape/model_1/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\r\n         [[Func/mean_squared_error/cond/then/_0/input/_29/_48]]\r\n  (1) Invalid argument:  transpose expects a vector of size 5. But input(1) is a vector of size 4\r\n         [[{{node gradient_tape/model_1/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_3095]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nMy batch size is 32 as defined in my dataset. I believe it has something to do with the squeeze method because in an earlier version of this model I did not use the squeeze or split methods and it ran perfectly fine. However, because my dataset is much larger now, I shifted to using tf.Datasets to input the data. This required me to input the 2 images together in a single tensor as the input.\r\n\r\nThe shape of my dataset is: (batch, features, labels) with the label being a scalar, and each feature being of shape: (2, 256, 256, 3)\r\n\r\n```python\r\ndef main():\r\n    # Create model\r\n\r\n    # Start with smaller model that processes the two images in the same way.\r\n    single_image_input = keras.Input(shape=(256,256,3))\r\n\r\n    image = layers.Conv2D(64, (3,3))(single_image_input)\r\n    image = layers.LeakyReLU()(image)\r\n    image = layers.BatchNormalization()(image)\r\n    # Run through MaxPool2D to help the algorithm identify features in different areas of the image.\r\n    # Has the effect of downsampling and cutting the dimensions in half.\r\n    image = layers.MaxPool2D()(image)\r\n\r\n    image = layers.Conv2D(128, (3, 3))(image)\r\n    image = layers.LeakyReLU()(image)\r\n    image = layers.BatchNormalization()(image)\r\n    image = layers.Dropout(.3)(image)\r\n\r\n    image_model = keras.Model(single_image_input, image)\r\n    \r\n    # Create larger model\r\n    image_inputs = keras.Input(shape=(2,256,256,3))\r\n\r\n    first_image, second_image = tf.split(image_inputs, num_or_size_splits=2, axis=0)\r\n    first_image, second_image = tf.squeeze(first_image), tf.squeeze(second_image)\r\n\r\n    image_outputs = [image_model(first_image), image_model(second_image)]\r\n    model = layers.Concatenate()(image_outputs)\r\n\r\n    model = layers.Flatten()(model)\r\n\r\n    model = layers.Dense(128)(model)\r\n    model = layers.LeakyReLU()(model)\r\n    model = layers.BatchNormalization()(model)\r\n    model = layers.Dropout(.3)(model)\r\n\r\n    # Output is change in y-position of drone\r\n    out_layer = layers.Dense(1, activation='linear')(model)\r\n\r\n    final_model = keras.Model(image_inputs, out_layer)\r\n    final_model.compile(loss=\"mse\", optimizer=optimizers.Adam(lr=0.0003, beta_1=0.7))\r\n\r\n    image_model.summary()\r\n\r\n    final_model.summary()\r\n\r\n\r\n    #Preprocess data\r\n    print(\"Loading and processing data...\")\r\n    train_data = tf_load_data()\r\n\r\n    #Train model\r\n    final_model.fit(train_data, epochs=5)\r\n```\r\n", "comments": ["Hold up, I just realized my mistake. I thought the split method was ignoring the batch dimension. It does not. I fixed it by changing the split method to read: \r\ntf.split(image_inputs, num_or_size_splits=2, **axis=1**) ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52329\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52329\">No</a>\n", "Sigh... Nevermind. It's still an issue, it just gave me a different error at first that I thought I could fix. After I fixed that error it gave me a very similar error to the one above. However, it appears that it attempted to start training the model.\r\n\r\nIn case it matters, the previous error was an OOM error. I just reduced the size of the images I am feeding the network to 128x128 instead of 256x256.\r\n\r\n```\r\nEpoch 1/5\r\n2021-10-11 11:41:23.993854: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-10-11 11:41:28.606390: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8200\r\n      7/Unknown - 18s 81ms/step - loss: 63.80682021-10-11 11:41:41.279014: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 3. But input(1) is a vector of size 4\r\n2021-10-11 11:41:41.279317: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 3. But input(1) is a vector of size 4\r\nTraceback (most recent call last):\r\n  File \"d:/.../Deep Sight/deep_sight.py\", line 155, in <module>\r\n    main()\r\n  File \"d:/.../Deep Sight/deep_sight.py\", line 150, in main\r\n    final_model.fit(train_data, epochs=5)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 917, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3040, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1964, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 596, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  transpose expects a vector of size 3. But input(1) is a vector of size 4\r\n         [[{{node gradient_tape/model_1/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\r\n         [[Func/mean_squared_error/cond/then/_0/input/_29/_48]]\r\n  (1) Invalid argument:  transpose expects a vector of size 3. But input(1) is a vector of size 4\r\n         [[{{node gradient_tape/model_1/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_3137]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function\r\n```", "Hi @Koratun \r\nCan you please provide the shape of the train_data or better can you please provide the code to generate the error. Instead of images you may use a np.random array of the same shape.", "As I indicated in my first post the shape of train_data is a nested structure as follows: \r\n(batch: 32, features: [2, 128, 128, 3], labels: a scalar) \r\nNote: I only changed the features to 128x128 after encountering an OOM error with 256.\r\n\r\nThe code I have provided is the code that generates this error. \r\n\r\nThe point of my model is to train it to see how much movement occurred based on the images, so random data would not help in this situation.", "@Koratun ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.Thanks!", "Hi @Koratun \r\nYou are splitting your input in second model along axis= 0\r\n`first_image, second_image = tf.split(image_inputs, num_or_size_splits=2, axis=0)`\r\naxis =0 is meant for batch and you dataset of shape (32, 2, 128, 128, 3) gets splitted into shape (16, 2, 128, 128, 3) and thus squeeze doesnt work.\r\nCan you please try out by replacing the axis=0 with axis =1\r\nThank you", "Here they are @tilakrayal \r\n[Data and Code.zip](https://github.com/tensorflow/tensorflow/files/7331695/Data.and.Code.zip)\r\n\r\nAnd @old-school-kid, as I indicated in my second comment, I noticed this and fixed it. It then produced the error I reported in my third comment.\r\n", "@Koratun ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "I went ahead and opened an issue on Keras as you recommended: https://github.com/keras-team/keras/issues/15518", "@Koratun ,\r\nPlease feel free to close this issue,as it has been tracked there in Keras repo.Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52329\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52329\">No</a>\n"]}, {"number": 52328, "title": "r2.7 cherry-pick request: Update MklMatMulPrimitiveFactory to support Arm Compute Library backend", "body": "Original PR (merged into master): https://github.com/tensorflow/tensorflow/pull/52261\r\n\r\nAdd support for caching oneDNN matmul primitives in the `mkl_aarch64` build. (Doesn't affect vanilla TF.) The changes in TF are small. Most of the changes are in the patch file for the oneDNN aarch64 repository.\r\n\r\nThis is more of a performance improvement (feature) PR rather than a performance regression fix. Creating a cherry-pick just in case it can be accepted.\r\n\r\n@cfRod Could you please help post some performance numbers here (e.g., how much improvements you saw for some models)? Thank you very much!\r\n\r\n\r\n\r\n", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52328) for more info**.\n\n<!-- need_author_consent -->", "Manually setting CLA to yes since the commit is from a PR that is already merged into master (https://github.com/tensorflow/tensorflow/pull/52261).", "Hi @penpornk, that would be approximately ~2x performance improvements for BERT benchmarks over reference oneDNN.\r\n\r\n"]}, {"number": 52327, "title": "Fix the Person tutorial link, direct to tensorflow/tflite-micro", "body": "Addresses https://github.com/tensorflow/tensorflow/issues/52321 @advaitjain PTAL, thanks!", "comments": ["Thanks for the PR. I'll help get this merged."]}, {"number": 52326, "title": "r2.7 cherry-pick request: Fix oneDNN-related eager nightly test failures", "body": "Original PR (merged into master): https://github.com/tensorflow/tensorflow/pull/52204 \r\n\r\nFix `//tensorflow/python/kernel_tests:matmul_op_test` and `run_eager_op_as_function_test`, that failed with error \"Could not find device for node:\" when oneDNN is on.\r\n\r\nThese failures are because of the recent `WrapInCallOp` changes https://github.com/tensorflow/tensorflow/commit/1224326\r\n\r\nDetailed explanation from the original PR:\r\n> For MKL : we expect WrapInCallOp to be called before we infer device, which marks the '_kernel' attribute as NameChangeOp label for nodeDef of funcDef.\r\nSince with new commit, WrapInCallOp is called AFTER the device inference, no device is found for the MKL Op as no kernel match is found without namechange label.\r\n>\r\n> In this PR: we mark nodeDef with '_kernel' attribute as NameChange label at both places : a) before inferring the device and b) inside WrapInCallOp (already present in current code base)\r\n\r\n\r\n", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52326) for more info**.\n\n<!-- need_author_consent -->", "Manually setting CLA to yes because these commits are from a PR that is already merged into master (https://github.com/tensorflow/tensorflow/pull/52204)."]}, {"number": 52325, "title": "keras.layers.IntegerLookup fails to deserialize vocubulary", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nWhen creating a keras.layers.IntegerLookup, we provide a vocabulary.  This is saved off via serialization.  However, upon deserialization, the vocabulary is not loaded correctly --- the layer continues to work, however, one cannot serialize again.\r\n\r\n**Describe the expected behavior**\r\nWe should be able to serialize and deserialize IntegerLookups any number of times.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nTo reproduce, see https://colab.research.google.com/drive/1tpXdEsfYKyax5QhYLR7KAV4P2vQHIT8D?usp=sharing .  It is interesting to note that I cannot reproduce by just serializing to JSON --- I have to serialize to SavedModel.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nFrom looking at the code, https://github.com/keras-team/keras/blob/v2.6.0/keras/layers/preprocessing/index_lookup.py#L200 , it appears that we are setting `vocabulary`, but not `input_vocabulary`.  Since `vocabulary` is set, the layer works fine.  But, upon the next serialization, we do serialize an empty vocab: https://github.com/keras-team/keras/blob/v2.6.0/keras/layers/preprocessing/index_lookup.py#L333 .\r\n\r\nIt is not clear to me the difference between `input_vocabulary` and `vocabulary`.\r\n\r\nThis is also related to https://github.com/tensorflow/tensorflow/issues/43834\r\n", "comments": ["Hi @sanatmpa1! Could you look at this issue .It is replicating [2.6](https://colab.research.google.com/gist/mohantym/a09239e2a3c500fecda32a3e8a14f8d9/re-serialization-of-integerlookup.ipynb#scrollTo=I4jgqXmeMZEs) and [nightly ](https://colab.research.google.com/gist/mohantym/fb1ce23703caff04827585a8c81ee134/re-serialization-of-integerlookup.ipynb#scrollTo=SiIdXEt9OVmi)and throwing attribute error in [2.5](https://colab.research.google.com/gist/mohantym/48c7ba895cbb6ea86409bb6fe789f62b/re-serialization-of-integerlookup.ipynb#scrollTo=WMHcuqiO_6cC)", "@jeisinge,\r\n\r\nAs this issue is mostly related to Keras, Can you please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues),To know more see;[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)", "Done - I just reposted at https://github.com/keras-team/keras/issues/15508 .  It is not clear to me if this is a Keras issue or a TF issue.", "@jeisinge,\r\n\r\nAs I see a new issue has been raised in `Keras` repo and it is in progress, Can you close this issue here? Thanks!", "Sure --- if that is the best place for the defect!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52325\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52325\">No</a>\n"]}, {"number": 52324, "title": "Add support for python 3.10 please.", "body": null, "comments": ["@thisisamirv \r\nDepending on our dependencies, plan is to start supporting python 3.10 in tf-nightly first and then in the TF 2.8 release.Please refer to this [comment ](https://github.com/tensorflow/tensorflow/issues/51776#issuecomment-934569048)and let us know if it answers your query ? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Please see discussion in [TF Forum](https://discuss.tensorflow.org/t/support-python-3-10/124?u=mihaimaruseac)", "Is Tensorflow for python 3.10 still unavailable? I couldn't find it ", "Please see reply above you, quoted here for convenience\r\n\r\n> Please see discussion in [TF Forum](https://discuss.tensorflow.org/t/support-python-3-10/124?u=mihaimaruseac)\r\n\r\n", "I see tf2.8-rc0 cames out already. does it support python3.10 already?", "Yes, except on windows. See TF Forum for more details", "> Yes, except on windows. See TF Forum for more details\r\n\r\nAny timeline for when it will also work on windows?"]}, {"number": 52322, "title": "tensorflow_addons.losses.metric_learning.pairwise_distance. Cannot convert a symbolic Tensor (2nd_target:0) to a numpy array", "body": "Whent I try to use the pairwise_distance function is the the following error \"Cannot convert a symbolic Tensor (2nd_target:0) to a numpy array\".\r\n\r\nI found that is because **line 67 in the pairwise_distance function** is written as:\r\n\r\n**tf.ones([num_data])**\r\n\r\nInstead of: \r\n\r\n**tf.ones((num_data))**\r\n\r\nPlease check if this is correct and fix it.\r\n\r\nThe function works perfectly after I changed that line of code.\r\n", "comments": ["@spaghettix ,\r\nCan you please share the link where requested change is to be made.Thanks!\r\n", "Hi, do you mean this?\r\n\r\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/losses/metric_learning.py#:~:text=tf.linalg.diag(-,tf.ones(%5Bnum_data%5D,-)", "@spaghettix ,\r\nCan you please provide the colab gist for the mentioned code where your statement got justified.It helps to analyse the issue and raise the PR for the bug.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52322\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52322\">No</a>\n"]}, {"number": 52321, "title": "Tutorial link is missing", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/tutorials/pose_classification\r\n\r\n## Description of issue (what needs changing):\r\n\r\n![2021-10-11-16-41-12](https://user-images.githubusercontent.com/22192610/136760032-46631c11-5db9-46f4-9833-2ae4f2e4618a.png)\r\nTutorial link is missing:\r\n![2021-10-11-16-42-33](https://user-images.githubusercontent.com/22192610/136760173-e6fcbaa5-db92-4f74-8ffb-3fe1870f4ff4.png)\r\n![2021-10-11-16-43-19](https://user-images.githubusercontent.com/22192610/136760314-73b2970d-d283-4cfe-b319-918b0549b848.png)\r\n\r\n\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["Hi @sachinprasadhs !Could you please look at this bug ?", "PR submitted, thanks all", "The related PR has been merged , closing this issue.Thank you"]}, {"number": 52320, "title": "CropAndResizeGradImage yields different results for each run", "body": "**System information**\r\n- Have I written custom code, see attached script at the end\r\n- Linux Ubuntu 18.04, kernel 4.15\r\n- TensorFlow 2.6 installed via pip\r\n- Python version 3.6.9\r\n\r\n**Describe the current behavior**\r\nrunning the attached script fails due to results mismatch between runs\r\n\r\n**Describe the expected behavior**\r\nall runs of CropAndResizeGradImage should produce the same exact results\r\n\r\nNote that changing channels to smaller value makes the test passing.\r\n\r\nCode:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nout_dtype = tf.float32\r\nimg_size = 1\r\nC = 40 # stable results\r\nC = 41 # unstable results\r\nN = 1  # batch size\r\nH = img_size\r\nW = img_size\r\nB = 2  # qnt of boxes\r\nboxes_shape = (B, 4)\r\nindices_shape = (B,)\r\ncropsize = [14, 14]\r\nimage_size = [N, H, W, C]\r\ngrads_shape = (B, cropsize[0], cropsize[1], C)\r\nnp.random.seed(1000)\r\ngrads = np.random.uniform(-1.0, 1.0, grads_shape)\r\nboxes = np.zeros(boxes_shape)\r\nindices = np.zeros(indices_shape)\r\n\r\ndef run_graph():\r\n    return tf.raw_ops.CropAndResizeGradImage(\r\n            grads=grads,\r\n            boxes=boxes,\r\n            box_ind=indices,\r\n            image_size=image_size,\r\n            method='bilinear',\r\n            T=out_dtype)\r\n\r\nfirst_result = run_graph()\r\n\r\nfor i in range(10):\r\n    np.testing.assert_array_equal(run_graph(), first_result)\r\n```", "comments": ["@sanatmpa1 Was able to reproduce this issue on colab using TF v2.6 and tf-nightly ,Please find the [gist](https://colab.research.google.com/gist/sushreebarsa/44c6ea431c870c788985b73a0821e047/52320.ipynb) for reference.Thanks!", "Hi @sushreebarsa \r\nI tried the same code with data type float64 and the results are better than float32. It passes sometimes completely with no mismatch and sometimes only 1 out of 41 is mismatched. Could you please let know how to access the source code of low-level APIs. Thank you!", "The source code for the op is at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/image/crop_and_resize_op.cc#L354 if you wanted to take a look. \r\n\r\nThe code seems to suggest there is a bit of non-determinism introduced because of sharding and if you want deterministic execution you can enable op determinism\r\n\r\n```\r\ntf.config.experimental.enable_op_determinism()\r\n```\r\n\r\nAlthough, this is feature is only available in TF nightly for now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52320\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52320\">No</a>\n"]}, {"number": 52319, "title": "Build the proto files using protoc seperately", "body": "Hi Tensorflow team,\r\n\r\nI want to separately compile the proto files which are present here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/framework and generate the .pb.h and .pb.h.cc files for each proto file.\r\nSo, what is the way to do that? Can anyone help me with the same? Would be a great help from yourside.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow version: 2.3\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 3.9.1\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n\r\nLooking forward to your reply.\r\n\r\nThanks and Regards\r\n\r\n\r\n\r\n", "comments": ["@Darshvino ,\r\nCan you please look at this links [1](https://developers.google.com/protocol-buffers/docs/reference/cpp-generated#invocation) and [2](https://stackoverflow.com/questions/55092496/compiling-proto-in-tensorflow-models-research-not-object-detctio) which provide information on proto files.Also please try to test the code in latest tf v2.6.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52319\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52319\">No</a>\n"]}, {"number": 52318, "title": "tf.lite.Interpreter set_tensor failing to properly recognize uint8 input tensors", "body": "**System information**\r\n- Ubuntu 20.0.04\r\n- Intel Atom\r\n- Binary installation installed from build without SSE3 instructions\r\n- TensorFlow 2.3.0\r\n- Python 3.6\r\n- No CUDA/GPU/TPU\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI have a working `.tflite` model (which takes 180x180 float greyscale image) as input, and returns 6 float sigmoid outputs. All works as-expected yielding expected results with test images.\r\n\r\nI am trying to quantize `.tflite` model to `uint8`. Notice I am setting the input and output types to `unit8` (edited for brevity):\r\n\r\n```model = tf.keras.models.load_model(\"bkgmodel.h5\")\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n```\r\nWhen I try to run inference on it with the following code (brevity):\r\n\r\n``` img_array= np.array(np.expand_dims(img_array/1.0,0), dtype=np.uint8)\r\n  print (\"IMAGE_ARRAY type\",img_array.dtype)\r\n  interpreter = tf.lite.Interpreter(model_path=\"bkgmodel_quant.tflite\")\r\n  interpreter.resize_tensor_input(0, [1, 180, 180, 1])\r\n  interpreter.allocate_tensors()\r\n  print (\"INPUT TENSOR\",interpreter.get_input_details())\r\n  input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\r\n  output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\r\n  interpreter.set_tensor(0, img_array)\r\n```\r\nWhen I run I get the following error:\r\n\r\n`ValueError: Cannot set tensor: Got value of type UINT8 but expected type INT8 for input 0, name: input_2_int8`\r\n\r\nWhen I look at the types of the image data and input tensors, they inded _are_ `uint8`:\r\n\r\n```\r\nIMAGE_ARRAY type uint8\r\nINPUT TENSOR [{'name': 'input_2', 'index': 22, 'shape': array([  1, 180, 180,   1], dtype=int32), 'shape_signature': array([ -1, 180, 180,   1], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n```\r\n(look only at `dtype` in the input tensor, I assume).\r\n\r\nSo - indeed, the input tensor _should_ be a uint8, and the image _is_ a uint8 - yet I get this error.\r\n\r\nAs an experiment - I tried changing _only_ my inference code to set the image data to `int8`. i.e:\r\n\r\n```img_array= np.array(np.expand_dims(img_array/1.0,0), dtype=np.int8)\r\n```\r\n\r\nWhen I do, the error goes away and the inference runs (as expected) - no error, *however* my models predictions are all wrong.\r\n\r\n(It is notable that the output values all add up to _almost_ 256. I am assuming this means that the model is working correctly and yielding valid data - and I am also assuming that 8-bit sigmoids are expected to have a bit of a roundoff error where they don't add up to exactly 256??)\r\n\r\nIf I am doing something wrong, or is this a bug in Tensorflow-lite??\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect that when I leave it as:\r\n`img_array= np.array(np.expand_dims(img_array/1.0,0), dtype=np.uint8)`\r\n...that it runs with no error, and yields expected inference results against these known files  - which give expected results running all the same code (except changing the `uint8` and `int8`s above to floats) with a non-quantitized, float `.tflite` model.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nSee `liteinfer.py` and `convert.py` (quantize) at:\r\nhttps://github.com/bkgoodman/espcam_training_tools\r\n\r\n\r\n", "comments": ["Hi @bkgoodman! Could you please look at this threads for answer ?[ Link1](https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_integer-only_quantization), [Link2](https://stackoverflow.com/questions/69519267/tensorflow-lite-tf-lite-interpreter-set-tensor-failing-to-properly-recognize-uin).", "@mohantym Thanks for the reply - the first link was the one that I used to describe how it _should_ work, which I followed. The second was my own question on the matter on StackOverflow ;-) \r\n\r\nSo - the first link is another datapoint which indicates it *should* work as I expected given what I am doing - but it clearly is not.\r\n", "P.S. I more exactly lifted the code from the first link you posted - so now I do:\r\n\r\n```  \r\n  input_details = interpreter.get_input_details()[0]\r\n  print (\"INPUT dtype \",input_details[\"dtype\"])\r\n  img_array = np.expand_dims(img_array, axis=0).astype(input_details[\"dtype\"])\r\n  interpreter.set_tensor(0, img_array)\r\n```\r\n\r\nMy output indicates:\r\n```\r\nINPUT dtype  <class 'numpy.uint8'>\r\n```\r\n\r\nbut I still get \r\n```\r\nValueError: Cannot set tensor: Got value of type UINT8 but expected type INT8 for input 0, name: input_2_int8\r\n```\r\n", "Ok @bkgoodman! Could you please share a link to model file too as it will help expedite the issue further.", "Good news - (I spent $59 on an NVIDIA Jetson Nano and a) fresh install of Tensorflow 2.5. The problem seems fixed here - so I'm guessing it was a problem in 2.3 that was already fixed.\r\n\r\nThanks for the help and sorry for the hassle!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52318\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52318\">No</a>\n", "@bkgoodman ! Thanks for confirming the same."]}, {"number": 52317, "title": "Remove unused `kFloatValuesPerSseVector` variable", "body": "Hi! Thanks for the great library and one of the best open source projects.\r\n\r\nLooks like variable `kFloatValuesPerSseVector` is unused and my compiler (`clang-12`) reports error:\r\n```\r\n/contrib/tensorflow/tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.cc:141:15: error: unused variable 'kFloatValuesPerSseVector' [-Werror,-Wunused-const-variable]\r\nconstexpr int kFloatValuesPerSseVector = 4;\r\n              ^\r\n1 error generated.\r\nmake[2]: *** [tensorflow-lite/CMakeFiles/tensorflow-lite.dir/build.make:356: tensorflow-lite/CMakeFiles/tensorflow-lite.dir/kernels/internal/optimized/sse_tensor_utils.cc.o] Error 1\r\nmake[2]: *** Waiting for unfinished jobs....\r\nmake[1]: *** [CMakeFiles/Makefile2:1948: tensorflow-lite/CMakeFiles/tensorflow-lite.dir/all] Error 2\r\nmake: *** [Makefile:156: all] Error 2\r\n\r\n```", "comments": []}, {"number": 52316, "title": "Add support of filesystem_set_configuration to tensorflow core", "body": "This is a follow up to PR in https://github.com/tensorflow/io/pull/1443 to add set_configuration support to tensorflow core repo.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @mihaimaruseac. One scenario of kernel ops usage is the situation where the file system has to be configured when graph is running (not pre-configure it before graph runs). In that case, I think of adding a kernel ops might be needed as otherwise the graph might not know what will be used for configuration."]}, {"number": 52315, "title": "code annotation fix", "body": "change input_tensor: A [1, height, width, 3] ----> input_tensor: A [height, width, 3]", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/52315\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "![2021-10-10-22-29-59](https://user-images.githubusercontent.com/22192610/136700493-dd87ff85-2a5c-478d-b141-39f83daf47fb.png)\r\nthe input_tensor shape should be [height, width, 3]", "![2021-10-10-22-31-47](https://user-images.githubusercontent.com/22192610/136700558-9f725e2b-5b96-4bc7-aa65-3c99f55f06b8.png)\r\nthe keypoints_with_scores shape should be [17,3]", "![2021-10-10-22-33-14](https://user-images.githubusercontent.com/22192610/136700645-9c996517-28ff-4035-84ba-d1776c7cd979.png)\r\n![2021-10-10-22-33-28](https://user-images.githubusercontent.com/22192610/136700648-12bd9114-334a-4e1d-ba24-4bb0e5329837.png)\r\nFix Note display problem", "change all keypoint_with_scores ---> keypoints_with_scores\r\nUniform variable representation", "@gbaned The changes LGTM. Can you approve the PR?", "I think it should be approved by you  @khanhlvg\r\n![2021-10-15-19-58-06](https://user-images.githubusercontent.com/22192610/137483434-ffaf2864-f138-4b35-b396-ace5838e461a.png)\r\n![2021-10-15-19-57-50](https://user-images.githubusercontent.com/22192610/137483444-362c89d7-32f9-455a-8d62-cb8b353c1270.png)\r\n\r\n\r\n"]}, {"number": 52314, "title": "The loss is negative number and the accuracy is always 0 per epoch", "body": "I downloaded csv data of boston house price to practice;\r\nThe csv data have 13 columns and the No.13 column is price;\r\nBut the loss is negative number and became bigger and bigger, the accuracy is always 0 per epoch when training.\r\nIs there any wrong with my code when process the data or build the model?\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\n\r\nf = open('bostonHouse.csv')\r\n\r\ndf = pd.read_csv(f)\r\ndata = np.array(df)\r\nplt.figure()\r\nplt.plot(data)\r\nplt.show()\r\n\r\nnormalize_data = (data - np.mean(data)) / np.std(data)\r\nnormalize_data = normalize_data[:, np.newaxis]\r\n\r\ntrain_x, train_y = [], []\r\nfor i in range(len(normalize_data)):\r\n    x = normalize_data[i][0][:12]\r\n    y = normalize_data[i][0][12]\r\n    train_x.append(x.tolist())\r\n    train_y.append(y.tolist())\r\n\r\n# print(\"train_x data:{}\".format(train_x[:1]))\r\n# print(\"train_y data:{}\".format(train_y[:1]))\r\n# print('train x len', len(train_x[0]))\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(128, activation='relu', input_shape=(12,)),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(\r\n    loss=\"binary_crossentropy\",\r\n    optimizer='adam',\r\n    metrics=['accuracy'],\r\n)\r\n\r\nmodel.summary()\r\nmodel.fit(x=train_x, y=train_y, epochs=20)\r\n```\r\nTraining result:\r\n```\r\nEpoch 15/20\r\n16/16 [==============================] - 0s 2ms/step - loss: -57761.8555 - accuracy: 0.0000e+00\r\nEpoch 16/20\r\n16/16 [==============================] - 0s 2ms/step - loss: -78732.5547 - accuracy: 0.0000e+00\r\nEpoch 17/20\r\n16/16 [==============================] - 0s 2ms/step - loss: -105031.8750 - accuracy: 0.0000e+00\r\nEpoch 18/20\r\n16/16 [==============================] - 0s 2ms/step - loss: -137373.6094 - accuracy: 0.0000e+00\r\nEpoch 19/20\r\n16/16 [==============================] - 0s 2ms/step - loss: -177102.2344 - accuracy: 0.0000e+00\r\nEpoch 20/20\r\n16/16 [==============================] - 0s 2ms/step - loss: -224581.0312 - accuracy: 0.0000e+00\r\n```\r\nmy csv data:\r\n```\r\na | b | c | d | e | f | g | h | i | j | k | l | m\r\n-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --\r\n0.00632 | 18 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.09 | 1 | 296 | 15.3 | 396.9 | 4.98\r\n0.02731 | 0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.9 | 9.14\r\n0.02729 | 0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03\r\n0.03237 | 0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94\r\n0.06905 | 0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.9 | 5.33\r\n0.02985 | 0 | 2.18 | 0 | 0.458 | 6.43 | 58.7 | 6.0622 | 3 | 222 | 18.7 | 394.12 | 5.21\r\n0.08829 | 12.5 | 7.87 | 0 | 0.524 | 6.012 | 66.6 | 5.5605 | 5 | 311 | 15.2 | 395.6 | 12.43\r\n...\r\n```\r\n\r\n", "comments": ["@cngobd \r\nIn order to expedite the trouble-shooting process here,Could you please provide us the dataset and let us know which TF you're using? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@cngobd \r\nLoss should be \u201cmse\u201d or \u201cmae\u201d. as crossentropy loss is suited only for classification tasks, and here you have regression.\r\nPlease refer to similar [issue](https://github.com/rromanss23/Machine_Leaning_Engineer_Udacity_NanoDegree/blob/master/projects/boston_housing/boston_housing.ipynb),in case the error persist you may open this issue in tf discussion forum.\r\nalso this [issues](https://stats.stackexchange.com/questions/282160/how-is-it-possible-that-validation-loss-is-increasing-while-validation-accuracy), ", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52313, "title": "Remove C++ content from tensorflow/c/c_api_macros.h", "body": "This PR tries to remove C++ conent from tensorflow/c/c_api_macros.h\r\nso that it is possible to include this file from an external plugin\r\nwithout depending on tensorflow's C++ headers (tensorflow/core/platform/status.h).\r\n\r\nThe reason for this move is that for external plugins (e.g., file systems plugins)\r\nthat utilize C API, it cannot include status.h as otherwise the whole tensorflow's\r\nC++ library will be a dependency. This defeat the purpose of C APi modular plugin.\r\n\r\nThis PR place C++ content to tensorflow/core/platform/status.h instead so that\r\neverything will still be combined both for C external plugins and C++ plugins.\r\n\r\n(Note the C++ inclusion was added in PR #51647.)\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@mihaimaruseac At the moment upgrade of tensorflow-io's dependency to TF 2.7.0rc0 is not working due to the C++ inclusion. For that it might make sense to include this PR to 2.7 if there is still enough time.", "Hmm, can you post what the error message is?\r\n\r\nThese lines got added recently via #51647 (manual import + fix) as Intel needed this for the 2.7 release.\r\n\r\nCC @penpornk ", "@yongtang The C++ part is wrapped with `#ifdef __cplusplus` so I think it should be fine with C compilers. Is the error message something like [this](https://github.com/tensorflow/tensorflow/pull/51647#discussion_r715426238)?\r\n\r\ncc: @jbaiocchi ", "Thanks @mihaimaruseac @penpornk.\r\n\r\nThe issue is because of the following:\r\n1. While C++ part is wrapped within `#ifdef __cplusplus`, `c_api_macros.h` itself is a header file and can be included by a C++ source file or C source file.\r\n2. However, if a C++ source file include this header, it will invoke the inclusion of \"status.h\", which, will include almost lots of C++ header files under tensorflow (not just for C headers under `tensorflow/c/`:\r\n\r\nSo the issue is not really about C++ itself, but the include of `status.h` that expands the inclusion of too many header files (and defeat the purpose of a small limited set of C header files):\r\n\r\nBelow are the included headers within  \"status.h\":\r\n```\r\n#include \"absl/types/optional.h\"\r\n#include \"tensorflow/core/platform/logging.h\"\r\n#include \"tensorflow/core/platform/macros.h\"\r\n#include \"tensorflow/core/platform/stack_frame.h\"\r\n#include \"tensorflow/core/platform/stringpiece.h\"\r\n#include \"tensorflow/core/platform/types.h\"\r\n#include \"tensorflow/core/protobuf/error_codes.pb.h\"\r\n```\r\n", "@mihaimaruseac @penpornk wondering if there is any update on this PR?\r\n\r\nIt would be great if this PR can be part of the 2.7 release as external plugin will be impacted."]}, {"number": 52312, "title": "TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto.", "body": "System information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.3\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 2.6.0\r\nKeras version (use command below): 2.6.0\r\nPython version: 3.8.12\r\nCUDA/cuDNN version: n/a\r\nGPU model and memory: n/a\r\nDescribe the current behavior\r\n\r\nWhen building simple Sequential model with Keras, strange errors occur. I'v tried to update Conda, re-create a new py38 virtualenv to establish another environment but still encountered the same issue. I'v searched similiar issues before, like re-install protobuf, add pywrap_tensorflow etc. but did not work for me. It should be compatible issue. The traceback is:\r\n-----------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/var/folders/94/dvh9t1_x3w9bnp_ghskg3rzr0000gn/T/ipykernel_17083/2882519647.py in <module>\r\n      1 # define the model\r\n----> 2 model = Sequential([\r\n      3     Dense(units=16,input_shape=(1,),activation='relu'),\r\n      4     Dense(units=32,activation='relu'),\r\n      5     Dense(units=2,activation='softmax')\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    528     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    529     try:\r\n--> 530       result = method(self, *args, **kwargs)\r\n    531     finally:\r\n    532       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    112     \"\"\"\r\n    113     # Skip the init in FunctionalModel since model doesn't have input/output yet\r\n--> 114     super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call\r\n    115         name=name, autocast=False)\r\n    116     base_layer.keras_api_gauge.get_cell('Sequential').set(True)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    528     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    529     try:\r\n--> 530       result = method(self, *args, **kwargs)\r\n    531     finally:\r\n    532       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in __init__(self, *args, **kwargs)\r\n    316     self._steps_per_execution = None\r\n    317 \r\n--> 318     self._init_batch_counters()\r\n    319     self._base_model_initialized = True\r\n    320 \r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    528     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    529     try:\r\n--> 530       result = method(self, *args, **kwargs)\r\n    531     finally:\r\n    532       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _init_batch_counters(self)\r\n    324     # `evaluate`, and `predict`.\r\n    325     agg = variables.VariableAggregationV2.ONLY_FIRST_REPLICA\r\n--> 326     self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n    327     self._test_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n    328     self._predict_counter = variables.Variable(\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    266       return cls._variable_v1_call(*args, **kwargs)\r\n    267     elif cls is Variable:\r\n--> 268       return cls._variable_v2_call(*args, **kwargs)\r\n    269     else:\r\n    270       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    248     if aggregation is None:\r\n    249       aggregation = VariableAggregation.NONE\r\n--> 250     return previous_getter(\r\n    251         initial_value=initial_value,\r\n    252         trainable=trainable,\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)\r\n    241                         shape=None):\r\n    242     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 243     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n    244     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    245       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)\r\n   2660   shape = kwargs.get(\"shape\", None)\r\n   2661 \r\n-> 2662   return resource_variable_ops.ResourceVariable(\r\n   2663       initial_value=initial_value,\r\n   2664       trainable=trainable,\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    268       return cls._variable_v2_call(*args, **kwargs)\r\n    269     else:\r\n--> 270       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    271 \r\n    272 \r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n   1601       self._init_from_proto(variable_def, import_scope=import_scope)\r\n   1602     else:\r\n-> 1603       self._init_from_args(\r\n   1604           initial_value=initial_value,\r\n   1605           trainable=trainable,\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\r\n   1755           else:\r\n   1756             shape = initial_value.shape\r\n-> 1757           handle = eager_safe_variable_handle(\r\n   1758               initial_value=initial_value,\r\n   1759               shape=shape,\r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in eager_safe_variable_handle(initial_value, shape, shared_name, name, graph_mode)\r\n    237   \"\"\"\r\n    238   dtype = initial_value.dtype.base_dtype\r\n--> 239   return _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name,\r\n    240                                                graph_mode, initial_value)\r\n    241 \r\n\r\n~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value)\r\n    177     handle_data.is_set = True\r\n    178     handle_data.shape_and_type.append(\r\n--> 179         cpp_shape_inference_pb2.CppShapeInferenceResult.HandleShapeAndType(\r\n    180             shape=shape.as_proto(), dtype=dtype.as_datatype_enum))\r\n    181 \r\n\r\nTypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto.\r\n", "comments": ["@yosemite1998 ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "OK. I re-posted it in keras group ", "@yosemite1998 ,\r\nPlease feel free to close this issue, since it is already being tracked in Keras repo. Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52312\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52312\">No</a>\n"]}, {"number": 52311, "title": "\"zoom_range\" argument of \"ImageDataGenerator\" class show distortions around edges", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are\r\nnot verified bugs in TensorFlow, please go to\r\n[Discourse](https://discuss.tensorflow.org/).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org\r\n\r\n================================================================================\r\n\r\n\"zoom_range\" argument of \"ImageDataGenerator\" class shows distortions/noise on the augmented images towards the edges. It turns out, new augmentations are carried out on previously augmented image instead of original image. Please have a look at image #2 and image #4 from left in below images. The legs of the dog are distorted for a zoom_range=0.5\r\n\r\n![image](https://user-images.githubusercontent.com/20167138/136653991-92ecdc9b-a895-4dc9-8b94-fc00493c9b06.png)\r\n", "comments": ["Hi @Roshan1986! Could you please provide more code snippet as a Colab Gist if possible to reproduce this issue? ", "# Data used: Cats vs. Dogs dataset from Kaggle pulled from Tensorflow Datasets\r\n\r\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\r\nzip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\r\n\r\n# ImageDataGenerator class used\r\nimage_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)\r\n\r\ntrain_data_gen = image_gen.flow_from_directory(batch_size=100,\r\n                                               directory=train_dir,\r\n                                               shuffle=True,\r\n                                               target_size=(150, 150))\r\n\r\naugmented_images = [train_data_gen[0][0][0] for i in range(5)]\r\n\r\n# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\r\ndef plotImages(images_arr):\r\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\r\n    axes = axes.flatten()\r\n    for img, ax in zip(images_arr, axes):\r\n        ax.imshow(img)\r\n    plt.tight_layout()\r\n    plt.show()\r\n\r\nplotImages(augmented_images)", "Hi @Roshan1986,\r\nThis does not seem to be a bug or feature request, Please open this issue in tf discussion [forum](https://discuss.tensorflow.org/) as there is a larger community there to help you out.Thank you!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52309, "title": "wrong cupti dll name", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary):  source\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.9.7\r\n- Bazel version (if compiling from source): 3.9.2\r\n- GCC/Compiler version (if compiling from source): Visual Studio 2019\r\n- CUDA/cuDNN version: 11.4/8.2.4\r\n- GPU model and memory: RTX3090 GDDR6x 24GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nwrong cupti name for loading\r\n\r\n**Describe the expected behavior**\r\ncupti loaded\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):  change filename to  cupti64*.dll\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\r\n```", "comments": ["the name is \"cupti64_2021.2.2.dll\"", "@alanpurple ,\r\nCan you please take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/44697) from the issue with similar error.It helps.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52309\">No</a>\n", "@tilakrayal \r\n\r\nsimilar things happens again with another different name,......so how does seeing old issue helps me or anyone?", "@alanpurple ,\r\nCan you please share a reproducible code that supports your statement so that the issue can be easily understood? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52309\">No</a>\n"]}, {"number": 52308, "title": "shared_embedding can't be used with tf.keras.layers.DenseFeatures", "body": "Hi, i'm using tf.keras.layers.DenseFeatures with feature_columns to build my model. But it seems i can't use shared_embedding in feature_columns.\r\ncode:\r\n         input_layer = tf.keras.layers.DenseFeatures(all_feature_columns)\r\n\r\nand in all_feature_columns, there exists a _shared_embedding:\r\n\r\n`_SharedEmbeddingColumn(categorical_column=HashedCategoricalColumn(key='tag_1_int', hash_bucket_size=1000, dtype=tf.string), dimension=100, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7fec1bc30d60>, shared_embedding_collection_name='tag', ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True)`\r\n\r\nand it causes:\r\n`ValueError: Items of feature_columns must be a FeatureColumn. Given (type <class 'tensorflow.python.feature_column.feature_column._SharedEmbeddingColumn'>): _SharedEmbeddingColumn(categorical_column=HashedCategoricalColumn(key='tag_1_int', hash_bucket_size=1000, dtype=tf.string), dimension=100, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7fd488b86dc0>, shared_embedding_collection_name='tag', ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True)`\r\n\r\nwhen i change the _SharedEmbeddingColumn to EmbeddingColumn, it works.\r\n\r\nSame question with tf.keras.experimental.SequenceFeatures([seq_feature_column])\r\n\r\nTo summary, that's DenseFeatures and SequenceFeatures can't accept _SharedEmbeddingColumn\r\n\r\n**System information**\r\n- TensorFlow version 2.6.0\r\n- Python 3.8\r\n\r\n\r\n", "comments": ["Hi @linWujl!\r\nCould you please the template  from [here ](https://github.com/tensorflow/tensorflow/issues/new/choose)too as it helps us analyse the issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52307, "title": "map_on_gpu", "body": "Does this function work?\r\nWhere is the manual for this function?\r\n```tensorflow/python/data/experimental/ops/prefetching_ops.py: 264``` ```def map_on_gpu(map_func):```", "comments": ["@zhaozheng09 Could you please have a look at the [map_func](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/data/experimental/ops/prefetching_ops.py#L260) and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52306, "title": "[MLIR] Add two canonicalization patterns for mhlo::DynamicReshapeOp", "body": "Add two patterns to do canonicalization for mhlo::DynamicReshapeOp, when the shape is known or partially known.", "comments": ["@linearhit  Can you please check @smit-hinsu's comments and keep us posted ? Thanks!", "@linearhit Can you please check @smit-hinsu's comments and resolve conflicts?. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 52305, "title": "Fix the segfault issue when no fallback in AutotuneEntry", "body": "The new AutotuneEntry might cause a segfault issue when the no_scratch_fallback is null and its ToString() method is called.\r\n\r\n\r\n\r\ncc. @nluehr ", "comments": ["@timshen91 for vis."]}, {"number": 52304, "title": "Update estimator version in TF-core release branch", "body": "PiperOrigin-RevId: 401872511\r\nChange-Id: I554a5f98063c85c37c9a4e444fa72724d9d3b441", "comments": []}, {"number": 52303, "title": "Argmin failures for N-D tensors", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n```\r\ntensor = tf.constant([[1.5, 3.2], \r\n                      [1.7, 0.9]])\r\nargmin = tf.argmin(a_total)\r\n```\r\nI would expect argmin to be the global index, i.e. [1,1]. however, it returns [0,1]\r\n\r\n**Describe the expected behavior**\r\nI would expect argmin to be the global index, i.e. [1,1]. however, it returns [0,1]\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\ntensor = tf.constant([[1.5, 3.2], \r\n                      [1.7, 0.9]])\r\nargmin = tf.argmin(a_total)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["The documentation defaults to axis=None, however it seems that the default is actually axis=0?", "@ctargon ,\r\nIn order to expedite the trouble-shooting process, could you please provide a complete code and the TensorFlow version you are using.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52303\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52303\">No</a>\n"]}, {"number": 52302, "title": "change efficientdet-lite0 --> efficientdet_lite0", "body": null, "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/52302\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "![2021-10-08-22-01-21](https://user-images.githubusercontent.com/22192610/136570433-8568aeeb-91ab-4328-a1e9-3f471b58c168.png)\r\n", "![2021-10-09-17-50-38](https://user-images.githubusercontent.com/22192610/136653366-17d63283-b170-4e7b-a5bd-2c232ff40663.png)\r\nMissing import QuantizationConfig", "Hi, When will this branch be merged. @gbaned ", "> Hi, When will this branch be merged. @gbaned\r\n\r\nHi @MaoXianXin Sorry for the late replay. It is showing internal checks failures, we are working on it. Thank you."]}, {"number": 52301, "title": "NotAbleToGenerate : Inference time and model size ", "body": "I have tested a model, I have also run the epochs but I am not able to generate inference time and model size.\r\nCan you tell me a way in which I can print these two? I search it in the TensorFlow library but it shows an error.\r\nPlease also share the necessary links.\r\nThanks!", "comments": ["Hi @starboyvarun! This issue seems to linked with compressing models to Tflite models and measuring inference time . Attaching reference as below. [Link1](https://www.tensorflow.org/hub/tutorials/object_detection) ,[Link2](https://www.tensorflow.org/lite/performance/measurement),[Link3](https://www.tensorflow.org/lite/guide/inference) ,[Link4](https://stackoverflow.com/questions/58513385/how-to-compare-or-measure-the-actual-size-of-models-in-tensorflow). Please post on Stackoverflow/[discuss](https://discuss.tensorflow.org/) for further details as there is a larger community there to help you out.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52300, "title": "Segmentation fault when running inference using the TensorFlow Lite C++ API", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): Compiled against TensorFlow 919f693420e35d00c8d0a42100837ae3718f7927, however we've also seen the issue in [the `tflite` crate](https://github.com/boncheolgu/tflite-rs) which is pinned to 3db52be\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): We have seen this when using both the Bazel and CMake builds\r\n- GCC/Compiler version (if compiling from source): Various - seen using recent Clang and GCC\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nWhile using the TensorFlow Lite C++ API inside a Rust application, doing inference on certain models will trigger a segfault deep inside the `gemmlowp` library used by TensorFlow Lite. This only seems to occur on MacOS machines and not for all models.\r\n\r\nSteps to reproduce:\r\n\r\n```shell\r\n# Install the Rust toolchain from rustup\r\n$ curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\r\n\r\n# Download a version of the Rune binary\r\n$ wget https://github.com/hotg-ai/rune/releases/download/v0.8.0/rune.x86_64-apple-darwin.zip\r\n$ unzip rune.x86_64-apple-darwin.zip\r\n$ chmod +x ./rune\r\n\r\n# Run the Rune\r\n$ ./rune run examples/person_detection/person_detection.rune --image examples/person_detection/image_grayscale.png\r\nzsh: segmentation fault\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nNo segfault.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing): N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n\r\n**Other info / logs**\r\n\r\nWe managed to get a backtrace using LLDB. \r\n\r\n```\r\n(lldb) thread backtrace\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x3110)\r\n  * frame #0: 0x000000010095f664 rune`void gemmlowp::DispatchGemmShape<unsigned char, short, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)0, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, std::__1::tuple<gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToInt16>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<short, (gemmlowp::MapOrder)0>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, std::__1::tuple<gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToInt16> const&) + 20\r\n    frame #1: 0x000000028456d9c0\r\n    frame #2: 0x000000010095b3e8 rune`gemmlowp::ComputeImpl<gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormat<gemmlowp::CellFormat<4, 2, (gemmlowp::CellOrder)1>, 3> >, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormat<gemmlowp::CellFormat<4, 2, (gemmlowp::CellOrder)1>, 1> >, gemmlowp::PackedResult>::ComputeRun(int, int, int, int) + 216\r\n    frame #3: 0x00000001008cd436 rune`void gemmlowp::SingleThreadGemm<gemmlowp::KernelFormat<gemmlowp::KernelSideFormat<gemmlowp::CellFormat<4, 2, (gemmlowp::CellOrder)1>, 3>, gemmlowp::KernelSideFormat<gemmlowp::CellFormat<4, 2, (gemmlowp::CellOrder)1>, 1> >, unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)1, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, std::__1::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> >(gemmlowp::SingleThreadGemmContext*, gemmlowp::KernelBase const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)1>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, std::__1::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) + 1398\r\n    frame #4: 0x00000001008cc28f rune`void gemmlowp::DispatchGemmShape<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)1, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, std::__1::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)1>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, std::__1::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) + 287\r\n    frame #5: 0x00000001008cc13b rune`void gemmlowp::DispatchGemmShape<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)0, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, std::__1::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)0> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)0>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, std::__1::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)0> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) + 251\r\n    frame #6: 0x00000001008cbfcc rune`tflite::cpu_backend_gemm::detail::GemmImplUsingGemmlowp<unsigned char, unsigned char, int, unsigned char, (tflite::cpu_backend_gemm::QuantizationFlavor)1>::Run(tflite::cpu_backend_gemm::MatrixParams<unsigned char> const&, unsigned char const*, tflite::cpu_backend_gemm::MatrixParams<unsigned char> const&, unsigned char const*, tflite::cpu_backend_gemm::MatrixParams<unsigned char> const&, unsigned char*, tflite::cpu_backend_gemm::GemmParams<int, unsigned char, (tflite::cpu_backend_gemm::QuantizationFlavor)1> const&, tflite::CpuBackendContext*) + 220\r\n    frame #7: 0x00000001008c93e7 rune`void tflite::cpu_backend_gemm::Gemm<unsigned char, unsigned char, int, unsigned char, (tflite::cpu_backend_gemm::QuantizationFlavor)1>(tflite::cpu_backend_gemm::MatrixParams<unsigned char> const&, unsigned char const*, tflite::cpu_backend_gemm::MatrixParams<unsigned char> const&, unsigned char const*, tflite::cpu_backend_gemm::MatrixParams<unsigned char> const&, unsigned char*, tflite::cpu_backend_gemm::GemmParams<int, unsigned char, (tflite::cpu_backend_gemm::QuantizationFlavor)1> const&, tflite::CpuBackendContext*) + 279\r\n    frame #8: 0x00000001008c92ba rune`tflite::optimized_ops::Conv(tflite::ConvParams const&, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, unsigned char*, tflite::RuntimeShape const&, unsigned char*, tflite::CpuBackendContext*) + 618\r\n    frame #9: 0x00000001008df171 rune`void tflite::ops::builtin::conv::EvalQuantized<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*, TfLiteConvParams*, tflite::ops::builtin::conv::OpData*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*, TfLiteTensor*) + 1249\r\n    frame #10: 0x00000001008dcb1a rune`TfLiteStatus tflite::ops::builtin::conv::EvalImpl<(tflite::ops::builtin::conv::KernelType)2, (TfLiteType)3>(TfLiteContext*, TfLiteNode*) + 698\r\n    frame #11: 0x00000001008a5780 rune`TfLiteStatus tflite::ops::builtin::conv::Eval<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*) + 128\r\n    frame #12: 0x0000000100a757be rune`tflite::Subgraph::Invoke() + 1150\r\n    frame #13: 0x0000000100a79579 rune`tflite::Interpreter::Invoke() + 89\r\n    frame #14: 0x000000010081fe5b rune`infer + 139\r\n    frame #15: 0x00000001005dac7b rune`hotg_runecoral::context::InferenceContext::infer::h9edb39c38c81e707 + 763\r\n    frame #16: 0x000000010015a4b8 rune`_$LT$hotg_runicos_base_runtime..image..runecoral..RuneCoralModel$u20$as$u20$hotg_runicos_base_runtime..image..Model$GT$::infer::hc87b3f895994a40f + 312\r\n    frame #17: 0x0000000100167a63 rune`hotg_runicos_base_runtime::image::wasmer_impl::rune_model_infer::he7a5c51e5c2920d7 + 1091\r\n    frame #18: 0x00000001001551eb rune`_$LT$Func$u20$as$u20$wasmer..externals..function..inner..HostFunction$LT$$LP$A1$C$A2$C$A3$RP$$C$Rets$C$wasmer..externals..function..inner..WithEnv$C$Env$GT$$GT$::function_body_ptr::func_wrapper::h490ab2c575aacc33 + 11\r\n    frame #19: 0x00000001017c7dd8\r\n    frame #20: 0x00000001017cb7bc\r\n    frame #21: 0x00000001017cc8de\r\n    frame #22: 0x00000001017db3f2\r\n    frame #23: 0x000000010057b409 rune`wasmer_register_setjmp + 73\r\n    frame #24: 0x0000000100177780 rune`wasmer_vm::trap::traphandlers::tls::set::h18404a427f1d465b + 128\r\n    frame #25: 0x000000010017372a rune`wasmer_vm::trap::traphandlers::wasmer_call_trampoline::hb18b59c24dca92f7 + 138\r\n    frame #26: 0x0000000100176e3d rune`wasmer::native::NativeFunc$LT$$LP$A1$C$A2$C$A3$RP$$C$Rets$GT$::call::h2d748b56879248d3 + 525\r\n    frame #27: 0x0000000100172c1b rune`hotg_rune_wasmer_runtime::Runtime::call::h0cd6d828d9f429eb + 331\r\n    frame #28: 0x0000000100034ac5 rune`hotg_rune_cli::run::command::Run::execute::hb9bfa1ab91f6d41b + 4053\r\n    frame #29: 0x00000001000073bc rune`rune::main::h823e153ddfeaa780 + 4220\r\n    frame #30: 0x000000010000aff6 rune`std::sys_common::backtrace::__rust_begin_short_backtrace::h96a6a8ebc29b41a3 + 6\r\n    frame #31: 0x0000000100002ee1 rune`std::rt::lang_start::_$u7b$$u7b$closure$u7d$$u7d$::h1b2d1c373cb0f18b + 17\r\n    frame #32: 0x00000001007f6819 rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] core::ops::function::impls::_$LT$impl$u20$core..ops..function..FnOnce$LT$A$GT$$u20$for$u20$$RF$F$GT$::call_once::hdf4f188556f78df7 at function.rs:259:13 [opt]\r\n    frame #33: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::panicking::try::do_call::hb7b1a93f0946c677 at panicking.rs:403 [opt]\r\n    frame #34: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::panicking::try::hc49e70695c7e0cac at panicking.rs:367 [opt]\r\n    frame #35: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::panic::catch_unwind::h3df4d361649a5b95 at panic.rs:129 [opt]\r\n    frame #36: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::rt::lang_start_internal::_$u7b$$u7b$closure$u7d$$u7d$::hdba2bd3fb6f7733e at rt.rs:45 [opt]\r\n    frame #37: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::panicking::try::do_call::h90a258d8350a7861 at panicking.rs:403 [opt]\r\n    frame #38: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::panicking::try::h32056c8bc9923070 at panicking.rs:367 [opt]\r\n    frame #39: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 [inlined] std::panic::catch_unwind::h5db5f082733be7e8 at panic.rs:129 [opt]\r\n    frame #40: 0x00000001007f680c rune`std::rt::lang_start_internal::h89c9a0e84eca73a6 at rt.rs:45 [opt]\r\n    frame #41: 0x0000000100008609 rune`main + 41\r\n    frame #42: 0x00007fff6b928cc9 libdyld.dylib`start + 1\r\n    frame #43: 0x00007fff6b928cc9 libdyld.dylib`start + 1\r\n```\r\n\r\nSee also https://github.com/hotg-ai/rune/issues/131.", "comments": ["Can you send a small tflite model that reproduces the issue?", "We've seen the Segfault occur consistently on [this model](https://github.com/hotg-ai/rune/blob/95c286bade22c3c4e079ed8f24c72284a82709af/examples/person_detection/model.tflite).", "Bumping this up again :) ", "> We've seen the Segfault occur consistently on [this model](https://github.com/hotg-ai/rune/blob/95c286bade22c3c4e079ed8f24c72284a82709af/examples/person_detection/model.tflite).\r\n\r\nCan you provide a minimal reproducer? The smaller the reproducer, the faster it is to get a fix.\r\n\r\n> Bumping this up again :)\r\n\r\nPlease don't spam to bump activity.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52300\">No</a>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52300\">No</a>\n"]}, {"number": 52299, "title": "Copy removal", "body": "This copy removal pass is based on the UserangeAnalysis. First, all Operations implementing the CopyOpInterface are found, then the useranges of the source and target of the CopyOpInterface are intersected. The only Operation in the intersection must be the CopyOp or Operations that are within the nested region if the CopyOp implements a Region. If this is the case, we can remove the CopyOp.\r\n\r\nThis PR includes an addition to the UserangeAnalysis to intersect two useranges.\r\n\r\nThis is the implementation of the Implementation of a Copy Removal Pass #52029.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52299) for more info**.\n\n<!-- need_sender_cla -->"]}]