[{"number": 27307, "title": "Python module generated by `tf.load_op_library` contains no custom ops", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.19.2-dist\r\n- GCC/Compiler version (if compiling from source):5.4.0\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Problem**\r\nI followed the instructions on https://tensorflow.google.cn/guide/extend/op to customize my own OPs step by step. For simple verification, I used the fact OP that comes with tensorflow (I also tried my own OP). I add BUILD file in the same directory with fact.cc \r\n```\r\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\r\n\r\ntf_custom_op_library(\r\n    name = \"fact.so\",\r\n    srcs = [\"fact.cc\"],\r\n)\r\n```\r\nand then build \r\n```\r\nbazel build --config opt //tensorflow/core/user_ops:fact.so\r\n```\r\nBut when I use fact.so as the instructions describe:\r\n```\r\n# python\r\nimport tensorflow as tf\r\nfact_module = tf.load_op_library('./fact.so')\r\nfact_module.fact\r\n```\r\nI got following errors\r\n```\r\nTraceback (most recent call last):\r\n  File \"/tmp/remote_python/main.py\", line 10, in <module>\r\n    fact_module.fact\r\nAttributeError: module '670cc8cfec5b6d3b8635f39bd583d769' has no attribute 'fact'\r\n```\r\nIs this normal?", "comments": ["This is due to the fact that I have installed tensorflow with my own op...", "@dMokaMoka hi, what do you mean by 'installed tensorflow with my own op'?", "Did you solve that? I meet same error ,  but when i chang usr_op name to FactStr ( \"Fact\" to \"FactStr\"), error no more  appear\uff0ci dont figure out how it run normal"]}, {"number": 27306, "title": "ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory", "body": "I am getting the error mentioned above when trying to use TF GPU.\r\nMy setup is as follows:\r\nOS: Ubuntu 16.04\r\nPython 3.5.2\r\nTensorflow: tensorflow-gpu 1.13.1\r\nCuda version: 10.0\r\nlibcublas.so.10.0 is present in /usr/local/cuda-10.0/lib64\r\n/usr/local/cuda-10.0/lib64 is added to PATH and LD_LIBRARY_PATH.\r\n\r\nOther Github issue threads related to similar issues didn't help.\r\n\r\nI would be grateful for any help/suggestions, thanks!", "comments": ["This is a very common error while setting up tensorflow gpu.\r\nYou are using GPU. \r\nHere Cuda is not installed correctly. \r\nSo, Libcublas version is not found. This Libcublas version is speaking of the required Cuda version 10.0 to be compatible with this tensorflow version. (Still sometimes there are gotchas which means incompatibility with the version of Cuda, CuDNN and Tensorflow-gpu)\r\n\r\nMake sure you have installed - cuda-libraries . \r\n\r\nsudo apt-get install cuda-libraries-version\r\n\r\nFor detailed help on how to install and work on tensorflow-gpu you can see my blog here. \r\n\r\nhttps://medium.com/@mainakdutta76/gpu-configuration-for-deep-learning-f35a8bf0f5e1\r\n\r\n", "I think it was resolved. I am closing the issue. But, please let me know if I'm mistaken.", "I have the same problem.\r\nOS: Ubuntu 16.04\r\nPython: 3.6\r\nTensorflow: 1.13\r\nNvidia Driver version: 410.78\r\nCuda version: 10.0\r\n\r\nWhen I import Keras, I get this error. I haven't used tensorflow standalone. Help.\r\n\r\nEDIT: \r\nIt doesn't work with only tensorflow also.\r\nmy deviceQuery shows this:\r\n![devicequery](https://user-images.githubusercontent.com/2729048/57115901-ce3cb200-6d7b-11e9-8326-b3c023136046.png)\r\n", "What is the version of CUDNN? \r\nAnd did you install cuda-libraries along with cuda? ", "I have installed cudnn 7.4.2\r\nThis is what I get when verifying Cudnn installation:\r\n![cudnn-test-passed](https://user-images.githubusercontent.com/2729048/57148333-93766080-6df3-11e9-88af-5fa727660cd0.png)\r\n\r\nWhat other cuda-libraries do I need to install ?\r\n\r\nWhen I run sudo apt-get install cuda-libraries-version, I get Unable to locate package cuda-libraries-version.", "pip install cuda-libraries-10-1\r\n\r\nAnd even after this if it fails.\r\n\r\nCheck my blog here.https://medium.com/@mainakdutta76/gpu-configuration-for-deep-learning-f35a8bf0f5e1\r\n\r\nOn Fri 3 May, 2019, 9:11 PM SubigyaPanta, <notifications@github.com> wrote:\r\n\r\n> I have installed cudnn 7.4.2\r\n> This is what I get when verifying Cudnn installation:\r\n> [image: cudnn-test-passed]\r\n> <https://user-images.githubusercontent.com/2729048/57148333-93766080-6df3-11e9-88af-5fa727660cd0.png>\r\n>\r\n> What other cuda-libraries do I need to install ?\r\n>\r\n> \u2014\r\n> You are receiving this because you commented.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/27306#issuecomment-489137766>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/AIRDMQTVWEHCOYCDWYIX6WLPTRMMHANCNFSM4HCNFIJQ>\r\n> .\r\n>\r\n", "My cuda is 10.1,  and now have the same mistakes with yours ,ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory\r\nplease give me a hand.\r\n", "@pointcloudniphon please go through the link.  If you are using Tf 2.0 alpha , you need to install CUDA 10.0 and CUDNN 7.4. Else downgrade your tensorflow to 1.8.0. Follow this link  https://medium.com/@mainakdutta76/gpu-configuration-for-deep-learning-f35a8bf0f5e1. Thanks. "]}, {"number": 27305, "title": "Document stride parameter for XlaBuilder::Slice", "body": "Doc Link: https://www.tensorflow.org/xla/operation_semantics\r\nThe documentation for [XlaBuilder::Slice](https://www.tensorflow.org/xla/operation_semantics#slice) does not mention the stride parameter. ", "comments": ["In [xla_builder.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/client/xla_builder.h#L1206), the signature looks like:\r\n```\r\nXlaOp Slice(XlaOp operand, absl::Span<const int64> start_indices,\r\n            absl::Span<const int64> limit_indices,\r\n            absl::Span<const int64> strides);\r\n```\r\nIn the docs, it looks like: `Slice(operand, start_indices, limit_indices)`"]}, {"number": 27304, "title": "FileNotFoundError while running %tensorboard", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nmac os 10.14\r\n- TensorFlow installed from (source or binary):\r\n`pip install tensorflow==2.0.0-alpha0`\r\n- TensorFlow version:\r\n2.0.0-alpha0\r\n- Python version:\r\n 3.7.2\r\n- Installed using virtualenv? pip? conda?:\r\nconda: tf was installed in a conda env, the jupyter notebook is launched in the base environment. There is a jupyter kernel for the tensorflow env.\r\n\r\n**Describe the problem**\r\nAfter loading the tensorboard extension with `%load_ext tensorboard.notebook`,  the `%tensorboard` magic fails with:\r\n```\r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-4-d46782f9619b> in <module>\r\n----> 1 get_ipython().run_line_magic('tensorboard', '--logdir logs')\r\n\r\n[...]\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tensorboard': 'tensorboard'\r\n```\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nimport tensorflow\r\n%load_ext tensorboard.notebook\r\n%tensorboard --logdir logs\r\n```\r\n\r\n**Any other info / logs**\r\nThe issue is that the `tensorboard` binary is installed in the environment's bin dir which is added to the path when the env is activated. However, when selecting the kernel in the notebook, the path is not modified. So, while the tensorboard extension loads, the magic `%tensorboard` fails because it cannot find the `tensorboard` executable.\r\n\r\nA workaround is to manually add the environment's bin dir to the path from inside the notebook:\r\n\r\n```\r\nimport os\r\nPATH = os.getenv('PATH')\r\n%env PATH=/Users/anto/miniconda3/envs/tf2_env/bin:$PATH\r\n````\r\n\r\nWith this the `%tensorboard` magic starts working.", "comments": ["Hi @tritemio! Thanks for the report. Can you clarify how you installed\r\nTensorFlow and Jupyter, and how you\u2019re launching Jupyter, preferably by\r\nproviding a list of steps to create an environment that demonstrates the\r\nproblem?\r\n\r\nYou\u2019re correct that `tensorboard(1)` is installed into the virtualenv\u2019s\r\n`bin` directory, and that `%tensorboard` requires `tensorboard(1)` to be\r\non the path to be launched as a subprocess. But my understanding is that\r\nJupyter prepends the `bin` directory for the active virtualenv to the\r\n`PATH` seen by the notebook context, so I don\u2019t see why this doesn\u2019t\r\nsuffice.\r\n", "For the installation, it is a standard installation on a conda env:\r\n\r\n```\r\nconda create -n py37 python=3.7\r\nconda activate py37\r\nconda install matplotlib pandas scipy scikit-learn\r\npip install tensorflow==2.0.0-alpha0\r\npython -m ipykernel install --user --name py37 --display-name \"Python 3.7 (TF2)\"\r\n```\r\n\r\nThe last command creates the kernel.\r\nAs I said before, the notebook app is installed in the base environment.\r\n\r\n> But my understanding is that\r\nJupyter prepends the bin directory for the active virtualenv to the\r\nPATH seen by the notebook context\r\n\r\nApparently, this is not the case. When you select a kernel to use with a notebook, the PATH is not modified. The PATH is modified when you activate the env in the terminal, but not when you select a kernel from the notebook app. Maybe there is a way to write a special kernelspec in a way that the PATH is prepended with the current env bin dir, but I don't  know how.\r\n\r\nBTW, this is an issue with `tensorboard` and not `tensorflow`. I believe that a simple fix would be replacing the call to:\r\n\r\n```\r\ntensorboard\r\n```\r\n\r\nwith\r\n\r\n```\r\npython -m tensorboard.main\r\n```\r\n\r\nin the tensorboard code.\r\n", "Okay, thanks for clarifying.\r\n\r\nInvoking `tensorboard` rather than `python -m tensorboard.main` is\r\nintentional: it enables you to provide a different TensorBoard entry\r\npoint. For instance, within Google, `tensorboard` is actually a compiled\r\nprogram that runs a slightly different module with some wrapper code and\r\nadditional Google-specific configuration.\r\n\r\nPersonally, I\u2019ve found that the best way to avoid `PATH` headaches like\r\nthis is to only install packages inside virtualenvs, avoiding system-\r\nand user-level site packages entirely. If you want to use fancier\r\nsetups, more power to you, but it\u2019s much harder to support such setups\r\nin full generality.\r\n\r\nI\u2019ll add a note to the documentation that indicates that `tensorboard`\r\nmust be on your path inside the notebook context for the notebook\r\nextensions to work. Thanks for the report!\r\n", "Fine for me. Thanks for the patch."]}, {"number": 27302, "title": "Minor fix for Docs", "body": "", "comments": []}, {"number": 27301, "title": "Fix crash of GFile in python 3.7", "body": "This fix tries to address the issue raised in #27276 where in Python 3.7, opening a zip file (of GFile) will results in the error of\r\n```\r\n    bytes = self.zip.open(key)\r\n  File \"/usr/lib64/python3.7/zipfile.py\", line 1480, in open\r\n    self._fpclose, self._lock, lambda: self._writing)\r\n  File \"/usr/lib64/python3.7/zipfile.py\", line 722, in __init__\r\n    self.seekable = file.seekable\r\nAttributeError: 'GFile' object has no attribute 'seekable'\r\n```\r\n\r\nThe issue is that Python 3.7 adds seekable check:\r\nhttps://github.com/python/cpython/commit/066df4fd454d6ff9be66e80b2a65995b10af174f\r\n\r\nThis fix adds `seekable()` and returns True, as GFile is indeed seekable.\r\n\r\nThis fix fixes #27276\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can you update api_compatibility_test goldens as well? That test is failing now because 'seekable' is a new method added in the API.\r\nSee instructions here to update goldens: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/api/tests", "Thanks @annarev for the review. The api goldens has been updated."]}, {"number": 27300, "title": "[Intel MKL] Enabling BFloat16 NN ops using MKLDNN API - Round 1", "body": "This PR enables support for BFloat16 type in all the pooling ops using MKLDNN APIs.", "comments": ["I am not familiar with this code, so I'll leave the review to @penpornk"]}, {"number": 27299, "title": "TFTRT: Allow reshape from weights to constant scalar tensors", "body": "TensorRT allows scalar tensors, which is denoted by setting nvinfer1::Dims to `nbDims=0, d=[empty]`. You are allowed to reshape a tensor with dims `nbDims=1, d=1` to a scalar.\r\n\r\nTensorRT does not allow weights to be scalars, so a similar weight would have to have dims `nbDims=1, d=1`. But we can convert a weight into a tensor with IConstantLayer. Since we will then have a tensor, we can make it a scalar by setting `nbDims=0, d=[empty]`. However, we had a check in `PrepareTensorForShape` that prevented this. This change removes that unnecessary check.\r\n \r\nThis solves some conversion errors for object detection models.", "comments": ["@aaroey Could you please review the test cases? It would be great if we can get this merged before 1.14 is cut off.", "@trevor-m sure, sorry for the delay."]}, {"number": 27297, "title": "Training set+Validation set+Test set != data set", "body": "Hello,\r\nMy training data set size is 82278 rows. But when I run a train on the csv file, I see below size for my train, validation and test sets. Can you help me run training on the full data set? \r\n\r\nLoading NLP pipeline\r\nWriting dataset\r\nWriting train set metadata with vocabulary\r\nTraining set: 21343\r\nValidation set: 2988\r\nTest set: 6041\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["can you provide more details please.", "The issue seems to be from my dataset. I cannot share it. I will reach out if I can reproduce the issue using a public dataset. \r\n\r\nthanks "]}, {"number": 27295, "title": "tf.keras.layers.AveragePooling1D data_format init argument broken", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu GNU/Linux 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 9.2, cuDNN 7.3.1\r\n- GPU model and memory: Nvidia Titan V, P100, K80\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nWhen instantiating a tf.keras.layers.AveragePooling1D, the data_format argument does not properly change which axis over which the pooling is performed - the pooling operation is conducted across the 2nd dimension of the input tensor regardless of the init argument supplied.\r\n\r\nTo illustrate this, consider 2 layers instantiated as\r\n```\r\npool_1 = tf.keras.layers.AveragePooling1D(data_format='channels_first', pool_size=64)(prev_layer0) \r\npool_2 = tf.keras.layers.AveragePooling1D(data_format='channels_last', pool_size=64)(prev_layer1)\r\n```\r\n\r\n- Assuming the output shape of prev_layer0 is (None,32,None), pool_1 outputs (None,0,None) when it should be outputting (None,32,None)\r\n- Assuming the output shape of prev_layer1 is (None,None,32), pool_2 outputs (None,None,32) correctly\r\n\r\nI have confirmed this is NOT merely the model summary misreporting the output shape - if you run training or prediction with a model containing an output shape of (None,0,None) generated in this way, it will lead to a 'Floating point exception (core dumped)' error.\r\n\r\n**Describe the expected behavior**\r\nWhen the `data_format='channels_first'` init argument is supplied, AveragePooling1D layers should pool along the last dimension of the 3D input tensors instead of the penultimate dimension (which is the expected behaviour when `data_format='channels_last'` is supplied)\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\n#Channels first case\r\ninput_0 = Input(shape=(1,None))\r\nconv1d_1 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation=tf.nn.leaky_relu, data_format = 'channels_first')(input_0)\r\nconv1d_2 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation=tf.nn.leaky_relu, data_format = 'channels_first')(conv1d_1)\r\npool_2 = tf.keras.layers.AveragePooling1D(data_format='channels_first', pool_size=64)(conv1d_2)\r\nconv1d_3 = tf.keras.layers.Conv1D(filters=256, kernel_size=1, padding='same', activation=tf.nn.leaky_relu, data_format = 'channels_first')(pool_2)\r\nmod = Model(input_0, conv1d_3)\r\nmod.summary() #Note the output shape of pool_2 - it will be (None,0,None)\r\n#print(mod.predict(tf.random.uniform((1,1,128), dtype = tf.keras.backend.floatx())).shape) #If you run this it will cause a core dump\r\n\r\n#Channels last case\r\ninput_0 = Input(shape=(None,1)) #implement arbitrary input shapes later\r\nconv1d_1 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation=tf.nn.leaky_relu, data_format = 'channels_last')(input_0)\r\nconv1d_2 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation=tf.nn.leaky_relu, data_format = 'channels_last')(conv1d_1)\r\npool_2 = tf.keras.layers.AveragePooling1D(data_format='channels_last', pool_size=64)(conv1d_2)\r\nconv1d_3 = tf.keras.layers.Conv1D(filters=256, kernel_size=1, padding='same', activation=tf.nn.leaky_relu, data_format = 'channels_last')(pool_2)\r\n\r\nmod2 = Model(input_0, conv1d_3)\r\nmod2.summary()\r\n\r\nprint(mod2.predict(tf.random.uniform((1,128,1), dtype = tf.keras.backend.floatx())).shape) #Outputs a tensor of shape (1,2,256) as expected\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@aligirayhanozbay I cannot reproduce the issue with `!pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190724`. Please check the gist [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/03c58eb73f4a965a40ecfcaf0671dccf/tf_27295_keras_pooling.ipynb). \r\n\r\nLooks like it was resolved. I am closing the issue but feel free to open the issue if it persists again. Thanks!"]}, {"number": 27294, "title": "Rephrase description", "body": "", "comments": []}, {"number": 27293, "title": "Documentation for tf.math.add_n", "body": "Modified tf.math.add_n  #25820 by adding example and linking it to tf.math.accumulate_n.", "comments": ["please @dynamicwebpaige  review this", "I have done the changes as asked by you.", "I still see the trailing whitespace line. Did you push the new commit?", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/backprop.py\r\nyou can check line 215 and 216 in original repo.", "The lines are the same, if you ignore whitespace changes. But you do have trailing whitespace which you should remove, see below:\r\n![bp](https://user-images.githubusercontent.com/323199/55263449-43254500-522e-11e9-8746-3f97947b9225.png)\r\n\r\nThis PR should not have tensorflow/python/eager/backprop.py as a changed file, please revert to the version on master\r\n", "You can try running the following commands (make sure to copy them exactly, one by one):\r\n\r\n```\r\ngit stash\r\ngit checkout master\r\ngit pull\r\ngit checkout -\r\ngit checkout master -- tensorflow/python/eager/backprop.py\r\ngit commit -m \"Fixed whitespace\"\r\ngit stash pop\r\ngit push\r\n```", "@mihaimaruseac  changed that white line trailing issue int his pr also.\r\n", "Now please somebody review", "Please somebody review this PR", "@mihaimaruseac  please review", "Please review this PR", "@rthadur please assign a reviewer to this pr", "@tomhennigan  done with the changes please review it now.", "please review @tomhennigan ", "@tomhennigan please review it now", "Please review it @tomhennigan ", " @rthadur  please add kokoro force run ", "@rthadur tests are still pending", "please somebody intialize checks", "@tomhennigan  can you please tell me why it is failing ubuntu sanity check.", "@tomhennigan I think that error was because of longer length of lines so I reduced length of lines.", "Please keep `tf.math.` prefix", "> Please keep `tf.math.` prefix\r\n\r\n@mihaimaruseac i made changes internally , please approve "]}, {"number": 27292, "title": "keras.layers.RNN with contants ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version (use command below): 1.13 and 1.14\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1 and 10.0\r\n- GPU model and memory: 1080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nTypeError: can only concatenate list (not \"tuple\") to list in RNN::build() if a call the RNN with a Tensor as constants.\r\n\r\n**Describe the expected behavior**\r\n\r\nBasically the build() function of the RNNCellWithConstants should be called, with the input_shape = [(3,3,5), (3,3)]\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass RNNCellWithConstants(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, **kwargs):\r\n        self.state_size = 5\r\n        super(RNNCellWithConstants, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        print(input_shape)\r\n        self.built = True\r\n\r\n    def call(self, inputs, states, constants):\r\n        print(inputs, states, constants)\r\n        return inputs, [inputs]\r\n\r\n\r\n# Test basic case.\r\nx = tf.keras.Input((None, 5))\r\nc = tf.keras.Input((3,))\r\ncell = RNNCellWithConstants()\r\nlayer = tf.keras.layers.RNN(cell)\r\ny = layer(x, constants=c) # Works as expected.\r\n\r\n# Test basic case.\r\nx = tf.zeros([3, 3, 5], dtype=tf.float32)\r\nc = tf.zeros([3, 3], dtype=tf.float32)\r\ncell = RNNCellWithConstants()\r\nlayer = tf.keras.layers.RNN(cell)\r\ny = layer(x, constants=c) # Crash with the following error\r\n```\r\n\r\n**Other info / logs**\r\n\r\nException from example:\r\n```\r\nTraceback (most recent call last):\r\n  File \"bug.py\", line 25, in <module>\r\n    y = layer(x, constants=c)\r\n  File \"/home/matthias/.local/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 690, in __call__\r\n    return super(RNN, self).__call__(inputs, **kwargs)\r\n  File \"/home/matthias/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 585, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/matthias/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1706, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"/home/matthias/.local/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 555, in build\r\n    self.cell.build([step_input_shape] + constants_shape)\r\nTypeError: can only concatenate list (not \"tuple\") to list\r\n```\r\nIf I correct the error temporarily I come to another problem, that the input shapes at build call are not correct any more: [(3, 5), (5,)]\r\n\r\nSo I think the mistake lies in that distinction:\r\n\r\n```\r\n    if is_keras_tensor:\r\n      # Compute the full input spec, including state and constants\r\n      full_input = [inputs] + additional_inputs\r\n      # The original input_spec is None since there could be a nested tensor\r\n      # input. Update the input_spec to match the inputs.\r\n      full_input_spec = [None for _ in range(len(nest.flatten(inputs)))\r\n                        ] + additional_specs\r\n      # Perform the call with temporarily replaced input_spec\r\n      self.input_spec = full_input_spec\r\n      output = super(RNN, self).__call__(full_input, **kwargs)\r\n      # Remove the additional_specs from input spec and keep the rest. It is\r\n      # important to keep since the input spec was populated by build(), and\r\n      # will be reused in the stateful=True.\r\n      self.input_spec = self.input_spec[:-len(additional_specs)]\r\n      return output\r\n    else:\r\n      if initial_state is not None:\r\n        kwargs['initial_state'] = initial_state\r\n      if constants is not None:\r\n        kwargs['constants'] = constants\r\n      return super(RNN, self).__call__(inputs, **kwargs)\r\n```\r\nIf I set is_keras_tensor to True, everything will behave as expected.", "comments": ["I want to work on this issue please @ymodak can you guide me please?", "Should be fixed by https://github.com/tensorflow/tensorflow/commit/3e8a80bce0f7ef0ab2ee49f3528a2652f26110f0 now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27292\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27292\">No</a>\n", "I wanted to reopen this, because it now seems that its impossible to build the cell based on the shape of any constants, since the cells build method is only ever called with the timestep input shape. We can pass constants into the cells call method, but without having some sort of weights to go along with it there's not much functionality"]}, {"number": 27291, "title": "Spell fix", "body": "", "comments": []}, {"number": 27290, "title": "AttributeError: 'KerasTPUModel' object has no attribute '_distribution_strategy'", "body": "I load inceptionV3 with:\r\n\r\n```\r\nfrom keras.applications import InceptionV3\r\n\r\nmodel= InceptionV3(weights='imagenet',\r\n                             include_top=False,\r\n                             pooling='max',\r\n                             input_shape=(229, 229, 3))\r\n```\r\n\r\nThen I convert it to TPU model with:\r\n\r\n```\r\nTPU_WORKER = 'grpc://10.x.x.x:8470'\r\nmodel = tf.contrib.tpu.keras_to_tpu_model(\r\n            model,\r\n            strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n                tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\r\n```\r\n\r\nAnd I try to extract feature vector of an image with:\r\n\r\n`model.predict`\r\n\r\nThe error I receive is\r\n\r\n>  AttributeError: 'KerasTPUModel' object has no attribute '_distribution_strategy'\r\n\r\nMy code works fine without the TPU part, however its very slow and I want to do the predict part on TPU for better performance.", "comments": ["@ValentinMezev Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. Thanks!", "Hi @jvishnuvardhan \r\nThank you for your reply and guidance. Apologies for the poor description. Here is the filled template:\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 18.10 cosmic\r\n- Mobile device: N/A\r\n- TensorFlow installed from (source or binary): installed with pip install tensorflow\r\n- TensorFlow version:\r\n- Python version: tensorflow (1.13.1); tensorflow-estimator (1.13.0)\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): not sure\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 8.2.0-7ubuntu1) 8.2.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: Using GCP TPU\r\n\r\n\r\n\r\n**Describe the problem**\r\nI use InceptionV3 from tf.keras.applications for feature extraction.\r\nWhen I obtain the model I call predict on it in order to extract the features.\r\nThis works but slow and I want to use TPU. I saw keras_to_tpu_model function I can use to transform Keras model into KerasTPUModel which should run on TPU.\r\n\r\nHere is my code:\r\n\r\n```\r\nmodel= tf.keras.applications.InceptionV3(weights='imagenet',\r\n                             include_top=False,\r\n                             pooling='max',\r\n                             input_shape=(229, 229, 3))\r\n\r\nTPU_WORKER = 'grpc://10.x.x.x:8470'\r\nmodel = tf.contrib.tpu.keras_to_tpu_model(\r\n            model,\r\n            strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n                tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\r\n\r\nmodel.predict(source)\r\n```\r\n\r\nThe error thrown is:\r\n\r\n> AttributeError: 'KerasTPUModel' object has no attribute '_distribution_strategy'\r\n", "That particular implementation was a placeholder.\r\n\r\nSourabh might know if TPUStrategy works with predict in TF 1.13:\r\nhttps://www.tensorflow.org/versions/r1.13/api_docs/python/tf/contrib/distribute/TPUStrategy?hl=en", "`tf.contrib.tpu.keras_to_tpu_model` is deprecated please use [tf.distribute.TPUStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy) instead.\r\nSee https://www.tensorflow.org/guide/tpu for usage details. Thanks!"]}, {"number": 27289, "title": "Test case reports an exception to stdout, with stack trace, when testing under self.assertRaises()", "body": "**System information**\r\n- Have I written custom code: Only for testing\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): From PyPI via pip3 install --upgrade tensorflow==1.11.0\r\n- TensorFlow version: v1.11.0-0-gc19e29306c 1.11.0\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: CUDA 9.0, cuDNN 7.0\r\n- GPU model and memory: NVIDIA GeForce GTX 1080, 8GB\r\n\r\n\r\n**Describe the current behavior**\r\nException is reported to stdout, with stack trace, when testing under `self.assertRaises()`:\r\n\r\n```\r\n2019-03-29 13:48:50.433118: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nERROR:tensorflow:assertion failed: [1]\r\n         [[{{node Assert/AssertGuard/Assert}} = Assert[T=[DT_FLOAT], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Assert/AssertGuard/Assert/Switch, Assert/AssertGuard/Assert/Switch_1)]]\r\n\r\nCaused by op 'Assert/AssertGuard/Assert', defined at:\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n...\r\n  File \"/usr/lib/python3.5/unittest/case.py\", line 600, in run\r\n    testMethod()\r\n  File \"/home/pryldm1/work/tmp/mock_test.py\", line 19, in testRaises\r\n    sess.run(foo())\r\n  File \"/home/pryldm1/work/tmp/mock_test.py\", line 7, in foo\r\n    max_assert = tf.Assert(tf.greater(max_val, 1.01), [max_val])\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py\", line 189, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs))\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 158, in Assert\r\n    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2087, in cond\r\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1920, in BuildCondBranch\r\n    original_result = fn()\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 156, in true_assert\r\n    condition, data, summarize, name=\"Assert\")\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 52, in _assert\r\n    name=name)\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"/home/dl_docker/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): assertion failed: [1]\r\n         [[{{node Assert/AssertGuard/Assert}} = Assert[T=[DT_FLOAT], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Assert/AssertGuard/Assert/Switch, Assert/AssertGuard/Assert/Switch_1)]]\r\n\r\n..\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.045s\r\n\r\nOK\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe exception must be saliently catched:\r\n\r\n```\r\n2019-03-29 13:52:58.147694: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n..\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.026s\r\n\r\nOK\r\n```\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef foo():                                                                                                                                                                                                                                                            \r\n    result = tf.constant(0)                                                                                                                                                                                                                                           \r\n    max_val = tf.constant(1.0)                                                                                                                                                                                                                                        \r\n    max_assert = tf.Assert(tf.greater(max_val, 1.01), [max_val])                                                                                                                                                                                                      \r\n    with tf.control_dependencies([max_assert]):                                                                                                                                                                                                                       \r\n        result = tf.identity(result)                                                                                                                                                                                                                                  \r\n    return result                                                                                                                                                                                                                                                     \r\n\r\n\r\nclass DummyTestCase(tf.test.TestCase):                                                                                                                                                                                                                                \r\n                                                                                                                                                                                                                                                                      \r\n    def testRaises(self):                                                                                                                                                                                                                                             \r\n        with self.test_session() as sess:                                                                                                                                                                                                                             \r\n            with self.assertRaises(tf.errors.InvalidArgumentError):                                                                                                                                                                                                   \r\n                sess.run(foo())                                                                                                                                                                                                                                       \r\n\r\n\r\nif __name__ == '__main__':                                                                                                                                                                                                                                            \r\n    tf.test.main()\r\n```\r\n", "comments": ["I should note the issue stars appearing from TF v1.11. Earlier versions of TensorFlow behave as expected.", "@alextp any ideas?", "Huh I noticed the same thing, it makes our test failure logs very unfortunate to read.\r\n\r\nDo you know if this is something TF itself does or if it's a property of the library we use under the hood for unit tests, https://github.com/abseil/abseil-py/blob/master/absl/testing/absltest.py ?", "Ah, I misread that after the logging it still fails, but it is just the logging.\r\nI think assertRaises comes from this implementation in python unittest:\r\nhttps://docs.python.org/3/library/unittest.html#unittest.TestCase.assertRaises\r\nhttps://github.com/python/cpython/blob/3.8/Lib/unittest/case.py#L208\r\nI cannot see where it prints anything in the terminal.\r\n\r\nThe message looks like it is fully constructed here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/logging_ops.cc#L67\r\n\r\nAnd puzzlingly to me, it does not seem to have any TF error message prefixes (date, timestamp) or anything around it.\r\nSo I do not think TF prints it, but I also do not think python unittest prints it.\r\n\r\n\r\n\r\n", "Are we sure we depend on python unittest and not absl for assertraises?\n(not that I see a print anywhere on absl's code either).\n\nI wonder if we can debug this somehow; maybe redirect stdout to a pipe and\nstop reading from this pipe when an exception comes and then crash the\npython program to get a stack trace?\n\nOn Wed, Nov 20, 2019 at 12:10 PM Gunhan Gulsoy <notifications@github.com>\nwrote:\n\n> Ah, I misread that after the logging it still fails, but it is just the\n> logging.\n> I think assertRaises comes from this implementation in python unittest:\n>\n> https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertRaises\n> https://github.com/python/cpython/blob/3.8/Lib/unittest/case.py#L208\n> I cannot see where it prints anything in the terminal.\n>\n> The message looks like it is fully constructed here:\n>\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/logging_ops.cc#L67\n>\n> And puzzlingly to me, it does not seem to have any TF error message\n> prefixes (date, timestamp) or anything around it.\n> So I do not think TF prints it, but I also do not think python unittest\n> prints it.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27289?email_source=notifications&email_token=AAABHRLEZPGDZA5FYDNZOUDQUWKUFA5CNFSM4HCJZA52YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEUPJSY#issuecomment-556332235>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHROTOK2JKSVGDFN6S3LQUWKUFANCNFSM4HCJZA5Q>\n> .\n>\n\n\n-- \n - Alex\n", "https://github.com/abseil/abseil-py/blob/master/absl/testing/absltest.py#L519\r\n\r\nAbsl inherits from unittest.Testcase, and I cannot find an override of assertRaises within absl.", "@dprylipko We see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Hence moving this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27289\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27289\">No</a>\n"]}, {"number": 27288, "title": "GPU Memory Leak for eager mode, tf.scatter_nd_update.", "body": "- Have I written custom code : yes\r\n- OS Platform and Distribution : ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: v1.12.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 9.2/7.2.1\r\n- GPU model and memory: Tesla P40, 24GB\r\n\r\nwhen i use `tf.scatter_nd_update`, if ref is tf.int32 Variable, everything is fine. if ref is tf.float32 Variable, then there is a memory leak.\r\n\r\ni hope the folloing code will reproduce the bug.\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.memory_stats import BytesInUse\r\n\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\r\nconfig = tf.ConfigProto(allow_soft_placement=True)\r\nconfig.gpu_options.allow_growth = True\r\ntf.enable_eager_execution(config=config)\r\n\r\nfor i in range(10):\r\n    ref = tf.zeros((128, 21, 4), dtype=tf.int32)\r\n    indices = tf.zeros([128, 2], dtype=tf.int32)\r\n    updates = tf.ones([128, 4], dtype=tf.int32)\r\n    update = tf.scatter_nd_update(tf.Variable(ref), indices, updates)\r\n    tf.set_random_seed(1)\r\n    print(BytesInUse().numpy())\r\n\r\nprint('------------------------------------')\r\n\r\nfor i in range(10):\r\n    ref = tf.zeros((128, 21, 4), dtype=tf.float32)\r\n    indices = tf.zeros([128, 2], dtype=tf.int32)\r\n    updates = tf.ones([128, 4], dtype=tf.float32)\r\n    update = tf.scatter_nd_update(tf.Variable(ref), indices, updates)\r\n    tf.set_random_seed(1)\r\n    print(BytesInUse().numpy())\r\n```\r\n\r\nwhen i run the code, get the following results\r\n\r\n```\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n------------------------------------\r\n89344\r\n132608\r\n175616\r\n261376\r\n303616\r\n347648\r\n389632\r\n433664\r\n475648\r\n519680\r\n```\r\n", "comments": ["Can you remove allow_growth and add a \"import gc; gc.collect()\" before printing the bytes in use to confirm it's not an issue just of the python gc taking a while to run?", "@alextp hi, thanks for your reply. i add `import gc; gc.collect()` & remove session config and get the same result.\r\n\r\ncodes\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.memory_stats import BytesInUse\r\n\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\r\ntf.enable_eager_execution()\r\n\r\nfor i in range(10):\r\n    ref = tf.zeros((128, 21, 4), dtype=tf.int32)\r\n    indices = tf.zeros([128, 2], dtype=tf.int32)\r\n    updates = tf.ones([128, 4], dtype=tf.int32)\r\n    update = tf.scatter_nd_update(tf.Variable(ref), indices, updates)\r\n    tf.set_random_seed(1)\r\n    import gc; gc.collect()\r\n    print(BytesInUse().numpy())\r\n\r\nprint('------------------------------------')\r\n\r\nfor i in range(10):\r\n    ref = tf.zeros((128, 21, 4), dtype=tf.float32)\r\n    indices = tf.zeros([128, 2], dtype=tf.int32)\r\n    updates = tf.ones([128, 4], dtype=tf.float32)\r\n    update = tf.scatter_nd_update(tf.Variable(ref), indices, updates)\r\n    tf.set_random_seed(1)\r\n    import gc; gc.collect()\r\n    print(BytesInUse().numpy())\r\n```\r\n\r\nresults\r\n```\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n1280\r\n------------------------------------\r\n89344\r\n132608\r\n175616\r\n261376\r\n303616\r\n347648\r\n389632\r\n433664\r\n475648\r\n519680\r\n```", "@jaingaurav can you look at this?", "Also does this also reproduce on tf nightly? 1.12 is a little old and it had some known memory leaks.", "I do know there are some known memory leaks for v1.12.0\r\n#19671, this issue mentioned that `tf.set_random_seed(1)` can fix the known issue.\r\nAs far as i know, tf nightly gpu need cuda 10 instead of cuda 9. It's a bit difficult for me to run the code on tf nightly right now. I may have a try in two days.", "tf nightly gpu(1.14.1-dev20190404) can reproduce the bug.", "@jaingaurav could you please look at this?", "@irvingzhang0512: A little swamped at the moment, but I plan on starting work on this bug next week.", "same issue here, any updates? @irvingzhang0512  btw, tf.set_random_seed(x) workaround could assign any value for x, right?", "@XuesongYang yes, i think `tf.set_random_seed(x)` clears eager mode caches by calling `pywrap_tensorflow.TFE_ContextClearCaches(self._context_handle)`. so any value works.", "at what point do you add tf.set_random_seed(1). i placed the line before model.compile() but i'm still having problems. I have to comment out tf.enable_eager_execution() otherwise my RAM gets depleted and computer freezes.", "@jaingaurav this is serious enough we should at least triage it before the 2.0 RC", "I believe I'm able to reproduce this in a unit test now. Working on finding the source of the leak.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27288\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27288\">No</a>\n"]}, {"number": 27287, "title": "Lite: Concatenate Op 4D restriction removed", "body": "Current kernel can support higher dimension as well.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27287) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> memo **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> \r\n>     * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> \r\n> ##### Corporate signers\r\n> \r\n>     * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\r\n> \r\n>     * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n>     * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \r\n> information_source **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27287) for more info**.\r\n\r\nI signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27287) for more info**.\n\n<!-- ok -->", "Thanks for the PR. "]}, {"number": 27286, "title": "Lite: Concatenate Op 4D restriction removed", "body": "Current kernel can support higher dimension as well.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27286) for more info**.\n\n<!-- need_sender_cla -->", "Closing for CLA issue"]}, {"number": 27285, "title": "Depthwise separable conv with floating point 16 and batch norm is too slow.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution: **16.04.5 LTS (Xenial Xerus)**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **n.a.**\r\n- TensorFlow installed from (source or binary): **source**\r\n- TensorFlow version (use command below): **1.12.0**\r\n- Python version: **3.6.7**\r\n- Bazel version (if compiling from source): **0.21.0**\r\n- GCC/Compiler version (if compiling from source): **5.4.0**\r\n- CUDA/cuDNN version: **10.0 / 7.3.0**\r\n- GPU model and memory: **v100 16gb**\r\n\r\n**Describe the current behavior**\r\nThe depthwise separable convolution, unlike the normal convolution when used with floating point 16 is slower than floating point 32, but more importantly when it is used with batch norm and an optmizer (sgd, adam, etc.), it becomes very much (~40 times) slower than floating point 32. Another unexpected behavior is getting \"core dumped\" with most of the filter sizes, that only happens in case of separable conv with fp16, but not with the other combinations. \r\nFollowing is what I am getting from the given code:\r\n```\r\nExperiment {'fp16': False, 'sep_conv': False, 'bn': True, 'kernel_size': 4} started\r\nand took 1945 ms\r\nExperiment {'fp16': True, 'sep_conv': False, 'bn': True, 'kernel_size': 4} started\r\nand took 1425 ms\r\nExperiment {'fp16': False, 'sep_conv': True, 'bn': True, 'kernel_size': 4} started\r\nand took 4430 ms\r\nExperiment {'fp16': True, 'sep_conv': True, 'bn': True, 'kernel_size': 4} started\r\nand took 161081 ms\r\nExperiment {'fp16': True, 'sep_conv': True, 'bn': False, 'kernel_size': 4} started\r\nand took 7191 ms\r\nExperiment {'fp16': True, 'sep_conv': True, 'bn': False, 'kernel_size': 3} started\r\n2019-03-29 13:20:30.522213: F tensorflow/stream_executor/stream_executor_pimpl.cc:712] Check failed: 0 == size % 4 (0 vs. 2)need 32-bit multiple size to fill with 32-bit pattern\r\nAborted (core dumped)\r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect the batch norm not to make it so much slower and not to get core dumped with different kernel sizes.\r\nAlso, I expected fp 16, to be faster than fp 32, (as is in normal conv).\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport time\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import layers\r\n\r\ndepth = 50\r\nwidth = 100\r\nnum_filters = 100\r\nbatch_size = 16\r\nrepeat = 3\r\n\r\n\r\ndef create_optimize_op(use_fp_16: bool, use_separable_conv: bool, use_batch_norm: bool, kernel_size: int,\r\n                       exp_index: int) -> tf.Tensor:\r\n\r\n    label = tf.random_normal(shape=[batch_size, width, width, num_filters],\r\n                             dtype=tf.float16 if use_fp_16 else tf.float32)\r\n    input_image = tf.random_normal(shape=[batch_size, width, width, 3], dtype=tf.float16 if use_fp_16 else tf.float32)\r\n    head = input_image\r\n    for layer_ind in range(depth):\r\n        conv_f = layers.separable_conv2d if use_separable_conv else layers.conv2d\r\n        head = conv_f(head, num_filters, (kernel_size, kernel_size), stride=(1, 1), padding=\"SAME\", normalizer_fn=None,\r\n                      reuse=tf.AUTO_REUSE, scope=f\"{exp_index}layer{layer_ind}\", data_format=\"NHWC\")\r\n        if use_batch_norm:\r\n            head = tf.contrib.layers.batch_norm(head, scale=True, is_training=True)\r\n    reshaped_label = tf.reshape(label, shape=[batch_size, -1])\r\n    reshaped_pred = tf.reshape(head, shape=[batch_size, -1])\r\n    loss = tf.losses.softmax_cross_entropy(reshaped_label, reshaped_pred)\r\n    return tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\r\n\r\n\r\nexperiments = [{\"fp16\": False, \"sep_conv\": False, \"bn\": True, \"kernel_size\": 4},\r\n               {\"fp16\": True, \"sep_conv\": False, \"bn\": True, \"kernel_size\": 4},\r\n               {\"fp16\": False, \"sep_conv\": True, \"bn\": True, \"kernel_size\": 4},\r\n               {\"fp16\": True, \"sep_conv\": True, \"bn\": True, \"kernel_size\": 4},\r\n               {\"fp16\": True, \"sep_conv\": True, \"bn\": False, \"kernel_size\": 4},\r\n               {\"fp16\": True, \"sep_conv\": True, \"bn\": False, \"kernel_size\": 3}]\r\n\r\nwith tf.Session() as session:\r\n    for index, experiment in enumerate(experiments):\r\n        step = create_optimize_op(experiment[\"fp16\"], experiment[\"sep_conv\"], experiment[\"bn\"],\r\n                                  experiment[\"kernel_size\"], index)\r\n        init_op = tf.global_variables_initializer()\r\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n        print(f\"Experiment {experiment} started\")\r\n        # a first warmup run.\r\n        _ = session.run([init_op])\r\n        _ = session.run([update_ops, step])\r\n\r\n        start = time.clock()\r\n        for i in range(repeat):\r\n            _ = session.run([init_op])\r\n            _ = session.run([update_ops, step])\r\n        end = time.clock()\r\n        time_taken = int((end - start) * 1000)\r\n        print(f\"and took {time_taken} ms\")\r\n```\r\n", "comments": ["I notice that you're using contrib layers. Can you test this with Keras layers and see if you see the same issue?", "Thanks so much for your response. Changing to keras layers fixes the very slow (~40x slower) combination of depthwise separable conv, fp16, and normalization (see the following report); though I had to decrease the network depth (from 50 to 25) to enable it to fit in the memory with the keras layers api. However, still with depthwise separable conv, using fp16 is ~1.6 times slower than using fp32.\r\nAlso, the experiment gets 'core dumped' with different kernel sizes (3).\r\n\r\n> Experiment {'fp16': False, 'sep_conv': False, 'bn': True, 'kernel_size': 4} started\r\nand took 1021 ms\r\nExperiment {'fp16': True, 'sep_conv': False, 'bn': True, 'kernel_size': 4} started\r\nand took 464 ms\r\nExperiment {'fp16': False, 'sep_conv': True, 'bn': True, 'kernel_size': 4} started\r\nand took 1815 ms\r\nExperiment {'fp16': True, 'sep_conv': True, 'bn': True, 'kernel_size': 4} started\r\nand took 2957 ms\r\nExperiment {'fp16': True, 'sep_conv': True, 'bn': False, 'kernel_size': 4} started\r\nand took 2829 ms\r\nExperiment {'fp16': True, 'sep_conv': True, 'bn': False, 'kernel_size': 3} started\r\n2019-04-24 13:57:01.250352: F tensorflow/stream_executor/stream_executor_pimpl.cc:712] Check failed: 0 == size % 4 (0 vs. 2)need 32-bit multiple size to fill with 32-bit pattern\r\nAborted (core dumped)", "I have the same problem. FP16 separable_conv2D is super slow.", "Same problem. tf.nn.depthwise_conv2d in FP16 turns out to be several times slower than in FP32.", "any update?", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/depthwise_conv_op_gpu.h#L1766\r\n\r\nIt seems to be a bug here. In this case `num_filter_backprop = 3 * 3 * 3, sizeof(fp16) = 2`, so `ThenMemset32` will definitely raise error `0 == size % 4 (0 vs. 2)`. \r\n\r\n@jvishnuvardhan could you take a look at this?", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. "]}, {"number": 27284, "title": "Added custom object for Keras Model.", "body": "Added the custom object for Keras model.", "comments": ["This functionality was added in https://github.com/tensorflow/tensorflow/commit/09deaeb03ca4ceb40cf600a337083e2054e65390."]}, {"number": 27283, "title": "InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'Reshape' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NO\r\n- TensorFlow installed from (source or binary): N/A\r\n- TensorFlow version (use command below):1.3.0 GPU\r\n- Python version:2.7.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):NO\r\n- CUDA/cuDNN version: 9/6\r\n- GPU model and memory: Tesla K80 11441MiB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nSo I've loaded my model via a `.pb` file and it loaded fine, but when I try to use it to predict an image it throws the error below.\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'Reshape' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='CPU'; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_COMPLEX128]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_COMPLEX64]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_INT8]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT8]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_INT16]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_UINT16]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_DOUBLE]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_FLOAT]; Tshape in [DT_INT32]\r\n  device='GPU'; T in [DT_HALF]; Tshape in [DT_INT32]\r\n\r\n           [[Node: Reshape_165 = Reshape[T=DT_FLOAT, Tshape=DT_INT64](transpose_145, add_31)]]\r\n```\r\n\r\nPS: I loaded this model on TF v1.13 and it worked fine, so maybe the problem is in v1.3. I just want to know why this is happening.\r\n**Describe the expected behavior**\r\nIt should produce the predicted arrays. \r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["How do you fix it?I meet the same issues about Op \"Sin\"."]}, {"number": 27282, "title": "/tensorflow/lite/experimental/c/c_api_types.h is not readable on Windows filesystem.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: f089b3180ec7ddecd503d6d499cd6977c22b8f11\r\n- Python version: No\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): gcc 8.3\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n**Describe the problem**\r\n\r\n`/tensorflow/lite/experimental/c/c_api_types.h` is symbolic link to `/tensorflow/lite/c/c_api_internal.h`.  On DOS compatible file system, it is replaced with following text file.\r\n```\r\n../../c/c_api_internal.h\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nClone repository, and make sure file `/tensorflow/lite/experimental/c/c_api_types.h`  is NOT a symbolic link on Windows.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nNo", "comments": ["I suggest that the file `c_api_types.h` is replaced to be:\r\n\r\n```\r\n#include \"tensorflow/lite/c/c_api_internal.h\"\r\n```\r\n\r\nOr fix all files which include `c_api_types.h` to include `c_api_internal.h`.", "We'll be removing the symlink in the next week or so, which should resolve the problem. Is this breaking your build?", "As I mentioned above, symbolic link is not created with git clone. Windows Git makes plain text file that the path is written.", "@jdduke Do you have any plans to introduce patch #27427?\r\nThis issue is important for us.", "Apologies for the delay, hoping to land a fix by EOD. Thanks for your patience.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27282\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27282\">No</a>\n", "@jdduke do you mean exerimental feature will be merged into standard feature soon?", "Yes we're hoping to migrate the C API bindings out of experimental."]}, {"number": 27281, "title": " Error polling for event status: failed to query event: CUDA_ERROR_UNKNOWN during training process", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.10\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 9.0/7.2.1\r\n- GPU model and memory: 3x NVIDIA RTX 2080 Ti\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nSometimes, during training process , i get this error:  E tensorflow/stream_executor/cuda/cuda_event.cc:48] Error polling for event status: failed to query event: CUDA_ERROR_UNKNOWN: unknown error\r\n2019-03-28 20:00:09.965396: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:274] Unexpected Event status: 1\r\n\r\nThis happens sometimes when i am not connected to that machine. For some reason, when i am working on that machine, i'm not getting that error.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Small snippet of code\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam', metrics=['accuracy','binary_crossentropy'])\r\nfilepath=\"weights-{epoch:02d}-{acc:.4f}.h5\"\r\nmc = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=50)\r\nbaseline = model.fit(X,Y,epochs=200, batch_size=32,validation_data=(Xtest, Ytest), callbacks=[mc])\r\n\r\n\r\n**Code to reproduce the issue**\r\nIt reproduces at an epoch numeber bigger than 150( sometimes is around 200, sometimes 500)\r\n\r\n**Other info / logs**.\r\n", "comments": ["> This happens sometimes when i am not connected to that machine. For some reason, when i am working on that machine, i'm not getting that error.\r\n\r\nAre you sure this is a problem with TensorFlow?  This aspect of the problem makes it sound like a systemic issue (e.g. perhaps disconnecting from the machine shuts down the GPU?).", "I have just encountered the same bug whilst training a custom GAN built with the tensorflow framework. It also occured after a few hundred epochs and the loss function+optimiser I used are the same as christiangogosilas. Rtx 2070super, python 3.7.4, tensorflow installed using anaconda. ", "> I have just encountered the same bug whilst training a custom GAN built with the tensorflow framework. It also occured after a few hundred epochs and the loss function+optimiser I used are the same as christiangogosilas. Rtx 2070super, python 3.7.4, tensorflow installed using anaconda.\r\n\r\nDid you notice anything suspicious in the logs?  If you link to them from here I'm happy to take a look as well.", "Thank you for the offer sanjoy. Do you know if tensorflow save error logs like this somewhere? I found it hard to search for an answer online as anything with tensorflow and logs brings up code guidelines as you can imagine.\r\n", "> Thank you for the offer sanjoy. Do you know if tensorflow save error logs like this somewhere?\r\n\r\nJust what it prints out to stderr.\r\n\r\nFor extra points you could also set the environment variable `TF_CPP_MIN_VLOG_LEVEL` to `1` (used [here](https://github.com/tensorflow/tensorflow/blob/8191585626f438c185ce608e177a8c33fb9d3bee/tensorflow/core/platform/default/logging.cc#L178)) which will turn on verbose logging.  However, I'm not  sure if the logging output will remain small enough to be uploaded with this set.", "I can try catch the print out, but unfortunately it freezes my pc then the system reboots when it does occur. I guess the GPU crashes? I do not have this problem on every run so it is even harder to catch.", "> unfortunately it freezes my pc then the system reboots when it does occur. I guess the GPU crashes?\r\n\r\nThat sounds like a kernel / driver issue to me, not something specific to TF (IIUC TF should not be able to crash the machine).  Can you bring this up on NVIDIA's support forums?", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27281\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27281\">No</a>\n"]}, {"number": 27280, "title": "Fix compilation warning", "body": "```\r\nc:/users/mattn/go/src/github.com/tensorflow/tensorflow/tensorflow/lite/delegates/gpu/gl_delegate.h:42:22:\r\nwarning: 'dllimport' attribute ignored [-Wattributes]\r\n enum TFL_CAPI_EXPORT TfLiteGlObjectType {\r\n                      ^~~~~~~~~~~~~~~~~~\r\n```\r\nenum is not an exportable type for DLL.", "comments": []}, {"number": 27279, "title": "TFLite allocate tensors fails", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (use command below):\r\n2.0.0-dev20190327\r\n- Python version:\r\n3.6.8\r\nNo GPU\r\n\r\n**Describe the current behavior**\r\nI have been trying to convert Yolov3 from tensorflow to tflite and was facing issues due to the lack of ResizeNearestNeighbor custom operation. However with the recent nightly build I was able to convert the model and save the tflite file. When I attempt to load the tflite model, allocate tensors fails with the following error : \r\n\r\n`~/anaconda3/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)\r\n     93   def allocate_tensors(self):\r\n     94     self._ensure_safe()\r\n---> 95     return self._interpreter.AllocateTensors()\r\n     96 \r\n     97   def _safe_to_run(self):\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)\r\n    104 \r\n    105     def AllocateTensors(self):\r\n--> 106         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\n    107 \r\n    108     def Invoke(self):\r\n\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:57 t0->dims->size <= 4 was not true.Node number 265 (CONCATENATION) failed to prepare.`\r\n\r\nCode to convert tensorflow frozen graph to tflite\r\n`import tensorflow as tf\r\nINPUT_ARRAYS = ['Placeholder']\r\nOUTPUT_ARRAYS = ['concat_9','mul_6']\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\r\n            'checkpoint/yolov3_cpu_nms.pb', INPUT_ARRAYS, OUTPUT_ARRAYS)\r\nconverter.allow_custom_ops=True\r\ntflite_model = converter.convert()`\r\n\r\nCode to load tflite model and allocate tensors:\r\n`import tensorflow as tf\r\ninterpreter=tf.lite.Interpreter(model_path='test.tflite')\r\n\r\ninterpreter.allocate_tensors()`\r\n\r\n", "comments": ["Can you provide your model or a minimal model which which reproduces your error?", "> Can you provide your model or a minimal model which which reproduces your error?\r\n\r\nHow? The TFLite file or anything else? The tflite file is around 240 Mb for coco dataset not really sure how I can provide it here", "@reorder-cv Please provide `checkpoint/yolov3_cpu_nms.pb`.", "> @reorder-cv Please provide `checkpoint/yolov3_cpu_nms.pb`.\r\n\r\nThe file is larger than 10MB so I am not able to upload it here.\r\n\r\n", "@reorder-cv : This issue is solved with my PR #27287, please try using latest code from TFLite, it will solve your blocking issue. If it solves, please close this issue.", "> @reorder-cv : This issue is solved with my PR #27287, please try using latest code from TFLite, it will solve your blocking issue. If it solves, please close this issue.\r\n\r\nI compiled from the latest code. I am getting a new issue \"Didn't find op for builtin opcode 'CONV_2D' version '2'\" when I load the tflite file. ", "@reorder-cv : Could you please check in your workspace: [https://github.com/tensorflow/tensorflow/blob/12ee3420367f9a0f728c6b2e0493f5fb150eea47/tensorflow/lite/kernels/register.cc#L192](url)\r\nwhat is min & max version?\r\n\r\nAlso please cross check [https://github.com/tensorflow/tensorflow/blob/12ee3420367f9a0f728c6b2e0493f5fb150eea47/tensorflow/lite/toco/tflite/operator.cc#L105](url)\r\nwhether it is in sync with latest code? If possible please try to post the code snippet for the api.", "@reorder-cv : Also for my reference would you be able to share your model Graphdef file(pbtxt)?", "> @reorder-cv : Could you please check in your workspace: [https://github.com/tensorflow/tensorflow/blob/12ee3420367f9a0f728c6b2e0493f5fb150eea47/tensorflow/lite/kernels/register.cc#L192](url)\r\n> what is min & max version?\r\n> \r\n> Also please cross check [https://github.com/tensorflow/tensorflow/blob/12ee3420367f9a0f728c6b2e0493f5fb150eea47/tensorflow/lite/toco/tflite/operator.cc#L105](url)\r\n> whether it is in sync with latest code? If possible please try to post the code snippet for the api.\r\n\r\nQ1) Min - 1 and Max - 3 \r\nAddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(),\r\n             /* min_version */ 1,\r\n             /* max_version */ 3)\r\n\r\nQ2) I checked diff between the tensorflow github repository and the cloned repository I used to compile. There are zero removals and additions. ", "> @reorder-cv : Also for my reference would you be able to share your model Graphdef file(pbtxt)?\r\n\r\nI do not have a pbtxt file, I have a .pb file. I converted it using the following code and the size of the file is large for me to share across github. \r\n`from google.protobuf import text_format\r\nfrom tensorflow.python.platform import gfile\r\ndef graphdef_to_pbtxt(filename): \r\n    with gfile.FastGFile(filename,'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n        tf.import_graph_def(graph_def, name='')\r\n        tf.train.write_graph(graph_def, 'checkpoint/', 'yolov3.pbtxt', as_text=True)\r\n    return`\r\n", "> @reorder-cv : Also for my reference would you be able to share your model Graphdef file(pbtxt)?\r\n\r\nOk I recompiled with some changes, allocate tensors cleared. But I have a new problem now interpreter.invoke() causes core dumped and exits shell", "> > @reorder-cv : Also for my reference would you be able to share your model Graphdef file(pbtxt)?\r\n> \r\n> Ok I recompiled with some changes, allocate tensors cleared. But I have a new problem now interpreter.invoke() causes core dumped and exits shell\r\n\r\n@reorder-cv : Would you please share more details, so that i can debug. Also i press on sharing the changes you did to clear the allocate tensor failures, it is a learning for everyone in the community, if you share here. Thanks!", "Unfortunately, I'm unsure what is happening. Given that it's a little difficult to debug on my end without a model, can you try a few things and provide as detailed output as possible:\r\n\r\n1. Try converting the model with the latest 2.0 nightly. There have been some fixes in the `compat.v1` pipeline so there might be a relevant one here.\r\n2. Try converting the model without `allow_custom_ops=True`. It is possible this flag is suppressing an unrelated ops error.\r\n3. Optionally, if possible, try running this conversion code (with and without the `allow_custom_ops=True`) against the 1.X nightly just to confirm the same errors are occurring. This will confirm it's not an issue with 2.0 specifically but an issue converting this model more generally.\r\n\r\nAdditionally, when was this model generated? There have been some changes to the code to freeze models in the last week or two to adapt to some underlying changes - so if it's a newer model can you try and freeze it again.", "@reorder-cv : I think 2 of your issues reported here is addressed successfully. If the thread continues it may be difficult for other community user to analyze. So i suggest you close this issue, as your original post is addressed here. And open a new issue thread with all details as asked by @gargn . Also it is true as mentioned by @gargn , it is very difficult to debug, without a model or pseudo code to reproduce the issue, unless its a pretty straight forward error. Please try to work on that as well, Thanks!\r\nPlease feel free to post your end remarks, Thanks!", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken. Please open a new issue if there are any unresolved issues. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27279\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27279\">No</a>\n", "I was having the exact same issue for a keras yolo model . I changed my gradle dependency to     implementation 'org.tensorflow:tensorflow-android:1.13.1'\r\nand I also froze the graph in tensorflow version 1.13.1 . Also keras verion was 2.3.1.\r\n\r\nHope these configurations work out for you as well", "@kartikwar which yolo version were you using? I'm having a similar issue with yolov5"]}, {"number": 27278, "title": "Error occur while converting graphdef to .tflite. ConverterError: TOCO failed. See console for info.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version (or github SHA if from source): 1.13\r\n\r\nI am try to convert the graphDef model to tflite using tf.lite.TFLiteConverter.from_frozen_graph()\r\nchecked every steps as mentioned in the document. And also tried to check with the code available [here.](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python)\r\n\r\n```\r\n`ConverterError                            Traceback (most recent call last)\r\n<ipython-input-60-6e749ab72451> in <module>\r\n      9 converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shape)\r\n     10 #converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]\r\n---> 11 tflite_model = converter.convert()\r\n     12 open(\"E:/training_models/tensorflow_face_detection/model/detect_face.tflite\", \"wb\").write(tflite_model)\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    453           input_tensors=self._input_tensors,\r\n    454           output_tensors=self._output_tensors,\r\n--> 455           **converter_kwargs)\r\n    456     else:\r\n    457       result = _toco_convert_graph_def(\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)\r\n    440   data = toco_convert_protos(model_flags.SerializeToString(),\r\n    441                              toco_flags.SerializeToString(),\r\n--> 442                              input_data.SerializeToString())\r\n    443   return data\r\n    444 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)\r\n    203       stderr = _try_convert_to_unicode(stderr)\r\n    204       raise ConverterError(\r\n--> 205           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    206   finally:\r\n    207     # Must manually cleanup files.`\r\n```\r\n\r\nPlease check the GraphDef model [here](https://github.com/jyotirmayghosh/tensorflow-face-detection).\r\n\r\nBelow is the detail ConverterError Log:\r\n`ConverterError: TOCO failed. See console for info.\r\n2019-03-29 15:04:07.619011: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.619546: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\r\n2019-03-29 15:04:07.619822: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\r\n2019-03-29 15:04:07.620164: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\r\n2019-03-29 15:04:07.620413: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\r\n2019-03-29 15:04:07.620818: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.621030: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayScatterV3\r\n2019-03-29 15:04:07.621242: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayScatterV3\r\n2019-03-29 15:04:07.621439: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.621643: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.621821: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.621980: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.622124: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.622431: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.622693: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.622951: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.623237: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: LoopCond\r\n2019-03-29 15:04:07.623506: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: LoopCond\r\n2019-03-29 15:04:07.623810: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.624086: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.624364: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.624635: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.624921: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayReadV3\r\n2019-03-29 15:04:07.625226: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayReadV3\r\n2019-03-29 15:04:07.625557: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.625834: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.626113: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\r\n2019-03-29 15:04:07.626416: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayWriteV3\r\n2019-03-29 15:04:07.626709: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\r\n2019-03-29 15:04:07.626974: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Exit\r\n2019-03-29 15:04:07.627246: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\r\n2019-03-29 15:04:07.627534: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArraySizeV3\r\n2019-03-29 15:04:07.627767: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\r\n2019-03-29 15:04:07.628010: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayGatherV3\r\n2019-03-29 15:04:07.655854: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.656194: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.656419: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.656584: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.656792: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.657003: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.657222: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayScatterV3\r\n2019-03-29 15:04:07.657419: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayScatterV3\r\n2019-03-29 15:04:07.657637: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayScatterV3\r\n2019-03-29 15:04:07.657834: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayScatterV3\r\n2019-03-29 15:04:07.658037: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayScatterV3\r\n2019-03-29 15:04:07.658200: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayScatterV3\r\n2019-03-29 15:04:07.658401: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.658657: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.658953: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.659242: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.659429: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.659616: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.659818: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-03-29 15:04:07.660003: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-03-29 15:04:07.660208: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.660408: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.660574: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.660748: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.660924: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.661116: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.661290: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.661484: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.661666: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.661830: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.662024: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.662207: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.662376: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: LoopCond\r\n2019-03-29 15:04:07.662560: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: LoopCond\r\n2019-03-29 15:04:07.662757: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.662926: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.663089: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.663260: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.663444: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayReadV3\r\n2019-03-29 15:04:07.663614: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayReadV3\r\n2019-03-29 15:04:07.663804: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.664024: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.664298: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.664561: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.664845: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayReadV3\r\n2019-03-29 15:04:07.665148: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayReadV3\r\n2019-03-29 15:04:07.665444: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.665711: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.665988: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.666254: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.666525: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayReadV3\r\n2019-03-29 15:04:07.666812: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayReadV3\r\n2019-03-29 15:04:07.667245: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-03-29 15:04:07.667517: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-03-29 15:04:07.667823: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.668095: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.668382: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-03-29 15:04:07.668655: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-03-29 15:04:07.668981: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppression\r\n2019-03-29 15:04:07.669255: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppression\r\n2019-03-29 15:04:07.669547: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-03-29 15:04:07.669712: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-03-29 15:04:07.669987: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-03-29 15:04:07.670221: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-03-29 15:04:07.670478: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppression\r\n2019-03-29 15:04:07.670756: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppression\r\n2019-03-29 15:04:07.671031: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Size\r\n2019-03-29 15:04:07.671248: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Size\r\n2019-03-29 15:04:07.672109: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.672288: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.672471: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\r\n2019-03-29 15:04:07.672678: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayWriteV3\r\n2019-03-29 15:04:07.672832: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.673133: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.673332: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\r\n2019-03-29 15:04:07.673552: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayWriteV3\r\n2019-03-29 15:04:07.673795: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.673988: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.674160: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\r\n2019-03-29 15:04:07.674376: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayWriteV3\r\n2019-03-29 15:04:07.674649: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-03-29 15:04:07.674840: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-03-29 15:04:07.675038: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\r\n2019-03-29 15:04:07.675345: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayWriteV3\r\n2019-03-29 15:04:07.675728: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\r\n2019-03-29 15:04:07.676027: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Exit\r\n2019-03-29 15:04:07.676381: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\r\n2019-03-29 15:04:07.676575: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Exit\r\n2019-03-29 15:04:07.676756: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\r\n2019-03-29 15:04:07.676946: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Exit\r\n2019-03-29 15:04:07.677100: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\r\n2019-03-29 15:04:07.677284: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Exit\r\n2019-03-29 15:04:07.677453: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\r\n2019-03-29 15:04:07.677657: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArraySizeV3\r\n2019-03-29 15:04:07.677871: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\r\n2019-03-29 15:04:07.678061: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayGatherV3\r\n2019-03-29 15:04:07.678274: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\r\n2019-03-29 15:04:07.678468: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArraySizeV3\r\n2019-03-29 15:04:07.678671: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\r\n2019-03-29 15:04:07.678837: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayGatherV3\r\n2019-03-29 15:04:07.679068: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\r\n2019-03-29 15:04:07.679302: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArraySizeV3\r\n2019-03-29 15:04:07.679614: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\r\n2019-03-29 15:04:07.679907: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayGatherV3\r\n2019-03-29 15:04:07.680209: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\r\n2019-03-29 15:04:07.680499: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArraySizeV3\r\n2019-03-29 15:04:07.680816: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\r\n2019-03-29 15:04:07.681064: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayGatherV3\r\n2019-03-29 15:04:07.757845: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1461 operators, 2604 arrays (0 quantized)\r\n2019-03-29 15:04:07.881035: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1402 operators, 2490 arrays (0 quantized)\r\n2019-03-29 15:04:08.033914: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1402 operators, 2490 arrays (0 quantized)\r\n2019-03-29 15:04:08.127816: F tensorflow/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size >= 1 (0 vs. 1)\r\n`\r\n\r\nI tried to check very things but not getting the error. Can anyone please check.\r\n", "comments": ["Instated of training the model with model_main.py, if I train it with export_tflite_ssd_graph.py.\r\nAs in the document it mentioned \r\n> Exports an SSD detection model to use with tf-lite.\r\n\r\n> Outputs file:\r\n> A tflite compatible frozen graph - $output_directory/tflite_graph.pb\r\n\r\nI am trying to train on **ssdlite_mobilenet_v2** model", "Could you print out what parameters you pass in this line:\r\n`converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shape)`", "> Could you print out what parameters you pass in this line:\r\n> `converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shape)`\r\n\r\n```\r\ngraph_def_file = \"E:/training_models/tensorflow_face_detection/model/frozen_inference_graph_face.pb\"\r\ninput_arrays = [\"image_tensor\"]\r\noutput_arrays = [\"detection_boxes\",\"detection_scores\",\"detection_classes\",\"num_detections\"]\r\ninput_shape = {\"image_tensor\" : [1, 300, 300, 3]}\r\n```", "I didn't see any errors in those arguments provided to TOCO. Could you share the model with us so we can debug with it (assuming it's not confidential) ?", "Hi, \r\nI am facing the same issue with the retrained model ssd_resnet_50_fpn. \r\nYou can replicate the issue by using the model file (frozen_inference_graph.pb) file here: http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\r\nAlthough, with this model I am getting a new error : \r\nCheck failed: other_op->type == OperatorType::kMerge Found Sub as non-selected output from Switch, but only Merge supported. \r\n\r\nAny help is appreciated. \r\nThanks in advance. ", "Dear @jyotirmayghosh @haozha111 , I have almost the same issue with @skulhare that tflite do not support Merge and Switch, details can be in  [#27241](https://github.com/tensorflow/tensorflow/issues/27241).\r\n\r\nWill the control flow operations be implemented recently? Could you give me some advice?\r\n\r\nThank you very much.", "Hi @WilliamL1 & @skulhare\r\n\r\nThe new error is due to missing control flow ops in tflite, which is different from the issue in the original post.\r\n\r\nControl flow ops will be added to TF Lite soon. Details could be found in RFC here:\r\nhttps://github.com/tensorflow/community/pull/83", "@haozha111 \r\nExtremely grateful.", "I believe I have this same issue, trying to convert multires.pb from this zip file: https://github.com/DIUx-xView/baseline/releases/download/v1.1/models_release_v1-1.zip\r\n\r\nI (independently and before I found this page) used the same parameters command as jyotirmayghosh to convert the model. The output is very similar:\r\n\r\n`tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-04-09 11:25:21.211644: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-04-09 11:25:21.212823: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\r\n2019-04-09 11:25:21.213907: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\r\n2019-04-09 11:25:21.215348: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\r\n2019-04-09 11:25:21.216672: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\r\n2019-04-09 11:25:21.218438: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-04-09 11:25:21.219391: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayScatterV3\r\n2019-04-09 11:25:21.220345: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayScatterV3\r\n2019-04-09 11:25:21.221271: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayV3\r\n2019-04-09 11:25:21.222198: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayV3\r\n2019-04-09 11:25:21.223127: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-04-09 11:25:21.223980: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-04-09 11:25:21.224879: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-04-09 11:25:21.225467: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-04-09 11:25:21.226541: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-04-09 11:25:21.227182: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-04-09 11:25:21.227740: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: LoopCond\r\n2019-04-09 11:25:21.227939: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: LoopCond\r\n2019-04-09 11:25:21.228170: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-04-09 11:25:21.228364: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-04-09 11:25:21.229870: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-04-09 11:25:21.230800: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-04-09 11:25:21.231710: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayReadV3\r\n2019-04-09 11:25:21.232506: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayReadV3\r\n2019-04-09 11:25:21.233316: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Enter\r\n2019-04-09 11:25:21.233993: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Enter\r\n2019-04-09 11:25:21.234658: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayWriteV3\r\n2019-04-09 11:25:21.235873: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayWriteV3\r\n2019-04-09 11:25:21.236603: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Exit\r\n2019-04-09 11:25:21.237245: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Exit\r\n2019-04-09 11:25:21.237910: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArraySizeV3\r\n2019-04-09 11:25:21.238706: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArraySizeV3\r\n2019-04-09 11:25:21.239583: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TensorArrayGatherV3\r\n2019-04-09 11:25:21.240268: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: TensorArrayGatherV3\r\n2019-04-09 11:25:21.413253: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.413635: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.414040: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.414392: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.414844: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.415333: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.415903: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.416343: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.416856: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.417076: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.417328: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.417545: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.418560: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.419000: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.419540: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.419975: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.420455: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.420946: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.421502: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.421933: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.422473: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.422909: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.423406: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.424039: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.424610: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.425042: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.425511: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.425948: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.426451: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.426918: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.427464: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.427905: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.428440: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.428660: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.429236: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.429724: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.430272: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.430751: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.431294: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.431715: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.432222: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.432675: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.433109: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.433577: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.434113: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.434548: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.435051: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.435548: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.436082: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.436460: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.437004: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.437442: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.437958: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.438439: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.438882: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.439321: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.439965: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.440405: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.440914: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.441286: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.441840: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.442277: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.442815: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.443252: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.443754: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.444204: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.444731: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.445166: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.445704: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.446144: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.446660: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.446997: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.447404: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.447818: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.448558: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.449096: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.449775: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.450511: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.451249: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.451757: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.452467: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.453003: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.453760: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.454426: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.455428: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.456209: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.456931: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.457482: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.458262: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.458895: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.459605: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.460233: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.461015: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.461732: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.462791: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.463429: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.464411: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.464966: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.465962: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.466526: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.467472: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.468101: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.468816: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.469369: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.470258: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.470825: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.471507: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.472094: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.473103: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.473648: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.474627: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.475201: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.476109: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.476992: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.477724: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.478170: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.478887: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.479471: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.480173: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.481059: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.482070: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.482625: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.483527: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.484107: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.484782: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.485429: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.486163: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.486731: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.487703: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.488235: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.488902: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.489776: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.490496: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.491276: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.492299: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.492878: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.493890: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.494521: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.495380: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.495948: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.496668: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.497243: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.498178: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.498792: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.499804: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.500362: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.501116: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.501686: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.502623: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.503239: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.503979: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.504664: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.505397: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.505926: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.506853: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.507476: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.508190: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.509005: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.509499: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.509761: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.510129: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.510449: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.510844: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.511151: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.511620: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.511939: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.512183: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.512541: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.512885: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.513190: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.513560: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.513822: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.514195: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.514527: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.514897: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.515168: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.515554: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.515899: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.516237: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.516566: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.516951: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.517220: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.517589: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.517851: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.518210: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.518541: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.518883: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.519181: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.519570: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.519871: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.520211: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.520557: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.520941: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.521201: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.521592: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.521849: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.522163: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.522465: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.522888: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.523182: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.523724: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.524026: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.524392: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.524727: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.525170: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.525479: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.525841: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.526124: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.526491: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.526827: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.527209: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.527450: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.527719: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.528100: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.528472: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.528795: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.529229: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.529509: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.529923: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.530263: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.530624: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.530895: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.531157: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.531563: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.531946: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.532226: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.532480: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.532854: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.533260: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.533478: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.533869: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.534167: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.534494: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.534823: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.535207: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.535495: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.535873: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.536151: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.536560: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.536897: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.537265: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.537574: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.537967: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.538243: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.538575: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.538918: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.539322: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.539611: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.540140: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.540790: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.541394: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.541972: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.542608: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.543112: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.543738: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.544247: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.544839: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.545388: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.546023: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.546521: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.547142: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.547662: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.548257: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.548823: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.549448: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.549939: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.550575: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.551083: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.551673: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.552255: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.552896: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.553407: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.554037: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.554548: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.555155: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.555791: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.556449: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.556952: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.557588: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.558109: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.558709: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.559274: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.559918: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.560411: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.561051: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.561566: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.562159: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.562713: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.563371: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.563873: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.564521: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.565032: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.565630: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.566195: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.566843: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.567341: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.567983: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.568490: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.569083: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.569650: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.570314: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.570822: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.571572: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.572024: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.572690: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.573292: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.574013: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.574576: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.575542: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.576138: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.576750: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.577326: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.578050: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.578633: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.579393: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.579927: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.580543: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.581136: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.581868: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.582439: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.583146: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.583714: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.584403: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.585072: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.585821: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.586396: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.587175: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.587730: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.588367: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.588947: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.589666: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.590232: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.590948: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.591446: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.592205: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.592829: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.593708: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.594285: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.594962: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.595491: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.596152: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.596754: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.597512: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.598101: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.598749: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.599293: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.599950: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.600577: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.601343: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.601913: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.603139: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.603545: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.603992: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.604383: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.604842: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.605178: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.605518: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.605844: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.606272: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.606637: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.607078: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.607397: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.608044: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.608604: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.609306: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.609994: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.610730: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.611285: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.611995: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.612551: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.613230: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.613883: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.614604: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.615177: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.615872: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.616417: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.617088: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.617700: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.618484: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.619017: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.619730: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.620292: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.620955: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.621630: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.622349: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.622882: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.623584: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.624147: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.624861: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.625522: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.626223: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.626812: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.627524: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.628104: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.628810: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.629449: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.630166: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.630735: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.631461: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.632017: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.632690: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.633314: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.634148: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.634353: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.634754: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.634977: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.635353: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.635626: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.636020: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.636285: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.636558: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.636831: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.637438: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.637722: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.638093: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.638407: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.638922: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.639240: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.639651: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.639949: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.640312: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.640604: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.641002: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.641256: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.641627: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.641842: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.642200: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.642540: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.642942: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.643157: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.643398: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.643809: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.644124: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.644372: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.644816: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.645093: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.645472: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.645808: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.646196: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.646695: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.647149: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.647447: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.647912: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.648236: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.648503: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.648986: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.649440: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.649832: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.650200: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.650550: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.650920: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.651200: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.651621: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.651863: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.652211: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.652521: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.652933: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.653177: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.653554: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.653841: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.654255: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.654594: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.654966: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.655260: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.655657: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.655921: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.656511: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.656869: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.657262: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.657573: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.657942: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.658250: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.658677: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.659279: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.659691: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.659990: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.660378: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.660696: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.661016: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.661257: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.661636: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.661929: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.662320: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.662613: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.663022: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.663347: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.663688: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.663988: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.664370: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.664644: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.665050: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.665421: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.665772: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.666062: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.666448: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.666731: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.667098: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.667423: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.667796: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.668086: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.668442: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.668724: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.668974: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.669364: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.669732: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.669921: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.670344: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.670630: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.670977: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.671323: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.671691: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.671975: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.672351: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.672594: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.672968: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.673303: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.673684: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.673887: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.674323: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.674632: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.674998: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.675318: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.675739: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.676036: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.676542: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.676822: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.677187: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.677544: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.677936: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.678219: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.678632: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.678926: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.679282: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.679610: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.679925: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.680236: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.680639: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.680949: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.681326: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.681666: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.682060: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.682342: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.682699: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.683008: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.683389: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.683714: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.684112: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.684418: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.684838: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.685161: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.685676: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.685968: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.686373: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.686680: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.687098: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.687399: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.687756: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.688106: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.688505: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.688794: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.689168: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.689570: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.690084: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.690401: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.690717: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.691010: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.691409: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Where\r\n2019-04-09 11:25:21.691664: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Where\r\n2019-04-09 11:25:21.691909: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.692292: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: NonMaxSuppressionV2\r\n2019-04-09 11:25:21.692903: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Size\r\n2019-04-09 11:25:21.693212: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: Size\r\n2019-04-09 11:25:23.503175: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 5468 operators, 9072 arrays (0 quantized)\r\n2019-04-09 11:25:24.917934: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 5418 operators, 8958 arrays (0 quantized)\r\n2019-04-09 11:25:27.236038: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 5418 operators, 8958 arrays (0 quantized)\r\n2019-04-09 11:25:28.037189: F tensorflow/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size >= 1 (0 vs. 1)`", "> I didn't see any errors in those arguments provided to TOCO. Could you share the model with us so we can debug with it (assuming it's not confidential) ?\r\n\r\nHey,\r\nyou can find the model [here](https://github.com/yeephycho/tensorflow-face-detection)\r\nwe are just trying to convert this pre-trained model to tflite. ", "There are lots of control flow ops in the model, such as 'Enter', 'Exit', which are not supported by TF Lite at the moment. Sorry about that.", "> \r\n> \r\n> There are lots of control flow ops in the model, such as 'Enter', 'Exit', which are not supported by TF Lite at the moment. Sorry about that.\r\n\r\nIs there an option to quantize a model from TensorFlow that would avoid this issue?", "Please use [export_tflite_ssd_graph](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py) function to export the frozen graph and convert to tflite please. \r\nSample was in this [blog post](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193)", "@achowdhery\r\n\r\nEarlier I tried to traind the model with export_tflite_ssd_graph.py instead of model_main.py. but still I got few errors, I will share with you soon.", "> Please use [export_tflite_ssd_graph](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py) function to export the frozen graph and convert to tflite please.\r\n> Sample was in this [blog post](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193)\r\n\r\nHello, \r\nSorry for being reply late.\r\nAs you said i tried with /object_detection/export_tflite_ssd_graph.py to export the frozen graph. \r\n\r\n`python3 object_detection/export_tflite_ssd_graph.py     --pipeline_config_path=/home/user/Documents/training/pipeline.config     --trained_checkpoint_prefix /home/user/Documents/training/models/ssdlite_mobilenet_v2_coco/model.ckpt     --output_directory /home/user/Documents/training/tflite/     --add_postprocessing_op=true`\r\n\r\nAnd this successfully export to detect.pb and detect.pbtxt.\r\n\r\nBut when i am trying to convert this frozen graph to detect.tflite, I met with this following error\r\n\r\n`TOCO failed. See console for info.\r\n2019-04-17 16:25:40.628140: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TFLite_Detection_PostProcess\r\n2019-04-17 16:25:40.652921: F tensorflow/lite/toco/tooling_util.cc:897] Check failed: GetOpWithInput(model, input_array.name()) Specified input array \"image_tensor\" is not consumed by any op in this graph. Is it a typo? To silence this message, pass this flag:  allow_nonexistent_arrays\r\nAborted (core dumped)`\r\n\r\nCan you please help me?\r\n\r\nThanks in adv", "@jyotirmayghosh I also have the same issue. Have you found the solution to that?", "> > Please use [export_tflite_ssd_graph](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py) function to export the frozen graph and convert to tflite please.\r\n> > Sample was in this [blog post](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193)\r\n> \r\n> Hello,\r\n> Sorry for being reply late.\r\n> As you said i tried with /object_detection/export_tflite_ssd_graph.py to export the frozen graph.\r\n> \r\n> `python3 object_detection/export_tflite_ssd_graph.py --pipeline_config_path=/home/user/Documents/training/pipeline.config --trained_checkpoint_prefix /home/user/Documents/training/models/ssdlite_mobilenet_v2_coco/model.ckpt --output_directory /home/user/Documents/training/tflite/ --add_postprocessing_op=true`\r\n> \r\n> And this successfully export to detect.pb and detect.pbtxt.\r\n> \r\n> But when i am trying to convert this frozen graph to detect.tflite, I met with this following error\r\n> \r\n> `TOCO failed. See console for info. 2019-04-17 16:25:40.628140: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TFLite_Detection_PostProcess 2019-04-17 16:25:40.652921: F tensorflow/lite/toco/tooling_util.cc:897] Check failed: GetOpWithInput(model, input_array.name()) Specified input array \"image_tensor\" is not consumed by any op in this graph. Is it a typo? To silence this message, pass this flag: allow_nonexistent_arrays Aborted (core dumped)`\r\n> \r\n> Can you please help me?\r\n> \r\n> Thanks in adv\r\n\r\nHie...\r\nHow did you solve this error ?", "> > Please use [export_tflite_ssd_graph](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py) function to export the frozen graph and convert to tflite please.\r\n> > Sample was in this [blog post](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193)\r\n> \r\n> Hello,\r\n> Sorry for being reply late.\r\n> As you said i tried with /object_detection/export_tflite_ssd_graph.py to export the frozen graph.\r\n> \r\n> `python3 object_detection/export_tflite_ssd_graph.py --pipeline_config_path=/home/user/Documents/training/pipeline.config --trained_checkpoint_prefix /home/user/Documents/training/models/ssdlite_mobilenet_v2_coco/model.ckpt --output_directory /home/user/Documents/training/tflite/ --add_postprocessing_op=true`\r\n> \r\n> And this successfully export to detect.pb and detect.pbtxt.\r\n> \r\n> But when i am trying to convert this frozen graph to detect.tflite, I met with this following error\r\n> \r\n> `TOCO failed. See console for info. 2019-04-17 16:25:40.628140: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TFLite_Detection_PostProcess 2019-04-17 16:25:40.652921: F tensorflow/lite/toco/tooling_util.cc:897] Check failed: GetOpWithInput(model, input_array.name()) Specified input array \"image_tensor\" is not consumed by any op in this graph. Is it a typo? To silence this message, pass this flag: allow_nonexistent_arrays Aborted (core dumped)`\r\n> \r\n> Can you please help me?\r\n> \r\n> Thanks in adv\r\n\r\nSame issue, trying to convert a retinanet model to tflite. tf version: 1.13.1", "After converting my frozen graph to tflite_graph.pb using tensorflow's object_detection/export_tflite_ssd_graph.py, I had success changing \"image_tensor\" to \"normalized_input_image_tensor\". \r\n\r\nadd tensorflow object detection folder to python path using \r\n```\r\nexport PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\r\n```\r\n \r\ncommand for converting frozen graph:\r\n```\r\npython object_detection/export_tflite_ssd_graph.py --input_type image_tensor --pipeline_config_path pipeline.config --trained_checkpoint_prefix model.ckpt --output_directory ./output/\r\n```\r\n\r\ncommand for converting tflite pb to .tflite:\r\n```\r\ntflite_convert --output_file=model.tflite --graph_def_file=output/tflite_graph.pb --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess --input_shapes=1,640,640,3 --allow_custom_ops\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27278\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27278\">No</a>\n", "> Hi @WilliamL1 & @skulhare\r\n> \r\n> The new error is due to missing control flow ops in tflite, which is different from the issue in the original post.\r\n> \r\n> Control flow ops will be added to TF Lite soon. Details could be found in RFC here:\r\n> [tensorflow/community#83](https://github.com/tensorflow/community/pull/83)\r\n\r\nThen when will control flow ops be add in tflite \uff1f I tried tf1.15\uff0cit seems still the same. If it will be add in tf 2.x, another problem is `TFLiteConverter` does not supprt `from_frozen_graph`, isn't ?", "@wwdok You can use it in TF2.x as `tf.compat.v1.lite.TFLiteConverter.from_frozen_graph`. If you notice any bugs, please create a new issue with a standalone code to reproduce the issue. Thanks!"]}, {"number": 27277, "title": "Added Test cases for missing scenarios.", "body": "Completed the TODO mentioned in the file.", "comments": ["@jdduke , thanks for the review, i have updated the code as per your suggestion, kindly check and approve.\r\n\r\nRegards\r\nAmit"]}, {"number": 27276, "title": "Crash when opening .npz file with tf.gfile.GFile on Python 3.7 ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): v1.13.0-rc2-5-g6612da8 / 1.13.1\r\n- Python version: Python 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1 / 7.5.0\r\n- GPU model and memory: GTX 1080 / 8G\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nA code below works well on Python 3.6 with TF 1.12. On Python 3.7 with TF 1.13, however, the code crashes. \r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nDo not crash.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```Python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ninformation = { \"a\": 1, \"b\": 2 }\r\nnp.savez_compressed(\"a.npz\", **information)\r\n\r\nwith tf.gfile.Open(\"a.npz\", \"rb\") as file_:\r\n  info = np.load(file_)\r\n\r\ninfo_dict = { key: info[key] for key in info.items() }  # crash on Python 3.7 with TF 1.13.1\r\n```\r\n\r\nTraceback \r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"<stdin>\", line 1, in <dictcomp>\r\n  File \"/csehome/youhanmir/.virtualenvs/learning-implicit-action/lib/python3.7/_collections_abc.py\", line 744, in __iter__\r\n    yield (key, self._mapping[key])\r\n  File \"/csehome/youhanmir/.virtualenvs/learning-implicit-action/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 251, in __getitem__\r\n    bytes = self.zip.open(key)\r\n  File \"/usr/lib64/python3.7/zipfile.py\", line 1480, in open\r\n    self._fpclose, self._lock, lambda: self._writing)\r\n  File \"/usr/lib64/python3.7/zipfile.py\", line 722, in __init__\r\n    self.seekable = file.seekable\r\nAttributeError: 'GFile' object has no attribute 'seekable'\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Added a PR #27301 for the fix.", "As I wrote comments on https://github.com/tensorflow/tensorflow/pull/27301#discussion_r275780277, this issue should be opened again. \r\n@ymodak, Could you re-open this issue? ", "Reopened and add a follow up PR #28006 to fix the issue."]}, {"number": 27275, "title": "The training value of tf.keras.Model.call() becomes None when tf.keras.Model.fit(). (tf2.0.0-alpha0)", "body": "I read the [document](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#__call__) and implemented a model with `tf.keras.Model` as a subclass, but the value of training argument becomes `None`.\r\n\r\nIs this a bug? Or is my understanding wrong? This is a basic question, but please let me know.\r\n\r\nHere is the simplified code.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tfk\r\n\r\n\r\nclass MyLayer(tfk.layers.Layer):\r\n    def __init__(self):\r\n        super(MyLayer, self).__init__()\r\n\r\n    def call(self, inputs, training=None):\r\n        # got: Tensor(\"keras_learning_phase:0\", shape=(), dtype=bool)\r\n        print(\"layer training arg: \", training)\r\n        \r\n        return inputs\r\n\r\n\r\nclass MyModel(tfk.Model):\r\n    def __init__(self):\r\n        super(MyModel, self).__init__()\r\n        self.l1 = MyLayer()\r\n\r\n    def call(self, inputs, training=None):\r\n        # want: Tensor(\"keras_learning_phase:0\", shape=(), dtype=bool)  got: None\r\n        print(\"model training arg: \", training)\r\n        \r\n        inputs = self.l1(inputs)\r\n        return inputs\r\n\r\n\r\nif __name__ == '__main__':\r\n    x = np.zeros((1, 2))\r\n    model = MyModel()\r\n    model.compile(loss=\"mse\", optimizer=\"sgd\")\r\n    model.fit(x, x, epochs=1)\r\n\r\n```\r\n\r\n\r\n\r\n**System information**\r\n\r\n- macOS Mojave 10.14.3\r\n- TensorFlow installed from : pip\r\n- TensorFlow version: 2.0.0a0\r\n- Python version: 3.5.6 (using pyenv)", "comments": [":+1: I noticed the same bug and I'm also interested in the solution.\r\n\r\nI use Ubuntu 16.04.1, Python 3.7 in Anaconda, Tensorflow installed from pip:\r\n```\r\n>>> print(tf.__version__)\r\n2.0.0-alpha0\r\n>>> print(tf.keras.__version__)\r\n2.2.4-tf\r\n```\r\n\r\n", "Thanks for the bug! Was able to repro, will update when a fix is available", "A fix should now be available in the latest nightly :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27275\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27275\">No</a>\n"]}]