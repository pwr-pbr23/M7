[{"number": 5995, "title": "GPU MUCH slower than CPU", "body": "GPU training is MUCH slower than CPU training. It's possible I'm doing something wrong. If I'm not I can gather more data on this. The data set is pretty small and it slows to a crawl. GPU usage is around 2-5%, It fills up the memory in the GPU pretty quickly to 90% but the PCIe Bandwidth Utilization is 1%. My CPU and Memory usage are otherwise minimal.\r\n\r\nMy setup: 32gb ram, 8 core 4.3 Ghz processor, (2) GTX 660's, 367.57 Nvidia Driver, Cuda Toolkit 7.5, cudnn 7.5, Python 2.7. Tensorflow matches 7.5.\r\n\r\nI can take exact time measurements later if needed but I would guess GPU is about 10x slower if not more than the CPU training.\r\n\r\n```\r\npprint.pprint(len(X))\r\npprint.pprint(len(Y))\r\n\r\nnet = tflearn.input_data(shape=[None, 7])\r\nnet = tflearn.fully_connected(net, 32)\r\nnet = tflearn.fully_connected(net, 32)\r\nnet = tflearn.fully_connected(net, 2, activation='softmax')\r\nnet = tflearn.regression(net)\r\n\r\nmodel = tflearn.DNN(net)\r\nmodel.fit(X, Y, n_epoch=100, batch_size=16, show_metric=True)\r\n\r\nmodel.save(\"model.tfl\")\r\n```\r\n\r\n```\r\ncamj256@camj256:~/PycharmProjects/DeepLearning$ python build.py \r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\r\nExceptions: 0\r\n3003\r\n3003\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \r\nname: GeForce GTX 660\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 1.0975\r\npciBusID 0000:02:00.0\r\nTotal memory: 1.99GiB\r\nFree memory: 1.27GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x2af5d00\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \r\nname: GeForce GTX 660\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 1.0975\r\npciBusID 0000:01:00.0\r\nTotal memory: 1.99GiB\r\nFree memory: 1.24GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 660, pci bus id: 0000:02:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 660, pci bus id: 0000:01:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 660, pci bus id: 0000:02:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 660, pci bus id: 0000:01:00.0)\r\n---------------------------------\r\nRun id: 17E6I9\r\nLog directory: /tmp/tflearn_logs/\r\n---------------------------------\r\nTraining samples: 3003\r\nValidation samples: 0\r\n```\r\n\r\n\r\n", "comments": ["Have you tried using timeline to find out where the time is going?\r\n\r\nhttp://stackoverflow.com/questions/34293714/tensorflow-can-i-measure-the-execution-time-of-individual-operations/37774470#37774470\r\n\r\n", "This can be closed pretty soon if nothing jumps out at anyone. I screwed up my linux install late last night messing with drivers. Once I have time to fix my linux install and dig into this I can re-open.\r\n\r\nI'm wondering if the batch size was too small and it was bottle necking somewhere? ", "@camj256,\r\n\r\nI have similar issues I still have not got to the bottom of with an RL model.  It seems like TensorFlow maybe optimized for larger datasets, but my understanding is other deep learning tools might handle the smaller datasets more efficiently.  I would rather stay with TensorFlow if I can so it would be nice if some optimization can be done on smaller datasets to get close to the performance of the other tools.  There is an open item #2444 which also has documented the same issue.  I have a StackOverflow posting as well to see if it is just a matter of optimization.\r\nhttp://stackoverflow.com/questions/38688777/tensorflow-graph-optimization-gpu-vs-cpu-performance\r\n\r\nHopefully we can move TensorFlow in the director of some optimization for the smaller dataset sizes.", "My actual data set is 200k. Same result there too.", "The basic question here is whether your poor performance is due to a slow GPU kernel, to inefficiencies in moving data back and forth between CPU and GPU, or something else.   If you could use timeline and other profiling tools to track this down on your side, it would be helpful.   When data sizes are tiny, GPUs provide no advantage over CPUs.  However, if another DNN framework can run this same model on GPU much faster, that's a performance problem we'd like to address.", "I'm gonna close this for now then. I won't be able to look into that for another week or so. Too busy with work.", "I got my linux install fixed and am looking into this right now. Hopefully someone can answer a few rookie questions that are getting in the way of my understanding of this.\r\n\r\nI've noticed that I can just up the batch size to 100k and process a lot quicker than CPU but I'm curious if the batch size has any affect on how the DNN learns? Also, I've noticed if I change the size of the NN to be much larger (512 instead of 32) the accuracy gets stuck at one spot. The GPU usage does go up to about 50% when doing that which leads me to believe there is an IO bottleneck somewhere. Lastly, how many epochs should I run? I've run 10k epochs on this data set in about an hour (with batchsize of 100k) and it seems to bounce around between 60 and 82% acc. \r\n\r\nI'm going to run the timeline thing later tonight. For now, if someone could answer those it would really help my understanding of what I'm trying to do. Also, the docs on the tensorflow seem to assume I already know what everything does. I've not had much luck finding a place that explains that.", "There's no simple answer to these questions.  But there should be many papers and blog posts about the general topics of SGD training and hyperparameter tuning.\r\n\r\nIf you're really a beginner, you should try playing with http://playground.tensorflow.org/\r\n", "Well, I went and bought a gtx 1080 tonight. It was time to upgrade. Turns out this most likely is a bug as my 1080 hauls absolute ass with the exact same code and setup (even same drivers) \r\n\r\nAs for what it was I will never know. Probably just CUDA the 660's being an older version of CUDA?"]}, {"number": 5994, "title": "build failure", "body": "Attempting to install master on a SLES11sp3 system under\r\ngcc-4.9.3\r\nPython 3.5.1\r\nbazel-0.4.1\r\n\r\nTensorFlow hash is\r\ngit rev-parse HEAD\r\na70a2d9f0e7d34e36018e83e4b17c45a26a2f3dc\r\n\r\nSeems similar to\r\nhttps://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/Tm5ztabIUCw\r\n\r\n./configure\r\n~/play/TensorFlow/tensorflow ~/play/TensorFlow/tensorflow\r\nPlease specify the location of python. [Default is /usr/bin/python]: /nasa/pkgsrc/2016Q2/bin/python3.5\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] N\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] N\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /nasa/pkgsrc/2016Q2/lib/python3.5/site-packages\r\nPlease input the desired Python library path to use.  Default is [/nasa/pkgsrc/2016Q2/lib/python3.5/site-packages]\r\n\r\nUsing python library path: /nasa/pkgsrc/2016Q2/lib/python3.5/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] N\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /nasa/pkgsrc/2015Q4/gcc49/bin/gcc]: \r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5\r\nPlease specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /nasa/cuda/7.5\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /nasa/cuda/7.5]: /u/dkokron/play/cuDNN/cuda\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 3.5\r\n..........\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n..........\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n\r\n\r\nbazel --output_base=/tmp/dkokron build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nINFO: Found 1 target...\r\nERROR: /home6/dkokron/play/TensorFlow/tensorflow/tensorflow/core/BUILD:1121:1: Executing genrule //tensorflow/core:version_info_gen failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nTraceback (most recent call last):\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 260, in <module>\r\n    generate(args.generate)\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 212, in generate\r\n    git_version = get_git_version(data[\"path\"])\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 150, in get_git_version\r\n    val = bytes(subprocess.check_output([\r\nAttributeError: 'module' object has no attribute 'check_output'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2.236s, Critical Path: 1.79s\r\n\r\nll /nasa/cuda/7.5/lib64/libcu*\r\nlrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas.so -> libcublas.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas.so.7.5 -> libcublas.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff  23938736 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff  28585480 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas_device.a\r\n-rw-r--r-- 1 hsp cstaff  28220076 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas_static.a\r\n-rw-r--r-- 1 hsp cstaff    322936 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart.so -> libcudart.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff    383336 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff    720192 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 hsp cstaff        15 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft.so -> libcufft.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        18 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft.so.7.5 -> libcufft.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff 111231960 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff 115104400 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft_static.a\r\nlrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw.so -> libcufftw.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw.so.7.5 -> libcufftw.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff    447664 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff     42206 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw_static.a\r\nlrwxrwxrwx 1 hsp cstaff        17 Feb 11  2016 /nasa/cuda/7.5/lib64/libcuinj64.so -> libcuinj64.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        20 Feb 11  2016 /nasa/cuda/7.5/lib64/libcuinj64.so.7.5 -> libcuinj64.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff   5751400 Feb 11  2016 /nasa/cuda/7.5/lib64/libcuinj64.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff   1649726 Feb 11  2016 /nasa/cuda/7.5/lib64/libculibos.a\r\nlrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand.so -> libcurand.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand.so.7.5 -> libcurand.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff  51765952 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff  51992564 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand_static.a\r\nlrwxrwxrwx 1 hsp cstaff        18 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver.so -> libcusolver.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        21 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver.so.7.5 -> libcusolver.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff  37034328 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff  16613348 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver_static.a\r\nlrwxrwxrwx 1 hsp cstaff        18 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse.so -> libcusparse.so.7.5\r\nlrwxrwxrwx 1 hsp cstaff        21 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse.so.7.5 -> libcusparse.so.7.5.18\r\n-rwxr-xr-x 1 hsp cstaff  36816424 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse.so.7.5.18\r\n-rw-r--r-- 1 hsp cstaff  44445334 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse_static.a\r\n\r\nll /u/dkokron/play/cuDNN/cuda/lib64/\r\ntotal 117596\r\nlrwxrwxrwx 1 dkokron scicon       13 Jun 10 01:20 libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 dkokron scicon       17 Jun 10 01:20 libcudnn.so.5 -> libcudnn.so.5.1.3\r\n-rwx------ 1 dkokron scicon 60696704 Jun 10 01:18 libcudnn.so.5.1.3\r\n-rw------- 1 dkokron scicon 59715990 Jun 10 01:18 libcudnn_static.a\r\n\r\n", "comments": ["SLES11sp3 is not a supported operating system.  Hopefully someone in the community can help you.  Might be good to ask on stackoverflow.", "The root cause of the failure seems to be right here:\r\n```\r\nval = bytes(subprocess.check_output([\r\nAttributeError: 'module' object has no attribute 'check_output'\r\n```\r\nwhich looks really weird. Does SLES have a different subprocess module?\r\ncould you try running python manually and checking:\r\n```\r\nimport subprocess\r\n'check_output' in dir(subprocess)\r\n```", "Also I found this online:\r\nhttp://stackoverflow.com/questions/26894024/subprocess-check-output-module-object-has-out-attribute-check-output\r\n\r\nMaybe the python libraries have an old version of subprocess?", "In reply to gunan.\r\n\r\nPython 3.5.1 (default, Jul 28 2016, 13:15:08)\r\n[GCC 4.9.3] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import subprocess\r\n>>> 'check_output' in dir(subprocess)\r\nTrue\r\n>>>", "it looks like check_output is available, but during build, somehow it is not.\r\nI would guess this would be something specific to your python setup.\r\n\r\nThe root cause of your issue is:\r\n```\r\nval = bytes(subprocess.check_output([\r\nAttributeError: 'module' object has no attribute 'check_output'\r\n```\r\n\r\nI cannot really say why this is happening, since check_output is actually available in your python's subprocess module. At this point, I would say someone more familiar with your python setup or stack overflow (as suggested above) would be the best place to ask.", "Not sure what is going on here, because it is really difficult to get a SLES/openSuse box ready with all TF  dependencies. I will probably not be able to reproduce the problem.\r\n\r\nBut I am sure that the culprit is your subprocess library. Therefore I will close the issue.\r\n\r\n", "Another great suggestion I received from @aselle is using cmake.\r\nThat might be a much better solution, as bazel also does not have official support for SLES.\r\n\r\nI heard that a lot of our users on CentOS have successfully built TF using cmake.", "Gunan,\n\nWe were eventually able to get a working TF environment using the Anaconda\nframework.\nThank you for all the help and suggestions.\n\nDan\n\nOn Mon, Dec 19, 2016 at 5:31 PM, gunan <notifications@github.com> wrote:\n\n> Another great suggestion I received from @aselle\n> <https://github.com/aselle> is using cmake.\n> That might be a much better solution, as bazel also does not have official\n> support for SLES.\n>\n> I heard that a lot of our users on CentOS have successfully built TF using\n> cmake.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5994#issuecomment-268128232>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AJw66IpxHfedrtFh6YB1lm3_rH9QHgW7ks5rJy_mgaJpZM4LAy1b>\n> .\n>\n", "I got the same error when trying to install TensorFlow with a Python installation that was not the default one on the system. Adding the desired version to the path solved the issue, e.g. with:\r\n```\r\nPATH=~/tensorflow-0.12.0-nogpu/bin:$PATH\r\nexport PATH\r\n```\r\n\r\nIn my case, I was using python 3 and there was no file in my /bin folder that was just called `python`, so I added a symlink:\r\n```\r\nln -s ~/tensorflow-0.12.0-nogpu/bin/python3.5 ~/tensorflow-0.12.0-nogpu/bin/python\r\n```", "I got it working by adding this function to configure.py\r\n```\r\ndef check_output(command_list):\r\n    proc = subprocess.Popen(command_list, stdout=subprocess.PIPE)\r\n    proc.wait()\r\n    return proc.stdout.read()\r\n```\r\nbelow run_shell function and change all \r\n`subprocess.check_output(cmd)`\r\nto\r\n`check_output(cmd)`\r\nthe problem is the configure script use default python. \r\n```\r\nif [ -z \"$PYTHON_BIN_PATH\" ]; then\r\n  PYTHON_BIN_PATH=$(which python || which python3 || true)\r\nfi\r\n```\r\nwhich is python 2.6 in my machine. `check_output` was introduced in python 2.7.\r\nI know it's 2 y.o. issue but there's no explanation about the compatibility problem.", "Another workaround is that specifying the python to use by changing \r\n`PYTHON_BIN_PATH=$(which python || which python3 || true)`\r\nto\r\n`PYTHON_BIN_PATH=$(which python<python version above 2.7> || which python3 || true)`\r\nin `configure` shellscript"]}, {"number": 5993, "title": "Fix: Do not use perl in configure, use only standard bash tools.", "body": "", "comments": []}, {"number": 5992, "title": "Update 1_notmnist.ipynb", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?"]}, {"number": 5991, "title": "[Windows] Don't try to read numa node from SysFS", "body": "This makes the behavior on Windows consistent with Mac OS X, and prevents a needless error message when using GPUs.\r\n\r\nPartially addresses #5986.", "comments": ["Jenkins failed to fetch changes from github, retrying tests.\r\nJenkins, test this please.", "@tensorflow-jenkins test this please."]}, {"number": 5990, "title": "iOS: No OpKernel for Pow op", "body": "We're running a model on iOS and finding that the `tf.pow` Pow op is not supported; we added a line with `tensorflow/core/kernels/cwise_op_pow.cc` to `tensorflow/contrib/makefile/tf_op_files.txt`, rebuild TensorFlow, and after that, the model worked.\r\n\r\nCould this op be added to the iOS makefile so that in the future other folks do not run into this problem?\r\n\r\n(I would submit a PR but this is at a company that has not signed the TensorFlow CLA so for such a small change it is not worth the hassle.)\r\n", "comments": ["This has been taken care of by the referenced PR, so I am closing this."]}, {"number": 5989, "title": "RuntimeError for minimal RNNCell example", "body": "I am just trying to get a simple RNNCell to work. This simple code:\r\n\r\n    with tf.Session() as sess:\r\n        x = tf.Variable(np.ones((2, 3)))\r\n        tf.global_variables_initializer().run()\r\n        out, state = BasicRNNCell(4)(x, x)\r\n\r\nThrows the following error:\r\n\r\n    /Users/ethan/env/bin/python /Users/ethan/tf-bug/main.py\r\n    Traceback (most recent call last):\r\n      File \"/Users/ethan/tf-bug/main.py\", line 8, in <module>\r\n        out, state = BasicRNNCell(4)(x, x)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 200, in __call__\r\n        output = self._activation(_linear([inputs, state], self._num_units, True))\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 905, in _linear\r\n        \"Matrix\", [total_arg_size, output_size], dtype=dtype)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1024, in get_variable\r\n        custom_getter=custom_getter)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 850, in get_variable\r\n        custom_getter=custom_getter)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 346, in get_variable\r\n        validate_shape=validate_shape)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 331, in _true_getter\r\n        caching_device=caching_device, validate_shape=validate_shape)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 677, in _get_single_variable\r\n        expected_shape=shape)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\r\n        expected_shape=expected_shape)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 327, in _init_from_args\r\n        initial_value(), name=\"initial_value\", dtype=dtype)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 665, in <lambda>\r\n        shape.as_list(), dtype=dtype, partition_info=partition_info)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 284, in _initializer\r\n        dtype, seed=seed)\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py\", line 231, in random_uniform\r\n        minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\r\n      File \"/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 683, in convert_to_tensor\r\n        dtype.name, ret.dtype.name))\r\n    RuntimeError: min: Conversion function <function _constant_tensor_conversion_function at 0x10cb461b8> for type <type 'object'> returned incompatible dtype: requested = float64_ref, actual = float64\r\n\r\n    Process finished with exit code 1\r\n\r\nThis is the output of `pip show tensorflow`:\r\n\r\n > Name: tensorflow\r\n > Version: 0.12.0rc0\r\n > Summary: TensorFlow helps the tensors flow\r\n > Home-page: http://tensorflow.org/\r\n > Author: Google Inc.\r\n > Author-email: opensource@google.com\r\n > License: Apache 2.0\r\n > Location: /Users/ethan/env/lib/python2.7/site-packages\r\n > Requires: numpy, mock, wheel, six, protobuf\r\n\r\n\r\nThanks!\r\n", "comments": ["Automatically closing due to lack of recent activity. We hope that you were able to resolve it on your own. However, since this is a support issue rather than a bug or feature request, you will probably get more information by posting it on StackOverflow.", "Facing the same issue here... anyone else has this same problem?", "Try passing x through tf.identity:\r\n\r\nx = tf.identity(x)\r\n\r\nBefore passing to the rnn."]}, {"number": 5988, "title": "fused_batch_norm throws ValueError for partially known 2D-Tensor", "body": "I'm trying to use the new fused_batch_norm layer (as I also have this problem #3290)\r\nUsing it for 4D Tensors works fine so far (as in: it doens't crash)\r\nHowever, when using 2D Tensors ([None, X]) I get this error:\r\n\r\n\r\n> Traceback (most recent call last):\r\n...\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 467, in batch_norm\r\n    scope=scope)\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 350, in _fused_batch_norm\r\n    outputs = array_ops.reshape(outputs, original_shape)\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2448, in reshape\r\n    name=name)\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 503, in apply_op\r\n    as_ref=input_arg.is_ref).dtype.name\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py\", line 194, in _tensor_shape_tensor_conversion_function\r\n    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\r\nValueError: Cannot convert a partially known TensorShape to a Tensor: (?, 256)\r\n\r\nSame code works for the normal batch_norm layer.\r\nAlso works if I reshape it manually to [None, 1, 1, X] before calling fused_batch_norm\r\n\r\nCuda 8.0, cuDNN 5.1, tf r0.12", "comments": ["@abred, thanks for reporting the issue. Could you give a minimum example that reproduces the error? Is the first dimension of the 2D Tensor known? Could you set its shape to a complete shape, rather than a partially known shape (that is what is being complained)? Could you also share the code snippet of your manual reshape? I am curious why your manual reshape succeeded without complaining about partial shape info, while the internal reshape failed.", "here is a small example:\r\nhttps://gist.github.com/abred/daf06a496ebb585212529b7c0ecbad02\r\n\r\nthe first dimension of the 2D Tensor is not known (None/-1)\r\nwhen I change it to a fixed number it works.\r\nI included the reshapes in the code snippet (def batch_norm), so when you run it as-is it should work (comment the if..reshapes to get the error)", "still occurring with 0.12.1", "This issue has been resolved with the two commits below:\r\n\r\nhttps://github.com/tensorflow/tensorflow/commits?author=zhangyaobit&since=2017-03-17T07:00:00Z&until=2017-03-18T07:00:00Z"]}, {"number": 5987, "title": "Request for documentation on recommended flow in slim for train, validation, and test sets", "body": "The examples in the [slim README.md](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) give basic documentation for training and evaluating models when used separately; however, there is guidance missing on how to do the classic cycle of mini-batch gradient descent using shuffled subsets of the training set, periodically evaluating validation set, and then evaluating on the test set post-training. \r\n\r\nUsing the [MNIST tutorial](https://www.tensorflow.org/versions/r0.12/tutorials/mnist/tf/index.html) and [this tutorial](https://github.com/mnuke/tf-slim-mnist) for reference, the best I came up with was something like this where I'm effectively monkey-patching the train_step_fn to periodically output accuracies: \r\n\r\n```\r\nfrom tensorflow.contrib.slim.python.slim.learning import train_step\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n  image, label = input('train', FLAGS.dataset_dir)\r\n  images, labels = tf.train.shuffle_batch([image, label], batch_size=FLAGS.batch_size, capacity=1000 + 3 * FLAGS.batch_size, min_after_dequeue=1000)\r\n  images_validation, labels_validation = inputs('validation', FLAGS.dataset_dir, 5000)\r\n  images_test, labels_test = inputs('test', FLAGS.dataset_dir, 10000)\r\n \r\n  with tf.variable_scope(\"model\") as scope:\r\n    predictions = model(images, FLAGS)\r\n    scope.reuse_variables()\r\n    predictions_validation = model(images_validation, FLAGS)\r\n    predictions_test = model(images_test, FLAGS)\r\n    \r\n  slim.losses.softmax_cross_entropy(predictions, labels)\r\n  optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\r\n  train_op = slim.learning.create_train_op(slim.losses.get_total_loss(), optimizer)\r\n\r\n  accuracy_validation = slim.metrics.accuracy(tf.to_int32(tf.argmax(predictions_validation, 1)), tf.to_int32(tf.argmax(labels_validation, 1)))\r\n  accuracy_test = slim.metrics.accuracy(tf.to_int32(tf.argmax(predictions_test, 1)), tf.to_int32(tf.argmax(labels_test, 1)))\r\n    \r\ndef train_step_fn(session, *args, **kwargs):\r\n  total_loss, should_stop = train_step(session, *args, **kwargs)\r\n\r\n  if train_step_fn.step % FLAGS.validation_check == 0:\r\n    accuracy = session.run(train_step_fn.accuracy_validation)\r\n    print('Step %s - Loss: %.2f Accuracy: %.2f%%' % (str(train_step_fn.step).rjust(6, '0'), total_loss, accuracy * 100))\r\n\r\n  if train_step_fn.step == (FLAGS.max_steps - 1):\r\n    accuracy = session.run(accuracy_test)\r\n    print('%s - Loss: %.2f Accuracy: %.2f%%' % ('FINAL TEST', total_loss, accuracy * 100))\r\n    \r\n  train_step_fn.step += 1\r\n  return [total_loss, should_stop]\r\n\r\ntrain_step_fn.step = 0\r\ntrain_step_fn.accuracy_validation = accuracy_validation\r\n\r\nslim.learning.train(\r\n  train_op,\r\n  FLAGS.logs_dir,\r\n  train_step_fn=train_step_fn,\r\n  graph=graph,\r\n  number_of_steps=FLAGS.max_steps\r\n)\r\n```\r\n\r\n**Note**: one problem with this implementation is that the final test set is not guaranteed to be run in the case of early exit.\r\n \r\nI've posted in the slack channel and Googled around, but haven't been able to find any examples for this basic use case. Accordingly, I would like to propose that an example providing the best practice to periodically evaluate batch trained models using the validate set and the trained model against the test set to be added to the slim README.md.\r\n\r\nI think it would really help the community to have a clearer idea on the intentions of the slim team on how the batch training and evaluation paths were designed to be used together during and after training.\r\n", "comments": ["@nathansilberman any suggestion?", "+1\r\n\r\n@kmalakoff don't you need to `feed_dict` your batch to placeholders?", "+1", "+1", "Come on guys, the critical use case of training + validating is still \u2014 even on r1.0 \u2014 completely non-obvious to implement using the slim \"lego blocks\". We need guidance here, if you please.", "Same here ... I am having trouble with that too!", "Looking for inputs too!", "+1", "+1", "+1", "We have found that running eval on validation dataset in a different process works better. \r\nIn most cases, the validation dataset requires several batches, and takes time that could be used to make progress on training.\r\n\r\nSo the recommended way is to save checkpoints at regular intervals, then use slim.evaluation_loop() to keep evaluating checkpoints while training.\r\n\r\nFinally after training, one would run eval on test set. ", "@sguada @nathansilberman. Has there any update on this? Is there a good way to periodically verify accuracy on training & validation set DURING training instead of two separate processes? Thanks.", "+1", "@sguada \r\nThanks for your suggestion. I agree that validating in a separate process sounds like a better approach. \r\n\r\nThere are a number of things that are known during training time: what data file is used, what samples are used for training (as opposed to reserved for validation), what kink was introduced in the code to perform a certain test....etc. These important pieces of information  need to be passed to the other process reliably.\r\n\r\nSince it seems to be the standard use case, would it be possible to have, in the repo, an example of such mechanics? slim seems incomplete if it provides many awesome ways to train a network easily, but no easy way to monitor/validate its progress.\r\n\r\nThanks again.\r\n", "@ybsave what @kmalakoff wrote is a way to compute evaluation metrics while training.\r\n\r\nAs I mentioned above, that has some problems, like slowing down the training, but could be used for early stopping.\r\n\r\nFor examples on how to train and evaluate in two different process see:\r\nhttps://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py\r\nhttps://github.com/tensorflow/models/blob/master/slim/eval_image_classifier.py\r\n\r\nI typically just run train_image_classifier in one process and eval_image_classifier in another.", "In the meantime I've been using the (pre-trained) classification models (vgg, resnet) created by slim, with a regular tensorflow train+val loop. This works well. \r\nWhen creating the model, for resnet use something like\r\n\r\n`is_training = tf.Variable(True, name='is_training')`\r\n`with slim.arg_scope(resnet_v1.resnet_arg_scope(is_training=is_training)):`\r\n`    net = resnet_v1.resnet_v1_101`\r\n`    y_est, _ = net(images_in, num_classes=nclasses)`\r\n`...`\r\n\r\nAt the training part in each epoch run:\r\n    `sess.run(is_training.assign(True))`\r\nand at the validation:\r\n    `sess.run(is_training.assign(False))`\r\n", "Since there's no single official procedure, I created a couple of scripts to perform the training/validation in different processes (which we used to participate in a machine learning challenge). If you wanna take a look, they're here: https://github.com/learningtitans/isbi2017-part3#deep-learning-component-model-rc30 \u2014 the most relevant code is a shell script in [./etc/launch_validation_loop.sh](https://github.com/learningtitans/isbi2017-part3/blob/master/etc/launch_validation_loop.sh).", "Seems Slim saves checkpoints at a fixed time interval defined in the save_interval_secs. This seems cause issue if we want to synchronization this with validation set evaluation process. Plus saving checkpoints at fixed time interval (instead of training steps) seems introduce an extra set of uncertainty. I believe override the supervisor can change this behavior but it is kind of messy. Is there a simpler way to do this?", "You can dig into the supervisor and change it. I did the same and customized it a little bit for myself.", "I would like to have an option in slim to be able to periodically run evaluation in the same process as training. Running in separate processes has some downsides for me when training on a single multi-gpu system: 1. A GPU is dedicated to running eval. Training would be faster if I could use all GPUs as \"clones\" for multi-gpu training, even accounting for doing periodic evaluation. Running eval on the CPU slows down training because eval uses a lot of CPU and then bottlenecks training on image decoding and augmentation. 2. My training process uses most of the system RAM. I can't run eval at the same time without heavy swapping.", "Doesn't  TFSlim update anymore? It's really boring. Convenient setting for validation while trainning is really in need.", "I found the following section really helpful: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim#evaluation-loop\r\n\r\nI initially thought the main slim page was:\r\nhttps://github.com/tensorflow/models/tree/master/slim\r\n\r\nI created a PR to make this more explicit here:\r\nhttps://github.com/tensorflow/models/pull/2371\r\n\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Please reopen if tensorflow/models#2371 hasn't addressed it.", "As explained above, the solution proposed in https://github.com/tensorflow/models/pull/2371 does not address the problem. We are looking for a canonical way to interleave training and evaluation, not for a way to perform evaluation as a separate process. For those of us with few GPUs (or just one!) the current pattern just doesn't work.", "@liavassif \r\n\r\n> At the training part in each epoch run:\r\nsess.run(is_training.assign(True))\r\nand at the validation:\r\nsess.run(is_training.assign(False))\r\n\r\nthis seems like an interesting approach. can you give a more complete example? I'm not sure how to use `feed_dict` to feed the different train/val inputs into the same model and reuse weights", "@mixuala \r\nAfter using sess.run() to set the is_training variable, the rest is just the usual mini-batch approach (at train or at validation).\r\n```\r\n        # is_train should be True when training and False for validation\r\n        sess.run(is_training.assign(is_train))\r\n        for batchid in range(batchN):\r\n            if is_train:\r\n                  cur_batch = get_batch_train(batchid)\r\n            else:\r\n                  cur_batch = get_batch_test(batchid)\r\n            run_results = sess.run(ops_train, feed_dict=cur_batch)\r\n```\r\n", "@liavassif I keep getting `RuntimeError: Graph is finalized and cannot be modified.` but I am trying to run this inside `slim.learning.train()` in `def train_step_fn(sess, ...)` . maybe that is not the right way to go...", "@mixuala this approach should be used instead of slim.learning.train(). You should just run the for loop in the example in your main code in order to perform training/val. Similarly as done in the regular Tensorflow MNIST/CIFAR tutorials (well, at least in the old tutorials, now they are using something called an Estimator)."]}, {"number": 5986, "title": "TensorFlow on Windows logs an error when using GPUs: \"Could not identify NUMA node\"", "body": "I use one GPU card now,  tensorflow(0.12) reports follow error, but the process run correctly.   How to suport  if we use multi-gpu on windows ?\r\n\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA support.\r\n\r\n", "comments": ["This error should be a warning. Multiple GPUs work today on Windows, and they should work with a NUMA setup (although we haven't tested this). However, the stream executor code will not take advantage of NUMA topology if it is available.", "@poxvoculi I think you know most about the more complex bus topologies we use. What are we missing if we don't have GPU-to-NUMA-node mapping information in stream executor?", "The code and comments in gpu_device.cc clarify what's going on.  We use the StreamExecutor interface to get NUMA affinity for a GPU, then use that to set a (PCI) bus identifier for the GPU.  In the generic open-source version of TensorFlow, the bus id is of no consequence because there are no adaptations for multi-bus architectures.    It would be possible to utilize this feature to customize TF for higher performance in some kinds of multi-bus architecture.", "Should we remove this log statement from `tensorflow/stream_executor` then? Or should we even remove the code for querying the NUMA affinity, since the bus ID is never used?", "That should probably be a LOG(INFO), not an error. "]}, {"number": 5985, "title": "None gradient from GRU", "body": "Hello everybody,\r\n\r\n**Introduction:**\r\nI am trying to reproduce the work of Szegedy et al: [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199) and Dezfooli et al: [Universal adversarial perturbations](https://arxiv.org/abs/1610.08401). What they do, briefly, is that they take the gradient `g` of the network with respect to the input image `x`, then slightly modify the input image `x` \"against\" the obtained gradient, i.e. `x-0.001g`. The modified images are consequently considered as another network input, hence new gradients `g'` might be computed and obtained. The result gradients are manually set to the average of those two set obtains gradients, i.e. `g/2 + g'/2`. I hope I explained that clearly.\r\n\r\nI successfully implemented it for images in TF 0.10 (working on 0.12RC as well). Now I want to do something similar with recurrent networks (sentiment analysis task). So I have a input sequence of tokens (numbers), a variable `embeddings` which is used by `tf.nn.embedding_lookup`. After the lookup, the sequence of proper embeddings is traversed by GRU (dynamically). It's last state is considered as the representation of the sequence. Then a MLP with a single hidden layer and ReLU activation is applied, resulting in 2 neurons representing the positive and negative logits respectively. The loss is traditional categorical cross entropy.\r\n\r\n**Bug**\r\nSimilarly to the papers mentioned above, I obtain gradients of the embedding, and modify the current embeddings slightly \"against\" the obtained gradient. Than I compute the new loss and _new gradients (here is the problem!)_ and update the network by their mean.\r\n\r\nThe problem is that the returned _new gradients_ are all `None`s. I originally worked with TF 0.10, however, I got an error explaining that second order derivatives are impossible to obtain from scan. I upgraded to recently released TF 0.12RC which doesn't throw this error but returns `None`s instead.\r\n\r\n**Related Issues and SOs**\r\n#783 is somewhat similar, but not the same. [This question](http://stackoverflow.com/questions/36874522/tensorflow-gradients) deals with very the same problem  but the solution isn't sufficient as replacing the `None` value with zero is really worthless in my case since I need to modify the variable against the gradient.\r\n\r\n**Minimal Not-Working Example**\r\nI am sorry the code is so long. It is partially caused by the fact that the problem is non-trivial and requires few lines and partially by the amount of comments I tried to write in order to make the code more readable. All platform/version information is stored at beginning of the file.\r\n\r\nThe `main()` function constructs two `SimpleSentiment`s as the models that are trained. Each one is trained for few epochs and batches. First instance is without the adversarial, hence we perform no trick regarding modifying the gradients (for a sanity check). The second uses the complicated `if` branch in the constructor and obtains `None`s as described above.\r\n\r\nI believe this is a bug and not my mistake, however, it can't be ruled out as I am not as experienced with TF as I'd like to be.\r\n\r\n```python\r\n# #!/usr/bin/env python3\r\n\r\n# python 3.5 (anaconda)\r\n# TF 0.12 RC from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl\r\n# $ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n#  0.12.0-rc0\r\n\r\n# OS: RedHat 7.2\r\n# CPU version only, no GPU, no CUDA, no CUDNN\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.rnn_cell import GRUCell\r\n\r\n\r\nBATCH = 5  # batch size\r\nMAX_LEN = 10  # max length of the sequence\r\nMLP_HIDDEN_DIM = 128  # number of hidden neurons in the MLP\r\nEMBEDDING_DIM = 300  # embedding dimension\r\nVOCAB_SIZE = 8  # vocabulary size\r\n\r\nTHREADS = 4  # number of threads to be used\r\nSTD=0.001  # standard deviation of ariable initializers\r\n\r\n\r\nclass SimpleSentiment:\r\n    def __init__(self, adversarial=False, device='/cpu:0'):\r\n\r\n        self.embeddings = tf.get_variable('word_embeddings',\r\n                                          initializer=tf.random_uniform([VOCAB_SIZE, EMBEDDING_DIM], -1.0, 1.0))\r\n\r\n        with tf.variable_scope('sentiment') as scope:\r\n            with tf.device(device):\r\n                # Inputs\r\n                self.text = tf.placeholder(tf.int32, [BATCH, MAX_LEN])\r\n                self.text_len = tf.placeholder(tf.int32, [BATCH])\r\n                self.sentiment = tf.placeholder(tf.int32, [BATCH])\r\n\r\n                # Normal loss\r\n                loss_normal = self._loss(self.text, self.text_len, self.sentiment)\r\n\r\n                # Define the optimizer\r\n                # Note: I've tried multiple of optimizers and none helped\r\n                optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\r\n\r\n                if adversarial:  # Define adversarial loss\r\n                    # Let's acces already defined variables\r\n                    scope.reuse_variables()\r\n\r\n                    # Gradients of all variable (according to normal loss)\r\n                    gradients = optimizer.compute_gradients(loss_normal)\r\n                    print(len(gradients), gradients)\r\n\r\n                    # gradients of the embeddings\r\n                    emb_gradient = optimizer.compute_gradients(loss_normal, [self.embeddings])[0][0]\r\n\r\n                    # this how much we want to shift the embeddings, i.e. going \"against\" the gradient\r\n                    delta = 0.001*tf.sign(emb_gradient)\r\n\r\n                    # let's compute the loss once again but this time we add the delta to the embeddings\r\n                    loss_adversarial = self._loss(self.text, self.text_len, self.sentiment, delta)\r\n\r\n                    # new gradient of the whole computational graph\r\n                    adversarial_gradients = optimizer.compute_gradients(loss_adversarial)\r\n                    print(len(adversarial_gradients), adversarial_gradients)  # everything is None!\r\n\r\n                    # Now we compute an average of old and new gradients\r\n                    new_gradients = [((g + ag)/2, vg) for ((g, vg), (ag, avg)) in zip(gradients, adversarial_gradients)]\r\n\r\n                    # and apply them\r\n                    self.training = optimizer.apply_gradients(new_gradients)\r\n\r\n                    # Btw this doesn't work either\r\n                    # self.training = optimizer.apply_gradients(adversarial_gradients)\r\n\r\n                    self.loss_final = (loss_normal + loss_adversarial) / 2\r\n\r\n                else:  # Normal loss\r\n                    # simply minimize according to the gradients\r\n                    self.loss_final = loss_normal\r\n                    self.training = optimizer.minimize(loss_normal)\r\n\r\n                # Create the session\r\n                self.session = tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=THREADS,\r\n                                                                intra_op_parallelism_threads=THREADS,\r\n                                                                allow_soft_placement=True))\r\n\r\n                # init everything (still deprecated way)\r\n                self.session.run(tf.initialize_all_variables())\r\n\r\n    def _loss(self, text, text_len, sentiment, emb_delta=0):\r\n        # use embedding\r\n        # note that emb_delta is zero as long as adversarial=False\r\n        # if adversarial=False then each embedding is shifted by appropriate emb_delta\r\n        text = tf.nn.embedding_lookup(self.embeddings + emb_delta, text)\r\n\r\n        # run gru\r\n        gru_cell = GRUCell(MLP_HIDDEN_DIM)\r\n        outputs, state = tf.nn.dynamic_rnn(cell=gru_cell,\r\n                                           inputs=text,\r\n                                           sequence_length=text_len,\r\n                                           dtype=tf.float32)\r\n\r\n        # define MLP\r\n        W1 = tf.get_variable(name='MLP_W1',\r\n                             shape=[state.get_shape()[1], MLP_HIDDEN_DIM],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n        W2 = tf.get_variable(name='MLP_W2',\r\n                             shape=[MLP_HIDDEN_DIM, 2],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n        h1 = tf.get_variable(name='MLP_h1',\r\n                             shape=[MLP_HIDDEN_DIM],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n        h2 = tf.get_variable(name='MLP_h2',\r\n                             shape=[2],\r\n                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))\r\n\r\n        # apply MLP of the last GRU state\r\n        after_first_layer = tf.nn.relu(tf.matmul(state, W1) + h1)\r\n        logits = tf.matmul(after_first_layer, W2) + h2\r\n\r\n        # compute loss via categorial cross entropy\r\n        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, sentiment))\r\n        return loss\r\n\r\n\r\ndef main():\r\n    for adversarial in [False, True]:\r\n        print('\\n=================================')\r\n        if adversarial:\r\n            print('Using the adversarial loss')\r\n        else:\r\n            print('Using the standard loss')\r\n\r\n        net = SimpleSentiment(adversarial=adversarial)\r\n\r\n        for epoch in range(5):\r\n            print('Epoch {}'.format(epoch))\r\n\r\n            for batch in range(3):\r\n                _, loss_final = net.session.run([net.training, net.loss_final],\r\n                                                {net.text: np.array([[3, 1, 1, 2, 1, 0, 0, 0, 0, 0],\r\n                                                                     [3, 4, 1, 2, 1, 4, 4, 0, 0, 0],\r\n                                                                     [1, 1, 1, 2, 0, 0, 0, 0, 0, 0],\r\n                                                                     [3, 3, 3, 2, 1, 7, 0, 0, 0, 0],\r\n                                                                     [7, 1, 5, 2, 4, 2, 2, 2, 1, 7]], dtype='int32'),\r\n                                                 net.text_len: np.array([5, 7, 4, 6, 10], dtype='int32'),\r\n                                                 net.sentiment: np.array([0, 0, 1, 1, 0], dtype='int32')})\r\n\r\n                print('\\tBatch {}: {}'.format(batch, loss_final))\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nThanks for help\r\nPetr", "comments": ["@rmlarsen @vrv Could this be related to a known missing 2nd order derivative?", "I am also getting None gradients when trying to compute second order derivatives of a GRU.", "If I revert to tensorflow 0.10 I get the error message:\r\n\r\n    TypeError: Second-order gradient for while loops not supported.\r\n\r\nThe error disappears if I switch from using `tf.nn.dynamic_rnn` to `tf.nn.rnn`, but this appears to slow things down quite a bit.", "@vladfi1 Does it really work for you with `tf.nn.rnn`? I updated my code so that is uses `tf.nn.rnn`, i.e. used `tf.split` on the input tensor in order to support it. However, the gradients are still `None`s and I get a really weird error `AttributeError: 'NoneType' object has no attribute 'pred'`.\r\n\r\nI attach the code [here in a gist](https://gist.github.com/petrbel/6c72395490aa90d68d3d68fb6e5747a4 ) so that it doesn't mess with the original post. I still use TF 0.12. but I suppose it is back-compatible.\r\n\r\nThanks for help.", "@petrbel It runs fine for me with tensorflow 0.10.0.", "I'm not sure, since this uses dynamic_rnn, I'm assigning to @ebrevdo .", "@vladfi1 It is as you said, it runs fine with 0.10. However I still think it is an issue as it doesn't work with 0.12.\r\nPetr", "tf.while_loop definitely doesn't support second derivatives.  You should have received an error instead of None.  Which seems like a bug. If you only needed to use the first derivative values as values and didn't mean to differentiate them, wrap them in tf.stop_grdients to avoid trying to calculate their derivatives in your second gradients calculation.", "@ebrevdo Will this change in the future? If while_loop has a first derivative, then that first derivative itself should probably itself be a while_loop (this is probably where I'm mistaken), in which case there's no reason not to take the derivative again.", "That is the general idea, but the implementation is complex enough, for\nmany reasons, that we do not plan to implement a second derivative.\n\nOn Dec 16, 2016 6:50 PM, \"Vlad Firoiu\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Will this change in the future? If\n> while_loop has a first derivative, then that first derivative itself should\n> probably itself be a while_loop (this is probably where I'm mistaken), in\n> which case there's no reason not to take the derivative again.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5985#issuecomment-267743388>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8l9aUZijyU3mq36EhhAGSYNvq3Eks5rI2owgaJpZM4LAZNz>\n> .\n>\n", "@ebrevdo: you mean in its current formulation, right?  That is, if we redesigned how while_loop was implemented, it could be done more easily?", "I don't know.  The current implementation requires a lot of special casing\nand careful graph introspection to properly identify which tensors should\nstay in the stack for gradient purposes, and for e.g. handling of external\nand within body stop gradient calls.  There is also a lot of special\nhandling in the runtime.  Compound that with nested while loop handling and\npossibly needing to modify TensorArray to support second+ derivatives...\n\nAt the very least, first we should move while loop and gradients to the c++\napi, and decide whether we want full Jacobian support, then we can consider\nthis.\n\nOn Dec 17, 2016 7:43 AM, \"Vijay Vasudevan\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo>: you mean in its current\n> formulation, right? That is, if we redesigned how while_loop was\n> implemented, it could be done more easily?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5985#issuecomment-267776014>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim7vVjKRbtSsZ7jpoveltRo7CjeOMks5rJB8ngaJpZM4LAZNz>\n> .\n>\n", "Is it possible to compute second order derivatives with `tf.nn.rnn` if I switch to 0.10, or does it silently suppress any errors? cc @petrbel @vladfi1 @ebrevdo ", "regarding second or derivatives, i think we fixed bugs from 0.10 to 1.0 and\nin the nightlies; so definitely use that instead.\n\nkeep in mind the following ops don't have second derivatives:\n\ntf.nn.sparse_softmax_cross_entropy_with_logits\ntf.nn.softmax_cross_entropy_with_logits\n\nso if you're using those for your loss, you'll have trouble.  implement\nthem yourself using tensorflow primitives and you'll be able to use second\nderivatives.\n\nOn Wed, Apr 5, 2017 at 10:09 AM, Ankesh Anand <notifications@github.com>\nwrote:\n\n> Is it possible to compute second order derivatives with tf.nn.rnn if I\n> switch to 0.10, or does it silently suppress any errors? cc @petrbel\n> <https://github.com/petrbel> @vladfi1 <https://github.com/vladfi1>\n> @ebrevdo <https://github.com/ebrevdo>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5985#issuecomment-291929879>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim5Rc1STYBZLGoOOc8fwAz7FY_wy0ks5rs8q6gaJpZM4LAZNz>\n> .\n>\n", "Slightly confused here, you mean I should use 1.0? I am already using that and it doesn't allow me to compute second order derivatives for RNNs", "Do you have some example code and the error you get?", "The relevant portion is this:\r\n`gradients = tf.gradients(discriminator(x_dash, reuse=True)[0], [x_dash])[0]`\r\n\r\nThe `discriminator` here is a simple LSTM implemented using `tf.nn.dynamic_rnn`.\r\n\r\nThe error I get is: `TypeError: Second-order gradient for while loops not supported.`\r\n\r\nI am trying to implement the gradient penalty term from this paper: https://arxiv.org/abs/1704.00028 (Improved training of WassGANs)\r\n", "Ah.\n\nThat's right, tf.while_loop (used by dynamic_rnn) does not support second\nderivatives; and there are no plans for support in the near or mid-term\nfuture.  I'm afraid if you want this, you'll have to use a static RNN.\n\nOn Wed, Apr 5, 2017 at 5:18 PM, Ankesh Anand <notifications@github.com>\nwrote:\n\n> The relevant portion is this:\n> gradients = tf.gradients(discriminator(x_dash, reuse=True)[0],\n> [x_dash])[0]\n>\n> The discriminator here is a simple LSTM implemented using\n> tf.nn.dynamic_rnn.\n>\n> The error I get is: TypeError: Second-order gradient for while loops not\n> supported.\n>\n> I am trying to implement the gradient penalty term from this paper:\n> https://arxiv.org/abs/1704.00028 (Improved training of WassGANs)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5985#issuecomment-292033647>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxZMeUPnCyEaRmHnKQAQOh6Q0z5Hks5rtC9SgaJpZM4LAZNz>\n> .\n>\n", "@asimshankar @skye I do know there's been work to move While loops into C API already, but I don't know how gradient support within it works, if at all yet.  Just an FYI of something that would be great to have, though I don't know the scope of the work required.", "@ebrevdo `static_rnn` doesn't work either, gives me nan losses.", "@ankeshanand I think it might work in 0.10/0.11, but I don't remember for sure. I just ended up writing my own unroller:\r\n\r\n```python\r\ndef rnn(cell, inputs, initial_state):\r\n  inputs = tf.unpack(inputs, axis=1)\r\n  outputs = []\r\n  state = initial_state\r\n  for input_ in inputs:\r\n    output, state = cell(input_, state)\r\n    outputs.append(output)\r\n  outputs = tf.pack(outputs, axis=1)\r\n  return outputs, state\r\n```\r\n\r\nThis assumes the time axis is 1. In more recent tensorflow versions, `[un]pack` has been renamed to `[un]stack`.", "@ankeshanand <https://github.com/ankeshanand> are you passing the\nsequence_length= argument to the static rnn call?\n\nOn Thu, Apr 6, 2017 at 2:43 AM, Vlad Firoiu <notifications@github.com>\nwrote:\n\n> @ankeshanand <https://github.com/ankeshanand> I think it might work in\n> 0.10/0.11, but I don't remember for sure. I just ended up writing my own\n> unroller:\n>\n> def rnn(cell, inputs, initial_state):\n>   inputs = tf.unpack(inputs, axis=1)\n>   outputs = []\n>   state = initial_state\n>   for input_ in inputs:\n>     output, state = cell(input_, state)\n>     outputs.append(output)\n>   outputs = tf.pack(outputs, axis=1)\n>   return outputs, state\n>\n> This assumes the time axis is 1. In more recent tensorflow versions,\n> [un]pack has been renamed to [un]stack.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5985#issuecomment-292122739>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim0rbxiPCNfdmX3QipRXehOp8B-JSks5rtLO4gaJpZM4LAZNz>\n> .\n>\n", "@ebrevdo I didn't, I realized from the docs that passing `sequence_length` would again result in dynamic computation. \r\n\r\nEven the authors of the paper Improved WassGan faced this issue it seems (https://www.reddit.com/r/MachineLearning/comments/63dfun/r170400028_improved_training_of_wasserstein_gans/dftqi72/)", "@vrv @ebrevdo Any updates on this thread?", "Any update? Is there already any way of computing second order gradients for dynamic_rnn modules?", "(I'll defer to @ebrevdo for an update on that, but would expressing the model with [eager execution](https://www.tensorflow.org/programmers_guide/eager) be an option that works for you? That may be more natural and will work with higher order gradients. See the [instructional notebooks](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/notebooks)). ", "@ebrevdo @asimshankar Has any progress been made on taking 2nd order gradients in dynamic_rnn ?", "There is work in progress to implement while loops using different\nprimitives. These should allow 2nd order gradients.  Unfortunately there's\nno estimate when this will be ready.\n\nOn Sun, Aug 19, 2018, 5:46 PM pythonanonuser <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> @asimshankar\n> <https://github.com/asimshankar> Has any progress been made on taking 2nd\n> order gradients in dynamic_rnn ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5985#issuecomment-414168300>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1D_HUm-Jfr9sZI0qwXt3t7IEzKdks5uSgbbgaJpZM4LAZNz>\n> .\n>\n", "@ebrevdo Is there a branch or PR you can point me to? Perhaps I can help contribute", "Hi @pythonanonuser, please email me if you'd like to contribute, and I can give you some more context and point you to ways you can help.", "@skye Thanks have emailed you! ", "Any updates? It seems `dynamic_rnn` still can't work with second-derivatives.", "You can try enabling the new while_loop implementation, which supports second derivatives, by setting the environment variable `TF_ENABLE_CONTROL_FLOW_V2=1` (make sure this is set before importing tf). It's still a work in progress, so please file issues for any problems you find! Please see the [design doc](https://github.com/tensorflow/community/blob/master/rfcs/20180821-differentiable-functional-while.md) for more information on the new implementation."]}, {"number": 5984, "title": "Bug report : tf.contrib.learn.train API has a problem", "body": "Hi, everyone\r\n\r\nFirst, please understand that I cannot speak English well\r\n\r\nI tried to use high-level API(tf.contrib) for code simplicity. \r\nWhen I use tf.contrib.learn.train API, I find a problem that execution time per batch increases\r\n\r\nAn example code is described as below \r\n```\r\ntf.conbrib.learn.train(defualt_graph, FLAGS.train_dir, train_op, loss, global_step, max_steps=300,\r\n                                            supervisor_save_summaries_steps = 100)\r\n```\r\n\r\nwhen I run above code, execution time per batch increases after step 100.\r\nSo, I analyzed tf.contrib.learn.train API\r\n\r\nIn **graph_actions.py** file, there is train function and this function calls **_train_internal function** in the same file\r\n\r\nIn _train_internal function, _run_with_monitors function is called for execution of train_op and monitor\r\n\r\n_run_with_monitors function is described as below\r\n```\r\n  for monitor in monitors:\r\n    tensors +=  monitor.step_begin(step)\r\n  tensors = list(set(tensors))\r\n\r\n  outputs = session.run(tensors, feed_dict=feed_dict)\r\n  outputs = dict(zip(\r\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\r\n      outputs))\r\n\r\n  should_stop = False\r\n  for monitor in monitors:\r\n    induce_stop = monitor.step_end(step, outputs)\r\n    should_stop = should_stop or induce_stop\r\n  return outputs, should_stop\r\n```\r\nIn this function, I examined two functions in class EveryN(monitors.py) : **monitor.step_begin**,  **monitor.step_end**\r\n\r\nIn monitor.step_begin function, monitor is executed when the following conditions are fulfilled\r\n```\r\n    if (step <= self._first_n_steps or\r\n        step >= (self._every_n_steps + self._last_active_step) or\r\n        step == self._max_steps):  # Note: max_steps can be None here.\r\n      self._every_n_step_begin_called = True\r\n      return self.every_n_step_begin(step)\r\n```\r\nand monitor.step_end function is described as follows\r\n```\r\n  def step_end(self, step, output):\r\n    super(EveryN, self).step_end(step, output)\r\n    if self._every_n_step_begin_called:\r\n      return self.every_n_step_end(step, output)\r\n    return False\r\n```\r\nIn these codes, I find **self._last_active_step variable** is not updated.\r\nSo, I add the **monitor.post_step function** in _run_with_monitors function as follows\r\n```\r\n  for monitor in monitors:\r\n    tensors += monitor.step_begin(step)\r\n  tensors = list(set(tensors))\r\n\r\n  outputs = session.run(tensors, feed_dict=feed_dict)\r\n  outputs = dict(zip(\r\n      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],\r\n      outputs))\r\n\r\n  should_stop = False\r\n  for monitor in monitors:\r\n    induce_stop = monitor.step_end(step, outputs)\r\n    monitor.post_step(step, session=session)\r\n    should_stop = should_stop or induce_stop\r\n  return outputs, should_stop\r\n```\r\n**monitor.post_step function** performs _last_active_step variable update as follows\r\n```\r\n  def post_step(self, step, session):\r\n    super(EveryN, self).post_step(step, session)\r\n    if self._every_n_step_begin_called:\r\n      self.every_n_post_step(step, session)\r\n      self._last_active_step = step\r\n    self._last_successful_step = step\r\n```\r\n\r\nWhen the code is revised above, tf.contrib.learn.train function is well operated.\r\n", "comments": ["Thanks for the detailed report.", "I apologize for not asking sooner, but  have you had a chance to try this in the latest TensorFlow to see if it is still a problem. Thanks!", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 5983, "title": "[Windows] TensorBoard doesn't work", "body": "I installed the tensorflow for windows with\r\n`pip install --upgrade --ignore-installed https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl`\r\n(I added the '--ignore-installed', for the official one didn't work on my pc)\r\n\r\nThen I tried some code and ran tensorboard, however the browser shows nothing \r\nWhen running with '--debug' there appears some 404.\r\nI also tried tensorboard on mac os, it worked well, so the problem is not caused by the .tfevent file\r\nI've read through a bunch of related issues, and found that maybe the pip install didn't install tensorflow completely. And I searched the tensorflow file and did not found some certain files appears in mac os tensorflow, such as 'paper-toolkit'\r\n\r\n", "comments": ["Have you tried `pip install tensorflow` as [this post](https://developers.googleblog.com/2016/11/tensorflow-0-12-adds-support-for-windows.html) says?", "check [this PR](https://github.com/tensorflow/tensorflow/pull/5844)\r\nIt seems that TensorBoard is not ready for Windows right now.", "As @aaronzs observes, TensorBoard currently doesn't work on Windows. #5844 could work, but the TensorBoard team is changing the way they handle external packages, so a different approach might be necessary.\r\n\r\n@danmane Do you have an estimate of when this will be ready?", "We just merged #5844, which adds TensorBoard support to the master branch. #6020 will add support to the r0.12 branch, and it should appear in the final release.", "I am still getting this issue after `pip` installing the latest version (`0.12.0-rc0`).  Did this make it into the release?", "@drasmuss We haven't made a new release since the #5844 was merged. You can either build it yourself, download a [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/), or wait a few more days until we have a new release candidate.", "I'm closing this for now, since the fix is in. At present, only nightly builds have the fix, but they should be in the imminent `0.12.0rc1` release as well.", "@mrry In Tensorflow protal, there is a command with 0.12.0rc1 version for Windows. \r\n![image](https://cloud.githubusercontent.com/assets/16149289/21174325/7804e11c-c217-11e6-97cd-82610917d196.png)\r\nBut it can't be executed because there is still only 0.12.0rc0 version for Windows in https://storage.googleapis.com/tensorflow/ \r\n![image](https://cloud.githubusercontent.com/assets/16149289/21174362/a8026aa6-c217-11e6-834b-55ef19a3029c.png)\r\nMay I know when the 0.12.0rc1 version will be available for Windows system? ", "I have the problem of the tensorboard cannot show the event data in windows10, 64-bit, tensorflow-gpu-.12.0rc1; it can be solved by making the \"tensorborad.exe\" and the event file in the same disk.", "@emodark: This is a known issue with TensorBoard, because it uses the `:` character in its flags in a way that's incompatible with Windows paths. See #7856 for more discussion and a potential workaround.", "Which is the current state? Is it already possible to run tensorflow on windows?", "Yes, we have been publishing packages for TensorFlow (including TensorBoard) since the final release of version 0.12. AFAIK, the issue with Windows-style paths is still an open issue (see #7856) but there is a workaround that involves specifying a run name.", "Thanks for the fast response @mrry and for the work. Could you elaborate a bit more on that workaround you mention please?", "Here's a [link](https://github.com/tensorflow/tensorflow/issues/7856#issuecomment-282617523) to the explanation.", "Lets continue discussion of this issue within tensorflow/tensorboard#42. We have moved TensorBoard to a new repo outside of tensorflow/tensorflow."]}, {"number": 5982, "title": "tf.dynamic_rnn causes rnn state vector to have an undefined batch size", "body": "Minimal example:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nsess = tf.Session()\r\ninputs = tf.zeros([4, 10, 12], tf.float32)\r\ncell = tf.nn.rnn_cell.BasicLSTMCell(20)\r\nmulticell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)\r\noutput, state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\r\nprint state, '\\n', output\r\n# LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_3:0' shape=(?, 20) dtype=float32>) \r\n# Tensor(\"RNN/transpose:0\", shape=(4, 10, 20), dtype=float32)\r\n```\r\n\r\n[This code](https://github.com/tensorflow/tensorflow/blob/5657d0dee8d87f4594b3e5902ed3e3ca8d6dfc0a/tensorflow/python/ops/rnn.py#L809) seems to be the the where the problem is being caused:\r\n```python\r\n    input_shape = tuple(array_ops.shape(input_) for input_ in flat_input)\r\n    batch_size = input_shape[0][1]\r\n\r\n    for input_ in input_shape:\r\n      if input_[1].get_shape() != batch_size.get_shape():\r\n        raise ValueError(\"All inputs should have the same batch size\")\r\n```\r\nFrom what I understand:\r\n1. `flat_input` is a tuple of tensors\r\n2. thus `input_shape` is a tuple of 1D tensors\r\n3. `batch_size` gets the 2nd element of the 1st `input_shape` tensor, which is a 0D tensor\r\n4. `input_[1]` is the shape of the 1st element of the 1D `input_shape` tensor which is a 0D tensor\r\n5. => `input_[1].get_shape() == batch_size.get_shape() == TensorShape([]) ` for all `flat_input`\r\n\r\nThus regardless of the content of `flat_input`, the `ValueError` will never be raised and batch_size will always be a 0D tensor, unknown until it is evaluated, as opposed to a number.\r\n\r\nRewriting the above code to something that makes more sense to me (below) causes the tests to fail when `dynamic_rnn` is instantiated with variable batch size.\r\n\r\n```python\r\n    input_shape = tuple(input_.get_shape() for input_ in flat_input)\r\n    batch_size = input_shape[0][1]\r\n \r\n    for shape in input_shape:\r\n      if shape[1] != batch_size:\r\n        raise ValueError(\"All inputs should have the same batch size\")\r\n```\r\n\r\nI suppose the question I'm asking is whether it is intended behaviour to throw away the batch size information when it is fixed? If it isn't, I'm happy to write a fix.\r\n\r\nThis was brought to my attention by a subtle bug found when implementing a custom LSTM cell:\r\n\r\n```python\r\nclass VariationalLSTMCell(tf.nn.rnn_cell.BasicLSTMCell):\r\n\t\"\"\"\r\n\tLong short-term memory unit (LSTM) recurrent network cell based on:\r\n\r\n\thttp://arxiv.org/pdf/1512.05287v3.pdf\r\n\r\n\tYarin Gal\r\n\t\"A theoretically grounded application of dropout in recurrent neural networks\"\r\n\t\"\"\"\r\n\tdef __init__(self, num_units, keep_prob_w, keep_prob_u=None, **kwargs):\r\n\t\tsuper(VariationalLSTMCell, self).__init__(num_units, **kwargs)\r\n\t\tself._keep_prob_w = keep_prob_w\r\n\t\tself._keep_prob_u = keep_prob_u if keep_prob_u is not None else keep_prob_w\r\n\t\tself._t0_cell = False\r\n\r\n\tdef __call__(self, inputs, state, scope=None):\r\n\t\t\"\"\"Long short-term memory cell (LSTM).\"\"\"\r\n\t\twith tf.variable_scope(scope or type(self).__name__) as scope:\t# \"VariationalLSTMCell\"\r\n\t\t\tif not scope.reuse:\r\n\t\t\t\tself._t0_cell = True\r\n\r\n\t\t\tif self._state_is_tuple:\r\n\t\t\t\tc, h = state\r\n\t\t\telse:\r\n\t\t\t\tc, h = tf.split(1, 2, state)\r\n\r\n\t\t\tdtype = inputs.dtype\r\n\t\t\tbatch_size, input_size = inputs.get_shape().with_rank(2)\r\n\t\t\tif input_size.value is None:\r\n\t\t\t\traise ValueError(\"Could not infer input size from inputs.get_shape()[-1]\")\r\n\t\t\t(w_i, w_g, w_f, w_o), (u_i, u_g, u_f, u_o) = self.get_weights(input_size, dtype)\r\n\t\t\tb_i, b_g, b_f, b_o = self.get_biases(dtype)\r\n\t\t\t(m_wi, m_wg, m_wf, m_wo), (m_ui, m_ug, m_uf, m_uo) = self.get_dropout_masks(batch_size, input_size)\r\n\r\n\t\t\t# i = input_gate, g = new_input, f = forget_gate, o = output_gate\r\n\t\t\ti = tf.matmul(inputs * m_wi, w_i) + tf.matmul(h * m_ui, u_i) + b_i\r\n\t\t\tg = tf.matmul(inputs * m_wg, w_g) + tf.matmul(h * m_ug, u_g) + b_g\r\n\t\t\tf = tf.matmul(inputs * m_wf, w_f) + tf.matmul(h * m_uf, u_f) + b_f\r\n\t\t\to = tf.matmul(inputs * m_wo, w_o) + tf.matmul(h * m_uo, u_o) + b_o\r\n\r\n\t\t\tnew_c = (c * tf.sigmoid(f + self._forget_bias) + tf.sigmoid(i) * self._activation(g))\r\n\t\t\tnew_h = self._activation(new_c) * tf.sigmoid(o)\r\n\r\n\t\t\tif self._state_is_tuple:\r\n\t\t\t\tnew_state = tf.nn.rnn_cell.LSTMStateTuple(new_c, new_h)\r\n\t\t\telse:\r\n\t\t\t\tnew_state = tf.concat(1, [new_c, new_h])\r\n\t\treturn new_h, new_state\r\n\r\n\tdef get_dropout_masks(self, batch_size, input_size):\r\n\t\twith tf.variable_scope('dropout'):\r\n\t\t\tw_mask = tf.get_variable('w_mask', [4, batch_size.value, input_size.value], tf.float32, tf.ones_initializer, trainable=False)\r\n\t\t\tu_mask = tf.get_variable('u_mask', [4, batch_size.value, self._num_units], tf.float32, tf.ones_initializer, trainable=False)\r\n\t\t\tif self._t0_cell:\r\n\t\t\t\tw_mask = w_mask.assign(tf.random_uniform([4, batch_size.value, input_size.value], dtype=tf.float32))\r\n\t\t\t\tu_mask = u_mask.assign(tf.random_uniform([4, batch_size.value, self._num_units], dtype=tf.float32))\r\n\t\t\tw_mask = tf.maximum(tf.sign(self._keep_prob_w - w_mask), 0) / self._keep_prob_w\r\n\t\t\tu_mask = tf.maximum(tf.sign(self._keep_prob_u - u_mask), 0) / self._keep_prob_u\r\n\t\t\tw_masks, u_masks = [tf.unpack(mask) for mask in [w_mask, u_mask]]\r\n\t\t\treturn w_masks, u_masks\r\n\r\n\tdef get_weights(self, input_size, dtype):\r\n\t\tw_weights = tf.get_variable('w_weights', [4, input_size.value, self._num_units], dtype)\r\n\t\tu_weights = tf.get_variable('u_weights', [4, self._num_units, self._num_units], dtype)\r\n\t\ttf.add_to_collection('weights', w_weights)\r\n\t\ttf.add_to_collection('weights', u_weights)\r\n\t\tw_weights, u_weights = [tf.unpack(weights) for weights in [w_weights, u_weights]]\r\n\t\treturn w_weights, u_weights\r\n\r\n\tdef get_biases(self, dtype):\r\n\t\tbiases = tf.get_variable('biases', [4, self._num_units], dtype, tf.zeros_initializer)\r\n\t\ttf.add_to_collection('biases', biases)\r\n\t\treturn tf.unpack(biases)\r\n```\r\n\r\nWhen `batch_size > 1` this works fine, but when `batch_size == 1` due to the potential to be broadcast, the dimensions of `new_h` and `new_c` cannot be inferred, leading to crashes in higher layers in `get_dropout_masks`. This works fine however with the change to `dynamic_rnn` I mentioned above.\r\n\r\nI'm mainly working in `r0.11`, but I have also observed the issue in master (`5657d0d`) and `0.12.0-rc0`\r\n\r\nPlease let me know if any more information would be helpful.", "comments": ["By the way, I just realized you implemented the same paper (Gal 2015) I am just implementing. Thank you! :-)", "Automatically closing due to lack of recent activity. We hope that you were able to resolve it on your own. However, since this is a support issue rather than a bug or feature request, you will probably get more information by posting it on StackOverflow.", "I believe this is fixed.\n\nOn Jun 16, 2017 10:29 AM, \"Toby Boyd\" <notifications@github.com> wrote:\n\n> Closed #5982 <https://github.com/tensorflow/tensorflow/issues/5982>.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5982#event-1127216156>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzodp25UMzYWQL1joBeJo7q81V0bks5sErt5gaJpZM4LATi7>\n> .\n>\n"]}, {"number": 5981, "title": "Tensorflow profiling overhead", "body": "The profiling mechanism (which by the way really deserves to be documented...) can add a prohibitive large computational overhead to the execution. Specifically, my training script runs 10 times slower with profiling. I stripped it down to a small self-contained [example](https://gist.github.com/rizar/f4556741c2c79c4adf4f47c6ed1cefd7) and the slowdown became just 3x, but I think this is bad enough.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/1824\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nDebian 8.6\r\nCUDA 8.0\r\nCUDNN 5.1.3\r\n\r\nTensorflow was installed by running\r\n\r\n`pip install --user https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nhttps://gist.github.com/rizar/f4556741c2c79c4adf4f47c6ed1cefd7\r\n\r\n\r\n\r\n", "comments": ["From reading your code, there are two likely reasons for this, one fairly obvious, the other less so:\r\n1) Your benchmark measures the overheads of retrieving a large trace protobuf via the `session.run` API.  This includes the cost of serializing trace data into a protobuf and copying back to Python.\r\n2) `BasicLSTMCell` includes quite a large number of tiny elementwise ops, plus one large(ish) MatMul.  Tracing overheads are typically order 1us per op at execution time.  Most of the tiny ops in an LSTM cell execute in less time than this on a GPU.\r\n\r\nWhen I run on my desktop with a K40, I get 1.3s without profiling and 4.0s with profiling.  So basically the same ratio you reported.\r\n\r\nIf you examine the timeline generated from the computation I expect the time spent _computing_ is not much different to your baseline measurement....\r\n\r\nI added code to write out the profile and generate a chrome trace viewer timeline:  \r\n```\r\nprint(len(run_metadata.SerializeToString()))\r\n# Create the Timeline object, and write it to a json\r\ntl = timeline.Timeline(run_metadata.step_stats)\r\nctf = tl.generate_chrome_trace_format()\r\nwith open('timeline.json', 'w') as f:\r\n  f.write(ctf)\r\n```\r\nWhen you look at the captured profiler data you can see that the computation still executes in approx 1.3s.  This is basically identical to the time without profiling (which includes feeding input tensors from Python)\r\n![image](https://cloud.githubusercontent.com/assets/11547801/20807274/178c91f4-b7b3-11e6-9c65-7fdf77dda742.png)\r\n\r\nSo tracing isn't actually slowing down execution by very much.  Retrieving the trace seems to be expensive in this case.\r\n\r\nThe size of the `run_metadata` is about 5MB.... larger than it _could_ be, but I agree that it seems ridiculous that fetching back the extra 5MB takes over 2 seconds.  It's probably worth running under a CPU profiler to work out what's going on here! \r\n", "Interesting - there is a big perf difference between our internal build and the open source install:\r\n\r\nWhen I run the internal build, the step time with tracing (and lots of extra logging) is 1.47s.\r\n```\r\nI1201 13:50:53.102052   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\r\nI1201 13:50:53.106980   24865 direct_session.cc:489] Run\r\nI1201 13:50:53.364928   24865 direct_session.cc:499] Run done\r\nI1201 13:50:53.364971   24865 direct_session.cc:513] Got trace\r\nI1201 13:50:53.364982   24865 direct_session.cc:527] Got outputs\r\nI1201 13:50:53.365004   24865 tf_session_helper.cc:521] To NumPy\r\nI1201 13:50:53.365013   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\r\nI1201 13:50:53.365126   24865 profiling-5981.py:50] Init done.\r\nI1201 13:50:53.365229   24865 profiling-5981.py:62] sess.run\r\nI1201 13:50:53.365682   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\r\nI1201 13:50:53.397088   24865 dso_loader.cc:233] successfully opened CUDA library /google/src/cloud/pbar/triage/google3/third_party/gpus/cuda_7_0/extras/CUPTI/lib64/libcupti.so.7.0.28\r\nI1201 13:50:53.467417   24865 direct_session.cc:489] Run\r\nI1201 13:50:54.774907   24865 direct_session.cc:499] Run done\r\nI1201 13:50:54.781975   24865 direct_session.cc:513] Got trace\r\nI1201 13:50:54.782018   24865 direct_session.cc:527] Got outputs\r\nI1201 13:50:54.816643   24865 tf_session_helper.cc:521] To NumPy\r\nI1201 13:50:54.920562   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\r\nI1201 13:50:54.950649   24865 profiling-5981.py:67] sess.run done\r\nI1201 13:50:54.950703   24865 profiling-5981.py:68] 1.58546686172\r\nI1201 13:50:54.950723   24865 profiling-5981.py:62] sess.run\r\nI1201 13:50:54.951195   24865 tf_session_helper.cc:402] TF_Run_wrapper_helper\r\nI1201 13:50:54.951274   24865 direct_session.cc:489] Run\r\nI1201 13:50:56.217795   24865 direct_session.cc:499] Run done\r\nI1201 13:50:56.224791   24865 direct_session.cc:513] Got trace\r\nI1201 13:50:56.224850   24865 direct_session.cc:527] Got outputs\r\nI1201 13:50:56.263171   24865 tf_session_helper.cc:521] To NumPy\r\nI1201 13:50:56.385349   24865 tf_session_helper.cc:540] TF_Run_wrapper_helper done\r\nI1201 13:50:56.422490   24865 profiling-5981.py:67] sess.run done\r\nI1201 13:50:56.422549   24865 profiling-5981.py:68] 1.47181797028\r\n```\r\n\r\nOne of the first differences btw internal and external builds that I usually try to rule out is the malloc implementation.  (We use TCMalloc, whereas standard Python is compiled against the regular libc heap).\r\n\r\nI tried using TCMalloc as follows:\r\n```\r\nLD_PRELOAD=/usr/lib/libtcmalloc_minimal.so.4 python profiling-5981.py\r\n```\r\nBut still see the same step time... perhaps 100ms faster.\r\n\r\nI couldn't see anything obvious running under the CPU profiler either .... will keep looking, since this is a little suspicious.\r\n", "This is most likely a protobuf issue... can you please check the output of the following:\r\n```\r\n$ python\r\n>>> import google.protobuf.internal.api_implementation as ai\r\n>>> ai.Type()\r\n```\r\nIf this prints `'python'` (as opposed to `'cpp'`) then you probably need to install the fast protobuf library as described here: \r\nhttps://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#protobuf-library-related-issues", "@rizar After I do the following, my step time with profling comes down to 1.45s:\r\n```\r\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0-cp27-none-linux_x86_64.whl\r\n```\r\n\r\nPlease reopen if this doesn't fix your problem.\r\n"]}, {"number": 5980, "title": "fix broken link in docs", "body": "This fixes issue #5978", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 5979, "title": "Translate.py - Added the option to translate a file ", "body": "With this pull request you can easily translate/test a batch of sentences, which makes it easier to see how good your trained model is. \r\n\r\nIf you specify a filename this functionality is used, if you don't specify anything the script continues to function as it used to. ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Can you move this PR over to github.com/tensorflow/models? We have moved the models to that repo. You can call out @nealwu for a review."]}, {"number": 5978, "title": "Broken link in \"A Tool Developer's Guide...\" for graph_run_run2.pbtxt", "body": "The link for `graph_run_run2.pbtxt` is broken in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/tool_developers/index.md", "comments": ["thanks for the PR.  ", "the same for the graph_metrics.py link there", "graph_metrics.py is being fixed by #5917 "]}, {"number": 5977, "title": "split_v generates tensors of unspecified size for all dimensions, when one dimension is missing at the original one", "body": "The new split_v function introduced in 0.12rc0 does not correctly predict the shapes of the resulting tensors when the original tensor has an unknown dimension, resulting on the split dimension being of unknown size. For instance:\r\n\r\n```\r\ntensor = tf.placeholder(tf.float32, [None, 12])\r\nparts = tf.split_v(tensor, [6, 4, 2], split_dim=1)\r\n```\r\n\r\nThis results in three tensors, all with shapes [?, ?], instead of the expected [?, 6], [?, 4] and [?, 2]. While at runtime the resulting tensors are of the right size, this makes it more difficult to debug the code during graph definition.\r\n\r\nEDIT: This also creates problems when combined with scan. Because scan expects fn to return tensors of the same shape as the initializers, it forces the use of a reshape just to clear the 'unknown' dimension.", "comments": ["Shape inference is done in C++, not python, and at that point everything is a tensor and it is not possible to inspect the contents of tensors during shape inference.  So, in general, it is not possible to provide any better shape information beyond the rank.\r\n\r\nThat said, we can hack the python interface to check if the size list is a list of integers and not a tensor and then reshape the outputs correctly.  Is that your use case?  Or do you generate the size list dynamically?  Because if it is dynamically generated, there is no way to do the shape inference that you want.\r\n\r\n*By dynamically, I mean as part of the TF graph.", "Hello ekelsen, yes that is my case. The list provided to split_v is a list of integers, so the size for this dimension is provided.", "This feature should be added before the next release.  Note that this shape inference behavior will be optional as it will add a reshape operation to every output tensor which could be a performance penalty, especially when there are many output tensors (1000+) and the tensors are small.", "Thank you in advance. Nevetheless, I'm a little bit confused as to why a reshape for each output tensor is required. I'm not familiar with how tensorflow works internally, but even if the tensor operation itself has no information on the tensor shape other than the rank, shouldn't it be possible to set the output tensors dimension to the provided values (if these are given as integers) without having to add a reshape operator? After all, under these circumstances the output is guaranteed to have this shape for the split dimension, a reshape seems unnecessary to enforce this.", "Sorry, yes you're correct that all that's needed here is to set the shape."]}, {"number": 5976, "title": "More similar typo to #5973", "body": "", "comments": ["Can one of the admins verify this patch?", "Please revert the markdown files, those are automatically-generated from the source"]}, {"number": 5975, "title": "no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package ", "body": "when I run inceptionv3, tensorflow/examples/image_retraining, I encounter a problem\uff0ci go to the root directory and run:\r\n`bazel build tensorflow/examples/image_retraining:retrain` or `bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain`:\r\nit appear the same error :\r\n\r\n`\r\nERROR: /home/duan/tensorflow/tensorflow/core/BUILD:1121:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /home/duan/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: /home/duan/tensorflow/tensorflow/core/BUILD:1121:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /home/duan/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: /home/duan/tensorflow/tensorflow/core/BUILD:1121:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /home/duan/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: Analysis of target '//tensorflow/examples/image_retraining:retrain' failed; build aborted.\r\nINFO: Elapsed time: 4.179s\r\n`\r\nhow to slove this problem?\r\n\r\nand my content is\uff1a\r\n\r\n`tensorflow-\r\n           +-tensorflow\r\n           +-third_party\r\n           +-tools\r\n           +-util\r\n           +-......\r\n           +-......\r\n`\r\nbazel version:\r\n`\r\nBuild label: 0.4.0\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Nov 2 17:54:14 2016 (1478109254)\r\nBuild timestamp: 1478109254\r\nBuild timestamp as int: 1478109254\r\n`\r\nmy operating system is\uff1a\r\n`Linux ubuntu 3.13.0-24-generic #46-Ubuntu SMP Thu Apr 10 19:11:08 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux`\r\nand  my TensorFlow version is cpu version\uff1a\r\n`python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n0.9.0\r\n`\r\n", "comments": ["Please see #4279", "I met this too"]}, {"number": 5974, "title": "tensorboard visualize embedding error", "body": "env: tensorflow v. 0.12.0 RC0\r\n\r\nFollowing the [instructions](https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html#tensorboard-embedding-visualization), I use tensorboard to visualize embeddings (without any metadata) and comes the following error:\r\n\r\n> File \"/home/morphe/miniconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/tensorboard/plugins/projector/plugin.py\", line 139, in configs\r\n    run_path_pairs.append(('.', self.logdir))\r\nAttributeError: 'dict_items' object has no attribute 'append'\r\n\r\nIt seems to work if I attempt to change `tensorflow/tensorboard/plugins/projector/plugin.py`:\r\n```\r\n- run_path_pairs.append(('.', self.logdir))\r\n+ run_path_pairs = [('.', self.logdir)]\r\n```\r\n\r\nNot sure if this is the right way to go. Is this a bug?", "comments": ["Hi,\r\n\r\nIt turns out to be a python3 issue where dict.items() doesn't return an appendable list, like in python2.\r\n\r\nWe've fixed the issue internally, and the commit will show up in 1-2 days. Then a build from master should work. We will also make sure to include this fix in 0.12 RC1.\r\n\r\nThank you!", "Just an FYI I get the same issue with 0.12 RC1 and Python 3. Python 2 works fine.", "Thanks for letting us know. The fix didn't make it in RC1, but I'm following up and making sure we get it in RC2  (and potentially in an updated RC1)\r\n\r\nThanks!"]}, {"number": 5973, "title": "Fix #5946.", "body": "Fix error in documentation about global_variables_initializer.", "comments": ["Jenkins, test this please."]}, {"number": 5972, "title": "optimize variable with dynamic shape not supported", "body": "TensorFlow 0.11.0.\r\n\r\nI want to use a variable where the shape is unknown in advance and it will change from time to time (although ndim is known and fixed).\r\n\r\nI declare it like:\r\n\r\n```\r\ninitializer = tf.random_uniform_initializer()\r\nshape = (s0, s1, s2)  # these are symbolic vars\r\nfoo_var = tf.Variable(initializer(shape=shape), name=\"foo\", validate_shape=False)\r\n```\r\nThis seems to work when I create the computation graph up to the point where I want to optimize w.r.t. this variable, i.e.:\r\n```\r\noptimizer = tf.train.AdamOptimizer(learning_rate=0.1, epsilon=1e-4)\r\noptim = optimizer.minimize(loss, var_list=[foo_var])\r\n```\r\n\r\nThat fails in the optimizer in some function `create_zeros_slot` where it seems to depend on the static shape information (it uses `primary.get_shape().as_list()`).\r\n\r\nSo, using the optimizer works only with variables with static shape? Is that a bug?\r\n\r\nMy current solution is some hacky monkey patching:\r\n```\r\ndef _tf_create_slot_var(primary, val, scope):\r\n  \"\"\"Helper function for creating a slot variable.\"\"\"\r\n\r\n  from tensorflow.python.ops import variables\r\n  slot = variables.Variable(val, name=scope, trainable=False, validate_shape=primary.get_shape().is_fully_defined())\r\n  # pylint: disable=protected-access\r\n  if isinstance(primary, variables.Variable) and primary._save_slice_info:\r\n    # Primary is a partitioned variable, so we need to also indicate that\r\n    # the slot is a partitioned variable.  Slots have the same partitioning\r\n    # as their primaries.\r\n    real_slot_name = scope[len(primary.op.name + \"/\"):-1]\r\n    slice_info = primary._save_slice_info\r\n    slot._set_save_slice_info(variables.Variable.SaveSliceInfo(\r\n        slice_info.full_name + \"/\" + real_slot_name,\r\n        slice_info.full_shape[:],\r\n        slice_info.var_offset[:],\r\n        slice_info.var_shape[:]))\r\n  # pylint: enable=protected-access\r\n  return slot\r\n\r\n\r\ndef _tf_create_zeros_slot(primary, name, dtype=None, colocate_with_primary=True):\r\n  \"\"\"Create a slot initialized to 0 with same shape as the primary object.\r\n\r\n  Args:\r\n    primary: The primary `Variable` or `Tensor`.\r\n    name: Name to use for the slot variable.\r\n    dtype: Type of the slot variable.  Defaults to the type of `primary`.\r\n    colocate_with_primary: Boolean.  If True the slot is located\r\n      on the same device as `primary`.\r\n\r\n  Returns:\r\n    A `Variable` object.\r\n  \"\"\"\r\n  if dtype is None:\r\n    dtype = primary.dtype\r\n  from tensorflow.python.ops import array_ops\r\n  val = array_ops.zeros(\r\n      primary.get_shape().as_list() if primary.get_shape().is_fully_defined() else tf.shape(primary),\r\n      dtype=dtype)\r\n  from tensorflow.python.training import slot_creator\r\n  return slot_creator.create_slot(primary, val, name, colocate_with_primary=colocate_with_primary)\r\n\r\n\r\ndef monkey_patch_tf_slot_creator():\r\n    \"\"\"\r\n    The TensorFlow optimizers cannot handle variables with unknown shape.\r\n    We hack this.\r\n    \"\"\"\r\n    from tensorflow.python.training import slot_creator\r\n    slot_creator._create_slot_var = _tf_create_slot_var\r\n    slot_creator.create_zeros_slot = _tf_create_zeros_slot\r\n```\r\n\r\n(That was also asked [on StackOverflow](http://stackoverflow.com/questions/40863082/optimize-variable-with-dynamic-shape/).)", "comments": ["@albertz Your comment on StackOverflow \r\n\r\n> During optimization, it wont change. At some point, I reset it explicitly to a new value which will likely have another shape. Then I want to do optimization again. I don't want to recreate the computation graph every time\r\n\r\nThis is something that TensorFlow does not support. In a TensorFlow graph, shape of variables have to be fixed at graph construction time. When you want to \"reset\" to a new value with a different shape, you have to essentially reconstruct the rest of the graph. This is by design and not a bug. Closing this one.", "@keveman Well, with my suggested fix, it works (as far as I can see). And this is just a simple check. Why should this not be added?", "@albertz Sorry, I was too quick to pull the trigger on this one. What you are trying to do is morally equivalent to the following code, which is supported by TensorFlow :\r\n\r\n    import tensorflow as tf\r\n    sess = tf.InteractiveSession()\r\n\r\n    init = tf.placeholder(tf.float32)\r\n    a = tf.Variable(init,validate_shape=False)\r\n\r\n    b = a+1\r\n    c = tf.gradients(b, a)[0]\r\n\r\n    # run the graph with [1] as the shape for the variable a\r\n    sess.run(a.initializer, feed_dict={init: [1.0]})\r\n    c_val = c.eval()\r\n    print(c_val)\r\n\r\n    # run the graph with [2] as the shape for the variable a\r\n    sess.run(a.initializer, feed_dict={init: [1.0, 2.0]})\r\n    c_val = c.eval()\r\n    print(c_val)\r\n\r\nAlthough I have to say, this use case is pretty esoteric. It looks like we can support this in the `AdamOptimizer`. Feel free to send PR. I am reopening this and marking as 'contributions welcome'.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 5971, "title": "Very strange issue on estimator predict function", "body": "Yesterday, I use the tf.contrib.learn.LinearClassifier to fit my data and predict the result. Every thing works fine. The predict function will return an numpy array of label.\r\n\r\nToday I use the same LinearClassifier, it give me the warning like this:\r\nWARNING:tensorflow:From /s/chopin/l/grad/tthhmm/miniconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:454 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\n\r\nAnd the predict function just return <generator object _as_iterable at 0x7fb490fe1f68>. I have no idea how to use these function any more. I don't know where I can find SKCompat class from tensorflow also. ", "comments": ["The contrib code is not strongly supported.  I found this documentation page.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard3/tf.contrib.learn.Estimator.md\r\n\r\nThis forum is for bug reports.  Usage questions best asked on stackoverflow.", "@poxvoculi link is not working anymore ", "https://www.tensorflow.org/extend/estimators"]}, {"number": 5970, "title": "[Windows] How to install cuDNN and enable GPU for Windows?", "body": "Operating System: Windows 10\r\n\r\nHere is what I got when tried to import tensorflow (which is successful in itself):\r\n\r\n`C:\\Users\\GoBack>python\r\nPython 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1\r\n900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll\r\nlocally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll l\r\nocally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll local\r\nly\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll\r\nlocally\r\n>>>`\r\n\r\nIt seems that the Cuda Toolkit can be installed properly, but cuDNN may not. Besides, I didn't see any instructions about this matter in the Tutorials or the Release notes.\r\nThanks a lot in advance!", "comments": ["This looks like the same problem as #5968, so I'm going to close this as a duplicate. Please look at  my response there and let me know on that thread if it solves the problem. Thanks!"]}, {"number": 5969, "title": "fixed the argscope example", "body": "There was a problem with the padding offset, and inconsistent use of \"slim.\" prefix.", "comments": ["Can one of the admins verify this patch?", "@KyotoSunshine can you resolve the conflict?", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->", "After resolving the conflict, the change is empty. I'll merge it, but I guess it will disappear."]}, {"number": 5968, "title": "[Windows] Tensorflow GPU fails to find CUDA.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n**NONE** (Tensorflow for Windows is very new).\r\n\r\n### Environment info\r\nOperating System: Windows 8.1 (Conda 4.2.9)\r\n\r\n`conda --version\r\nconda 4.2.9`\r\n\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n`nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Sat_Sep__3_19:05:48_CDT_2016\r\nCuda compilation tools, release 8.0, V8.0.44`\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n`pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl`\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\n`python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n0.12.0-rc0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally\r\n`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nWhat I did:\r\nI attempt to run some tensorflow code that works within ubuntu CPU instance. \r\n\r\nCode:\r\nMNIST simple autoencoder (requires MNIST dataset);\r\n[CODE](https://gist.github.com/kingtaurus/ae5b38b07cbf3775992ca7be479bb45c)\r\n\r\nError Message [error_message](https://gist.github.com/kingtaurus/3f75835b33501ba51be7fccb0fb0ab8e):\r\n```\r\nIn [10]: %run CNN_autoencoder.py\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll\r\nlocally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll l\r\nocally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll local\r\nly\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll\r\nlocally\r\nExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\r\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\r\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 965M\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.9495\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.86GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:916] 0:   Y\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (d\r\nevice: 0, name: GeForce GTX 965M, pci bus id: 0000:01:00.0)\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:586] Could not identify NUMA node of /job:loca\r\nlhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been bu\r\nilt with NUMA support.\r\nWARNING:tensorflow:From C:\\Users\\Gregoty\\Programming\\cs231n\\repo\\project\\tensorf\r\nlow\\autoencoder\\CNN_autoencoder.py:188 in <module>.: initialize_all_variables (f\r\nrom tensorflow.python.ops.variables) is deprecated and will be removed after 201\r\n7-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nnumber of test       =  10000\r\nnumber of train      =  55000\r\nnumber_of validation =  5000\r\nDone splitting up test data set;\r\nStarting training loop.\r\nEpoch:  0\r\nShuffling the training data;\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_dnn.cc:221] Check failed: s.ok() could not find cudnnCreat\r\ne in cudnn DSO; dlerror: cudnnCreate not found\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nTried running it through `ipython` (conda), `python` (initiated by msys2)\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["Sorry for the poor formatting.\r\n\r\nAdditional relevant information:\r\n(1) Correct Device is found.\r\n```\r\nIn [7]: sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 965M\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.9495\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.86GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:916] 0:   Y\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (d\r\nevice: 0, name: GeForce GTX 965M, pci bus id: 0000:01:00.0)\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_device.cc:586] Could not identify NUMA node of /job:loca\r\nlhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been bu\r\nilt with NUMA support.\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 965M, pci\r\nbus id: 0000:01:00.0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\direct_session.cc:255] Device mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 965M, pci\r\nbus id: 0000:01:00.0\r\n```\r\n\r\n(2) Simple matrix multiplication works (and goes onto the GPU);\r\n```\r\nIn [8]: a = tf.random_normal((100,100))\r\n\r\nIn [9]: b = tf.random_normal((100,500))\r\n\r\nIn [10]: c = tf.matmul(a,b)\r\n\r\nIn [11]: sess.run(c)\r\nrandom_normal_1/RandomStandardNormal: (RandomStandardNormal): /job:localhost/rep\r\nlica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal_1/RandomStandardNormal: (Ran\r\ndomStandardNormal)/job:localhost/replica:0/task:0/gpu:0\r\nrandom_normal_1/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal_1/mul: (Mul)/job:localhost/r\r\neplica:0/task:0/gpu:0\r\nrandom_normal_1: (Add): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal_1: (Add)/job:localhost/repli\r\nca:0/task:0/gpu:0\r\nrandom_normal/RandomStandardNormal: (RandomStandardNormal): /job:localhost/repli\r\nca:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal/RandomStandardNormal: (Rando\r\nmStandardNormal)/job:localhost/replica:0/task:0/gpu:0\r\nrandom_normal/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal/mul: (Mul)/job:localhost/rep\r\nlica:0/task:0/gpu:0\r\nrandom_normal: (Add): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal: (Add)/job:localhost/replica\r\n:0/task:0/gpu:0\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] MatMul: (MatMul)/job:localhost/replica:0/t\r\nask:0/gpu:0\r\nrandom_normal_1/stddev: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal_1/stddev: (Const)/job:localh\r\nost/replica:0/task:0/gpu:0\r\nrandom_normal_1/mean: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal_1/mean: (Const)/job:localhos\r\nt/replica:0/task:0/gpu:0\r\nrandom_normal_1/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal_1/shape: (Const)/job:localho\r\nst/replica:0/task:0/gpu:0\r\nrandom_normal/stddev: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal/stddev: (Const)/job:localhos\r\nt/replica:0/task:0/gpu:0\r\nrandom_normal/mean: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal/mean: (Const)/job:localhost/\r\nreplica:0/task:0/gpu:0\r\nrandom_normal/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\simple_placer.cc:827] random_normal/shape: (Const)/job:localhost\r\n/replica:0/task:0/gpu:0\r\nOut[11]:\r\narray([[ 10.14889431,  -7.62123919,  -1.77695155, ...,  -3.52391839,\r\n         -4.05815506,   8.25485229],\r\n       [-15.96041965,  -4.74459457,  -4.31855917, ...,   2.38201094,\r\n          1.88767397,  11.53111267],\r\n       [-16.73142433,  -6.41328716,   3.74670029, ...,  -0.70338029,\r\n         11.00368786,  -9.65341663],\r\n       ...,\r\n       [ -0.36278108,  11.4246645 , -10.04188251, ...,   1.75270677,\r\n         14.56924343,  -1.01836491],\r\n       [-23.42072105,  -8.07039452,  11.91343594, ..., -13.5128355 ,\r\n          9.64110279,  16.35452461],\r\n       [ 13.46339703,  16.37274551,  -6.37776566, ...,   1.38949025,\r\n          9.08513069,   3.71655941]], dtype=float32)\r\n\r\nIn [12]:\r\n```\r\n\r\n**Problem Appears to be with `cudnn`**\r\n\r\n\r\n", "A few quick questions to figure out the problem:\r\n\r\n1. Have you installed CuDNN, and if so, to what directory? (It should contain the file `cudnn64_5.dll`.)\r\n2. Is that directory in your `%PATH%` environment variable?\r\n3. If not, and you add that directory to your `%PATH%` environment variable, does that fix the problem?", "I was missing the `cudnn64_5.dll` (I did a quick search and the file wasn't found). I'll download the file and check to see if this fixes the problem.", "Thanks. This was the problem (I hadn't placed cudnn in the proper location) - I copied it into the nVidia CUDA install location. I downloaded [Windows 7 Version cuDNN](https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v5.1/prod/8.0/cudnn-8.0-windows7-x64-v5.1-zip) - incase other people are wondering.\r\n\r\nI then copied the `cudnn64_5.dll` (`cuda\\bin\\cudnn64_5.dll`) from that zip archive into `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin\\`; \r\n\r\n`cuda\\include\\cudnn.h` to `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\include\\`; \r\n\r\nand \r\n\r\n`cuda\\lib\\x64\\cudnn.lib` to `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\lib\\x64\\`\r\n\r\n**WHERE** `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0` is my install PATH for the CUDA toolkit.\r\n\r\nI had already added `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin\\` to my PATH (you need to make sure this is done too).\r\n\r\n", "This should be added to the install instructions for running Tensorflow with Windows.", "I have the same problem, but my library cudnn64_5.dll is loaded correctly ?\r\n\r\nC:\\Users\\Ron>python\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally\r\n>>> import numpy as np\r\n>>> x_data = np.random.rand(100).astype(np.float32)\r\n>>> y_data = x_data * 0.1 + 0.3\r\n>>> W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\r\n>>> b = tf.Variable(tf.zeros([1]))\r\n>>> y = W * x_data + b\r\n>>> loss = tf.reduce_mean(tf.square(y - y_data))\r\n>>> optimizer = tf.train.GradientDescentOptimizer(0.5)\r\n>>> train = optimizer.minimize(loss)\r\n>>> init = tf.global_variables_initializer()\r\n>>> sess = tf.Session()\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 960\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2785\r\npciBusID 0000:01:00.0\r\nTotal memory: 4.00GiB\r\nFree memory: 3.33GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:916] 0:   Y\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0)\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA support.", "@rleplae I posted an answer to your question [on Stack Overflow](http://stackoverflow.com/a/40892205/3574081): this is a benign warning that can be ignored. Please comment there if it doesn't solve the problem!", "Same issue as **rleplae** everything is successfully opened however the \"Your kernel may not have been built with NUMA support.\" appears and then my entire system is frozen for 20-30 minutes. After that the error appears again and my system is frozen again for the same amount of time etc in a loop. I'm running a single GPU setup so it's odd that this is having such a significant impact.\r\n\r\n> I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 1070\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\r\npciBusID 0000:01:00.0\r\nTotal memory: 8.00GiB\r\nFree memory: 6.68GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:916] 0:   Y\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA support.\r\n\r\n", "And dont forget to restart. ", "C:\\Users\\snow>python\r\n\r\nPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AM\r\n\r\nD64)] on win32\r\n\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nimport tensorflow as tf\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\n\r\nam_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll\r\n\r\nlocally\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\n\r\nam_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll lo\r\n\r\ncally\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\n\r\nam_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll l\r\n\r\nocally\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\n\r\nam_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll local\r\n\r\nly\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\n\r\nam_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll\r\n\r\nlocally\r\n\r\nhello = tf.constant('Hello,TensorFlow')\r\n\r\nsess = tf.Session()\r\n\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\n\r\nam_executor\\cuda\\cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: snow-PCI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_diagnostics.cc:165] hostname: snow-PC\r\n\r\n\r\n\r\n", "You don't need to overwrite the files in the CUDA\\v8.0 directory. Just paste them from the respective ones in cudnn (i.e. move cudnn64_5.dll  inside the CUDA\\v8.0\\bin directory, etc.)", "i have the same problem \r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n\r\n", "I have a similar issue as @snowluliang \r\nOS: Windows 7, GPU Quadro 2000M\r\nPython 3.5.0 |Anaconda custom (64-bit)| (default, Dec  1 2015, 11:46:22) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally\r\n>>> sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: myhostname\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_diagnostics.cc:165] hostname: myhostname\r\nDevice mapping: no known devices.\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\direct_session.cc:257] Device mapping:", "@raoanonymous  you solve it? you can try this \r\n\r\n> You don't need to overwrite the files in the CUDA\\v8.0 directory. Just paste them from the respective ones in cudnn (i.e. move cudnn64_5.dll inside the CUDA\\v8.0\\bin directory, etc.)\r\n", "@snowluliang  I tried as you suggested, it didn't solve my problem.", "your error message:\r\n> win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n\r\nhave you install **CUDA\u00ae Toolkit 8.0** and **cuDNN v5.1** ?\r\n\r\n>  sess = tf.Session()\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtim\r\ne\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 850M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 0.9015\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.69GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtim\r\ne\\gpu\\gpu_device.cc:906] DMA: 0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtim\r\ne\\gpu\\gpu_device.cc:916] 0:   Y\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtim\r\ne\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX\r\n850M, pci bus id: 0000:01:00.0)\r\n\r\nyour error message doesn't have this message  \r\n\r\n> name: GeForce GTX 850M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 0.9015\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.69GiB\r\n\r\n[see here](https://www.tensorflow.org/install/install_windows)\r\n", "@snowluliang  I think I have both Cuda 8.0 and cudNN 5.1\r\n```\r\nC:\\Program Files\\NVIDIA Corporation\\NVSMI>nvcc -V\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Mon_Jan__9_17:32:33_CST_2017\r\nCuda compilation tools, release 8.0, V8.0.60\r\n```\r\n\r\n![image](https://cloud.githubusercontent.com/assets/24497120/24913815/f8b25d6e-1eef-11e7-98e6-28d14415102e.png)\r\n\r\nMy GPU is different from yours\r\n```\r\nC:\\Program Files\\NVIDIA Corporation\\NVSMI>nvidia-smi.exe\r\nMon Apr 10 18:37:06 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 376.51                 Driver Version: 376.51                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Quadro M2000M      WDDM  | 0000:01:00.0     Off |                  N/A |\r\n| N/A   39C    P8    N/A /  N/A |     99MiB /  4096MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n```\r\nWhenever I try to run ```tf.Session()``` I get the error:\r\n\r\n![cuda_error](https://cloud.githubusercontent.com/assets/24497120/24913967/6b9e08c8-1ef0-11e7-9ad1-4d215f49de03.png)\r\n\r\nIt would be of great help if anyone can point out what I am missing out.\r\n", "as of 14/4/2017 if you're downloading the cuDNN `[Download cuDNN v6.0 (March 23, 2017), for CUDA 8.0]`\r\npay attention that TF will still look for **cudnn64_5.dll** , while the cuDNN contains **cudnn64_6.dll**\r\nI was able to fix this by simply renaming the file **cudnn64_6.dll** -> **cudnn64_5.dll**", "kaminskypavel that fixed it! Thanks :)\r\n\r\n>>> import tensorflow as tf\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally\r\n>>>", "@kaminskypavel  that fixed my issue as well. Thank you!", "I have met this problem when I work on assignment 4 with my windows machine(CUDA 8.0, cudnn 6.0), the error message is as follows:\r\n\r\n![](http://wx4.sinaimg.cn/large/778d5ca9gy1fey1qxbmnsj20op0gnwgc.jpg)\r\n![](http://wx4.sinaimg.cn/mw690/778d5ca9gy1fey1qymfbqj20op0gn763.jpg)\r\n![](http://wx1.sinaimg.cn/mw690/778d5ca9gy1fey1qzdv84j20op0gnwga.jpg)\r\n![](http://wx3.sinaimg.cn/mw690/778d5ca9gy1fey1r02o2wj20pq0iijtj.jpg)\r\n\r\nIt was strange that this problem was never happening before the first 3 assigment, and the assignment(1-3) code could run as well. \r\n\r\nI google it for solutions, and do it as the @kingtaurus @mrry methods, problem still there, I really don't know what happend, is that because I am using windows???", " renaming the file **cudnn64_6.dll** -> **cudnn64_5.dll**", "copying as @kingtaurus suggestetd and renaming as @snowluliang suggested solved my same problem.", "@swordspoet i melt same problem,did you solved it? ", "@kaminskypavel  I  rename the file cudnn64_6.dll -> cudnn64_5.dll but it does not work . And i have the error  \"ImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\"   ", "\u53bb\u641c\u4e00\u4e0b\u9519\u8bef\u4fe1\u606f\u5457", "@liygzting Can you double check if you have added the path of cudnn65_5.dll in your PATH?\r\nSee the 4th comment of @kingtaurus ", "I haven't been able to solve my problem with the answers in this thread alone.\r\n\r\nI had just downloaded a nightly build of tensorflow. No matter what, it would not find my GPU. I then did\r\n\r\n`pip install --upgrade tensorflow-gpu`\r\n\r\nand it upgraded my tensorflow gpu version from 1.2.1 to 1.4.0. Then I got a new error message prompting me to give cudnn64_6 rather than cudnn64_5. I downloaded the most recent version of CUDNN 6 from NVIDIA which indeed gives cudnn64_6.dll now. Everything works", "I just checked to see if there are any files in the folder,\r\nand repeated the instructions, and it helped.\r\n\r\nCopy the following files into the CUDA Toolkit directory.\r\nCopy <installpath> \\ cuda \\ bin \\ cudnn64_7.dll to C: \\ Program Files \\ NVIDIA GPU Computing Toolkit \\ CUDA \\ v9.0 \\ bin.\r\nCopy <installpath> \\ cuda \\ include \\ cudnn.h to C: \\ Program Files \\ NVIDIA GPU Computing Toolkit \\ CUDA \\ v9.0 \\ include.\r\nCopy <installpath> \\ cuda \\ lib \\ x64 \\ cudnn.lib to C: \\ Program Files \\ NVIDIA GPU Computing Toolkit \\ CUDA \\ v9.0 \\ lib \\ x64.\r\n\r\n\r\nRead more at: http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#ixzz56wCXCTwH\r\nFollow us: @GPUComputing on Twitter | NVIDIA on Facebook", "And dont forget to restart. it is really important, which waste me 30 min...."]}, {"number": 5967, "title": "seperable -> separable", "body": "fixed grammatical error", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it.", "CLAs look good, thanks!\n\n<!-- ok -->", "Thanks"]}, {"number": 5966, "title": "How to map '\\n' to id in a metadata.tsv when visualizing embedding", "body": "I'm quite excited about the new embedding visualization feature in TF 0.12.0-RC0. But when I walk through the [new documentation page](https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html#tensorboard-embedding-visualization) in the metadata part, it says that the metadata has the exact format with first line as header and others as fields.\r\n\r\nWhat if I have to map char '\\n' to id? In this way, the specific format of tsv file will broken. This is often the case in most NLP tasks. \r\n\r\nHope the developer will explain this. thanks.", "comments": ["Hi @leido,\r\n\r\nYou would have to represent the newline character as \"\\n\" (a 2 characters string). We chose the TSV format since it is well know, human-readable, and allows for white space in labels. If we get a big push on this, we will reconsider switching to another format.\r\n\r\nThanks for reporting this!"]}]