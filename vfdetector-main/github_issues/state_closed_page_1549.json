[{"number": 6451, "title": "ig", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": []}, {"number": 6450, "title": "Branch 142716019", "body": "", "comments": []}, {"number": 6449, "title": "Using OpenCL on macOS", "body": " Thank you very much for developing nice framework. I have a question about OpenCL support for macOS. Is there no way to run tensorflow with GPU on recent MacBookPro?  Tensorflow support OpenCL. But I think this is for Linux, not for macOS. Tensorflow + OpenCL need ComputeCpp. But ComputeCpp compiler do not support macOS(I couldn't find ComputeCpp binary for mac). Do you have a plot to support recent MacBook pro's GPU? ", "comments": ["OpenCL  support is tracked on  #22   ", "@lukeiwanski maybe have more information on the ComputeCpp plan for MacOS", "Hello @k-hashimoto,\r\nCurrently, unfortunately no, you cannot use ComputeCpp on macOS.\r\nAs of today, SPIR 1.2 ( https://www.khronos.org/spir ) support is essential for ComputeCpp to work on any platform and it boils down to Apple not providing SPIR 1.2 support yet.\r\n\r\nmacOS support is definitely an important milestone on our roadmap - a lot of developers are asking for it - and the support should be available in the future.\r\n\r\nPerhaps http://www.apple.com/feedback/ would speed it up :)\r\n\r\nThanks,\r\nLuke", "OK. Thanks!", "@lukeiwanski What do you think to rely on something similar to SPIR-V MSL translability https://github.com/KhronosGroup/SPIRV-Cross/blob/master/README.md?", "@bhack at the moment we target SPIR. It might be possible to translate that into other formats but at the moment we output SPIR 1.2 only. SPIR-V is an interesting format but we cannot emit it right now.", "@lukeiwanski Will XLA impact also your effort?", "Closing for now. Please reopen if there's a specific issue beyond those tracked in #22.", "@lukeiwanski Now that a first version of XLA it s released what do you think of https://github.com/tensorflow/tensorflow/issues/22#issuecomment-272426528?"]}, {"number": 6448, "title": "Documentation request: leave all function names on the sidebar", "body": "Before, I found it really nice that I could `ctrl+f` to look up a function really quickly. Now I either have to Google it or use the search bar, or worse, scan through the hierarchy and click a few times and scroll til I find it. Not a huge deal, but relatively painful.\r\n\r\nIt was nice to get instant search results for even partial bits of function names.", "comments": ["I agree this was nice to be able to have one page to search around, but they may not think this would scale as the TensorFlow API grows.\r\n\r\nI also just can't help acknowledging that, at some level, this is a complaint about having to Google that's being delivered to Google. :-)", "@wolffg, don't know if there is an easy way to get a ctrl-f'able page.\r\n", "I think I understand your request, and it was a use case we thought about.  The landing page:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/\r\n\r\nis designed to be complete index that you could use ctrl-f to hunt around in.  Does that cover your use case?  Is it missing functions?\r\n", "That's the right idea - I still think it would be an improvement to the current sidebar. I guess you folks would have to A-B test it or something to see how much people use the sidebar the way it is vs. the comprehensive API list.", "After some further discussion, I don't think this is something we're going to pursue---an unrolled list like that is functionally a multipage hidden index on every page, which isn't really useful as left navigation, and (as noted above) won't scale as we add more packages.\r\n\r\nThe API landing page has an entire index and comments available for text search, and we're working on ways to make site search more accurate.  I'm going to close this issue, however.", "Discussion is good enough for me. Thanks for looking into it."]}, {"number": 6447, "title": "Improved support for OpenCL", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "All CLAs signed. Googlebot wont change final status because of merge PR bug.\r\nOnce the final test finishes, good to go."]}, {"number": 6446, "title": "TF_CUDA_VERSION and TF_CUDNN_VERSION can be too specific", "body": "If you run `./configure` and provide your own `TF_CUDA_VERSION` and `TF_CUDNN_VERSION`, you will get an error message if your version is too specific.\r\n\r\nFor example, setting `TF_CUDA_VERSION=7.5.18` will result in an error when `nvcc` reports a version `7.5`. If you set `TF_CUDNN_VERSION=5.1.3`, you get an error because `cudnn.h` reports version `5`.\r\n\r\nI think in previous versions of TensorFlow this didn't happen, and it's only a minor annoyance, but it would be nice to fix this.", "comments": ["Please take a look @gunan. Thanks!", "This is still an issue.  @gunan  agreed we can take a look.  I also find this frustrating.  Unless you are doing different version locally it is easier to say nothing and it will compile from the default folders.  If you have multiple versions you will want to point to the correct folder.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@gunan , any updates?"]}, {"number": 6445, "title": "Fix how error message is generated when running configure", "body": "Very minor fix:\r\n\r\nWhen your TF_CUDA_VERSION does not match the observed CUDA version, an error is raised. Before this patch, the error message generation fails because the `%` operator is applied to only half of the format string. After this patch it correctly creates the error message and displays it as expected.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 6444, "title": "Branch 142707321", "body": "", "comments": []}, {"number": 6443, "title": "Branch 142694447", "body": "", "comments": []}, {"number": 6442, "title": "Build on windows using bazel broken", "body": "Operating System: Windows\r\nbazel 0.4.2, issue is seen at master branch.\r\n\r\nIt looks like sometime after our update to libjpeg turbo, our build has been broken in windows.\r\nI am looking into it, but I cannot see a clear resolution to the problem.\r\nThe error message says:\r\nhttp://ci.tensorflow.org/job/tf-master-win-bzl/218/console\r\n```\r\n00:04:27.376 c:\\tmp\\_bazel_system\\rrc05caq\\execroot\\tf-master-win-bzl\\external\\jpeg\\jmorecfg.h(242): error C2371: 'boolean': redefinition; different basic types\r\n00:04:27.376 c:\\program files (x86)\\windows kits\\10\\include\\10.0.14393.0\\shared\\rpcndr.h(193): note: see declaration of 'boolean'\r\n```\r\n\r\nI checked jmorecfg.sh, and tried to use `#define HAVE_BOOLEAN` to get around the issue. However that causes:\r\nhttp://ci.tensorflow.org/view/Experimental/job/exp-win-bzl/4/console\r\n\r\nCreating the issue to track a quick resolution to the problem.\r\n\r\nCC Our in house windows experts:\r\n@meteorcloudy @mrry \r\n\r\n@guschmue @vit-stepanovs Do you have any ideas how we can solve this?\r\nWe would like to also upgrade cmake build to use libjpeg-turbo, but before that I want to make sure it builds when we do.\r\n\r\n", "comments": ["A quick search showed that 'boolean' is defined in Windows SDK header rpcndr.h.\r\n\r\nActually, it looks like jpeg-turbo does handle this case in in [win/jconfig.h.in](https://github.com/libjpeg-turbo/libjpeg-turbo/blob/master/win/jconfig.h.in):\r\n\r\n#ifndef __RPCNDR_H__\t\t/* don't conflict if rpcndr.h already read */\r\ntypedef unsigned char boolean;\r\n#endif\r\n#define HAVE_BOOLEAN\r\n\r\nOne of the following is possible:\r\n\r\n1. Bazel does not generate the proper version of jconfig.h for Windows.\r\n2. The JCONFIG_INCLUDED macro is defined somewhere by Bazel, i.e. at the top of jpeglib.h:\r\n\r\n#ifndef JCONFIG_INCLUDED        /* in case jinclude.h already did */\r\n#include \"jconfig.h\"            /* widely used configuration options */\r\n#endif", "OK, I think I have an idea about what we are missing\r\nhttps://github.com/libjpeg-turbo/libjpeg-turbo/blob/master/CMakeLists.txt#L186\r\n\r\nIn cmake based libjpeg turbo build, jconfig.h is replaced by win/jconfig.h.in\r\nFor us, we seem to have some genrules, which do some sort of magic \r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/jpeg.BUILD#L279\r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/jpeg.BUILD#L304\r\n\r\n@jart Do you know why our BUILD file does this, instead of copying things? like the cmake rules?", "When writing jpeg.BUILD I primarily copied off of the internal Google configuration in //third_party. If you want to restructure those genrules to copy the default config.h files rather than inlining them, then I would recommend comparing their contents with the Google modifications internally.", "OK, I have an idea now to how to proceed.\nI am working on a solution.\n\nOn Wed, Dec 21, 2016 at 4:04 PM, Justine Tunney <notifications@github.com>\nwrote:\n\n> When writing jpeg.BUILD I primarily copied off of the internal Google\n> configuration in //third_party. If you want to restructure those genrules\n> to copy the default config.h files rather than inlining them, then I would\n> recommend comparing their contents with the Google modifications internally.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6442#issuecomment-268679614>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOZOFMBhtPiefp_DdV84H_5Cwafmuks5rKb6QgaJpZM4LTYC0>\n> .\n>\n"]}, {"number": 6441, "title": "Add an environment variable for the Python binary to enable Python 3.5 builds", "body": "Tested:\r\nhttp://ci.tensorflow.org/view/Release/job/release-matrix-protobuf/", "comments": []}, {"number": 6440, "title": "AttributeError: 'module' object has no attribute 'legacy_seq2sec'", "body": "In Tensorflow 0.12.0 && python 2.7.10  When I run :\r\n        `ptb_word_lm.py --data_path=/Users/mac/Documents/Tensor/simple-examples/data/ --model small`\r\n\r\nIt throws such exception:\r\n      \r\n\r\n>   AttributeError: 'module' object has no attribute 'legacy_seq2sec'\r\n\r\nHow can I fix this issue?", "comments": ["I got the same problem and have no idea.\r\nAnd I can not find legacy_seq2sec in API r0.12. Is this api removed?", "@nealwu, could this be related to your migrations? Could you fix the instructions to flex this if so.", "I tried this out with the current master version of TensorFlow and with r0.12, and they both worked for me.\r\n\r\nMake sure you are either building TensorFlow from the master version of the repository and running the latest [code in the models repo](https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb) or running TensorFlow r0.12 with the r0.12 version of the model (https://github.com/tensorflow/tensorflow/releases/tag/0.12.1 in tensorflow/models/rnn/ptb).", "If it's still not working after that, feel free to reopen this."]}, {"number": 6439, "title": "Have TensorBoard graph smoothing not overestimate last gotten scalar", "body": "When plotting scalars in TensorBoard, the smoothed curve overfits the latest value. It means the curve jumps around with subsequent updates, and for a line fit it just plainly looks bad and feels wrong.\r\n\r\nFor example, when progress reporting neural networks training and plotting the loss over the training data, surely the blue line will continue with a slight downwards slope given a stable learning rate but instead this happens at the end of the curve:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1595907/21398836/3efff694-c7a9-11e6-94cb-1b996021c1d4.png)\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1595907/21398869/64c3fe66-c7a9-11e6-8440-29ca1e959d91.png)", "comments": ["@danmane, could you please take a look?", "Is this fixed by: https://github.com/tensorflow/tensorflow/pull/7891 ?", "https://github.com/tensorflow/tensorflow/pull/7891 looks great.\r\n\r\nEDIT: Screenshots I mean, haven't done code review.", "Fixed?", "Fixed in 1.1"]}, {"number": 6438, "title": "Cannot show stderr when using Jupyter", "body": "Hello,\r\nCould you please have a look about this.\r\n\r\nI am using TF and Jupyter. But what makes me confuse is that the log text cannot be shown in Jupyter output cell (but it output correctly in ipython). \r\nI think it is because of the stderr. This issue have been discussed before in #3047. You add several lines to determine whether or not current context is in an interactive environment. \r\n\r\nHowever, even if I use Jupyter, the return value of \"sys.flags.interactive\" is still zero. and the logger lever can never be setted to \"info\" and use \"stdout\" instead of \"stderr\".\r\n\r\n\r\nThanks a lot!", "comments": ["This would be good to fix, meanwhile I've been using this work-around with FDRedirector from [here](https://github.com/bitemyapp/ipython/blob/master/IPython/kernel/core/fd_redirector.py)\r\n\r\n```\r\nSTDERR = 2\r\nredirect = FDRedirector(STDERR)\r\nimport tensorflow as tf\r\nsess = tf.Session(\"\")\r\nnode = tf.Print(tf.constant(1), [tf.constant(1)], \"longstringlongstring\")\r\ndef print_to_stderr():\r\n    sess.run(node)   # this prints to stderr\r\nredirect.start();\r\nprint_to_stderr()\r\ncaptured_stderr = redirect.stop()\r\n```\r\n\r\nThe downside is that this hangs inside tensorflow printf if pipe buffer is exceeded (65k)", "@zheng-xq do you think we need a fix like the one you did for interactive? Or just a flag?", "Same issue happens exists `Jupyter QtConsole`, no logs. ipython shows the logs. Also this does not help:\r\n\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "This bug still seems valid. This behavior has not changed.", "Is there a way to tell whether you're in that particular Jupyter environment?\r\n\r\nWe are already checking for some interactive environments, and redirecting logs appropriately (from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/tf_logging.py#L65):\r\n\r\n```\r\n      _interactive = False\r\n      try:\r\n        # This is only defined in interactive shells.\r\n        if _sys.ps1: _interactive = True\r\n      except AttributeError:\r\n        # Even now, we may be in an interactive shell with `python -i`.\r\n        _interactive = _sys.flags.interactive\r\n\r\n      # If we are in an interactive environment (like Jupyter), set loglevel\r\n      # to INFO and pipe the output to stdout.\r\n      if _interactive:\r\n        logger.setLevel(INFO)\r\n        _logging_target = _sys.stdout\r\n      else:\r\n        _logging_target = _sys.stderr\r\n```\r\n\r\nIf anyone knows of a better way to determine `_interactive`, send a PR (or tell me, and I will).\r\n\r\n", "@martinwicke How about adding a check to see if IPython has injected the appropriate attribute?  (I have no current environment to test this at the moment, else i'd do the code change myself.)\r\n```python\r\n      _interactive = False\r\n      try:\r\n        # This is only defined in interactive shells.\r\n        if _sys.ps1: _interactive = True\r\n      except AttributeError:\r\n        # Even now, we may be in an interactive shell with `python -i`.\r\n        _interactive = _sys.flags.interactive\r\n\r\n      if not _interactive:\r\n        try:\r\n          # Do we have access to IPython libraries, and if we do has get_ipython been injected?\r\n          from IPython.display import clear_output\r\n          get_ipython\r\n          _interactive = True\r\n        except (ImportError, NameError):\r\n          pass\r\n\r\n      # If we are in an interactive environment (like Jupyter), set loglevel\r\n      # to INFO and pipe the output to stdout.\r\n      if _interactive:\r\n        logger.setLevel(INFO)\r\n        _logging_target = _sys.stdout\r\n      else:\r\n        _logging_target = _sys.stderr\r\n```", "Excellent! I will try this.", "Seems to work, sent PR. Thanks Loki!", "Poifect... my pleasure.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It looks like I made a mistake verifying this earlier. I was using `tf.Print` (which is still not `jupyter` compatible).\r\n\r\n`tf.logging` is currently working well with `jupyter` already.\r\n\r\nI hope I didn't waste too much of anyone's time.", "tf.Print still works in Jupyter with the FDRedirector trick from above", "Is there a clean way to fix the issue, or some manual override to make tf.Print works with Jupyter? \r\n\r\nFDRedirector is a barely workable solution, as it is not available in latest IPython anymore."]}, {"number": 6437, "title": "Separable convolutions in 3D ( For example, separable_conv3d )", "body": "Is there a function to implement separable convolutions with 3D convolutions. We have a similar function in the case of 2D called as separable_conv2d()\r\n\r\nIs there a similar implementations in 3D as well? \r\n\r\nThanks in Advance!", "comments": ["@sankethvedula, I don't think there exists something like that.", "You might ask on StackOverflow and see if there exists a feature like that, but I am not aware of such.", "A separable_conv3d would be great to implement architectures like Xception to video and medical imaging data. Any way of extending the separable_conv2d implementation already present in TF?", "Please refer to #7278"]}, {"number": 6436, "title": "Failed to build from source for r0.12 for missing urls.", "body": "Hi, I'm trying to install tensorflow r0.12 on a cluster with CentOS. Since I don't have sudo permission and got the same problem as [#53]( https://github.com/tensorflow/tensorflow/issues/53 ), I have to build from source.\r\n\r\nWhen trying to build r0.12, during `./configure` step, I got following errors:\r\n```\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:17:3: //external:eigen_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:17:3: //external:eigen_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:28:3: //external:libxsmm_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:28:3: //external:libxsmm_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:44:3: //external:com_googlesource_code_re2: no such attribute 'urls' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:44:3: //external:com_googlesource_code_re2: missing value for mandatory attribute 'url' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:54:3: //external:gemmlowp: no such attribute 'urls' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:54:3: //external:gemmlowp: missing value for mandatory attribute 'url' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:64:3: //external:farmhash_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:64:3: //external:farmhash_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:80:3: //external:highwayhash: no such attribute 'urls' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:80:3: //external:highwayhash: missing value for mandatory attribute 'url' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:90:3: //external:nasm: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:90:3: //external:nasm: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:101:3: //external:jpeg: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:101:3: //external:jpeg: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:112:3: //external:png_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:112:3: //external:png_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:123:3: //external:gif_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:123:3: //external:gif_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:135:3: //external:six_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:135:3: //external:six_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:151:3: //external:protobuf: no such attribute 'urls' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:151:3: //external:protobuf: missing value for mandatory attribute 'url' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:161:3: //external:gmock_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:161:3: //external:gmock_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:187:3: //external:pcre: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:187:3: //external:pcre: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:198:3: //external:swig: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:198:3: //external:swig: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:222:3: //external:grpc: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:222:3: //external:grpc: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:245:3: //external:linenoise: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:245:3: //external:linenoise: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:258:3: //external:llvm: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:258:3: //external:llvm: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:269:3: //external:jsoncpp_git: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:269:3: //external:jsoncpp_git: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:285:3: //external:boringssl: no such attribute 'urls' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:285:3: //external:boringssl: missing value for mandatory attribute 'url' in 'http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:295:3: //external:nanopb_git: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:295:3: //external:nanopb_git: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:311:3: //external:zlib_archive: no such attribute 'urls' in 'new_http_archive' rule.\r\nERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:311:3: //external:zlib_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': error loading package 'external': Could not load //external package.\r\nERROR: missing fetch expression. Type 'bazel help fetch' for syntax and help.\r\n```\r\n\r\nWhen I turned back to r0.11,  `./configure`  works fine.\r\n\r\nAny ideas?", "comments": ["Which version of Bazel you have? I was ok with 4.2", "This may sound stupid and is definitely irrelevant to the issue but pip install doesn't require sudo permission, does it?", "I had the same problem with bazel 0.4.0 and upgrading to 0.4.2 fixed this for me. @hasitpbhatt - you need 'sudo' if you do not have write permission to your 'site-packages' directory and you can find the location of this with 'python -c \"import site; print(site.getsitepackages())\"'. If you cannot use 'sudo' you can get around this by installing your own local version of python.", "You have to upgrade to bazel 0.4.2\r\nThere has been a backwards incompatible change with bazel, so our external dependency rule formats have been slightly modified.\r\n\r\nSorry for not broadcasting this wider. I will see what I can do to make error messages better.", "@hasitpbhatt Did you try with Bazel 0.4.2? Let us know", "I was facing the same issue earlier and tried configuration with Bazel 0.4.2 and it works. ", "I upgraded Bazel from 0.3.1 to 0.4.3, and this issue was resolved for me as well.", "Not work for `0.4.1` and work for `0.4.3`.", "@gunan: https://github.com/tensorflow/tensorflow/blob/4433079e7f317724eaa92ec120c6b1c3c0c52f2f/tensorflow/tensorflow.bzl#L25 should be checking the bazel version and failing with a helpful error message.  Perhaps the check got broken somehow (wouldn't be surprised).\r\n\r\n@damienmg in case he knows whether it changed in unexpected ways.", "The check was there, but it was not happening as the first thing we need to do.\r\nModified it in master.\r\nShould we cherrypick it into the release?", "We'll need to get good at cherrypicking releases into branches, so I say why not :)"]}, {"number": 6435, "title": "training.slot_creator: support for non-fully-defined shaped vars", "body": "This is a possible solution for #5972.\r\n\r\nWith this patch, the `AdamOptimizer` (and other optimizers) can optimize variables with non-fully-defined shape which would raise an exception without the patch because `primary.get_shape().as_list()` does not work.\r\n", "comments": ["Can one of the admins verify this patch?", "@keveman any cycles for this?", "Jenkins, test this please.", "Shouldn't we have a test for this?", "Good point.", "@albertz could you add a unit test as requested by the reviewers?", "Closing due to conflicts + lack of update, to keep our list of open PRs small so they all get attention.  Please feel free to update and we can reopen, or send a brand new PR once you've addressed these comments.  "]}, {"number": 6434, "title": "Update cudnn version in instruction for mac gpu. (#6407)", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "All of r0.12 is already merged back into master. Closing this PR."]}, {"number": 6433, "title": "Add synthetic datasets fix", "body": "This fixes #5314 and #5315  that was reverted by #6288 by re-introducing a fix by @comicchang in  #6283 . Fix #6283 was not merged as it was submitted after #6288 reverted it.  \r\n\r\nThe error was that `import tensorflow as tf` is not allowed (sorry didn't know that).\r\nI think I checked everything, lgtm\r\n\r\n@ilblackdragon @caisq @martinwicke \r\n\r\n", "comments": ["Can one of the admins verify this patch?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@comicchang Could you sign the CLA? I didn't rewrite my commit to add your changes, I added your changes directly. As you are a contributor, you need to sign it :)", "My bad @comicchang, it doesn't need CLA, it says you need confirm here that you are OK with this PR\r\n\r\n> \ud83d\ude15 The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter. We need to confirm that they're okay with their commits being contributed to this project. Please have them confirm that here in the pull request.", "@zafartahirov I've already sighed the CLA\r\nI'm ok with this PR\r\n\r\nBut...didn't my PR/commits already merged to the master?", "@comicchang No it didn't, it was revoked before the merge was complete\r\n", "@zafartahirov\r\nI'm confused, but l'm sure the PR was already merged.\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/datasets\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/81eae9ac713e02b6d36785de8b7f29258601592b\r\n\r\n", "That's odd, when I was reading the #6288 it was saying that it got cancelled -- my bad, will close it now", "I know what happened - You are right, I checked it now - I was reading an old thread from #6283 before you reverted the changes - disadvantage of keeping open tabs as my \"todo-list\", my bad :)", "That's ok.\nHave a good day :)\nZafar Takhirov <notifications@github.com>\u4e8e2016\u5e7412\u670821\u65e5 \u5468\u4e09\u4e0b\u53482:17\u5199\u9053\uff1a\n\n> I know what happened - You are right, I checked it now - I was reading an\n> old thread from #6283 <https://github.com/tensorflow/tensorflow/pull/6283>\n> before you reverted the changes - disadvantage of keeping open tabs as my\n> \"todo-list\", my bad :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/6433#issuecomment-268445225>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABMu0WXuZQEm3bX3rtAnuQjio7nJ18VNks5rKMRcgaJpZM4LSmeY>\n> .\n>\n"]}, {"number": 6432, "title": "rnn_cell has no BasicLSTMCell", "body": "lstm_cell = tf.contrib.rnn.BasicLSTMCell(\r\nAttributeError: 'module' object has no attribute 'BasicLSTMCell'.\r\n\r\nIs it been replaced by other cell?\r\n", "comments": ["You can use BasicLSTMCell through\r\n`tf.nn.rnn_cell.BasicLSTMCell`\r\n\r\nI was able to verify this in 0.12", "gunan I hwas having the same problem as xusong2008 . I replaced tf.contrib.rnn.BasicLSTMCell by tf.nn.rnn_cell. BasicLSTMCell as you said but now a new error is being shown:\r\n\r\nTraceback (most recent call last):\r\n  File \"ptb_word_lm.py\", line 362, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"ptb_word_lm.py\", line 324, in main\r\n    m = PTBModel(is_training=True, config=config, input_=train_input)\r\n  File \"ptb_word_lm.py\", line 110, in __init__\r\n    self._initial_state = cell.zero_state(batch_size, data_type())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 166, in zero_state\r\n    for s in state_size_flat]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 79, in _state_size_with_prefix\r\n    result_state_size = tensor_shape.as_shape(state_size).as_list()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 815, in as_shape\r\n    return TensorShape(shape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 448, in __init__\r\n    self._dims = [as_dimension(dims)]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 374, in as_dimension\r\n    return Dimension(value)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 33, in __init__\r\n    self._value = int(value)\r\nTypeError: int() argument must be a string or a number, not 'BasicLSTMCell'\r\n\r\nPls help soon !!", "Looks like your is a breakage in one of the models in our models repository.\r\nCOuld you file an issue in tensorflow/models repository for a fix for that?", "@sharod I think I saw you open an issue in github.com/tensorflow/models and close it later -- did you end up figuring it out?", "AttributeError: module 'tensorflow.contrib.rnn' has no attribute 'static_rnn'", "@userljw please upgrade your TensorFlow installation to 1.4. [`static_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn) should be available."]}, {"number": 6431, "title": "Does TF support multicore processing on Android?", "body": "As we know, iPhone play better performance than other Android mobiles on single CPU, presenting Android takes more time to run an inference. But Android usually have four or more CPU cores and iPone have only two. So I want to speed up Android's inference by using multicore processing.\r\n\r\n**What solutions have you tried?**\r\nI add -fopenmp build options according to Eigen multi-threading docs, but it doesn't work, the speed is still the same. \r\nCould anyone point me in the right direction here?\r\nThanks!", "comments": ["From [the source code here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/direct_session.cc#L210), looks like multi thread execution on Android is not enabled.\r\nWe are also interested in this.", "@benoitsteiner Is this restriction caused by eigen::ThreadPoolTempl? \r\n>   // On Android, there is no implementation of ThreadPool that takes\r\n  // std::function, only Closure, which we cannot easily convert.\r\n\r\nWhat's the cause of this? Because std::function is regarded as unsupported on Android? Looks like from [this discussion](https://groups.google.com/forum/#!topic/android-ndk/ez3tWOEtCFY) and [also another one](http://stackoverflow.com/questions/33584288/android-ndk-and-functional-stdfunction-support), at least [some runtime here](https://developer.android.com/ndk/guides/cpp-support.html) support it?", "Hi, according to http://stackoverflow.com/a/42169898/4571192 , \r\n1) there will be java api for setting session options soon, anybody know when will it be?\r\n2) It's possible to manually set the session options to enable multicore/multithread support, but I don't know exactly how to achieve this. Could someone guide me how to do this?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 6430, "title": "Fix TF_CONFIG example in ClusterConfig documentation", "body": null, "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 6429, "title": "[Tensorboard Feature Requests] Binding the run selectors of the tabs together", "body": "For now, in order to check the Events/Image/Distribution tabs for a run, I need to make the selection for each of the tab. It would be nice to be able to apply the same run filters across all tabs. If I made a selection in one tab, the other tabs will use the same filters automatically.", "comments": ["Just realized this is implemented. Nice!"]}, {"number": 6428, "title": "Update README.md - clarification ", "body": "I initially followed instructions - and got more errors.\r\nThe build all ios script should be first call to action for newbies stuck troubleshooting.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 6427, "title": "Update README.md - clarification", "body": "I initially followed instructions - and got more errors. \r\nThe build all script should be first call to action for newbies.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 6426, "title": "Outdated documentation of Assert op", "body": "From https://www.tensorflow.org/api_docs/python/control_flow_ops/debugging_operations#Assert\r\n\r\n```\r\n # Ensure maximum element of x is smaller or equal to 1\r\nassert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])\r\nx = tf.with_dependencies([assert_op], x)\r\n```\r\n\r\n`tf.with_dependencies` does not exist (see also a related [stack overflow discussion](http://stackoverflow.com/questions/37980078/tensorflow-has-no-attribute-with-dependencies))", "comments": ["This has been fixed---see:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Assert"]}, {"number": 6425, "title": "Branch 142576906", "body": "", "comments": ["Jenkins, test this please", "Jenkins, test this please", "Jenkins, test this please", "@mrry fyi, I had to move saved_model deps from `tf_cc_ops.cmake` to `tf_core_cpu.cmake` to fix the windows cmake build. I added saved_model support to the C API in this set of changes, and it's closer to core anyway despite being under `cc/`.", "Maybe `tf.norm` should use `tf.norm(m, ord='fro')` instead of `tf.norm(m, order='fro')` for consistency with numpy? @martinwicke ", "@aselle See the `tf.norm` comment above ^", "I am ok with order instead of ord, because frankly, numpy's name there is worse. Incompatibility with keyword arguments is less pressing, since those basically will not cause as much confusion as positional argument mismatches (we do match them in some cases, like our change on axis).", "@yaroslavvb fyi, it's being renamed to `ord` and should show up during the next sync."]}, {"number": 6424, "title": "Branch 142573865", "body": "", "comments": ["Jenkins, test this please", "Hmm, got some commits from my master branch somehow. Redoing."]}, {"number": 6423, "title": "Swift 3 wrapper around c interface. ", "body": "From comments here @rxwei\r\nhttps://github.com/tensorflow/tensorflow/issues/19\r\n\r\nIt's apparent that the c wrapper is limited - and there's no feature parity matching python api. \r\nIn order to progress swift - we need more of the python functionality to be ported to c interface.\r\nOr a path forward using the services layer. \r\n\r\nI wonder if this c porting could be done automagically using some off the shelf library?\r\nhttp://stackoverflow.com/questions/4650243/convert-python-program-to-c-c-code", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "@rxwei  - Hi Richard, can you sign the contributor license? \r\nhttps://cla.developers.google.com/  ", "Hey @johndpope, my previous commit was highly incomplete and not ready for merge. Would you have time implementing `Session`, `Tensor`, `Graph` to make it at least able to execute a graph on trained params?\r\nFollow-up to @johndpope, for these things better go directly wrapping the C API", "Thanks for the contribution! We'd prefer not to commit language bindings to the tensorflow repository that the core TensorFlow team won't yet maintain.\r\n\r\nI'm happy to do code review on the Swift bindings and link to them on `tensorflow.org` when they're functional, though.", "Also, mind elaborating what you need that's in Python but not available in the C API yet?\r\n\r\nThe C API is intended to be complete for running inference tasks, such as on mobile phones.", "hi @jhseu,\r\n\r\napologies for late reply.\r\nfyi @rxwei  - I have succesfully generated  grpc wrappers for all tensorflow services in swift.\r\nhttps://github.com/nubbel/swift-tensorflow/\r\n(there's a script to auto build in different target languages too / java /cpp)\r\n\r\n@jhseu - When you asked previously about the api and what was missing - the answer would be everything that's in python and not in the c api. There is a growing interest, I imagine one day swift will supercede python for server side development. maybe swift v5.\r\nhttps://github.com/tensorflow/tensorflow/issues/19\r\n\r\nMy idea when digging into this was one day to sit down and build graphs in swift instead of using python.  so having a library as deep as the python api is would be the best.\r\nhttps://github.com/petewarden/tensorflow_makefile/blob/49c08e4d4ff3b6e7d99374dc2fbf8b358150ef9c/tensorflow/g3doc/api_docs/python/index.md\r\n\r\nthe grpc / from my reading is like how the c++ library currently works\r\n in that it's mostly for 'control the execution of a graph'\r\nhttps://github.com/petewarden/tensorflow_makefile/blob/49c08e4d4ff3b6e7d99374dc2fbf8b358150ef9c/tensorflow/g3doc/api_docs/cc/index.md\r\nin that effect / the corresponding swift tensorflow package could do that today (via grpc).\r\n\r\nTo move forward on original vision - I need to put all the bits of the puzzle together - but alas - it would never completely fulfill my intention of building the graph in swift. From reading into swig / this doesn't have support for swift. https://github.com/swig/swig/issues/981\r\n\r\nthere's an attempt to auto scaffold swift code from cpp \r\nhttps://github.com/sandym/swiftpp\r\nbut I'm reluctant to dive down that path as the cpp library I believe has parity with only the grpc services. \r\n\r\nI guess grpc could find a home with swift and end user if it was wired up to behave like sourcekitten / xcode in that as you type in editor it's executing the code and getting responses from the rpc calls.  \r\n\r\nI'm enjoying learning about grpc / swift microservices in any case. \r\n\r\nA question to ponder - could you do everything in python today if you were using python via grpc (the old adage eating your own dog food comes to mind - but it describes what I need from google to flesh out my swift project)\r\n\r\nI'm off to the pub.\r\n\r\n\r\n", "hi @jhseu,\r\n\r\nfyi - you may consider linking to this swift port\r\n https://github.com/PerfectlySoft/Perfect-TensorFlow\r\n\r\n", "@johndpope one might say that a swift port unusable on iOS is not a swift port.\r\nMore like server-side swift tensorflow", "@tirrorex  - there's been some developers pushing things forward. \r\nto do a vanillla swift + tensorflow app - I'm only aware of \r\nhttps://github.com/xmartlabs/Bender\r\n\r\nthere's more updates (swift server side libraries) here - \r\nhttps://github.com/tensorflow/tensorflow/issues/19\r\n\r\nFor my needs / Bender couldn't handle a neural net that was not specific to images. \r\nhttps://github.com/xmartlabs/Bender/issues/21\r\n\r\n", "@johndpope yes i bumped into Bender yesterday after some research, doesn't seem to be anything else unfortunatly."]}, {"number": 6422, "title": "[Feature request] Ability to reimplement backprop.", "body": "Currently there is no straightforward way to do things like implementing different learning rates for different layers. Much less apply learning rate masks for individual unit adjustment.\r\n\r\nTorch allows you to easily reimplement backprop however you want. TF seems limited to this: https://www.tensorflow.org/api_docs/python/framework/core_graph_data_structures#Graph.gradient_override_map", "comments": ["What is the abstraction used in Torch/how would it look in TensorFlow?", "@alexmonroe87 while there is probably a good feature request here, we need this to be a lot more precise for it to be useful.\r\n\r\nOne can use different instantiations of optimizers for variables with different learning rates to get per-layer learning rates.  I also don't know what a 'learning rate mask' is, so I'm not sure why it's hard.\r\n\r\nIt would be helpful to detail the use case more.  It's possible that what you want to do is possible in TF, but may require a little effort to think more declaratively, and we can't know unless we see a more concrete use case.", "@vrv Using different optimizer instances for different variables would lead to the problem of computing the same gradients multiple times and probably some other issues. Might also not work as intended with an optimizer like Adam.\r\n\r\nWhat I'm essentially asking for the is the ability to scale a gradient on a per neuron basis with a mask, or as in the use case of individual layers having their own learning rate, a scalar.\r\n\r\nSimple example:\r\nSome layer contains 5 neurons and you apply this mask: [1 1 2 1 1] to it, when doing backprop the middle neuron gets updated with twice the learning rate. Though in practice the learning rate will just be made 1 and the mask will specify it.\r\n\r\nAlso it may prove interesting and perhaps even valuable to instead of adjusting the learning rate, actually adjust the gradient itself which would also flow backward - this is not at all obvious how to do in TF.\r\n", "@alexmonroe87 an example where using different optimizer instances doesn't work would be useful -- I don't think we'd compute the same gradients multiple times if every variable is associated with one optimizer.  \"Might not work as intended\" is not sufficient evidence for a new feature request :).\r\n\r\nAs for your mask idea, you can do that today:  Let's say you have a single variable you want to optimize with a mask, using a GradientDescentOptimizer (for simplicity).  Here's my untested semi-TF code:\r\n\r\n```\r\n    v = tf.Variable(...)\r\n\r\n    # Define your mask here, matching the shape of the variable.  E.g., could be [1.0, 1.0, 2.0, 1.0, 1.0]\r\n    # if 'v' was a vector of 5.\r\n    mask = tf.constant(..., dtype=tf.float32)\r\n\r\n    # Base learning rate\r\n    optimizer = tf.GradientDescentOptimizer(learning_rate)\r\n\r\n    # Compute the gradients and have them returned\r\n    grads_and_vars = optimizer.compute_gradients(loss, var_list=[v], ...)\r\n\r\n    # Scale the gradient by the mask you want\r\n    masked_grad_and_vars = [(tf.multiply(mask, g), v) for g, v in grads_and_vars]\r\n    \r\n    # Apply the scaled gradient\r\n    optimizer.apply_gradients(masked_grad_and_vars)\r\n```\r\n\r\nThe only difference between this and normal code is the addition of the 'mask' and the 'masked_grad_and_vars'.  Everything else is the same.\r\n\r\nCan you explain why this wouldn't work for you?", "@vrv Scaling incoming gradients doesn't work for optimizers that adaptively rescale the gradients. Such as Adam.", "There's a solution [here](http://stackoverflow.com/a/39793644/419116) that works for adam (specify different optimizer for each layer)", "@alexmonroe87 reimplementing backprop for a given op would only allow you to control the output prior to the optimizer, so I still don't understand your feature request. \r\n\r\nI'm going to close this particular issue since the request is still unclear (to me) after repeated requests for clarfiication.\r\n\r\nIf you can provide *concrete* examples of what is not possible / what is hard, (or more evidence of why something is impossible), we can reopen."]}]