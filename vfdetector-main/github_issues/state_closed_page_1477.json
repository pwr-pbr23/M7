[{"number": 8633, "title": "Please provide an example how to use a model trained from scratch for image classification", "body": "The following documentation of TensorFlow-Slim contains how to train a model from scratch, but it's not explained how to use the resulting checkpoint files for image classification.\r\nhttps://github.com/tensorflow/models/tree/master/slim#training-a-model-from-scratch\r\n\r\nAlthough it's possible to load the pre-trained models (https://github.com/tensorflow/models/tree/master/slim#pre-trained-models) and use it for image classification with the example given in https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb, it seems not possible to simply use the checkpoint files generated by \"training from scratch\" in the same way.\r\n\r\nAny example on how to use the newly generated checkpoints for image classification (for example with inception) would be appreciated.", "comments": ["@wolffg @martinwicke @nealwu to consider?", "The garden should contain that documentation, eventually. ", "Is there already any code example on which it's possible to build on?", "Closing as too open ended.  Watch the gardener space."]}, {"number": 8632, "title": "Doc addition to tf.gather describing validate_indices option behavior", "body": "See Issue #3638 . This helps people debugging their code, as otherwise they may assume `tf.gather` throws an error when invalid indices are present (it currently does so only when executed on CPU).", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "Can one of the admins verify this patch?", "Can one of the admins verify this patch?", "Can one of the admins verify this patch?", "I've been trying to get Googlebot to recognize me as the one who signed the CLA. Been juggling email addresses both at github and Google; apparently so far not working. Will try again later. Any tips appreciated.", "Can one of the admins verify this patch?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 8631, "title": "Minor bugfix in DynamicAttentionWrapper; improve docs", "body": "", "comments": ["Can one of the admins verify this patch?", "Sorry, I'm not too familiar with this new code, un-assigning myself. Maybe Thang?", "LGTM thank you for the fix!", "Jenkins, test this please."]}, {"number": 8630, "title": "NAN returning for cost and optimizer for tensorflow.train.GradientDescentOptimizer (updated code)", "body": "Been working on this all day now and totally at a loss...  I keep getting Nan values for my cost function right away and i cannot tell why.  Any help much appreciated at this point....\r\n\r\nI am running the following code with tensorflow GradientDescentOptmizer...\r\n\r\n```\r\n#!/usr/bin/env python\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\nfrom   os.path import isfile, join\r\nimport argparse\r\nimport sys\r\nimport glob\r\nimport pandas as pd\r\nimport csv\r\nimport re\r\nimport tempfile\r\nimport urllib\r\nimport matplotlib.pyplot as plt\r\n\r\n# Start basic regression\r\ntf.reset_default_graph()\r\n\r\nrng = np.random\r\n\r\n# Parameters\r\nlearning_rate = 0.0001\r\ntraining_epochs = 1000\r\ndisplay_step = 50\r\n\r\nlogs_path = '/tmp/tensorflow_logs/example'\r\n\r\n# Bad Training Data\r\ntrain_Y = np.asarray([  59.8000,   60.5000,   60.9000,   61.0000,   61.5000,   64.0000,   64.5000,\r\n                        64.8000,   67.8000,   71.2000,   72.0000,   78.9000,   79.2000,   81.0000,\r\n                        82.6000,   84.0000,   84.0000])\r\ntrain_X = np.asarray([600., 760., 802., 568., 679., 865., 1103., 865., 896., 1068.,\r\n                        769., 1062., 1123., 1081., 1137., 1137., 1137.])\r\n# Good Training Data\r\n#train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\r\n#                     7.042,10.791,5.313,7.997,5.654,9.27,3.1])\r\n#train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\r\n#                     2.827,3.465,1.65,2.904,2.42,2.94,1.3])\r\n\r\nprint(train_X.dtype)\r\nprint(train_Y.dtype)\r\nprint(str(train_X))\r\nprint(str(train_Y))\r\n\r\nn_samples = train_X.shape[0]\r\n\r\nprint(\"Samples = %d\" % n_samples)\r\n\r\n# tf Graph Input\r\nX = tf.placeholder(\"float\")\r\nY = tf.placeholder(\"float\")\r\n\r\n# Set model weights\r\nW = tf.Variable(1.0, name=\"weight\")\r\nb = tf.Variable(1.0, name=\"bias\")\r\n\r\n# Construct a linear model\r\nwith tf.name_scope('Model'):\r\n    pred = tf.add(tf.multiply(X, W), b)\r\n\r\n# Mean squared error\r\nwith tf.name_scope('Loss'):\r\n    cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\r\n# Gradient descent\r\nwith tf.name_scope('SGD'):\r\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\r\n\r\n# Initializing the variables\r\ninit = tf.global_variables_initializer()\r\n\r\n# summaries\r\ntf.summary.scalar(\"loss\",cost)\r\nmerged_summary_op = tf.summary.merge_all()\r\n\r\n# Launch the graph\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    # op to write logs to Tensorboard\r\n    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\r\n\r\n    # Fit all training data\r\n    for epoch in range(training_epochs):\r\n        for (x, y) in zip(train_X, train_Y):\r\n            #print(\"x=%f y=%f\" % (x,y))\r\n            op, c, summary = sess.run([optimizer, cost, merged_summary_op], feed_dict={X: x, Y: y})\r\n\r\n            summary_writer.add_summary(summary, epoch)\r\n\r\n            # Display logs per epoch step\r\n        if (epoch+1) % display_step == 0:\r\n            c, summmary = sess.run([cost, merged_summary_op], feed_dict={X: train_X, Y:train_Y})\r\n            summary_writer.add_summary(summary, epoch)                \r\n              \r\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\r\n            \"W=\", sess.run(W), \"b=\", sess.run(b))\r\n\r\n    print(\"Optimization Finished!\")\r\n    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\r\n    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\r\n\r\n    # Graphic display\r\n    plt.plot(train_X, train_Y, 'ro', label='Original data')\r\n    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\r\n    plt.legend()\r\n    plt.show()\r\n\r\n    # Bad Test Data\r\n    test_Y = np.asarray([ 48.2000,  56.5000,  57.0000,  59.5000,  15.0000,  17.8000,  43.5000,  50.2000])\r\n    test_X = np.asarray([ 549.,  710.,  568.,  825., 414.,  439.,  460.,  614. ])\r\n\r\n    # Good Test Data\r\n    #test_X = np.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\r\n    #test_Y = np.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\r\n\r\n\r\n    print(\"Testing... (Mean square loss Comparison)\")\r\n    testing_cost = sess.run(\r\n        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\r\n        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\r\n    print(\"Testing cost=\", testing_cost)\r\n    print(\"Absolute mean square loss difference:\", abs(\r\n        training_cost - testing_cost))\r\n\r\n    plt.plot(test_X, test_Y, 'bo', label='Testing data')\r\n    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\r\n    plt.legend()\r\n    plt.show()`\r\n```\r\n\r\nAnd get the following result...\r\n\r\n> float64\r\n> float64\r\n> [  600.   760.   802.   568.   679.   865.  1103.   865.   896.  1068.\r\n>    769.  1062.  1123.  1081.  1137.  1137.  1137.]\r\n> [ 59.8  60.5  60.9  61.   61.5  64.   64.5  64.8  67.8  71.2  72.   78.9\r\n>   79.2  81.   82.6  84.   84. ]\r\n> Samples = 17\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n> Epoch: 0050 cost= nan W= nan b= nan\r\n> Epoch: 0100 cost= nan W= nan b= nan\r\n> Epoch: 0150 cost= nan W= nan b= nan\r\n> Epoch: 0200 cost= nan W= nan b= nan\r\n> Epoch: 0250 cost= nan W= nan b= nan\r\n> Epoch: 0300 cost= nan W= nan b= nan\r\n> Epoch: 0350 cost= nan W= nan b= nan\r\n> Epoch: 0400 cost= nan W= nan b= nan\r\n> Epoch: 0450 cost= nan W= nan b= nan\r\n> Epoch: 0500 cost= nan W= nan b= nan\r\n> Epoch: 0550 cost= nan W= nan b= nan\r\n> Epoch: 0600 cost= nan W= nan b= nan\r\n> Epoch: 0650 cost= nan W= nan b= nan\r\n> Epoch: 0700 cost= nan W= nan b= nan\r\n> Epoch: 0750 cost= nan W= nan b= nan\r\n> Epoch: 0800 cost= nan W= nan b= nan\r\n> Epoch: 0850 cost= nan W= nan b= nan\r\n> Epoch: 0900 cost= nan W= nan b= nan\r\n> Epoch: 0950 cost= nan W= nan b= nan\r\n> Epoch: 1000 cost= nan W= nan b= nan\r\n> Optimization Finished!\r\n> Training cost= nan W= nan b= nan \r\n> \r\n> Testing... (Mean square loss Comparison)\r\n> Testing cost= nan\r\n> Absolute mean square loss difference: nan\r\n> And get the following output...\r\n> \r\n\r\nif I uncomment out the alternate array values for X amd Y everything works fine...\r\n\r\n> float64\r\n> float64\r\n> [  3.3     4.4     5.5     6.71    6.93    4.168   9.779   6.182   7.59\r\n>    2.167   7.042  10.791   5.313   7.997   5.654   9.27    3.1  ]\r\n> [ 1.7    2.76   2.09   3.19   1.694  1.573  3.366  2.596  2.53   1.221\r\n>   2.827  3.465  1.65   2.904  2.42   2.94   1.3  ]\r\n> Samples = 17\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n> Epoch: 0050 cost= 8.580235481 W= 0.846042 b= 0.978224\r\n> Epoch: 0100 cost= 5.489832401 W= 0.72321 b= 0.960839\r\n> Epoch: 0150 cost= 3.522622824 W= 0.625209 b= 0.946956\r\n> Epoch: 0200 cost= 2.270416975 W= 0.547022 b= 0.935869\r\n> Epoch: 0250 cost= 1.473346949 W= 0.484644 b= 0.927012\r\n> Epoch: 0300 cost= 0.965984821 W= 0.434878 b= 0.919934\r\n> Epoch: 0350 cost= 0.643029690 W= 0.395175 b= 0.914275\r\n> Epoch: 0400 cost= 0.437456042 W= 0.363499 b= 0.909749\r\n> Epoch: 0450 cost= 0.306603283 W= 0.338229 b= 0.906127\r\n> Epoch: 0500 cost= 0.223311335 W= 0.318069 b= 0.903225\r\n> Epoch: 0550 cost= 0.170292616 W= 0.301985 b= 0.900899\r\n> Epoch: 0600 cost= 0.136546493 W= 0.289155 b= 0.899031\r\n> Epoch: 0650 cost= 0.115067258 W= 0.278921 b= 0.89753\r\n> Epoch: 0700 cost= 0.101395160 W= 0.270757 b= 0.89632\r\n> Epoch: 0750 cost= 0.092692636 W= 0.264245 b= 0.895344\r\n> Epoch: 0800 cost= 0.087154001 W= 0.259051 b= 0.894554\r\n> Epoch: 0850 cost= 0.083628759 W= 0.254909 b= 0.893912\r\n> Epoch: 0900 cost= 0.081385054 W= 0.251606 b= 0.893389\r\n> Epoch: 0950 cost= 0.079956941 W= 0.248972 b= 0.892961\r\n> Epoch: 1000 cost= 0.079047829 W= 0.246872 b= 0.892606\r\n> Optimization Finished!\r\n> Training cost= 0.0790478 W= 0.246872 b= 0.892606 \r\n> \r\n> Testing... (Mean square loss Comparison)\r\n> Testing cost= 0.0796623\r\n> Absolute mean square loss difference: 0.000614464\r\n\r\n\r\nI am using tensorflow 1.01 libraries, and running on a mac OS Sierra...\r\n\r\nBanging my head against the wall trying to figure this out. As you can see I tried to setup tensorboad to help, but seems I have limited success, get a graph but so far has not been any help debugging this...\r\n", "comments": ["Have you tried [TensorFlow Debugger (tfdbg)](https://www.tensorflow.org/programmers_guide/debugger)? ", "Not yet, but I will try that now...\r\n(been playing with it, haven't gotten that far, hard to tell where the issue is, seems like in the calculation of the gradients)\r\n\r\nAlso if I flip the values,  make x = y and y = x it works fine, calculates a X and b weights just fine...  so this almost certainly means it is the solver which is sadly very far from robust...", "Also changing to AtomOptimizer works fine as well... Guess the answer is it is what it is....", "As far as I can tell, it seems like you just have a badly conditioned problem. It is entirely possible in TensorFlow (or any other numerical system) to construct problems with poor numerical conditioning. It is a generally difficult and unsolved problem to handle arbitrarily ill-conditioned problems with floating point numbers. Given that your problem is your custom model, there may be a better way to pose your problem. As you saw, other optimizers do better on some types of problems, but nothing is 100% foolproof. If you want more advice in this vein, StackOverflow is where usage problems with TensorFlow should be directed.", "It happens generally due to learning rate having high values. Please refer to: https://stackoverflow.com/questions/45770603/tensorflow-session-returns-nan", "Try transforming your variables. I.e. natural log.", "> It happens generally due to learning rate having high values. Please refer to: https://stackoverflow.com/questions/45770603/tensorflow-session-returns-nan\r\n\r\nyes it worked for me thank you  !!!!!!!!!\r\nI initially had learning rate =0.001 , cost returns Nan.\r\nNow after changing learning rate to 0.0001, my model has good accuracy."]}, {"number": 8629, "title": "explicitly assign to dtype for tf.Variable code", "body": "dtype is not the second parameter in tf.Variable, though the type is inferred correctly by the initial values.", "comments": ["Can one of the admins verify this patch?", "Thank you!"]}, {"number": 8628, "title": "Build configuration error: TensorFlow is not configured to build with GPU support.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nCommit \"ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69\" fails to configure for me, the commit before that succeeds. Might be related to issue #8619 which was closed, although for me using bazel 0.4.5 does not work.\r\n\r\nFails with \"git checkout ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69\"\r\nhttp://pastebin.com/FHt0r5kS\r\nSucceeds with \"git checkout 450386c513a4c68d6b77f9b475dc39b442775a86\"\r\nhttp://pastebin.com/3vGHik0G\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04.2 LTS\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n```\r\njbunk@desktop:~/libraries$ cat /usr/local/cuda/version.txt \r\nCUDA Version 8.0.61\r\njbunk@sherman:~/libraries/Tensorflow-Github$ ls /usr/local/cuda/lib64/libcudn*\r\n/usr/local/cuda/lib64/libcudnn.so  /usr/local/cuda/lib64/libcudnn.so.5  /usr/local/cuda/lib64/libcudnn.so.5.1.10  /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\nCommit \"ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69\"\r\n```\r\njbunk@desktop:~/libraries$ bazel version\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\nFails with \"git checkout ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69\"\r\nhttp://pastebin.com/FHt0r5kS\r\nSucceeds with \"git checkout 450386c513a4c68d6b77f9b475dc39b442775a86\"\r\nhttp://pastebin.com/3vGHik0G", "comments": ["Note: conversation currently continuing on #8619.", "Fixed by https://github.com/tensorflow/tensorflow/commit/fba05c300bf6840e76787680ed7fd1239cdb9ad0\r\n Thanks @damienmg !"]}, {"number": 8627, "title": "HDF5 library version mismatched error with latest Tensorflow build for windowsx64", "body": "Due to a bug still present in Tensorflow 1.0.1 release for windows (see https://github.com/tensorflow/tensorflow/issues/8336)\r\nI have installed the latest nightly build tensorflow cpu win 22-mar-2017 2.25.00 as suggested\r\n\r\nUnfortunately with this version, now kernel crashes for a different reason and I get this error:\r\n\r\n```\r\nWarning! ***HDF5 library version mismatched error***\r\nThe HDF5 header files used to compile this application do not match\r\nthe version used by the HDF5 library to which this application is linked.\r\nData corruption or segmentation faults may occur if the application continues.\r\nThis can happen when an application was compiled by one version of HDF5 but\r\nlinked with a different version of static or shared HDF5 library.\r\nYou should recompile the application or check your shared library related\r\nsettings such as 'LD_LIBRARY_PATH'.\r\nYou can, at your own risk, disable this warning by setting the environment\r\nvariable 'HDF5_DISABLE_VERSION_CHECK' to a value of '1'.\r\nSetting it to 2 or higher will suppress the warning messages totally.\r\nHeaders are 1.8.15, library is 1.8.18\r\n      SUMMARY OF THE HDF5 CONFIGURATION\r\n      =================================\r\n\r\nGeneral Information:\r\n-------------------\r\n                   HDF5 Version: 1.8.18\r\n                  Configured on: 2017-03-06\r\n                  Configured by: Visual Studio 14 2015 Win64\r\n                 Configure mode: CMAKE 3.7.2\r\n                    Host system: Windows-10.0.14393\r\n              Uname information: Windows\r\n                       Byte sex: little-endian\r\n                      Libraries:\r\n             Installation point: C:/Program Files/HDF5\r\n\r\nCompiling Options:\r\n------------------\r\n               Compilation Mode:\r\n                     C Compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n                         CFLAGS: /DWIN32 /D_WINDOWS /W3\r\n                      H5_CFLAGS:\r\n                      AM_CFLAGS:\r\n                       CPPFLAGS:\r\n                    H5_CPPFLAGS:\r\n                    AM_CPPFLAGS:\r\n               Shared C Library: YES\r\n               Static C Library: YES\r\n  Statically Linked Executables: OFF\r\n                        LDFLAGS: /machine:x64\r\n                     AM_LDFLAGS:\r\n                Extra libraries: X:inclib-vc14-x64/zlib.lib;X:/inclib-vc14-x64/libsz.lib;X:/inclib-vc14-x64/libaec.lib\r\n                       Archiver:\r\n                         Ranlib:\r\n              Debugged Packages:\r\n                    API Tracing: OFF\r\n\r\nLanguages:\r\n----------\r\n                        Fortran: OFF\r\n               Fortran Compiler:\r\n          Fortran 2003 Compiler:\r\n                  Fortran Flags:\r\n               H5 Fortran Flags:\r\n               AM Fortran Flags:\r\n         Shared Fortran Library: YES\r\n         Static Fortran Library: YES\r\n\r\n                            C++: ON\r\n                   C++ Compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n                      C++ Flags: /DWIN32 /D_WINDOWS /W3 /GR /EHsc\r\n                   H5 C++ Flags:\r\n                   AM C++ Flags:\r\n             Shared C++ Library: YES\r\n             Static C++ Library: YES\r\n\r\nFeatures:\r\n---------\r\n                  Parallel HDF5: OFF\r\n             High Level library: ON\r\n                   Threadsafety: OFF\r\n            Default API Mapping: v18\r\n With Deprecated Public Symbols: ON\r\n         I/O filters (external):  DEFLATE DECODE ENCODE\r\n                            MPE:\r\n                     Direct VFD:\r\n                        dmalloc:\r\nClear file buffers before write: ON\r\n           Using memory checker: OFF\r\n         Function Stack Tracing: OFF\r\n      Strict File Format Checks: OFF\r\n\r\n```\r\nThe script crashes when` tf.contrib.layers.convolution2d` is invoked\r\n\r\nI'm using windows 10 x64 and I have installed all available update released for the others libraries\r\n\r\nHere the list of packages of my setup\r\n```\r\nalabaster (0.7.10)\r\nanaconda-clean (1.0)\r\nanaconda-client (1.6.2)\r\nanaconda-navigator (1.5)\r\nanaconda-project (0.4.1)\r\nappdirs (1.4.3)\r\nargcomplete (1.8.2)\r\nasn1crypto (0.22.0)\r\nastroid (1.4.9)\r\nastropy (1.3.1)\r\nBabel (2.3.4)\r\nbackports.shutil-get-terminal-size (1.0.0)\r\nbeautifulsoup4 (4.5.3)\r\nbitarray (0.8.1)\r\nblaze (0.10.1)\r\nbleach (2.0.0)\r\nbokeh (0.12.4)\r\nboto (2.46.1)\r\nBottleneck (1.2.0)\r\ncffi (1.10.0)\r\nchardet (2.3.0)\r\nchest (0.2.3)\r\nclick (6.7)\r\ncloudpickle (0.2.2)\r\nclyent (1.2.2)\r\ncolorama (0.3.7)\r\ncomtypes (1.1.3)\r\nconda (4.3.14)\r\nconda-build (2.1.7)\r\nconda-verify (2.0.0)\r\nconfigobj (5.0.6)\r\ncontextlib2 (0.5.4)\r\ncryptography (1.8.1)\r\ncycler (0.10.0)\r\nCython (0.25.2)\r\ncytoolz (0.8.2)\r\ndask (0.14.1)\r\ndatashape (0.5.4)\r\ndecorator (4.0.11)\r\ndill (0.2.6)\r\ndocutils (0.13.1)\r\ndynd (c328ab7)\r\nentrypoints (0.2.2)\r\net-xmlfile (1.0.1)\r\nfastcache (1.0.2)\r\nfilelock (2.0.7)\r\nFlask (0.12)\r\nFlask-Cors (3.0.2)\r\ngevent (1.2.1)\r\nglue-core (0.10.1)\r\nglue-vispy-viewers (0.7.2)\r\nglueviz (0.10.1)\r\ngreenlet (0.4.12)\r\nh5py (2.7.0)\r\nHeapDict (1.0.0)\r\nhtml5lib (0.999999999)\r\nidna (2.5)\r\nimagesize (0.7.1)\r\nipykernel (4.5.2)\r\nipython (5.3.0)\r\nipython-genutils (0.2.0)\r\nipywidgets (6.0.0)\r\nisort (4.2.5)\r\nitsdangerous (0.24)\r\njdcal (1.3)\r\njedi (0.10.0)\r\nJinja2 (2.9.5)\r\njsonschema (2.6.0)\r\njupyter (1.0.0)\r\njupyter-client (5.0.0)\r\njupyter-console (5.1.0)\r\njupyter-core (4.3.0)\r\nlazy-object-proxy (1.2.2)\r\nllvmlite (0.16.0)\r\nlocket (0.2.0)\r\nlxml (3.7.3)\r\nMarkupSafe (1.0)\r\nmatplotlib (2.0.0)\r\nmccabe (0.6.1)\r\nmenuinst (1.4.4)\r\nmistune (0.7.4)\r\nmpmath (0.19)\r\nmultipledispatch (0.4.9)\r\nnb-anacondacloud (1.2.0)\r\nnb-conda (2.0.0)\r\nnb-conda-kernels (2.0.0)\r\nnbconvert (5.1.1)\r\nnbformat (4.3.0)\r\nnbpresent (3.0.2)\r\nnetworkx (1.11)\r\nnltk (3.2.2)\r\nnose (1.3.7)\r\nnotebook (4.4.1)\r\nnumba (0.31.0)\r\nnumexpr (2.6.2)\r\nnumpy (1.12.1)\r\nnumpydoc (0.6.0)\r\nodo (0.5.0)\r\nolefile (0.44)\r\nopencv-python (3.2.0.6)\r\nopenpyxl (2.4.5)\r\npackaging (16.8)\r\npandas (0.19.2)\r\npandocfilters (1.4.1)\r\npartd (0.3.7)\r\npath.py (10.1)\r\npathlib2 (2.2.1)\r\npatsy (0.4.1)\r\npep8 (1.7.0)\r\npickleshare (0.7.4)\r\nPillow (4.0.0)\r\npip (9.0.1)\r\npkginfo (1.4.1)\r\nply (3.10)\r\nprompt-toolkit (1.0.13)\r\nprotobuf (3.2.0)\r\npsutil (5.2.0)\r\npy (1.4.33)\r\npyasn1 (0.2.3)\r\npycosat (0.6.2)\r\npycparser (2.17)\r\npycrypto (2.6.1)\r\npycurl (7.43.0)\r\npyflakes (1.5.0)\r\nPygments (2.2.0)\r\npylint (1.6.5)\r\nPyOpenGL (3.1.0)\r\npyOpenSSL (16.2.0)\r\npyparsing (2.2.0)\r\npyreadline (2.1)\r\npytest (3.0.7)\r\npython-dateutil (2.6.0)\r\npytz (2016.10)\r\npywin32 (220)\r\nPyYAML (3.12)\r\npyzmq (16.0.2)\r\nQtAwesome (0.4.4)\r\nqtconsole (4.2.1)\r\nQtPy (1.2.1)\r\nrequests (2.13.0)\r\nrope-py3k (0.9.4.post1)\r\nscikit-image (0.12.3)\r\nscikit-learn (0.18.1)\r\nscipy (0.19.0)\r\nseaborn (0.7.1)\r\nsetuptools (34.3.2)\r\nsimplegeneric (0.8.1)\r\nsingledispatch (3.4.0.3)\r\nsix (1.10.0)\r\nsnowballstemmer (1.2.1)\r\nsockjs-tornado (1.0.3)\r\nSphinx (1.5.3)\r\nspyder (3.1.3)\r\nSQLAlchemy (1.1.6)\r\nstatsmodels (0.8.0)\r\nsympy (1.0)\r\ntables (3.3.0)\r\ntensorflow (1.0.1)\r\ntestpath (0.3)\r\ntoolz (0.8.2)\r\ntornado (4.4.2)\r\ntraitlets (4.3.2)\r\nunicodecsv (0.14.1)\r\nwcwidth (0.1.7)\r\nwebencodings (0.5)\r\nWerkzeug (0.12.1)\r\nwheel (0.29.0)\r\nwidgetsnbextension (2.0.0)\r\nwin-unicode-console (0.5)\r\nwrapt (1.10.10)\r\nxlrd (1.0.0)\r\nXlsxWriter (0.9.6)\r\nxlwings (0.10.4)\r\nxlwt (1.2.0)\r\n```\r\n\r\n", "comments": ["(I assume you're using Jupyter/IPython.) What commands have you executed in the notebook before this error is raised?", "@mrry The script crashes when `tf.contrib.layers.convolution2d` is invoked ", "Can you try running the script using [`python -m trace`](https://docs.python.org/3.5/library/trace.html) and report back with what the last lines were before the HDF5 error? That should help to track down what dependency is causing the problem.", "@mrry this is the last line\r\n`conv2d_layer1 = tf.contrib.layers.convolution2d(batch_immagine_float, num_outputs=32, kernel_size=(5, 5), stride=(2, 2), activation_fn=tf.nn.relu, weights_initializer=tf.random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32), trainable=True)`\r\n", "Did you get that line from running with `-m trace`? I would expect to see calls into various libraries (in particular, `import` statements for dependent libraries), and we'll need that information to determine the root cause. ", "@mrry unfortunately enviroment crashes completely at this line and I'm unable to track the calls with more details, if I try to use `-m trace` console start an endless loop and I'm not even able to copy paste what appears ", "If you run `python -m trace myscript.py` from the Command Prompt, can you capture the last few lines of trace output? (Or does it *crash* the command prompt? In that case, something would have to be very broken....)", "@mrry As i have said is not possible, if I try to run the script with `- m trace` console goes crazy and I'm forced to CTRL+ALT+DEL. If I run the script without -m trace the whole python crashes but let me copy paste the error described above. Yes, something is very broken", "Perhaps you could redirect the output with `-m trace` to a file?", "problem solved removing conda hdf5 and installing a newer version", "Glad to hear it!", "Removing and reinstalling wont work cause in this case, it says 'There is no module called 'Tensorflow', but when I install tensoeflow, the hdf5 is automatically back, so it's like a dead loop.\r\n", "> Removing and reinstalling wont work cause in this case, it says 'There is no module called 'Tensorflow', but when I install tensoeflow, the hdf5 is automatically back, so it's like a dead loop.\r\n\r\nI know this is extremely late. But after you have installed tensorflow downgrade your h5py, the previous version is working for me.\r\n\r\n\"pip install h5py==2.9.0\" hope this works for you too! :)\r\n\r\nhttps://i.gyazo.com/b77a04b84efad0f2e8eca5154c9b2ed2.png"]}, {"number": 8626, "title": "The reuse flag of tf.variable_scope doesn't work with tf.contrib.layers ?", "body": "For example, I defined a simple network\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.layers as tcl\r\n\r\ndef model(x, reuse=None):\r\n    with tf.variable_scope('foo', reuse=reuse) as scope:\r\n        tcl.conv2d(x, 3, 3, 1)\r\n```\r\nAnd then, I try to call the model function twice **without** setting reuse=True for second call\r\n```python\r\nx1 = tf.placeholder(tf.float32, (10,10,3))\r\nx2 = tf.placeholder(tf.float32, (10,10,3))\r\nmodel(x1)\r\nmodel(x2)\r\n```\r\nWhen using with tf.get_variable(), this will cause a error. However, it's not the case for tf.contrib.layers?\r\nI tried to print out all the nodes in the graph with following codes\r\n```python\r\nfor n in tf.get_default_graph().as_graph_def().node:\r\n    print(n.name)\r\n```\r\nI got this result:\r\n```\r\nPlaceholder\r\nPlaceholder_1\r\nfoo/Conv/weights/Initializer/random_uniform/shape\r\nfoo/Conv/weights/Initializer/random_uniform/min\r\nfoo/Conv/weights/Initializer/random_uniform/max\r\nfoo/Conv/weights/Initializer/random_uniform/RandomUniform\r\nfoo/Conv/weights/Initializer/random_uniform/sub\r\nfoo/Conv/weights/Initializer/random_uniform/mul\r\nfoo/Conv/weights/Initializer/random_uniform\r\nfoo/Conv/weights\r\nfoo/Conv/weights/Assign\r\nfoo/Conv/weights/read\r\nfoo/Conv/biases/Initializer/Const\r\nfoo/Conv/biases\r\nfoo/Conv/biases/Assign\r\nfoo/Conv/biases/read\r\nfoo/Conv/convolution/Shape\r\nfoo/Conv/convolution/dilation_rate\r\nfoo/Conv/convolution/ExpandDims/dim\r\nfoo/Conv/convolution/ExpandDims\r\nfoo/Conv/convolution/ExpandDims_1/dim\r\nfoo/Conv/convolution/ExpandDims_1\r\nfoo/Conv/convolution/Conv2D\r\nfoo/Conv/convolution/Squeeze\r\nfoo/Conv/BiasAdd\r\nfoo/Conv/Relu\r\nfoo_1/Conv/convolution/Shape\r\nfoo_1/Conv/convolution/dilation_rate\r\nfoo_1/Conv/convolution/ExpandDims/dim\r\nfoo_1/Conv/convolution/ExpandDims\r\nfoo_1/Conv/convolution/ExpandDims_1/dim\r\nfoo_1/Conv/convolution/ExpandDims_1\r\nfoo_1/Conv/convolution/Conv2D\r\nfoo_1/Conv/convolution/Squeeze\r\nfoo_1/Conv/BiasAdd\r\nfoo_1/Conv/Relu\r\n```\r\nIt seems that there is only one copy of weights, instead of two.\r\nSo, even if ```reuse``` is not set to ```True```, the weights can still be shared ?\r\n\r\nIs this the correct behavior?\r\nOr did I miss anything?\r\n\r\nI'm using Python3, Tensorflow 1.0.1, Ubuntu 16.04.", "comments": ["I am not sure how you get this, I use `layers` often and it performs as it should.\r\n\r\nI tried to run your lines and as expected `model(x2)` gives an error if used without the `reuse` flag.", "I was able to repro this 1.0, but I believe it's fixed in nightly.", "@SeguinBe  What's the version of tensorflow you use?\r\n@skye  OK,  I will try this in nightly\r\nThanks for your responses.", "Yeah I'm using nightly indeed.", "@skye vaguely thinks it's fixed.  Happy to reopen if not."]}, {"number": 8625, "title": "ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients,", "body": "I found a error when I try to train my models using the GradientDescentOptimizer(). There are my train code.\r\n```\r\n    y_prob = tf.sigmoid(layer_dropped)\r\n\r\n    # Set a thresholds value\r\n    y_pred = tf.floor(y_prob)\r\n\r\n    # Loss Operation\r\n    loss_op = tf.reduce_mean(tf.abs(y_true - y_pred))\r\n    optimizer_op = tf.train.GradientDescentOptimizer(0.005).minimize(loss_op)\r\n```\r\n\r\nIf I do not use the `tf.floor()` function in my loss operation, the training is OK. Just like this:\r\n```\r\nloss_op = tf.reduce_mean(tf.abs(y_true - y_prob))\r\noptimizer_op = tf.train.GradientDescentOptimizer(0.005).minimize(loss_op)\r\n```", "comments": ["That is correct. `tf.floor` doesn't have a gradient. It's not easily differentiable. See this stackoverflow [post](http://stackoverflow.com/questions/42206906/alternative-plan-of-tf-floor/42210345#42210345) for more details.", "ValueError                                Traceback (most recent call last)\r\n~\\NNV2\\train1.py in <module>()\r\n    106     case = args.case\r\n    107     logdir = '{}/{}/train1'.format(logdir_path, case)\r\n--> 108     train(logdir=logdir)\r\n    109     print(\"Done\")\r\n\r\n~\\NNV2\\train1.py in train(logdir, queue)\r\n     31     with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\r\n     32         var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'net/net1')\r\n---> 33         train_op = optimizer.minimize(loss_op, global_step=global_step, var_list=var_list)\r\n     34 \r\n     35     # Summary\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py in minimize(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\r\n    405           \"No gradients provided for any variable, check your graph for ops\"\r\n    406           \" that do not support gradients, between variables %s and loss %s.\" %\r\n--> 407           ([str(v) for _, v in grads_and_vars], loss))\r\n    408 \r\n    409     return self.apply_gradients(grads_and_vars, global_step=global_step,\r\n\r\nValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables ", "how to resolve this\r\n", "Did you get how to resolve this issue? @shwetagargade216 \r\nI too am facing the same issue.", "Same problem there "]}, {"number": 8624, "title": "Constant folding does not work across devices?", "body": "I've been trying to understand tensorflow internals recently. I found in `tensorflow/core/common_runtime/direct_session.cc`, if I understand it correctly, that constant folding only take place at [#L1051](https://github.com/tensorflow/tensorflow/blob/ef56133461079f28b61b5a83a62685051408aadb/tensorflow/core/common_runtime/direct_session.cc#L1051) after graph partitioning, so constants won't propagate through device boundary.\r\n\r\nThis is also evidenced by a simple experiment:\r\n```\r\nwith tf.device('gpu'):\r\n    a = tf.constant(0)\r\nwith tf.device('cpu'):\r\n    b = a + 1\r\n    c = b + 1\r\n```\r\nResulting computation time graph is\r\n![graph-run](https://cloud.githubusercontent.com/assets/10446514/24199102/62c291ae-0f43-11e7-8689-a595ded2c7ed.png)\r\nWhereas placing all ops on GPU gives a fully shaded graph.\r\n\r\nDid I miss something? Or is there any consideration not to run constant folding before partitioning the graph?", "comments": ["Right, from your example it looks like it should have been folded all the way up to `c = 2` on `cpu` in the ideal case.\r\n\r\nIf you're confident, that might be a good PR to send. Also, I'm curious to know what happens with XLA enabled.", "I have tried enabling XLA with both session config and jit_scope. With the session config approach, nothing changed. With jit_scope, all nodes became shaded, but even when `a` was fed, so it is more likely an incompatibility between XLA and tracing than an indication that constant folding is working.\r\n\r\nGlobal constant folding has its own problem, in that a full graph can only be run using a session, while a partition graph requires just an executor. Therefore, constant folding sounds more suitable as an JIT optimization to me. For example, a session triggers constant folding at the second run, then it identifies constant foldable tensors and add them to fetches, and finally substitute them at the third run.", "Right. When xla is enabled, all that is jit'ed shows as a single node. So\nit may or may not be folded inside.\n\nOn Mar 25, 2017 8:19 AM, \"Huazuo Gao\" <notifications@github.com> wrote:\n\n> I have tried enabling XLA with both session config and jit_scope. With the\n> session config approach, nothing changed. With jit_scope, all nodes became\n> shaded, but even when a was fed, so it is more likely an incompatibility\n> between XLA and tracing than an indication that constant folding is working.\n>\n> Global constant folding has its own problem, in that a full graph can only\n> be run using a session, while a partition graph requires just an executor.\n> Therefore, constant folding sounds more suitable as an JIT optimization to\n> me. For example, a session triggers constant folding at the second run,\n> then it identifies constant foldable tensors and add them to fetches, and\n> finally substitute them at the third run.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8624#issuecomment-289218123>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbbebDW61-pTcM9cp9tgmg3z2UEzlks5rpTBogaJpZM4MlL8n>\n> .\n>\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8623, "title": "TensorFlow install issue ", "body": "Hi Team .,\r\n\r\nWhile installing TensorFlow on Windows10 I'm facing the below error., \r\n>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl\r\n\r\n****tensorflow-1.0.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.****\r\n\r\nPlease let me know how to overcome this issue.\r\n\r\nThanks\r\nPavan", "comments": ["Just try this\r\n`pip3 install tensorflow`\r\n\r\nthis should do the trick", ">pip3 install tensorflow\r\n**'pip3' is not recognized as an internal or external command,\r\noperable program or batch file.**\r\nNote : My anaconda version is : Anaconda3-4.3.0.1-Windows-x86_64  (python 3.6.0)\r\n\r\nHelp me how can I resolve this ... Thanks ", "are u using pyhton 2.7?\r\nif so , try\r\npip install tensorflow", ">pip install tensorflow\r\nCollecting tensorflow\r\n  **Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow**", "On windows, we only support python 3.5. We do not have support for python 2.7\r\nThis is clearly stated in our installation guide here:\r\nhttps://www.tensorflow.org/install/install_windows\r\n\r\nClosing this issue, as this is not an issue in TF itself.", "Hi.,\r\nI'm using python 3.6 Version. Still facing the issue.. If you are interested in closing the issue, go ahead and close, but my issue is not resolved.   My environment details : OS - Windows 10 and Python 3.6 and how would you know my python version is 2.7 (no where I mentioned) ? ", "@upavan You can create and activate a new environment with python version 3.5 by doing `conda create --name tensorflow python=3.5`", "We currently only have support for python 3.5 on windows, as stated in our installation documentation.\r\nI assumed you used python 2.7, as you did not respond negatively to @lxsgdsgg 's query.\r\nSorry for the misunderstanding. But as I stated, it does not change the answer, we only have support for python 3.5 on windows.\r\n\r\nIf you are using anaconda, you can follow the suggestion by @jsondoo to create an environment that has python 3.5", "Hi Team.,\r\n\r\nThanks.. I guess TensorFlow got installed on my PC.. Thanks a lot.. \r\n\r\nAnd one more issue with Jupyter/ Spyder :  While working with Jupyter/ Spyder ., I'm facing the below error : **ModuleNotFoundError: No module named 'tensorflow'**  --- Do I need to install any other external software / Packages.. Please let me know how can I work with GUI tools like Jupyter/ Spyder .. meanwhile I'll try with my PC restart.\r\n\r\nThanks \r\nPavan\r\n\r\n\r\n", "Im glad the issue is resolved for you.\r\nFor the issue with Jupyter/Spyder, it sounds to me like a setup issue with Jupyter.\r\n\r\nGithub is a direct channel to tensorflow developers for reporting bugs in tensorflow itself.\r\nIt sounds like you are having some problems with Python/Jupyter/Spyder setup, which are standalone pieces of software themselves.\r\nI recommend reaching out to stackoverflow for general help with these software, or looking into product forums to see what is the best way to setup jupyter and set it up to use a specific conda environment you are creating.", "Thanks for the info.. can you give me the link for stackoverflow of github, I'm trying to post but I didn't find the link., please share me the link to post my issue... thanks  ", "stackoverflow is stackoverflow.com\r\nFor product forums, you will need to google search the products you are using and browse through the results.", "Thanks a lot... you are amazing .... ", "@jsondoo i tried creating conda create --name tensorflow python=3.5 but this error came:\r\n\"prefix already exists c:\\Anaconda\\envs\\tensorflow\" which makes sense, i dont understand how i can name it tensorflow when tensorflow is already installed via anaconda", "@davtomic  i got the same error. you must first remove the tensorflow environment you had already created. you can do that through command line which i couldnt figure out. So I removed it form anaconda navigator under Environments Tab. After removing you try to create a new environment with python=3.5", "it works for me.\r\ndelete the tensorflow env at anaconda navigator under Environments Tab. then create tf tenv for 3.5 again. then no more error below\r\ntensorflow-1.0.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.\r\n\r\nsimply, tensorflow not supporting 3.6 yet?", "\"conda create -n tensorflow  python=3.5\"  also works for me~\r\nI've installed Anaconda 4.3.1 with python 3.6 and following the guidance from \r\n[https://www.tensorflow.org/install/install_windows#common_installation_problems](url) to install tensorflow with it and meeting the \"not supported wheel\" problem. \r\nI just deactivate the former conda environment and remove it with:\r\n\"deactivate tensorflow\"\r\n\"conda env remove -n tensorflow\"\r\nAnd then repeating the guidance with additional \"python=3.5\" after the creating cmd fixed the problem\r\n \"conda create -n tensorflow  python=3.5\" has downloaded and installed python3.5 to this new environment~ ", "I'm having the same problem. Running Anaconda on Windows. I've created an environment and installed python 3.5 it in.\r\n```    \r\n$ python --version\r\nPython 3.5.3 :: Continuum Analytics, Inc.\r\n(py35_64)\r\n```\r\nWhen I execute \r\n```\r\npip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl\r\n```\r\nI get the error:\r\n```  \r\n tensorflow-1.2.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.\r\n```\r\n  ", "I got same error with @Geekly \r\nUsing Python 3.5, Windows 10 32-bit. ", "There is no support for 32 bit operating systems. You can try building from sources yourself, but there may be some issues even during build.", "Try with the latest version of TensorFlow your issue will get resolve., try\non 64Bit version.\n\nOn Thu, Jul 20, 2017 at 1:42 PM, gunan <notifications@github.com> wrote:\n\n> There is no support for 32 bit operating systems. You can try building\n> from sources yourself, but there may be some issues even during build.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8623#issuecomment-316629973>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALgYxMAwadOr3Vi0ZK93wc_S-KJHPOxIks5sPwvSgaJpZM4MlG6w>\n> .\n>\n", "Getting the same error as @Geekly.. When I try\r\n`pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp35-cp35m-win_amd64.whl`\r\nhowever, when i try \r\n` pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp36-cp36m-win_amd64.whl`\r\n\r\n**cp36-cp36m**\r\n\r\neverything excep tensorflow gets installed succesfully", "You should just try running\r\n```\r\npip install tensorflow\r\n```\r\nPip will pick the correct version for you based on your OS, python version, etc.\r\n", "I can confirm that `pip install tensorflow` works. My configuration - Windows 7, 64 bit. I upgraded to Anaconda 4.4 and python 3.6.2. I had a previous installation of TensorFlow 1.2 installed using the following command `pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0rc2-cp35-cp35m-win_amd64.whl `\r\n\r\nAll I had to do was `pip uninstall tensorflow` followed by `pip install tensorflow` ", "@gunan /@prachm i had to use` conda install `otherwise was getting the previous error", "@aritrabasu104 that works for me ! Thanks a lot!"]}, {"number": 8622, "title": "virtualenv install python issues.", "body": "While installing virtualenv for tensorflow, I get the following error.\r\n\r\nThe executable /Users/xxx/tensorflow/bin/python is not functioning ERROR: It thinks sys.prefix is\r\n'/Users/xxx' (should be '/Users/xxx/tensorflow')\r\n\r\nIt seems it is common and related to having python3 or conda installed. But I could not find a known solution.\r\n\r\nOn my OS Sierra 10.12.3 machine, I have Conda 1.4.3 (python 3.6) installed (came with standard Conda install). \r\n\r\nThanks.\r\n\r\n\r\n\r\n\r\n", "comments": ["It sounds like virtualenv is not functioning, regardless of tensorflow?", "This is definitely an issue with python in your virtualenv.\r\nSince it is not a TF issue, I will close this.\r\nPlease reach use support channels for anaconda for help with python issues in anaconda."]}, {"number": 8621, "title": "R1.1", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 8620, "title": "Add more Android Examples", "body": "Hi,\r\n\r\nThe only Android example is currently for image recognition, but there's a lot more that can be done with Machine Learning on handsets.\r\n\r\nCould more examples be added, using Tensorflow to recognize patterns from motion sensors such as accelerometer for example?\r\n\r\n[See related question here on StackOverflow](http://stackoverflow.com/questions/42901282/train-android-app-to-recognize-sensor-patterns-using-machine-learning)", "comments": ["where is it?", "@petewarden for comments.", "I agree that it would be good to have more examples outside of images, and we do have some in-progress. We would welcome contributions too of course!", "Closing since this is too open ended.  We'd be happy to accept PRs!"]}, {"number": 8619, "title": "compilation error on latest master", "body": "Seems to have been caused by ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69\r\n```\r\n$ bazel build -c opt //tensorflow/examples/android:tensorflow_demo\r\nERROR: /Users/yonits/dev/joytunes/tensorflow/third_party/gpus/cuda_configure.bzl:828:18: unexpected keyword 'environ' in call to repository_rule(implementation: function, *, attrs: dict or NoneType = None, local: bool = False).\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension file 'third_party/gpus/cuda_configure.bzl' has errors.\r\n```", "comments": ["Which version of Bazel are you using?", "Was using 0.4.4, upgrading to 0.4.5 seems to have solved it.\r\nThanks.", "Having a similar issue, build fails for me on bazel version 0.4.5.\r\n\r\nBuild fails using \"git checkout ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69\"\r\nhttp://pastebin.com/FHt0r5kS\r\n\r\nBuild succeeds using \"git checkout 450386c513a4c68d6b77f9b475dc39b442775a86\" which is the commit prior to the above failing one.\r\nhttp://pastebin.com/3vGHik0G\r\n\r\nCUDA Version 8.0.61\r\nCUDNN version 5.1.10\r\n\r\nbazel version info:\r\n\r\njbunk@desktop:~/libraries$ bazel version\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778", "Can you give the output of `export` after the failing build?\n\nOn Wed, Mar 22, 2017, 1:33 PM Jason Bunk <notifications@github.com> wrote:\n\n> Having a similar issue, build fails for me on bazel version 0.4.5.\n>\n> Build fails using \"git checkout ede5ebe\n> <https://github.com/tensorflow/tensorflow/commit/ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69>\n> \"\n> http://pastebin.com/FHt0r5kS\n>\n> Build succeeds using \"git checkout 450386c\n> <https://github.com/tensorflow/tensorflow/commit/450386c513a4c68d6b77f9b475dc39b442775a86>\"\n> which is the commit prior to the above failing one.\n> http://pastebin.com/3vGHik0G\n>\n> CUDA Version 8.0.61\n> CUDNN version 5.1.10\n>\n> bazel version info:\n>\n> jbunk@desktop:~/libraries$ bazel version\n> Build label: 0.4.5\n> Build target:\n> bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n> Build time: Thu Mar 16 12:19:38 2017 (1489666778)\n> Build timestamp: 1489666778\n> Build timestamp as int: 1489666778\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8619#issuecomment-288477369>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADjHf2bAhcOKtYERry09b3sWy9DVL1Xaks5roVtngaJpZM4Mk9v2>\n> .\n>\n", "The output of export is the same between the two commits except for ssh details I omitted.\r\n\r\n```\r\njbunk@desktop:~/libraries/Tensorflow-Github$ export\r\ndeclare -x DERBY_HOME=\"/usr/lib/jvm/java-8-oracle/db\"\r\ndeclare -x DISPLAY=\"localhost:11.0\"\r\ndeclare -x DYLD_LIBRARY_PATH=\"/home/jbunk/torch/install/lib:/home/jbunk/torch/install/lib:\"\r\ndeclare -x HISTFILE=\"/home/jbunk/.bash_eternal_history\"\r\ndeclare -x HISTFILESIZE=\"\"\r\ndeclare -x HISTSIZE=\"\"\r\ndeclare -x HISTTIMEFORMAT=\"[%F %T] \"\r\ndeclare -x HOME=\"/home/jbunk\"\r\ndeclare -x J2REDIR=\"/usr/lib/jvm/java-8-oracle/jre\"\r\ndeclare -x J2SDKDIR=\"/usr/lib/jvm/java-8-oracle\"\r\ndeclare -x JAVA_HOME=\"/usr/lib/jvm/java-8-oracle\"\r\ndeclare -x LANG=\"en_US.UTF-8\"\r\ndeclare -x LD_LIBRARY_PATH=\"/home/jbunk/torch/install/lib:/home/jbunk/torch/install/lib::/usr/local/cuda/lib64\"\r\ndeclare -x LESSCLOSE=\"/usr/bin/lesspipe %s %s\"\r\ndeclare -x LESSOPEN=\"| /usr/bin/lesspipe %s\"\r\ndeclare -x LOGNAME=\"jbunk\"\r\ndeclare -x LS_COLORS=\"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\"\r\ndeclare -x LUA_CPATH=\"/home/jbunk/torch/install/lib/?.so;/home/jbunk/.luarocks/lib/lua/5.1/?.so;/home/jbunk/torch/install/lib/lua/5.1/?.so;./?.so;/usr/local/lib/lua/5.1/?.so;/usr/local/lib/lua/5.1/loadall.so\"\r\ndeclare -x LUA_PATH=\"/home/jbunk/.luarocks/share/lua/5.1/?.lua;/home/jbunk/.luarocks/share/lua/5.1/?/init.lua;/home/jbunk/torch/install/share/lua/5.1/?.lua;/home/jbunk/torch/install/share/lua/5.1/?/init.lua;./?.lua;/home/jbunk/torch/install/share/luajit-2.1.0-beta1/?.lua;/usr/local/share/lua/5.1/?.lua;/usr/local/share/lua/5.1/?/init.lua\"\r\ndeclare -x MAIL=\"/var/mail/jbunk\"\r\ndeclare -x OLDPWD=\"/home/jbunk/libraries\"\r\ndeclare -x PATH=\"/home/jbunk/torch/install/bin:/home/jbunk/bin:/home/jbunk/.local/bin:/home/jbunk/torch/install/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin\"\r\ndeclare -x PWD=\"/home/jbunk/libraries/Tensorflow-Github\"\r\ndeclare -x QT_QPA_PLATFORMTHEME=\"appmenu-qt5\"\r\ndeclare -x SHELL=\"/bin/bash\"\r\ndeclare -x SHLVL=\"1\"\r\ndeclare -x TERM=\"xterm-256color\"\r\ndeclare -x USER=\"jbunk\"\r\ndeclare -x XDG_RUNTIME_DIR=\"/run/user/1001\"\r\ndeclare -x XDG_SESSION_ID=\"52\"\r\n```", "`cat .bazelrc` from the tensorflow workspace?\n\nOn Wed, Mar 22, 2017 at 2:41 PM Jason Bunk <notifications@github.com> wrote:\n\n> The output of export is the same between the two commits except for ssh\n> details I omitted.\n>\n> jbunk@desktop:~/libraries/Tensorflow-Github$ export\n> declare -x DERBY_HOME=\"/usr/lib/jvm/java-8-oracle/db\"\n> declare -x DISPLAY=\"localhost:11.0\"\n> declare -x DYLD_LIBRARY_PATH=\"/home/jbunk/torch/install/lib:/home/jbunk/torch/install/lib:\"\n> declare -x HISTFILE=\"/home/jbunk/.bash_eternal_history\"\n> declare -x HISTFILESIZE=\"\"\n> declare -x HISTSIZE=\"\"\n> declare -x HISTTIMEFORMAT=\"[%F %T] \"\n> declare -x HOME=\"/home/jbunk\"\n> declare -x J2REDIR=\"/usr/lib/jvm/java-8-oracle/jre\"\n> declare -x J2SDKDIR=\"/usr/lib/jvm/java-8-oracle\"\n> declare -x JAVA_HOME=\"/usr/lib/jvm/java-8-oracle\"\n> declare -x LANG=\"en_US.UTF-8\"\n> declare -x LD_LIBRARY_PATH=\"/home/jbunk/torch/install/lib:/home/jbunk/torch/install/lib::/usr/local/cuda/lib64\"\n> declare -x LESSCLOSE=\"/usr/bin/lesspipe %s %s\"\n> declare -x LESSOPEN=\"| /usr/bin/lesspipe %s\"\n> declare -x LOGNAME=\"jbunk\"\n> declare -x LS_COLORS=\"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\"\n> declare -x LUA_CPATH=\"/home/jbunk/torch/install/lib/?.so;/home/jbunk/.luarocks/lib/lua/5.1/?.so;/home/jbunk/torch/install/lib/lua/5.1/?.so;./?.so;/usr/local/lib/lua/5.1/?.so;/usr/local/lib/lua/5.1/loadall.so\"\n> declare -x LUA_PATH=\"/home/jbunk/.luarocks/share/lua/5.1/?.lua;/home/jbunk/.luarocks/share/lua/5.1/?/init.lua;/home/jbunk/torch/install/share/lua/5.1/?.lua;/home/jbunk/torch/install/share/lua/5.1/?/init.lua;./?.lua;/home/jbunk/torch/install/share/luajit-2.1.0-beta1/?.lua;/usr/local/share/lua/5.1/?.lua;/usr/local/share/lua/5.1/?/init.lua\"\n> declare -x MAIL=\"/var/mail/jbunk\"\n> declare -x OLDPWD=\"/home/jbunk/libraries\"\n> declare -x PATH=\"/home/jbunk/torch/install/bin:/home/jbunk/bin:/home/jbunk/.local/bin:/home/jbunk/torch/install/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin\"\n> declare -x PWD=\"/home/jbunk/libraries/Tensorflow-Github\"\n> declare -x QT_QPA_PLATFORMTHEME=\"appmenu-qt5\"\n> declare -x SHELL=\"/bin/bash\"\n> declare -x SHLVL=\"1\"\n> declare -x TERM=\"xterm-256color\"\n> declare -x USER=\"jbunk\"\n> declare -x XDG_RUNTIME_DIR=\"/run/user/1001\"\n> declare -x XDG_SESSION_ID=\"52\"\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8619#issuecomment-288498349>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADjHfy3C5I5-G8BdeG3-VcF2btb2Gv-3ks5roWtqgaJpZM4Mk9v2>\n> .\n>\n", "It appears to be empty (zero bytes) in ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69 after ./configure, while there is no \".bazelrc\" at all in 450386c513a4c68d6b77f9b475dc39b442775a86. If I simply delete the empty \".bazelrc\" in ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69 before `bazel build --config=opt --config=cuda ...` it still fails.", "In the latest commit 4e18625c55afdbe50e922a70a12df05320e387e0, if I revert the lines in \"third_party/gpus/cuda_configure.bzl\" changed by ede5ebe54f0689a53eeaf0fb1c9a25f136ab3a69 to what they were in 450386c513a4c68d6b77f9b475dc39b442775a86, the compiliation succeeds.", "Ok the problem is the missing TF_* environment variable in the environment. We should check them in the .bazelrc files, let me prepare a PR for that.", "Am still seeing this issue. Can anyone help by letting me know how to fix this.", "You need to upgrade the version of  bazel you are using.", "have the same problem with basel version 0.26.1  \r\n\r\n/4a5a8dc24223cbce1398873ead9ee5e3/external/org_tensorflow/third_party/gpus/cuda_configure.bzl:115:1: load() statements must be called before any other statement. First non-load() statement appears at /private/var/tmp/_bazel_anna.khaimovich/4a5a8dc24223cbce1398873ead9ee5e3/external/org_tensorflow/third_party/gpus/cuda_configure.bzl:26:1. Use --incompatible_bzl_disallow_load_after_statement=false to temporarily disable this check.\r\nERROR: error loading package '': in /private/var/tmp/_bazel_anna.khaimovich/4a5a8dc24223cbce1398873ead9ee5e3/external/org_tensorflow/tensorflow/workspace.bzl: Extension 'third_party/gpus/cuda_configure.bzl' has errors\r\n "]}, {"number": 8618, "title": "Cherrypicking Asim's changes.", "body": "Java: Load native library from class loader resources if possible.", "comments": ["Jenkins, test this please.", "Flake due to tight numerical bounds.\r\njenkins, test this please.\r\n\r\n@av8ramit Let's check if there is a bug filed for `conv_ops_3d_test` flakiness, and file a new one if there is none.\r\nCopying the failing job link here to make it easier to find later.:\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-gpu/4187/"]}, {"number": 8617, "title": "Error when using lookup table from tf.contrib.keras", "body": "I'm trying to build a simple model that includes string input and lookup in a lookup table, and embedding.\r\n\r\nI get an error that appears to caused by using non keras layers in a keras model\r\n\r\nthe code:\r\n```\r\nimport tensorflow.contrib.keras as keras\r\nimport tensorflow\r\n\r\ninput_layer = keras.layers.Input(shape=(1,), name='input', dtype='string')\r\nlut = tensorflow.contrib.lookup.HashTable(tensorflow.contrib.lookup.KeyValueTensorInitializer(['a', 'b', 'c'], [1, 2, 3]), default_value=-1)\r\nlut_layer = lut.lookup(input_layer)\r\nembed = keras.layers.Embedding(input_dim=10, output_dim=5)(lut_layer)\r\n\r\nmodel = keras.models.Model(inputs=[input_layer], outputs=[embed])\r\n\r\n\r\n```\r\nthe error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/ophir/dev/ophir/tf_keras_2.py\", line 10, in <module>\r\n    model = keras.models.Model(inputs=[input_layer], outputs=[embed])\r\n  File \"/Users/ophir/anaconda3/envs/tf_master/lib/python3.6/site-packages/tensorflow/contrib/keras/python/keras/engine/topology.py\", line 1640, in __init__\r\n    build_map_of_graph(x, seen_nodes, depth=0)\r\n  File \"/Users/ophir/anaconda3/envs/tf_master/lib/python3.6/site-packages/tensorflow/contrib/keras/python/keras/engine/topology.py\", line 1631, in build_map_of_graph\r\n    next_node = layer.inbound_nodes[node_index]\r\nAttributeError: 'NoneType' object has no attribute 'inbound_nodes'\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nusing tensorflow on macos, built from source revision: 88998663605ca3b728d6eec298717c8a8558639f", "comments": ["@fchollet any idea?", "For the time being, any op that is not a Keras layer should be wrapped inside a Keras `Lambda` layer:\r\n\r\n```python\r\ninputs = keras.layers.Input(shape=(1,), name='input', dtype='string')\r\nlut = tensorflow.contrib.lookup.HashTable(tensorflow.contrib.lookup.KeyValueTensorInitializer(['a', 'b', 'c'], [1, 2, 3]), default_value=-1)\r\nlut_output = keras.layers.Lambda(lut.lookup)(inputs)\r\n```\r\n\r\nIf the wrapping is broken at any point, then it prevents you from being able to build a Keras model with your inputs/outputs later on.\r\n\r\nWe will automate this wrapping in a later version.\r\n", "@fchollet, what if the non-Keras layer has a backprop function and/or trainable params (say `tf.nn.conv2d`)? How can these be added to a Keras model? A Lambda layer would not handle the backpropagation / trainable params, correct?\r\n\r\n", "If you have parameters to train, you should write a custom layer:\nhttps://keras.io/layers/writing-your-own-keras-layers/\n\nOn 13 July 2017 at 00:40, Hans Gaiser <notifications@github.com> wrote:\n\n> @fchollet <https://github.com/fchollet>, what if the non-Keras layer has\n> a backprop function and/or trainable params? How can these be added to a\n> Keras model? A Lambda layer would not handle the backpropagation /\n> trainable params, correct?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8617#issuecomment-314997898>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AArWbwXyeZL-v4ydQ-GqQVoEez-NE5dLks5sNcoJgaJpZM4Mky9s>\n> .\n>\n", "> If you have parameters to train, you should write a custom layer:\r\n> https://keras.io/layers/writing-your-own-keras-layers/\r\n\r\nThanks @fchollet, I think I'm beginning to understand the situation. In my specific case I'm tring to use a layer with no trainable weights (RoiPooling) but it does have a backward propagation function. If I register the op in the C API with `REGISTER_OP`, wrap it in a Keras `Lambda` layer and register the backward propagation function with the same op name (currently only possible in python with the `@ops.RegisterGradient` decorator), then tensorflow (and thus Keras) should be able to compute correct gradients. I believe this is correct and I will continue to work under that assumption. If it is not correct then I would gladly hear about it :)", "Keras delegates gradient computation to TF. If you have custom\ndifferentiable ops that don't have weights, a Lambda layer works fine.\n\nOn 15 July 2017 at 09:37, Hans Gaiser <notifications@github.com> wrote:\n\n> If you have parameters to train, you should write a custom layer:\n> https://keras.io/layers/writing-your-own-keras-layers/\n>\n> Thanks @fchollet <https://github.com/fchollet>, I think I'm beginning to\n> understand the situation. In my specific case I'm tring to use a layer with\n> no trainable weights (RoiPooling) but it does have a backward propagation\n> function. If I register the op in the C API with REGISTER_OP, wrap it in\n> a Keras Lambda layer and register the backward propagation function with\n> the same op name (currently only possible in python with the\n> @ops.RegisterGradient decorator), then tensorflow (and thus Keras) should\n> be able to compute correct gradients. I believe this is correct and I will\n> continue to work under that assumption. If it is not correct then I would\n> gladly hear about it :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8617#issuecomment-315545819>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AArWb_IW-Mm04tVs1YHIzNBJBhZenWc7ks5sOOragaJpZM4Mky9s>\n> .\n>\n"]}, {"number": 8616, "title": "Branch 150846197", "body": "", "comments": ["Apologies I was not close to being done. Which is why I noted commit incomplete. I hadn't finished writing and obviously hadn't tested yet. Obviously you guys are moving way faster and I will stay out of the way. Only have an hour or two a day open to look at it. ", "@RealTimeDeployment Not sure this is the right PR for this comment? This is an internal PR."]}, {"number": 8615, "title": "Update version 1.1.0-rc0", "body": "Running the update_version script on r1.1.0-rc0.", "comments": ["Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 8614, "title": "Update 1.1.0rc0", "body": "Running the update_version script on r1.1.0-rc0.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 8613, "title": "Update version to r1.1.0-rc0.", "body": "Running the update_version script on r1.1.0-rc0.", "comments": ["Jenkins, test this please."]}, {"number": 8612, "title": "make_test_graphs.py fails to open file in binary mode, breaks in py3", "body": "The file //tensorflow/compiler/aot/tests/make_test_graphs.py attempts to write binary data to files without opening the files in binary mode, which raises errors in Python 3. This can be fixed by opening the files in binary mode, i.e. \r\n\r\n```\r\n74     with open(saver_file, 'wb') as f:\r\n75         f.write(saver.as_saver_def().SerializeToString())\r\n```\r\n\r\nI'm not sure if making this change will break Python 2. I will try and submit a pull request later in the week.\r\n", "comments": ["Thanks, that sounds like a good PR to send!", "Please mention this bug in the PR (`Fixes #8612` will make it auto-close this issue)."]}, {"number": 8611, "title": "TensorBoard not working, ", "body": " I run it as https://www.tensorflow.org/get_started/summaries_and_tensorboard here described, but the browser can't display it ,what's wrong with it ? \r\n![0x22a3](https://cloud.githubusercontent.com/assets/15243563/24180783/edbb7ff2-0ef1-11e7-852b-a579773aa8be.jpg)\r\n", "comments": ["and the version of Tensorflow is 0.11", "Please use the latest version of TF.\r\nThe tutorials on our website point to the latest version unless you specificly select older versions of TF."]}, {"number": 8610, "title": "Tensorboard Embedding Sprite Image Aspect Ratio", "body": "I tried to use tensorboard embedding visualization with sprite images. \r\nIt works well except two things:\r\n1) Even though I set the image width and height as:\r\nembedding.sprite.single_image_dim.extend([my_width, my_height])\r\nand the projector_config.pbtxt file has:\r\nsprite {\r\n    image_path: \"sprite.png\"\r\n    single_image_dim: my_width\r\n    single_image_dim: my_height\r\n}\r\nTensorboard **resizes the images to be square**, though it can get correct part from the sprite image, except that:\r\n2) Every last image of each row is not correct. This happens when I have lots of images (like 200 images with size 70*100).\r\n\r\nSeems like it only support square images?\r\n\r\n", "comments": ["@dandelionmane ", "@dsmilkov ", "I can confirm that indeed Tensorboard resizes the images to be square.", "Thanks for reporting this! I've migrated it to our new repository at https://github.com/tensorflow/tensorboard/issues/44."]}, {"number": 8609, "title": "Problem with 3-D matmul", "body": "I want to do a multiplication with two 3-D tensors, as defined:\r\na = tf.random_uniform(shape = [5,3,3])\r\nb = tf.ones(shape = [5,3,1])\r\nc = tf.matmul(a,b)\r\nbut I can't get the right answer as described in the tf.matmul function\r\nhttps://www.tensorflow.org/api_docs/python/tf/matmul\r\na:\r\n[[[ 0.05892992  0.12031484  0.7328496 ]\r\n  [ 0.70889461  0.19382548  0.74017155]\r\n  [ 0.90600419  0.91791809  0.19239831]]\r\n\r\n [[ 0.81325758  0.82476532  0.08050001]\r\n  [ 0.48782277  0.21102762  0.22384059]\r\n  [ 0.92273653  0.27739847  0.09880614]]\r\n\r\n [[ 0.6034205   0.83058596  0.74381268]\r\n  [ 0.848786    0.59108317  0.19264364]\r\n  [ 0.16111362  0.97805214  0.53506196]]\r\n\r\n [[ 0.26249301  0.67511797  0.16425216]\r\n  [ 0.91532063  0.62129664  0.26845133]\r\n  [ 0.48103786  0.38934362  0.7424022 ]]\r\n\r\n [[ 0.69902301  0.23881793  0.7409364 ]\r\n  [ 0.91846371  0.71484613  0.45291376]\r\n  [ 0.20789778  0.31036663  0.40649498]]]\r\nb = \r\n[[[ 1.]\r\n  [ 1.]\r\n  [ 1.]]\r\n\r\n [[ 1.]\r\n  [ 1.]\r\n  [ 1.]]\r\n\r\n [[ 1.]\r\n  [ 1.]\r\n  [ 1.]]\r\n\r\n [[ 1.]\r\n  [ 1.]\r\n  [ 1.]]\r\n\r\n [[ 1.]\r\n  [ 1.]\r\n  [ 1.]]]\r\nc = \r\n[[[ 2.07270455]\r\n  [ 1.61431181]\r\n  [ 1.29296649]]\r\n\r\n [[ 1.85375774]\r\n  [ 1.27382767]\r\n  [ 2.0612402 ]]\r\n\r\n [[ 1.18541944]\r\n  [ 0.6504941 ]\r\n  [ 0.26519179]]\r\n\r\n [[ 1.86258638]\r\n  [ 2.32511139]\r\n  [ 0.82957554]]\r\n\r\n [[ 2.26229262]\r\n  [ 1.60952091]\r\n  [ 1.65814292]]]\r\n", "comments": ["Hi @DingkunLong  that's a great question for stackoverflow where we monitor all questions with the tag `tensorflow`. We reserve github issues for bugs in tensorflow. Thanks!"]}, {"number": 8608, "title": "gradient_override_map not working for tf.matmul", "body": "### `gradient_override_map` not working for `tf.matmul`\r\n\r\nI want to mask the gradient of `tf.matmul`, but I found that the `gradient_override_map` didn't work while it worked for `tf.square`.\r\n\r\n### Gradient override for `tf.matmul`: failed\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.RegisterGradient(\"CustomMatmul\")\r\ndef _custom_matmul_grad(op, grad):\r\n    mask = tf.eye(3)\r\n    return [tf.multiply(grad, mask)]\r\n\r\nwith tf.Graph().as_default() as g:\r\n    w = tf.Variable(tf.eye(3), dtype=tf.float32)\r\n    x = tf.constant([1,2,3], dtype=tf.float32, shape=[3,1])\r\n    with g.gradient_override_map({\"Matmul\": \"CustomMatmul\"}):\r\n            logits = tf.matmul(w, x, a_is_sparse=True, name=\"Matmul\")\r\n    loss = logits\r\n    optimizer = tf.train.GradientDescentOptimizer(0.1)#.minimize(loss)\r\n    grad_val = optimizer.compute_gradients(loss)\r\n    # I do not use the following method because my actual code has many other gradients\r\n    # mask = tf.eye(3)\r\n    # grad_val = [(tf.multiply(g, mask), v) for g, v in grad_val]\r\n    train_op = optimizer.apply_gradients(grad_val)\r\n\r\nwith tf.Session(graph=g) as session:\r\n    session.run(tf.global_variables_initializer())\r\n    _, g_v, w = session.run([train_op, grad_val, w])\r\n\r\n    for g, v in g_v:\r\n        print(g)\r\n        print('*' * 80)\r\n        print(v)    \r\n```\r\n\r\nThe output:\r\n```\r\n[[ 1.  2.  3.]\r\n [ 1.  2.  3.]\r\n [ 1.  2.  3.]]\r\n\r\n[[ 0.89999998 -0.2        -0.30000001]\r\n [-0.1         0.80000001 -0.30000001]\r\n [-0.1        -0.2         0.69999999]]\r\n```\r\n\r\nThe expected output:\r\n```\r\n[[ 1.  0.  0.]\r\n [ 0.  2.  0.]\r\n [ 0.  0.  3.]]\r\n\r\n[[ 0.89999998  0.          0.        ]\r\n [ 0.          0.80000001  0.        ]\r\n [ 0.          0.          0.69999999]]\r\n```\r\n\r\n### Gradient override for `tf.square`: worked\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.RegisterGradient(\"CustomSquare\")\r\ndef _custom_square_grad(op, grad):\r\n  return tf.constant([101.0])\r\n\r\nwith tf.Graph().as_default() as g:\r\n  c = tf.Variable([5.0], dtype=tf.float32)\r\n  s_1 = tf.square(c)  # Uses the default gradient for tf.square.\r\n  with g.gradient_override_map({\"Square\": \"CustomSquare\"}):\r\n    s_2 = tf.square(c, name='Square')\r\n\r\n  optimizer = tf.train.GradientDescentOptimizer(0.1)#.minimize(loss)\r\n  grad_val = optimizer.compute_gradients(s_2)\r\n  train_op = optimizer.apply_gradients(grad_val)\r\n\r\nwith tf.Session(graph=g) as session:\r\n  session.run(tf.global_variables_initializer())\r\n\r\n  _, g_v = session.run([train_op, grad_val])\r\n\r\n  for g, v in g_v:\r\n      print(g)\r\n      print('*' * 80)\r\n      print(v)\r\n```\r\n\r\nThe output:\r\n```\r\n[ 101.]\r\n\r\n[-5.10000038]\r\n```\r\n\r\n### Environment info\r\nOperating System:\r\nUbuntu 16.04\r\nTensorFlow:\r\n1.0.1\r\n", "comments": ["@mrry could you take a look?", "At a guess, the `a_is_sparse=True` might imply that the op being created isn't a `\"MatMul\"`-type op. Maybe the override needs to be for `\"SparseMatMul\"` instead?", "@mrry   `tf.matmul(w, x, name=\"Matmul\")` is still not working", "Problem solved! Without `a_is_sparse=True`, the op name is \"MatMul\", not \"Matmul\"! With `a_is_sparse=True`, the op name is \"SparseMatMul\"."]}, {"number": 8607, "title": "Branch 150817673", "body": "", "comments": ["flakes?\r\nJenkins, test this please.", "Jenkins, test this please.", "Ignoring timing out pooling ops test."]}, {"number": 8606, "title": "Use str(Label(...)) in tensorflow.bzl for use as a submodule", "body": "tf_kernel_library and friends do not currently work if called from a\r\nrepo that contains tensorflow as submodule.  Justine recommended this\r\nas the right fix.\r\n\r\nFixes #8439.", "comments": ["Jenkins, test this please (the makefile failure may have been due to a recent reactivation of a broken slave)", "We just upgraded to bazel 0.4.5.\r\n@jart With 0.4.5 do we have a better solution we can use now? maybe just editing these rules to be `@org_tensorflow://....` ?", "@gunan @jart Can you decide whether this PR or https://github.com/tensorflow/tensorflow/pull/8763 is the better one?", "I think the other PR is much better. (If we can get it working, there seems to be a test issue with it.)", "The other solution is not working even with bazel 0.4.5, so we will go with this solution for a little while longer.", "@gunan Thanks!", "This PR broke inside Google, so I'm going to redo it from the inside."]}, {"number": 8605, "title": "Release notes for 1.1 release", "body": "", "comments": []}, {"number": 8604, "title": "Creating variables in a `while_loop`", "body": "I understand why this fails given the way control inputs are inserted in non-Variable ops created in while loops, but maybe the limitations should be documented somewhere:\r\n\r\n```python\r\nimport tensorflow as tf\r\ni = tf.constant(0)\r\ndef body(i):\r\n  w = tf.Variable(tf.constant(1))\r\n  return [i+w]\r\nloop = tf.while_loop(lambda i: tf.less(i,5), body, [i])\r\ns = tf.Session()\r\ns.run(tf.global_variables_initializer())\r\n```  \r\n\r\n```\r\n\r\nInvalidArgumentError: The node 'while/w/Assign' has inputs from different frames. The input 'while/j' is in frame 'while/while/'. The input 'while/w' is in frame ''.\r\n```\r\n", "comments": ["I'll try to improve this if I have spare cycles, but for now I'm gonna mark this contributions welcome. I imagine it should additionally be possible to improve the error message in this case.", "I haven't seen any docs describing the word \"frame\" in this sense. It would help a lot to describe what frames are and how they get created.\r\n\r\nEDIT: And also, the proper way to debug variables and states inside such frames (e.g. those that are ~~created~~ updated inside while loops. I could not find any way to do that.)", "Is there any real use case where defining variables inside while_loop would help?\r\nAny plans of augmenting the functionality of while_loop? Are contributions welcomed here?", "@jcaraban Ah, I actually meant to say \"updated\" (for instance an RNN cell state). I am not sure if variables can be created inside a while_loop, or whether there would be any use for it.", "Note that there is also a bug with the name scope (\"while/while/\"), I guess because there might be some variable_scope/name_scope mixup. I see the same bug in the same situation (`InvalidArgumentError: The node 'output/rec/orth_embed/b/Assign' has inputs from different frames. The input 'output/rec/orth_embed/Const' is in frame 'output/rec/while/output/rec/while/'. The input 'output/rec/orth_embed/b' is in frame ''.`).\r\n\r\nIs it possible to set the frame as a scope? Then the variable creation could look like this:\r\n```\r\nwith tf.frame_scope(''):\r\n  w = tf.Variable(tf.constant(1))\r\n```\r\n\r\nI don't see a reason why not to create the variables inside the loop. It can make some code easier (in my current case, I don't really see a good option to avoid that).\r\n\r\nI guess the problem is only because of the Assign-Op and the Const-Op which are assigned to the while-frame?", "I think #4478 is related (or even the same bug) (as well as #3114).", "Actually, this will make it work:\r\n\r\n```\r\nwith tf.control_dependencies(None):\r\n  w = tf.Variable(tf.constant(1))\r\n```\r\n", "It is always a good idea to use `tf.get_variable`. `tf.Variable` doesn't work well with control dependency and control flow (cond and while_loop).  For your example, I would do something like this:\r\n\r\n```\r\ndef body(i):\r\n  w = tf.get_variable(\"w\", shape=(), dtype=tf.int32,\r\n                      initializer=tf.ones_initializer())\r\n  return i+w\r\nloop = tf.while_loop(lambda i: i < 5, body, [0])\r\ns = tf.Session()\r\ns.run(tf.global_variables_initializer())\r\n\r\ns.run(loop)\r\n```\r\n\r\n   ", "@yuanbyu wrote\r\n\r\n> It is always a good idea to use `tf.get_variable`. `tf.Variable` doesn't work well with control dependency and control flow (cond and while_loop).\r\n\r\nThis advice needs an update now that `get_variable` is gone in Tensorflow 2. Can we just use `tf.Variable` from within cond/while_loop? If not, what exactly makes it not \"work well with control dependency and control flow\", and how can we guard against this?\r\n\r\n(Apologies for thread necromancy, but I think it's important to have this information on this thread for the sake of people coming from Google search results.)"]}]