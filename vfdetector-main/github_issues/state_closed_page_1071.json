[{"number": 21146, "title": "A faster BatchSelectFunctor for tf.where on CPU.", "body": "Op 'tf.where(c, t, e)' supports that 't' and 'e' are N-D tensors while 'c' is a 1D tensor, which would call BatchSelectFunctor to get the result. But its basic implementation broadcasts 'c' to the same dimension with 't' and 'e', which would get bad efficiency on CPU for large tensors.\r\n\r\nHere a loop-based implementation would be adopted to make this operation faster on CPU. There would be no broadcast during the calculation, thus would effectively improve the performance (seeing the benchmark test 'BatchSelect').\r\n\r\nBenchmark result below was done on a 2 x E5-2682v4 (16c @ 2.5GHz) platform:\r\ncompiling args: -mfma -mavx2 -mavx -msse4.2 -msse4.1 -O3\r\n(old version):\r\nBenchmark: m_1000_n_10_use_gpu_False \t wall_time: 0.000196 s \t Throughput: 0.409 GB/s\r\nBenchmark: m_1000_n_100_use_gpu_False \t wall_time: 0.000323 s \t Throughput: 2.48 GB/s\r\nBenchmark: m_1000_n_1000_use_gpu_False \t wall_time: 0.000623 s \t Throughput: 12.8 GB/s\r\nBenchmark: m_10000_n_10_use_gpu_False \t wall_time: 0.00031 s \t Throughput: 2.58 GB/s\r\nBenchmark: m_10000_n_100_use_gpu_False \t wall_time: 0.00061 s \t Throughput: 13.1 GB/s\r\nBenchmark: m_10000_n_1000_use_gpu_False \t wall_time: 0.00364 s \t Throughput: 22 GB/s\r\nBenchmark: m_100000_n_10_use_gpu_False \t wall_time: 0.000602 s \t Throughput: 13.3 GB/s\r\nBenchmark: m_100000_n_100_use_gpu_False \t wall_time: 0.00367 s \t Throughput: 21.8 GB/s\r\nBenchmark: m_100000_n_1000_use_gpu_False \t wall_time: 0.0309 s \t Throughput: 25.9 GB/s\r\n\r\n(new version):\r\nBenchmark: m_1000_n_10_use_gpu_False \t wall_time: 0.000153 s \t Throughput: 0.524 GB/s\r\nBenchmark: m_1000_n_100_use_gpu_False \t wall_time: 0.000178 s \t Throughput: 4.49 GB/s\r\nBenchmark: m_1000_n_1000_use_gpu_False \t wall_time: 0.000327 s \t Throughput: 24.5 GB/s\r\nBenchmark: m_10000_n_10_use_gpu_False \t wall_time: 0.000203 s \t Throughput: 3.94 GB/s\r\nBenchmark: m_10000_n_100_use_gpu_False \t wall_time: 0.000344 s \t Throughput: 23.3 GB/s\r\nBenchmark: m_10000_n_1000_use_gpu_False \t wall_time: 0.00123 s \t Throughput: 64.9 GB/s\r\nBenchmark: m_100000_n_10_use_gpu_False \t wall_time: 0.000326 s \t Throughput: 24.6 GB/s\r\nBenchmark: m_100000_n_100_use_gpu_False \t wall_time: 0.0016 s \t Throughput: 50 GB/s\r\nBenchmark: m_100000_n_1000_use_gpu_False \t wall_time: 0.0166 s \t Throughput: 48.2 GB/s", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "I believe I have signed the CLA.", "CLAs look good, thanks!\n\n<!-- ok -->", "Is there any comment for this code? @caisq ", "ping @rmalrsen ?"]}, {"number": 21145, "title": "InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MklConv2DWithBias' with these attrs.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: debian 8\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Python version**: Python 2.7.13\r\n- **Bazel version (if compiling from source)**: 0.4.2\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 4.9.2 (Debian 4.9.2-10)\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\ntf_env_collect.sh:\r\n\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux 4be8a8788f34 4.9.60-linuxkit-aufs #1 SMP Mon Nov 6 16:00:12 UTC 2017 x86_64 GNU/Linux\r\nVERSION_ID=\"8\"\r\nVERSION=\"8 (jessie)\"\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Debian 4.9.2-10) 4.9.2\r\nCopyright (C) 2014 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux 4be8a8788f34 4.9.60-linuxkit-aufs #1 SMP Mon Nov 6 16:00:12 UTC 2017 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nintel-numpy            1.13.3.10\r\nnumpy                  1.14.5\r\nprotobuf               3.6.0\r\ntensorflow             1.1.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.1.0\r\ntf.GIT_VERSION = v1.1.0-0-g1ec6ed5\r\ntf.COMPILER_VERSION = v1.1.0-0-g1ec6ed5\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /code/:/code//lib:/usr/local/lib\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n/tensor/tensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```\r\n\r\n### Describe the problem\r\nI posted a stackoverflow issue: https://stackoverflow.com/questions/51530592/invalidargumenterror-see-above-for-traceback-no-opkernel-was-registered-to-su\r\n\r\n### How to Generate the problem\r\n\r\nI found a way to reproduce this problem.\r\n\r\n1. download tensorflow zip and unzip. \r\n  https://drive.google.com/file/d/1k616LEvgTUXpHuX6Fz7EDXukaG5tGZwQ/view\r\n\r\n2. mount tensorflow folder to container:\r\n  docker run --rm -it -v $(pwd):/code econtal/numpy-mkl  bash\r\n\r\n3. create the test script:\r\n\r\n  ```\r\n  $ cd /code\r\n  $ vi test_conv2d.py\r\n\r\n  # demo from https://www.jianshu.com/p/a70c1d931395\r\n  import tensorflow as tf \r\n  import tensorflow.contrib.slim as slim\r\n  import numpy as np\r\n \r\n  x1 = tf.ones(shape=[1, 64, 64, 3]) \r\n  w = tf.fill([5, 5, 3, 64], 1)\r\n  # print(\"rank is\", tf.rank(x1))\r\n\r\n  # x1 = tf.cast(x1, tf.float32)  \r\n  w = tf.cast(w, tf.float32)\r\n\r\n  print('-----debugging-----')\r\n  print(type(x1))\r\n  print(x1.dtype.base_dtype)\r\n\r\n  print(type(w))\r\n  print(w.dtype.base_dtype)\r\n  print('-------------------')\r\n\r\n  # x1 = tf.cast(x1, tf.float16)\r\n\r\n  y1 = tf.nn.conv2d(x1, w, strides=[1, 1, 1, 1], padding='SAME')\r\n  y2 = slim.conv2d(x1, np.float32(64.0), np.array([5.0, 5.0], dtype=np.float32), \r\n  weights_initializer=tf.ones_initializer, padding='SAME')\r\n\r\n  with tf.Session() as sess: \r\n      sess.run(tf.global_variables_initializer()) \r\n      y1_value,y2_value,x1_value=sess.run([y1,y2,x1])\r\n      print(\"shapes are\", y1_value.shape, y2_value.shape)\r\n      print(y1_value==y2_value)\r\n      print(y1_value)\r\n      print(y2_value)\r\n  ```\r\n\r\n  4. run the test script\r\n\r\n  ```\r\n  $ python test_conv2d.py\r\n  ```\r\n\r\nCan anyone give some advice on how to find the problem? Thanks.\r\n\r\n", "comments": ["Any chance for you to bump your TF version? \r\nI tried TF v1.8.0 built with \"--config=mkl\" and I did not encounter this issue. \r\n", "Sorry, our project relies on version 1.1.0 of tensorflow. \r\n\r\nThis is the version of tensorflow 1.1.0 that I compiled:\r\nhttps://drive.google.com/file/d/1k616LEvgTUXpHuX6Fz7EDXukaG5tGZwQ/view\r\n\r\nI wrote the compilation steps on tensorflow:\r\nhttps://stackoverflow.com/questions/51530592/invalidargumenterror-see-above-for-traceback-no-opkernel-was-registered-to-su\r\n\r\nYou can use my compiled tensorflow version 1.1.0 directly.\r\n\r\nCan you reproduce it according to the steps I mentioned above?", "ping @wei-v-wang ", "Nagging Assignee @poxvoculi: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@wei-v-wang I also tried TF v1.8.0 built with \"--config=mkl\" and did not encounter this issue.\r\nMaybe, we can only solve the problem by upgrading the tf version.\r\n\r\nThanks for your help.", "Yes, thank you for trying TF v1.8.0. "]}, {"number": 21144, "title": "Fix typo: accidently -> accidentally.", "body": "", "comments": ["@caisq Ubuntu CC and Ubuntu Sanity had been waiting a long time for status to be reported. Something went wrong?"]}, {"number": 21143, "title": "fix: No need to convert to tensor in embedding_lookup", "body": "fix: No need to convert to tensor when using ResourceVariable in embedding_lookup, because ResourceVariable support ResourceGather OP.\r\nThis is a performance improvement.\r\nIt will add a VariableRead OP behind ResourceVariable convert-to-tensor, which makes low performance.", "comments": ["Hi, can someone help take a look? 3ks.", "Nagging Reviewer @rohan100jain: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 20 days with no activity and the `awaiting review` label has been applied.", "Nagging Reviewer @rohan100jain: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 35 days with no activity and the `awaiting review` label has been applied.", "@rohan100jain "]}, {"number": 21142, "title": "Feature Request: Provide tf.pow with supporting  broadcasting?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I wonder if the following example isn't a broadcast already?\r\n<img width=\"317\" alt=\"screen shot 2018-07-26 at 11 16 18 pm\" src=\"https://user-images.githubusercontent.com/7251084/43304697-f3af671e-9129-11e8-9cb4-62221a263a0c.png\">\r\n", "@ayush2991  It' s my carelessness. The tf.pow()  API description doesn't refer to the broadcasting feature, while other operations (eg. tf.multiply()) have mentioned it if they support broadcasting.  And I mistakenly think that there is not broadcasting in tf.pow(). Thx a lot! :)", "@lepangdan, in that case I think you can close the issue now."]}, {"number": 21141, "title": "ValueError: No variables to save | Tensorflow", "body": "Traceback (most recent call last):\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\uthir\\Anaconda3\\envs\\qwerty\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"C:\\tensorflow12345\\models\\research\\object_detection\\trainer.py\", line 392, in train\r\n    init_saver = tf.train.Saver(available_var_map)\r\n  File \"C:\\Users\\uthir\\Anaconda3\\envs\\qwerty\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\r\n    self.build()\r\n  File \"C:\\Users\\uthir\\Anaconda3\\envs\\qwerty\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\Users\\uthir\\Anaconda3\\envs\\qwerty\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1372, in _build\r\n    raise ValueError(\"No variables to save\")\r\nValueError: No variables to save\r\n\r\nI am trying to train my own model using ssd_mobile_v2_coco with ssd_mobilenet_v1_pets.config. I got this error. Please help me to solve this.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I have  the same issue ,using ssd_resnet50_v1", "Could you provide more context about what you're doing? Ideally a [minimal, complete, verifiable example](https://stackoverflow.com/help/mcve). \r\n\r\nWithout additional context, it's hard to provide help. \r\n\r\nThe error itself is suggesting that the model you're trying to checkpoint has no trainable parameters", "It has been 22 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 37 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I have the same issue ,using ssd_resnet50_v1", ">           I have  the same issue ,using ssd_resnet50_v1\r\n\r\nHave you solved the problem?", "@minda163  see https://github.com/tensorflow/tensorflow/issues/21141#issuecomment-411456740\r\n\r\nIf you can provide a reproduction or more information (such as whether your model has any variables or not), that would be helpful. Thanks.", "python ~/code/gitmaster/tensorflow-master2/tensorflow-master/tensorflow/python/tools/freeze_graph.py --input_checkpoint=\"./model.ckpt-5000\" --output_graph= xxx.pb --input_mete_graph= ./model.ckpt-5000.meta --output_node_names=output\r\n\r\nraise ValueError(\"No variables to save\")\r\nValueError: No variables to save\r\n", "I am getting the same error: \r\nTraceback (most recent call last):\r\n  File \"cnn.py\", line 77, in <module>\r\n    saver = tf.train.Saver()\r\n  File \"/home/faeza/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1094, in __init__\r\n    self.build()\r\n  File \"/home/faeza/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1106, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/home/faeza/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1131, in _build\r\n    raise ValueError(\"No variables to save\")\r\nValueError: No variables to save\r\n\r\nand here is the code:\r\n```\r\nsaver = tf.train.Saver()\r\n\r\ndef train_neural_network(x):\r\n    prediction = convolutional_neural_network(x)\r\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\r\n\r\n    hm_epochs = 5\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        successful_runs = 0\r\n        total_runs = 0\r\n\r\n        for epoch in range(hm_epochs):\r\n            epoch_loss = 0\r\n            for data in train_data:\r\n                total_runs += 1\r\n                try:\r\n                    x_batch = data[0]\r\n                    y_batch = data[1]\r\n                    _, c = sess.run([optimizer, cost], feed_dict={x: x_batch, y: y_batch})\r\n                    epoch_loss += c\r\n                    successful_runs += 1\r\n\r\n                except Exception as e:\r\n                    # I am passing for the sake of notebook space, but we are getting 1 shaping issue from one\r\n                    # input tensor. Not sure why, will have to look into it. Guessing it's\r\n                    # one of the depths that doesn't come to 20.\r\n                    pass\r\n                    #print(str(e))\r\n\r\n            #print('Epoch', epoch + 1, 'completed out of', hm_epochs, 'loss:', epoch_loss)\r\n\r\n            correct = tf.equal(tf.argmax(prediction), tf.argmax(y))\r\n            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\r\n\r\n            #print('Accuracy:', accuracy.eval({x: [i[0] for i in validation_data], y: [i[1] for i in validation_data]}))\r\n        correct = tf.equal(tf.argmax(prediction), tf.argmax(y))\r\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\r\n        saver.save(sess, \"model.ckpt\")\r\n        print('Done. Finishing accuracy:')\r\n        a =  accuracy.eval({x: [i[0] for i in validation_data], y: [i[1] for i in validation_data]})\r\n        print('Accuracy:', a)\r\n```"]}, {"number": 21140, "title": "[Intel MKL] Removing old MKL development Dockerfile", "body": "Use Dockerfile.devel-mkl instead.", "comments": []}, {"number": 21139, "title": "[CMake] tf_tests.py | Add CheckExists", "body": "Fixes #10296\r\nReplaces #15590\r\n@gunan /cc", "comments": ["Lots of tests failing on the CMake build with the exception....\r\n\r\nImportError: No module named 'tensorflow.compiler'\r\n\r\nIs this due to your change do you think? Or should we try rerunning the tests", "windows cmake build on master is broken, as we officially migrated to bazel on windows.\r\nThat failure is an existing issue.\r\nFrom now on, we will just depend on users to test their code with cmake."]}, {"number": 21138, "title": "Wiring update", "body": "Fix wiring issues in case engine building fails and add control connections to engines", "comments": ["@pooyadavoodi", "Thanks for the review!"]}, {"number": 21137, "title": "KNN classifier.setClassifierDataset", "body": "hi\r\n\r\ncan you help me to save and retrieve the model I've created based on KNN Classifier?\r\nI've seen that I need to use classifier.setClassifierDataset and classifier.getClassifierDataset, but I cannot make it workj\r\n\r\nthanks", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "i'm trying to load a classifierdataset in this way\r\n\r\nafter train with addExample I save the model with this\r\n`localStorage.setItem('classifier', JSON.stringify(classifier.getClassifierDataset()));`\r\n\r\nand recover with\r\n`classifier.setClassifierDataset(JSON.parse(localStorage.getItem('classifier')));`\r\n\r\nknn-classifier:2 Uncaught (in promise) TypeError: r.clone is not a function\r\n    at knn-classifier:2\r\n\r\nthanks", "For people stumbling across this during a web search like I did, the solution to saving a classifier as text is over here: https://github.com/tensorflow/tfjs/issues/633 :+1: "]}, {"number": 21136, "title": "Feature Request: tf.contrib.image.interpolate_spline partially known TensorShape", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.5\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nWhen using tf.contrib.image.interpolate_spline(), the input cannot have partially known shape, e.g., a placeholder. I wonder if new features to allow inputs with partially known shape can be added. The following is a code snippet to demonstrate the problem. Thank you for helping!\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nimport tensorflow as tf\r\n\r\nX = tf.placeholder(tf.float32, [None])\r\nY = tf.constant([4,5,6], tf.float32)\r\nx2 = tf.constant([2.5,2.3,2.9], tf.float32)\r\n\r\nx = tf.reshape([[X]], [1, -1, 1])\r\ny = tf.reshape([[Y]], [1, -1, 1])\r\nx2 = tf.reshape([[x2]], [1, -1, 1])\r\ny2 = tf.contrib.image.interpolate_spline(x, y, x2, order=1)\r\n\r\nwith tf.Session() as session:\r\n    result = session.run(y2, feed_dict={X: [1, 2, 3]})\r\n    print(result[0,:,0])", "comments": ["/CC @rmlarsen, @davidbelanger, can either of you work on this?", "Nagging Assignee @rmlarsen: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Sorry for the delay. I'm just returning from paternity leave. I can address\nthis issue some time in the next few days.\n\nOn Tue, Aug 14, 2018 at 3:58 PM, Alfred Sorten Wolf <\nnotifications@github.com> wrote:\n\n> Nagging Assignee @rmlarsen <https://github.com/rmlarsen>: It has been 15\n> days with no activity and this issue has an assignee. Please update the\n> label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21136#issuecomment-412994534>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABH_qp3Z621tlSRS-XmY1z17K5BzxEAWks5uQyvigaJpZM4Vg6Uw>\n> .\n>\n"]}, {"number": 21135, "title": "[Bug] Conflict between Tensorboard and Tensorflow Training ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7\r\n- **GPU model and memory**: Quadro M4000\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nUsing the new Tensorflow v1.9 framework's keras interfaces, I just add Tensorboard callback in the example Keras classification codes. However, when tensorboard is activated, the training crashed. The error is \r\n\r\n2018-07-24 16:08:28.615130: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at save_restore_v2_ops.cc:137 : Unknown: Failed to rename: E:\\projects\\keras1\\sc_weight.ckpt.index.tempstate893681564054566973 to: E:\\projects\\keras1\\sc_weight.ckpt.index : Access is denied.\r\n\r\nWhen tensorboard is not used, training has no problem. \r\n\r\nIt seems that the Tensorflow needs to rename the files every time when saving occurs. The tensorboard people thinks they could do nothing on their end, and the solution should be based the Tensorflow end. (See the last response in the link below)\r\nhttps://github.com/tensorflow/tensorboard/issues/892#issuecomment-407901434\r\n\r\nCould people on Tensorflow's end fix this \"renaming\" issue? Thank you.", "comments": ["@asimshankar could you please take a look or assign it to Object Detection API folks if its on their end.", "If I understand correctly, the checkpoint is being written to the same file repeatedly. Can this be avoided, i.e., each checkpoint be written with a different file prefix so that the checkpoint file isn't being rewritten while Tensorboard is reading it?\r\n\r\n", "The issue has not been solved. I think that if Tensorflow side changes the saving scheme as @asimshankar mentioned, the problem would be solved.", "@ybsave : My question was intended for you - could you avoid writing the checkpoint to the same file repeatedly?\r\n\r\nOr, can you provide a [minival, verifiable, complete example](https://stackoverflow.com/help/mcve) to reproduce the problem?", "@asimshankar Thank you for your response. Manually setting the checkpoint and writing into different files does work; however, I believe it should be processed by Tensorflow internally but not a user's extra effort. In previous Tensorflow versions, there is no such problem, but just since version 1.9, I started to encounter this conflict.\r\n\r\nOne sample code could just be the Tensorflow's tutorial codes with a few extra lines as below:\r\n\r\n\tmnist = tf.keras.datasets.mnist\r\n\tdef test_tesnorboard():\r\n\t  (x_train, y_train),(x_test, y_test) = mnist.load_data()\r\n\t  x_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\n\t  model = tf.keras.models.Sequential([\r\n\t\ttf.keras.layers.Flatten(),\r\n\t\ttf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n\t\ttf.keras.layers.Dropout(0.2),\r\n\t\ttf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n\t  ])\r\n\t  model.compile(optimizer='adam',\r\n\t\t\t\t\tloss='sparse_categorical_crossentropy',\r\n\t\t\t\t\tmetrics=['accuracy'])\r\n\r\n\t  saver_callback = keras.callbacks.ModelCheckpoint(\r\n\t\t'test/test_save.ckpt', verbose=1, save_weights_only=True, period=1)\r\n\r\n\t  model.fit(x_train, y_train, epochs=1000000, callbacks=[saver_callback])\r\n\t  model.evaluate(x_test, y_test)\r\n\r\nIf we run the tensorboard at the same time during training, the training program will crash.", "I have the same problem (windows 10, tensorflow 1.11.0, tensorbard 1.11.0, tensorflow-gpu 1.9.0): saving the model weights with `Saver.save()` multiple times to the same file **within the tensorboard logdir folder** fails. As a workaround, I write them **outside the tensorboard logdir folder** and it works.", "I have the same problem (windows 10, tensorflow 1.11.0, tensorbard 1.11.0), although I am not using keras. I also tried with other version of tensorflow 1.8, but the problem goes on. Is it possible that someone tell me other versi\u00f3n of tensorflow that I could use while this bug is solved?", "I have found that I get this error if I have an Explorer window also watching the folder. I close the Explorer window and the error stopped appearing. That leads me to think that it's Explorer that is locking the file and TensorBoard gets locked out.", "Also get that problem.\r\nDon't have an explorer window open.\r\nAlso deactivated antivirus software.\r\nNeed to watch progress of a running tensorflow training progress.\r\nStill allways get this problem when i'm using the tensorboard.\r\nI'm using:\r\ntensorflow Version: 1.13.1\r\ntensorboard Version: 1.12.2\r\npython version: 3.6.4\r\n\r\nError still happens after i upgrade:\r\ntensorboard to version: 1.13.1\r\npython to version: 3.6.8", "@ybsave , @TheCrazyT ,\r\nSorry for the delayed response. I tried reproducing the issue with Tensorflow Version 1.14 and 1.13.1 but I didn't get the error you mentioned. Instead, I got the below error. Can you please provide the working reproducible code. Thanks!\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-7080519d0cae> in <module>\r\n     15     model.evaluate(x_test, y_test)\r\n     16 \r\n---> 17 test_tesnorboard()\r\n\r\n<ipython-input-4-7080519d0cae> in test_tesnorboard()\r\n     12     saver_callback = keras.callbacks.ModelCheckpoint('test/test_save.ckpt', verbose=1, save_weights_only=True, period=1)\r\n     13 \r\n---> 14     model.fit(x_train, y_train, epochs=1000000, callbacks=[saver_callback])\r\n     15     model.evaluate(x_test, y_test)\r\n     16 \r\n\r\n~/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    878           initial_epoch=initial_epoch,\r\n    879           steps_per_epoch=steps_per_epoch,\r\n--> 880           validation_steps=validation_steps)\r\n    881 \r\n    882   def evaluate(self,\r\n\r\n~/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\r\n    323         # Callbacks batch_begin.\r\n    324         batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\r\n--> 325         callbacks._call_batch_hook(mode, 'begin', batch_index, batch_logs)\r\n    326         progbar.on_batch_begin(batch_index, batch_logs)\r\n    327 \r\n\r\n~/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)\r\n    194     t_before_callbacks = time.time()\r\n    195     for callback in self.callbacks:\r\n--> 196       batch_hook = getattr(callback, hook_name)\r\n    197       batch_hook(batch, logs)\r\n    198     self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n\r\nAttributeError: 'ModelCheckpoint' object has no attribute 'on_train_batch_begin'\r\n```", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=21135\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=21135\">No</a>\n", "Error still happens.\r\n\r\nI made a proof of concept on appveyor:\r\n\r\nhttps://ci.appveyor.com/project/TheCrazyT/tensorflow-poe/builds/26605745#L378\r\n\r\nImportant error is the following (you can ignore the others about pip upgrade):\r\n\"tensorflow.python.framework.errors_impl.UnknownError: Failed to rename\"\r\n\r\n\r\nSource code used (appveyor runs the run_test.ps1 script):\r\n\r\nhttps://github.com/TheCrazyT/tensorflow_poe\r\n\r\nTo reproduce you need some random script that uses tensorflow and stores checkpoint-data.\r\nThen run tensorboard.\r\nTo finally produce the error you need to access the tensorboard with a webbrowser.\r\nThats it.", "@rmothukuru Doesn't seem to be resolved, and it's easily reproducible since a TensorFlow tutorial script crashes with the same error message when watching progress with TensorBoard. This is using tensorflow-gpu 1.14 on Windows 10.\r\n\r\nThe tutorial script is at https://github.com/tensorflow/hub/raw/master/examples/image_retraining/retrain.py\r\n\r\nIt dies after training is complete, so run it with for example `--how_many_training_steps=40`. \r\n\r\nFull stacktrace:\r\n```\r\n2019-08-17 23:36:20.321895: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at save_restore_v2_ops.cc:137 : Unknown: Failed to rename: /tmp/_retrain_checkpoint.index.tempstate14236087840509299070 to: /tmp/_retrain_checkpoint.index : Access is denied.\r\n; Input/output error\r\nTraceback (most recent call last):\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Failed to rename: /tmp/_retrain_checkpoint.index.tempstate14236087840509299070 to: /tmp/_retrain_checkpoint.index : Access is denied.\r\n; Input/output error\r\n         [[{{node save_2/SaveV2}}]]\r\n  (1) Unknown: Failed to rename: /tmp/_retrain_checkpoint.index.tempstate14236087840509299070 to: /tmp/_retrain_checkpoint.index : Access is denied.\r\n; Input/output error\r\n         [[{{node save_2/SaveV2}}]]\r\n         [[save_2/SaveV2/_1602]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"retrain.py\", line 1349, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"retrain.py\", line 1143, in main\r\n    train_saver.save(sess, FLAGS.checkpoint_path)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1173, in save\r\n    {self.saver_def.filename_tensor_name: checkpoint_file})\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Failed to rename: /tmp/_retrain_checkpoint.index.tempstate14236087840509299070 to: /tmp/_retrain_checkpoint.index : Access is denied.\r\n; Input/output error\r\n         [[node save_2/SaveV2 (defined at retrain.py:1069) ]]\r\n  (1) Unknown: Failed to rename: /tmp/_retrain_checkpoint.index.tempstate14236087840509299070 to: /tmp/_retrain_checkpoint.index : Access is denied.\r\n; Input/output error\r\n         [[node save_2/SaveV2 (defined at retrain.py:1069) ]]\r\n         [[save_2/SaveV2/_1602]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node save_2/SaveV2:\r\n module/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/BatchNorm/moving_mean/Read/ReadVariableOp (defined at C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_hub\\native_module.py:459)\r\n final_retrain_ops/biases/final_biases (defined at retrain.py:765)\r\n final_retrain_ops/weights/final_weights (defined at retrain.py:761)\r\n\r\nInput Source operations connected to node save_2/SaveV2:\r\n module/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/BatchNorm/moving_mean/Read/ReadVariableOp (defined at C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_hub\\native_module.py:459)\r\n final_retrain_ops/biases/final_biases (defined at retrain.py:765)\r\n final_retrain_ops/weights/final_weights (defined at retrain.py:761)\r\n\r\nOriginal stack trace for 'save_2/SaveV2':\r\n  File \"retrain.py\", line 1349, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"retrain.py\", line 1069, in main\r\n    train_saver = tf.train.Saver()\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\r\n    self.build()\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\r\n    build_restore=build_restore)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 505, in _build_internal\r\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 206, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 122, in save_op\r\n    tensors)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 2060, in save_v2\r\n    name=name)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n```\r\n", "I'm also still observing the error. It is possible (though I don't know for sure) that this is related to: https://github.com/tensorflow/models/issues/4177", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Guess someone should remove that label ...", "@ybsave @TheCrazyT @Efaq Can you check the following [gitst](https://colab.sandbox.google.com/gist/jvishnuvardhan/bd452d8652f0fe7c9059a67d07fb0d53/tf_21135_callbacks.ipynb) and let me know your comments. I updated @ybsave code little bit and ran it in google colab. I don't see any issue but want to know whether you have any concerns. Thanks! ", "Correct me if I'm wrong, but google collab is linux (atleast thats what \"!uname -a\" shows in jupyter).\r\nBut the problem is related to windows version of tensorflow!\r\n(thats why I used appveyor)\r\n\r\nEdit:\r\nOh maybe i just misunderstood, will check the nightly build of tensorflow at my windows pc this weekend.", "First test with my testcode and tf-nightly failed(https://ci.appveyor.com/project/TheCrazyT/tensorflow-poe/builds/27221666), will check your code once I have the time.", "Ok ... second test seem to work, so it looks like \"tf.train.Saver()\" is the problem?\r\n(Thats what i use at: https://github.com/TheCrazyT/tensorflow_poe/blob/master/doit.py)\r\n\r\nAtleast I'm not 100% shure why your version with callbacks seem to work.\r\nhttps://ci.appveyor.com/project/TheCrazyT/tensorflow-poe/builds/27259776\r\n(atleast it runned 25 epochs with 25 checkpoints without problems)\r\n\r\nEdit:\r\nOh well I'm now totally confused, tried to rerun my old code but it also didn't produce the problem anymore (although version of tf-nightly was the same).\r\n\r\nEdit#2:\r\nCurrently can't reliably test on appveyor because of:\r\n\"tb-nightly 1.15.0a20190907 has requirement setuptools>=41.0.0, but you'll have setuptools 40.6.2 which is incompatible.\"\r\nGuess thats why I have no problems at the moment, because it uses an older version.\r\n(sadly can't even update  setuptools to the required version)", "Hello\r\nI am also facing the same problem and getting following error at step 93526 while training ssd_inception_v2_coco.config  and visualizing its performance with TensorBoard on windows 10 (tensorflow-estimator 1.14.0, tensorflow-gpu  1.14.0, Python 3.7.4) .  \r\n\r\nI do not know why I am getting this error.  (I have not it synchronized it with google or one drive for saving) \r\n**Would you please guide me that why am I getting this error and how can I fix it?**\r\n  coordinator.py:219] Error reported to Coordinator: Failed to rename: training\\checkpoint.tmp5e2c65c350c24211a132a1aabfa7d446 to: training\\checkpoint : Access is denied.\r\n\r\n-------\r\nI0910 00:01:09.369776 16632 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\r\nI0910 00:01:10.502128 21188 learning.py:507] global step 93525: loss = 3.5969 (1.415 sec/step)\r\nI0910 00:01:10.557096 17904 supervisor.py:1050] Recording summary at step 93525.\r\nI0910 00:01:11.644474 21188 learning.py:507] global step 93526: loss = 3.4009 (1.140 sec/step)\r\nI0910 00:01:11.886335 16632 coordinator.py:219] Error reported to Coordinator: Failed to rename: training\\checkpoint.tmp5e2c65c350c24211a132a1aabfa7d446 to: training\\checkpoint : Access is denied.\r\n; Input/output error\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 495, in run\r\n    self.run_loop()\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1119, in run_loop\r\n    self._sess, self._sv.save_path, global_step=self._sv.global_step)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1183, in save\r\n    save_relative_paths=self._save_relative_paths)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_management.py\", line 242, in update_checkpoint_state_internal\r\n    text_format.MessageToString(ckpt))\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 540, in atomic_write_string_to_file\r\n    rename(temp_pathname, filename, overwrite)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 502, in rename\r\n    rename_v2(oldname, newname, overwrite)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 519, in rename_v2\r\n    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to rename: training\\checkpoint.tmp5e2c65c350c24211a132a1aabfa7d446 to: training\\checkpoint : Access is denied.\r\n; Input/output error\r\nI0910 00:01:13.594354 21188 learning.py:507] global step 93527: loss = 2.3798 (1.322 sec/step)\r\nI0910 00:01:13.596354 21188 learning.py:785] Finished training! Saving model to disk.\r\nC:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\r\n  warnings.warn(\"Attempting to use a closed FileWriter. \"\r\nTraceback (most recent call last):\r\n  File \"legacy/train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"legacy/train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"C:\\tensorflow1\\models\\research\\object_detection\\legacy\\trainer.py\", line 416, in train\r\n    saver=saver)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 790, in train\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 839, in stop\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\six.py\", line 693, in reraise\r\n    raise value\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 495, in run\r\n    self.run_loop()\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1119, in run_loop\r\n    self._sess, self._sv.save_path, global_step=self._sv.global_step)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1183, in save\r\n    save_relative_paths=self._save_relative_paths)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_management.py\", line 242, in update_checkpoint_state_internal\r\n    text_format.MessageToString(ckpt))\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 540, in atomic_write_string_to_file\r\n    rename(temp_pathname, filename, overwrite)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 502, in rename\r\n    rename_v2(oldname, newname, overwrite)\r\n  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 519, in rename_v2\r\n    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to rename: training\\checkpoint.tmp5e2c65c350c24211a132a1aabfa7d446 to: training\\checkpoint : Access is denied.\r\n; Input/output error\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>I0910 00:01:09.084940 21188 learning.py:507] global step 93524: loss = 5.1544 (1.134 sec/step)\r\n'I0910' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>I0910 00:01:09.369776 16632 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\r\n'I0910' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>I0910 00:01:10.502128 21188 learning.py:507] global step 93525: loss = 3.5969 (1.415 sec/step)\r\n'I0910' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>I0910 00:01:10.557096 17904 supervisor.py:1050] Recording summary at step 93525.\r\n'I0910' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>I0910 00:01:11.644474 21188 learning.py:507] global step 93526: loss = 3.4009 (1.140 sec/step)\r\n'I0910' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>I0910 00:01:11.886335 16632 coordinator.py:219] Error reported to Coordinator: Failed to rename: training\\checkpoint.tmp5e2c65c350c24211a132a1aabfa7d446 to: training\\checkpoint : Access is denied.\r\n'I0910' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>; Input/output error\r\n'Input' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>Traceback (most recent call last):\r\n'Traceback' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>  File \"C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\r\nC:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py,: cannot open `C:\\Users\\sbas\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py,' (No such file or directory)\r\nline:                                                                                                     cannot open `line' (No such file or directory)\r\n297,:                                                                                                     cannot open `297,' (No such file or directory)\r\nin:                                                                                                       cannot open `in' (No such file or directory)\r\nstop_on_exception:                                                                                        cannot open `stop_on_exception' (No such file or directory)", "@Docker300 Can you post your issue in Tensorboard repo where the team actively responds and resolves issues faster. When you post there, Please provide a simple standalone code. Thanks!\r\n\r\nI am closing issue here as the issue is more related to the tensorboard repo. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=21135\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=21135\">No</a>\n", "I stubled upon this **unable to rename error** doing just basic tensorflow-gpu stuff on win10, without actually knowing what tensorboard is and not actively using it.\r\n\r\nIt happened to me while using checkpoints between epochs in training a LSTM NN.\r\n\r\nsomeone at #892 mentioned, that the Windows Explorer (or other programs) locking the directory for writing (for some reason), so I closed VS Code and any explorer windows and the script runs as intended.\r\n\r\n(edit: i had the folder opened in VS Code using the Windows Subsystem for Linux (WSL), opening the folder in regular VS Code without WSL seems to have resolved it.)\r\n", "The solution: Look on the rename file names and delete the target file ( e.g.  Failed to rename: training\\checkpoint.tmp5e2c65c350c24211a132a1aabfa7d446 to: training\\checkpoint -> delete training\\checkpoint)\r\nIn my case i think the error cause was that a backup program(syncplicity) locked the target file when it was supposed to be deleted.", "@dshirron thank you, i have the same issue with syncplicty.", "> I stubled upon this **unable to rename error** doing just basic tensorflow-gpu stuff on win10, without actually knowing what tensorboard is and not actively using it.\r\n> \r\n> It happened to me while using checkpoints between epochs in training a LSTM NN.\r\n> \r\n> someone at #892 mentioned, that the Windows Explorer (or other programs) locking the directory for writing (for some reason), so I closed VS Code and any explorer windows and the script runs as intended.\r\n> \r\n> (edit: i had the folder opened in VS Code using the Windows Subsystem for Linux (WSL), opening the folder in regular VS Code without WSL seems to have resolved it.)\r\n\r\nThis seems to be working in my case. I closed my Spyder IDE and the programs runs normally now.", "I was facing the same problem. Just change the **data_dir attribute like data_dir=r\"D:\\data\"** and make sure it should not be in C: drive. You are good to go."]}, {"number": 21134, "title": "apply_gradients does not work with var_list", "body": "I use Windows 10, Tensorflow 1.9.0rc0, Python 3 with latest pycharm.\r\n\r\nIn a project I want to use compute_gradients and apply_gradients. I'm actually following this example https://gist.github.com/tillahoffmann/c04dd6ca9259ef68f743e44c74e3d095 to solve this problem https://github.com/tensorflow/tensorflow/issues/6692. The problem is that the solution does not work when we want to use  var_list with compute_gradients a simple example is\r\n`\r\n\r\n    loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\r\n    optimizer = tf.train.RMSPropOptimizer(learning_rate)\r\n    grads = optimizer.compute_gradients(loss, var_list=[w])    \r\n    train_op = optimizer.apply_gradients(grads)\r\n`\r\nwhich gives me the following error, unless I remove the var_list which is a critical part of my network design.\r\n\r\n`File \"G:\\python-venv\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 602, in apply_gradients\r\n    update_ops.append(processor.update_op(self, grad))\r\n  File \"G:\\python-venv\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 188, in update_op\r\n    raise NotImplementedError(\"Trying to update a Tensor \", self._v)\r\nNotImplementedError: ('Trying to update a Tensor ', <tf.Tensor 'mul:0' shape=(2560, 256) dtype=float32>)`\r\n\r\n\r\n", "comments": ["Seems like [w] here is a Tensor and not a variable? Can you supply the code that relates to [w]? We can only compute gradients wrt Variables.", "Just a note: there are other ways to accomplish the goal of #6692. I was looking for how to do this, albeit with Keras, but the idea still applies: simply apply an elementwise multiplication of your weight matrix by a constant binary matrix in the forward propagation. I created a simple implementation as a Keras layer (see my comment [here](https://github.com/keras-team/keras/issues/9790#issuecomment-408693945)), I'm sure it's easy to also do in pure Tensorflow. (and yes, it is a hack, but it's very simple and I think the cost of additional computation is not very large given the speed of matrix multiplication on a GPU)\r\nBest of luck.", "It has been 32 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "> Seems like [w] here is a Tensor and not a variable? Can you supply the code that relates to [w]? We can only compute gradients wrt Variables.\r\n\r\nwhen i use `w = tf.get_default_graph().get_tensor_by_name('w:0')` for\r\n`optimizer.compute_gradients(loss, var_list=[w])` get the same problem, then i use\r\n`w = tf.trainable_variables()[0]` for\r\n`optimizer.compute_gradients(loss, var_list=[w]),` no more errors.", "I do have the simmer issue \r\ntf version 2.1 \r\n\r\nhttps://stackoverflow.com/questions/61197297/softmax-cross-entropy-with-logits-v2-giving-non-trainable-output\r\nsoftmax_cross_entropy_with_logits_v2 is giving non trainable out put \r\n\r\nIs it a bug ?\r\n", "OK for any body here struggling. I was not giving 1 of 2 arguments to `softmax_cross_entropy_with_logits_v2`  which was the output of NN.\r\nHope this will help "]}, {"number": 21133, "title": "TfLite : Prefixes in makefile for RPI aren't properly prepended", "body": "This was breaking RPI builds for me. \r\n\r\nIf you look at the commit before the tensorflow-gardner you can [see that this wasn't an issue](https://github.com/tensorflow/tensorflow/commit/b933865ed6bb2c04b74df45e3e2ab6a88faf7990#diff-984468042643f6f33fbdcde29db47f01R84). ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "[This was fixed in a later pull request that got merged in](https://github.com/tensorflow/tensorflow/pull/21399)"]}, {"number": 21132, "title": "Develop upstream fusion", "body": "This is for tensorflow-migraph integration work.   The work can run simple inference models. but still at the stage of debugging and interactive hand-shake with MIGraph.   Anyway, you can review it. ", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Thanks a ton for the PR. But this PR is gigantic. Can you break this PR down into smaller, more reviewable PRs. And provide more detailed description and context.", " Sorry, it was my mistake to create this PR.\u00a0 It is premature to submit this change.\n    On Friday, August 10, 2018, 11:27:37 AM PDT, Michael Case <notifications@github.com> wrote:  \n \n \nClosed #21132.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n   "]}, {"number": 21131, "title": "[tftrt_tests]", "body": "unit test added for memory alignment test in trt.", "comments": ["Thanks for adding the test! LGTM.", "I tested that without the alignment fix this test will break.", "Thanks for verifying.\r\nShould have mentioned that I did that exact verification w/ & w/o alignment fix. :)"]}, {"number": 21129, "title": "Feature request: Add a `LMDBDataset` class, that inherits from `tf.data.Dataset`.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nN/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nN/A\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nN/A\r\n- **TensorFlow version (use command below)**:\r\n1.9\r\n- **Python version**:\r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\n\r\n**Feature request: Add a `LMDBDataset` class, that inherits from `tf.data.Dataset`.**\r\nCurrently TF only supports LMDB datasets with the method [`LMDBReader`](https://www.tensorflow.org/api_docs/python/tf/LMDBReader). Implementing a `LMDBDataset` class that inherits from `tf.data.Dataset` will allow users to load LMDB data with the friendly tf.data API, and also use [`tf.contrib.data.make_batched_features_dataset`](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_batched_features_dataset), which applies the most up-to-data performance optimization for loading data.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I updated the post, making them N/A", "Added a PR #21148 for LMDBDataset support.", "Thanks @yongtang! ", "Nagging Assignee @yongtang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21128, "title": "No contrib directory after installation via virtualenv", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.4\r\n- **TensorFlow installed from (source or binary)**: https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.9.0-py3-none-any.whl\r\n- **TensorFlow version (use command below)**: 1.9.0 (v1.9.0-0-g25c197e023)\r\n- **Python version**: 3.6.4\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: Intel Iris Graphics 6100 / 1536 MB\r\n- **Exact command to reproduce**: bazel build tensorflow/contrib/lite/toco:toco\r\n\r\n### Describe the problem\r\nHi, I've successfully installed the latest version of tensorflow with virtualenv and even created the frozen graph of my model with help of it, but then I needed the .tflite file and I found that ```bazel run -c opt tensorflow/contrib/lite/toco:toco``` returns ```no such package 'tensorflow/contrib/lite/toco'``` error (at first run there was ```The 'run' command is only supported from within a workspace.``` and I've created WORKSPACE file, because I saw some issue with such an advice, but problem was not in this file).\r\nThen I've admitted that directory structure differs from one from the github. I had only include, bin and lib directories and pip-selfcheck.json\r\nI've reinstalled tensorflow few times, I've deleted environment in Anaconda, when I had another build of tensorflow and reinstalled it again. Nothing changes. Also I haven't found any issues with this problem in github or stackoverflow. Maybe I've missed something (despite I followed the docs very precisely)? Any help would be very appreciated\r\n\r\n### Source code / logs\r\nI've installed When I'm trying to run \r\n```\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \\\r\n--input_file=/Users/kate/python/codes2/tflite_res/tflite_graph.pb \\\r\n--output_file=/Users/kate/python/codes2/tflite_res/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--mean_values=128 \\\r\n--std_values=128 \\\r\n--change_concat_input_ranges=false \\\r\n--allow_custom_ops\r\n```\r\nI get \r\n```\r\nERROR: Skipping 'tensorflow/contrib/lite/toco:toco': no such package 'tensorflow/contrib/lite/toco': BUILD file not found on package path\r\nWARNING: Target pattern parsing failed.\r\nERROR: no such package 'tensorflow/contrib/lite/toco': BUILD file not found on package path\r\nINFO: Elapsed time: 0.370s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n```\r\n\r\nBazel was installed with homebrew. Build command returns the same. \r\nAlso here is the info I've collected with the help of your script\r\n```\r\n== cat /etc/issue ===============================================\r\nDarwin MacBook-Pro-Ekaterina.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.2)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin MacBook-Pro-Ekaterina.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.15.0\r\nnumpydoc                           0.7.0\r\nprotobuf                           3.6.0\r\ntensorflow                         1.9.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.9.0\r\ntf.GIT_VERSION = v1.9.0-0-g25c197e023\r\ntf.COMPILER_VERSION = v1.9.0-0-g25c197e023\r\nSanity check: array([1], dtype=int32)\r\n/Users/kate/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\r\n  return f(*args, **kwds)\r\n/Users/kate/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n/Users/kate/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\r\n  return f(*args, **kwds)\r\n/Users/kate/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\r\n  return f(*args, **kwds)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```\r\n\r\nThere are some warnings about deprecation in python libs but them seem to be harmless. Also I don't understand why check for virtualenv is false (I've tried to run the command with both activated and deactivated tensorflow environment but it is always false).\r\n\r\nThanks\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nMobile device", "@kate-kate - The `bazel` commands are intended to build TensorFlow binaries (like `toco`) from source. So I'm confused a bit by your setup since it seems you're installing TensorFlow from `pip` and not building from source.\r\n\r\nCould you elaborate on your setup?\r\n", "@asimshankar aah, so that's ok for install from ```pip```? \r\nYou're right, I've installed from ```pip```, but I haven't found any info, that I can't use ```bazel``` or other ```contrib``` utils then. Even on ```contrib``` docs section. Thanks for claryfying, I'll try to make build from source", "@kate-kate - It's okay to install from `pip` which will make all the Python `contrib` APIs (e.g., `tf.contrib.*` symbols in Python) available.\r\n\r\nHowever, it seems you're trying to build the `toco` tool, which is built from source.\r\n\r\nIs there some documentation that you're following that led to this confusion? If so, please let us know which documentation you're looking at, and we'd be happy to update that to make it clearer. But yeah, to build the `toco` tool (and in general to use `bazel` which is a tool to build sources), you need the source code.\r\n\r\nHope that helps.", "@asimshankar Thanks for help!\r\nI think, first reason that led to this confusion is that neither in virtualenv installation guide nor in python API overview for ```contrib``` module  or even for ```toco``` (https://www.tensorflow.org/api_docs/python/tf/contrib/lite/TocoConverter) wasn't anynotr  that it should be installed from source and won't be available from ```pip``` build.\r\nActually there were some hint in ```toco``` [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md) \"Additional instructions\" section, that in order to get the latest version, you should build it from source. But I misunderstood, that it is necessary only for latest version. "]}, {"number": 21127, "title": "install libnccl-dev in Dockerfile.gpu to fix missing nccl.h", "body": "fix https://github.com/tensorflow/tensorflow/issues/21094 for ci_build.", "comments": ["Just saw this https://github.com/tensorflow/tensorflow/commit/402bb7353289013520fa99a38559319bc7b3d845\r\nseems this PR is not needed.\r\n"]}, {"number": 21126, "title": "Estimator model folder format", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: 9.2\r\n- **GPU model and memory**: 1080TI 11GB\r\n- **Exact command to reproduce**: python example.py\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI tried to make a working code for Estimator and Dataset APIs together. The `Estimator` constructor depends on `model_dir` parameter like this: `tf.estimator.Estimator(model_fn, model_dir, params={})`. I've noticed that `model_dir` string should not be ended with '/'. Step to reproduce:\r\n1. Run `python example.py` -> fail\r\n2. Replace line 11 by\r\n```\r\nexperiment_folder = '/output'\r\n```\r\n3. Run `python example.py` -> success\r\n\r\nI think it is a bug. It is simple and easy to avoid but I investigated not so much time to verify is it a symptom of some bigger problem. Hope someone will pay attention to it. \r\n\r\n### Source code / logs\r\nBoth `example.py` and console output could be found [here](https://gist.github.com/RomanSteinberg/840d58b9333a3359cec43bbf4c464e5a).", "comments": ["@RomanSteinberg,\r\nSorry for the delayed response. This behavior is expected because the **`slash`** at the start of the path indicates different path, not that of the folder. This is the property of **`Python`**, not **`Tensorflow`**. Thanks! ", "@rmothukuru please, read the first message attentively. I'm pointing out to the **end slash**, i.e. trailing, not leading.\r\n\r\nFor example, `pathlib` allows you to have or not trailing slash. \r\n```\r\nfrom pathlib import Path\r\n\r\na = Path('/dev')\r\nb = Path('/dev/')\r\na == b  # True\r\n```\r\nIt is an easy-easy issue :)", "@RomanSteinberg As this issue and your example was related to TF 1.x and we don't support TF 1.x anymore if you are still interested in this can you share a version of your example compatible with a recent version of Tensorflow or a Colab?\r\n\r\nThanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@bhack the situation is really weird. Issue has been created three years ago, now you say that 1.x is not supported. So, what do you expect from me? I should find a bug in a new software (tf 2.x)? After answering rmothukuru's perfunctory comment?\r\n\r\nMy code example was taken from official Estimators Guide. The only thing I changed was `model_dir`. Now this guide is removed from official site. And I haven't found any guide which includes `tf.estimator.train_and_evaluate` for images. So, I spent some time to move the example to Colab, shorten it and convert it to tf 2.x.[ Here it is](https://colab.research.google.com/drive/1XrozAWNLobx_3sHMguk_c0io8KSrpI35#scrollTo=5Qkx-n8zcRw3). Now it has another problem related to warm-up and checkpoints. **But I had not specified anything about them!** So, the problem described in this issue may be solved in tf 2.x, but may be not (if it is behind checkpoint problem). I don't know. May be you can create a new issue about new problem and after it resolved we can check `model_dir` problem.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21126\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21126\">No</a>\n"]}, {"number": 21125, "title": "TensorRT loses defined shapes ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **Bazel version**: N/A\r\n- **GPU model and memory**: Titan 12Gb\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10rc0\r\n- **Python version**: 3.5\r\n- **CUDA/cuDNN version**: 9 / 7.0.15\r\n\r\n### Describe the problem\r\nWhen `tf.contrib.tensorrt` compiles a graph which can be fully compiled it loses shape information.\r\n\r\nFor example if you compile a graph which has no activations, for example a model which ends in an average pool so that you can get [N, C] then the shape information is lost.\r\n\r\nIf you load up that optimised model and try to add an operation on the end which required a shape definition, for example a `tf.unstack` it will fail out stating there isn't any shape information.\r\n\r\nThis seems like the output shape should be kept.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nGPU model and memory\nExact command to reproduce\nMobile device", "N/A\r\nTitan 12Gb\r\nN/A\r\nNone", "Could you provide some piece / snippet of code that can reproduce the problem? That can help us debug.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to low activity"]}, {"number": 21124, "title": "The mobilenet predict results are different", "body": "**Problem Description:**\r\n\r\nI meet a very strange problem,the problem is that:\r\nMy job is train a pb file that can predict face's five key points,he network model is mobilenet v2,when I trained to get a small loss pb file, the loss is about 0.7,that's ok,no problem.But when I predict with trained pb file, there's a problem. When the input image shape is [100,224,224,3], get the output is [100,10],(ten means five key point coordinates),that's ok, the output is accurate,tes is right,but when I change input image shape[1,224,224,3](there's only one input image),the output [1,10] is different from privous result,the two cases of  input[0] is the same, but output[0] is different,  the input shape is  [100,224,224,3] more accurate, why? \r\n\r\nthe exact coordinates of output[0]:\r\n[38 46 71 54 62 70 26 81 56 88]\r\n\r\ninput shape [100,224,224,3], get input[0]:\r\n[39.381622 45.988384 73.15548  55.10713  64.56505  70.48474  29.348461\r\n 82.159615 53.589706 87.59885 ]\r\n\r\ninput shape [1,224,224,3],get input[0]:\r\n[[40.17595  47.69543  85.54374  50.631523 64.47522  71.54203  36.73784\r\n  85.07918  79.665985 87.313995]]\r\n\r\n\r\nthe exact coordinates of output[0]:\r\n[39 46 88 35 76 65 51 80 94 70]\r\n\r\ninput shape [100,224,224,3], get input[0]:\r\n[38.898895 45.90179  86.28276  34.750797 76.82557  65.86458  51.15553\r\n 79.85125  95.181885 70.00042 ]\r\n\r\ninput shape [1,224,224,3],get input[0]:\r\n[[39.191376 46.032986 88.266106 39.030933 72.28544  64.2173   49.861656\r\n  80.540855 94.46614  74.561905]]\r\n\r\n-------------------------------------\r\n\r\nSystem information\r\nLinux Ubuntu 16.04:\r\nTensorFlow installed from source:\r\nTensorFlow version 1.8.0:\r\nPython version:3.6:\r\nBazel version 0.11.1:\r\nGCC/Compiler version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) :\r\nCUDA/cuDNN 9.0/7.0.5:\r\nGPU 1060-6G:\r\n", "comments": ["the batch size of the training is 100", "when input shape is [50,224,224,3],the accurate less [100,224,224,3],but more than [1,224,224,3]", "Especially on the side face,the error will be greater, like this face:\r\n\r\nthe exact coordinates of output[0]:\r\n38 46 71 54 62 70 26 81 56 88\r\n\r\ninput shape [100,224,224,3], get input[0]:\r\n[39.381622 45.988384 73.15548  55.10713  64.56505  70.48474  29.348461\r\n 82.159615 53.589706 87.59885 ]\r\n\r\ninput shape [1,224,224,3],get input[0]:\r\n[[40.17595  47.69543  85.54374  50.631523 64.47522  71.54203  36.73784\r\n  85.07918  79.665985 87.313995]]\r\n", "Forgetting to set your batch-norm layers to training=False mode might cause this. As in training mode batch-norm uses batch-wise statistics of mean and variance as estimates for dataset statistics which are clearly less accurate with smaller batches.", "how to set training=False when pridect @atong01 ", "**network demo**\r\n```\r\nweight_decay = 1e-4\r\ndef relu(x, name='relu6'):\r\n    return tf.nn.relu6(x, name)\r\n\r\ndef batch_norm(x, momentum=0.9, epsilon=1e-5, train=True, name='bn'):\r\n    return tf.layers.batch_normalization(x,\r\n                      momentum=momentum,\r\n                      epsilon=epsilon,\r\n                      scale=True,\r\n                      training=train,\r\n                      name=name)\r\n\r\ndef conv2d(input_, output_dim, k_h, k_w, d_h, d_w, stddev=0.02, name='conv2d', bias=False):\r\n    with tf.variable_scope(name):\r\n        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\r\n              regularizer=tf.contrib.layers.l2_regularizer(weight_decay),\r\n              initializer=tf.truncated_normal_initializer(stddev=stddev))\r\n        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\r\n        if bias:\r\n            biases = tf.get_variable('bias', [output_dim], initializer=tf.constant_initializer(0.0))\r\n            conv = tf.nn.bias_add(conv, biases)\r\n        return conv\r\ndef conv2d_block(input, out_dim, k, s, is_train, name):\r\n    with tf.name_scope(name), tf.variable_scope(name):\r\n        net = conv2d(input, out_dim, k, k, s, s, name='conv2d')\r\n        net = batch_norm(net, train=is_train, name='bn')\r\n        net = relu(net)\r\n        return net\r\ndef conv_1x1(input, output_dim, name, bias=False):\r\n    with tf.name_scope(name):\r\n        return conv2d(input, output_dim, 1,1,1,1, stddev=0.02, name=name, bias=bias)\r\ndef pwise_block(input, output_dim, is_train, name, bias=False):\r\n    with tf.name_scope(name), tf.variable_scope(name):\r\n        out=conv_1x1(input, output_dim, bias=bias, name='pwb')\r\n        out=batch_norm(out, train=is_train, name='bn')\r\n        out=relu(out)\r\n        return out\r\ndef global_avg(x):\r\n    with tf.name_scope('global_avg'):\r\n        net=tf.layers.average_pooling2d(x, x.get_shape()[1:-1], 1)\r\n        return net\r\ndef flatten(x):\r\n    return tf.contrib.layers.flatten(x)\r\ndef mobilenetv2(inputs, num_output, is_train=True):\r\n\twith tf.variable_scope('mobilenetv2_128'):\r\n\t\tnet = conv2d_block(inputs, 32, 3, 2, is_train, name='conv1_1')\r\n                net = pwise_block(net, 160, is_train, name='conv7_1')\r\n                net = global_avg(net)\r\n                net = flatten(conv_1x1(net, num_output, name='logits'))\r\n\treturn net\r\n```\r\n**test demo**\r\n\r\n```\r\ndef read_image_cv(image_dir,sess):  # read image, bbx and landmarks\r\n    image_names = os.listdir(image_dir)\r\n    image_names = sorted(image_names)\r\n    image_paths = [image_dir + name for name in image_names]\r\n    image_list = []\r\n    for image_path in image_paths:\r\n        image = cv.imread(image_path)\r\n        image = tf.reshape(image, [128, 128, 3])\r\n        image = tf.cast(image, tf.float64)\r\n        image = tf.image.per_image_standardization(image)\r\n        x_test = image.eval(session=sess)\r\n        image_list.append(x_test)\r\n    return image_list\r\ndef predict_test_set_index(meta_path,checkpoint_path, test_image_dir, index):\r\n    saver = tf.train.import_meta_graph(meta_path)\r\n    saver.restore(sess, checkpoint_path)\r\n    test_image_path = [test_image_dir + name for name in sorted(os.listdir(test_image_dir))]\r\n    with tf.Session() as session:\r\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\r\n        image = read_image_cv(test_image_dir, session)\r\n        out = session.run(output, feed_dict={input: image})\r\n    image_path = test_image_path[index]\r\n    return out, image_path\r\ndef predict_test_one(meta_path,checkpoint_path, test_image_path):\r\n    saver = tf.train.import_meta_graph(meta_path)\r\n    saver.restore(sess, checkpoint_path)\r\n    with tf.Session() as session:\r\n        input = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n        output = tf.get_default_graph().get_tensor_by_name(\"output:0\")\r\n        image = cv.imread(test_image_path)\r\n        image = tf.reshape(image, [128, 128, 3])\r\n        image = tf.cast(image, tf.float64)\r\n        image = tf.image.per_image_standardization(image)\r\n        x_test = image.eval(session=session)\r\n        x_test = x_test[np.newaxis, :]\r\n        out = session.run(output, feed_dict={input: x_test})\r\n    return out\r\ndef test_one_img():\r\n    image_name = '182121.jpg'\r\n    output = predict_test_one(meta_path,checkpoint_path, TEST_IMAGINE_PATH+image_name)\r\n    print(output)\r\ndef test_set_img():\r\n    index = 0\r\n    # there are 100 images in this directory(TEST_IMAGINE_PATH),the index 0 is 182121.jpg\r\n    output,image_path= predict_test_set_index(meta_path,checkpoint_path, TEST_IMAGINE_PATH,index)\r\n    print(output[index])\r\n\r\ntest_set_img()\r\ntest_one_img()\r\n```\r\n", "when i remove batch_norm function, the problem is still there", "I sovled this preblom,this is because BN based on batch_size,when batch_size=1,the error will be enlarged,so can't use bn,we should use layer norm , instance norm or group norm, link:https://blog.csdn.net/qq_25737169/article/details/79713886"]}, {"number": 21123, "title": "Unresolved External Symbol: public: double __cdecl double_conversion::StringToDoubleConverter::StringToDouble(char const *,int,int *)const", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.9\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: Cmake 3.10.2, swigwin 3.0.12, Visual studio 2015 v140\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:  I followed to CMake tutorial here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake TensorFlow CMake build\r\n\r\n### Describe the problem\r\nError when compiling a sample program in Visual Studio:\r\n\r\n- Severity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tLNK2019\tunresolved external symbol \"public: double __cdecl double_conversion::StringToDoubleConverter::StringToDouble(char const *,int,int *)const \" (?StringToDouble@StringToDoubleConverter@double_conversion@@QEBANPEBDHPEAH@Z) referenced in function \"bool __cdecl tensorflow::strings::safe_strtod(char const *,double *)\" (?safe_strtod@strings@tensorflow@@YA_NPEBDPEAN@Z)\tTensorFlow r1.9\tD:\\GIT\\All\\TensorFlow.plugin\\tf_core_lib.lib(numbers.obj)\t1\t\r\n- Severity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tLNK2019\tunresolved external symbol \"public: float __cdecl double_conversion::StringToDoubleConverter::StringToFloat(char const *,int,int *)const \" (?StringToFloat@StringToDoubleConverter@double_conversion@@QEBAMPEBDHPEAH@Z) referenced in function \"unsigned __int64 __cdecl tensorflow::strings::FloatToBuffer(float,char *)\" (?FloatToBuffer@strings@tensorflow@@YA_KMPEAD@Z)\tTensorFlow r1.9\tD:\\GIT\\All\\TensorFlow.plugin\\tf_core_lib.lib(numbers.obj)\t1\t\r\n\r\nIs there any additional dependency that I am missing? Check below for the list. Thanks\r\n\r\n### Source code / logs\r\n\r\nSample program:\r\n\r\n```\r\n#include \"stdafx.h\"\r\n\r\n#include <vector>\r\n#include <eigen/Dense>\r\n\r\n#include \"matmul.h\"\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\n\r\nint main()\r\n{\r\n\tScope root = `Scope::NewRootScope();\r\n}\r\n```\r\n\r\nAdditional Dependencies:\r\n\r\n```\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\zlib\\install\\lib\\zlibstatic.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\gif\\install\\lib\\giflib.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\png\\install\\lib\\libpng16_static.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\jpeg\\install\\lib\\libjpeg.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\lmdb\\install\\lib\\lmdb.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\jsoncpp\\src\\jsoncpp\\src\\lib_json\\Release\\jsoncpp.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\farmhash\\install\\lib\\farmhash.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\fft2d\\\\src\\lib\\fft2d.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\highwayhash\\install\\lib\\highwayhash.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\nsync\\src\\nsync\\Release\\nsync.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\snappy\\src\\snappy\\Release\\snappy.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\protobuf\\src\\protobuf\\Release\\libprotobuf.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_string_ops.dir\\Release\\tf_string_ops.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_cc.dir\\Release\\tf_cc.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_cc_ops.dir\\Release\\tf_cc_ops.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_cc_framework.dir\\Release\\tf_cc_framework.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.dir\\Release\\tf_core_lib.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_core_cpu.dir\\Release\\tf_core_cpu.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_core_direct_session.dir\\Release\\tf_core_direct_session.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.dir\\Release\\tf_core_framework.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_core_kernels.dir\\Release\\tf_core_kernels.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_core_ops.dir\\Release\\tf_core_ops.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\tf_cc_while_loop.dir\\Release\\tf_cc_while_loop.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\Release\\tf_protos_cc.lib\r\nTensorFlow\\r1.9\\tensorflow\\contrib\\cmake\\build\\sqlite\\install\\lib\\sqlite.lib\r\n```", "comments": ["Solved by including double-conversion.lib", "Nagging Assignee @jart: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "`__cdecl`? Are you linking TensorFlow against a system library with a 32-bit ABI?\r\n\r\ncc: @martinwicke @gunan https://www.agner.org/optimize/calling_conventions.pdf"]}, {"number": 21122, "title": "nGraph Integration with TensorFlow ", "body": "This is the first revision of the integration of nGraph with TensorFlow. The nGraph provides a JIT compilation and execution of TensorFlow computation graphs. To enable nGraph, select the configuration option during running configure. ", "comments": ["I don't think I'm a good reviewer for this since it seems to be almost entirely build-system edits and I'm not very familiar with that.", "Nor am I particularly. @avijit-nervana Have you been in touch with anyone on the TensorFlow team who might have more context for this PR?", "@mrry Thanks for the follow up. Yes - we have been in discussions with Rajat Monga and Tatiana Shpeisman about this integration. Tatiana mentioned that she will be  following up on this PR. ", "cc @tatianashp ", "Great, thanks. @tatianashp I'll hand off the review to you, since this is out of my wheelhouse.", "I'll review and pull in others as necessary.", "@aaroey Thanks for the comments. I have updated the PR. There is no need to setup any specific build environment for building nGraph on Ubuntu 16.04 and macOS. Just selecting nGraph build option during the configure step will suffice to built TensorFlow with nGraph. Please let us know if you have additional questions or comments.  ", "Thanks for the fix @avijit-nervana. Would you please help to fix the conflicts?\r\nAlso +@gunan.", "@aaroey Resolved the conflicts. Please let me know if there are further changes needed. Thanks!", "License section (will need to update when info is 100%)\r\n\r\nWhat is ok or is not ok changes depending on a few things, one big one is if the binaries are included in the build or just used to compile and the user has to install the libraries to use them.  At a glance I believe all of the code is being included in the binary and I am listing what I see below.\r\n\r\n   * [ngraph](https://github.com/NervanaSystems/ngraph): Apache\r\n   * [nlohmann_json_lib](https://github.com/nlohmann/json/blob/develop/LICENSE.MIT) (json c++ lib)  MIT \r\n   * [ngraph_tf](https://github.com/NervanaSystems/ngraph-tf) (ngraph bridge for tensorflow) Apache\r\n\r\nThese all look ok. I know Apache is an approved license and I am nearly 100% sure MIT is. \r\n @thirupalanisamy owns the final confirmation but at a glance this looks fine.  "]}, {"number": 21121, "title": "add_to_collection does not update trainable attribute", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution**: ArchLinux\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:1.9.0-2\r\n- **Python version**:3.6.6\r\n- **CUDA/cuDNN version**: 9.2.148-1 / 7.1.4-1\r\n- **GPU model and memory**: GTX 1080 Ti\r\n- **Exact command to reproduce**: python test.py\r\n\r\n### Describe the problem\r\nUse `tf.add_to_collection` to add nontrainable variable to `tf.GraphKeys.TRAINABLE_VARIABLES` collection. The `trainable` attribute of variable is stiil False.\r\n\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\n\r\nwith tf.name_scope('some_scope1'):\r\n    a = tf.Variable(initial_value=1, name='a')\r\n    b = tf.Variable(initial_value=2, name='b', trainable=False)\r\n    c = tf.Variable(initial_value=3, name='c')\r\n\r\nwith tf.name_scope('some_scope2'):\r\n    d = tf.Variable(initial_value=4, name='d', trainable=False)\r\n    e = tf.Variable(initial_value=5, name='e', trainable=False)\r\n    f = tf.Variable(initial_value=6, name='f')\r\n\r\nh = tf.Variable(initial_value=8, name='h')\r\n\r\nprint('-------GLOBAL_VARIABLES-------')\r\nfor i in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='some_scope'):\r\n    print(i.name, i)   # i.name if you want just a name\r\n\r\nprint('-------TRAINABLE_VARIABLES 1-------')\r\nfor i in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='some_scope'):\r\n    print(i.name, i)   # i.name if you want just a name\r\n\r\nprint('-------Set ALL to Trainable------')\r\nfor i in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='some_scope'):\r\n    tf.add_to_collection(tf.GraphKeys.TRAINABLE_VARIABLES, i)\r\n\r\nprint('-------TRAINABLE_VARIABLES 2-------')\r\nfor i in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='some_scope'):\r\n    print(i.name, i, i.trainable)   # i.name if you want just a name\r\n\r\n'''\r\n-------GLOBAL_VARIABLES-------\r\nsome_scope1/a:0 <tf.Variable 'some_scope1/a:0' shape=() dtype=int32_ref>\r\nsome_scope1/b:0 <tf.Variable 'some_scope1/b:0' shape=() dtype=int32_ref>\r\nsome_scope1/c:0 <tf.Variable 'some_scope1/c:0' shape=() dtype=int32_ref>\r\nsome_scope2/d:0 <tf.Variable 'some_scope2/d:0' shape=() dtype=int32_ref>\r\nsome_scope2/e:0 <tf.Variable 'some_scope2/e:0' shape=() dtype=int32_ref>\r\nsome_scope2/f:0 <tf.Variable 'some_scope2/f:0' shape=() dtype=int32_ref>\r\n-------TRAINABLE_VARIABLES 1-------\r\nsome_scope1/a:0 <tf.Variable 'some_scope1/a:0' shape=() dtype=int32_ref>\r\nsome_scope1/c:0 <tf.Variable 'some_scope1/c:0' shape=() dtype=int32_ref>\r\nsome_scope2/f:0 <tf.Variable 'some_scope2/f:0' shape=() dtype=int32_ref>\r\n-------Set ALL to Trainable------\r\n-------TRAINABLE_VARIABLES 2-------\r\nsome_scope1/a:0 <tf.Variable 'some_scope1/a:0' shape=() dtype=int32_ref> True\r\nsome_scope1/c:0 <tf.Variable 'some_scope1/c:0' shape=() dtype=int32_ref> True\r\nsome_scope2/f:0 <tf.Variable 'some_scope2/f:0' shape=() dtype=int32_ref> True\r\nsome_scope1/a:0 <tf.Variable 'some_scope1/a:0' shape=() dtype=int32_ref> True\r\nsome_scope1/b:0 <tf.Variable 'some_scope1/b:0' shape=() dtype=int32_ref> False\r\nsome_scope1/c:0 <tf.Variable 'some_scope1/c:0' shape=() dtype=int32_ref> True\r\nsome_scope2/d:0 <tf.Variable 'some_scope2/d:0' shape=() dtype=int32_ref> False\r\nsome_scope2/e:0 <tf.Variable 'some_scope2/e:0' shape=() dtype=int32_ref> False\r\nsome_scope2/f:0 <tf.Variable 'some_scope2/f:0' shape=() dtype=int32_ref> True\r\n'''\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nMobile device", "This is working more or less as intended. It's an unfortunate combination, but we're trying to (slowly) move away from global collections. So I expect the resolution will be not to have a global trainable variable collection.\r\n\r\nDoes that make sense? If you'd like to explain the use-case, we can see what the alternatives are. For example if you'd like to toggle trainability, I'd suggest keeping the variables in a tf.keras.Model and switching model.trainable:\r\n\r\n```\r\n>>> import tensorflow as tf\r\n>>> m = tf.keras.Model()\r\n>>> m.v = tf.Variable(1., trainable=True)\r\n>>> m.trainable_variables\r\n[<tf.Variable 'Variable:0' shape=() dtype=float32_ref>]\r\n>>> m.trainable = False\r\n>>> m.trainable_variables\r\n[]\r\n```\r\n\r\nYou can have multiple sub-models with different `trainable` attributes, and trainable variables will be aggregated from those. Then the aggregated list can be passed to an optimizer's `var_list` (or whatever else).", "Thanks, Allen.\r\nThat's really an unfortunate combination. :+1: \r\nKeras is good enough.\r\nHope Tensorflow will be better.\r\n"]}, {"number": 21120, "title": "Log_probabilities returned by tf.nn.ctc_beam_search_decoder", "body": "**System Info**\r\n\r\n- Have I written custom code=Yes\r\n- OS Platform and Distribution :: Linux ( CentOS version 6.6 )\r\n- TensorFlow installed from: binary (pip install)\r\n- TensorFlow version : 1.3.0\r\n- Bazel version: N/A\r\n- CUDA/cuDNN version : v8.0.44\r\n- GPU model and memory: NVIDIA Quadro P5000 (16272MiB)\r\n- Exact command to reproduce :N/A \r\n- Mobile device: N/A\r\n\r\n**Problem**\r\nI am training a LSTM-CTC speech recognition system with using beam search decoding in the following configuration:\r\n\r\n`decoded, log_prob =\r\ntf.nn.ctc_beam_search_decoder(\r\n    inputs,\r\n    sequence_length,\r\n    beam_width=100,\r\n    top_paths=3,\r\n    merge_repeated=True\r\n)`\r\n\r\n\r\nThe output of log_probabilities for a batch by the above decoder are like-\r\n \r\n`     \r\n\r\n       [ [ 20.45407486,  20.44991684,  20.41798401],\r\n\r\n        [ 14.9961853 ,  14.925807  ,  14.88066769],\r\n        ..., \r\n        [ 18.89863396,  18.85992241,  18.85712433],\r\n\r\n        [  3.93567419,   3.92791557,   3.89198923],\r\n\r\n        [ 14.56258488,  14.55923843,  14.51092243]],`\r\n\r\n\r\nSo how these scores represent log probabilities and if I want to compare confidence for top paths among examples then what will be the normalisation factor???\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Yes its still an issue .\r\nNo response has been received till yet.", "Unfortunately, you don't have a probability, because it would mean summing over all possible sequences of all admissible lengths. You can pretend that the top hypotheses that you get out of the decoder comprise all of the probability mass. In that case, then the scores are in log domain. You can compute\r\n\r\n```\r\nZ = sum_k(exp(score_k))\r\n```\r\nThen each sequence has a probability of `exp(score_k) / Z`."]}, {"number": 21119, "title": "Add PATCH_COMMAND to eigen.cmake (fix #19198)", "body": "This PR adds the ability to apply a patch file to eigen as part of the build. Currently, Eigen has at least one issue under certain configurations. This PR is not to address any specific issue but to make the build more flexible. I linked a patch file below to fix the specific issue in #19198.\r\n\r\nJust add `-Deigen_PATCH_FILE=path/to/patch.txt` to cmake and it will run the patch file after downloading eigen. Defaults to `OFF` (no patch file).\r\n\r\nBug I was getting:\r\n- http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1526\r\n- https://github.com/tensorflow/tensorflow/issues/19198\r\n\r\nPatch file in gist below. Based on the bug above with some path and line number changes.\r\n- https://gist.github.com/bstriner/a7fb0a8da1f830900fa932652439ed44\r\n\r\nThis way no one is waiting on a third-party to make a new release. Should be easy enough to make other patches as necessary.\r\n\r\nThis does assume that `patch` command is on `PATH`. An alternative would be to let the user specify the entire patch command instead of just the patch file but that might unnecessarily complicate things.\r\n\r\nCheers", "comments": ["Thanks @caisq . Some odd failures like `Current Bazel version is 0.14.1, expected at least 0.15.0`. Also timed out on `kernel_tests:prefetching_ops_test` for some reason. I don't think the failures are legit but I could be wrong.", "Is there any way to slipstream this patch file fix into the Bazel build process? Currently, I'm hitting this exact same issue while trying to build TF 1.10 on Windows using Bazel, but there does not seem to be any way of having Bazel apply the patch similar to how it works with the cmake flag you added.", "@trias702  \r\n\r\n> \r\n> \r\n> Is there any way to slipstream this patch file fix into the Bazel build process? Currently, I'm hitting this exact same issue while trying to build TF 1.10 on Windows using Bazel, but there does not seem to be any way of having Bazel apply the patch similar to how it works with the cmake flag you added.\r\n\r\nHave you find a way? I have the same issue."]}, {"number": 21118, "title": "use custom operators  Failed to allocate tensors.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:iphone 6s\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:1.9\r\n- **Python version**:3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI follow [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/custom_operators.md) custom Abs operator,but I ran my code throw error:\r\ntensorflow/contrib/lite/simple_memory_arena.cc:82 it->size != alloc.size (52272 != 0)\r\n2018-07-25 14:03:50.795332+0800 testTF[1477:647442] Failed to allocate tensors.\r\n\r\n### Source code / logs\r\n    TfLiteStatus AbsPrepare(TfLiteContext* context, TfLiteNode* node) {\r\n    using namespace tflite;\r\n    TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\r\n    TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\r\n    \r\n    const TfLiteTensor* input = GetInput(context, node, 0);\r\n    TfLiteTensor* output = GetOutput(context, node, 0);\r\n    \r\n    int num_dims = NumDimensions(input);\r\n    \r\n    TfLiteIntArray* output_size = TfLiteIntArrayCreate(num_dims);\r\n    for (int i=0; i<num_dims; ++i) {\r\n        output_size->data[i] = input->dims->data[i];\r\n    }\r\n    \r\n    return context->ResizeTensor(context, output, output_size);\r\n    }\r\n\r\n    TfLiteStatus AbsEval(TfLiteContext* context, TfLiteNode* node) {\r\n    using namespace tflite;\r\n    const TfLiteTensor* input = GetInput(context, node,0);\r\n    TfLiteTensor* output = GetOutput(context, node,0);\r\n    \r\n    float* input_data = input->data.f;\r\n    float* output_data = output->data.f;\r\n    \r\n    size_t count = 1;\r\n    int num_dims = NumDimensions(input);\r\n    for (int i = 0; i < num_dims; ++i) {\r\n        count *= input->dims->data[i];\r\n    }\r\n    \r\n    for (size_t i=0; i<count; ++i) {\r\n        output_data[i] = std::abs(input_data[i]);\r\n    }\r\n    return kTfLiteOk;\r\n    }\r\n\r\n    TfLiteRegistration* Register_ABS() {\r\n    static TfLiteRegistration r = {nullptr, nullptr, AbsPrepare, AbsEval};\r\n    return &r;\r\n    }\r\n    int width = 24;\r\n     int height = 24;\r\n     NSString* RunInferenceOnImage() {\r\n     NSString* graph = @\"tf_Rnet\";\r\n     const int num_threads = 4;\r\n     std::string input_layer_type = \"float\";\r\n     std::vector<int> sizes = {1, height, width, 3};\r\n     //std::vector<int> sizes = {1, 224, 224, 3};\r\n    \r\n    const NSString* graph_path = FilePathForResourceName(graph, @\"tflite\");\r\n    \r\n    std::unique_ptr<tflite::FlatBufferModel> model(\r\n                                                   tflite::FlatBufferModel::BuildFromFile([graph_path UTF8String]));\r\n    if (!model) {\r\n        NSLog(@\"Failed to mmap model %@.\", graph);\r\n        exit(-1);\r\n    }\r\n    NSLog(@\"Loaded model %@.\", graph);\r\n    model->error_reporter();\r\n    NSLog(@\"Resolved reporter.\");\r\n    \r\n     #ifdef TFLITE_CUSTOM_OPS_HEADER\r\n    tflite::MutableOpResolver resolver;\r\n    RegisterSelectedOps(&resolver);\r\n    #else\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n    resolver.AddCustom(\"Abs\", Register_ABS());\r\n    #endif\r\n    \r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n    tflite::InterpreterBuilder(*model, resolver)(&interpreter);\r\n    if (!interpreter) {\r\n        NSLog(@\"Failed to construct interpreter.\");\r\n        exit(-1);\r\n    }\r\n    \r\n    if (num_threads != -1) {\r\n        interpreter->SetNumThreads(num_threads);\r\n    }\r\n    \r\n    int input = interpreter->inputs()[0];\r\n    std::vector<int> tensor_input =interpreter->inputs();\r\n    for (int index = 0; index < tensor_input.size(); index++)\r\n    {\r\n        TfLiteTensor* tensor = interpreter->tensor(tensor_input[index]);\r\n        TfLiteIntArray* dims = tensor->dims;\r\n        NSLog(@\"fi\");\r\n    }\r\n    if (input_layer_type != \"string\") {\r\n        interpreter->ResizeInputTensor(input, sizes);\r\n    }\r\n    \r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n        NSLog(@\"Failed to allocate tensors.\");\r\n        exit(-1);\r\n    }\r\n    NSString* image_path = FilePathForResourceName(@\"face\", @\"jpg\");\r\n    int image_width;\r\n    int image_height;\r\n    int image_channels;\r\n    std::vector<uint8_t> image_data =\r\n    LoadImageFromFile([image_path UTF8String], &image_width, &image_height, &image_channels);\r\n    const int wanted_width = width;\r\n    const int wanted_height = height;\r\n    const int wanted_channels = 3;\r\n    const float input_mean = 127.5f;\r\n    const float input_std = 127.5f;\r\n    //  const float input_mean = 127.5f;\r\n    //  const float input_std = 127.5f;\r\n    assert(image_channels >= wanted_channels);\r\n    uint8_t* in = image_data.data();\r\n    float* out = interpreter->typed_tensor<float>(input);\r\n    for (int y = 0; y < wanted_height; ++y) {\r\n        const int in_y = (y * image_height) / wanted_height;\r\n        uint8_t* in_row = in + (in_y * image_width * image_channels);\r\n        float* out_row = out + (y * wanted_width * wanted_channels);\r\n        for (int x = 0; x < wanted_width; ++x) {\r\n            const int in_x = (x * image_width) / wanted_width;\r\n            uint8_t* in_pixel = in_row + (in_x * image_channels);\r\n            float* out_pixel = out_row + (x * wanted_channels);\r\n            for (int c = 0; c < wanted_channels; ++c) {\r\n                out_pixel[c] = (in_pixel[c] - input_mean) / input_std;\r\n            }\r\n        }\r\n    }\r\n    \r\n    if (interpreter->Invoke() != kTfLiteOk) {\r\n        NSLog(@\"Failed to invoke!\");\r\n        exit(-1);\r\n    }\r\n    \r\n    std::vector<int> tensor_out =interpreter->outputs();\r\n\r\n    size_t size = tensor_out.size();\r\n    for (int index = 0; index < size; index++)\r\n    {\r\n        TfLiteTensor* tensor = interpreter->tensor(tensor_out[index]);\r\n        TfLiteIntArray* dims = tensor->dims;\r\n        float* output = interpreter->typed_output_tensor<float>(index);\r\n        for (int i = 0; i<dims->data[1]; i++)\r\n        {\r\n            NSLog(@\"%@\",@(output[i]));\r\n        }\r\n        NSLog(@\"finish\");\r\n    }\r\n    return NULL;\r\n    }", "comments": ["Hi @iChiaGuo, the first thing I'd try is making sure output_size has no zeros in it.", "Nagging Assignee @andrehentz: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21117, "title": "mpi build failed, wrong filename", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04 x64\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nno\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.10.0rc0\r\n- **Python version**:\r\n3.6.6 x64\r\n- **Bazel version (if compiling from source)**:\r\n0.15.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4.0\r\n- **CUDA/cuDNN version**: \r\n9.2/7.1.5\r\n- **GPU model and memory**:\r\nGTX1080Ti GDDR5X 11GB  X  6\r\n- **Exact command to reproduce**:\r\nbuild with mpi support\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n![image](https://user-images.githubusercontent.com/4515120/43182126-1e4d20e8-901b-11e8-9414-2bc216fbd49f.png)\r\n\r\n\r\nthere is no such file actually\r\n\r\n![image](https://user-images.githubusercontent.com/4515120/43182165-4789549a-901b-11e8-8086-f2da98551316.png)\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21116, "title": "tensorflow lite only one output", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **Mobile device (e.g iphone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:iphone 6s\r\n- **TensorFlow installed from (source or binary)**:no\r\n- **TensorFlow version (use command below)**:1.9\r\n- **Python version**:3.5\r\n- **Bazel version (if compiling from source)**:0.12\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI use my model in tensorflowlite ,it have two outputs,but in my iphone6s only get one output!\r\n\r\n(py35) ljg@ljg-linux:~/facenet/src/align/pb$ /home/ljg/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=Pnet.pb\r\nFound 1 possible inputs: (name=pnet/input, type=float(1), shape=[?,?,?,3]) \r\nNo variables spotted.\r\nFound 2 possible outputs: (name=pnet/conv4-1/BiasAdd, op=BiasAdd) (name=pnet/conv4-2/BiasAdd, op=BiasAdd) \r\nFound 6632 (6.63k) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 13 Const, 13 Identity, 6 Neg, 6 Relu, 5 BiasAdd, 5 Conv2D, 3 Add, 3 Mul, 1 MaxPool, 1 Placeholder\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=Pnet.pb --show_flops --input_layer=pnet/input --input_layer_type=float --input_layer_shape=-1,-1,-1,3 --output_layer=pnet/conv4-1/BiasAdd,pnet/conv4-2/BiasAdd\r\n\r\n/home/ljg/tensorflow-1.9.0/bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=Pnet.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --output_file=Pnet.tflite  --inference_type=FLOAT --inference_input_type=FLOAT --input_shape=1,12,12,3 --input_array=pnet/input --output_array=pnet/conv4-1/BiasAdd pnet/conv4-2/BiasAdd\r\n\r\n![problem](https://user-images.githubusercontent.com/13581022/43180218-6e6282b0-9009-11e8-8bd4-f1d6046ba7e5.png)\r\n\r\n### Source code / logs\r\n    `class PNet(Network):\r\n        def setup(self):\r\n             (self.feed('data') \r\n             .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')\r\n             .prelu(name='PReLU1')\r\n             .max_pool(2, 2, 2, 2, name='pool1')\r\n             .conv(3, 3, 16, 1, 1, padding='VALID', relu=False, name='conv2')\r\n             .prelu(name='PReLU2')\r\n             .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv3')\r\n             .prelu(name='PReLU3')\r\n             .conv(1, 1, 2, 1, 1, relu=False, name='conv4-1'))\r\n             .softmax(3,name='prob1'))\r\n\r\n             (self.feed('PReLU3') \r\n             .conv(1, 1, 4, 1, 1, relu=False, name='conv4-2'))\r\n        `   \r\n      `model_path='./'\r\n      export_dir='./pb/'\r\n      g1 = tf.Graph()\r\n      sess1 = tf.Session(graph=g1)\r\n      with sess1.as_default(): \r\n          with g1.as_default():\r\n              with tf.variable_scope('pnet'):\r\n                  data = tf.placeholder(tf.float32, (None,None,None,3), 'input')\r\n                  pnet = PNet({'data':data})\r\n                 pnet.load(os.path.join(model_path, 'det1.npy'), sess1)\r\n            \r\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n          sess1, sess1.graph_def, ['pnet/conv4-2/BiasAdd', 'pnet/conv4-1/BiasAdd'])\r\n    tf.train.write_graph(frozen_graphdef,export_dir, 'Pnet.pb', as_text=False)  \r\n    print ('finis')\r\n`     \r\n\r\n", "comments": ["@iChiaGuo you cannot use `--output_array` to set multiple outputs, please use `--output_arrays` instead", "thanks ,I solve my problem."]}]