[{"number": 14451, "title": "Oversampling functionality in dataset API", "body": "Hello,\r\nI would like to ask if current API of datasets allows for implementation of oversampling algorithm? I deal with highly imbalanced class problem. I was thinking that it would be nice to oversample specific classes during dataset parsing i.e. online generation. I've seen the implementation for `rejection_resample`  function, however this removes samples instead of duplicating them and its slows down batch generation (when target distribution is much different then initial one). The thing I would like to achieve is: to take an example, look at its class probability decide if duplicate it or not. Then call `dataset.shuffle(...)` `dataset.batch(...)` and get iterator. The best (in my opinion) approach would be to oversample low probable classes and subsample most probable ones. I would like to do it online since it's more flexible. Just wondering if this is possible with current API? ", "comments": ["If you have a function `f` that returns the number of times to duplicate an element, you can data-dependently repeat an element using `dataset.flat_map(lambda x: tf.data.Dataset.from_tensors(x).repeat(f(x))`. Perhaps that would work?", "Thanks I will try this.", "Hi @mrry , I've checked it, and it works perfectly :+1:  Thank you very much :) \r\nHere is a sample code which I'm going to try in my image classification problem. I'm posting it here in case if someone will want to experiment with the method.  The code is oversampling low frequent classes and undersampling high frequent classes, where `class_target_prob` is just uniform distribution in my case. I wanted to check conclusions from recent manuscript [A systematic study of the class imbalance problem in convolutional neural networks](https://arxiv.org/abs/1710.05381)\r\n\r\nHere is the code:\r\n\r\n```python\r\n# sampling parameters\r\noversampling_coef = 0.9 # if equal to 0 then oversample_classes() always returns 1\r\nundersampling_coef = 0.5 # if equal to 0 then oversampling_filter() always returns True\r\n\r\ndef oversample_classes(example):\r\n    \"\"\"\r\n    Returns the number of copies of given example\r\n    \"\"\"\r\n    class_prob = example['class_prob']\r\n    class_target_prob = example['class_target_prob']\r\n    prob_ratio = tf.cast(class_target_prob/class_prob, dtype=tf.float32)\r\n    # soften ratio is oversampling_coef==0 we recover original distribution\r\n    prob_ratio = prob_ratio ** oversampling_coef \r\n    # for classes with probability higher than class_target_prob we\r\n    # want to return 1\r\n    prob_ratio = tf.maximum(prob_ratio, 1) \r\n    # for low probability classes this number will be very large\r\n    repeat_count = tf.floor(prob_ratio)\r\n    # prob_ratio can be e.g 1.9 which means that there is still 90%\r\n    # of change that we should return 2 instead of 1\r\n    repeat_residual = prob_ratio - repeat_count # a number between 0-1\r\n    residual_acceptance = tf.less_equal(\r\n                        tf.random_uniform([], dtype=tf.float32), repeat_residual\r\n    )\r\n    \r\n    residual_acceptance = tf.cast(residual_acceptance, tf.int64)\r\n    repeat_count = tf.cast(repeat_count, dtype=tf.int64)\r\n    \r\n    return repeat_count + residual_acceptance\r\n\r\n\r\ndef undersampling_filter(example):\r\n    \"\"\"\r\n    Computes if given example is rejected or not.\r\n    \"\"\"\r\n    class_prob = example['class_prob']\r\n    class_target_prob = example['class_target_prob']\r\n    prob_ratio = tf.cast(class_target_prob/class_prob, dtype=tf.float32)\r\n    prob_ratio = prob_ratio ** undersampling_coef\r\n    prob_ratio = tf.minimum(prob_ratio, 1.0)\r\n    \r\n    acceptance = tf.less_equal(tf.random_uniform([], dtype=tf.float32), prob_ratio)\r\n\r\n    return acceptance\r\n\r\n\r\ndataset = dataset.flat_map(\r\n    lambda x: tf.data.Dataset.from_tensors(x).repeat(oversample_classes(x))\r\n)\r\n\r\ndataset = dataset.filter(undersampling_filter)\r\n\r\ndataset = dataset.repeat(-1)\r\ndataset = dataset.shuffle(2048)\r\ndataset = dataset.batch(32)\r\n\r\nsess.run(tf.global_variables_initializer())\r\n\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n```\r\n\r\nI think this issue can be closed now. Thanks again :+1: ", "Since your question has been resolved, also consider posting an answered question to [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow), where it's likely to reach more developers with a similar question. Thanks!", "Glad to hear that it worked! Thanks for posting the example, and +1 to @angersson's suggestion!", "I've followed the @angersson's suggestion and posted answered question to Stack Overflow. Here is the link [Q&A](https://stackoverflow.com/questions/47236465/oversampling-functionality-in-tensorflow-dataset-api/47236466#47236466). Once more time thanks for quick feedback. "]}, {"number": 14450, "title": "tf.nn.sparse_softmax_cross_entropy_with_logits documentation error", "body": "It looks like there may be a documentation error in [tf.nn.sparse_softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits). \r\n\r\nIt mentions \"ValueError: If logits are scalars (need to have rank >= 1) or if the **rank of the labels is not equal to the rank of the labels minus one**.\" \r\n\r\nBased on the argument requirements above, I believe this should read \"ValueError: If logits are scalars (need to have rank >= 1) or if the rank of the labels is not equal to the rank of the **logits** minus one.\" ", "comments": ["Thanks for catching this. Feel free to submit a pull request to fix it.\r\n", "The error in this case is not in the in-file documentation in master (which is correct) but only on the website. It seems that master has the correct documentation, but 1.4 does not. If it is still valuable to pull request that change for 1.4, I can do so. However, I did notice a related error in master, which I did submit a pull request for. ", "Yes, the typo of `sparse_softmax_cross_entropy_with_logits` is fixed in the master branch."]}, {"number": 14449, "title": "Is it a bug of tf.summary.image?", "body": "Look at the code: \r\n\r\n```\r\ntf.summary.image('xx', tf.constant(1.), collections='A')\r\nprint(len(tf.get_collection('A')))\r\n```\r\n\r\nIt prints `1`.\r\n\r\n```\r\ntf.summary.image('xx', tf.constant(1.), collections='IMAGE_SUMMARY')\r\nprint(len(tf.get_collection('IMAGE_SUMMARY')))\r\n```\r\nBut it prints `0`.", "comments": ["The API says:\r\n```\r\ncollections: Optional list of ops.GraphKeys. The collections to add the summary to. Defaults to [_ops.GraphKeys.SUMMARIES]\r\n```\r\nIt should be a __list__, not string.", "This appears to have been resolved (thanks!), so I'm closing the issue to keep the tracker focused."]}, {"number": 14448, "title": "[Feature request] Improve syntax for accessing Python objects in dataset pipelines", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary \r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\n\r\nHey, I have a python database class\r\n```python\r\nclass MyDatabase:\r\n    def __len__(self): return ...\r\n    def __getitem__(self, item): return ...  # slow code without gitlock, i.e. io and numpy\r\n```\r\nthat supports indexing and returns a dict. The loading of the data is longer than a NN iteration, therefore it would be nice when tensorflow loads the data in parallel. When I use tf.data.Dataset.from_generator I have to convert my Database to a generator\r\n```python\r\ndef generator():\r\n    db = MyDatabase()\r\n    yield from [db[i] for i in range(len(db))]\r\n```\r\n`from_generator` has no argument `num_parallel_calls`, therefore the loading is serial.\r\nI am not sure how difficult it is to add such an argument. \r\nBut in the case that `MyDatabase` has above structure it is possible to combine `tf.data.Dataset.range` with `tf.data.Dataset.map` and `tf.py_func` to get a parallel load. \r\nIn my mind, it could be easier to implement a parallel load for an indexable object.\r\n\r\nFurther point the interface of `tf.py_func` has more constraints than `tf.data.Dataset.from_generator` (dict's are not allowed and it hat no output_shape argument).\r\n\r\nSince I am new to tensorflow and have problems to understand the `tf.data.Dataset` code, here my feature request for a `num_parallel_calls` argument in `tf.data.Dataset.from_generator` or a new function `tf.data.Dataset.from_generator` with a `num_parallel_calls` argument.\r\n\r\n### Source code / logs\r\n\r\nHere a toy example, that demonstrate the non-parallel from_generator\r\n\r\n```python\r\nimport time\r\n\r\nstart = time.perf_counter()\r\n    \r\ndef body(i):\r\n    global start\r\n    if i == 0:\r\n        start = time.perf_counter()\r\n    time.sleep(0.2)\r\n    return np.array([float(i), time.perf_counter() - start])\r\n\r\ndef gen():\r\n    for i in range(5):\r\n        yield body(i)\r\n        \r\nds = tf.data.Dataset.from_generator(gen, tf.float64)\r\nds = ds.prefetch(5)\r\niterator = ds.make_one_shot_iterator()\r\n\r\nentry = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    \r\n    try:\r\n        while True:\r\n            print(sess.run(entry))\r\n    except tf.errors.OutOfRangeError:\r\n        pass\r\n# Serial execution:  [index, time from start of first load to return of current load]\r\n# [ 0.          0.20034038]\r\n# [ 1.          0.40189139]\r\n# [ 2.          0.60322792]\r\n# [ 3.          0.80472201]\r\n# [ 4.          1.00612245]\r\n```\r\nand here the parallel version (Less nice code and does not generalise so good as from_generator, e.g. no return dict support)\r\n```python\r\nds = tf.data.Dataset.range(5)\r\n\r\ndef map_func(i):\r\n    return tf.py_func(body, [i], tf.float64, stateful=False)\r\n\r\nds = ds.map(map_func, num_parallel_calls=4)\r\nds = ds.prefetch(1)\r\niterator = ds.make_one_shot_iterator()\r\n\r\nentry = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    \r\n    try:\r\n        while True:\r\n            print(sess.run(entry))\r\n    except tf.errors.OutOfRangeError:\r\n        pass\r\n\r\n# Parallel execution:  [index, time from start of first load to return of current load]\r\n# [ 0.          0.20026697]\r\n# [ 1.          0.20084557]\r\n# [ 2.          0.20095535]\r\n# [ 3.          0.20048737]\r\n# [ 4.          0.40154806]\r\n```", "comments": ["@vrv @mrry  Feature requests for datasets.", "It sounds like `Dataset.map()` and `tf.py_func()` are almost adequate for your needs, so I'd be more in favor of improving `tf.py_func()` to the point where it has the same feature set as `Dataset.from_generator()`. Approximately speaking, it would need support for nested structures as inputs and outputs, and optional shape hints. There might be some delicacy in doing this without breaking backwards compatibility, but it should be possible. (If not, we could add a new API in `tf.contrib` at first with the new support.)\r\n\r\nMarking this as contributions welcome.", "Thanks for the suggestion to modify `py_func`. I looked in the code of `from_generator` and there is the generalization of my workaround with dicts.\r\n\r\nI try to extract the code from `from_generator` and write a wrapper around `py_func`.\r\n\r\nCurrent signature\r\n`py_func(func, inp, Tout, stateful=True, name=None)`\r\nFuture signature\r\n`py_func(func, inp, output_types, output_shapes=None, stateful=True, name=None)`\r\n\r\nWith that modification, I will be able to a `from_indexable` for my use cases.\r\n\r\nBut first I will write a bugfix for `nest.assert_shallow_structure` for dicts with different keys.\r\n\r\n", "Now I have some working code, I extracted the code from 'tf.data.Dataset.from_generator' and modified it to have a similar signature as `py_func`.\r\nFurther, I added also a decorator (I prefer the decorator style.). For the decorator I allowed `output_type`/`output_shapes` to be callable to dynamic infer the `output_type`/`output_shapes`.\r\n\r\nIf there is an interest in a PR, I need some feedback on the code and some advise, where I place the code and tests.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport traceback\r\n\r\nfrom tensorflow.python.data.util import nest\r\nfrom tensorflow.python.framework import tensor_shape\r\nfrom tensorflow.python.ops import script_ops\r\n\r\ndef my_py_func(func, args=(), kwargs={}, output_types=None, output_shapes=None, stateful=True, name=None):\r\n    # Low level function\r\n    \r\n    if isinstance(args, list):\r\n        # Force tuple, nest.flatten interprets list as scalar\r\n        args = tuple(args)\r\n        \r\n    if callable(output_types):\r\n        # If callable, assume same signature and call with tensors and get the types\r\n        output_types = output_types(*args, **kwargs)\r\n    if callable(output_shapes):\r\n        # If callable, assume same signature and call with tensors and get the shapes\r\n        output_shapes = output_shapes(*args, **kwargs)\r\n    \r\n    flat_output_types = nest.flatten(output_types)\r\n    \r\n    args = (args, kwargs)\r\n        \r\n    flat_args = nest.flatten(args)\r\n\r\n    def python_function_wrapper(*py_args):\r\n        try:\r\n            py_args, py_kwargs = nest.pack_sequence_as(args, py_args)\r\n            ret = func(*py_args, **py_kwargs)\r\n            nest.assert_shallow_structure(output_types, ret)\r\n        except Exception:\r\n            traceback.print_exc()\r\n            raise\r\n        return nest.flatten(ret)\r\n    \r\n    flat_values = script_ops.py_func(\r\n      python_function_wrapper, flat_args, flat_output_types, stateful=stateful, name=name)\r\n\r\n    if output_shapes is not None:\r\n        # I am not sure if this is nessesary\r\n        output_shapes = nest.map_structure_up_to(\r\n            output_types, tensor_shape.as_shape, output_shapes)\r\n        flattened_shapes = nest.flatten(output_shapes)\r\n        for ret_t, shape in zip(flat_values, flattened_shapes):\r\n            ret_t.set_shape(shape)\r\n\r\n    return nest.pack_sequence_as(output_types, flat_values)\r\n    \r\ndef py_func_decorator(output_types=None, output_shapes=None, stateful=True, name=None):\r\n    def decorator(func):\r\n        def call(*args, **kwargs):\r\n            return my_py_func(\r\n                func, \r\n                args, kwargs, \r\n                output_types=output_types, output_shapes=output_shapes, \r\n                stateful=stateful, name=name\r\n            )\r\n        return call\r\n    return decorator\r\n            \r\n@py_func_decorator(\r\n    output_types=lambda a, b: {\r\n        'a': nest.map_structure(lambda x: x.dtype, a), \r\n        'b': nest.map_structure(lambda x: x.dtype, b),\r\n    }, \r\n    output_shapes=lambda a, b: {\r\n        'a': nest.map_structure(lambda x: x.shape, a), \r\n        'b': nest.map_structure(lambda x: x.shape, b),\r\n    },\r\n)\r\ndef foo(a, b):\r\n    return {'a': a, 'b': b}\r\n    \r\ndef bar(a, b):\r\n    return {'a': a, 'b': b}\r\n    \r\na = tf.constant([4., 5], name='a')\r\nb = tf.constant([4., 5], name='b')\r\nc = tf.constant([4., 5], name='c')\r\nout0 = my_py_func(\r\n    bar, [a, b], output_types={'a': a.dtype, 'b': b.dtype}, output_shapes={'a': a.shape, 'b': b.shape})\r\nout1 = foo(a, b)\r\nout2 = foo(a, b=b)\r\nout3 = foo(a=a, b=b)\r\nout4 = foo(a=dict(a=a, c=c), b=b)\r\nprint('out0', out0)\r\nprint('out1', out1)\r\n\r\nfrom IPython.lib.pretty import pprint\r\n\r\nwith tf.Session() as sess:\r\n    pprint(sess.run([out0]))\r\n    pprint(sess.run([out1, out2, out3]))\r\n    pprint(sess.run([out3]))\r\n\r\n```", "@mrry I started from `tf.data.from_generator` and wrote a wrapper around `pyfunc` to allow nested structures. Should I make a PR?\r\n\r\nFurther, I have now also a `tf.data.from_indexable` (Only some few lines with range and map) that support parallel loading with python code. Should I make a PR, else I will keep the code in my own code base?\r\n", "We'd welcome a PR with any improvements to `tf.py_func()`. Ideally those could be in-place and backwards compatible, rather than adding a new API.\r\n\r\nI'm less sure about `from_indexable()`, because I think it would amount to a one-line wrapper around `Dataset.map()` and `tf.py_func()` once the former changes go in. However, if it turns out to reduce the code complexity, perhaps we could find a place for it in `tf.contrib.data`.", "Ok, I will make a PR for improving `tf.pyfunc`. I argee backward compatibility is important, but maybe rename some arguments would be better:\r\n\r\nCurrent signature:\r\n```python\r\ndef py_func(func, inp, Tout, stateful=True, name=None)\r\n```\r\nMy prefared signature (similar to tf.data.Dataset.from_generator): (Note: output_types should not have a default argument.)\r\n```python\r\ndef my_py_func(func, args=(), kwargs={}, output_types=None, output_shapes=None, stateful=True, name=None)\r\n```\r\nSuggestion for better backward compatibility:\r\n```python\r\ndef my_py_func(func, inp=(), kwargs={}, Tout=None, Sout=None, stateful=True, name=None)\r\n```\r\n\r\nNote: An advantage of a decorator would be, that args and kwargs can be inferred (See example from_indexable).\r\n\r\nYou are right `from_indexable` takes only some few lines of code. For completeness here the code:\r\n\r\n```python\r\ndef from_indexable(iterator, output_types, output_shapes=None, num_parallel_calls=None, stateful=True, name=None):\r\n    length = \r\n    ds = tf.data.Dataset.range(len(iterator))\r\n    @py_func_decorator(output_types, output_shapes, stateful=stateful, name=name)\r\n    def index_to_entry(index):\r\n        return iterator[index]\r\n    return ds.map(index_to_entry, num_parallel_calls=num_parallel_calls)\r\n\r\n```", "Automatically closing this out since I understand it to be resolved by the PR #15121 (merged already), but please let me know if I'm mistaken.Thanks!"]}, {"number": 14447, "title": "PrefetchDataset with buffer_size==0 results in deadlock", "body": "Hey, \r\n\r\nI experimented with `tf.data.Dataset.prefetch` and found that an assert inside the code is missing.\r\nWhen `buffer_size` is zero, I got a deadlock.\r\nHere is a toy example to reproduce my bug:\r\n\r\n```python\r\nimport tensorflow as tf\r\ndef test(buffer_size):\r\n    ds = tf.data.Dataset.range(5)\r\n    ds = ds.prefetch(buffer_size=buffer_size)\r\n    iterator = ds.make_one_shot_iterator()\r\n    entry = iterator.get_next()\r\n    with tf.Session() as sess:\r\n        try:\r\n            while True:\r\n                print(sess.run(entry))\r\n        except tf.errors.OutOfRangeError:\r\n            pass\r\n        \r\ntest(1)\r\ntest(0)  # deadlock\r\n```\r\nand here my tensorflow version\r\n```bash\r\n$ pip show tensorflow\r\nName: tensorflow\r\nVersion: 1.4.0\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: .../lib/python3.6/site-packages\r\nRequires: protobuf, numpy, wheel, tensorflow-tensorboard, absl-py, six, enum34\r\n```\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Good! Perhaps it's better to check `buffer_size` at c++ side?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e951547c9ba5f883f3be9bd9b1a79ccc85b29629/tensorflow/core/kernels/prefetch_dataset_op.cc#L36-L40", "Yes, it would be better to have the assert in the C++ side.\r\nBut I am not sure if then the traceback gets lost.\r\nIs the C++ exception traceback readable? I have sometimes error msgs that are unrelated to the error.\r\nIf yes, only C++ else C++ and python.\r\n\r\nI am not familiar with the C++ code (and style), so maybe someone other can make the changes? \r\n\r\n ", "@boeddeker Hi, might we close the PR since #14508 has been merged. Thanks. ", "@facaiy Hi, thanks for the fix. I have closed this PR."]}, {"number": 14446, "title": "[Mac] Changes in fast-math-flags LLVM API cause XLA enabled build to fail", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13 High Sierra\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: HEAD\r\n- **Python version**: 3.6/2.7\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: 9.0.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\nFollow instructions in docs and build optimized for native architecture with XLA enabled (assumes fix in https://github.com/tensorflow/tensorflow/pull/14288).\r\n\r\n### Describe the problem\r\nLLVM latest release v5.0.0 does not include [recent fast-math-flags LLVM API changes](https://reviews.llvm.org/rL317488) already [updated](https://github.com/tensorflow/tensorflow/commit/4e69e02241067129379f73dd4fefe57f0a12bdc9#diff-866fd5845e79e513efd00ed931aa56f5L559) into TensorFlow codebase. \r\nNext LLVM release (v5.0.1) scheduled for the end of November, in the meanwhile besides building LLVM with CMake (?) there is no solution (?) but to wait.\r\n\r\nDisclaimer: I'm new to LLVM and stuff so if I'm missing something I apologize and appreciate any insight.\r\n\r\n```\r\ntensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:560:11: error: no member named 'setFast' in 'llvm::FastMathFlags'\r\n    flags.setFast();\r\n    ~~~~~ ^\r\n```\r\n\r\n", "comments": ["@tatatodd ", "@jlebar might know more about this.", "Hey there.\r\n\r\nAs you say, LLVM's APIs are not stable.  TF and XLA target LLVM built at head, not a particular LLVM release.  So if you want to build XLA, you also have to build LLVM.\r\n\r\nThis should happen automatically and transparently for you as part of the TF+XLA build.\r\n\r\nThe LLVM revision we check out is specified here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl#L570\r\n\r\nUnfortunately it looks like we updated XLA to use the new fastmath API and pushed that change upstream without the corresponding change to workspace.bzl.  :(\r\n\r\nUntil we upstream our next set of changes, you can either roll back to before 82cd76bd36, or you can change that section in workspace.bzl to:\r\n\r\n```\r\n  temp_workaround_http_archive(\r\n      name = \"llvm\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/llvm-mirror/llvm/archive/618cf290880ae9cd87b4bbf6c9b1759476f422eb.tar.gz\",\r\n          \"https://github.com/llvm-mirror/llvm/archive/618cf290880ae9cd87b4bbf6c9b1759476f422eb.tar.gz\",\r\n      ],\r\n      sha256 = \"ec2e032e58372c614c41b539c0309baa91843c30d7a9c6dee647dcd24be02e3c\",\r\n      strip_prefix = \"llvm-618cf290880ae9cd87b4bbf6c9b1759476f422eb\",\r\n      build_file = str(Label(\"//third_party/llvm:llvm.BUILD\")),\r\n      repository = tf_repo_name,\r\n  )\r\n```\r\n\r\nI'm sorry about this.  :-/  I don't know enough about our OSS-releasing process to know if this is avoidable on our end in some way.", "@jlebar Thank you for the thorough explanation and solution :) and no worries at all.\r\nI've made the suggested changes and it built successfully \ud83d\udc4d "]}, {"number": 14445, "title": "Target '@llvm//:support' is not visible from target '@org_tensorflow//tensorflow/compiler/xla/client:compile_only_client'.", "body": "I was doing an XLA compilation that worked before TensorFlow 1.4 but now errors with\r\n\r\n> ERROR: /home/travis/build/carl/project/cache/bazel/external/org_tensorflow/tensorflow/compiler/xla/client/BUILD:107:1: Target '@llvm//:support' is not visible from target '@org_tensorflow//tensorflow/compiler/xla/client:compile_only_client'.\r\n\r\nThis is how I get tfcompile:\r\n```sh\r\ngit clone https://github.com/tensorflow/tensorflow\r\ncd tensorflow\r\ngit checkout v1.4.0 # Note: master also fails\r\nPYTHON_BIN_PATH=$(which python) USE_DEFAULT_PYTHON_LIB_PATH=1 CC_OPT_FLAGS='-march=native'\r\n  TF_ENABLE_XLA=0 TF_NEED_MPI=0 TF_NEED_JEMALLOC=1 TF_NEED_GCP=0 TF_NEED_HDFS=0\r\n  TF_NEED_VERBS=0 TF_NEED_OPENCL=0 TF_NEED_CUDA=0 TF_NEED_GDR=0 TF_NEED_S3=0 TF_NEED_OPENCL_SYCL=0 ./configure\r\n```", "comments": ["Please provide details about what platform you are using  (operating system, architecture). If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "Ubuntu Trusty on Travis with Bazel 0.7.0.", "I have the same problem on osx", "Same on Debian Sid, Bazel v0.5.4.", "I've been able to trigger my build after changing roughly a dozen of visibility to public in `third_party/llvm/llvm.BUILD` by trial/error ... Not sure if it's a legit solution, though.", "I wonder how the Bazel in Jenkins differs from our configs considering the 1.4 tests passed. :confused: ", "@carlthome I took a chance and had a look at the `tensorflow/tools/ci_build/` tooling. It turns out that it seems those run without sandbox, using `--spawn_strategy=standalone --genrule_strategy=standalone`.\r\n\r\n*edit* Actually, I got tricked, it's really the use of `tfcompile` that triggers that, strategies have no impact whatsoever.", "@jart this seems potentially like a build issue rather than an XLA issue. Would you PTAL?", "I've pushed a fix for this to our staging tree, it will make its way to Github shortly.\r\n\r\nIf you wish to workaround this locally in your tree, just change this line:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/llvm/llvm.BUILD#L21\r\nfrom\r\npackage(default_visibility = [\"@%ws%//tensorflow/compiler/xla:internal\"])\r\nto\r\npackage(default_visibility = [\"//visibility:public\"])", "Sounds like @hawkinsp has got this one under control. That main repo reference issue has always been somewhat problematic.", "Thanks @hawkinsp, it's indeed a generalization of the workaround I was working with, as documented above :)", "Works again for me now. Thanks!", "I can confirm it also works for us. Thanks!"]}, {"number": 14444, "title": "Can not import graph after transform_graph with quantize_nodes", "body": "### System information\r\n- **What is the top-level directory of the model you are using**: models/object_detection\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.0-rc0\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **CUDA/cuDNN version**: 375.82\r\n- **GPU model and memory**: GeForce GTX 770 4GB\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n  --in_graph=\"/home/.../mobilenet_v2.pb\" \\\r\n  --out_graph=\"/home/.../mobilenet_v2_clean.pb\" \\\r\n  --inputs=image_tensor\\\r\n  --outputs=\"detection_boxes,detection_scores,detection_classes,num_detections\"\\\r\n  --transforms='add_default_attributes\r\n  strip_unused_nodes\r\n  remove_nodes(op=Identity, op=CheckNumerics)\r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  quantize_nodes\r\n  sort_by_execution_order'\r\n```\r\n\r\n### Problem\r\nI'm trying to quantize default SSD Mobilenet from models rep.\r\nAfter execution transformation as above, I can not import graph:\r\n```\r\ndetection_graph = tf.Graph()\r\nwith detection_graph.as_default():\r\n  od_graph_def = tf.GraphDef()\r\n  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n    serialized_graph = fid.read()\r\n    od_graph_def.ParseFromString(serialized_graph)\r\n    tf.import_graph_def(od_graph_def, name='')\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-0d8b8f2357e8> in <module>()\r\n      5     serialized_graph = fid.read()\r\n      6     od_graph_def.ParseFromString(serialized_graph)\r\n----> 7     tf.import_graph_def(od_graph_def, name='')\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    314                 'in a future version' if date is None else ('after %s' % date),\r\n    315                 instructions)\r\n--> 316       return func(*args, **kwargs)\r\n    317     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    318                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\r\n    337                 raise ValueError('Specified colocation to an op that '\r\n    338                                  'does not exist during import: %s in %s' % (\r\n--> 339                                      op_to_bind_to, node.name))\r\n    340               original_op = name_to_op[op_to_bind_to]\r\n    341               new_class_values.append(compat.as_bytes(\r\n\r\nValueError: Specified colocation to an op that does not exist during import: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/strided_slice in Postprocessor/BatchMultiClassNonMaxSuppression/map/while/TensorArrayWrite_4/TensorArrayWriteV3/Enter\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@UndeadBlow, hi, do you have solved this problem? I have the same problem.", "I got the same error => solved it by not using fold_constants in graph_transform", "@bignamehyp this is a bug. I run into this issue when I use the 'obfuscate_names' transform."]}, {"number": 14443, "title": "fix the distributed training problem for the estimator api", "body": "Current version will fail as I tried to use the `tf.estimator.train_and_evaluate` api for distributed training on the same machine. All the gpus will be occupied even when I  set `session_config.gpu_options.allow_growth = True` for `tf.estimator.RunConfig`.", "comments": ["Can one of the admins verify this patch?", "@xiejw FYI -- I think this makes sense: the gpu options set in TF_CONFIG should be used. If one wants to vary them by worker/PS, once can send different TF_CONFIG (though that would only rarely be necessary). Passing GPU options to non-GPU workers should be harmless. ", "Jenkins, test this please.", "@tensorflow-jenkins test this please", "@Dong--Jian could you update the change to handle when config.session_config is None? Thanks!", "Thanks for the reminder. I add the corresponding code.", "@Dong--Jian could you rebase and push again?", "I have rebased with the master.", "Jenkins, test this please."]}, {"number": 14442, "title": "Session.run() hangs in child thread if something was executed in main thread first", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Confirmed on Mac OS X (10.12.6) + Ubuntu 16.04 on GCP\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: Anaconda Python 3.6.1 \r\n- **GPU model and memory**: no gpu\r\n\r\n### Describe the problem\r\n`Session.run()` hangs in thread if it has executed something in the main thread. If we don't execute the first `calculate_something()` in the main thread- or execute it after we submitted to the pool, everything works. Only when first calculating something in the main thread, and then in the child thread does tensorflow hang. \r\n\r\n### Reproducing example\r\n```python\r\nfrom concurrent.futures import ProcessPoolExecutor as ProcessPool\r\n\r\n\r\ndef calculate_something():\r\n    import tensorflow as tf\r\n\r\n    with tf.Session() as sess:\r\n        a = tf.constant(2)\r\n        b = tf.constant(3)\r\n\r\n        print(\"a=2, b=3\")\r\n        print(\"Addition with constants: %i\" % sess.run(a+b))\r\n        print(\"Multiplication with constants: %i\" % sess.run(a*b))\r\n\r\ncalculate_something()\r\n\r\npool = ProcessPool(1)\r\npool.submit(calculate_something)\r\n```\r\n", "comments": ["I assume `ProcessPoolExecutor` uses `fork()` internally, and forking after the TensorFlow runtime creates internal threads is unsafe. Fortunately, there are two workarounds:\r\n\r\n1. Use `ThreadPoolExecutor` instead of `ProcessPoolExecutor`.\r\n2. Use `tf.Session(config=tf.ConfigProto(use_per_session_threads=True))` instead of `tf.Session()`.", "Thanks, that tip works!", "Hi @JosPolfliet,\r\n\r\nWhich of the two workarounds mentioned by @mrry worked for you?  I am facing the same problem.\r\n ", "FWIW I found that both 1 and 2 were necessary to prevent hang."]}, {"number": 14440, "title": "code comments error in docker notebook", "body": "as is related with issue #14430\r\n\r\n1. changed \"x_with_bias\" to \"bias_with_x\" for clear understanding \r\n2. changed weights updated comments in code for an error\r\n\r\n3. added lecun's repo for mnist data, for there would be no connection(no good connection) for google", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14439, "title": "Fix all tests under python/keras on windows", "body": "Fixes #12959 ", "comments": ["SUCCESS\n \n", "SUCCESS\n \n", "Looks like it has an API change?", "I see the problem, the new commit should fix it.\r\nIt is a small change, but it is still an API change, added API review tag to the PR.", "Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please.", "Passing all kokoro tests, and jenkins failures are just timeouts due to resource constraints.\r\n\r\n@fchollet, @martinwicke Is the API change OK?\r\nPreviously, the `_` made the tensorboard callback's `on_train_end` function require one positional arg, contraty to its superclass' definition of having one `kwarg`, `logs`. The change just makes subclass interface the same as the superclass interface.\r\n\r\n", "The change is ok. Thanks!"]}, {"number": 14438, "title": "code comments error in docker notebook", "body": "in related with issue #14430\r\n\r\n1. changed x_with_bias to bias_with_x for clear understanding\r\n2. changed weights updated comments in code for an error", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "can anyone help to draw this back? I issued a new one. thanks"]}, {"number": 14437, "title": "Typo", "body": "fix typo\r\ndissassemble -> disassemble", "comments": ["Can one of the admins verify this patch?", "Is PR #14435 already included in this PR, isn't it?", "Closing in favor of #14435 since it duplicates some of the changes."]}, {"number": 14436, "title": "Setting up a Jenkins job for ppc64le for Tensorflow ", "body": "We are interested in setting up a Jenkins job for ppc64le for Tensorflow\u00a0\u00a0@\u00a0http://ci.tensorflow.org/. We can work on providing and configuring a ppc64le slave node that can be hooked in to the Jenkins master. Please let me know if that can be done and if yes, what would be the minimum configuration requirements for the slave node? Thanks.", "comments": ["@gunan ", "We have plans to move away from jenkins and move to a fully internal build system (as we have been experimenting for a while).\r\nI will need to look into how contributed builds can be handled with that model.\r\n", "Thanks, @gunan. Is there any timeframe we are looking at by which this would be in place? We also have an external Jenkins based CI environment that can support Power builds, would it be something you would be interested in pursuing?", "I am pushing for a decision, but was not able to get a resolution before thanksgiving.\r\nI think Jenkins environment you are mentioning may be interesting.\r\n\r\nI will try to bring up the topic right after thanksgiving and see where we end up.", "Thanks @gunan. From our side, we are actively working on finalizing the access request form and documentation for this. Some additional information can be found at http://osuosl.org/services/powerdev/  for your reference.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "@sandipmgiri has there been any updates?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi @gunan ,\r\nYou can request for either VM or Jenkins from here (both CPU/GPU) - http://osuosl.org/services/powerdev/.\r\nWe can either provide VM or work with you to setup a job on the Jenkins infra hosted here \r\n\r\nThanks.", "I would like to go for the option where we can collaborate easier.\r\nSo let's go for the solution where we setup a job on the jenkins infra hosted there, where you can also have full access to the job setup.\r\n\r\nPlease reach out to me through (my github username) @ (companyname).com so we can discuss the details.", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gunan: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gunan: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gunan: It has been 90 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is now resolved. the new ppc64le job is also linked from the readme page at our repository root."]}, {"number": 14435, "title": "Fix typo", "body": "fix typo \r\ninitialize -> initialize", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14434, "title": "Fixed typo in tfprof", "body": "intialized -> initialized", "comments": ["Can one of the admins verify this patch?", "I think time has superceded this. Sorry!"]}, {"number": 14433, "title": "tensorflow.python.framework.errors_impl.InternalError: Failed to create session.", "body": "**I am running some preparation code with tf, it seems it doesn't to much memory for it. But:**\r\n\r\n(tensorflow) lab-huang.zhongyi@gpu-2:~/workspace/vae-npvc$ python build.py\r\n452 files found\r\nProcessing Tensor(\"ReaderReadV2:0\", shape=(), dtype=string)\r\n2017-11-10 12:24:55.938368: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-11-10 12:24:55.938398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-11-10 12:24:55.938408: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-11-10 12:24:55.938427: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-11-10 12:24:55.938435: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n\r\n2017-11-10 12:24:57.272601: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 8508145664\r\nTraceback (most recent call last):\r\n  File \"build.py\", line 100, in <module>\r\n    main()\r\n  File \"build.py\", line 24, in main\r\n    with sv.managed_session() as sess:\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\", line 59, in __enter__\r\n    return next(self.gen)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py\", line 964, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py\", line 792, in stop\r\n    stop_grace_period_secs=self._stop_grace_secs)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/lab-huang.zhongyi/.local/lib/python3.5/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py\", line 953, in managed_session\r\n    start_standard_services=start_standard_services)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py\", line 708, in prepare_or_wait_for_session\r\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py\", line 273, in prepare_session\r\n    config=config)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py\", line 178, in _restore_checkpoint\r\n    sess = session.Session(self._target, graph=self._graph, config=config)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1292, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 562, in __init__\r\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/home/lab-huang.zhongyi/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\r\n\r\n**and when I checkout \"nvidia-smi\", some GPUs still have many memory:**\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    On   | 0000:04:00.0     Off |                  N/A |\r\n| 49%   69C    P2    57W / 180W |   8046MiB /  8114MiB |     45%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 1080    On   | 0000:05:00.0     Off |                  N/A |\r\n| 48%   69C    P2    53W / 180W |   7393MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 1080    On   | 0000:08:00.0     Off |                  N/A |\r\n| 53%   72C    P2    54W / 180W |   7917MiB /  8114MiB |     19%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 1080    On   | 0000:09:00.0     Off |                  N/A |\r\n| 60%   76C    P2    54W / 180W |   7413MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  GeForce GTX 1080    On   | 0000:84:00.0     Off |                  N/A |\r\n| 24%   41C    P8    12W / 180W |   2684MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  GeForce GTX 1080    On   | 0000:85:00.0     Off |                  N/A |\r\n| 24%   35C    P8    12W / 180W |   1895MiB /  8114MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  GeForce GTX 1080    On   | 0000:88:00.0     Off |                  N/A |\r\n| 67%   82C    P2   163W / 180W |   6105MiB /  8114MiB |     88%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  GeForce GTX 1080    On   | 0000:89:00.0     Off |                  N/A |\r\n| 67%   82C    P2   144W / 180W |   6097MiB /  8114MiB |     89%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n\r\n**and here is the code:**\r\n https://github.com/JeremyCCHsu/vae-npvc/blob/master/build.py\r\n\r\n**Thank you all so much, I am really just a beginner.**", "comments": ["Oh it it really don\u2018t  enought memories.\r\nI solved it by allocating memories dynamically:\r\n\r\nimport tensorflow as tf  \r\nimport os  \r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'   #use GPU with ID=0 \r\nconfig = tf.ConfigProto()  \r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5  # maximun alloc gpu50% of MEM\r\nconfig.gpu_options.allow_growth = True      #allocate dynamically\r\nsess = tf.Session(config = config) \r\n", "mark", "In the case I just solved, it was updating the GPU driver to the latest and installing the cuda toolkit. First, the ppa was added and GPU driver installed:\r\n\r\n    sudo add-apt-repository ppa:graphics-drivers/ppa\r\n    sudo apt update\r\n    sudo apt install nvidia-390\r\n\r\nAfter adding the ppa, it showed options for driver versions, and 390 was the latest 'stable' version that was shown.\r\n\r\nThen install the cuda toolkit:\r\n\r\n    sudo apt install nvidia-cuda-toolkit\r\n\r\nThen reboot:\r\n\r\n    sudo reboot\r\n\r\nIt updated the drivers to a newer version than the 390 originally installed in the first step (it was 410; this was a p2.xlarge instance on AWS)."]}, {"number": 14432, "title": "Errors and warnings through op_kernel.cc and core/grappler/utils.cc", "body": "### Description of the problem\r\n\r\nI installed tensorflow from sources.\r\nThere was no errors during configure as well as build. \r\n\r\nBut I get the several errors [E] and warnings [W]. \r\n\r\nBut if I run neural network example from the repository [here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network.py), I get several warnings, but the code runs, gives output as expected.\r\n\r\nIn the logs below, I show the two examples. \r\n\r\nFirst one on the command line, trying to run \"Hello, World!\". I get the few errors of the form (op: \"some_operation\", device_type: \"CPU\") for unknown op: some_operation. Exact op's are in the log below. \r\n\r\nSecond one, example from the repository: [here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network.py). I get warnings [W] saying that \"MatMul_1_fused is not in the graph\".\r\n\r\nFiles involved are \r\n\r\n1. tensorflow/core/framework/op_kernel.cc:1142\r\n2. tensorflow/core/grappler/utils.cc:48\r\n\r\n```\r\n### Source code / logs\r\n********************************** log for validation script ***************************************************\r\nPython 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:09:58) \r\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, Tensorflow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\n2017-11-09 21:54:07.579195: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"DenseToSparseBatchDataset\" device_type: \"CPU\"') for unknown op: DenseToSparseBatchDataset\r\n2017-11-09 21:54:07.579255: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"GroupByWindowDataset\" device_type: \"CPU\"') for unknown op: GroupByWindowDataset\r\n2017-11-09 21:54:07.579261: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"IgnoreErrorsDataset\" device_type: \"CPU\"') for unknown op: IgnoreErrorsDataset\r\n2017-11-09 21:54:07.579286: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"DatasetToSingleElement\" device_type: \"CPU\"') for unknown op: DatasetToSingleElement\r\n2017-11-09 21:54:07.579301: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"DeserializeIterator\" device_type: \"CPU\"') for unknown op: DeserializeIterator\r\n2017-11-09 21:54:07.579307: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"MapAndBatchDataset\" device_type: \"CPU\"') for unknown op: MapAndBatchDataset\r\n2017-11-09 21:54:07.579324: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"ParallelInterleaveDataset\" device_type: \"CPU\"') for unknown op: ParallelInterleaveDataset\r\n2017-11-09 21:54:07.579336: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"ScanDataset\" device_type: \"CPU\"') for unknown op: ScanDataset\r\n2017-11-09 21:54:07.579345: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"SqlDataset\" device_type: \"CPU\"') for unknown op: SqlDataset\r\n2017-11-09 21:54:07.579410: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: \"SerializeIterator\" device_type: \"CPU\"') for unknown op: SerializeIterator\r\nb'Hello, Tensorflow!'\r\n```\r\n```\r\n****************************************************************************************************************\r\n\r\n********************************** log for neural network code from examples *****************************\r\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\r\nExtracting /tmp/data/train-images-idx3-ubyte.gz\r\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\r\nExtracting /tmp/data/train-labels-idx1-ubyte.gz\r\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\r\nExtracting /tmp/data/t10k-images-idx3-ubyte.gz\r\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\r\nExtracting /tmp/data/t10k-labels-idx1-ubyte.gz\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvak_s5_3\r\n2017-11-09 22:31:36.069140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-11-09 22:31:36.069505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] Found device 0 with properties: \r\nname: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 3.95GiB freeMemory: 3.50GiB\r\n2017-11-09 22:31:36.069519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1151] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2017-11-09 22:31:36.368840: W tensorflow/core/grappler/utils.cc:48] Node dense_3/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.368900: W tensorflow/core/grappler/utils.cc:48] Node dense_2/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.368918: W tensorflow/core/grappler/utils.cc:48] Node dense/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.368996: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_1_fused is not in the graph.\r\n2017-11-09 22:31:36.369024: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.369045: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_1_fused is not in the graph.\r\n2017-11-09 22:31:36.369074: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.369097: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_1_fused is not in the graph.\r\n2017-11-09 22:31:36.369122: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.526452: W tensorflow/core/grappler/utils.cc:48] Node dense_3/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.526488: W tensorflow/core/grappler/utils.cc:48] Node dense_2/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.526504: W tensorflow/core/grappler/utils.cc:48] Node dense/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.526534: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_1_fused is not in the graph.\r\n2017-11-09 22:31:36.526543: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_3/MatMul_grad/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.526562: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_1_fused is not in the graph.\r\n2017-11-09 22:31:36.526570: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense_2/MatMul_grad/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:36.526589: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_1_fused is not in the graph.\r\n2017-11-09 22:31:36.526597: W tensorflow/core/grappler/utils.cc:48] Node gradients/dense/MatMul_grad/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:38.129805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1151] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2017-11-09 22:31:38.168010: W tensorflow/core/grappler/utils.cc:48] Node dense_3/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:38.168065: W tensorflow/core/grappler/utils.cc:48] Node dense_2/MatMul_fused is not in the graph.\r\n2017-11-09 22:31:38.168081: W tensorflow/core/grappler/utils.cc:48] Node dense/MatMul_fused is not in the graph.\r\nTesting Accuracy: 0.9167\r\n\r\n*****************************************************************************************************************\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: CUDA-8.0, cuDNN - 6.1\r\n- **GPU model and memory**: GTX 1050, 4GB\r\n- **Exact command to reproduce**: sample code to validate installation", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.", "I have faced the same problem. Did you find the solution?"]}, {"number": 14431, "title": "typo fixed", "body": "thats -> that's", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14430, "title": "Some errors in docker tf notebooks", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS 7\r\n- **TensorFlow installed from (source or binary)**: docker images\r\n- **TensorFlow version (use command below)**: latest\r\n\r\n### Describe the problem\r\n\r\nit is just a documentation problem.\r\n\r\nin https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/2_getting_started.ipynb\r\n\r\nin section **the code again**, in the comments:\r\n\r\n```py\r\n    # Perform gradient descent. \r\n    # This essentially just updates weights, like weights += grads * learning_rate\r\n    # using the partial derivative of the loss with respect to the\r\n    # weights. It's the direction we want to go to move toward lower error.\r\n    update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\r\n```\r\nI do think to update weights, you should use `weights := weights - grads * learning_rate`, I think using `+=` is not a right choice\r\n\r\nAnd another one is also in this section, you should use `bias_with_x` instead of `x_with_bias`\r\n\r\nThat's all.", "comments": ["Thank you very much for your feedback. Feel free to submit a pull request."]}, {"number": 14429, "title": "tensorflow.python.framework.errors_impl.NotFoundError:", "body": "I got this erros.\r\nI tried to convert csv to tfrecord with https://www.youtube.com/watch?v=kq2Gjv_pPe8\r\n\r\nkimvlvl@cmlabUbuntu:~/object-detection$ python3 generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=datacord\r\nTraceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 107, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"generate_tfrecord.py\", line 98, in main\r\n    tf_example = create_tf_example(group, path)\r\n  File \"generate_tfrecord.py\", line 53, in create_tf_example\r\n    encoded_jpg = fid.read()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py\", line 118, in read\r\n    self._preread_check()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py\", line 78, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_ostatus\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/kimvlvl/object-detection/images/0265.png\r\n\r\nI cheacked all the names and labels of xxx.png\r\n\r\nplease help", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14427, "title": "golang: ~2x speedup for encodeTensor()", "body": "This is duplicate of https://github.com/tensorflow/tensorflow/pull/14368, but now it can be merged safely because https://github.com/tensorflow/tensorflow/pull/14331 is merged.\r\n\r\nCC: https://github.com/tensorflow/tensorflow/pull/14408\r\n\r\nbefore:\r\n\r\n$ go test -bench=.\r\ngoos: linux\r\ngoarch: amd64\r\npkg: github.com/tensorflow/tensorflow/tensorflow/go\r\nBenchmarkNewTensor/[150528]-8                200           6792809 ns/op\r\nPASS\r\nok      github.com/tensorflow/tensorflow/tensorflow/go  2.116s\r\n\r\nafter:\r\n\r\n$ go test -bench=.\r\ngoos: linux\r\ngoarch: amd64\r\npkg: github.com/tensorflow/tensorflow/tensorflow/go\r\nBenchmarkNewTensor/[150528]-8                500           3269740 ns/op\r\nPASS\r\nok      github.com/tensorflow/tensorflow/tensorflow/go  2.021s\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "@asimshankar Yeah, this is great idea. I'll open a new pr for this one.", "Jenkins, test this please", "SUCCESS\n \n", "FAILURE\n \n", "That test failure seems un-related. Haven't dug in, but it seems that the continuous builds are passing beyond that point, so perhaps something fixed at head.", "Jenkins, test this please", "Jenkins, test this please."]}, {"number": 14426, "title": "Fix absl flag initialization in cloud_tpu_profiler", "body": "This fixes a regression caused by 2652704b576adc16b4d735f651cea1024e88b72e where the command would not run. See also: tensorflow/tensorboard#716\r\n\r\nThis is caused by the PIP generated program wrapper not invoking the `tf.app.run` that normally goes in the `if __main__` clause of a script. That runner basically initializes flags. But as far as I can tell, this is the only pip console script in TensorFlow that still uses flags. The other two appear to have migrated to argparse. So this change should be sufficient.\r\n\r\nCC: @nfelt @PrashantJalan @yifeif ", "comments": ["Jenkins, test this please", "@tensorflow-jenkins test this please"]}, {"number": 14424, "title": "Fix typo <Copybara Experiment DO NOT MERGE>", "body": "Fix typo in tensorflow/python/framework/function.py", "comments": []}, {"number": 14423, "title": "Using newer NVIDIA drivers causes TF to freeze the entire system if terminated", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.3 LTS (Xenial Xerus)\"\r\n- **TensorFlow installed from (source or binary)**: Binary, through `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: 1.3.0, Git Version - `v1.3.0-rc2-20-g0787eee`\r\n- **Python version**: 2.7.13\r\n- **CUDA/cuDNN version**: CUDA - 8.0.61, cuDNN - 6\r\n- **GPU model and memory**: GeForce GTX 950M, 2GB\r\n\r\n### Describe the problem\r\nI had changed my NVIDIA driver version to 387.12 some time ago. After that, sometimes when I'd terminate TF code (either with `^C` in terminal or closing IPython tab in Spyder) it would successfully terminate with `KeyBoardInterrupt`. However the other times when I'd terminate, my entire computer would freeze and become unresponsive. Couldn't use `Ctrl + Alt + F1` to login into a virtual console and kill the process as keyboard also became unresponsive. However, if I was playing music through Spotify, it would continue playing without any interruption. \r\nThis would happen with different files, not one specific file. But I noticed it would usually happen during the run of `sess.run(tf.global_variables_initializer())` in any of the files. It also has happened some other times like - \r\n - Training completed in Spyder console and Python was idle and I closed the console tab in Spyder\r\n - Training completed in Spyder IPython tab and another file was run in terminal. I closed the IPython tab (which was idle) in Spyder when the new TF session in the terminal was initializing variables and then my computer froze completely. \r\n\r\nI don't think the contents of the code mattered. It would still freeze even if all my code did was define a variable and then initialize it.\r\nSo I tried reverting back to NVIDIA 384.98 to see if anything changed but it was still freezing. Now I've reverted back to NVIDIA 381.22 and I've tried terminating TF when it is initializing variables and so far the freezing hasn't happened. \r\n\r\nAnother thing I'd noticed after changing to NVIDIA 387 is that `tf.global_variables_initializer()` became very slow, always taking 10+ seconds. I found #7755 where I saw it could be because of CUDA generating PTX. So I tried calling the init a second time in the same session and it would run in milliseconds. Same for calling init on CPU. I understand the init can be slow when run on GPU, however I never noticed it running slow prior to when I changed to a newer NVIDIA driver. Even after the revert to 381, it still runs slow. \r\n\r\n\r\n### Source code / logs\r\nI'd really like to know what I can log and how to do that. I'm not sure if I can use gdb as my computer becomes unresponsive so I have no way of going into a terminal. \r\nBelow is the sample code I would run and terminate during init to see if computer froze.\r\n```\r\nimport tensorflow as tf\r\ninitial = tf.Variable(tf.truncated_normal([1,3], stddev=0.01, seed=1))\r\nsess = tf.Session()\r\nprint \"Starting initialization\"\r\nsess.run(tf.global_variables_initializer())\r\n```\r\n", "comments": ["@poxvoculi, can you take a look at this?", "This sounds like an NVIDIA problem, not TF.  I see several complaints about freezing related to the 387 driver on the web, for other applications.  @zheng-xq is most likely to know about the current recommendation for drivers to use with TF.", "Adding @benbarsdell and @nluehr ", "I have not been able to reproduce system hangs using the 387.12 driver on Ubuntu 16.04.\r\n\r\nThe slow initialization is indeed likely the driver JIT compiling PTX for your GPU's specific architecture.  On my system, this takes between 90 and 105 seconds and results in a cache size of ~116MB. During the jit, Ctrl-C waits for the jit to complete before exiting, but killing the jitting process from another terminal terminates the jit immediately.\r\n\r\nAfter the first run caches the tensorflow binaries, subsequent runs of the 'global_variable_initializer' test provided above runs in ~1.9 seconds.\r\n\r\nRe-Jitting is required after the driver is reinstalled. Also, if the JIT cache is too small, the JIT will be repeated on every run. You can set the jit cache size to 1GB by setting `export CUDA_CACHE_MAXSIZE=$((1024*1024*1024))`.\r\n\r\nI wouldn't expect it to make a significant improvement for a single 950M, but putting the driver into persistence mode with `nvidia-smi -pm 1` can also reduce CUDA initialization time.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing due to lack of activity.", "Same problem here (sometimes when I terminate script that uses TensorFlow, my entire computer freezes and becomes unresponsive), please reopen:\r\n\r\n**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** Yes\r\nOS Platform and Distribution: Ubuntu 18.04.1 LTS\r\n**TensorFlow installed from (source or binary):** Binary, through pip install tensorflow-gpu\r\n**TensorFlow version:** v1.10.1-0-g4dcfddc5d1 1.10.1\r\n**Python version:** 3.6.5\r\n**CUDA/cuDNN version:**  CUDA Version 9.0.176, cuDNN - 7.2.1\r\n**GPU model and memory:** GeForce GTX 970, 4GB\r\n**Nvidia driver:** Driver Version: 390.87\r\n\r\n"]}, {"number": 14422, "title": "Add the C++ gradient of the Prod operation.", "body": "This PR adds the gradient of the Prod operation to the C++ API.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@alextp @drpngx Any news regarding this PR?", "Jenkins, test this please.", "@tensorflow-jenkins test this please", "I merged with master in order to resolve conflicts. It's been more than a month since this PR has been submitted...", "Thank you @theflofly. Once the tests pass, we can merge the PR asap!", "@tensorflow-jenkins test this please", "Thanks @yifeif !"]}, {"number": 14421, "title": "[iOS] Add optional Selective Registration of Ops", "body": "The current iOS library is huge. Add the ability to selectively\r\nregister for the ops the tensorflow library will support. This\r\ngreatly reduces resultant binary based on the network.\r\n\r\nA \"full\" arm64 build was 122MB on my machine vs one selectively\r\nregistered for SSD Mobilenet was only 93MB.\r\n\r\nAlso fixes a minor bug where the selected arch wasn't being passed\r\nto the compile_ios_protobuf.sh script.\r\n\r\nTEST:build_all_ios.sh -a arm64 # generates a fat binary for arm64\r\n     build_all_ios_sh -a arm64 -g ~/Downloads/op_inference_graph.pb\r\n        #generates a binary that is much smaller", "comments": ["Can one of the admins verify this patch?", "cc @petewarden @martinwicke . Please review. Thanks", "@petewarden do you have any guidance on this change ? Thanks", "@jhseu any thoughts on this PR? Thanks", "@petewarden any thoughts on this change? Can you please help review? Thanks", "@aselle have a moment to review this change?", "@aselle any thoughts on this ? ", "Also adding @yifeif to see if he can find someone to review this. ", "@petewarden should be the right person if he has cycles.", "Jenkins, test this please.", "@gunan @drpngx can we please merge this ? Thx", "Thanks for pinging @powderluv ! Merged, woohoo!", "@powderluv I want to thank you for this, from the bottom of my heart. If you'd made this 6 months earlier you would have saved my team a lot of aimlessly banging our heads against walls trying to figure out build issues.  :)\r\nSo happy about this.", "Glad I could help. I did post the pull request four months ago :). We have a few more iOS build and performance improvements upcoming", "@powderluv just found a minor bug: if building `print_selective_registration_header` is necessary, it's not used until the next time you run `build_all_ios.sh` - it's only executed if it already existed (see line 83 in this PR is inside the enclosing `else`). Very minor change to fix. Would you like me to submit a PR, or take care of it yourself?", "Please submit the PR. Take the middle man out :). Thanks for fixing"]}, {"number": 14420, "title": "Fix allow_smaller_final_batches for bucket_by_sequence_length.", "body": "Fixes #8182 ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@martinwicke i think this is fine; but we'll want to run the test 1000x in opt mode.", "Jenkins, test this please", "Any updates here? Is there something I need to fix?", "@tensorflow-jenkins test this please.", "I patched this internally and ran it.  Looks stable:\r\n\r\ntensorflow/contrib/training:bucket_ops_test                PASSED in 84.3s\r\n  Stats over 1000 runs: max = 84.3s, min = 4.6s, avg = 28.3s, dev = 28.7s\r\ntensorflow/contrib/training:sequence_queueing_state_saver_test PASSED in 54.6s\r\n  Stats over 1000 runs: max = 54.6s, min = 12.2s, avg = 24.8s, dev = 7.0s\r\n\r\n"]}, {"number": 14419, "title": "Replace the docker check with an OS check.", "body": "PiperOrigin-RevId: 174057778", "comments": []}]