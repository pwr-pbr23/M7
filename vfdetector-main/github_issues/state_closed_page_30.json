[{"number": 54549, "title": "Append the path when the metadata was not found to the error message for easier debugging.", "body": "Append the path when the metadata was not found to the error message for easier debugging.\n", "comments": []}, {"number": 54548, "title": "Delete another ancient Dockerfile", "body": "This is intended to be another test of the new GitHub targeting presubmits.", "comments": []}, {"number": 54547, "title": "Remove java-related flags from .bazelrc that are ignored by Bazel 5.", "body": null, "comments": []}, {"number": 54546, "title": "Export current optimizer to legacy namespace. ", "body": "Export current optimizer to legacy namespace. \n\nA new-version optimizer is going to be available in TF 2.9 release. Although the new optimizer is now under experimental namespace, it will in future become the default optimizer. For backward compatibility, we will continue support the current optimizer in the legacy namespace.\n", "comments": []}, {"number": 54545, "title": "Bug in `tf.math.acos`: `string` input is not supported", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/math/acos?hl=en\r\n\r\n## Description of issue (what needs changing):\r\n### Parameters defined\r\nDoc says `x` must be one of the following types: bfloat16, half, ..., **string**, but obviously the input to `tf.math.acos` cannot be a `string` Tensor.\r\n\r\n", "comments": ["@ArrowIntoTheSky ,\r\nCan you please share a reproducible code that supports your statement so that the issue can be easily understood? Thanks!"]}, {"number": 54544, "title": "Deallocate TPU embedding enqueue Tensors", "body": "Deallocate TPU embedding enqueue Tensors\n", "comments": []}, {"number": 54543, "title": "Create `xla_gpu_nccl_termination_timeout_seconds` debug flag to terminate from WaitAndLogIfStuck in nccl_utils.", "body": "Create `xla_gpu_nccl_termination_timeout_seconds` debug flag to terminate from WaitAndLogIfStuck in nccl_utils.\n", "comments": []}, {"number": 54542, "title": "[NNAPI] update the NnapiDelegateVendorPlugin::MapNode() to take mutable TfLiteContext", "body": "[NNAPI] update the NnapiDelegateVendorPlugin::MapNode() to take mutable TfLiteContext\n", "comments": []}, {"number": 54541, "title": "Create a custom Spec for DynamicRaggedShape. This involves making functions in DynamicRaggedShape work for the spec too, e.g. functions such as _dimension.", "body": "Create a custom Spec for DynamicRaggedShape. This involves making functions in DynamicRaggedShape work for the spec too, e.g. functions such as _dimension.\n", "comments": []}, {"number": 54540, "title": "InaccessibleTensorError when running model as a .expand_dims call in the main model code", "body": "**System information** \r\nI have written a custom model in TensorFlow as a modification of the transformer model.\r\nM1 Pro 32 GB Macbook Pro 12.1 Monterey(also ran on colab T4 GPU 16 GB)\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.7.1 also tried 2.8\r\n- Python version: 3.7.1.2\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: 32 GB M1 PRO,  Tesla T4 16 GB\r\n\r\n**Describe the current behavior**\r\nCurrent when I run my model in eager execution model it is fine, but when I run it with @tf.function wrapper I get an inaccessible tensor error when building the AutoGraph. This is coming in the model call method, when I .expand_dims on the call of another layer class. The error is:\r\n\r\n```\r\nTypeError: <tf.Tensor 'hi_d_transformer/ExpandDims:0' shape=(64, 1, 64) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\r\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\r\n\r\n<tf.Tensor 'hi_d_transformer/ExpandDims:0' shape=(64, 1, 64) dtype=float32> was defined here:\r\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n      \"__main__\", mod_spec)\r\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\r\n      exec(code, run_globals)\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\r\n      app.launch_new_instance()\r\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\r\n      app.start()\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\r\n      self.io_loop.start()\r\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\r\n      self.asyncio_loop.run_forever()\r\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\r\n      self._run_once()\r\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\r\n      handle._run()\r\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\r\n      self._context.run(self._callback, *self._args)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\r\n      handler_func(fileobj, events)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\r\n      return fn(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\r\n      self._handle_recv()\r\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\r\n      self._run_callback(callback, msg)\r\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\r\n      callback(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\r\n      return fn(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n      return self.dispatch_shell(stream, msg)\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\r\n      handler(stream, idents, msg)\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n      user_expressions, allow_stdin)\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\r\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\r\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n      interactivity=interactivity, compiler=compiler, result=result)\r\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n      if self.run_code(code, result):\r\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n      exec(code_obj, self.user_global_ns, self.user_ns)\r\n    File \"<ipython-input-32-1bb5ee661811>\", line 13, in <module>\r\n      train_step(inp, tar)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\r\n      result = self._call(*args, **kwds)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 963, in _call\r\n      self._initialize(args, kwds, add_initializers_to=initializers)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 786, in _initialize\r\n      *args, **kwds))\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2983, in _get_concrete_function_internal_garbage_collected\r\n      graph_function, _ = self._maybe_define_function(args, kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3292, in _maybe_define_function\r\n      graph_function = self._create_graph_function(args, kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3140, in _create_graph_function\r\n      capture_by_value=self._capture_by_value),\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1161, in func_graph_from_py_func\r\n      func_outputs = python_func(*func_args, **func_kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 677, in wrapped_fn\r\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1143, in autograph_handler\r\n      user_requested=True,\r\n    File \"<ipython-input-20-949802b44a4a>\", line 5, in train_step\r\n      predictions,_ = transformer([inp, tar],\r\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\r\n      outputs = call_fn(inputs, *args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"<ipython-input-14-ac60aac10b0e>\", line 131, in call\r\n      if self.scvs == None:\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1321, in if_stmt\r\n      _py_if_stmt(cond, body, orelse)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1374, in _py_if_stmt\r\n      return body() if cond else orelse()\r\n    File \"<ipython-input-14-ac60aac10b0e>\", line 133, in call\r\n      scvs = tf.expand_dims(scvs, axis=1)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\r\n      return dispatch_target(*args, **kwargs)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 435, in expand_dims_v2\r\n      return gen_array_ops.expand_dims(input, axis, name)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2354, in expand_dims\r\n      \"ExpandDims\", input=input, dim=axis, name=name)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 742, in _apply_op_helper\r\n      attrs=attr_protos, op_def=op_def)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 695, in _create_op_internal\r\n      compute_device)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3784, in _create_op_internal\r\n      op_def=op_def)\r\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\r\n      self._traceback = tf_stack.extract_stack_for_node(self._c_op)\r\n\r\nThe tensor <tf.Tensor 'hi_d_transformer/ExpandDims:0' shape=(64, 1, 64) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=train_step, id=140104354578128), which is out of scope.\r\n```\r\n\r\nI expect the model to compile, I have tried to move the tf.expand_dims to other layers/subclasses and still get the same bug no matter where. I guess this could be rooted from somewhere else as well but I cannot understand the error.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nReproducible test case can be found here:  https://colab.research.google.com/gist/ae20cg/fe1577f53f6e68db1e3429643f1e957a/tft2tf2-graph.ipynb\r\n\r\n", "comments": ["Hi @ae20cg ! I was able to replicate in 2.7 and 2.8 , But Can you try again after changing empty lists to Tensor arrays ? Attaching relevant threads for reference. R [1](https://stackoverflow.com/questions/69670184/tensor-cannot-be-accessed-present-in-another-function-or-code-block) [2](https://stackoverflow.com/questions/70079385/inaccessibletensorerror-when-using-tf-keras-layers-layer-output-in-loop-cond). Thank you!", "@mohantym \r\n\r\nSince the argument that is causing the code to fail is 'optional', I removed it and the code runs is able to run train. And the tensor that is causing an error does not come from a list.\r\n\r\nI have updated the code to get rid of the empty lists, still the same error.", "I have fixed this issue. \r\n\r\nFor those this may apply to. This tensor was being called by another layer in the `call` method. This tensor was then being passed to another layer, however rather than calling it through the `call` method I was passing it in in initialization.\r\n\r\nI changed said method to accept the tensor in the `call` argument and it fixed the code. \r\n\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54540\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54540\">No</a>\n"]}, {"number": 54539, "title": "Remove more OSS embedding tests", "body": "Remove more OSS embedding tests\n", "comments": []}, {"number": 54538, "title": "Remove cuda_py_tests and gpu_py_tests.", "body": "Remove cuda_py_tests and gpu_py_tests.\n\nUsers can switch to the direct expansion of cuda_py_tests into cuda_py_test. It is a bit laboring but these are BUILD files anyway.\n\nThe impact for removal of gpu_py_tests is likely very small. A search on github showed 250 results. I scanned a few pages (~10) and they are all forks of tensorflow org projects.\n", "comments": []}, {"number": 54537, "title": "[tf:tfrt] Guard transpose codegen under a flag", "body": "[tf:tfrt] Guard transpose codegen under a flag\n\nThe transpose code generation strategy generates AVX2-specific assembly\nwhich may fail to run if the CPU doesn't have support for AVX2. Guarding\nthe transpose code generation strategy under a flag until we implement the\nproper solution to this problem. This will prevent the fuzzer from finding\nfalse positives when using a non-AVX2 CPU.\n", "comments": []}, {"number": 54536, "title": "Fix bug with loading checkpoints with the `root` arg and attached dependencies.", "body": "Fix bug with loading checkpoints with the `root` arg and attached dependencies.\n", "comments": []}, {"number": 54535, "title": "Moving NonMaxSuppressionV3 kernel to old bridge. MLIR canonicalization doesn't work b/c of lack of Dynamic Padder support in MLIR bridge.", "body": "Moving NonMaxSuppressionV3 kernel to old bridge. MLIR canonicalization doesn't work b/c of lack of Dynamic Padder support in MLIR bridge.\n", "comments": []}, {"number": 54534, "title": "Turn on merge control flow pass through introducing a new algorithm of the pass.", "body": "Turn on merge control flow pass through introducing a new algorithm of the pass.\n", "comments": []}, {"number": 54533, "title": "[NNAPI] Allow running dynamic shape models with vendor plugin", "body": "[NNAPI] Allow running dynamic shape models with vendor plugin\n", "comments": []}, {"number": 54532, "title": "tape.gradient returns None when assign is used in a model for computation of a function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Springdale\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.8.9\r\n- Python version: 3.7.10+\r\n\r\n\r\n**Describe the current behavior**\r\nWhen a function is calculated based on a weight of a model the gradient can't trace the connection and returns None. More precisely I am trying to define a log_posterior from a model that has multiple weights (a shallow neural network, if you will). But Hamiltonian Monte Carlo does not work because my defined log_posterior does not have a gradient.\r\n\r\n\r\n**Describe the expected behavior**\r\nTF should return the gradient of the log_posterior function defined.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n In the example below tape.gradient should return the value of w as the gradient. Here DummyModel's call supposed to replicate a log_postrior function, where I reassign its parameter \"w\" with \"x\". \r\n\r\n```\r\n>>> import tensorflow as tf\r\n>>> class DummyModel(tf.keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        pass\r\n    def build(self, input_shape):\r\n        self.w = self.add_weight('w', shape=(), dtype=tf.float64, initializer=lambda x, dtype:tf.constant(10., dtype=tf.float64))\r\n    def call(self, X):\r\n        return tf.cast(X, tf.float64) * self.w\r\n... \r\n>>> a = DummyModel()\r\n>>> print(\"the output of DummyModel for X=1:\", a(1.))\r\nthe output of DummyModel for X=1: tf.Tensor(10.0, shape=(), dtype=float64)\r\n>>> x = tf.Variable(3., dtype=tf.float64)\r\n>>> with tf.GradientTape() as tape:\r\n    tape.watch([x, a.w])\r\n    a.w.assign(x)\r\n    out = a(15.)\r\n... \r\n<tf.Variable 'UnreadVariable' shape=() dtype=float64, numpy=3.0>\r\n>>> print(tape.gradient(out, x))\r\nNone\r\n\r\n```\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54532\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54532\">No</a>\n"]}, {"number": 54531, "title": "Enable kernel fallback lowering for GPU.", "body": "Enable kernel fallback lowering for GPU.\n", "comments": []}, {"number": 54530, "title": "Add dtensor to the build tree of TensorFlow.", "body": "Add dtensor to the build tree of TensorFlow.\n", "comments": []}, {"number": 54529, "title": "[NNAPI] Allow reusable execution with dynamic shape", "body": "[NNAPI] Allow reusable execution with dynamic shape\n", "comments": []}, {"number": 54528, "title": "Enables macOS and Windows presubmits.", "body": "Enables macOS and Windows presubmits.\n", "comments": []}, {"number": 54527, "title": "Migrates to built-in `cc_shared_library`.", "body": "Migrates to built-in `cc_shared_library`.\n\nReplaces dependence on the @rules_cc version of `cc_shared_library` with the Bazel built-in one.\n", "comments": []}, {"number": 54526, "title": "[lite] Optimize reduce all dims use case when the number of elements is small. Parallelizing overhead might be huge.", "body": "[lite] Optimize reduce all dims use case when the number of elements is small. Parallelizing overhead might be huge.\n", "comments": []}, {"number": 54525, "title": "This CL makes two changes to handle the potential pointer invalidation across", "body": "This CL makes two changes to handle the potential pointer invalidation across\nclearing protocol buffers:\n\n(1) Instead of caching a map field, always refer it from the containing proto.\n(2) Instantiate NodeMap instance after output_graph is fully initialized.\n", "comments": []}, {"number": 54524, "title": "Delete an ancient Dockerfile", "body": "Discard an ancient 14.04 Dockerfile, as a test of new code migration settings.", "comments": []}, {"number": 54523, "title": "Reduce flakyness of `//tensorflow/c/eager:c_api_test_cpu`.", "body": "Reduce flakyness of `//tensorflow/c/eager:c_api_test_cpu`.\n\nApplying a similar fix as before, just increasing length of backfill queue\n", "comments": []}, {"number": 54522, "title": "[PluggableDevice] Add `DEVICE_DEFAULT` registration for EnsureShape", "body": null, "comments": []}, {"number": 54521, "title": "[PluggableDevice] Add `DEVICE_DEFAULT` registrations for Inplace ops", "body": null, "comments": []}, {"number": 54520, "title": "Simplifies the error message thrown by sparse tensor", "body": "Currently, there is a long error message and little confusing as mentioned by users. This PR simplifies the error message to be more specific.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/50349\r\nhttps://github.com/tensorflow/tensorflow/issues/50078", "comments": ["Could you sign google CLA first https://opensource.google/documentation/reference/cla?", "@JXRiver I already signed CLA long back. Can you please check? Thanks!", "Oh, just noticed the CLA check has passed.", "Sure. I will close it. Thanks @JXRiver "]}]