[{"number": 54358, "title": "lite: Update tflite_runtime builds", "body": "Switch to Makefile method which is easy to maintain and less dependent to TensorFlow scripts.\r\n\r\nPiperOrigin-RevId: 427943932\r\nChange-Id: I0aff1caaf34a890566ad8a745e8a1d417828c20a", "comments": ["ping?"]}, {"number": 54356, "title": "Add complex support for `tf.math.asin`", "body": "This PR address the feature requested by #54317 in adding complex support for tf.math.asin.\r\n\r\nThis PR fixes #54317.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 54355, "title": "How to select GPU device via NNAPI\uff1f", "body": "How to choose gpu1 and gpu2 device if using embedded platform and two gpus deployed via tflite's nnapi\uff1f\ne.g. Dual GPU for embedded platform NXP i.MX8 QuadMax", "comments": ["@Hank880223 ,\r\nCan you please take a look at this link [1](https://stackoverflow.com/questions/40069883/how-to-set-specific-gpu-in-tensorflow),  [2](https://www.tensorflow.org/guide/gpu), [3](https://www.tensorflow.org/lite/performance/nnapi) which delivers the required information.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54355\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54355\">No</a>\n"]}, {"number": 54353, "title": "[v2.8.0]: Cross compiling libtensorflow.so for ARM64 fails", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.8.0\r\n- Python version: 3.8.8\r\n- Installed using virtualenv? pip? conda?: Building from source, cross-compiling for Raspberry Pi\r\n- Bazel version (if compiling from source): Automatically done by build script via docker container\r\n- GCC/Compiler version (if compiling from source): Automatically selected by build script via docker container\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am trying to cross-compile `libtensorflow.so` to use on ARM64, but the build is failing at several steps. More info below\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nAfter downloading code and checking out `v2.8.0`, I ran following command:\r\n```\r\ntensorflow/tools/ci_build/ci_build.sh PI \\\r\n    tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n```\r\nThis command fails due to python3.6 not being available in the docker container. To fix this issue, I installed python3.6 via following entries in the `Dockerfile` and a few other modifications as shown below. Without these modification the build would fail.\r\n```\r\n\u2514\u2500 $ \u25b6 git diff\r\ndiff --git a/tensorflow/tools/ci_build/Dockerfile.pi b/tensorflow/tools/ci_build/Dockerfile.pi\r\nindex 53589774291..8a021f3434e 100644\r\n--- a/tensorflow/tools/ci_build/Dockerfile.pi\r\n+++ b/tensorflow/tools/ci_build/Dockerfile.pi\r\n@@ -2,6 +2,20 @@ FROM ubuntu:14.04\r\n \r\n LABEL maintainer=\"Jan Prach <jendap@google.com>\"\r\n \r\n+# install python 3.6\r\n+RUN apt-get update\r\n+RUN apt-get install build-essential libpq-dev libssl-dev openssl libffi-dev zlib1g-dev -y\r\n+RUN apt-get install python3-pip python3-dev -y\r\n+RUN apt install software-properties-common -y\r\n+RUN apt-get install wget -y\r\n+RUN wget https://www.python.org/ftp/python/3.6.3/Python-3.6.3.tgz\r\n+RUN tar -xvf Python-3.6.3.tgz\r\n+WORKDIR /Python-3.6.3\r\n+RUN ./configure --enable-optimizations\r\n+RUN make -j8\r\n+RUN make install\r\n+WORKDIR /\r\n+\r\n # Copy and run the install scripts.\r\n COPY install/*.sh /install/\r\n RUN /install/install_bootstrap_deb_packages.sh\r\ndiff --git a/tensorflow/tools/ci_build/install/install_auditwheel.sh b/tensorflow/tools/ci_build/install/install_auditwheel.sh\r\nindex c84bdf4e2ec..55e9f297f06 100755\r\n--- a/tensorflow/tools/ci_build/install/install_auditwheel.sh\r\n+++ b/tensorflow/tools/ci_build/install/install_auditwheel.sh\r\n@@ -27,7 +27,7 @@ patchelf_location=$(which patchelf)\r\n if [[ -z \"$patchelf_location\" ]]; then\r\n   set -e\r\n   # Install patchelf from source (it does not come with trusty package)\r\n-  wget https://nixos.org/releases/patchelf/patchelf-0.9/patchelf-0.9.tar.bz2\r\n+  wget --no-check-certificate https://nixos.org/releases/patchelf/patchelf-0.9/patchelf-0.9.tar.bz2\r\n   tar xfa patchelf-0.9.tar.bz2\r\n   cd patchelf-0.9\r\n   ./configure --prefix=/usr/local\r\ndiff --git a/tensorflow/tools/ci_build/install/install_pip_packages.sh b/tensorflow/tools/ci_build/install/install_pip_packages.sh\r\nindex 18e0bf73d3a..305a8c28760 100755\r\n--- a/tensorflow/tools/ci_build/install/install_pip_packages.sh\r\n+++ b/tensorflow/tools/ci_build/install/install_pip_packages.sh\r\n@@ -17,7 +17,8 @@\r\n set -e\r\n \r\n # Get the latest version of pip so it recognize manylinux2010\r\n-wget https://bootstrap.pypa.io/get-pip.py\r\n+#wget https://bootstrap.pypa.io/get-pip.py\r\n+wget https://bootstrap.pypa.io/pip/3.6/get-pip.py\r\n python3.6 get-pip.py\r\n rm -f get-pip.py\r\n```\r\n\r\nAt this point the build proceeds up to a point where it starts to compile tensorflow code. However, I ran into following issues:\r\n```\r\nINFO: Repository aarch64_compiler instantiated at:\r\n  /workspace/WORKSPACE:15:14: in <toplevel>\r\n  /workspace/tensorflow/workspace2.bzl:888:21: in workspace\r\n  /workspace/tensorflow/workspace2.bzl:208:20: in _tf_repositories\r\n  /workspace/third_party/repo.bzl:128:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /workspace/third_party/repo.bzl:81:35: in <toplevel>\r\nERROR: /workspace/tensorflow/core/util/BUILD:379:24: //tensorflow/core/util:version_info_gen depends on @local_config_git//:gen/spec.json in repository @local_config_git which failed to fetch. no such package '@local_config_git//': Git Configuration Error: Traceback (most recent call last):\r\n  File \"/home/sdeoras/Downloads/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_sdeoras/eab0d61a99b6696edb3d2aff87b585e8/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 28, in <module>\r\n    from builtins import bytes  # pylint: disable=redefined-builtin\r\nImportError: No module named builtins\r\n\r\nERROR: /workspace/tensorflow/core/util/BUILD:379:24: //tensorflow/core/util:version_info_gen depends on @local_config_git//:gen/head in repository @local_config_git which failed to fetch. no such package '@local_config_git//': Git Configuration Error: Traceback (most recent call last):\r\n  File \"/home/sdeoras/Downloads/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_sdeoras/eab0d61a99b6696edb3d2aff87b585e8/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 28, in <module>\r\n    from builtins import bytes  # pylint: disable=redefined-builtin\r\nImportError: No module named builtins\r\n\r\nERROR: /workspace/tensorflow/core/util/BUILD:379:24: //tensorflow/core/util:version_info_gen depends on @local_config_git//:gen/branch_ref in repository @local_config_git which failed to fetch. no such package '@local_config_git//': Git Configuration Error: Traceback (most recent call last):\r\n  File \"/home/sdeoras/Downloads/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_sdeoras/eab0d61a99b6696edb3d2aff87b585e8/external/org_tensorflow/tensorflow/tools/git/gen_git_source.py\", line 28, in <module>\r\n    from builtins import bytes  # pylint: disable=redefined-builtin\r\nImportError: No module named builtins\r\n\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 74.009s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (375 packages loaded, 10502 targets configured)\r\nFAILED: Build did NOT complete successfully (375 packages loaded, 10502 targets configured)\r\n```\r\n\r\nAny recommendations on what to do to be able to build `libtensorflow.so` for ARM64? Alternatively, if a pre-compiled library file exists what is a download location link? Also should I be building a previous version, if so, which one?\r\n\r\n\r\n", "comments": ["Hi @sdeoras ! Can you check these two threads on installing TFLite on ARM64 boards? Link[ 1](https://www.tensorflow.org/lite/guide/build_arm), [2](https://github.com/PINTO0309/Tensorflow-bin#usage). Thanks!", "hi @mohantym , i won't be able to use TFLite since i am using Go bindings that require `libtensorflow.so`. What is the best way to build? It would be super awesome if TensorFlow team can start to provide download links for precompiled C libraries for ARM64 :) ", "hi folks, any updates or possible workarounds for this one? thanks.", "hi folks, i was able to build c-lib using bazel. we can close this bug if needed. thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54353\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54353\">No</a>\n"]}, {"number": 54351, "title": "Reintegrate tensorflow/toolchains", "body": "Removing the tensorflow/toolchains repository has these benefits:\r\n\r\n- Speed up toolchain and RBE changes: with the repo, every toolchains adjustment requires a PR, a Release, a mirror upload, and another PR = ~hours of busywork. Without the repo, it's one PR. We wouldn't have to automate anything.\r\n- Reduce confusion about toolchains: the toolchains repository, except for the toolchains subdirectory which has been migrated here, is mostly unused junk that attempts to replicate TensorFlow's WORKSPACE setup to make the toolchains functional without TF. That isn't true; tensorflow/toolchains does not actually work if you try to bazel build anything because the WORKSPACE is broken.\r\n- Remove the maintenance burden of the toolchains repo: one less repository for us to worry about.\r\n- Remove coupling: tensorflow/toolchains and tensorflow/tensorflow are heavily coupled, i.e. they depend on each other.\r\n\r\nAnd these downsides:\r\n\r\n- Obligation to notify / fix downstream users: I haven't found any direct users for @tf_toolchains, but a few projects do use our toolchains. They usually use a WORKSPACE that pulls the entirety of TensorFlow. It's our responsibility to notify anyone who indirectly uses our toolchains to tell them that they may need to adjust their workflows.\r\n- Loss of toolchain history: we can't retain history across repositories, so all previous changes to the directory would be lost. I don't think we have a choice, and this isn't enough of a reason to keep it as a separate repo.\r\n- Loss of any benefits of the separate repository: the original goal of a _separate repository_ to \"enable reuse of all of [TF's toolchains] across TFRT, custom ops, and main TensorFlow.\" Considering that TFRT does not use these toolchains and that the custom op repository is unsupported, this goal has failed and there is no loss in re-integrating.\r\n\r\nThis PR is a demonstration of what little work is required to re-integrate the tensorflow/toolchains repository back under TensorFlow. The only changes I've made have been:\r\n\r\n- Move tensorflow/toolchains://toolchains back into //tensorflow/tools/toolchains\r\n- Update `@tf_toolchains` paths to match new locations\r\n- Remove the external WORKSPACE dependency and other unused files \r\n\r\nI was able to build TensorFlow successfully this way. Have I missed anything?\r\n\r\n@mihaimaruseac @learning-to-play\r\n", "comments": ["Trying to clean up those extra commits...", "Ubuntu Sanity has correctly noticed some formatting / broken-BUILD problems that I'll get around to fixing after discussing this more.", "Maybe add an item under 'downsides' that explains the motivation for splitting out the toolchains into a separate repository? Unfortunately, I don't remember what we tried to achieve. Maybe we wanted tensorflow/runtime to depend on it as well?", "> Maybe we wanted tensorflow/runtime to depend on it as well?\r\n\r\nThat appears to be the case based on the original proposal (internal-only link: http://go/tf-toolchains). TFRT doesn't reference tensorflow/toolchains at all in their repository, though, so I'm not sure if there are really any reasons left to keep it as-is."]}, {"number": 54350, "title": "[ROCm] Switch Dockerfile.rocm to use ROCm 5.0.0", "body": "/cc @cheshire @chsigg ", "comments": []}, {"number": 54349, "title": "Error with \"tf.keras.layers.Normalization\" when using multiple GPU devices", "body": "**System information**\r\nTensorflow 2.7.0 (gpu)\r\nPython 3.8\r\nLinux ubuntu.\r\n### Context:\r\nI am trying to use a normalization layer as demonstrated in load model code below:\r\nThe code works normally as expected when removing ```the tf.keras.layers.Normalization``` layer and keeping the Rescaling layer. Therefore i would discard any problem related to input pipeline, tfrecord parsing, incorrect label format, etc...  ***The error occurs at the end of the epoch at validation inference.***\r\n\r\n# Edit: \r\nI found out that the problem is related to running in multiple gpu devices. \r\nI created this [gist](https://colab.research.google.com/drive/1-6POGaRSpMhTu5gPO2XC_mtLil7eYXa6?usp=sharing) in order to test tensorflow/python versions and everything ran normally. I have even installed the exact same python version (3.8.10) to verify whether it would be the case but worked with no errors. Then, back in the original enviroment I've limited the number of gpu devices to 1 and the code ran normally.\r\n\r\n[tfrecords](https://drive.google.com/drive/folders/1iwmkIV93KAwTh3ML0ghcy0tn8u3Ny1wH?usp=sharing) for reproducing.\r\n\r\n### Code: \r\n```Python\r\ndef load_and_configure_model(optimizer, loss, metrics, path):\r\n  model = ResNet50V2(include_top=True, weights='imagenet')\r\n  transfer_layer = model.get_layer('avg_pool')\r\n  resnet_submodel = Model(inputs=model.input,outputs=transfer_layer.output)\r\n  model_config = resnet_submodel.get_config()\r\n  \r\n  submodel = model_config['layers']\r\n  submodel.remove(submodel[0]) # Remove the previous input layer\r\n  \r\n  input_layer = keras.Input(shape=(224, 224, 3), dtype='float32',name=\"input\") # Create a new input layer\r\n  normalization = tf.keras.layers.Normalization(mean=[118.662, 119.194, 96.877], variance=[2769.232, 2633.742, 2702.492], axis=-1, dtype='float32')(input_layer)\r\n  rescaling = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1, dtype='float32')(normalization)  \r\n  \r\n  new_model = Model(inputs=input_layer,outputs=rescaling) # Declare pre-processing model to be merged with the ResNet model.\r\n  new_model_cfg = new_model.get_config() \r\n      \r\n  new_model_cfg['layers'].extend(submodel) # Merge two models.\r\n\r\n  # Replace the previous input layer with the output from the preprocessing model\r\n  # (Connect the preprocessing model to the resnet) \r\n  output_name = new_model_cfg['layers'][2]['name'] # Get the output layer name (rescaling).\r\n  \r\n  new_model_cfg['layers'][3]['inbound_nodes'] = [[[output_name, 0, 0, {}]]] # Replace last inbound node name with the preprocessing model layer name.  \r\n  \r\n  new_model = new_model.__class__.from_config(new_model_cfg, custom_objects={})  # change custom objects if necessary\r\n\r\n  # Set back pre-trained weights on new model\r\n  weights = [layer.get_weights() for layer in resnet_submodel.layers[1:]] # For each layer (after the input_layer) in the original resnet50:\r\n  for layer, weight in zip(new_model.layers[3:], weights): # Set imagenet weights on each new model layer.\r\n      layer.set_weights(weight)\r\n\r\n  for layer in new_model.layers[:]:\r\n    layer.trainable = False\r\n  for layer in new_model.layers[:]:      \r\n    trainable = True\r\n    layer.trainable = trainable # Train everything. \r\n\r\n  transfer_layer = new_model.get_layer('avg_pool')\r\n  #dropout = tf.keras.layers.Dropout(rate=0.3)(transfer_layer.output)\r\n  species = Dense(1000, activation='softmax', dtype='float32',name='species')(transfer_layer.output) # Specify dtype for handling mixed precision specifications.\r\n\r\n  model = keras.Model(\r\n      inputs=[new_model.inputs],\r\n      outputs=[species],\r\n  )\r\n  if not path == None :\r\n    model.load_weights(path)\r\n  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n  return model\r\n```\r\n\r\n\r\n\r\nobs: the same normalization/scaling pipeline works just fine and as expected when creating a model cosisting of these two layers only as exemplified below:\r\n\r\n```Python\r\nnormalization = tf.keras.layers.Normalization(mean=[118.662, 119.194, 96.877], variance=[2769.232, 2633.742, 2702.492], axis=-1)(input_layer)\r\n\r\nrescaling = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)(normalization)\r\nmodel_2 = Model(inputs=input_layer,outputs=rescaling)\r\n\r\npred = model_2.predict(img)\r\npred = tf.cast(pred, tf.uint8)\r\npred = tf.squeeze(pred,axis=0)\r\npred = tf.io.encode_jpeg(pred)\r\n\r\nfname = tf.constant('norm_then_scale.jpg')\r\nfwrite = tf.io.write_file(fname, pred)\r\n\r\n\r\n```\r\n\r\n### Traceback:\r\n```\r\nEpoch 1/70\r\n2022-02-11 17:12:35.280711: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8302\r\n2022-02-11 17:12:35.671694: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8302\r\n2022-02-11 17:12:37.630704: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n 95/100 [===========================>..] - ETA: 2s - loss: 6.9175 - categori2022-02-11 17:13:46.316950: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: required broadcastable shapes\r\nTraceback (most recent call last):\r\n  File \"flat_resnet50.py\", line 263, in <module>\r\n    history = train_model(train_path, validation_path, epochs, steps_per_epoch, resnet_50V2)\r\n  File \"flat_resnet50.py\", line 82, in train_model\r\n    history = model.fit(x=train_dataset,\r\n  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 58, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.\r\n  (0) INVALID_ARGUMENT:  required broadcastable shapes\r\n\t [[node replica_1/model_2/normalization/sub\r\n (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py:257)\r\n]]\r\n\t [[div_no_nan/ReadVariableOp_1/_62]]\r\n  (1) INVALID_ARGUMENT:  required broadcastable shapes\r\n\t [[node replica_1/model_2/normalization/sub\r\n (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py:257)\r\n]]\r\n\t [[div_no_nan/AddN/_76]]\r\n  (2) INVALID_ARGUMENT:  required broadcastable shapes\r\n\t [[node replica_1/model_2/normalization/sub\r\n (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py:257)\r\n]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_test_function_65650]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node replica_1/model_2/normalization/sub:\r\nIn[0] cond/Identity_1 (defined at /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1355)\t\r\nIn[1] model_2/normalization/sub/y:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1349, in run_step\r\n>>>     outputs = model.test_step(data)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1303, in test_step\r\n>>>     y_pred = self(x, training=False)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\r\n>>>     return self._run_internal_graph(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py\", line 257, in call\r\n>>>     return ((inputs - self.mean) /\r\n>>> \r\n\r\nInput Source operations connected to node replica_1/model_2/normalization/sub:\r\nIn[0] cond/Identity_1 (defined at /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1355)\t\r\nIn[1] model_2/normalization/sub/y:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1349, in run_step\r\n>>>     outputs = model.test_step(data)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1303, in test_step\r\n>>>     y_pred = self(x, training=False)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\r\n>>>     return self._run_internal_graph(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py\", line 257, in call\r\n>>>     return ((inputs - self.mean) /\r\n>>> \r\n\r\nInput Source operations connected to node replica_1/model_2/normalization/sub:\r\nIn[0] cond/Identity_1 (defined at /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1355)\t\r\nIn[1] model_2/normalization/sub/y:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1349, in run_step\r\n>>>     outputs = model.test_step(data)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1303, in test_step\r\n>>>     y_pred = self(x, training=False)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\r\n>>>     return self._run_internal_graph(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py\", line 257, in call\r\n>>>     return ((inputs - self.mean) /\r\n>>> \r\n\r\nFunction call stack:\r\ntest_function -> test_function -> test_function\r\n\r\nError in sys.excepthook:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3/dist-packages/apport_python_hook.py\", line 72, in apport_excepthook\r\n    from apport.fileutils import likely_packaged, get_recent_crashes\r\n  File \"/usr/lib/python3/dist-packages/apport/__init__.py\", line 5, in <module>\r\n    from apport.report import Report\r\n  File \"/usr/lib/python3/dist-packages/apport/report.py\", line 32, in <module>\r\n    import apport.fileutils\r\n  File \"/usr/lib/python3/dist-packages/apport/fileutils.py\", line 27, in <module>\r\n    from apport.packaging_impl import impl as packaging\r\n  File \"/usr/lib/python3/dist-packages/apport/packaging_impl.py\", line 23, in <module>\r\n    import apt\r\n  File \"/usr/lib/python3/dist-packages/apt/__init__.py\", line 35, in <module>\r\n    apt_pkg.init_config()\r\napt_pkg.Error: E:Syntax error /etc/apt/apt.conf.d/20auto-upgrades:6: Extra junk at end of file\r\n\r\nOriginal exception was:\r\nTraceback (most recent call last):\r\n  File \"flat_resnet50.py\", line 263, in <module>\r\n    history = train_model(train_path, validation_path, epochs, steps_per_epoch, resnet_50V2)\r\n  File \"flat_resnet50.py\", line 82, in train_model\r\n    history = model.fit(x=train_dataset,\r\n  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 58, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.\r\n  (0) INVALID_ARGUMENT:  required broadcastable shapes\r\n\t [[node replica_1/model_2/normalization/sub\r\n (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py:257)\r\n]]\r\n\t [[div_no_nan/ReadVariableOp_1/_62]]\r\n  (1) INVALID_ARGUMENT:  required broadcastable shapes\r\n\t [[node replica_1/model_2/normalization/sub\r\n (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py:257)\r\n]]\r\n\t [[div_no_nan/AddN/_76]]\r\n  (2) INVALID_ARGUMENT:  required broadcastable shapes\r\n\t [[node replica_1/model_2/normalization/sub\r\n (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py:257)\r\n]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_test_function_65650]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node replica_1/model_2/normalization/sub:\r\nIn[0] cond/Identity_1 (defined at /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1355)\t\r\nIn[1] model_2/normalization/sub/y:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1349, in run_step\r\n>>>     outputs = model.test_step(data)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1303, in test_step\r\n>>>     y_pred = self(x, training=False)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\r\n>>>     return self._run_internal_graph(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py\", line 257, in call\r\n>>>     return ((inputs - self.mean) /\r\n>>> \r\n\r\nInput Source operations connected to node replica_1/model_2/normalization/sub:\r\nIn[0] cond/Identity_1 (defined at /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1355)\t\r\nIn[1] model_2/normalization/sub/y:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1349, in run_step\r\n>>>     outputs = model.test_step(data)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1303, in test_step\r\n>>>     y_pred = self(x, training=False)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\r\n>>>     return self._run_internal_graph(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py\", line 257, in call\r\n>>>     return ((inputs - self.mean) /\r\n>>> \r\n\r\nInput Source operations connected to node replica_1/model_2/normalization/sub:\r\nIn[0] cond/Identity_1 (defined at /usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1355)\t\r\nIn[1] model_2/normalization/sub/y:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1349, in run_step\r\n>>>     outputs = model.test_step(data)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1303, in test_step\r\n>>>     y_pred = self(x, training=False)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\r\n>>>     return self._run_internal_graph(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py\", line 257, in call\r\n>>>     return ((inputs - self.mean) /\r\n>>> \r\n\r\nFunction call stack:\r\ntest_function -> test_function -> test_function\r\n\r\n100/100 [==============================] - ETA: 0s - loss: 6.9095 - categorical_accuracy: 0.0055\r\n```", "comments": ["@FalsoMoralista \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54349\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54349\">No</a>\n"]}, {"number": 54345, "title": "Halts after: I tensorflow/stream_executor/platform/default/dso_loader.cc:49]Successfully opened dynamic library libcudart.so.10.1", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- No. Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Ubuntu 20.04. OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- No. Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- Tensorflow and gpu related binaries installed using: conda install -c anaconda tensorflow-gpu. TensorFlow installed from (source or binary):\r\n- unknown 2.4.1. TensorFlow version (use command below):\r\n- Python 3.9.7. Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- 4 x NVIDIA GeForce RTX 3090, 24M. GPU model and memory:\r\n\r\n- CUDA/cuDNN version:\r\n2022-02-11 09:45:08.686783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2022-02-11 09:45:08.686810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2022-02-11 09:45:08.686818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2022-02-11 09:45:08.686823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2022-02-11 09:45:08.686833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2022-02-11 09:45:08.686839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2022-02-11 09:45:08.686846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2022-02-11 09:45:08.686853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nExecuting the following cmd from the conda environment:\r\n$ python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n\r\nThis halts at:\r\n2022-02-11 09:45:08.695095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n\r\nBut aftter 10mins it outputs:\r\n2022-02-11 09:55:33.285562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-02-11 09:55:33.285591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 \r\n2022-02-11 09:55:33.285596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N \r\n2022-02-11 09:55:33.285599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N \r\n2022-02-11 09:55:33.285601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N \r\n2022-02-11 09:55:33.285604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N \r\n...\r\ntf.Tensor(-120.64484, shape=(), dtype=float32)\r\nFor full output, see faulty_behavior.txt.\r\n\r\n**Describe the expected behavior**\r\nI executed the same command in the docker:\r\n$ docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu python -c \"import tensorflow as tf;\r\n...\r\nno halts and it ends with\r\ntf.Tensor(-680.4232, shape=(), dtype=float32) \r\nfor full output, see expected_behavior.txt.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n- install miniconda\r\n- install python 3.9 environment using conda\r\n\r\n- install: conda install -c anaconda tensorflow-gpu\r\n- execute: python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n[faulty_behavior.txt](https://github.com/tensorflow/tensorflow/files/8048225/faulty_behavior.txt)\r\n[expected_behavior.txt](https://github.com/tensorflow/tensorflow/files/8048223/expected_behavior.txt)\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/8047786/tf_env.txt)\r\n", "comments": ["@alexjaw ,\r\nI was able to execute the given code without any issues.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/554257f1dec0de9608f970c9a6328653/untitled220.ipynb) and try to install the latest stable v2.7 from this [doc link](https://www.tensorflow.org/install) and test your code.Please take a [link](https://www.tensorflow.org/install/source) for the compatible tested build configurations.Thanks!", "@tilakrayal ,\r\nIt works in the new environment. Still the same issue in the Anaconda environment, i.e. I will (eventually) post the bug there.\r\nDid the following. Created new python 3.8 env with python3 venv. Installed tensorflow 2.7. Executed successfully: python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\". Also checked utilisation with nvidia-smi running a  more demanding ML job.\r\n\r\nThx, A.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54345\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54345\">No</a>\n"]}, {"number": 54344, "title": "How to update in get_config() a dictionary variable of Custom layer?", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): Tf 2.3\r\n- Python version:3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior** Not able to save or serialize a dictionary variable (vmap) of type Tensor in the get_config method while saving the model\r\n\r\n**Describe the expected behavior** Model successfully saved with my vmap dictionary\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI am trying to save my model with Custom layer , using model.save(). In my custom layer i have a dictionary variable (vmap), which i need to update in the get_config(). Since i have the custom layer i am defining in the get_config() method all the variables explicitly which i want to be saved and properly reloaded whenever i load the model. I keep getting a list of errors. Not sure if its the correct way of updating the get_config(). Any help is appreciated. \r\n    model.save('D:\\Thesis\\ma_sayli-deshmukh\\qnn\\qnn\\saved_model\\my_model')\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1978, in save\r\n    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\", line 133, in save_model\r\n    saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\", line 80, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 975, in save\r\n    _, exported_graph, object_saver, asset_info = _build_meta_graph(\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 1075, in _build_meta_graph\r\n    object_graph_proto = _serialize_object_graph(saveable_view,\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 720, in _serialize_object_graph\r\n    _write_object_proto(obj, obj_proto, asset_file_def_index,\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 761, in _write_object_proto\r\n    metadata=obj._tracking_metadata)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 3011, in _tracking_metadata\r\n    return self._trackable_saved_model_saver.tracking_metadata\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\base_serialization.py\", line 54, in tracking_metadata\r\n    return json_utils.Encoder().encode(self.python_properties)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 41, in python_properties\r\n    return self._python_properties_internal()\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\model_serialization.py\", line 35, in _python_properties_internal\r\n    metadata = super(ModelSavedModelSaver, self)._python_properties_internal()\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 59, in _python_properties_internal\r\n    metadata.update(get_config(self.obj))\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 118, in get_config\r\n    config = generic_utils.serialize_keras_object(obj)['config']\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\", line 245, in serialize_keras_object\r\n    config = instance.get_config()\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 468, in get_config\r\n    'layers': copy.deepcopy(layer_configs)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 205, in _deepcopy_list\r\n    append(deepcopy(a, memo))\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 230, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 230, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 153, in deepcopy\r\n    y = copier(memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\data_structures.py\", line 465, in __deepcopy__\r\n    copied = super(ListWrapper, self).__deepcopy__(memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\data_structures.py\", line 324, in __deepcopy__\r\n    return type(self)(copy.deepcopy(self._storage, memo))\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 205, in _deepcopy_list\r\n    append(deepcopy(a, memo))\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 172, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 270, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 230, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 172, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 270, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 230, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 172, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 270, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 146, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 230, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"C:\\Users\\deshm\\.conda\\envs\\qnn\\lib\\copy.py\", line 161, in deepcopy\r\n    rv = reductor(4)\r\nTypeError: cannot pickle '_thread.RLock' object\r\n\r\n\r\n\r\nFollowing is the custom layer code: \r\nclass valuemaplayer(keras.layers.Layer):\r\n    def __init__(self,**kwargs):\r\n        kwargs[\"dynamic\"] = True\r\n        super(valuemaplayer,self).__init__(**kwargs)\r\n\r\n        self._vmap = {}\r\n        self._data = []\r\n        self._compression = False\r\n\r\n      \r\n\r\n    def build(self, input_shape):\r\n        pass\r\n\r\n\r\n    def enable_compression(self):\r\n        value = list(self.get_values())\r\n        vmap = self._vmap\r\n        cnt = 0\r\n        # FIXME right now only 2D input data is supported\r\n        for v0 in value:\r\n            for v1 in v0:\r\n                for v2 in v1:\r\n                    for v3 in v2:\r\n                        v = tuple(v3)\r\n                        if v not in vmap:\r\n                            vmap[v]=cnt\r\n                            cnt+=1\r\n        self._compression = True\r\n\r\n\r\n    @tf.function\r\n    def do_mapping(self,pixel):\r\n        if self._compression :\r\n            pixel = tuple(pixel)\r\n        # to do convert pixel(of channel axis) from tensor to a tuple\r\n            enumerated_value=self._vmap.get(pixel)\r\n            print(enumerated_value)\r\n        # print(tf.shape(pixel))\r\n            exit()\r\n            return enumerated_value\r\n\r\n\r\n    @tf.function\r\n    def call(self, inputs, training=True):#use eager execution or decorate with @tf.function\r\n        if self._compression:\r\n\r\n            elems = []\r\n\r\n            for b in inputs:\r\n                for h in b :\r\n                    elems.append(h)\r\n\r\n            # TODO check if channel axis gets mapped by tf.map_fn\r\n            #resize inputs to 2 axis, 1 for each pixel and other channel , work on each pixel\r\n            changed_inputs = tf.map_fn(self.do_mapping, elems)\r\n            return changed_inputs\r\n\r\n         # else compression is disabled\r\n         # in case we're training, we do not want to observe values\r\n        if not training:\r\n            self._data.append(inputs)\r\n        return inputs\r\n\r\n        # get values of the output of value map layer\r\n    def get_values(self):\r\n        for d in self._data:\r\n            try:\r\n                d = d.numpy()\r\n            except AttributeError:\r\n                continue\r\n            yield d\r\n\r\n    def get_config(self):\r\n        config = super(valuemaplayer,self).get_config().copy()\r\n        config.update({'vmap': self._vmap,\r\n                       'data': self._data,\r\n                       })\r\n        return config\r\n\r\n    @classmethod\r\n    def from_config(cls, config):\r\n        return cls(**config)\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        print(\"input shape of value map layer:\", input_shape)\r\n        if self._compression:\r\n            # TODO did I set the channel axis? and does this work?\r\n            if input_shape[-1] == 1:\r\n                print(\"channel axis is set\")\r\n                input_shape[-1] = 1\r\n        return input_shape\r\n\r\n", "comments": ["Hi @saylideshmukh !Could you please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54344\">No</a>\n"]}, {"number": 54343, "title": "Tensorflow gradient tape returns exploding gradient model.trainable_variables", "body": "Dear Tensorflow-Team,\r\n\r\nI currently facing problems when using ```gradientTape``` facing exploding gradients. I have no problem when using tensorflows inbuild ```fit``` function. Based on the MNIST dataset my code looks the following:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nfrom tensorflow.keras.metrics import sparse_categorical_crossentropy\r\n\r\n#(x_train, labels), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n#(mnist_train, mnist_test), (x_test, y_test) = keras.datasets.cifar10.load_data()\r\n\r\n(mnist_train, mnist_test), mnist_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)\r\n\r\ndef prepare(ds, batch_size=128):\r\n  ds = ds.cache()\r\n  ds = ds.batch(batch_size)\r\n  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\r\n  return ds\r\n\r\ndef split_tasks(ds, predicate):\r\n  return ds.filter(predicate), ds.filter(lambda img, label: not predicate(img, label))\r\n\r\ntask_A_train, task_B_train = split_tasks(mnist_train, lambda img, label: label % 2 == 0)\r\ntask_A_train, task_B_train = prepare(task_A_train), prepare(task_B_train)\r\ntask_A_test, task_B_test = split_tasks(mnist_test, lambda img, label: label % 2 == 0)\r\ntask_A_test, task_B_test = prepare(task_A_test), prepare(task_B_test)\r\n\r\ndef evaluate(model, test_set):\r\n    acc = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\r\n    for i, (imgs, labels) in enumerate(test_set):\r\n        preds = model.predict_on_batch(imgs)\r\n        acc.update_state(labels, preds)\r\n    return acc.result().numpy()\r\n\r\nmulti_task_model = tf.keras.Sequential([\r\n   tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\r\n   tf.keras.layers.Dense(128, activation='relu'),\r\n   tf.keras.layers.Dense(10)\r\n])\r\n\r\nmulti_task_model.compile(optimizer='adam', loss=sparse_categorical_crossentropy, metrics='accuracy')\r\n\r\n\r\ndef l2_penalty(model, theta_A):\r\n  penalty = 0\r\n  for i, theta_i in enumerate(model.trainable_variables):\r\n    _penalty = tf.norm(theta_i - theta_A[i])\r\n    penalty += _penalty\r\n  return 0.5*penalty\r\n\r\n\r\ndef train_with_l2(model, task_A_train, task_B_train, task_A_test, task_B_test, epochs=6):\r\n  # First we're going to fit to task A and retain a copy of parameters trained on Task A\r\n  model.fit(task_A_train, epochs=epochs)\r\n  theta_A = {n: p.value() for n, p in enumerate(model.trainable_variables.copy())}\r\n \r\n  print(\"Task A accuracy after training on Task A: {}\".format(evaluate(model, task_A_test)))\r\n   \r\n  # Metrics for the custom training loop\r\n  accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\r\n  loss = tf.keras.metrics.SparseCategoricalCrossentropy('loss')\r\n \r\n  for epoch in range(epochs):\r\n    accuracy.reset_states()\r\n    loss.reset_states()\r\n    for batch, (imgs, labels) in enumerate(task_B_train):\r\n      with tf.GradientTape() as tape:\r\n        preds = model(imgs)\r\n        # Loss is crossentropy loss with regularization term for each parameter\r\n        total_loss = model.loss(labels, preds) + l2_penalty(model, theta_A)\r\n      grads = tape.gradient(total_loss, model.trainable_variables)\r\n      model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n       \r\n      accuracy.update_state(labels, preds)\r\n      loss.update_state(labels, preds)\r\n      print(\"\\rEpoch: {}, Batch: {}, Loss: {:.3f}, Accuracy: {:.3f}\".format(\r\n          epoch+1, batch+1, loss.result().numpy(), accuracy.result().numpy()), flush=True, end=''\r\n         )\r\n    print(\"\")\r\n   \r\n  print(\"Task B accuracy after training trained model on Task B: {}\".format(evaluate(model, task_B_test)))\r\n  print(\"Task A accuracy after training trained model on Task B: {}\".format(evaluate(model, task_A_test)))\r\n  \r\n\r\ntrain_with_l2(multi_task_model, task_A_train, task_B_train, task_A_test, task_B_test)\r\n```\r\n\r\nThis problem also persists when using another trained model.\r\n\r\nHere are my system specifications:\r\n- Windows\r\n- Tensorflow installed from source  (version 2.7.0)\r\n- Python version 3.9.7\r\n\r\n\r\n", "comments": ["@dalbertweiss \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54341, "title": "ValueError: No gradients provided for any variable:", "body": "I am using TensorFlow 2.6.0 and Python 3.9. I am attempting to implement a Variational Autoencoder toy example using MNIST dataset with Convolutional Neural Network as encoder and decoder. You can refer to the complete Jupyter notebook [here](https://github.com/arjun-majumdar/Autoencoders_Experiments/blob/master/Testing-VAE_TF2.ipynb).\r\n\r\nFor some reason, on using GradientTape for training - in this case, computing the gradients with respect to the trainable parameters of the defined model, it keeps giving **ValueError: No gradients provided for any variable:** error message.\r\n\r\nThe exact lines of code are:\r\n\r\n```\r\nwith tf.GradientTape() as tape:\r\n    total_loss = compute_total_loss(\r\n        data = X, reconstruction = X_recon,\r\n        mu = mu, log_var = log_var,\r\n        alpha = 1\r\n    )\r\n    \r\ngrads = tape.gradient(total_loss, model.trainable_weights)\r\n\r\ntype(grads), len(grads)\r\n# (list, 16)\r\n\r\n\r\n# No gradients are computed!\r\nfor x in grads:\r\n    print(x)\r\n'''\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\nNone\r\n'''\r\n\r\n\r\noptimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n\"\"\"\r\nValueError                                Traceback (most recent call last)\r\n~\\AppData\\Local\\Temp/ipykernel_232/111942921.py in <module>\r\n----> 1 optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n\r\n~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py in apply_gradients(self, grads_and_vars, name, experimental_aggregate_gradients)\r\n    639       RuntimeError: If called in a cross-replica context.\r\n    640     \"\"\"\r\n--> 641     grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\r\n    642     var_list = [v for (_, v) in grads_and_vars]\r\n    643 \r\n\r\n~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py in filter_empty_gradients(grads_and_vars)\r\n     73 \r\n     74   if not filtered:\r\n---> 75     raise ValueError(\"No gradients provided for any variable: %s.\" %\r\n     76                      ([v.name for _, v in grads_and_vars],))\r\n     77   if vars_with_empty_grads:\r\n\r\nValueError: No gradients provided for any variable: ['vae_1/encoder_4/conv2d_8/kernel:0', 'vae_1/encoder_4/conv2d_8/bias:0', 'vae_1/encoder_4/conv2d_9/kernel:0', 'vae_1/encoder_4/conv2d_9/bias:0', 'vae_1/decoder_3/dense_9/kernel:0', 'vae_1/decoder_3/dense_9/bias:0', 'vae_1/decoder_3/conv2d_transpose_9/kernel:0', 'vae_1/decoder_3/conv2d_transpose_9/bias:0', 'vae_1/decoder_3/conv2d_transpose_10/kernel:0', 'vae_1/decoder_3/conv2d_transpose_10/bias:0', 'vae_1/decoder_3/conv2d_transpose_11/kernel:0', 'vae_1/decoder_3/conv2d_transpose_11/bias:0', 'vae_1/dense_10/kernel:0', 'vae_1/dense_10/bias:0', 'vae_1/dense_11/kernel:0', 'vae_1/dense_11/bias:0'].\r\n\"\"\"\r\n\r\n```\r\n\r\nIs this a bug? Is it the case that tf.GradientTape() API is somehow not computing the gradients?\r\n", "comments": ["Hi @arjun-majumdar ! I was facing some issues to run the complete code. This error generally occurs normally when loss function is not differentiable. Can you change the compute_total_loss like below in  TF 2.8 (2.6 have Keras version mismatch issue) and let us know? Thanks!\r\n```\r\ndef compute_total_loss(data, reconstruction, mu, log_var, alpha = 1):\r\n    recon_loss = compute_reconstruction_loss(data = data, reconstruction = reconstruction)\r\n    kl_loss = compute_kl_divergence_loss(mu = mu, log_var = log_var)\r\n    \r\n    total_loss = (recon_loss * alpha) + kl_loss\r\n    loss = total_loss**2\r\n    return loss\r\n```", "Hey @mohantym the Jupyter notebook can be accessed [here](https://github.com/arjun-majumdar/Autoencoders_Experiments/blob/master/VAE_TF2-Testing.ipynb) which I ran on Google Colab (to make sure it runs as expected) to help you troubleshoot it better.\r\n\r\nI changed the loss function as suggested-\r\n\r\n```\r\ndef compute_total_loss(data, reconstruction, mu, log_var, alpha = 1):\r\n    recon_loss = compute_reconstruction_loss(data = data, reconstruction = reconstruction)\r\n    kl_loss = compute_kl_divergence_loss(mu = mu, log_var = log_var)\r\n    \r\n    total_loss = (recon_loss * alpha) + kl_loss\r\n    loss = total_loss**2\r\n    \r\n    # return total_loss\r\n    return loss\r\n\r\n\r\n# Make forward propagation using defined VAE model-\r\nX_recon, mu, log_var = model(X)\r\n\r\nX_recon.shape, X.shape\r\n# (TensorShape([4, 28, 28, 1]), (4, 28, 28, 1))\r\n\r\nmu.shape, log_var.shape\r\n# (TensorShape([4, 3]), TensorShape([4, 3]))\r\n\r\nwith tf.GradientTape() as tape:\r\n    loss = compute_total_loss(\r\n    data = X, reconstruction = X_recon,\r\n    mu = mu, log_var = log_var,\r\n    alpha = 1\r\n)\r\n\r\ngrads = tape.gradient(loss, model.trainable_weights)\r\n\r\ntype(grads), len(grads)\r\n# (list, 20)\r\n\r\n# But, this still raises the error as before-\r\noptimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n```\r\n\r\n\r\n> ValueError                                Traceback (most recent call last)\r\n> \r\n> [<ipython-input-39-455ef87a6a2b>](https://localhost:8080/#) in <module>()\r\n> ----> 1 optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n> \r\n> 1 frames\r\n> \r\n> [/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py](https://localhost:8080/#) in filter_empty_gradients(grads_and_vars)\r\n>      71   if not filtered:\r\n>      72     variable = ([v.name for _, v in grads_and_vars],)\r\n> ---> 73     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\r\n>      74                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\r\n>      75   if vars_with_empty_grads:\r\n> \r\n> ValueError: No gradients provided for any variable: (['vae/encoder/conv2d/kernel:0', 'vae/encoder/conv2d/bias:0', 'vae/encoder/conv2d_1/kernel:0', 'vae/encoder/conv2d_1/bias:0', 'vae/encoder/dense/kernel:0', 'vae/encoder/dense/bias:0', 'vae/decoder/dense_1/kernel:0', 'vae/decoder/dense_1/bias:0', 'vae/decoder/dense_2/kernel:0', 'vae/decoder/dense_2/bias:0', 'vae/decoder/conv2d_transpose/kernel:0', 'vae/decoder/conv2d_transpose/bias:0', 'vae/decoder/conv2d_transpose_1/kernel:0', 'vae/decoder/conv2d_transpose_1/bias:0', 'vae/decoder/conv2d_transpose_2/kernel:0', 'vae/decoder/conv2d_transpose_2/bias:0', 'vae/dense_3/kernel:0', 'vae/dense_3/bias:0', 'vae/dense_4/kernel:0', 'vae/dense_4/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'vae/encoder/conv2d/kernel:0' shape=(3, 3, 1, 32)", "Hi @chunduriv ! Could you please look at this issue? Attaching [gist](https://colab.research.google.com/gist/mohantym/2def7c2d53fed323583277d69274929d/vae-tf2.ipynb#scrollTo=pbU4QbBMKEQw) for reference?", "Solved issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54341\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54341\">No</a>\n"]}, {"number": 54340, "title": "Keep getting this error while training my model", "body": "ResourceExhaustedError:  OOM when allocating tensor with shape[5,64,4890,4890] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[node sequential/conv2d/Relu\r\n (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:4867)\r\n]]", "comments": ["@NevilShingala \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "I have already filled the Keras Issue template", "@NevilShingala \r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset , tensorflow version you are using. Thanks!", "from google.colab import drive\r\n\r\ndrive.mount('/content/drive')\r\n\r\nimport tensorflow as tf \r\nfrom keras.layers import Input, Lambda, Dense, Flatten, MaxPooling2D, Conv2D\r\nfrom keras.models import Model\r\n#from keras.applications.resnet50 import ResNet50\r\nfrom PIL import Image, ImageChops\r\nfrom keras.applications.vgg16 import VGG16\r\nfrom keras.applications.vgg16 import preprocess_input\r\nfrom keras.preprocessing import image\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.models import Sequential\r\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\r\nimport numpy as np\r\nfrom glob import glob\r\nimport matplotlib.pyplot as plt\r\nIMAGE_SIZE =[4892, 4892]\r\ntrain_path = '/content/drive/MyDrive/ColabNotebooks1/FinalDataLeft/Train'\r\nvalid_path = '/content/drive/MyDrive/ColabNotebooks1/FinalDataLeft/Test'\r\n\r\nfolders = glob('/content/drive/MyDrive/ColabNotebooks1/FinalDataLeft/Train/*')\r\n\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\n\r\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\r\n                                   shear_range = 0.2,\r\n                                   zoom_range = 0.2,\r\n                                   horizontal_flip = True)\r\n\r\ntest_datagen = ImageDataGenerator(rescale = 1./255)\r\ntest_set = test_datagen.flow_from_directory('/content/drive/MyDrive/ColabNotebooks1/FinalDataLeft/Test',\r\n                                            target_size = (4892, 4892),\r\n                                            batch_size = 5,\r\n                                            class_mode = 'categorical')\r\n\r\ntraining_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ColabNotebooks1/FinalDataLeft/Train',\r\n                                                 target_size = (4892, 4892),\r\n                                                 batch_size = 5,\r\n                                                 class_mode = 'categorical')\r\n\r\n#create model\r\nmodel = Sequential()\r\n\r\n#add model layers\r\nmodel.add((Conv2D\r\n           (64,(3,3), activation='relu', input_shape=(4892,4892,3))\r\n         ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\nmodel.add((Conv2D\r\n           (64, (3,3), activation='relu', input_shape=(4892,4892,3))\r\n         ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\nmodel.add((Conv2D\r\n           (64, (3,3), activation='relu', input_shape=(4892,4892,3))\r\n        ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\nmodel.add((Conv2D\r\n           (64, (3,3), activation='relu', input_shape=(4892,4892,3))\r\n        ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\nmodel.add((Conv2D\r\n           (128, (3,3), activation='relu', input_shape=(4892,4892,3))\r\n         ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\nmodel.add((Conv2D\r\n           (128, (3,3), activation='relu', input_shape=(4892,4892,3))\r\n         ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\nmodel.add((Conv2D\r\n           (128, (3,3), activation='relu', input_shape=(4892,4892,3))\r\n         ))\r\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\r\n\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(activation = 'relu', units = 128))\r\nmodel.add(Dense(activation = 'relu', units = 64))\r\nmodel.add(Dense(1, activation='softmax'))\r\n# compiling model\r\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n# train model\r\nmodel.fit(training_set,\r\n          batch_size=32,\r\n          epochs= 25,\r\n          validation_data= test_set,\r\n          #class_weight=cw,\r\n          #callbacks=callbacks_list\r\n\r\n          )\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTensorflow-2.7.0\r\nDataset link:- https://drive.google.com/drive/folders/1mSf0DbYrA07oWdz2Fwreh4EbAaKIOl5Z?usp=sharing", "Don't close", "@NevilShingala \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThanks!", "No one has replied their ", "I think this is because your video memory has been run out. I think you can try using a smaller batch_size, or optimizing your mode's structure.", "`ResourceExhaustedError: OOM [...]` means **O**ut **O**f **M**emory. Your program is asking for more GPU memory than it can provide. As a quick fix, consider decrease your batch size.", "@NevilShingala Could you please refer the above comments and also see the response on the [thread](https://github.com/keras-team/keras/issues/16047) ?\r\nPlease move this issue to closed status as we will track the other ticket .\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54340\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54340\">No</a>\n"]}, {"number": 54339, "title": "RuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.", "body": "2022-02-11 11:05:30.792376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"01_GenQuadProposals.py\", line 82, in <module>\r\n    CNNModel.restoreCNNSess()\r\n  File \"/home/dms/SupplementaryMaterials/CodeAndData/Code/QuadProposals/CNNQuadDetector.py\", line 92, in restoreCNNSess\r\n    saver = tf.train.import_meta_graph(self.cfg.cornerdet_sess + '.meta', import_scope=\"cornerdet\")\r\n  File \"/home/dms/anaconda3/envs/SupplementaryMaterials/lib/python3.8/site-packages/tensorflow/python/training/saver.py\", line 1460, in import_meta_graph\r\n    return _import_meta_graph_with_return_elements(meta_graph_or_file,\r\n  File \"/home/dms/anaconda3/envs/SupplementaryMaterials/lib/python3.8/site-packages/tensorflow/python/training/saver.py\", line 1472, in _import_meta_graph_with_return_elements\r\n    raise RuntimeError(\"Exporting/importing meta graphs is not supported when \"\r\nRuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.\r\n\r\n**System information**\r\n\r\ntensorboard 2.8.0\r\ntensorboard-data-server 0.6.1\r\ntensorboard-plugin-wit 1.8.1\r\ntensorflow 2.3.1\r\ntensorflow-estimator 2.3.0\r\ntensorflow-hub 0.12.0\r\ntensorflow-io-gcs-filesystem 0.24.0\r\ntensorflowjs 3.13.0\r\ncuda 10.1\r\ncudnn 7.6\r\npython 3.8\r\n\r\nhas update import tensorflow. as tf  to import tensorflow.compat.v1 as tf\r\n", "comments": ["@jackiezhang11 ,\r\nCan you please take a look at this [issue](https://github.com/tensorflow/hub/issues/350) with the same error.Also please try to update to latest tf v2.7 and let us know if the issue still persists.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54339\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54339\">No</a>\n"]}, {"number": 54338, "title": "RuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n2022-02-11 11:05:30.792376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"01_GenQuadProposals.py\", line 82, in <module>\r\n    CNNModel.restoreCNNSess()\r\n  File \"/home/dms/SupplementaryMaterials/CodeAndData/Code/QuadProposals/CNNQuadDetector.py\", line 92, in restoreCNNSess\r\n    saver = tf.train.import_meta_graph(self.cfg.cornerdet_sess + '.meta', import_scope=\"cornerdet\")\r\n  File \"/home/dms/anaconda3/envs/SupplementaryMaterials/lib/python3.8/site-packages/tensorflow/python/training/saver.py\", line 1460, in import_meta_graph\r\n    return _import_meta_graph_with_return_elements(meta_graph_or_file,\r\n  File \"/home/dms/anaconda3/envs/SupplementaryMaterials/lib/python3.8/site-packages/tensorflow/python/training/saver.py\", line 1472, in _import_meta_graph_with_return_elements\r\n    raise RuntimeError(\"Exporting/importing meta graphs is not supported when \"\r\nRuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\ntensorboard                  2.8.0\r\ntensorboard-data-server      0.6.1\r\ntensorboard-plugin-wit       1.8.1\r\ntensorflow                   2.3.1\r\ntensorflow-estimator         2.3.0\r\ntensorflow-hub               0.12.0\r\ntensorflow-io-gcs-filesystem 0.24.0\r\ntensorflowjs                 3.13.0\r\ncuda                           10.1\r\ncudnn                          7.6\r\npython                         3.8\r\n- Are you willing to contribute it (Yes/No):\r\nYes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": [" use tf.compat.v1.disable_v2_behavior() to stop all tensorflow2 behaviours  solve this problems."]}, {"number": 54337, "title": "TensorFlow Lite 2.8 ARM cross-compilation failed when XNNPACK=ON: unknown type name 'float16x8_t'", "body": "**System information**\r\n* Linux Ubuntu 20.04\r\n* TensorFlow 2.8\r\n* CMake 3.16.3\r\n* gcc-arm-8.3-2019.03-x86_64-arm-linux-gnueabihf ([here](https://www.tensorflow.org/lite/guide/build_cmake_arm#download_toolchain_2))\r\n\r\n**Describe the problem**\r\n\r\nI trying to cross-compile TensorFlow Lite 2.8 with XNNPACK=ON for ARM using CMake. I got error \"unknown type name 'float16x8_t'\":\r\n\r\n```\r\n...\r\n[ 60%] Building C object _deps/xnnpack-build/CMakeFiles/XNNPACK.dir/src/qc8-gemm/gen/2x8c2s4-minmax-fp32-neonv8-mlal.c.o\r\nmake[2]: Entering directory '/home/pi/tflite_build'\r\n/home/pi/tflite_build/xnnpack/src/f16-f32-vcvt/gen/vcvt-neonfp16-x16.c: In function \u2018xnn_f16_f32_vcvt_ukernel__neonfp16_x16\u2019:\r\ncd /home/pi/tflite_build/_deps/xnnpack-build && /home/pi/toolchains/gcc-arm-8.3-2019.03-x86_64-arm-linux-gnueabihf/bin/arm-linux-gnueabihf-gcc -DCPUINFO_SUPPORTED_PLATFORM=1 -DEIGEN_MPL2_ONLY -DFXDIV_USE_INLINE_ASSEMBLY=0 -DNOMINMAX=1 -DPTHREADPOOL_NO_DEPRECATED_API=1 -DXNN_ENABLE_ASSEMBLY=1 -DXNN_ENABLE_MEMOPT=1 -DXNN_ENABLE_SPARSE=1 -DXNN_LOG_LEVEL=0 -I/home/pi/tflite_build/xnnpack/include -I/home/pi/tflite_build/xnnpack/src -I/home/pi/tflite_build/clog/deps/clog/include -I/home/pi/tflite_build/cpuinfo/include -I/home/pi/tflite_build/pthreadpool-source/include -I/home/pi/tflite_build/FXdiv-source/include -I/home/pi/tflite_build/FP16-source/include  -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -O3 -DNDEBUG -fPIC   -Wno-psabi -pthread -std=gnu99  -marm  -march=armv8-a -mfpu=neon-fp-armv8  -O2  -o CMakeFiles/XNNPACK.dir/src/qc8-gemm/gen/2x8c2s4-minmax-fp32-neonv8-mlal.c.o   -c /home/pi/tflite_build/xnnpack/src/qc8-gemm/gen/2x8c2s4-minmax-fp32-neonv8-mlal.c\r\n/home/pi/tflite_build/xnnpack/src/f16-f32-vcvt/gen/vcvt-neonfp16-x16.c:31:11: error: unknown type name \u2018float16x8_t\u2019\r\n     const float16x8_t vh0 = vreinterpretq_f16_u16(vld1q_u16(i)); i += 8;\r\n           ^~~~~~~~~~~\r\n/home/pi/tflite_build/xnnpack/src/f16-f32-vcvt/gen/vcvt-neonfp16-x16.c:31:29: warning: implicit declaration of function \u2018vreinterpretq_f16_u16\u2019; did you mean \u2018vreinterpretq_s16_u16\u2019? [-Wimplicit-function-declaration]\r\n     const float16x8_t vh0 = vreinterpretq_f16_u16(vld1q_u16(i)); i += 8;\r\n                             ^~~~~~~~~~~~~~~~~~~~~\r\n                             vreinterpretq_s16_u16\r\n/home/pi/tflite_build/xnnpack/src/f16-f32-vcvt/gen/vcvt-neonfp16-x16.c:32:11: error: unknown type name \u2018float16x8_t\u2019\r\n     const float16x8_t vh1 = vreinterpretq_f16_u16(vld1q_u16(i)); i += 8;\r\n           ^~~~~~~~~~~\r\n```\r\n\r\nI able to compile TensorFlow Lite 2.7 with XNNPACK=ON for ARM using CMake.\r\n\r\nI using build instructions provided [here](https://www.tensorflow.org/lite/guide/build_cmake_arm#build_for_armv7_neon_enabled)", "comments": ["@distlibs,\r\nCan you take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/53545) which discusses about the similar issue and let us know if it helps? Thanks!", "@chunduriv\r\nI able to compile TensorFlow Lite 2.7 with XNNPACK=ON. Problems with 2.8.", "@chunduriv any news regarding this issue?", "Any updates? I've hit the same issue when cross compiling TFlite for ARM?", "Could you try to add an additional compiler option \"-mfp16-format=ieee\", and see whether it will fix the issue? Thx!", "Thanks, that fixed it.", "@distlibs, \r\n\r\nCan you try as suggested [here](https://github.com/tensorflow/tensorflow/issues/54337#issuecomment-1056060276) and let us know? Thanks.", "I have successfully cross-compiled TensorFlow Lite 2.8 with XNNPACK=ON when I added `-mfp16-format=ieee` additional compiler option. I think this compiler option should be added in the documentation [here](https://www.tensorflow.org/lite/guide/build_cmake_arm#run_cmake_2).\r\n\r\n```\r\nARMCC_FLAGS=\"-march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -mfp16-format=ieee\"\r\n```", "> I have successfully cross-compiled TensorFlow Lite 2.8 with XNNPACK=ON when I added `-mfp16-format=ieee` additional compiler option. I think this compiler option should be added in the documentation [here](https://www.tensorflow.org/lite/guide/build_cmake_arm#run_cmake_2).\r\n\r\nGreat to know this works for you :-) We'll fix the doc asap as suggested.\r\n\r\n> \r\n> ```\r\n> ARMCC_FLAGS=\"-march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -mfp16-format=ieee\"\r\n> ```\r\n\r\n", "@distlibs, \r\n\r\nThank you for the confirmation. Please feel free to close the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54337\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54337\">No</a>\n", "I still have this issue with `v2.8.0`. "]}, {"number": 54335, "title": "Inference overhead when resizing input image", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): PIP Binary\r\n- TensorFlow version (use command below): 2.6\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nInference time increases by a lot when changing input image resolution in a dynamic tensor shape model. \r\nThis only happens if the input shape changes, consecutive runs for different images performs well as long as the input size is the same. Once it changes, even for lower resolutions (1024x768 -> 512x512), the inference time increases for the first inference and then goes back to normal for the next ones.\r\n\r\n", "comments": ["Hi @BernardoGO ! Have you checked the performance in Python [3.7 /3.8](https://www.tensorflow.org/install) ? Please provide a simple stand alone code to replicate the issue. Thanks! ", "Hello @mohantym\r\n\r\nSorry, I mistyped python version. It's version 3.7.\r\nAs for the code, I've been trying Style Transfer from with provided weights: https://github.com/cryu854/FastStyle\r\n\r\nThe issue only happens at inference time\r\n", "Ok @BernardoGO ! Could you please provide exact code with  inference time code snippet? It is always better to resize all the input images prior inputting them into model for training or evaluating . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54334, "title": "Unable to Quantize Model with Custom Op Transpose", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: \r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n-   **Python version**: 3.8.2\r\n-   **CUDA/cuDNN version**: N/A\r\n-   **GPU model and memory**: N/A\r\n-  **Command to reproduce**: python bug_demo_01.py\r\n\r\n### Describe the problem\r\nWhen attempting to quantize a Saved Model that contains a Custom Transpose op, it fails as it cannot initialize that op for quantization. The source code for bug_demo_01.py is listed below. The model folder is listed here. [BisNet-512x512x3-rgb-model.zip](https://github.com/tensorflow/tensorflow/files/8044758/BisNet-512x512x3-rgb-model.zip)\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef representative_dataset_gen():\r\n    for _ in range(10):\r\n        yield [np.random.random([1,512,512,3]).astype(np.float32)]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('BisNet-512x512x3-rgb-model')\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.experimental_new_converter = True\r\nconverter.allow_custom_ops = True\r\n\r\ntflite_model = converter.convert()\r\n```\r\n\r\nThe ending error is as follows\r\n2022-02-10 15:12:03.161809: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1786] The following operation(s) need TFLite custom op implementation(s):\r\nCustom ops: Transpose\r\nDetails:\r\n        tf.Transpose {device = \"\"}\r\nTraceback (most recent call last):\r\n  File \"bug_demo_01.py\", line 14, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\Users\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 921, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"C:\\Users\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 521, in _calibrate_quantize_model\r\n    calibrated = calibrate_quantize.calibrate(\r\n  File \"C:\\Users\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py\", line 172, in calibrate\r\n    self._calibrator.Prepare([list(s.shape) for s in sample])\r\nRuntimeError: Failed to initialize op resolver for calibration:\r\nThere are unresolved custom ops: [Transpose]tensorflow/lite/kernels/conv.cc:349 input->dims->data[3] != filter->dims->data[3] (512 != 3)Node number 2 (CONV_2D) failed to prepare.\r\n", "comments": ["@msquigle Could you please try with the latest TF version 2.8.0 and let us know the outcome?Please refer [this](https://www.tensorflow.org/lite/guide/ops_compatibility) link and let us know if it helps?\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54334\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54334\">No</a>\n"]}, {"number": 54333, "title": "Align average pool between TFL and TOSA", "body": "TFL calculates average pool without subtracting the zero point first.\r\nTOSA defines average pool with the zero point subtract. Some\r\ncalculations will round differently depending on the zero point value.\r\nWhen legalizing TFL to TOSA, force the zero points to zero to get the\r\nexact behavior match.\r\n\r\nSigned-off-by: Eric Kunze <eric.kunze@arm.com>", "comments": []}, {"number": 54332, "title": "Allow gather batch_dims attribute in TOSA legalization", "body": "The gather op legalization previously ignored the batch_dims attribute from the TensorFlow lite operator. This modifies to use the batch_dims attribute if present.\r\n\r\nSigned-off-by: Eric Kunze <eric.kunze@arm.com>", "comments": []}, {"number": 54330, "title": "Constrain pytree type annotations to produce lists", "body": "This is consistent with assumptions already made by JAX code.\r\n\r\nThis is part 1 of https://github.com/google/jax/pull/9079.  @hawkinsp as requested :smile: ", "comments": ["@r4ant ping?"]}, {"number": 54329, "title": "add c++17/1z support for cuda 11 and above", "body": "TF with GPU support failed to build for `CUDA 11.4` and `c++17`.  This change adds `c++17 c++1z` to list of supported std options for CUDA 11 and above", "comments": ["@smuzaffar Can you please sign CLA. Thanks!", "CLA signed", "I have signed CLA but no idea why it still shows missing CLA. ", "I just sent a similar pull request: https://github.com/tensorflow/tensorflow/pull/54409\r\n\r\nOne comment, I don't think --std=c++1z is supported by nvcc unfortunately:  https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-altering-compiler-linker-behavior-std", "thanks @hironaka for pointing out that `c++1z` is not supported by `nvcc`. I think your fix in https://github.com/tensorflow/tensorflow/pull/54409 will not work for `cuda<11` and also it will fail for tensorflow with `c++1z` build option. I have updated this PR with proper fix which should allow tensorflow to build with `cuda<11` and also with `c++1z`"]}, {"number": 54328, "title": "Getting error data cardinality is ambigous on running in functional api , while running it line by line doesn't", "body": "<em>Please make sure that this is an issue related to keras.\r\ntag:keras_template</em>\r\n\r\n**Important Notice**\r\n\r\nPlease note that `tf.keras` code was moved entirely to\r\n[keras-team/keras](https://github.com/keras-team/keras) repository\r\n\r\nYou can open any code/doc bugs, performance issues, and feature requests\r\n in [keras-team/keras](https://github.com/keras-team/keras/issues) repository\r\n\r\n`tf.keras` related issues opened in\r\n[tensorflow/tensorflow](https://github.com/tensorflow/tensorflow) repository may\r\nnot get attention as [keras-team/keras](https://github.com/keras-team/keras)\r\nrepository is dedicated for the development of `keras` code\r\n", "comments": ["Hi @Redeye234 !You can use **[np.expand_dims(dataset,axis=-1)](https://stackoverflow.com/questions/62253289/valueerror-data-cardinality-is-ambiguous)** on datasets to resolve the issue? Please provide a sample stand alone code for further assistance .  Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 54327, "title": "Cant install TF2", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20 LTS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: any\r\n- Python version: 3.7 (and same with 3.8)\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: i dont know this\r\n- GPU model and memory: 64gb ram. No gpu i guess? (Because its VPS)\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npip install tensorflow\r\npip3 install tensorflow\r\n( Any of those 2 )\r\n```bash\r\nSame when trying install 2.3.1\r\nERROR: Could not find a version that satisfies the requirement tensorflow>=2.3.1 (from -r requirements.txt (line 5)) (from versions: none)\r\nERROR: No matching distribution found for tensorflow>=2.3.1 (from -r requirements.txt (line 5))\r\n```\r\n\r\n**Error**\r\n```bash\r\nroot@vm:~/bot/DolboNet# pip install tensorflow\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n", "comments": ["@MrMasrozYTLIVE We see that you are using older version of TF v2.3.1 and older versions are no longer supported. We recommend you to kindly upgrade to TF v2.4 or latest . Please have a look at [ this ](https://www.tensorflow.org/install/source#ubuntu)link and also refer the tested build [configurations](https://www.tensorflow.org/install/source#tested_build_configurations). \r\nPlease let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54327\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54327\">No</a>\n"]}, {"number": 54326, "title": "NotFoundError\uff1adlopen(.../roi_pooling.so, 6): image not found", "body": "I try to run Faster_RCNN_TF from this source\uff1a\r\nhttps://github.com/smallcorgi/Faster-RCNN_TF#installation-sufficient-for-the-demo\r\nand I get this error can't solve.\r\n--------------------------------------------------------------------------------\r\n...line 60, in load_op_library \r\nlib_handle = py_tf.TF_LoadLibrary(library_filename)\r\n\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/anthony/Faster-RCNN_TF/tools/../lib/roi_pooling_layer/roi_pooling.so, 6): image not found\r\n\r\n--------------------------------------------------------------------------------\r\nEnvironment\uff1a\r\nRun on the Mac m1  chip\r\nmacOS\uff1a11.6.1\r\nPython\uff1a3.7.11\r\nTensorFlow\uff1a2.0.0\r\nTensorFlow install form anaconda\r\nGPU model and memory\uff1aM1 GPU,16 GB RAM\r\nBazel version\uff1aN/A\r\nCUDA/cuDNN\uff1aN/A \r\n\r\n--------------------------------------------------------------------------------\r\nI have solved most of error so far but I can't find a solution for this error.\r\nI would appreciate any ideas.", "comments": ["@Anthony1011 ,\r\nWe see that you are using tf version 2.0 which is not actively supported, please update to tensorflow v2.7 and let us know if you are facing same issue.Also please take a look at this [link](https://github.com/tensorflow/tensorflow/issues/53309#issuecomment-986657957).Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54326\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54326\">No</a>\n"]}, {"number": 54323, "title": "TensorFlow Lite 2.8.0, benchmark_model build, error C2065: 'M_PI': undeclared identifier", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 21H1 19043.1526\r\n- TensorFlow installed from (source or binary): None\r\n- TensorFlow version: 2.8.0\r\n- Python version: Python 3.7.6\r\n- Installed using virtualenv? pip? conda?: None\r\n- Bazel version (if compiling from source): None, using CMake version 3.19.2\r\n- GCC/Compiler version (if compiling from source): Microsoft Visual Studio Professional 2019, Version 16.11.6\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nDuring benchmark_model build I've received following error:\r\n```\r\nD:\\Git_repos\\tensorflow\\tensorflow/core/lib/random/random_distributions_utils.h(83,27): error C2065: 'M_PI': undeclared identifier [D:\\Git_repos\\tensorflow\\tensorflow\\lite\\build_win_2_8\\tensorflow-lite.vcxpro\r\nj]\r\nD:\\Git_repos\\tensorflow\\tensorflow/core/lib/random/random_distributions_utils.h(83,15): error C2737: 'v1': const object must be initialized [D:\\Git_repos\\tensorflow\\tensorflow\\lite\\build_win_2_8\\tensorflow-li\r\nte.vcxproj]\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\nI've tried to build benchmark_model (tag v2.8.0) on Windows with following steps:\r\n```\r\ncd tensorflow\\tensorflow\\lite\r\nmkdir build_win_2_8\r\ncd build_win_2_8\r\ncmake ..\r\ncmake --build . -j -t benchmark_model --config Release\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nI've managed to fix this with following code change:\r\n\r\n```patch\r\nindex f09b32f63d3..65c8d90b919 100644\r\n--- a/tensorflow/core/lib/random/random_distributions_utils.h\r\n+++ b/tensorflow/core/lib/random/random_distributions_utils.h\r\n@@ -25,6 +25,10 @@ limitations under the License.\r\n namespace tensorflow {\r\n namespace random {\r\n\r\n+#ifndef M_PI\r\n+  #define M_PI 3.14159265358979323846\r\n+#endif\r\n+\r\n // Helper function to convert an 32-bit integer to a float between [0..1).\r\n PHILOX_DEVICE_INLINE float Uint32ToFloat(uint32_t x) {\r\n   // IEEE754 floats are formatted as follows (MSB first):\r\n```\r\n\r\nIs this a correct way of solving this issue or am I missing something in the build process?\r\n", "comments": ["Are there any updates regarding this issue?\r\n\r\nJust a heads up, I tried this on a different Windows machine which is running Visual Studio 2017 version 15.9.5 and I got the same error. On that machine I was able to fix this with a patch mentioned in the issue description.\r\n\r\nIt seams to me that this is an issue on a TensorFlow side because documentation doesn't specify any specific steps (link: https://www.tensorflow.org/lite/guide/build_cmake#step_6_build_tensorflow_lite_benchmark_tool_and_label_image_example_optional).", "@Jukyy ,\r\nWould you like build Tensorflow from Bazel.\r\nTake a look [#4148](https://github.com/bazelbuild/bazel/issues/4148#issuecomment-468288778)\r\nThanks !", "I tried building with Bazel (version 4.2.1), but now I get following error:\r\n\r\n```\r\ntensorflow/lite/nnapi/sl/SupportLibrary.cc(20): fatal error C1083: Cannot open include file: 'dlfcn.h': No such file or directory\r\n```\r\n\r\nFor some reason Bazel tries to build with Linux header on Windows. This just raises more questions and we are diverging from an original issue at hand which is solving `error C2065: 'M_PI': undeclared identifier` on Windows platform.\r\n\r\nThe code at question was added in this commit https://github.com/tensorflow/tensorflow/commit/89428690d177fb2577359e682687f4022a89ec23 (this part of the source code wasn't used in previous TFLite builds). Also TFLite source code recognizes that some macros are not available on all platforms https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/lite/kernels/internal/constants.h#L19 \r\n\r\nTo me it this seems like an simple oversight where you didn't account for M_PI being missing on Windows platform. Simply adding this definition as I have shown in issue description should solve the problem because this is not the first time in TensorFlow source code where this fix was added (example: https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/lite/experimental/microfrontend/lib/window_util.c#L23).\r\n\r\n", "Using cmake I just added `/D_USE_MATH_DEFINES` to `CMAKE_CXX_FLAGS` and it built the C shared library without problems\r\n\r\n```\r\n> cmake -GNinja ..\\tensorflow\\tensorflow\\lite\\c -DCMAKE_CXX_FLAGS=\"/DWIN32 /D_WINDOWS /GR /EHsc /D_USE_MATH_DEFINES\"\r\n```", "@augustineam I've generated cmake project like this\r\n```\r\ncmake .. -DCMAKE_CXX_FLAGS=\"/DWIN32 /D_WINDOWS /GR /EHsc /D_USE_MATH_DEFINES\"\r\n```\r\nAfter that I've managed to build `benchmark_model` target successfully without resorting to a code changes.\r\n\r\nThat being said, what is the actual solution to this issue?\r\nIt should be one of the following:\r\n\r\n1. Adding MI_PI definition as I suggested in an issue description\r\n2. Adding those `CMAKE_CXX_FLAGS` to a TensorFlow Lite CMake\r\n3. Adding those instruction to a CMake build documentation as an known issue for a Windows platform", "@Jukyy The suggestion 1. has [already been added to the `random_distributions_utils.h` file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/random/random_distributions_utils.h#L25-L27). This is the preferred solution.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54323\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54323\">No</a>\n"]}, {"number": 54322, "title": "TFlite on Raspberry 4B: cannot find VerifyField<int8_t>", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 2021-10-30-raspios-bullseye-arm64\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): TensorFlow Lite 2.6.0\r\n\r\nHi, i follow the steps from  https://qengineering.eu/install-tensorflow-2-lite-on-raspberry-64-os.html\r\nfor installing TensorFlow Lite on RPi4B with Bullseye 64-bits OS\r\n\r\nDependencies was fully installed and the C++ installation was successful, after exchanging the old version of flatbuffers and successful compilation, i got two libraries and two folders with header files.\r\n![2022-02-08-030833_1920x1080_scrot](https://user-images.githubusercontent.com/33203044/153391879-c8926b6b-9ce9-47c8-8e3d-eeeb42b2d5ad.png)\r\n\r\nbut when i run TestTensorFlow_Lite.cpb from https://github.com/Qengineering/TensorFlow_Lite_Pose_RPi_64-bits/issues/3 with Code::Blocks, comes out the following errors. That VerifyField<int8_t> is missing. could you please tell me, how can i solve this problem, thx? \r\n![2022-02-08-030032_1920x1080_scrot](https://user-images.githubusercontent.com/33203044/153392022-a764ca94-24d3-4efe-9640-3b848a5f43f0.png)\r\n\r\n\r\n\r\n\r\n\r\n![2022-02-08-030319_1920x1080_scrot](https://user-images.githubusercontent.com/33203044/153392028-a09f1d11-a76f-4d1e-ad50-d194275af42a.png)\r\n", "comments": ["https://github.com/Qengineering/TensorFlow_Lite_Pose_RPi_64-bits/issues/3 solved ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54322\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54322\">No</a>\n"]}, {"number": 54321, "title": "How to apply/link the Flex delegate before inference.", "body": "**System information**\r\n- I was working for porting tflite models on to raspberry pi, so for that TensorFlow library does not work in raspberry pi so I need to somehow use tensorflow_runtime library, but while using it in colab I faced the error for the following code.\r\n\r\n\r\n**Code**\r\n\r\n```\r\n# \r\n#import tensorflow.lite as tflite\r\nimport tflite_runtime.interpreter as tt\r\n#from interpreter import Interpreter \r\nimport numpy as np\r\nimport IPython\r\n\r\n# Test the model on random input data.\r\ndef fastspeech_infer(tflite_model_path, input_text):\r\n  # Load the TFLite model and allocate tensors.\r\n  interpreter = tt.Interpreter(model_path=tflite_model_path)\r\n  print(interpreter)\r\n  #print(interpreter.get_tensor_details())\r\n\r\n  # Get input and output tensors.\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n\r\n  a = {\"pad\": 0, \"-\": 1, \"!\": 2, \"'\": 3, \"(\": 4, \")\": 5, \",\": 6, \".\": 7, \":\": 8, \";\": 9, \"?\": 10, \" \": 11, \"A\": 12, \"B\": 13, \"C\": 14, \"D\": 15, \"E\": 16, \"F\": 17, \"G\": 18, \"H\": 19, \"I\": 20, \"J\": 21, \"K\": 22, \"L\": 23, \"M\": 24, \"N\": 25, \"O\": 26, \"P\": 27, \"Q\": 28, \"R\": 29, \"S\": 30, \"T\": 31, \"U\": 32, \"V\": 33, \"W\": 34, \"X\": 35, \"Y\": 36, \"Z\": 37, \"a\": 38, \"b\": 39, \"c\": 40, \"d\": 41, \"e\": 42, \"f\": 43, \"g\": 44, \"h\": 45, \"i\": 46, \"j\": 47, \"k\": 48, \"l\": 49, \"m\": 50, \"n\": 51, \"o\": 52, \"p\": 53, \"q\": 54, \"r\": 55, \"s\": 56, \"t\": 57, \"u\": 58, \"v\": 59, \"w\": 60, \"x\": 61, \"y\": 62, \"z\": 63, \"@AA\": 64, \"@AA0\": 65, \"@AA1\": 66, \"@AA2\": 67, \"@AE\": 68, \"@AE0\": 69, \"@AE1\": 70, \"@AE2\": 71, \"@AH\": 72, \"@AH0\": 73, \"@AH1\": 74, \"@AH2\": 75, \"@AO\": 76, \"@AO0\": 77, \"@AO1\": 78, \"@AO2\": 79, \"@AW\": 80, \"@AW0\": 81, \"@AW1\": 82, \"@AW2\": 83, \"@AY\": 84, \"@AY0\": 85, \"@AY1\": 86, \"@AY2\": 87, \"@B\": 88, \"@CH\": 89, \"@D\": 90, \"@DH\": 91, \"@EH\": 92, \"@EH0\": 93, \"@EH1\": 94, \"@EH2\": 95, \"@ER\": 96, \"@ER0\": 97, \"@ER1\": 98, \"@ER2\": 99, \"@EY\": 100, \"@EY0\": 101, \"@EY1\": 102, \"@EY2\": 103, \"@F\": 104, \"@G\": 105, \"@HH\": 106, \"@IH\": 107, \"@IH0\": 108, \"@IH1\": 109, \"@IH2\": 110, \"@IY\": 111, \"@IY0\": 112, \"@IY1\": 113, \"@IY2\": 114, \"@JH\": 115, \"@K\": 116, \"@L\": 117, \"@M\": 118, \"@N\": 119, \"@NG\": 120, \"@OW\": 121, \"@OW0\": 122, \"@OW1\": 123, \"@OW2\": 124, \"@OY\": 125, \"@OY0\": 126, \"@OY1\": 127, \"@OY2\": 128, \"@P\": 129, \"@R\": 130, \"@S\": 131, \"@SH\": 132, \"@T\": 133, \"@TH\": 134, \"@UH\": 135, \"@UH0\": 136, \"@UH1\": 137, \"@UH2\": 138, \"@UW\": 139, \"@UW0\": 140, \"@UW1\": 141, \"@UW2\": 142, \"@V\": 143, \"@W\": 144, \"@Y\": 145, \"@Z\": 146, \"@ZH\": 147, \"eos\": 148}\r\n  l=[]\r\n  temp=''\r\n  for i in input_text.lower():\r\n    if i== ' ' :\r\n      if temp!=' ':\r\n        l.append(a[i])\r\n    else:\r\n      l.append(a[i])\r\n    temp=i\r\n\r\n  l.append(148) \r\n  \r\n\r\n  interpreter.resize_tensor_input(input_details[0]['index'], \r\n                                  [1, len(l)])\r\n  interpreter.resize_tensor_input(input_details[1]['index'], \r\n                                  [1])\r\n  interpreter.resize_tensor_input(input_details[2]['index'], \r\n                                  [1])\r\n  interpreter.resize_tensor_input(input_details[3]['index'], \r\n                                  [1])\r\n  interpreter.resize_tensor_input(input_details[4]['index'], \r\n                                  [1])\r\n  interpreter.allocate_tensors()\r\n  #input_data = fastspeech_prepare_input(l)\r\n  \r\n  #input_data = fastspeech_prepare_input(input_ids)\r\n\r\n  x=np.array(l, dtype=np.int32)\r\n  x.resize(1,len(x))\r\n  y=np.array([0],dtype=np.int32)\r\n  z=np.array([1.0],dtype=np.float32)\r\n  w=np.array([1.0],dtype=np.float32)\r\n  v=np.array([1.0],dtype=np.float32)\r\n\r\n  interpreter.set_tensor(0, x.astype(np.int32))\r\n  interpreter.set_tensor(1, y)\r\n  interpreter.set_tensor(2, z)\r\n  interpreter.set_tensor(3, w)\r\n  interpreter.set_tensor(4,v)\r\n\r\n\r\n\r\n\r\n  interpreter.invoke()\r\n\r\n  # The function `get_tensor()` returns a copy of the tensor data.\r\n  # Use `tensor()` in order to get a pointer to the tensor.\r\n  return (interpreter.get_tensor(output_details[0]['index']),\r\n          interpreter.get_tensor(output_details[1]['index']))\r\n  \r\ndef run_melgan(mel_spec, quantization):\r\n    model_name = f'melgan_{quantization}.tflite'\r\n    \r\n    feats = np.expand_dims(mel_spec, 0)\r\n    interpreter = tt.Interpreter(model_path=model_name)\r\n\r\n    input_details = interpreter.get_input_details()\r\n\r\n    output_details = interpreter.get_output_details()\r\n\r\n    interpreter.resize_tensor_input(input_details[0]['index'],  [1, feats.shape[1], feats.shape[2]], strict=True)\r\n    interpreter.allocate_tensors()\r\n\r\n    interpreter.set_tensor(input_details[0]['index'], feats)\r\n\r\n    interpreter.invoke()\r\n\r\n    output = interpreter.get_tensor(output_details[0]['index'])\r\n    \r\n    return output\r\n\r\ntext =  \"Hello how are you my name is text to speech \"    \r\n_, tac_output = fastspeech_infer('fastspeech_quant.tflite', text)\r\ntac_output = np.squeeze(tac_output)\r\nsample_rate = 22050\r\n\r\nwaveform = run_melgan(tac_output, 'float16')\r\nwaveform = np.squeeze(waveform)\r\n\r\nIPython.display.display(IPython.display.Audio(waveform, rate=sample_rate))\r\n\r\n\r\n\r\n```\r\n\r\n**Output**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n[<ipython-input-3-6c23683cd482>](https://localhost:8080/#) in <module>()\r\n     91 \r\n     92 text =  \"Hello how are you my name is text to speech \"\r\n---> 93 _, tac_output = fastspeech_infer('fastspeech_quant.tflite', text)\r\n     94 tac_output = np.squeeze(tac_output)\r\n     95 sample_rate = 22050\r\n\r\n1 frames\r\n[<ipython-input-3-6c23683cd482>](https://localhost:8080/#) in fastspeech_infer(tflite_model_path, input_text)\r\n     62 \r\n     63 \r\n---> 64   interpreter.invoke()\r\n     65 \r\n     66   # The function `get_tensor()` returns a copy of the tensor data.\r\n\r\n[/usr/local/lib/python3.7/dist-packages/tflite_runtime/interpreter.py](https://localhost:8080/#) in invoke(self)\r\n    921     \"\"\"\r\n    922     self._ensure_safe()\r\n--> 923     self._interpreter.Invoke()\r\n    924 \r\n    925   def reset_all_variables(self):\r\n\r\nRuntimeError: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding \"org.tensorflow:tensorflow-lite-select-tf-ops\" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_selectNode number 456 (FlexRandomUniform) failed to prepare.\r\n```\r\n\r\nPlease do help me out to solve this error.\r\n", "comments": ["Hi @jeevan-revaneppa-hirethanad ! Can you try again with [tf.lite.interpreter api](https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter)  and [TFliteconverter](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) api  for getting inference from the respective tflite model ? You can specify  target_spec.supported_ops as mentioned in this [thread](https://www.tensorflow.org/lite/guide/ops_select#convert_a_model) to convert the model further.You  can also update the [dependencies](https://www.tensorflow.org/lite/guide/ops_select#android_aar) in build.gradle file if you wanted use in any android app. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54321\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54321\">No</a>\n"]}, {"number": 54320, "title": "[bugfix] Use std::set::lower_bound instead of std::lower_bound for improved performance", "body": "Using std::set::lower_bound has a logarithmic (O(log2N)) complexity while using std::lower_bound have a linear (O(n)). Thus, it is preferable to use std::set::lower_bound.\r\n\r\nSource:\r\n* cpp reference: [std::set::lower_bound](https://en.cppreference.com/w/cpp/algorithm/lower_bound)\r\n* cpp reference: [std::lower_bound](https://en.cppreference.com/w/cpp/container/set/lower_bound)\r\n* https://www.geeksforgeeks.org/difference-between-stdsetlower_bound-and-stdlower_bound-in-c/", "comments": []}, {"number": 54318, "title": "`tf.compat.v1.layers.AveragePooling3D` lack support for float64", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\npool_size = [3,3,3]\r\nstrides = 2\r\npadding = \"valid\"\r\nx = tf.random.uniform([1, 11, 12, 10, 4], dtype=tf.float64)\r\nprint(tf.compat.v1.layers.AveragePooling3D(pool_size,strides,padding=padding,)(x))\r\n```\r\nthrows \r\n```\r\nNotFoundError: Exception encountered when calling layer \"average_pooling3d\" (type AveragePooling3D).\r\n\r\nCould not find device for node: {{node AvgPool3D}} = AvgPool3D[T=DT_DOUBLE, data_format=\"NDHWC\", ksize=[1, 3, 3, 3, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1]]\r\nAll kernels registered for op AvgPool3D:\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_FLOAT]\r\n [Op:AvgPool3D]\r\n```\r\n\r\n**Expected output**\r\n`tf.compat.v1.layers.AveragePooling3D` should be able to accept a `float64` input.", "comments": ["@ArrowIntoTheSky` tf.compat.v1.layers.AveragePooling3D` API was designed for TensorFlow v1, please have a look at [this](https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/AveragePooling3D) link . TF v1.x is not actively supported so we recommend you to rewrite the code using native TF v2 API.Please refer this migration [guide](https://www.tensorflow.org/guide/migrate) to migrate rest of your code.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54318\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54318\">No</a>\n"]}, {"number": 54317, "title": "`tf.math.asin` lack support for complex", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nx = tf.complex(tf.random.uniform([4], dtype=tf.float64),tf.random.uniform([4], dtype=tf.float64))\r\nprint(tf.math.asin(x))\r\n# Could not find device for node: {{node Asin}} = Asin[T=DT_COMPLEX128]\r\n```\r\n\r\n**Expected output**\r\nAccording to the document [tf.math.asin](https://www.tensorflow.org/api_docs/python/tf/math/asin), it should be able to accept a complex input.", "comments": ["@chunduriv ,\r\nI was able to reproduce the issue in tf v2.7, v2.8 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/e984b885c1efc3c9cc06b3659914c4da/54317.ipynb).", "Added a PR #54356 for the complex support of tf.math.asin.", "@ArrowIntoTheSky, The issue will move to closed status once the https://github.com/tensorflow/tensorflow/pull/54356 is merged. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54317\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54317\">No</a>\n"]}]