[{"number": 12153, "title": "Branch 164739939", "body": "", "comments": ["@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "This passed earlier with only known flakes failing. I'll merge this to fix flaky macOS test."]}, {"number": 12152, "title": "Fixing an issue with merge back with rc2.", "body": "", "comments": ["@tensorflow-jenkins test this please", "@av8ramit sorry, closed by mistake."]}, {"number": 12151, "title": "Fix Windows Linking error", "body": "Fix https://github.com/tensorflow/tensorflow/issues/12117\r\n\r\n`stringpiece.cc` is only the src of `lib_internal`, so we have to add it as a dependency.\r\n@gunan @learyg", "comments": ["@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @andrewharp, @drpngx and @tensorflower-gardener to be potential reviewers.", "Testing at http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/35/console", "Jenkins, test this please.", "the failure is due to sanity checks failing.\r\nHere is the log:\r\n\r\n```\r\nRunning do_buildifier on 213 files\r\n\r\ntensorflow/tools/proto_text/BUILD # listsort unsafesort sort:cc_binary.deps\r\n\r\nbuildifier took 0 s\r\n\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n37d36\r\n<         \"//tensorflow/core:lib_proto_parsing\",\r\n38a38\r\n>         \"//tensorflow/core:lib_proto_parsing\",\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```", "@meteorcloudy  You may remove core:lib_proto_parsing\r\n\r\n```diff\r\n--- a/tensorflow/tools/proto_text/BUILD\r\n+++ b/tensorflow/tools/proto_text/BUILD\r\n@@ -34,7 +34,7 @@ cc_binary(\r\n\t visibility = [\"//tensorflow:internal\"],\r\n\t deps = [\r\n\t\t \":gen_proto_text_functions_lib\",\r\n-        \"//tensorflow/core:lib_proto_parsing\",\r\n+        \"//tensorflow/core:lib_internal\",\r\n\t ],\r\n )\r\n\r\n@@ -60,7 +60,7 @@ cc_library(\r\n\t\t ],\r\n\t }),\r\n\t deps = [\r\n-        \"//tensorflow/core:lib_proto_parsing\",\r\n+        \"//tensorflow/core:lib_internal\",\r\n\t ],\r\n )\r\n```", "Looks like the build is fixed!\r\nThe test failures at http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/35/console is caused by a bug in Bazel.\r\nAlready filed https://github.com/bazelbuild/bazel/issues/3531, I'll make sure the fix cherry-picked for 0.5.4", "Lint error is fixed. \\o/", "Thanks for the fix, and sorry for the breakage!", "@meteorcloudy I'm afraid that this creates a layering check violation internally. I'll have to roll it back.", "@rmlarsen I see, I'm fine with the rollback.\r\n\r\n@learyg Is it possible to implement vmodule without introducing `stringpiece` in [`logging.cc`](https://github.com/tensorflow/tensorflow/commit/072b0c9#diff-9c3ca4a8ed42c1c586aff410128f2ab0R17)?\r\n\r\nRelated change: https://github.com/tensorflow/tensorflow/commit/072b0c9", "@meteorcloudy Yes, we could define a hasher for use with the unordered map, that was the primary motivation for grabbing StringPiece (it already had one defined). I'm unfortunately AFK for the next few days, understand if you need to roll back in the meantime, might not be too hard to dupe a custom hasher into that translation unit though.", "@rmlarsen Looks like this change is not getting rollbacked? Is it OK to keep it like this way?\r\nOtherwise, @learyg do you mind implementing the hasher for unordered map to avoid include stringpiece?", "Hi,\r\n\r\nNow we get the same error for gen_proto_text_functions.exe. "]}, {"number": 12150, "title": "Unable to load saved model", "body": "I am facing similar issue but for GRU. I am using tensorflow  1.1.0 and I tried dumping the model in different ways: \r\na)          saver = tf.train.Saver(tf.global_variables())\r\n        model_exporter = exporter.Exporter(saver)\r\n\r\n        # Restore variables from training checkpoint\r\n        # TODO: This restores the most recent checkpoint, but if we use validation to counterract\r\n        #       over-fitting, we may want to restore an earlier checkpoint.\r\n        checkpoint = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\r\n        checkpoint_path = checkpoint.model_checkpoint_path\r\n        saver.restore(session, checkpoint_path)\r\n        log_info('Restored checkpoint at training epoch %d' % (int(checkpoint_path.split('-')[-1]) + 1))\r\n\r\n        # Initialise the model exporter and export the model\r\n        model_exporter.init(session.graph.as_graph_def(),\r\n                            named_graph_signatures = {\r\n                                'inputs': exporter.generic_signature(\r\n                                    { 'input': input_tensor,\r\n                                      'input_lengths': seq_length}),\r\n                                'outputs': exporter.generic_signature(\r\n                                    { 'outputs': decoded})})\r\n        if FLAGS.remove_export:\r\n            actual_export_dir = os.path.join(FLAGS.export_dir, '%08d' % FLAGS.export_version)\r\n            if os.path.isdir(actual_export_dir):\r\n                log_info('Removing old export')\r\n                shutil.rmtree(actual_FLAGS.export_dir)\r\n        try:\r\n            # Export serving model\r\n            model_exporter.export(FLAGS.export_dir, tf.constant(FLAGS.export_version), session)\r\n\r\n            # Export graph\r\n            input_graph_name = 'input_graph.pb'\r\n            tf.train.write_graph(session.graph, FLAGS.export_dir, input_graph_name, as_text=False)\r\n\r\n            # Freeze graph\r\n            input_graph_path = os.path.join(FLAGS.export_dir, input_graph_name)\r\n            input_saver_def_path = ''\r\n            input_binary = True\r\n            output_node_names = 'output_node'\r\n            restore_op_name = 'save/restore_all'\r\n            filename_tensor_name = 'save/Const:0'\r\n            output_graph_path = os.path.join(FLAGS.export_dir, 'output_graph.pb')\r\n            clear_devices = False\r\n            freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\r\n                                      input_binary, checkpoint_path, output_node_names,\r\n                                      restore_op_name, filename_tensor_name,\r\n                                      output_graph_path, clear_devices, '')\r\nb)          output_graph_def = graph_util.convert_variables_to_constants(session, session.graph.as_graph_def(), ['output_node'])\r\n        with gfile.FastGFile('./data/ldc93s1/output_graph2.pb', 'wb') as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n\r\nbut for both the dump I get the following error: -\r\n'rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/cond/rnn/while/multi_rnn_cell/cell_0/gru_cell/gates/r/strided_slice/_assign/RefEnter': Input tensor 'rnn/multi_rnn_cell/cell_0/gru_cell/gates/r/pop_mean:0' **Cannot convert a tensor of type float32 to an input of type float32_ref**\r\n\r\nAny solution so far? \r\nI followed the similar bug but that is specifically related to Batch norm #3628 . And what is the reason behind this??\r\n", "comments": ["Seems like this is a duplicate of the issue you mentioned: https://github.com/tensorflow/tensorflow/issues/3628\r\n\r\nSeems like there is some bug in freeze_graph that is causing this issue. Maybe you should add on to that bug with a proper stack trace to debug.", "I tried to storing the model from other method which doesn't use freeze_graph. Method mentioned in 'b point' in my original post. In that also I get the same error.", "same error here", "Hello all, just follow the below video and export your own model with in a 10 seconds\r\n\r\nhttps://youtu.be/w0Ebsbz7HYA"]}, {"number": 12149, "title": "Update estimator.py", "body": "Replace summary_io.SummaryWriterCache for tf.summary.FileWriterCache", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 12148, "title": "Tensorflow Experiment shape mismatch between train set and test set", "body": "Hi guys,\r\n\r\nI am not sure if this is a bug or my mistake but it looks like when the experiment evaluates with the testing set it expects it to be of the same shape as the training set.\r\n\r\nFirst let me show you how I feed the experiment with the train set and eval set:\r\n\r\n```\r\ndef input_fun(data):\r\n        x, y = data\r\n        x, y = np.reshape(x,(1, -1, n_inputs)), np.reshape(y,(1, -1, n_outputs))\r\n        return tf.constant(x, dtype = tf.float32), tf.constant(y, dtype = tf.float32)\r\n\r\n    def get_train_inputs():\r\n        return input_fun(train_set)\r\n\r\n    def get_test_inputs():\r\n        return input_fun(test_set)\r\n```\r\n\r\nwhen I print my train set and eval set, I have :\r\n   \r\n> (<tf.Tensor 'Const_22:0' shape=(1, 1000, 1) dtype=float32>, <tf.Tensor 'Const_23:0' shape=(1, 1000, 1) dtype=float32>)\r\n>     (<tf.Tensor 'Const_24:0' shape=(1, 100, 1) dtype=float32>, <tf.Tensor 'Const_25:0' shape=(1, 100, 1) dtype=float32>)\r\n\r\nThen I build my model: \r\n\r\n```\r\ndef model_fn(x, y, mode, params):\r\n       predict = prediction(x)\r\n       loss = None\r\n       train_op = None\r\n       eval_metric_ops = None\r\n    \r\n       if mode == learn.ModeKeys.TRAIN or mode == learn.ModeKeys.EVAL:\r\n          loss = model_loss(y, predict, mode)\r\n          #eval_metric_ops = { \"rmse\":tf.metrics.root_mean_squared_error(tf.cast(y,tf.float32), predict) }\r\n    \r\n       if mode == learn.ModeKeys.TRAIN:\r\n          global_step = tf.train.get_global_step()\r\n          #train_op = model_train_op(loss, params['learning_rate'], global_step, mode)\r\n    \r\n          learning_rate = tf.train.exponential_decay(learning_rate = params[\"learning_rate\"], \r\n                                                  global_step = tf.contrib.framework.get_global_step(), \r\n                                                  decay_steps = 20, \r\n                                                  decay_rate = 0.96, \r\n                                                  staircase = True)\r\n\r\n           train_op = tf.contrib.layers.optimize_loss(loss = loss,\r\n                                              global_step = tf.contrib.framework.get_global_step(),\r\n                                              learning_rate = learning_rate,\r\n                                              optimizer = \"Adam\")\r\n    \r\n       predictions = {\"predictions\": predict}\r\n    \r\n       return model_fn_lib.ModelFnOps(\r\n          mode = mode, \r\n          predictions = predictions,\r\n          loss = loss, \r\n          train_op = train_op,\r\n       )\r\n```\r\n\r\nThen I define the experiment:\r\n\r\n```\r\ndef experiment_fn(output_dir):\r\n        model_params = {'learning_rate': 0.01}\r\n        trainingConfig = tf.contrib.learn.RunConfig(save_checkpoints_steps = 4, save_summary_steps = 2)\r\n        export_strategy = saved_model_export_utils.make_export_strategy(serving_input_fn=serving_input_fn, exports_to_keep=None)\r\n        hooks = [\r\n            #tf.train.LoggingTensorHook({'loss'}, every_n_iter = 2),\r\n            tf.train.StepCounterHook(every_n_steps = 2, output_dir = output_dir),\r\n            tf.train.CheckpointSaverHook(output_dir, save_steps = 10, checkpoint_basename = 'model.ckpt'),\r\n            tf.train.SummarySaverHook(\r\n                save_steps = 10, \r\n                output_dir = output_dir, \r\n                #summary_op = ['loss'],\r\n                scaffold= tf.train.Scaffold(),\r\n                summary_op=tf.summary.merge_all()\r\n            )\r\n        ]\r\n        return learn.Experiment(\r\n            estimator = learn.Estimator(model_fn = model_fn, \r\n                                params = model_params, \r\n                                model_dir = output_dir, \r\n                                config = trainingConfig),\r\n            train_input_fn = get_train_inputs,\r\n            eval_input_fn = get_test_inputs,\r\n            #eval_metrics = model_eval_metrics(),\r\n            train_steps = 100,\r\n            #train_monitors = hooks,\r\n            eval_hooks = hooks,\r\n            export_strategies = export_strategy\r\n        )\r\n```\r\n\r\nEventually I run this line:\r\n\r\n ```\r\nlearn_runner.run(experiment_fn = experiment_fn, \r\n                     output_dir = outdir)\r\n```\r\n\r\nThe results are as followed:\r\n\r\n> Monitors are deprecated. Please use tf.train.SessionRunHook.\r\n>     INFO:tensorflow:Create CheckpointSaverHook.\r\n>     INFO:tensorflow:Saving checkpoints for 1 into .\\model.ckpt.\r\n>     INFO:tensorflow:step = 1, loss = 0.043889\r\n\r\n\r\nIt works fine for the training set, but when it evaluates on the test set I get the following error:\r\n\r\n> ValueError: Features are incompatible with given information. Given features: Tensor(\"Const:0\", shape=(1, 100, 1), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(1), Dimension(1000), Dimension(1)]), is_sparse=False).\r\n\r\nDo you know where it comes from ?\r\n\r\nThanks!", "comments": ["I think that is mostly the problem... the shapes need to be the same.. Usually the train_input_fn and eval_input_fn return a batch_size full of data to process. Look into methods like https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py#L434 (and more methods in that file).", "@nikky78 Were you able to resolve the error? I am experiencing the same issue with `tf.contrib.learn.DNNRegressor()`. `tf.contrib.learn.DNNRegressor.evaluation()` works fine, but the error appears when using `tf.contrib.learn.monitors.ValidationMonitor()` and at its first evaluation step.", "Based on this SO [answer](https://stackoverflow.com/questions/44937001/feature-are-incompatible-with-given-information-in-evaluate-using-tf-contrib-l), I was able to resolve the error. When using `input_fn` in `ValidaitonMonitor()`, `fit()`, and `evaluate()`, features needed to be passed as a dictionary with the same key. That key also needed to specified in `tf.contrib.layers.real_valued_column()`. Here is a reproducible example:\r\n\r\n```\r\nimport numpy as np\r\nfrom sklearn.cross_validation import train_test_split\r\nimport tensorflow as tf\r\nimport logging\r\n\r\nlogging.getLogger().setLevel(logging.INFO)\r\n\r\nn = 200\r\nx = np.array(range(n), dtype=np.float32)/(n/10)\r\nx = x[:,np.newaxis]\r\ny = np.sin(x.squeeze()) + np.random.normal(0, 0.5, n)\r\n\r\nx_train, x_test, y_train, y_test = train_test_split(y, y,\r\n                                                    train_size=0.8,\r\n                                                    test_size=0.2)\r\n\r\ndef get_inputs_for_fit(x, y):\r\n    x = {'x': tf.constant(x)}\r\n    y = tf.constant(y)\r\n    return x, y\r\n\r\nfeature_columns = [tf.contrib.layers.real_valued_column('x', dimension=1)]\r\n\r\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\r\n    input_fn=lambda: get_inputs_for_fit(x_test, y_test),\r\n    every_n_steps=50,\r\n    eval_steps=1)\r\n\r\nregressor = tf.contrib.learn.DNNRegressor(\r\n    feature_columns=feature_columns,\r\n    hidden_units=[10, 20, 10],\r\n    config=tf.contrib.learn.RunConfig(save_checkpoints_steps=validation_monitor._every_n_steps))\r\n\r\nregressor.fit(\r\n    input_fn=lambda: get_inputs_for_fit(x_train, y_train),\r\n    steps=2000,\r\n    monitors=[validation_monitor])\r\n\r\nprint regressor.evaluate(input_fn=lambda: get_inputs_for_fit(x_test, y_test),\r\n    steps=1)\r\n```", "How do I split the dataset into batches in this case?"]}, {"number": 12147, "title": "EigenAllocator for GPU ran out of memory when allocating 0 ", "body": "Environment info\r\n\r\nOperating System: Ubuntu 16.04\r\nInstalled version of CUDA and cuDNN: CUDA-8.0, CUDNN 5.1.10\r\nTensorflow version r1.1\r\n\r\nHello, does anyone encountered this error ?\r\n\r\nAfter some random number of iterations, i'm getting the below exception. Can anyone help me where its going wrong?\r\n\r\n: E tensorflow/core/common_runtime/bfc_allocator.cc:244] tried to allocate 0 bytes\r\n: W tensorflow/core/common_runtime/allocator_retry.cc:32] Request to allocate 0 bytes\r\n: F tensorflow/core/common_runtime/gpu/gpu_device.cc:103] EigenAllocator for GPU ran out of memory when allocating 0. See error logs for more detailed info.\r\nAborted (core dumped)\r\n\r\nRegards,\r\nSharath", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nAlso note #492 has some extra info that may be interesting to you.  I found that via the following search:\r\nhttps://github.com/issues?utf8=%E2%9C%93&q=repo%3Atensorflow%2Ftensorflow+%22EigenAllocator+for+GPU+ran+out+of+memory%22"]}, {"number": 12146, "title": "[OpenCL] Extends BiasAdd to cover integral types", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 12145, "title": "Fix broken URL in `tensorflow/java/README.md`", "body": "Fixes broken URL in `tensorflow/java/README.md`, this fix fixes #12141.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @asimshankar, @tensorflower-gardener and @andrewharp to be potential reviewers."]}, {"number": 12144, "title": "[OpenCL] Fixes linking issue", "body": "c13cb2e5777852c6a498410669b24ac346114eba introduced linking issue that caused\r\n\r\nlogging.cc:(.text+0xa64): undefined reference to\r\n`tensorflow::StringPiece::Hasher::operator()(tensorflow::StringPiece) const'", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Windows failure is an unrelated infra flake. OK to merge if that is the only issue."]}, {"number": 12143, "title": "const variable placement issue in distributed tensorflow", "body": "### Describe the problem\r\nIn my model, I use the FTRL Optimizer like below:\r\n\r\n`self.optimizer = tf.train.FtrlOptimizer(0.005,\r\n                learning_rate_power=-0.5,\r\n                initial_accumulator_value=0.1,\r\n                l1_regularization_strength=1.0,\r\n                l2_regularization_strength=0.00001)\r\n`\r\n\r\nInside the FtrlOptimizer it will create several const variables for the parameters, such as learning rate, learning rate power, etc. \r\n\r\nWhen I run the distributed tensorflow job, from the timeline I can see that for each session run I can see that the worker will send the above const variables to all the ps nodes. This is a cost since the variables are const and not needed to sent to ps nodes repeatedly.  \r\n\r\nI was wondering is there a way to pin those const variables to the ps and save the transferring cost during each session run.\r\n\r\nThanks.\r\n", "comments": ["@suharshs Do you have any suggestions here?", "(I think @prb12 might be interested in a solution to this as well....)", "By 'const variable' (!!), do you mean that the `FtrlOptimizer` creates a `tf.Variable` for learning rate, that is placed on the PS, and is read each step even though the value of that variable never changes?  (I could imagine this would be useful if you ever wanted an adjustable learning rate schedule)\r\n\r\nOr... does this produce a `Const` op that is placed on the PS and used on each worker, and the graph partitioner doesn't create a duplicate const on `/cpu:0` of the worker?\r\n\r\nAttaching a `GraphDef` would be helpful...", "FtrlOptimizer create several const variable such as learning rate, learning rate power, etc, placing at each worker side.\r\n\r\nYou can see these information when you enabled the variable placement configuration.\r\n```\r\nwith sv.managed_session(server.target, config = tf.ConfigProto(log_device_placement=True)) as sess:\r\n```\r\n\r\nThen you will see below information.\r\n```\r\nFtrl/learning_rate_power: (Const): /job:worker/replica:0/task:0/cpu:0\r\nFtrl/l2_regularization_strength: (Const): /job:worker/replica:0/task:0/cpu:0\r\nFtrl/l1_regularization_strength: (Const): /job:worker/replica:0/task:0/cpu:0\r\nFtrl/learning_rate: (Const): /job:worker/replica:0/task:0/cpu:0\r\n```\r\n\r\nThen during each session run, I can see that the request from the each ps asking the read of the above variables. I added several logs in the code.\r\n```\r\n3317063:2017-08-10 09:01:01.577890: I tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:241] RecvTensorHandlerRaw step_id:127424566250596053  and key:/job:worker/replica:0/task:0/cpu:0;3df08c8c86dccc7c;/job:ps/replica:0/task:3/cpu:0;edge_2045_Ftrl/learning_rate;0:0\r\n```\r\n\r\n@prb12 I wish I can place these const variables in the ps nodes, but i don't know how. and in the meantime each ps will need these const variables to apply the gradients. \r\n", "@YongCHN as a side-comment -- it sounds like you are dealing with Const nodes (there are also Variable nodes which would be different). I recall seeing Const nodes being cached on devices (ie, fetching same Const by GPU several times would only transfer once), it seems like an omission if they aren't cached by distributed workers.", "@yaroslavvb yes, i am dealing with the Const nodes and I need them be cached in the distributed ps nodes, instead of worker side since these const variables are actually used in the ps nodes.", "Anyone help take a look?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "@YongCHN Is this still an issue for you?  Have you tried on the latest TensorFlow release?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 12142, "title": "Update README.md", "body": "Fixed Stale URL in Tutorial Link.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 12141, "title": "Link to Linux and Mac OS broken in TF for Java README", "body": "The link to `Linux `and `Mac OS` under section [Building from Source](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md#building-from-source) is broken. ", "comments": ["The Linux should point to:\r\nhttps://www.tensorflow.org/install/install_sources#PrepareLinux\r\n\r\nAdded a PR #12145 for the fix."]}, {"number": 12140, "title": "[XLA] Assert when running XLA unit test", "body": "If I run the test //tensorflow/compiler/xla/tests:tuple_test_cpu with a VLOG level of >=2 , then I receive the following assert:\r\n\r\n```\r\nCheck failed: current_id >= 0 (-1 vs. 0)-1: 0x7ff6b960bd60: instruction may not have parent computation\r\n```\r\n\r\nI don't think that this is due to any changes that I have in my own repo.\r\n\r\n", "comments": ["An internal change went in a couple days ago which fixes this issue. To verify I repro'd the problem with the change rolledback. And I see it landed in the repo with f431494. Let me know if you still run into the problem. Closing speculatively."]}, {"number": 12139, "title": "Build error with Tensorflow 1.3.0 and cuDNN 7.0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux - Arch Linux\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.5.3 for Arch Linux\r\n- **CUDA/cuDNN version**: CUDA: 8.0.61, cuDNN: 7.0.1\r\n- **GPU model and memory**: NVIDIA GeForce GTX 960M\r\n- **Exact command to reproduce**: bazel build --config=opt --config=mkl --config=cuda //tensorflow/tools/pip_package:build_pip_package \r\n\r\n### Describe the problem\r\nI can't build tensorflow from source with cuDNN 7, as it throws an error pertaining to cuDNN. I'm currently using a tensorflow 1.2.1 built earlier from sources using cuDNN 6.\r\n\r\n### Source code / logs\r\n```\r\nERROR: /home/rharish/Data/tensorflow/tensorflow/stream_executor/BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1).\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'cudnnStatus_t perftools::gputools::cuda::wrap::WrapperShim__cudnnSetRNNDescriptor::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...) [with Args = {cudnnRNNStruct*, int, int, cudnnDropoutStruct*, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t}]':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1017:50:   required from here\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:139:38: error: cannot convert 'cudnnRNNStruct*' to 'cudnnHandle_t {aka cudnnContext*}' for argument '1' to 'cudnnStatus_t cudnnSetRNNDescriptor(cudnnHandle_t, cudnnRNNDescriptor_t, int, int, cudnnDropoutDescriptor_t, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnRNNAlgo_t, cudnnDataType_t)'\r\n       cudnnStatus_t retval = ::__name(args...);                    \\\r\n                                      ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:233:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'\r\n   __macro(cudnnSetRNNDescriptor)                              \\\r\n   ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:238:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R5'\r\n CUDNN_DNN_ROUTINE_EACH_R5(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)\r\n ^\r\nIn file included from tensorflow/stream_executor/cuda/cuda_dnn.cc:42:0:\r\nbazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda/cuda/include/cudnn.h:1553:8: note: class type 'cudnnRNNStruct' is incomplete\r\n struct cudnnRNNStruct;\r\n        ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'int perftools::gputools::cuda::{anonymous}::CudnnDataTypeToByteSize(cudnnDataType_t)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:858:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'int perftools::gputools::cuda::CudnnRnnParamsDescriptor::GetRegionCountPerLayer() const':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1200:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnRNNInputMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnInputMode(perftools::gputools::dnn::RnnInputMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:821:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnDirectionMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnDirectionMode(perftools::gputools::dnn::RnnDirectionMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:833:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnRNNMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnMode(perftools::gputools::dnn::RnnMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:845:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnDataType_t perftools::gputools::cuda::{anonymous}::ToCudnnDataType(perftools::gputools::dnn::DataType, perftools::gputools::dnn::DataLayout)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:809:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmType)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:283:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmType)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:305:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdFilterAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardFilterAlgo(perftools::gputools::dnn::AlgorithmType)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:327:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: At global scope:\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:128:26: warning: 'tensorflow::thread::ThreadPool* perftools::gputools::cuda::wrap::GetCudaThreadpool()' defined but not used [-Wunused-function]\r\n static port::ThreadPool* GetCudaThreadpool() {\r\n                          ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```", "comments": ["Please see and update #12052 for the cuDNN 7 status\r\n"]}, {"number": 12138, "title": "Fix sparse_matmul_op_test on Power LE", "body": "Fix for issue #12137. Add the pbroadcast_* functions for ppc, this passes the sparse_matmul_op_test on ppc64le", "comments": ["Can one of the admins verify this patch?", "@vaibhavsood, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @benoitsteiner and @namrata-ibm to be potential reviewers.", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 12137, "title": "sparse_matmul_op_test fails on ppc64le", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL/SLES ppc64le\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 2.7.5\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: bazel test  --test_output=errors //tensorflow/core/kernels:sparse_matmul_op_test\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nTest fails since the pbroadcast_* functions in tensorflow/core/kernels/sparse_matmul_op.h are not implemented for PowerPC (has SSE versions), resulting in incorrect values received by BroadcastPacketTest function in the test case code (tensorflow/core/kernels/sparse_matmul_op_test.cc) , log of failure in below section\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nINFO: From Testing //tensorflow/core/kernels:sparse_matmul_op_test:\r\n==================== Test output for //tensorflow/core/kernels:sparse_matmul_op_test:\r\nRunning main() from test_main.cc\r\n[==========] Running 4 tests from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 4 tests from SparseMatmulOpTest\r\n[ RUN      ] SparseMatmulOpTest.BroadcastPacketTest\r\n[0.170094 0.170094 0.170094 0.170094] != [  0.170094    0.14922 -0.0823886   0.026985], differences: [         0 -0.0208738  -0.252482  -0.143109]\r\ntensorflow/core/kernels/sparse_matmul_op_test.cc:257: Failure\r\nValue of: areApprox(ref, data2, PacketSize)\r\n  Actual: false\r\nExpected: true\r\n[  FAILED  ] SparseMatmulOpTest.BroadcastPacketTest (1 ms)\r\n[ RUN      ] SparseMatmulOpTest.InterleavePacketTest\r\n[       OK ] SparseMatmulOpTest.InterleavePacketTest (0 ms)\r\n[ RUN      ] SparseMatmulOpTest.Bfloat16ExpandTest\r\n[       OK ] SparseMatmulOpTest.Bfloat16ExpandTest (0 ms)\r\n[ RUN      ] SparseMatmulOpTest.Bfloat16LoadTest\r\n[       OK ] SparseMatmulOpTest.Bfloat16LoadTest (0 ms)\r\n[----------] 4 tests from SparseMatmulOpTest (1 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 4 tests from 1 test case ran. (1 ms total)\r\n[  PASSED  ] 3 tests.\r\n[  FAILED  ] 1 test, listed below:\r\n[  FAILED  ] SparseMatmulOpTest.BroadcastPacketTest\r\n\r\n 1 FAILED TEST\r\n================================================================================\r\nTarget //tensorflow/core/kernels:sparse_matmul_op_test up-to-date:\r\n  bazel-bin/tensorflow/core/kernels/sparse_matmul_op_test\r\nINFO: Elapsed time: 14.711s, Critical Path: 14.07s\r\n//tensorflow/core/kernels:sparse_matmul_op_test                          FAILED in 1 out of 2 in 0.0s\r\n  /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/testlogs/tensorflow/core/kernels/sparse_matmul_op_test/test.log\r\n\r\nExecuted 1 out of 1 test: 1 fails locally.", "comments": ["@vaibhavsood Thanks for filing the issue and the PR!  I'm marking this as contributions welcome, and we'll close this out once your PR gets merged.", "Thanks!"]}, {"number": 12136, "title": "Quantize_training_test fails with matmul operation on Ubuntu 16.04", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**:  'v1.2.1-0-gb4957ff', '1.2.1'\r\n- **Python version**:  2.7.12\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: No GPU\r\n- **GPU model and memory**: No GPU\r\n- **Exact command to reproduce**: bazel test -c opt //tensorflow/python:quantize_training_test\r\n\r\n### The problem\r\nThe `testQuantizedSaveRestore` from  `//tensorflow/python:quantize_training_test` is failing on s390x while importing graph [here.](https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/python/training/quantize_training_test.py#L72) \r\n\r\nThe error message shown is : \r\n`ValueError: Shapes must be equal rank, but are 0 and 2 for 'a/Min/AssignValue' (op: 'Assign') with input shapes: [], [1,1].\r\n`\r\nThe check for this failure is at [Merge function](https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/core/framework/shape_inference.cc#L374) . This Merge is called by `Assign` Op kernel. \r\n\r\nI tried changing the `math_ops.matmul` operation from the above test to `math_ops.subtract/minimum/multiply`. With these operations the test passes after removing asserts for `'a/Min/Variable:0'` or `'b/read/Max/Variable:0'` etc. I suppose other operations do not create these tensors. \r\n\r\nCould anyone please provide some inputs on this failure? I am not aware about the computations that are happening when graph is imported with the `matmul` operation.\r\n\r\n### Source code / logs\r\n```\r\n.E.\r\n======================================================================\r\nERROR: testQuantizedSaveRestore (__main__.PywrapQuantizeTrainingTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/quantize_training_test.runfiles/org_tensorflow/tensorflow/python/training/quantize_training_test.py\", line 73, in testQuantizedSaveRestore\r\n    _ = importer.import_graph_def(result, name='')\r\n  File \"/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/quantize_training_test.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 409, in import_graph_def\r\n    ops.set_shapes_for_outputs(op)\r\n  File \"/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/quantize_training_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/quantize_training_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/quantize_training_test.runfiles/org_tensorflow/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/quantize_training_test.runfiles/org_tensorflow/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shapes must be equal rank, but are 0 and 2 for 'a/Min/AssignValue' (op: 'Assign') with input shapes: [], [1,1].\r\n```\r\n", "comments": ["Could you please provide more information about what exactly you are running? What steps should we follow to reproduce?", "@ali01, I m running : `bazel test -c opt //tensorflow/python:quantize_training_test`.\r\nAs per above log, ` testQuantizedSaveRestore` fails with error `Shapes must be equal rank, but are 0 and 2 for 'a/Min/AssignValue' (op: 'Assign') with input shapes: [], [1,1].`\r\n\r\nI tried printing the graph_def object in `tensorflow/python/framework/importer.py`. It is similar to x86:\r\n\r\n```\r\n(Pdb) p graph_def\r\nnode {\r\n  name: \"save/RestoreV2/shape_and_slices\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_STRING\r\n        tensor_shape {\r\n          dim {\r\n            size: 1\r\n          }\r\n        }\r\n        string_val: \"\"\r\n      }\r\n    }\r\n  }\r\n}\r\n.\r\n.\r\nnode {\r\n  name: \"save/restore_all\"\r\n  op: \"NoOp\"\r\n  input: \"^save/Assign\"\r\n  input: \"^save/Assign/_1\"\r\n  input: \"^save/Assign/_3\"\r\n  input: \"^save/Assign/_5\"\r\n  input: \"^save/Assign/_7\"\r\n}\r\n.\r\n.\r\nlibrary {\r\n}\r\nversions {\r\n  producer: 22\r\n}\r\n\r\n```\r\n\r\nSo I further printed 2 things:\r\n1.  `ops` in [importer.py](https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/python/framework/importer.py#L407)\r\nusing:   \r\n```\r\n+        print(\"op.type:\", op.type)\r\n         ops.set_shapes_for_outputs(op)\r\n```\r\n\r\n \r\n 2.  rank in [shape_inference.cc](https://github.com/tensorflow/tensorflow/blob/v1.2.1/tensorflow/core/framework/shape_inference.cc#L371) using\r\n```\r\n+  printf(\"\\nRank(s0):%d\\n\", Rank(s0));\r\n+  printf(\"Rank(s1):%d\\n\", Rank(s1));\r\n```\r\n\r\n which gives:\r\n\r\n```\r\nop.type: Const\r\nop.type: Const\r\nop.type: Const\r\nop.type: Const\r\nop.type: Const\r\nop.type: RestoreV2\r\nRank(s0):1\r\nRank(s1):1\r\n\r\nop.type: VariableV2\r\nop.type: Assign\r\nop.type: NoOp\r\nop.type: Identity\r\nop.type: Identity\r\nop.type: Const\r\nop.type: Assign\r\nRank(s0):2\r\nRank(s1):2\r\n\r\nop.type: NoOp\r\nop.type: Const\r\nop.type: MatMul\r\nop.type: Const\r\nop.type: Const\r\nop.type: Const\r\nop.type: Rank\r\nop.type: Range\r\nop.type: Min\r\nop.type: Max\r\nop.type: VariableV2\r\nop.type: IsVariableInitialized\r\nop.type: Switch\r\nop.type: Const\r\nop.type: Sub\r\nop.type: Sub\r\nop.type: Mul\r\nop.type: Sub\r\nop.type: Merge\r\nop.type: Assign\r\nRank(s0):0\r\nRank(s1):2\r\n```\r\n\r\nAnd fails here while on x86, the ranks are both 0 at this point.\r\nSo I am unable to understand the exact root cause of this on s390x(which is big endian). Could you please provide inputs in understanding how the `matmul` operation works while importing a graph.", "This was related to the numpy bug and resolved by #12963.\r\nClosing this. "]}, {"number": 12135, "title": "tf.shape return wrong shape", "body": "I have a png image of shape `[128,128,3]` \r\n\r\n`tf.shape(r)` returns `Tensor(\"load_images/Shape:0\", shape=(3,), dtype=int32)`\r\n\r\nwhile `numpy.shape(r)` returns `(128, 128, 3)`\r\n\r\n**tensorflow 1.1.0**", "comments": ["Ok  I do not understand tf.shape return type as is also contradicts its tensorflow documentation but in my case problem was not arising from this so i am closing it"]}, {"number": 12134, "title": "Nudge function in fake quantization returns non-nudegd scale value ", "body": "The Nudge function(tensorflow/tensorflow/core/kernels/fake_quant_ops_functor.h) aims to keep the real zero value including in quantization input range. \r\nAfter min/max values are nudged, the scale keeps its original value. Is it intended to be?\r\n", "comments": ["@cwhipkey can you take a look at this?", "nudged min and nudged max are both adjusted by the same amount, so the scale should be the same - but I suppose arithmetic errors might make it so we should recompute the scale?\r\n\r\n@suharshs  can you take a look as well?", "The scale should be the same because the min and max will be nudged by the same amount based on the zero point. I am unaware of a case where arithmetic errors have caused issues with this. @passerbyd , did you have a specific example where the scale should change?", "I realized that this function is quite different with min/max adjust in quantizeV2 operator, which just modify one end of the range. nudge function modifies both ends together. So the fake_quantization makes a different value-mapping with quantize operator?", "@suharshs ping?", "@petewarden is the QuantizeV2 behavior supposed to correspond to the FakeQuantizeWithMinMaxVars functionality? If not, is this something we would want to add to QuantizeV2?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Closing since it's been a while. Feel free to reopen."]}, {"number": 12133, "title": "[Feature] [Java]: Inspect tensors in a Graph", "body": "Dear Tensorflow maintainers,\r\n\r\nFirst of all i really like it that tensorflow allows easy interop from keras to tensorflow and then allows for interference to Java.\r\n\r\nI have noticed that when you load an invalid graph, for example an empty byte array, then it will just accept it without giving an error. An exception will be thrown when we try to run the graph.\r\n\r\nThus i would propose two improvements for the tensorflow java API,\r\n* throw an exception when loading an invalide graph.\r\n* add api functionality to inspect the tensors contained in the graph\r\n\r\nI also noticed in the example for java that you wrapped the graph builder in a convenience java class and it seems that this could be implemented in a really clean way in scala, I would gladly offer you my assistance to implement a scala wrapper. \r\n\r\nKind regards, Boris", "comments": ["@asimshankar Can you comment on the suggestions from @borissmidt ?  Thanks!", "@borissmidt : Thanks for the notes. Some thoughts:\r\n\r\n- In general, `importGraphDef` will raise an exception when provided an invalid serialized `GraphDef` protocol message. It's just that the empty byte array is a valid serialization of an empty graph :). So I think it's working correctly for an empty graph. Are there invalid graphs for which you do not see an exception raised?\r\n\r\n- For the other two, yeah, that seems fine to add. Though, what kinds of inspection were you interested in? You can get tensors by name using something like [`Graph.operation(String name)`](https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/Graph.html#operation(java.lang.String)). If you'd want some form of graph traversal, that will require some implementation work, but the underlying C API does have the functions you need to build on (e.g., [`TF_OperationOutputConsumers`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/c/c_api.h#L601))\r\n\r\nWe (TensorFlow maintainters) will probably not get to it in the near future, but if anyone would like to contribute a PR, we'd be more than happy to take a look. Just please do outline the proposed additions to the Java API here first before sending the PR with the implementation :)\r\n\r\nThanks!", "@asimshankar \r\nThanks for noting me that there is a function named `Graph.operation(String name)`, it is really useful and it could be further improved with a function like `Graph.getOperations()` which returns a list of operations in the graph. This would allow us the inspect the graph directly and see if the correct one is loaded. \r\n\r\nI'm thinking about the empty graph behavior, since it seems like an odd thing to load an empty graph on purpose?\r\n\r\nI know this happened because of a simple bug in my code but it was just a bit hard to track with the current api. I loaded an empty graph :(. ", "@borissmidt So it sounds like you're asking for `List<Operation> getOperations ();` to be added to `org.tensorflow.Graph`\r\n\r\nWhich would entail, @asimshankar, (((i think, having looked at the code for the first time this morning))) additionally adding\r\n`private static native long[] allOperations(long handle);`\r\nto `Graph.java`\r\n\r\n`JNIEXPORT jlongArray JNICALL Java_org_tensorflow_Graph_allOperations(JNIEnv *, jclass, jlong);`\r\nto `graph_ini.h`\r\n\r\nIn the implementation of that in `graph_ini.cc`, we'd call a new function to be implemented in `c_api`, stubbed in the `.h` as\r\n`TF_CAPI_EXPORT extern void TF_GraphAllOperations(TF_Graph* graph, TF_Operation** operations);`\r\nand implemented in the `.cc` aggregating out of `graph->name_map`\r\n\r\nSound about right?\r\n", "Yes this would make it easier to analyze the graph that is loaded :)\n\nOn Aug 11, 2017 8:47 PM, \"loki der quaeler\" <notifications@github.com>\nwrote:\n\n> @borissmidt <https://github.com/borissmidt> So it sounds like you're\n> asking for List<Operation> getOperations (); to be added to\n> org.tensorflow.Graph\n>\n> Which would entail, @asimshankar <https://github.com/asimshankar>, (((i\n> think, having looked at the code for the first time this morning)))\n> additionally adding\n> private static native long[] allOperations(long handle);\n> to Graph.java\n>\n> JNIEXPORT jlongArray JNICALL Java_org_tensorflow_Graph_allOperations(JNIEnv\n> *, jclass, jlong);\n> to graph_ini.h\n>\n> In the implementation of that in graph_ini.cc, we'd call a new function\n> to be implemented in c_api, stubbed in the .h as\n> TF_CAPI_EXPORT extern void TF_GraphAllOperations(TF_Graph* graph,\n> TF_Operation** operations);\n> and implemented in the .cc aggregating out of graph->name_map\n>\n> Sound about right?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12133#issuecomment-321890077>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFt8ln-W_pAPDsY_4qdZPlJQRXSnzgyHks5sXKHOgaJpZM4OxyUY>\n> .\n>\n", "@borissmidt An iterator which provides this functionality has been merged into master. Please let me know if that suffices to close this issue!\r\n", "@quaeler Thank you very much, it works as expected and it is really useful to inspect if you are using the right input/outputs for interference or if you have loaded the correct model.\r\n\r\nSo thanks again for making the java api more flexible and easier to debug, i couldn't have done it myself.\r\n"]}, {"number": 12132, "title": "slim.separable_conv2d is too slow", "body": "------------------------\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom, yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: from pip\r\n- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')\r\n- **Python version**: python2.7\r\n- **Bazel version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: CPU version, no CUDA\r\n- **GPU model and memory**: CPU version, no CUDA\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nthe depthwise+pointwise structure is faster than the traditional convolution layer theoretically, but the implemetation of tensorflow make it slower. it doesn't make sense.\r\nhere is part of my network defination:\r\n#net = slim.conv2d(net, 32, [3, 3], scope='conv1-2')\r\n    #end_points['conv1-2'] = net\r\n    net = slim.separable_conv2d(net,None,[3,3],depth_multiplier=1,stride=1,rate=1,normalizer_fn=slim.batch_norm,scope='conv1-2-depthwise')\r\n    end_points['conv1-2-depthwise'] = net\r\n    net = slim.conv2d(net, depth(32), [1, 1], stride=1, normalizer_fn=slim.batch_norm, scope='conv1-2-pointwise')\r\n    end_points['conv1-2-pointwise'] = net\r\n\r\n    net = slim.max_pool2d(net, [2, 2], 2, scope='pool1')\r\n    end_points['pool1'] = net # 58*58\r\n\r\n    #net = slim.conv2d(net, 48, [3, 3], padding='VALID', scope='conv2')\r\n    #end_points['conv2'] = net\r\n    net = slim.separable_conv2d(net,None,[3,3],depth_multiplier=1,stride=1,rate=1,normalizer_fn=slim.batch_norm,scope='conv2-depthwise')\r\n    end_points['conv2-depthwise'] = net\r\n    net = slim.conv2d(net, depth(48), [1, 1], stride=1, normalizer_fn=slim.batch_norm, scope='conv2-pointwise')\r\n    end_points['conv2-pointwise'] = net\r\n\r\n    net = slim.max_pool2d(net, [2, 2], 2, scope='pool2')\r\n    end_points['pool2'] = net # 28*28\r\n\r\ni just change the network defination \r\nfrom: \r\nnet = slim.conv2d(net, 32, [3, 3], scope='conv1-2')\r\nend_points['conv1-2'] = net\r\nto:\r\nnet = slim.separable_conv2d(net,None,[3,3],depth_multiplier=1,stride=1,\r\n         rate=1,normalizer_fn=slim.batch_norm,scope='conv1-2-depthwise')\r\nend_points['conv1-2-depthwise'] = net\r\nnet = slim.conv2d(net, depth(32), [1, 1], stride=1, normalizer_fn=slim.batch_norm, \r\n         scope='conv1-2-pointwise')\r\nend_points['conv1-2-pointwise'] = net\r\ni do not think i am doing something wrong. so where the problem is?\r\n", "comments": ["I am also wondering why tf.nn.separable_conv2d is so slow compared to tf.nn.conv2d?\r\n\r\nI would expect the separable conv to be a lot faster when the channel multiplier is far smaller than the number of output channels? In reality, it is only slightly faster. Why is this? Is it because conv2d uses cudnn internally, whereas the seperable_conv2d does not? Or is there an other reason?", "@BKZero or @stengoes, can you give a full self-contained example to run that demonstrates the performance difference? In the example above, I do not know the initial value of `net`.", "@reedwm, the code below shows that the separable convolution (depthwise followed by pointwise) is pretty much useless. It is much more efficient in terms of time to compute the effective filters and use the normal convolution function (tf.nn.conv2d) instead of the seperable convolution.\r\n\r\nWith the settings below, one would expect the separable convolution to be much faster since it only needs to compute 32x8 convolutions heavy convolutions (15x15 filter size) and 32x8x64 light convolutions (1x1 filter size). Whereas the normal convolution needs to compute 32x64 heavy convolutions (15x15 filter size).\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n# Define a scenario\r\nbatch_size = 64\r\nchannels = 32\r\nimage_size = 32\r\nfeature_maps = 64\r\nfilter_size = 15\r\ndepthwise_filters = 8\r\n\r\n# Dummy images\r\nimages = tf.random_normal(shape=[batch_size, channels, image_size, image_size], \r\n                          dtype=tf.float32)\r\n\r\n# Filter definitions\r\nbasis_filters = tf.random_normal(shape=[filter_size, filter_size, channels, depthwise_filters], \r\n                                 dtype=tf.float32)\r\ncoeffs = tf.random_normal(shape=[channels, depthwise_filters, feature_maps], \r\n                          dtype=tf.float32)\r\n\r\n# Normal method\r\neffective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\nnormal = tf.nn.conv2d(images, \r\n                      effective_filters, \r\n                      strides=[1, 1, 1, 1], \r\n                      padding=\"SAME\", \r\n                      use_cudnn_on_gpu=True, \r\n                      data_format=\"NCHW\")\r\n\r\n# Separable method\r\ndepthwise = tf.nn.depthwise_conv2d_native(images, \r\n                                          basis_filters, \r\n                                          strides=[1, 1, 1, 1], \r\n                                          padding=\"SAME\", \r\n                                          data_format=\"NCHW\")\r\n\r\ncoeffs = tf.reshape(coeffs, [1, 1, channels*depthwise_filters, feature_maps])\r\nseparable = tf.nn.conv2d(depthwise, \r\n                         coeffs, \r\n                         strides=[1, 1, 1, 1], \r\n                         padding=\"VALID\", \r\n                         use_cudnn_on_gpu=True, \r\n                         data_format=\"NCHW\")\r\n\r\n\r\nwith tf.Session() as sess:\r\n\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=3)\r\n\r\n    repeats = 100\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d2 = int((end - start) / repeats * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\r\n```\r\n\r\nEvaluated on a Nvidia M60 with tensorflow-v1.1.0, this code outputs:\r\n```\r\nNormal method: 8ms \t Separable method: 116ms\r\n```\r\n\r\nMy guess is that the tf.nn.depthwise_conv2d function is much slower than the tf.nn.conv2d ?", "I found this question on stackoverflow, which exactly captures the essence of my remark that seperable convolution in its current implementation seems pretty much useless, because the depthwise convolution is much slower than the normal tf.nn.conv2d:\r\n\r\nhttps://stackoverflow.com/questions/39368367/tf-nn-depthwise-conv2d-is-too-slow-is-it-normal", "I am facing with the same problem, seperable convolution some times run slower than normal conv2d on my GPU, but faster than conv2d on CPU, did you manage to find the solution ?", "@BKZero Could you post an example using the separableconv2d function of keras? . I want to present an example of a CNN model with conv2d to another with separableconv2d, but I do not find examples in keras.", "Any updates on this? I have experienced separable convolutions running slower than regular convolution at inference time as well. ", "In my eyes, the slow performance of tf.nn.depthwise_conv2d() compared to tf.nn.conv2d() is definitely an issue (see my reaction above).", "Any updates on this? I have experienced separable convolutions running slower than regular convolution at inference time as well.", "Any updates on this? I have a similar experience", "@stengoes I think your implementation may be wrong,\r\n\r\n1. You can simply print the tensor shape between depth-wise conv and point-wise conv in your code.  the. The output channel of the depth-wise conv should be equal to input channel.\r\n\r\n2.To implement the right separable, you can simply use separable conv in tensor lib \r\nor you can correct the depth-wise implementation in your code.\r\n\r\nIn my test, separable conv is faster than traditional conv on CPU(Mac, 2 GHz Intel Core i7)\r\nMaybe you implementation is on GPU and the speed varies, but I think the implementation maybe wrong\r\n\r\nIn terms of depth-wise, it is faster than traditional, But the speed-up is not proportional the MAC operation ratio of two conv(depth-wise is slower than the expected) \r\n  ", "@AustinVan I still believe that my implementation is right. \r\n\r\nThe number of output channels of the depthwise-conv does NOT necessarily have to be equal to the number input channels. See the documentation of the seperable conv here:\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d\r\n\r\nIt says that the pointwise filter has dimensions: \r\n```[1, 1, channel_multiplier * in_channels, out_channels]```. \r\n\r\nThis means that the number of input channels of the pointwise-conv (which is the same as the number of output channels of the depthwise-conv) is channel_multiplier * in_channels. So unless channel_multiplier equals 1 your claim is wrong. \r\n\r\nThe channel multiplier comes from the number of depthwise filters which has dimensions:\r\n```[filter_height, filter_width, in_channels, channel_multiplier]```\r\n\r\nMoreover the implementation also checks for equality between my implementation and the seperable conv: \r\n```python \r\n# Assert equality of the different methods\r\nnorm, sep = sess.run([normal, separable])\r\nnp.testing.assert_almost_equal(norm, sep, decimal=3)\r\n```\r\n\r\nHowever, I did just notice that with the newer versions of tensorflow the implementation of the seperable conv layer [(see here)](https://github.com/tensorflow/tensorflow/blob/c959ec71e8a06a9a4a20fc3fce0511f4316d337d/tensorflow/python/ops/nn_impl.py#L453-L547)  has changed. So the new implementation might be faster now. I will check it later this week.\r\n\r\n", "@stengoes Thanks. But in the paper [https://arxiv.org/abs/1704.04861](url) \r\nI believe the author mentioned that the input channel of depth-wise should be equal to output channel.\r\n(you are right, the implementation in tensorflow can be different, but we need to let our implementation make sense)\r\n\r\nI am not sure the if accuracy will increase or decrease when the internal channel becomes large in mobilenet.\r\n\r\nBut in my opinion, I think it is an unfair comparison if we didn't follow the paper.\r\n\r\nWhen I changed the output channel of the depthwise conv in your code, the time of depthwise+pointwise is equal to that of separable conv in tensor lib", "I found another interesting repo[https://github.com/peisuke/DeepLearningSpeedComparison](url), which lists all the speed of mobilenet on several mainstreaming deep learning framework.\r\n\r\nIf you still think the implementation of tensorflow is too slow,\r\nmaybe mxnet is another option.....", "sorry i am late. i found a intrest phenomenon, if i use mobilenet on PC, it is really slow, but on android platform, it is fast. i do not know why, but it is real.", "Any updates? I can confirm this problem on PC. Other DL libraries seem to face similar problems. I found an interesting repo for a caffe impl. of the sep conv. that sped up the computation noticably:  [https://github.com/yonghenglh6/DepthwiseConvolution](url)\r\nMaybe s.o. is interested in implementing something similar for tensorflow? I'm reluctant to switch to a different DL platform.\r\n", "```python\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n# Define a scenario\r\nbatch_size = 64\r\nchannels = 32\r\nimage_size = 32\r\nfeature_maps = 64\r\nfilter_size = 15\r\ndepthwise_filters = 8\r\n\r\n# Dummy images\r\nimages = tf.random_normal(shape=[batch_size, channels, image_size, image_size], \r\n                          dtype=tf.float32)\r\n\r\n# Filter definitions\r\nbasis_filters = tf.random_normal(shape=[filter_size, filter_size, channels, depthwise_filters], \r\n                                 dtype=tf.float32)\r\ncoeffs = tf.random_normal(shape=[channels, depthwise_filters, feature_maps], \r\n                          dtype=tf.float32)\r\n\r\n# Normal method\r\neffective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\nnormal = tf.nn.conv2d(images, \r\n                      effective_filters, \r\n                      strides=[1, 1, 1, 1], \r\n                      padding=\"SAME\", \r\n                      use_cudnn_on_gpu=True, \r\n                      data_format=\"NCHW\")\r\n\r\n# Separable method\r\ndepthwise = tf.nn.depthwise_conv2d_native(images, \r\n                                          basis_filters, \r\n                                          strides=[1, 1, 1, 1], \r\n                                          padding=\"SAME\", \r\n                                          data_format=\"NCHW\")\r\n\r\ncoeffs = tf.reshape(coeffs, [1, 1, channels*depthwise_filters, feature_maps])\r\nseparable = tf.nn.conv2d(depthwise, \r\n                         coeffs, \r\n                         strides=[1, 1, 1, 1], \r\n                         padding=\"VALID\", \r\n                         use_cudnn_on_gpu=True, \r\n                         data_format=\"NCHW\")\r\n\r\n\r\nwith tf.Session() as sess:\r\n\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=3)\r\n\r\n    repeats = 100\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d2 = int((end - start) / repeats * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\r\n```\r\n\r\nI evaluated the code snippet once more. This time on a Nvidia Pascal Titan X: \r\nThe results are listed below:\r\n```\r\nNormal method: 8ms \t Separable method: 116ms  # Tesla M60 with Tensorflow-v1.1.0\r\nNormal method: 7ms \t Separable method: 35ms   # Pascal Titan X with Tensorflow-v1.1.0\r\nNormal method: 5ms \t Separable method: 23ms   # Pascal Titan X with Tensorflow-v1.6.0\r\n```\r\nIn tensorflow-v1.6.0 (on the the pascal titan X) the separable method is ~4-5x slower than the normal method. So one could argue that the relative performance of the separable conv has improved with the newer versions of tensorflow.\r\n\r\nI guess that the normal method is still faster because it only has to apply 1 CUDA kernel?! Whereas the separable convolution needs 2 kernels: a depthwise and a pointwise kernel?! Maybe this could be solved by fusing the depthwise and pointwise CUDA kernel? But I am no CUDA expert.\r\n\r\n**TLDR:**\r\nThe current implementation of the seperable conv layer is still useless in my opinion. Because fusing the separated filters first, and then applying a normal conv2d is much faster. Therefore this is still an issue in my opinion.", "For me the tf.nn.depthwise_conv2d_native function is really annoying.\r\nI ran the code @stengoes provided and added the time test for tf.nn.depthwise_conv2d_native.\r\nIn tensorflow v1.6.0 with cuda 9.1.85.2 and cudnn 7.1.2 on the gtx 1080, I get:\r\n`Normal method: 4ms       Depthwise method: 31ms          Separable method: 28ms`\r\n\r\nThe code is as follow:\r\n```\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n# Define a scenario\r\nbatch_size = 64\r\nchannels = 32\r\nimage_size = 32\r\nfeature_maps = 64\r\nfilter_size = 15\r\ndepthwise_filters = 8\r\n\r\n# Dummy images\r\nimages = tf.random_normal(shape=[batch_size, channels, image_size, image_size], \r\n                          dtype=tf.float32)\r\n\r\n# Filter definitions\r\nbasis_filters = tf.random_normal(shape=[filter_size, filter_size, channels, depthwise_filters], \r\n                                 dtype=tf.float32)\r\ncoeffs = tf.random_normal(shape=[channels, depthwise_filters, feature_maps], \r\n                          dtype=tf.float32)\r\n\r\n# Normal method\r\neffective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\nnormal = tf.nn.conv2d(images, \r\n                      effective_filters, \r\n                      strides=[1, 1, 1, 1], \r\n                      padding=\"SAME\", \r\n                      use_cudnn_on_gpu=True, \r\n                      data_format=\"NCHW\")\r\n\r\n# Separable method\r\ndepthwise = tf.nn.depthwise_conv2d_native(images, \r\n                                          basis_filters, \r\n                                          strides=[1, 1, 1, 1], \r\n                                          padding=\"SAME\", \r\n                                          data_format=\"NCHW\")\r\n\r\ncoeffs = tf.reshape(coeffs, [1, 1, channels*depthwise_filters, feature_maps])\r\nseparable = tf.nn.conv2d(depthwise, \r\n                         coeffs, \r\n                         strides=[1, 1, 1, 1], \r\n                         padding=\"VALID\", \r\n                         use_cudnn_on_gpu=True, \r\n                         data_format=\"NCHW\")\r\n\r\n\r\nwith tf.Session() as sess:\r\n\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=3)\r\n\r\n    repeats = 256\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in range(repeats):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark depthwise method\r\n    start = time.time()\r\n    for _ in range(repeats):\r\n        _ = sess.run(depthwise)\r\n    end = time.time()\r\n    d2 = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in range(repeats):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d3 = int((end - start) / repeats * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Depthwise method: {}ms \\t Separable method: {}ms\".format(d1, d2, d3))\r\n\r\n```", "I find that training mobile v2 is much slow than mobilenet v1 on tensorflow, about 50% fps. Then main difference between the two versions is that latter has much larger depthwise_conv layers. But the training time on Pytorch is reduced. These problems are also reported in [https://www.zhihu.com/question/265709710](url). So I think the overhead occurs in tensorflow rather than CUDA.", "I'm using arch linux. So for the experiment mentioned above it's tensorflow\nv1.6.0 with cuda 9.1.85.2 and cudnn 7.1.2 on the gtx 1080. I didn't test\nthis on tensorflow v1.7.0 though.\n\n2018-04-19 15:41 GMT+08:00 Sebyakin Andrei <notifications@github.com>:\n\n> What about perfomance with cudnn 7.1? One of its new features is to handle\n> grouped conv.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12132#issuecomment-382640708>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AF_Qx44qMSMsMzC0BYYtIUvqru1YhmDLks5tqD-ygaJpZM4OxxQM>\n> .\n>\n", "Any updates on this? I have a similar experience. Do you guys have any alternatives? ", "same here! I have got a same experience. please update any news. Thank you in advance.\r\nI also ran the code @stengoes provided and added the time test for tf.nn.depthwise_conv2d_native.\r\nIn tensorflow v1.8.0 on the GTX TitanX, I get:\r\nNormal method: 4ms \t Depthwise method: 39ms \t Separable method: 39ms\r\n\r\n", "I was also previously having issues with the speed of separable convolutions but it was because of how I was using them. The effectiveness of separable convolutions compared to normal convolutions depends on two variables, the number of channels and the depth multiplier. This script demonstrates where separable convolutions are faster than normal convolutions and where they are slower.\r\n```\r\nimport time\r\nfrom typing import Tuple\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\n# Define a scenario\r\nIMAGE_SIZE = 320\r\nCHANNELS_BATCH_SIZE = 2048  # channels * batch_size\r\nKERNEL_SIZE = 3\r\nREPEATS = 100\r\n\r\n\r\ndef build_ops(image: tf.Tensor, channels: int, depth_multiplier: int) -> Tuple[tf.Operation, tf.Operation]:\r\n    with tf.variable_scope(\"{}_{}\".format(channels, depth_multiplier)):\r\n        in_channels = out_channels = channels\r\n        data_format = \"NCHW\"\r\n\r\n        # Filter definitions\r\n        basis_filters = tf.random_normal(\r\n            shape=[KERNEL_SIZE, KERNEL_SIZE, in_channels, depth_multiplier], dtype=tf.float32)\r\n        coeffs = tf.random_normal(\r\n            shape=[in_channels, depth_multiplier, out_channels], dtype=tf.float32)\r\n\r\n        sep_coffs = tf.reshape(coeffs, [1, 1, channels * depth_multiplier, out_channels])\r\n\r\n        # Normal method\r\n        effective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\n\r\n        # Separable method\r\n        depthwise = tf.nn.depthwise_conv2d_native(\r\n            image,\r\n            basis_filters,\r\n            strides=[1, 1, 1, 1],\r\n            padding=\"SAME\",\r\n            data_format=data_format)\r\n\r\n        separable = tf.nn.conv2d(\r\n            depthwise,\r\n            sep_coffs,\r\n            strides=[1, 1, 1, 1],\r\n            padding=\"VALID\",\r\n            use_cudnn_on_gpu=True,\r\n            data_format=data_format)\r\n\r\n        # Normal method\r\n        normal = tf.nn.conv2d(\r\n            image,\r\n            effective_filters,\r\n            strides=[1, 1, 1, 1],\r\n            padding=\"SAME\",\r\n            use_cudnn_on_gpu=True,\r\n            data_format=data_format)\r\n\r\n        return normal, separable\r\n\r\n\r\ndef run(sess: tf.Session, normal: tf.Operation, separable: tf.Operation):\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=2)\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in range(REPEATS):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / REPEATS * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in range(REPEATS):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d2 = int((end - start) / REPEATS * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\r\n\r\n\r\nif __name__ == '__main__':\r\n    with tf.Session() as sess:\r\n        for channels in [32, 128, 1024]:\r\n            # adjust batch_size so gpu doesn't run out of memory\r\n            batch_size = CHANNELS_BATCH_SIZE // channels\r\n            image = tf.random_normal(shape=[batch_size, channels, IMAGE_SIZE, IMAGE_SIZE], dtype=tf.float32)\r\n\r\n            for depth_multiplier in [1, 4, 8]:\r\n                normal, separable = build_ops(image, channels, depth_multiplier)\r\n\r\n                print('Channels:', channels, 'depth_multiplier:', depth_multiplier)\r\n                run(sess, normal, separable)\r\n```\r\nResults:\r\n```\r\nChannels: 32 depth_multiplier: 1\r\nNormal method: 145ms \t Separable method: 139ms\r\n\r\nChannels: 32 depth_multiplier: 4\r\nNormal method: 139ms \t Separable method: 173ms\r\n\r\nChannels: 32 depth_multiplier: 8\r\nNormal method: 139ms \t Separable method: 219ms\r\n\r\nChannels: 128 depth_multiplier: 1\r\nNormal method: 149ms \t Separable method: 141ms\r\n\r\nChannels: 128 depth_multiplier: 4\r\nNormal method: 149ms \t Separable method: 181ms\r\n\r\nChannels: 128 depth_multiplier: 8\r\nNormal method: 149ms \t Separable method: 237ms\r\n\r\nChannels: 1024 depth_multiplier: 1\r\nNormal method: 414ms \t Separable method: 168ms\r\n\r\nChannels: 1024 depth_multiplier: 4\r\nNormal method: 414ms \t Separable method: 296ms\r\n\r\nChannels: 1024 depth_multiplier: 8\r\nNormal method: 414ms \t Separable method: 473ms\r\n```\r\nWhen channels is small (32) separable convs are actually slower than normal convs. The value of separable convs is apparent as the number of channels increases. The inflection point is ~64 channels.\r\n\r\nThe depth multiplier does not effect the runtime performance of normal convolutions. Which makes sense, the matrix multiplication of the `basis_filters` and the `coeffs` above drops the depth multiplier value from the `effective_filters` shape. So the depth multiplier will only effect the runtime of the separable conv. The public architectures using separable convolutions that I am familiar with all use depth multipliers of 1 (e.g. MobileNet and Xception).\r\n\r\nFor my own projects, I have been using normal convolutions for the first 2-3 layers and switch to separable convs when the number of channels is at least 64. I also exclusively use a depth multiplier of 1. Using these two ideas I have personally seen models using separable convs perform 50-100% faster than models using only normal convs.", "@stengoes In your code you've used convolution's associative property by combining the filters of separable convolution and 1x1 convolution assuming that both operation does not use non linearity. After that, you have used this effective filter to convolve with the original input image. This entire operation is taking less time as the first combining operation is applied on much smaller tensors(filters) compared to the other approach(depth separable conv using native functions.). However, this assumption  of linearity does not hold as we do use relu after separable convolution and also the 1x1 convolution in the original MobileNetv1. So, you cannot use the **normal** method. I have edited your code and added the relu after each operation. It should give you an assertion error at line **np.testing.assert_almost_equal(norm, sep, decimal=3)** when you try to run it.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n# Define a scenario\r\nbatch_size = 64\r\nchannels = 32\r\nimage_size = 32\r\nfeature_maps = 64\r\nfilter_size = 15\r\ndepthwise_filters = 8\r\n\r\n# Dummy images\r\nimages = tf.random_normal(shape=[batch_size, channels, image_size, image_size], \r\n                          dtype=tf.float32)\r\n\r\n# Filter definitions\r\nbasis_filters = tf.random_normal(shape=[filter_size, filter_size, channels, depthwise_filters], \r\n                                 dtype=tf.float32)\r\ncoeffs = tf.random_normal(shape=[channels, depthwise_filters, feature_maps], \r\n                          dtype=tf.float32)\r\n\r\n# Normal method\r\neffective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\n#nm = tf.Print(effective_filters, [effective_filters], message=\"This is a: \")\r\nnormal = tf.nn.conv2d(images, \r\n                      effective_filters, \r\n                      strides=[1, 1, 1, 1], \r\n                      padding=\"SAME\", \r\n                      use_cudnn_on_gpu=True, \r\n                      data_format=\"NCHW\"\r\n                      )\r\nnormal = tf.nn.relu(normal)\r\n# Separable method\r\ndepthwise = tf.nn.depthwise_conv2d_native(images, \r\n                                          basis_filters, \r\n                                          strides=[1, 1, 1, 1], \r\n                                          padding=\"SAME\", \r\n                                          data_format=\"NCHW\",\r\n                                          )\r\ndepthwise = tf.nn.relu(depthwise)\r\ncoeffs = tf.reshape(coeffs, [1, 1, channels*depthwise_filters, feature_maps])\r\n\r\nseparable = tf.nn.conv2d(depthwise, \r\n                         coeffs, \r\n                         strides=[1, 1, 1, 1], \r\n                         padding=\"VALID\", \r\n                         use_cudnn_on_gpu=True, \r\n                         data_format=\"NCHW\",\r\n                         )\r\nseparable = tf.nn.relu(separable)\r\nwith tf.Session() as sess:\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=3)\r\n\r\n    repeats = 100\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d2 = int((end - start) / repeats * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\r\n    writer.close()\r\n``` ", "I have run the code above, it seems separable_conv is faster than the normal one in this form, but when I use tf.nn.separable_conv2d or tf.keras.layers.SeparableConv2d, the separable one still lower than the normal method, what's wrong with it?  Any updates on it? \r\nThanks.", "Also experiencing that SeparableConv2d is slower than Conv2d in Keras. The number of input_channels does not seem to matter, I tested 32-2048 and in all cases the Conv2d is faster. Interestingly, in the SeparableConv2d-model the number parameters is lower as well as the FLOPS. Still this does not seem to have the wanted affect on the inference.", "I am using TF version 1.13.\r\nUsing both tf.keras.layers.SeparableConv2D and tf.keras.layers.DepthwiseConv2D without ReLU followd by pointwise tf.keras.layers.Conv2D I'm getting the same results which are ~50% increase of inference runtime (17ms to 26ms).\r\nFor people that want to use DWS convolutions for faster inference it hinders this layers useless using the keras module.", "I also face a strange issue. when I use DepthwiseConv2D in decoder stage(4 * 4-->resize to 8 * 8 --> DepthWiseConv2D ---> resize to 16* 16 -->DepthWiseConv2D ...) of a FCN, it run much more slower than the encoder (from big feature map to small feature map) stage which use the same DepthWiseConv2D. (decoder: more than 1s VS encoder: less than 100ms). I ran the test code in a mobile device.", "Any updates of this?", "Same problem here, especially with @chenbiaolong. Have you figured out to fix it? ", "why this bug not fixed in many year? separable_conv2d used in mobileNet is very popular.", "Maybe not proper here but here's some of my experiments on MxNET & NVIDIA Titan X + CUDA 10.1(Not sure about cudnn version):\r\nInferencing 120 images\r\n|Model|parameters|Cost time on GPU|Cost time on CPU|\r\n|:--:|:--:|:--:|:--:|\r\n|Resnet50_v2|25.6M|0.3964s|5.4333s|\r\n|EfficientNet B2|9.2M|0.6466s|1.6488s|\r\nEfficientnet is the sota model on ImageNet published by google, which is mainly built with MBConv(A depthwise separable convolution block)\r\nThe performance of resnet50 was tested with (1, 3, 160, 160), whereas efficientnetb2's is tested with (1, 3, 260, 260)", "There is a paper discussing the trap of FLOPs, maybe in depthwise convolutions the memory access dominates the real cost time on GPU/CPU implementations\r\n[https://papers.nips.cc/paper/7835-constructing-fast-network-through-deconstruction-of-convolution](url)", "@keunwoochoi  problem still exists. I agree with @boluoweifenda ,the slow inference speed are not caused by a bug of  depthwise convolutions, FLOPs  are not the only factor that affect inference time. maybe we should change the network architecture of decoder stage.", "In my case with tf.layer.separable_conv2d\r\n\r\ntensorflow v1.12: too slow\r\ntensorflow v1.14: not slow\r\n\r\nHow about you?", "@yoshizamurai  did you test on an arm cpu? I did't test tensorflow v1.14, my test run on tensorflow 1.13", "So, you should test on an arm cpu with tensorflow 1.14.", "```\r\ntf.__version__ 1.13.1\r\nGeForce GTX 1080 Ti\r\nNormal method: 3ms \t Separable method: 19ms\r\n```\r\n\r\n```\r\ntf.__version__ 1.14.0-rc1\r\nGeForce RTX 2080 Ti\r\nNormal method: 9ms \t Separable method: 13ms\r\n```", "@robieta This issue seems unresolved.\r\n\r\n@trevor-m @samikama @houtoms I tested NGC TF 19.06 and the issue is gone. Would you mind to share the configuration/patch that makes tf.nn.separable_conv2d perform well as intended?", "This seems to be fixed by latest TF nightly and should be available on 2.2. It requires fp16, NCHW, stride==1, and cuDNN version >= 7.6.3 though. See #33836 for details.\r\n\r\nPing @houtoms to confirm.", "Yes, we follow the https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_763.html#rel_763 to enable fast depwise cuDNN paths. ", "Hi @byronyi and @houtoms , it requires fp16 , it is not enough. I think this issue still open", "any updates here? I'm suffereing from this too", "Hi @BKZero! \r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. Have you checked this [document](https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d) from latest version TF 2.7 yet? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 12131, "title": "ckpt get in win7 anaconda cannot be used in win10\uff1fThe same CNN structure and params", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["_Warning: As you've not filled in the required info above you may not get the support you're looking for from the devs. Perhaps this is an issue for Stack Overflow?_\r\n\r\nWithout you filling in the template above there is no way anyone can help you. If the **only** difference is the OS then i'm surprised that the ckpt's don't work. They should work fine. Are you using any LSTM cells or different versions of Tensorflow. Please fill in the issue template above.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12130, "title": "Add handle_ties arg to in_top_k Op to deal with ties.(#10767)", "body": "[#10767](https://github.com/tensorflow/tensorflow/issues/10767)\r\nAdd handle_ties argument to in_top_k Op to make the Op more clear.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@nolanliou FYI: Removing the stable sort from top_k was a mistake. We are in the process of restoring it. Perhaps this change becomes unnecessary then?", "The change is about `in_top_k`, Is there a relationship between `top_k` and `in_top_k`?", "@nolanliou Ah, nevermind :-)  Can you please rebase?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Sorry, I screw it up, I'll close this and reopen a [PR](https://github.com/tensorflow/tensorflow/pull/12230)."]}, {"number": 12129, "title": "Add int64 support for out_idx of tf.unique", "body": "This fix tries to address the issue raised in #12113 where tf.unique does not support int64 for out_idx. The support of int64 was specified by the docs, though.\r\n\r\nThe int64 support was enabled and additional tests were added.\r\n\r\nThis fix fixes #12113.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @keveman and @a-dai to be potential reviewers.", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 12128, "title": "Where is device_attributes.pb.h ", "body": "I have to use the  device_attributes.pb.h  and I don't know where it is.\r\n\r\nThank you !", "comments": ["Create it as an empty dummy file", "Closing this as a duplicate of #11899 - like for the file mentioned there, `device_attributes.pb.h` is generated during the build and is placed in `bazel-genfiles`"]}, {"number": 12127, "title": "tf.reshape accepts Dimension objects for the shape parameter", "body": "The PR aims to fix #11974.\r\n\r\nBecause it's my first contribution, so the PR is opened early to get feedback from community.\r\n\r\n### What changes were proposed in this pull request?\r\n\r\nCast tf.Dimension to int for shape argument.\r\n\r\n\r\n### How was this patch tested?\r\n\r\n+ [x] add a doctest. ", "comments": ["Can one of the admins verify this patch?", "@facaiy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @vrv and @tensorflower-gardener to be potential reviewers.", "Sorry I don't understand the motivation\r\ncompat.as_bytes(x.__str__()) instead of compat.as_bytes(x)\r\n\r\nwhat does this improve?", "@yaroslavvb , the PR is modified as suggested by @pmccarter . But I am not sure whether it is implemented correctly, could you give more feedback? Thanks.", "@tensorflow-jenkins test this please", "@facaiy As you can see here: https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/6320/consoleFull\r\nthis breaks a large number of tests. I'll let @martinwicke give detailed comments.", "@rmlarsen @martinwicke  It'll be really useful for me if I can check test.log of CI. Because my laptop is left on office, hence I'll check it later. Thanks very much! ", "@tensorflow-jenkins test this please", "Hi, @rmlarsen . I submit a fix, and could you help retest the PR? Thanks.", "By the way, since `reshape` is migrated from `_gen_array_op` to `array_op`, should we remove the duplicate document of `_gen_array_op._reshape`? If I understand correctly, the description is in the [tensorflow/core/ops/ops.pbtxt](https://github.com/tensorflow/tensorflow/blob/ca1f9846a1fa6056c28b6512e3dd1037132ef7af/tensorflow/core/ops/ops.pbtxt#L19593)", "@facaiy The docs are inside cc file which defines reshape op.\r\n\r\nTo think of it, this approach would trigger an API review. I wonder if there's a simple solution which would only touch a couple of lines of Python code, better chance of being accepted without a lot of work on maintaining team. BTW, the best way to test things is to run all relevant tests locally first, using \"bazel test\"", "Thanks for your explanation, @yaroslavvb . \r\n\r\nI agree that migrating `reshape` will introduce duplicate code and increase maintain cost, so I'd like to try to fix it in `tensor_util.make_tensor_proto` as well. If success, another PR will be opened, see #12513 .\r\n\r\nAnyway, if you have any new idea / suggestion, please tell me. I'd like to take a try.\r\n\r\nRunning all test locally is time-consuming, hence only several unit tests are selected by me to be tested at first. By the way, could you tell me how to run doctest? Thanks."]}, {"number": 12126, "title": "Where is NumTraits.h ?", "body": "https://stackoverflow.com/questions/45579072/compiling-tensorflow-api-c-cc-using-mingw-gcc", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12125, "title": "Add `skip_empty` option to `tf.string_split`", "body": "This fix add `skip_empty` to `tf.string_split` so that it is possible to have `tf.string_split` behaving similiarly with python.\r\n\r\nThis fix fixes #12108.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "(Looks good for API change, removing the label)", "@asimshankar Thanks!", "@tensorflow-jenkins test this please", "@rmlarsen @asimshankar Thanks for the review. All Jenkins tests passed except `//tensorflow/tools/api/tests:api_compatibility_test`\r\n\r\nThe PR has now been updated with \r\n```\r\nbazel-bin/tensorflow/tools/api/tests/api_compatibility_test           --update_goldens True\r\n```\r\n\r\nPlease take a look.", "@yongtang thanks for the contribution!"]}, {"number": 12124, "title": "Branch 164665656", "body": "", "comments": ["@rmlarsen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @keveman and @alisidd to be potential reviewers."]}]