[{"number": 33592, "title": "TensorFlow Models Installation on wondows 10 using protobuf ,cmake fails", "body": "Following tutorial on below link to train few pics.\r\n\r\nhttps://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html.\r\n\r\nBut protobuf lib is not getting created , following below link for windows 10 :\r\nhttps://github.com/protocolbuffers/protobuf/blob/master/cmake/README.md\r\n\r\nwhile , executing below command  , getting error : \r\nLINK : fatal error LNK1104: cannot open file 'LIBCMT.lib'\r\n\r\ncommand:\r\ncmake -G \"NMake Makefiles\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../../../../install ../..\r\n\r\nAttached are error and output files :\r\n[CMakeError.log](https://github.com/tensorflow/tensorflow/files/3753881/CMakeError.log)\r\n[CMakeOutput.log](https://github.com/tensorflow/tensorflow/files/3753882/CMakeOutput.log)\r\n\r\nPlease help.Need to get this done urgently\r\n\r\n", "comments": ["duplicte  of #33578 ,hence closing"]}, {"number": 33591, "title": "Person_detection.zip not present after update in reference to issue  #33552 and PR #33579 ", "body": "This is issue is made in reference to Issue #33552 and the PR #33579:\r\nwhen I click on the person_detection.zip link after update this pops out:\r\n`\r\nThis XML file does not appear to have any style information associated with it. The document tree is shown below.\r\n<Error nighteye=\"disabled\">\r\n<Code>NoSuchKey</Code>\r\n<Message>The specified key does not exist.</Message>\r\n<Details>\r\nNo such object: tensorflow-nightly/github/tensorflow/tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection/person_detection.zip\r\n</Details>\r\n</Error>\r\n` \r\n", "comments": ["> @Samsomyajit I think I found the package!\r\n> https://storage.googleapis.com/tensorflow-nightly/github/tensorflow/tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection/tensorflow_lite.zip\r\n> \r\n> It's named tensorflow_lite.zip instead of person_detection.zip\r\n> \r\n> We were able to flash the example correctly after renaming the zip to person_detection.zip, renaming the library name as it appears in `Arduino/libraries/` to person_detection, as well as changing the name in the ` library.properties` file in the zip to `name=TensorFlowLite:person_detection`\r\n\r\nIn reference to the above reply from  @smellslikeml the package was named tensorflow_lite.zip instead of person_detection.zip , that was the reason it was not openning but with the PR #33579 I have updated the link... so the problem no longer exist"]}, {"number": 33589, "title": "Update test_util.py", "body": "", "comments": ["Several things:\r\n\r\n1. Please describe the reason for the PR, so we know the context under which to review\r\n2. Please provide test cases, especially on behavior changing PRs\r\n3. Please make the PR against `master` branch, not the `r..` release ones. The release branch are cut from master when a new release process starts and only receive updates and cherry-picks to enable the release. Once the release is made, the release branches are only updated when doing patch releases and those patch releases are security related in at least 99% of the case.", "I tried manually changing base to master but that resulted in too many conflicts. Hence, closing this PR, please reopen/open a new one against `master`"]}, {"number": 33588, "title": "tflite interpreter makes huge difference in output for tf.reduce_mean() when it is quantized", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from source\r\n- TensorFlow version (use command below): ('v2.0.0-0-g64c3d38', '2.0.0') & ('v2.0.0-rc2-26-g64c3d38', '2.0.0')\r\n- Python version: 2.7.12\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\r\n- CUDA/cuDNN version: 10.0 / 7.0\r\n- GPU model and memory: GeForce GTX TITAN\r\n\r\n**Describe the current behavior**\r\nWhen I quantize the graph with tf.reduce_mean, it makes huge difference in outputs, compared original tf function and tflite model (not quantized).\r\n\r\n**Describe the expected behavior**\r\nthe quantized model gives similar output values with the original tf graph.\r\n\r\nWith quantization=True,\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Initialized TensorFlow Lite runtime.\r\ninput_x:\r\n[[[[7. 7. 3.]\r\n   [0. 2. 3.]\r\n   [6. 3. 8.]]\r\n\r\n  [[5. 2. 9.]\r\n   [7. 3. 7.]\r\n   [9. 9. 8.]]\r\n\r\n  [[3. 2. 0.]\r\n   [6. 8. 7.]\r\n   [2. 0. 7.]]]]\r\noutput (tf.function):\r\ntf.Tensor(\r\n[[[[5.6666665]\r\n   [1.6666666]\r\n   [5.6666665]]\r\n\r\n  [[5.3333335]\r\n   [5.6666665]\r\n   [8.666667 ]]\r\n\r\n  [[1.6666666]\r\n   [7.       ]\r\n   [3.       ]]]], shape=(1, 3, 3, 1), dtype=float32)\r\noutput (tflite):\r\n[[[[5.011765 ]\r\n   [4.5176473]\r\n   [4.5176473]]\r\n\r\n  [[4.5176473]\r\n   [4.5176473]\r\n   [4.5176473]]\r\n\r\n  [[4.5176473]\r\n   [4.5176473]\r\n   [0.6      ]]]]\r\n```\r\nThe output of the tflite model seems too different with that of the original tf function.\r\n\r\nWhen quantization=False,\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\ninput_x:\r\n[[[[3. 6. 5.]\r\n   [4. 8. 9.]\r\n   [1. 7. 9.]]\r\n\r\n  [[6. 8. 0.]\r\n   [5. 0. 9.]\r\n   [6. 2. 0.]]\r\n\r\n  [[5. 2. 6.]\r\n   [3. 7. 0.]\r\n   [9. 0. 3.]]]]\r\noutput (tf.function):\r\ntf.Tensor(\r\n[[[[4.6666665]\r\n   [7.       ]\r\n   [5.6666665]]\r\n\r\n  [[4.6666665]\r\n   [4.6666665]\r\n   [2.6666667]]\r\n\r\n  [[4.3333335]\r\n   [3.3333333]\r\n   [4.       ]]]], shape=(1, 3, 3, 1), dtype=float32)\r\noutput (tflite):\r\n[[[[4.6666665]\r\n   [7.       ]\r\n   [5.6666665]]\r\n\r\n  [[4.6666665]\r\n   [4.6666665]\r\n   [2.6666667]]\r\n\r\n  [[4.3333335]\r\n   [3.3333333]\r\n   [4.       ]]]]\r\n```\r\nthe their outputs looks the same.\r\n\r\nIt does not seem normal that the quantization gives too much differences in output values.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec(shape=[None,3,3,3], dtype=tf.float32, name='x')])\r\ndef model(x, epsilon=1e-6):\r\n  mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\r\n  #variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keepdims=True)\r\n  #norm_x = (x - mean) * tf.math.rsqrt(variance + epsilon)\r\n  #print(norm_x.shape)\r\n  #return norm_x\r\n  return mean\r\n\r\ndef run():\r\n  def _representative_dataset_gen():\r\n    for i in range(100):\r\n      yield [np.random.random_integers(0, 9, size=[1,3,3,3]).astype('float32'),]\r\n\r\n  np.random.seed(1234)\r\n  quantization=True\r\n  cfunc = model.get_concrete_function()\r\n  converter = tf.lite.TFLiteConverter.from_concrete_functions([cfunc])\r\n  if quantization:\r\n         converter.representative_dataset = _representative_dataset_gen\r\n         converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\n\r\n\r\n  tflite_model = converter.convert()\r\n  model_file = \"tflite_mean_4D_v2.tflite\"\r\n  open(model_file, \"wb\").write(tflite_model)\r\n\r\n  interpreter = tf.lite.Interpreter(model_path=model_file)\r\n  interpreter.allocate_tensors()\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n\r\n  # test values\r\n  input_x = np.random.random_integers(0, 9, size=[1,3,3,3]).astype('float32')\r\n\r\n  print(\"input_x:\")\r\n  print(input_x)\r\n\r\n  output_fun = cfunc(tf.constant(input_x))\r\n  print(\"output (tf.function):\")\r\n  print(output_fun)\r\n\r\n  # tflite test\r\n  interpreter.set_tensor(input_details[0]['index'], input_x)\r\n  output_tflite = interpreter.get_tensor(output_details[0]['index'])\r\n  print(\"output (tflite):\")\r\n  print(output_tflite)\r\n\r\nif __name__ == '__main__':\r\n  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\r\n  run()\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I modified 'lite/kernels/reduce.cc' and obtained following result that seems correct.\r\n\r\n```\r\ninput_x:\r\n[[[[7. 7. 3.]\r\n   [0. 2. 3.]\r\n   [6. 3. 8.]]\r\n\r\n  [[5. 2. 9.]\r\n   [7. 3. 7.]\r\n   [9. 9. 8.]]\r\n\r\n  [[3. 2. 0.]\r\n   [6. 8. 7.]\r\n   [2. 0. 7.]]]]\r\n(1, 3, 3, 3)\r\noutput (tf.function):\r\ntf.Tensor(\r\n[[[[5.6666665]\r\n   [1.6666666]\r\n   [5.6666665]]\r\n\r\n  [[5.3333335]\r\n   [5.6666665]\r\n   [8.666667 ]]\r\n\r\n  [[1.6666666]\r\n   [7.       ]\r\n   [3.       ]]]], shape=(1, 3, 3, 1), dtype=float32)\r\noutput (tflite):\r\n[[[[5.647059 ]\r\n   [1.6941178]\r\n   [5.647059 ]]\r\n\r\n  [[5.329412 ]\r\n   [5.647059 ]\r\n   [8.647059 ]]\r\n\r\n  [[1.6941178]\r\n   [6.9882355]\r\n   [3.0000002]]]]\r\n```\r\n\r\ntflite interpreter runs following function, that is not correct interpretation of tf.reduce_mean().\r\nhttps://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/lite/kernels/reduce.cc#L323\r\n```\r\n  if (op_context.input->type == kTfLiteInt8) {\r\n    tflite::MeanParams op_params;\r\n    op_params.axis_count = num_axis;\r\n    ResolveAxis(GetTensorData<int>(op_context.axis), num_axis, &op_params);\r\n    const TfLiteTensor* input = op_context.input;\r\n    reference_integer_ops::Mean(\r\n        op_params, data->multiplier, data->shift, GetTensorShape(input),\r\n        GetTensorData<int8_t>(input), op_context.input->params.zero_point,\r\n        GetTensorShape(op_context.output),\r\n        GetTensorData<int8_t>(op_context.output),\r\n        op_context.output->params.zero_point);\r\n    return kTfLiteOk;\r\n  }\r\n```\r\nThis code block should be changed as\r\n```\r\n  if (op_context.input->type == kTfLiteInt8) {\r\n    tflite::MeanParams op_params;\r\n    op_params.axis_count = num_axis;\r\n    ResolveAxis(GetTensorData<int>(op_context.axis), num_axis, &op_params);\r\n    const TfLiteTensor* input = op_context.input;\r\n    if (op_context.params->keep_dims && NumDimensions(input) == 4 &&\r\n        op_params.axis_count == 2 &&\r\n        ((op_params.axis[0] == 1 && op_params.axis[1] == 2) ||\r\n         (op_params.axis[0] == 2 && op_params.axis[1] == 1))){\r\n       reference_integer_ops::Mean(\r\n           op_params, data->multiplier, data->shift, GetTensorShape(input),\r\n           GetTensorData<int8_t>(input), op_context.input->params.zero_point,\r\n           GetTensorShape(op_context.output),\r\n           GetTensorData<int8_t>(op_context.output),\r\n           op_context.output->params.zero_point);\r\n       return kTfLiteOk;\r\n    }\r\n  }\r\n```\r\nto prevent wrong operation.\r\n\r\nSecondly, it should be dealt with elsewhere. It seems that the code contains suitable macro 'TF_LITE_MEAN'. \r\nhttps://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/lite/kernels/reduce.cc#L332\r\n\r\nI don't know why the authors did not call this already, but I can use this to cover the case. I added following code into the switch statement, borrowing the kTfLiteUInt8 case.\r\n```\r\n      case kTfLiteInt8:\r\n        if (op_context.input->params.zero_point ==\r\n                op_context.output->params.zero_point &&\r\n            op_context.input->params.scale == op_context.output->params.scale) {\r\n          TF_LITE_ENSURE(context, TF_LITE_MEAN(reference_ops, int8_t, int));\r\n        } else {\r\n          TF_LITE_ENSURE(\r\n              context,\r\n              reference_ops::QuantizedMeanOrSum<>(\r\n                  GetTensorData<int8_t>(op_context.input),\r\n                  op_context.input->params.zero_point,\r\n                  op_context.input->params.scale, op_context.input->dims->data,\r\n                  op_context.input->dims->size,\r\n                  GetTensorData<int8_t>(op_context.output),\r\n                  op_context.output->params.zero_point,\r\n                  op_context.output->params.scale,\r\n                  op_context.output->dims->data, op_context.output->dims->size,\r\n                  GetTensorData<int>(op_context.axis), num_axis,\r\n                  op_context.params->keep_dims, GetTensorData<int>(temp_index),\r\n                  GetTensorData<int>(resolved_axis),\r\n                  GetTensorData<int>(temp_sum),\r\n                  /*compute_sum=*/false));\r\n        }\r\n        break;\r\n```\r\n\r\nThen the interpreter seems work. \r\n\r\nIt seems that similar correction is already implemented in the 'master' branch. Maybe it works fine in the tf-nightly version, however, the v2.0.0 version needs this modification to run the test code correctly.", "Fix is in tf-nightly. It'll appear in the next tf.2.x release soon.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33588\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33588\">No</a>\n"]}, {"number": 33587, "title": "Performant (distributed) tf dataset creation from replay buffer using distribute strategies?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.7.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7.6.2\r\n- GPU model and memory: Titan XP\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently, there is a lot of overhead in making and distributing a dataset from a replay buffer (for RL) as this requires, pulling data from an Actor's queue, creating the dataset (tf.experimental_make_numpy_dataset), batching, distributing (self.strategy.experimental_distribute_dataset), and building the iterator upon each update to the replay buffer. See below for an example.\r\n\r\n```     \r\n    def gather_data(self):\r\n        self.output_queue = Queue(maxsize=self.data_params[\"num_envs\"])\r\n        self.data_provider = DataProvider( \r\n                    self.policy,\r\n                    self.output_queue,\r\n                    self.strategy,\r\n                    self.train_summary_writer,\r\n                )\r\n        for i in range(self.replay_buffer_len):\r\n            self.data_provider.collect_episode()\r\n\r\n    def get_batch(self):\r\n        with self.strategy.scope():\r\n            batch = self.output_queue.get()\r\n            dataset = self.strategy.experimental_make_numpy_dataset(batch)\r\n            dataset = dataset.batch(self.train_params[\"global_batch_size\"])\r\n            dataset = self.strategy.experimental_distribute_dataset(dataset)\r\n            self.iter = iter(dataset)\r\n\r\n    def distributed_train(self):\r\n        self.gather_data()\r\n        self.get_batch()\r\n        while step < self.train_steps:\r\n            if step > 0 and (step % train_steps_per_buffer_refresh == 0):\r\n                self.data_provider.collect_episode()\r\n                self.get_batch()\r\n            with self.strategy.scope():\r\n                train_res = self.train_step(\r\n                    next(self.iter),\r\n                    self.policy,\r\n                    self.strategy,\r\n                )\r\n            self.log_hook(train_res, step)\r\n            self.save_hook(step)\r\n            step += 1\r\n                                                                                                                                                        \r\n```\r\n\r\nThis follows the recommendation of the current docs. It takes a very long time (4s, 8x longer than each train step) to rebuild the dataset after adding to the replay buffer, distributed roughly evenly between self.strategy.experimental_make_numpy_dataset, self.strategy.experimental_distribute_dataset, and iter(dataset). Given than I updated the replay buffer every 4 train steps, this adds up to a significant performance hit.\r\n\r\nIt seems like tf-agents has an [implementation](https://github.com/tensorflow/agents/blob/e084e5184757dd84374e9b67176b8623d4b18a0f/tf_agents/replay_buffers/tf_uniform_replay_buffer.py#L301-L324) of a replay buffer to dataset Class method involving using tf.Counter and map, however, I haven't tested it's performance when calling distribute dataset on it. Is this the recommended way to have a Dataset does not have to be rebuilt after the replay buffer is updated? ", "comments": []}, {"number": 33586, "title": "non_max_suppression GPU version not working on TF 1.15", "body": "Getting the following error on trying to place non_max_suppression() on GPU. \r\n\r\n```\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 5407, in _eval_using_default_session\r\n    return session.run(tensors, feed_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation non_max_suppression/NonMaxSuppressionV3: node non_max_suppression/NonMaxSuppressionV3 (defined at /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\r\n         [[non_max_suppression/NonMaxSuppressionV3]]\r\n\r\n```\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nGet the above error on  placing the op in GPU.\r\n\r\n**Describe the expected behavior**\r\n\r\nNot see that error.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\n\r\nimport time\r\nfrom tensorflow.python.ops import gen_image_ops\r\n\r\n\r\ndef yolo_non_max_suppression(scores, boxes, classes, sess, max_boxes = 10, iou_threshold = 0.5):\r\n    \"\"\"\r\n    Applies Non-max suppression (NMS) to set of boxes\r\n    \r\n    Arguments:\r\n    scores -- tensor of shape (None,), output of yolo_filter_boxes()\r\n    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\r\n    classes -- tensor of shape (None,), output of yolo_filter_boxes()\r\n    max_boxes -- integer, maximum number of predicted boxes you'd like\r\n    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\r\n    \r\n    Returns:\r\n    scores -- tensor of shape (, None), predicted score for each box\r\n    boxes -- tensor of shape (4, None), predicted box coordinates\r\n    classes -- tensor of shape (, None), predicted class for each box\r\n    \r\n    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes. Note also that this\r\n    function will transpose the shapes of scores, boxes, classes. This is made for convenience.\r\n    \"\"\"\r\n   \r\n    init_val_np = np.array ( [max_boxes], dtype=np.int32) \r\n    max_boxes_tensor = tf.Variable(max_boxes,  dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\r\n    sess.run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor\r\n    \r\n    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\r\n    ### START CODE HERE ### (~ 1 line)\r\n    with tf.device(\"gpu:0\"):\r\n        boxes_np = boxes.eval() \r\n        time0 = time.time()\r\n        score_threshold = 0.1\r\n        soft_nms_sigma=0.0\r\n        pad_to_max_output_size=False\r\n        for i in range(1,2):\r\n            nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\r\n            #nms_indices = nms(boxes_np, 0.5)\r\n            #nms_indices = gen_image_ops.non_max_suppression_v2(boxes, scores, max_boxes_tensor, iou_threshold, )\r\n            #nms_indices = gen_image_ops.non_max_suppression_v3(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold)\r\n            #nms_indices = gen_image_ops.non_max_suppression_v4(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, pad_to_max_output_size)\r\n            #nms_indices = gen_image_ops.non_max_suppression_v5(boxes, scores, max_boxes_tensor, iou_threshold, score_threshold, soft_nms_sigma)\r\n            if i%100 == 0:\r\n                print (i, (time.time() - time0)/i )\r\n        ### END CODE HERE ###\r\n\r\n        ### START CODE HERE ### (~ 3 lines)\r\n        scores = tf.gather(scores, nms_indices)\r\n        boxes = tf.gather(boxes, nms_indices)\r\n        classes = tf.gather(classes, nms_indices)\r\n        summary_writer = tf.summary.FileWriter(os.getenv('TENSORBOARD_DIR'), sess.graph)\r\n        ### END CODE HERE ###\r\n\r\n    return scores, boxes, classes\r\n\r\ndef test_yolo_non_max_suppression():\r\n    with tf.device(\"cpu:0\"):\r\n        with tf.Session() as test_b:\r\n            scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\r\n            boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\r\n            classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\r\n            scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, test_b)\r\n            #scores, boxes, classes = yolo_non_max_suppression0(scores, boxes, classes)\r\n            print(\"scores[2] = \" + str(scores[2].eval()))\r\n            print(\"boxes[2] = \" + str(boxes[2].eval()))\r\n            print(\"classes[2] = \" + str(classes[2].eval()))\r\n            print(\"scores.shape = \" + str(scores.eval().shape))\r\n            print(\"boxes.shape = \" + str(boxes.eval().shape))\r\n            print(\"classes.shape = \" + str(classes.eval().shape))\r\n\r\n\r\ntest_yolo_non_max_suppression()\r\n\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sgambient,\r\nCouldn't reproduce the Error in Google Colab with `Python Version 2.7` and with `Runtime` Type as `GPU`. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/78724392111645fb87db0d2189536585/33586_gpu_error.ipynb).\r\n\r\nOne probable solution, as per this [Stack Overflow Issue](https://stackoverflow.com/questions/47362590/tensorflow-gpu-error-invalidargumenterror-cannot-assign-a-device-for-operation) is to change/add the Data Type to `tf.float32`.\r\n\r\nCan you please try replacing the code,\r\n\r\n```\r\nscores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\r\nboxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\r\nclasses = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\r\n```\r\nwith below code and let us know how it goes. Thanks!\r\n```\r\nscores = tf.random_normal([54,], mean=1, dtype = tf.float32, stddev=4, seed = 1)\r\nboxes = tf.random_normal([54, 4], mean=1, dtype = tf.float32, stddev=4, seed = 1)\r\nclasses = tf.random_normal([54,], mean=1, dtype = tf.float32, stddev=4, seed = 1)\r\n```", "I've created a minimal reproducing example for this but it does not use the Colab environment:\r\n\r\n```py\r\n\"\"\"Minimum reproducing example.\r\n\r\nDevice specs:\r\n    GPU: NVIDIA RTX 2080\r\n    TF version: 1.15 (tensorflow/tensorflow:1.15.0-gpu-py3 container)\r\n    Python version: 3.6.8\r\n    Host driver: 418.56\r\n    CUDA version: 10.1\r\n\"\"\"\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import gen_image_ops\r\n\r\n# Use placeholder to guarantee that we are feeding floats\r\nboxes = tf.placeholder(tf.float32, [5, 4])\r\nscores = tf.placeholder(tf.float32, [5])\r\nwith tf.device('gpu:0'):\r\n    # Try out all 5 of the NMS options, tf.image.non_max_suppression uses V3\r\n    # behind the scenes.\r\n    indices1 = tf.image.non_max_suppression(\r\n        boxes=boxes, scores=scores, max_output_size=2, iou_threshold=0.5)\r\n    indices2 = gen_image_ops.non_max_suppression_v2(\r\n        boxes=boxes, scores=scores, max_output_size=2, iou_threshold=0.5)\r\n    indices3 = gen_image_ops.non_max_suppression_v3(\r\n        boxes=boxes, scores=scores, max_output_size=2, iou_threshold=0.5,\r\n        score_threshold=0.5)\r\n    indices4 = gen_image_ops.non_max_suppression_v4(\r\n        boxes=boxes, scores=scores, max_output_size=2, iou_threshold=0.5,\r\n        score_threshold=0.5, pad_to_max_output_size=False)\r\n    # V5 doesn't exist in TF1.15 yet\r\n    #indices5 = gen_image_ops.non_max_suppression_v5(\r\n    #    boxes=boxes, scores=scores, max_output_size=2, iou_threshold=0.5,\r\n    #    score_threshold=0.5, soft_nms_sigma=0.0, pad_to_max_output_size=False)\r\n\r\n# Log device placement to see if NMS op is placed on GPU\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n\r\n# None of these 5 work\r\ntry:\r\n    sess.run(indices1, feed_dict={\r\n        boxes: np.random.random([5, 4]),\r\n        scores: np.random.random([5])})\r\nexcept Exception as e:\r\n    print('tf.image.non_max_suppression failed: ', e)\r\n\r\ntry:\r\n    sess.run(indices2, feed_dict={\r\n        boxes: np.random.random([5, 4]),\r\n        scores: np.random.random([5])})\r\nexcept Exception as e:\r\n    print('gen_image_ops.non_max_suppression_v2 failed: ', e)\r\n\r\ntry:\r\n    sess.run(indices3, feed_dict={\r\n        boxes: np.random.random([5, 4]),\r\n        scores: np.random.random([5])})\r\nexcept Exception as e:\r\n    print('gen_image_ops.non_max_suppression_v3 failed: ', e)\r\n\r\ntry:\r\n    sess.run(indices4, feed_dict={\r\n        boxes: np.random.random([5, 4]),\r\n        scores: np.random.random([5])})\r\nexcept Exception as e:\r\n    print('gen_image_ops.non_max_suppression_v4 failed: ', e)\r\n\r\n#try:\r\n#    sess.run(indices5, feed_dict={\r\n#        boxes: np.random.random([5, 4]),\r\n#        scores: np.random.random([5])})\r\n#except Exception as e:\r\n#    print('gen_image_ops.non_max_suppression_v5 failed: ', e)\r\n```\r\n\r\nAll of the NMS options fail with the same error, which includes the error log:\r\n\r\n```\r\nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[\r\nCPU] possible_devices_=[]\r\nNonMaxSuppressionV3: CPU\r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  non_max_suppression/NonMaxSuppressionV3 (NonMaxSuppressionV3) /device:GPU:0\r\n\r\nOp: NonMaxSuppressionV3\r\nNode attrs: T=DT_FLOAT\r\nRegistered kernels:\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n         [[node non_max_suppression/NonMaxSuppressionV3 (defined at nms.py:20) ]]\r\n```\r\n\r\nRemoving `tf.device('gpu:0')` works but the device placement shows that the op is always placed on CPU.\r\n\r\nIt seems that the GPU kernel does not exist? I see the registered kernel here however: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/non_max_suppression_op.cc#L913\r\n\r\nIs it possible that this is not built into the TF1.15 release?", "I used the  TF 1.15 container from \"docker pull tensorflow/tensorflow:1.15.0-gpu \".  Is that different from what Colab TF 1.15 version  ? ", "> I used the TF 1.15 container from \"docker pull tensorflow/tensorflow:1.15.0-gpu \". Is that different from what Colab TF 1.15 version ?\r\n\r\nIt is equivalent to using `tensorflow-gpu-1.15.0` on colab\r\n\r\n\r\n@sgambient The error states that you are trying to do an operation that can\u2019t be done on a GPU.\r\nIf this is the case, you can either manually change the device to a CPU for this operation, or set TensorFlow to automatically change the device in this case. To do this, set allow_soft_placement tp True in the configuration, done as part of creating the session. The prototype looks like this:\r\n```\r\nwith tf.Session(config=tf.ConfigProto(allow_soft_placement=True)):\r\n    # Run your graph here\r\n```\r\nFor more info you can refer to the following [link](https://databricks.com/tensorflow/using-a-gpu)", "A quick update. Looks like the cause was   \"docker pull tensorflow/tensorflow:1.15.0-gpu\" container  needs to be started with  nvidia-docker for the gpu ops to be visible.   **But the  bigger issue I see now is that the gpu version is almost 3x slower !!**  Have added my test to the same [Gist](https://colab.research.google.com/gist/rmothukuru/78724392111645fb87db0d2189536585/33586_gpu_error.ipynb#scrollTo=Scf1hrLjPc7A) .\r\n\r\n\r\n", "@sgambient Please create a new issue regarding the performance issue. This would help us track the issue separately. Thanks!"]}, {"number": 33585, "title": "tf.compat.v1.wrap_function throws error when creating variable in tf.distribute scope", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab TPU\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n%tensorflow_version 2.x\r\nimport tensorflow as tf\r\n\r\n# define a function that uses tf.compat.v1.get_variable with some initializer\r\ndef f():\r\n    v = tf.compat.v1.get_variable(\r\n      'v',\r\n      initializer=tf.compat.v1.variance_scaling_initializer(), shape=(1), trainable=True\r\n    )\r\n    return v\r\n\r\n# this works:\r\nwrapped = tf.compat.v1.wrap_function(f, [])\r\n\r\n# but, connect to a TPU...\r\ntpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\r\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\r\ntf.config.experimental_connect_to_cluster(cluster_resolver)\r\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\nwith tf.distribute.experimental.TPUStrategy(cluster_resolver).scope():\r\n    # ...and, this throws:\r\n    # ValueError: Tensor-typed variable initializers must either be\r\n    # wrapped in an init_scope or callable\r\n    wrapped = tf.compat.v1.wrap_function(f, [])\r\n```\r\n\r\nIt seems like wrapped_function variable creation is interacting poorly with distribute somehow.\r\n\r\nNote, a simple `lambda: 0` initializer doesn't seem to cause this to happen. Not sure why. \r\n\r\n**Expected behavior**\r\nThis should \"just work\", unless these features aren't intended to be used together.", "comments": ["I meet the same problem", "Was able to replicate the issue with TF v2.5 ,please find the [gist ](https://colab.research.google.com/gist/mohantym/4966cc2e7c58c329b940713f949452f2/33585.ipynb#scrollTo=CdEj98g42R9r)here ..Thanks!", "@kazimuth I tried to reproduce the issue on Colab using TF v2.7.0 and didn't see the error reported .Could you please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/60aa323a9986e8f947cb0e25d1850342/gist33585.ipynb) for reference ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33585\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33585\">No</a>\n"]}, {"number": 33584, "title": "Better Assertions for LearningRateScheduler", "body": "The assertions used in the LearningRateScheduler test wouldn't show an error if the final learning rate was wrong but smaller than the correct value.", "comments": ["@rchao Can you please take a look on this PR? Thanks!", "Closing outdated PR. Very sorry that we did not review it in time (process issues). If the PR is still relevant, please feel free to open a new PR, and we'll take a look at it asap (new process!)."]}, {"number": 33583, "title": "[XLA:GPU] Expand batchnorm inference by default ", "body": "When  using cudnn for BN inference, there seems to be some constraints imposed on dimension 0 of the input descriptor for `cudnnBatchNormalizationInference` that causes `CUDNN_STATUS_NOT_SUPPORTED` error. The best solution for this is to NOT use cudnn for inference since it is basically pointwise operations that would be much better handled by kernel fusion itself.\r\n\r\n\r\n~While investigating performance of mobilenet, it was found that enabling cuDNN for Batchnorm improves performance by around 10-12%. Running the numbers for a set of convolutional networks in addition to mobilenet with cuDNN turned on for Batchnorm, showed that enabling cuDNN, either improves performance or keeps it the same. This PR enables cudnn for batchnorm by default based on the above-mentioned performance enhancements.~\r\n\r\n~All necessary changes for use of cudnn for fp16 have been made in #32887 and #33259~", "comments": ["@sanjoy Is this ready to be merged? It looks like the dependent PR has been merged (#33259)", "> @sanjoy Is this ready to be merged? It looks like the dependent PR has been merged (#33259)\r\n\r\nNot yet.  I ran our internal benchmarks and it looks like this regresses a keras resnet50 eagner model by more than 10x.  Trying to extract a standalone reproducer now.", "> > @sanjoy Is this ready to be merged? It looks like the dependent PR has been merged (#33259)\r\n> \r\n> Not yet. I ran our internal benchmarks and it looks like this regresses a keras resnet50 eagner model by more than 10x. Trying to extract a standalone reproducer now.\r\n\r\nThanks for the update @sanjoy . ", "Hi Ayan,\r\n\r\nWhen I run with cuDNN batchnorm enabled on https://gist.github.com/sanjoy/1d1655a25cfc52f453bbbe54bda41886 (HLO module, effectively resnet inference) I get an error: \r\n\r\n```\r\ndnn.cc:596] CUDNN_STATUS_NOT_SUPPORTED\r\nin third_party/tensorflow/stream_executor/cuda/cuda_dnn.cc(3575): 'cudnnBatchNormalizationForwardInference( cudnn.handle(), mode, &one, &zero, x_descriptor.handle(), x.opaque(), x_descriptor.handle(), y->opaque(), scale_offset_descriptor.handle(), scale.opaque(), offset.opaque(), estimated_mean.opaque(), maybe_inv_var, epsilon)'\r\n```\r\n\r\nPresumably we're sending convolutions to cuDNN that it doesn't support?\r\n\r\n[edit: this only happens on Titan-V, on P100 the module runs fine.]", "> this only happens on Titan-V, on P100 the module runs fine\r\n\r\nInteresting! The issue seems to be independent of my change...I'll take a look.", "> Hi Ayan,\r\n> \r\n> When I run with cuDNN batchnorm enabled on https://gist.github.com/sanjoy/1d1655a25cfc52f453bbbe54bda41886 (HLO module, effectively resnet inference) I get an error:\r\n> \r\n> ```\r\n> dnn.cc:596] CUDNN_STATUS_NOT_SUPPORTED\r\n> in third_party/tensorflow/stream_executor/cuda/cuda_dnn.cc(3575): 'cudnnBatchNormalizationForwardInference( cudnn.handle(), mode, &one, &zero, x_descriptor.handle(), x.opaque(), x_descriptor.handle(), y->opaque(), scale_offset_descriptor.handle(), scale.opaque(), offset.opaque(), estimated_mean.opaque(), maybe_inv_var, epsilon)'\r\n> ```\r\n> \r\n> Presumably we're sending convolutions to cuDNN that it doesn't support?\r\n> \r\n> [edit: this only happens on Titan-V, on P100 the module runs fine.]\r\n\r\nHey @sanjoy .. I have been able to find the issue and the possible solution. The issue arises from a combination of couple of things: how xla creates input descriptors for cudnn BN inference and how cudnn handles BN inference with specific descriptor configurations. I am working on a fix now. ", "Do you have any update on the performance of any other cases?", "There seem to be some constraints imposed on dimension 0 of the input descriptor for `cudnnBatchNormalizationInference` that is causing this error. We realized that the best fix for this would be NOT to use cudnn for inference since it is basically pointwise operations that would be much better handled by kernel fusion itself. I am pushing a change to this PR to always expand BN inference since that definitely seems to be the right way to go about this issue even from a performance perspective. ", "@sanjoy... also, by any chance was the regression you found related to inference? ", "> @sanjoy... also, by any chance was the regression you found related to inference?\r\n\r\nJust kicked off a run with the latest version of this PR, should have the results by tomorrow.", "TIA #", "@sanjoy  is there anything else we can do on our end in order to make progress on this PR?\r\nPlease let us know.", "> @sanjoy is there anything else we can do on our end in order to make progress on this PR?\r\n> Please let us know.\r\n\r\nRight now I'm trying to triage an OOM I see when I enable this change.  Unfortunately the OOM doesn't happen in isolation, I have to run several TF graphs in the same process one after another to reproduce the OOM so I can't isolate to a single HLO module or TF graph.\r\n\r\nI'm trying to come up with an open source reproducer that runs all the TF graphs necessary to reproduce the OOM that I can share with you.", "Thanks @sanjoy for chasing this down\r\nAs this change does not change clustering, I'm surprised to see an OOM.", "> Right now I'm trying to triage an OOM I see when I enable this change. Unfortunately the OOM doesn't happen in isolation\r\n\r\nThis isn't quite correct.  The _OOM_ does not happen in isolation, but I'm able to see the total memory usage by XLA is higher with this change but not without it.  For https://gist.github.com/sanjoy/727530eef759f92314e17025897e5752\r\n\r\nTotal bytes used without this change 13379927947\r\nTotal bytes used with [edit: was \"without\"] this change 15257771355\r\n\r\nwhich is a 14% increase in memory usage.", "> > Right now I'm trying to triage an OOM I see when I enable this change. Unfortunately the OOM doesn't happen in isolation\r\n> \r\n> This isn't quite correct. The _OOM_ does not happen in isolation, but I'm able to see the total memory usage by XLA is higher with this change but not without it. For https://gist.github.com/sanjoy/727530eef759f92314e17025897e5752\r\n> \r\n> Total bytes used without this change 13379927947\r\n> Total bytes used without this change 15257771355\r\n> \r\n> which is a 14% increase in memory usage.\r\n\r\nYou've used relay_computation with fake_data to get these memory numbers? I'll try to reproduce this. Also, could `allow_growth` be useful in this case while running the original script? ", "> > > Right now I'm trying to triage an OOM I see when I enable this change. Unfortunately the OOM doesn't happen in isolation\r\n> > \r\n> > \r\n> > This isn't quite correct. The _OOM_ does not happen in isolation, but I'm able to see the total memory usage by XLA is higher with this change but not without it. For https://gist.github.com/sanjoy/727530eef759f92314e17025897e5752\r\n> > Total bytes used without this change 13379927947\r\n> > Total bytes used without this change 15257771355\r\n> > which is a 14% increase in memory usage.\r\n> \r\n> You've used relay_computation with fake_data to get these memory numbers?\r\n\r\nI used an internal tool we have called `run_hlo_module` (not sure if there are good reasons to not just open source this).  But `replay_computation` should do the same thing, LMK if it doesn't.\r\n\r\n> I'll try to reproduce this. Also, could `allow_growth` be useful in this case while running the original script?\r\n\r\nNot sure, why do you think `allow_growth` would help?", "> > > > Right now I'm trying to triage an OOM I see when I enable this change. Unfortunately the OOM doesn't happen in isolation\r\n> > > \r\n> > > \r\n> > > This isn't quite correct. The _OOM_ does not happen in isolation, but I'm able to see the total memory usage by XLA is higher with this change but not without it. For https://gist.github.com/sanjoy/727530eef759f92314e17025897e5752\r\n> > > Total bytes used without this change 13379927947\r\n> > > Total bytes used without this change 15257771355\r\n> > > which is a 14% increase in memory usage.\r\n> > \r\n> > \r\n> > You've used relay_computation with fake_data to get these memory numbers?\r\n> \r\n> I used an internal tool we have called `run_hlo_module` (not sure if there are good reasons to not just open source this). But `replay_computation` should do the same thing, LMK if it doesn't.\r\n> \r\n> > I'll try to reproduce this. Also, could `allow_growth` be useful in this case while running the original script?\r\n> \r\n> Not sure, why do you think `allow_growth` would help?\r\n\r\nNow that I think about it, it probably wouldn't help. I was thinking in terms of releasing memory, but figured that isn't allowed to avoid fragmentation. Anyway, based on the memory required  it 's no surprise that it runs out of memory. ", "`replay_computation` gives a round-trip compilation error: \r\n```\r\n2019-11-26 01:50:21.706818: E tensorflow/compiler/xla/tools/replay_computation.cc:458] Compilation failed: Internal: Expected instruction to have shape equal to u32[], actual shape is s32[]:\r\n%get-dimension-size.713 = s32[] get-dimension-size(f32[128,3,306,306]{3,2,1,0} %pad.565), dimensions={0}: hlo { hlo_module { name: \"tower_0_v_cluster_1567701717702666830__.5168\" entry_computation_name: \"\\\r\ntower_0_v_cluster_1567701717702666830__.5168\" computations { name: \"add_float_.342\" instructions { name: \"x.343\" opcode: \"parameter\" shape { element_type: F32 layout { format: DENSE } } metadata { } fron....\r\n```", "Nevermind...I fixed the hlo and was able to run it via replay_computation/fake_data. However, I don't think this is a reliable way to get memory numbers. I used `nvidia-smi -l` to poll for memory usage but was able to reliably get any numbers. There were a couple of spikes in the usage percentage but it mostly remained consistent at around 463MB. I'll try and look into the memory usage of cudnn BN.", "You can get the memory usage as per XLA's buffer assignment this way:\r\n\r\n1. Enable HLO dumping by setting the `XLA_FLAGS` environment variable to `--xla_dump_to=${HLO_DIR}`\r\n\r\n2. `${HLO_DIR}` will have a file named `module_NNNN.after_optimizations-buffer-assignment.txt`.  That file will have a `Total bytes used:  MMMM` line, which is the line I was reporting above.", "> You can get the memory usage as per XLA's buffer assignment this way:\r\n> \r\n> 1. Enable HLO dumping by setting the `XLA_FLAGS` environment variable to `--xla_dump_to=${HLO_DIR}`\r\n> 2. `${HLO_DIR}` will have a file named `module_NNNN.after_optimizations-buffer-assignment.txt`.  That file will have a `Total bytes used:  MMMM` line, which is the line I was reporting above.\r\n\r\nThanks @sanjoy . I was able to reproduce ur results. The TF I used to avoid the contrib issue didn't seem to have this `Total bytes used:` calculation in `BufferAssignement::ToString()` method. The number jumps from 13249775923 to 15622862023 in my case. I'll look into this in detail.", "> > You can get the memory usage as per XLA's buffer assignment this way:\r\n> > \r\n> > 1. Enable HLO dumping by setting the `XLA_FLAGS` environment variable to `--xla_dump_to=${HLO_DIR}`\r\n> > 2. `${HLO_DIR}` will have a file named `module_NNNN.after_optimizations-buffer-assignment.txt`.  That file will have a `Total bytes used:  MMMM` line, which is the line I was reporting above.\r\n> \r\n> Thanks @sanjoy . I was able to reproduce ur results. The TF I used to avoid the contrib issue didn't seem to have this `Total bytes used:` calculation in `BufferAssignement::ToString()` method. The number jumps from 13249775923 to 15622862023 in my case. I'll look into this in detail.\r\n\r\n\r\nThere doesn't seem to be any obvious issue with cudnn that causes this increase. It seems that based on enabling cudnn for BN, in this particular case, the graph ends up being in a state which requires more nodes to be alive at a time. ", "Based on the unexpected issues that might come up, I think it might be better to leave enabling cudnn for batchnorm as an option (rather than enabling it by default). I am reverting the change for setting the cudnn BN flag to true by default. However, the change made to `cudnn_batchnorm_rewriter` is still valid and is required. Modifying the PR details accordingly.", "> LGTM.\r\n> \r\n> Thank you for your patience while I was sorting this out on my end.\r\n> \r\n> I know you were working with @thomasjoerg to figure out why XLA generated batchnorm was slow. Are you still working on that? If we can have fast batchnorm generation from XLA then that seems like a win-win.\r\n\r\nFusion through GTE seemed to be a reason but we later figured out the speedup with cudnn was mainly due to persistent kernels. However, I believe @thomasjoerg had prototyped fusing through GTEs. I remember it working but created massive fusions. I am not sure what happened after that.", "> was mainly due to persistent kernels\r\n\r\nI still don't understand what a \"persistent kernel\" is.  Can you maybe give a brief overview (or point me to documentation elsewhere)?"]}, {"number": 33582, "title": "Update README.md", "body": "in reference to issue #33552 .... Just like the person detection .zip name in the magic-wand documentation the same problem is present.", "comments": ["this should be combined with #33579 , closing this, thank you."]}, {"number": 33581, "title": "Enable use of cudnn for Batchnorm by default", "body": "While investigating performance of mobilenet, it was found that enabling cuDNN for Batchnorm improves performance by around 10-12%. Running the numbers for a set of convolutional networks in addition to mobilenet with cuDNN turned on for Batchnorm, showed that enabling cuDNN, either improves performance or keeps it the same. This PR enables cudnn for batchnorm by default based on the above-mentioned performance enhancements.\r\n\r\nAll necessary changes have been made in https://github.com/tensorflow/tensorflow/pull/32887 and https://github.com/tensorflow/tensorflow/pull/33259", "comments": []}, {"number": 33580, "title": "Throw error on build_pip_package --cpu --gpu", "body": "Previously, running\r\n`./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg --gpu --cpu`\r\nwould fail as desired, but \r\n`./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg --cpu --gpu`\r\nwould succeed.\r\n\r\nThis simple bash script change checks both cases.", "comments": []}, {"number": 33579, "title": "Update README.md", "body": "This update is requested in reference to the issue #33552 \r\n[Under the heading \"Obtain and Import the Library\", the link incorrectly refers to the micro_speech.zip package instead of a person_detection example.]\r\nSo I updated the \"Obtain and Import the Library\" section on  the micro_speech.zip [now: person_detection_example.zip].", "comments": ["please combine #33582 with this PR", "in reference to issue #33552 .... Just like the person detection .zip name in the magic-wand documentation the same problem is present.", "@rthadur would you please check this out: when I click on the person_detection.zip link after update this pops out:\r\n\r\n`\r\nThis XML file does not appear to have any style information associated with it. The document tree is shown below.\r\n<Error nighteye=\"disabled\">\r\n<Code>NoSuchKey</Code>\r\n<Message>The specified key does not exist.</Message>\r\n<Details>\r\nNo such object: tensorflow-nightly/github/tensorflow/tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/person_detection/person_detection.zip\r\n</Details>\r\n</Error>\r\n`\r\n", "@rthadur Why close #33582 ? The magic_wand has the same problem as person_detection in README.md", "@rthadur Please check the update made to the README.md and tell me if its fine now", "This should include the changes from #33582?", "> Yes, the link for `person_detection` is fixed. Also the`magic-wand` documentation needs this same fix as #33582 suggests. You can include the changes from #33582 here in #33579.\r\n\r\nI have added the magic_wand.zip issue just like the person_detection as requested....", "@mihaimaruseac PLease check the updated README.md the rquested line is removed.", "Hello. I'm trying to check a magic wand example. But I couldn't download magic_wand.zip on the README.md."]}, {"number": 33578, "title": "tensorflow model installation fails on windows10,using cmake3.15.4win64 , visual studio anyversion", "body": "following https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\r\nand https://github.com/protocolbuffers/protobuf/blob/master/cmake/README.md \r\n protobuf failing while using command \r\n\r\ncmake -G \"NMake Makefiles\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../../../../install ../..\r\n\r\nerror says : /out:CMakeCCompilerId.exe \r\nCMakeCCompilerId.obj \r\nLINK : fatal error LNK1104: cannot open file 'LIBCMT.lib'\r\n\r\nlib path is given in environment variables.\r\nrunning from command prompt.\r\nattached are error and output files\r\n[CMakeError.log](https://github.com/tensorflow/tensorflow/files/3752000/CMakeError.log)\r\n[CMakeOutput.log](https://github.com/tensorflow/tensorflow/files/3752002/CMakeOutput.log)\r\n\r\n\r\n\r\n", "comments": ["@devitnow15 ,\r\nWe don't support cmake related issue's,  please try installation of TF using bazel refer [this](https://www.tensorflow.org/install/source_windows) link.Thanks!", "I want to train few models for my requirements for which tensorFlow Models Installation is necessary.\r\n\r\nAm following below link :\r\nhttps://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\r\n\r\nTensorflow Object Detection API uses Protobufs to configure model and training parameters.Before the framework can be used, the Protobuf libraries must be downloaded and compiled.\r\nAfter downloading the latest protoc-3.5.1-win32.zip , to configure and compile , cmake is necessary ?\r\nCan I train the models without using Cmake ? Bazel doesnt look like it would server the purpose here.\r\nlet me know how else I can use tensor flow for training models if I need not use cmake ?\r\nI am new to this whole thing , and this is taking away a lot of time", "@devitnow15 ,\r\nUnfortunately we don't support issues related to any other package installer other than bazel. Hence bazel is the only option to install TF. Thanks!", "worked using command prompt of C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build>vcvars64.bat , cd to Google Protobuf\\cmake\\build\\release \r\nand then run command :\r\ncmake -G \"NMake Makefiles\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../../../../install ../..", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33578\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33578\">No</a>\n"]}, {"number": 33577, "title": "additional \"axis\" parameter and different default values of keras.layers.LayerNormalization", "body": "Hello,\r\n\r\n\r\n**System Info**\r\n\r\nTensorflow Version 2.0 \r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThe current (tensorflow 2.0) implementation of keras.layers.LayerNormalization accepts one argument, \"axis\", specifying the axis that should be normalized. The \"center\" and \"scale\" parameter tensors are created with the same shape as the axis that is normalized. The default of this parameter is '-1', i.e. the normalization, re-centering and re-scaling is over the last axis only.\r\n\r\nI think it would be great to adapt the implementation to the behavior of the Tensorflow 1.x implementation in contrib.layers.layer_norm. There, 2 arguments \"begin_norm_axis\" and \"begin_params_axis\" where used. The former specifying the axis to normalize over, the latter to specify the axis to build the center and scale parameters (there called beta and gamma). The default values where \"begin_norm_axis=1\" (i.e. normalize over all axis but the first) and \"begin_param_axis=-1\", i.e. only re-scale and re-center along the last axis. \r\n\r\n**Will this change the current api? How?**\r\n\r\nOnly the implementation of keras.layers.LayerNormalization would be affected.  Note that keras.layers.LayerNormalization is not part of the \"official\" Keras API so it would not create any conflicts. \r\n\r\nThe \"axis\" argument would be replaced by two arguments \"norm_axis\" and \"param_axis\".\r\n\r\n**Who will benefit with this feature?**\r\n\r\nThis is especially relevant for convolutional networks. \r\nIn my experience, the aforementioned default configuration works way better than normalizing, re-scaling and re-centering over a common set of axes.\r\n\r\n\r\n\r\nBest wishes,\r\nPhilipp\r\n\r\n", "comments": [" Keeping `axis=-1` arg only is the intended behavior. By default we should scale/center on the same axes as the axes that are being normalized, so this should default to the same as `axis`.  This also keeps the API of LayerNorm consistent with BatchNorm layer. \r\n\r\nTF addons also has [an implementation](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/normalizations.py) which can be taken as a reference."]}, {"number": 33576, "title": "Decorated function tried to create variables on non-first call", "body": "I am training a TM model using transfer and whin I executing the fit(dataset, epochs=3) I got the following error\r\n\r\n```\r\n`---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-38-c3f14a31606c> in <module>\r\n      2 EPOCHS = 1\r\n      3 \r\n----> 4 model.fit(dataset, epochs=EPOCHS)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    518         # Lifting succeeded, so variables are initialized and we can run the\r\n    519         # stateless function.\r\n--> 520         return self._stateless_fn(*args, **kwds)\r\n    521     else:\r\n    522       canon_args, canon_kwds = \\\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1820   def __call__(self, *args, **kwargs):\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n-> 1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n   2149         if graph_function is None:\r\n-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n   2151           self._function_cache.primary[cache_key] = graph_function\r\n   2152         return graph_function, args, kwargs\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2039             arg_names=arg_names,\r\n   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2041             capture_by_value=self._capture_by_value),\r\n   2042         self._function_attributes,\r\n   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    913                                           converted_func)\r\n    914 \r\n--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n    916 \r\n    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    357         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    360 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)\r\n     71     strategy = distribution_strategy_context.get_strategy()\r\n     72     outputs = strategy.experimental_run_v2(\r\n---> 73         per_replica_function, args=(model, x, y, sample_weights))\r\n     74     # Out of PerReplica outputs reduce or pick values to return.\r\n     75     all_outputs = dist_utils.unwrap_output_dict(\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)\r\n    758       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\r\n    759                                 convert_by_default=False)\r\n--> 760       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    761 \r\n    762   def reduce(self, reduce_op, value, axis):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)\r\n   1785       kwargs = {}\r\n   1786     with self._container_strategy().scope():\r\n-> 1787       return self._call_for_each_replica(fn, args, kwargs)\r\n   1788 \r\n   1789   def _call_for_each_replica(self, fn, args, kwargs):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)\r\n   2130         self._container_strategy(),\r\n   2131         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\r\n-> 2132       return fn(*args, **kwargs)\r\n   2133 \r\n   2134   def _reduce_to(self, reduce_op, value, destinations):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    290   def wrapper(*args, **kwargs):\r\n    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\r\n--> 292       return func(*args, **kwargs)\r\n    293 \r\n    294   if inspect.isfunction(func) or inspect.ismethod(func):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)\r\n    262       y,\r\n    263       sample_weights=sample_weights,\r\n--> 264       output_loss_metrics=model._output_loss_metrics)\r\n    265 \r\n    266   if reset_metrics:\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)\r\n    313     outs = [outs]\r\n    314   metrics_results = _eager_metrics_fn(\r\n--> 315       model, outs, targets, sample_weights=sample_weights, masks=masks)\r\n    316   total_loss = nest.flatten(total_loss)\r\n    317   return {'total_loss': total_loss,\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py in _eager_metrics_fn(model, outputs, targets, sample_weights, masks)\r\n     72         masks=masks,\r\n     73         return_weighted_and_unweighted_metrics=True,\r\n---> 74         skip_target_masks=model._prepare_skip_target_masks())\r\n     75 \r\n     76   # Add metric results from the `add_metric` metrics.\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)\r\n   2061           metric_results.extend(\r\n   2062               self._handle_per_output_metrics(self._per_output_metrics[i],\r\n-> 2063                                               target, output, output_mask))\r\n   2064         if return_weighted_and_unweighted_metrics or return_weighted_metrics:\r\n   2065           metric_results.extend(\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)\r\n   2012       with K.name_scope(metric_name):\r\n   2013         metric_result = training_utils.call_metric_function(\r\n-> 2014             metric_fn, y_true, y_pred, weights=weights, mask=mask)\r\n   2015         metric_results.append(metric_result)\r\n   2016     return metric_results\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in call_metric_function(metric_fn, y_true, y_pred, weights, mask)\r\n   1065 \r\n   1066   if y_pred is not None:\r\n-> 1067     return metric_fn(y_true, y_pred, sample_weight=weights)\r\n   1068   # `Mean` metric only takes a single value.\r\n   1069   return metric_fn(y_true, sample_weight=weights)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __call__(self, *args, **kwargs)\r\n    191     from tensorflow.python.keras.distribute import distributed_training_utils  # pylint:disable=g-import-not-at-top\r\n    192     return distributed_training_utils.call_replica_local_fn(\r\n--> 193         replica_local_fn, *args, **kwargs)\r\n    194 \r\n    195   @property\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in call_replica_local_fn(fn, *args, **kwargs)\r\n   1133     with strategy.scope():\r\n   1134       return strategy.extended.call_for_each_replica(fn, args, kwargs)\r\n-> 1135   return fn(*args, **kwargs)\r\n   1136 \r\n   1137 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in replica_local_fn(*args, **kwargs)\r\n    174     def replica_local_fn(*args, **kwargs):\r\n    175       \"\"\"Updates the state of the metric in a replica-local context.\"\"\"\r\n--> 176       update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\r\n    177       with ops.control_dependencies([update_op]):\r\n    178         result_t = self.result()  # pylint: disable=not-callable\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py in decorated(metric_obj, *args, **kwargs)\r\n     73 \r\n     74     with tf_utils.graph_context_for_symbolic_tensors(*args, **kwargs):\r\n---> 75       update_op = update_state_fn(*args, **kwargs)\r\n     76     if update_op is not None:  # update_op will be None in eager execution.\r\n     77       metric_obj.add_update(update_op)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in update_state(self, y_true, y_pred, sample_weight)\r\n    579         y_pred, y_true)\r\n    580 \r\n--> 581     matches = self._fn(y_true, y_pred, **self._fn_kwargs)\r\n    582     return super(MeanMetricWrapper, self).update_state(\r\n    583         matches, sample_weight=sample_weight)\r\n\r\n<ipython-input-37-0d57172496e6> in accuracy(y_true, y_pred)\r\n      8     # ensure labels have shape (batch_size, MAX_LENGTH - 1)\r\n      9     y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n---> 10     accuracy = tf.metrics.SparseCategoricalAccuracy()(y_true, y_pred)\r\n     11     return accuracy\r\n     12 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, name, dtype)\r\n    762   def __init__(self, name='sparse_categorical_accuracy', dtype=None):\r\n    763     super(SparseCategoricalAccuracy, self).__init__(\r\n--> 764         sparse_categorical_accuracy, name, dtype=dtype)\r\n    765 \r\n    766 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, fn, name, dtype, **kwargs)\r\n    552       **kwargs: The keyword arguments that are passed on to `fn`.\r\n    553     \"\"\"\r\n--> 554     super(MeanMetricWrapper, self).__init__(name=name, dtype=dtype)\r\n    555     self._fn = fn\r\n    556     self._fn_kwargs = kwargs\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, name, dtype)\r\n    452     \"\"\"\r\n    453     super(Mean, self).__init__(\r\n--> 454         reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\r\n    455 \r\n    456 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in __init__(self, reduction, name, dtype)\r\n    291     with ops.init_scope():\r\n    292       self.total = self.add_weight(\r\n--> 293           'total', initializer=init_ops.zeros_initializer)\r\n    294       if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\r\n    295                        metrics_utils.Reduction.WEIGHTED_MEAN]:\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in add_weight(self, name, shape, aggregation, synchronization, initializer, dtype)\r\n    271         collections=[],\r\n    272         synchronization=synchronization,\r\n--> 273         aggregation=aggregation)\r\n    274 \r\n    275   ### End: For use by subclasses ###\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\r\n    520         collections=collections_arg,\r\n    521         synchronization=synchronization,\r\n--> 522         aggregation=aggregation)\r\n    523     backend.track_variable(variable)\r\n    524 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    742         dtype=dtype,\r\n    743         initializer=initializer,\r\n--> 744         **kwargs_for_getter)\r\n    745 \r\n    746     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    137       synchronization=synchronization,\r\n    138       aggregation=aggregation,\r\n--> 139       shape=variable_shape if variable_shape else None)\r\n    140 \r\n    141 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    256   def __call__(cls, *args, **kwargs):\r\n    257     if cls is VariableV1:\r\n--> 258       return cls._variable_v1_call(*args, **kwargs)\r\n    259     elif cls is Variable:\r\n    260       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\r\n    217         synchronization=synchronization,\r\n    218         aggregation=aggregation,\r\n--> 219         shape=shape)\r\n    220 \r\n    221   def _variable_v2_call(cls,\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2046     def creator(next_creator, *args, **kwargs):\r\n   2047       _require_strategy_scope_strategy(strategy)\r\n-> 2048       return next_creator(*args, **kwargs)\r\n   2049 \r\n   2050     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2046     def creator(next_creator, *args, **kwargs):\r\n   2047       _require_strategy_scope_strategy(strategy)\r\n-> 2048       return next_creator(*args, **kwargs)\r\n   2049 \r\n   2050     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2046     def creator(next_creator, *args, **kwargs):\r\n   2047       _require_strategy_scope_strategy(strategy)\r\n-> 2048       return next_creator(*args, **kwargs)\r\n   2049 \r\n   2050     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in invalid_creator_scope(*unused_args, **unused_kwds)\r\n    411       \"\"\"Disables variable creation.\"\"\"\r\n    412       raise ValueError(\r\n--> 413           \"tf.function-decorated function tried to create \"\r\n    414           \"variables on non-first call.\")\r\n    415 \r\n\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```", "comments": ["Please fill in template and provide a short/minimal reproducing example. I already added backticks to the error paste to make it readable, though it is extremely long.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I'm having the same issue. Any updates particularly at train_on_batch?", "@ryanmaxwell96, Please open new issue and provide all the information asked in the template. Thanks "]}, {"number": 33575, "title": "Fix build failures for python 3.8", "body": "This fix tries to address the issue raised in #33543 where tensorflow build on python 3.8 failed.\r\n\r\nThis fix fixed the issue as was suggested in #33543 and pip builds finished successfully.\r\n\r\n**NOTE: tensorflow depends on h5py which does not have python 3.8\r\nsupport yet, as such a release version of tensorflow for python 3.8\r\nmay have to wait for h5py first.**\r\n\r\nThis fix fixes #33543.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Very cool!  Since the blocking factor in providing Tensorflow wheel files for python 3.8 has been other dependencies not having 3.8 support, and since those dependencies now have support, can we have Tensorflow wheel files with Python 3.8 support, please?  Thank you in advance!\r\n\r\nHere's some PyPi links showing Python 3.8 support for some dependencies:\r\nhttps://pypi.org/project/grpcio/#files\r\nhttps://pypi.org/project/h5py/#files\r\nhttps://pypi.org/project/scipy/#files\r\nhttps://pypi.org/project/numpy/#files", "@Mosely https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-571074915", "I see a regression on https://github.com/tensorflow/tensorflow/commit/9ec6997dfbb08c978d31f236c1347db8de6fdf5a. \r\n\r\nEDIT: see my comment https://github.com/tensorflow/tensorflow/commit/9ec6997dfbb08c978d31f236c1347db8de6fdf5a#commitcomment-38824994"]}, {"number": 33574, "title": "The choice of the values of the batch size", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9.0/7.5\r\n- GPU model and memory:Nvidia Geforce 840m\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nScientists over the past years have made significant progress in increasing the speed of neural networks by dividing the data into different patches and their number in the thousands or sometimes millions of images and other data\r\nThe splitting into batches makes the neural network more efficient, but .....\r\nIn spite of this, the large size of the patches leads to weak results of the neural network often\r\nIt is not clear why the size of patches is sometimes appropriate when it is large and sometimes it is appropriate when it is small\r\nBut after research, it was concluded that the gradient noise scale can be useful in determining the appropriate patch size\r\nSince it calculates the noise size approximate to the size of the patch and so it can calculate the size of variation in our data from the model point of view\r\n\r\nWhen the noise scale is small, checking and studying a lot of data in parallel becomes fast, while when its volume is large, we can still learn a lot from large batches.\r\nI have a dataset and I would like to train my own dataset to detect the eye region of human with landmarks.\r\nIn order to perform a good prediction after training , I would like to know if is it possible to calculate the gradient noise scale and adjust this variable with Tensorflow library to get a good value of the batch size?\r\n\r\n**Code to reproduce the issue**\r\nI used this simple CNN to detect the eye region:\r\nhttps://github.com/yinguobing/cnn-facial-landmark\r\n\r\n\r\nThanks.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.", "I have asked this question because I have a bug performance ( the avg loss of the training decrease and increase )", "@abdou31 Can you please provide a small reproducible test case for us to reproduce your bug. Thanks!", "I have used a Github project \"CNN facial landmark\" for detecting eye region ( Resnet Architecture ).\r\nI have trained my model with a dataset ( annotated with 40 points ).\r\nThat was the graph loss:\r\n\r\n![image](https://user-images.githubusercontent.com/19480228/67637519-aae26200-f8db-11e9-9361-e0ed2c8a9e17.png)\r\n\r\nI have tested the model on TestSet images and the result given is below:\r\n\r\nThe blue points: Predictions points\r\nThe green points: Annotations points\r\n\r\n![image](https://user-images.githubusercontent.com/19480228/67637533-c51c4000-f8db-11e9-9077-1e2345c6a23d.png)\r\n\r\nThat was the code for testing the image:\r\n\r\n```python\r\ndef _predict_input_fn():\r\n    \"\"\"Function for predicting.\"\"\"\r\n    return input_fn(\r\n        record_file=\"./data300VW_test.record\",\r\n        batch_size=2,\r\n        num_epochs=1,\r\n        shuffle=False)\r\n\r\n\r\ndef serving_input_receiver_fn():\r\n    \"\"\"An input receiver that expects a serialized tf.Example.\"\"\"\r\n    image = tf.placeholder(dtype=tf.uint8,\r\n                           shape=[IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL],\r\n                           name='input_image_tensor')\r\n    receiver_tensor = {'image': image}\r\n    feature = tf.reshape(image, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL])\r\n    return tf.estimator.export.ServingInputReceiver(feature, receiver_tensor)\r\n\r\n\r\ndef main(unused_argv):\r\n    \"\"\"MAIN\"\"\"\r\n    # Create the Estimator\r\n    estimator = tf.estimator.Estimator(\r\n        model_fn=cnn_model_fn, model_dir=\"./tr2\")\r\n\r\n    # Choose mode between Train, Evaluate and Predict\r\n    mode_dict = {\r\n        'train': tf.estimator.ModeKeys.TRAIN,\r\n        'eval': tf.estimator.ModeKeys.EVAL,\r\n        'predict': tf.estimator.ModeKeys.PREDICT\r\n    }\r\n\r\n    mode = mode_dict['predict']\r\n\r\n```\r\n\r\nI have freezed the model using this code:\r\n\r\n```python\r\n\r\nfrom tensorflow.python.tools import freeze_graph\r\n\r\ninput_meta_graph = \"C:\\\\Users\\\\test\\\\cnn-facial-landmark\\\\tr2\\\\model.ckpt-187690.meta\"\r\ncheckpoint = 'C:\\\\Users\\\\test\\\\cnn-facial-landmark\\\\tr2\\\\model.ckpt-187690'\r\noutput_graph_filename ='C:\\\\Users\\\\test\\\\cnn-facial-landmark\\\\frozen_model_300VW.pb'\r\n\r\ninput_saver_def_path = \"\"\r\ninput_binary = True\r\noutput_node_names = 'logits/BiasAdd,input_to_float'\r\nrestore_op_name = \"save/restore_all\"\r\nfilename_tensor_name = \"save/Const:0\"\r\nclear_devices = False\r\n\r\nfreeze_graph.freeze_graph(\r\n\"\", input_saver_def_path, input_binary, checkpoint,\r\noutput_node_names, restore_op_name, filename_tensor_name,\r\noutput_graph_filename, clear_devices, \"\", \"\", \"\", input_meta_graph)\r\n\r\n```\r\n\r\nand I test the frozen model on a video, the result was so bad as you can see here;\r\n\r\n![image](https://user-images.githubusercontent.com/19480228/67637580-15939d80-f8dc-11e9-8a1d-95e788b36c1d.png)\r\n\r\n\r\nCan you help me to find the source of this problem?\r\n\r\n\r\n", "@abdou31 Please post this question in stack overflow as it not related to bug/performance, build/installation or feature request. Thanks!", "I have solved the problem \r\nThanks."]}, {"number": 33573, "title": "Cannot find the placeholder op that is an input to ReadVariableOp.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 4.15.0-62-generic\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tensorflow-gpu 2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): no\r\n- GCC/Compiler version (if compiling from source): no\r\n- CUDA/cuDNN version:  V10.0.130\r\n- GPU model and memory: rtx 2060 6gb\r\n\r\n\r\n**Describe the current behavior**\r\nI'm unable to perform post-training quantization on my V2 model. \r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import optimizers\r\nfrom tensorflow.keras.datasets import cifar100\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nkeras.backend.clear_session()\r\nkeras.backend.set_learning_phase(0)\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\nimport os\r\n\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\n(x_train, y_train), (x_test, y_test) = cifar100.load_data()\r\nx_train = np.float32(x_train)[:64*(x_train.shape[0]//64)]\r\nx_train /= 255.0\r\ni_shape = x_train[0].shape\r\n\r\ninputs = layers.Input(i_shape)\r\nbase_model = keras.models.Sequential([\r\n    layers.Conv2D(128, 3, padding='same', strides=(2, 2)),\r\n    layers.BatchNormalization(),\r\n    layers.LeakyReLU(0.2),\r\n\r\n    layers.Conv2D(256, 3, padding='same', strides=(2, 2)),\r\n    layers.BatchNormalization(),\r\n    layers.LeakyReLU(0.2),\r\n\r\n    layers.Conv2D(512*100, 3, padding='same', strides=(2, 2)),\r\n    layers.BatchNormalization(),\r\n    layers.LeakyReLU(0.2),\r\n    layers.Flatten(),\r\n    layers.Dense(5*128),\r\n    layers.Reshape((5, 128)),\r\n    layers.LSTM(128),\r\n    layers.Flatten(),\r\n])(inputs)\r\n\r\nprediction = layers.Dense(100, activation='softmax')(base_model)\r\nmodel = keras.Model(inputs=inputs, outputs=prediction)\r\noptimizer = optimizers.Adam(0.00001)\r\nmodel.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])\r\nprint(model.summary())\r\nsaved_model_dir = os.getcwd()\r\noutput_directory = os.getcwd()\r\ntf.saved_model.save(model, saved_model_dir)\r\n\r\n# graph quantization\r\nloaded = tf.saved_model.load(saved_model_dir)\r\n\r\nparams = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\r\n    precision_mode='FP16',\r\n    is_dynamic_op=True,\r\n    maximum_cached_engines=16)\r\nconverter = trt.TrtGraphConverterV2(\r\n    input_saved_model_dir=saved_model_dir,\r\n    input_saved_model_tags=\"serve\",\r\n    input_saved_model_signature_key=\"serving_default\",\r\n    conversion_params=params)\r\nconverter.convert()\r\nsaved_model_dir_trt = output_directory\r\nconverter.save(saved_model_dir_trt)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"optimize_graphv2.py\", line 33, in <module>\r\n    main(args)\r\n  File \"optimize_graphv2.py\", line 22, in main\r\n    converter.convert()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py\", line 960, in convert\r\n    frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/convert_to_constants.py\", line 479, in convert_variables_to_constants_v2\r\n    raise ValueError(\"Cannot find the Placeholder op that is an input \"\r\nValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.\r\n```", "comments": ["any progress on this?", "I have the exact same issue, any insight into whats going on? A workaround / anything?", "@PolinaDemochkina \r\nI ran the shared code on tf nightly and do not face the value error, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/f600487363649dc7aeaa1017345e7362/untitled356.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33573\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33573\">No</a>\n"]}, {"number": 33572, "title": "[tflite] Support INT8 quantization for PACK with TFLITE_BUILTINS_INT8 OpsSet", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14 \r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nSimilar to the UNPACK node issue in https://github.com/tensorflow/tensorflow/issues/31902, the new TFLiteConverter post-training quantisation flow, as described in https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations, does not support quantization of PACK/STACK operation when only integer operations are requested in the output model. When such conversion is attempted the following error is reported:\r\n> RuntimeError: Quantization not yet supported for op: PACK\r\n\r\n**Code to reproduce the issue**\r\nFor example, the script below:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef representative_dataset_gen():\r\n\tinput_1 = np.ones([1, 10],dtype=np.float32)\r\n\tinput_2 = np.ones([1, 10],dtype=np.float32)\r\n\tfor _ in range(10):\r\n\t\tyield [input_1, input_2]\r\n\r\n# tf Graph Input\r\nfoo = tf.compat.v1.placeholder(\"float32\", [1, 10])\r\nbar = tf.compat.v1.placeholder(\"float32\", [1, 10])\r\nout_stacked = tf.stack([foo, bar], axis=0)\r\n\r\nwith tf.compat.v1.Session() as sess:\r\n\ttf.io.write_graph(tf.compat.v1.get_default_graph(), '.','pack.pb', as_text=False)\r\n\r\ninput_name = [\"Placeholder\", \"Placeholder_1\"]\r\noutput_name = [\"stack\"]\r\n\r\ntflite_model_name = \"int8_pack.tflite\"\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\"pack.pb\", input_name, output_name)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_model = converter.convert()\r\nopen(tflite_model_name, \"wb\").write(tflite_model)\r\n\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(tflite_model_name)\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test model on random input data.\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\ninterpreter.invoke()`\r\n```\r\nproduces errors as follows:\r\n```\r\n2019-10-21 14:02:33.682706: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-21 14:02:33.708278: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-10-21 14:02:33.708892: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x33f5a60 executing computations on platform Host. Devices:\r\n2019-10-21 14:02:33.708924: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-10-21 14:02:33.717107: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-10-21 14:02:33.717228: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\nINFO: Initialized TensorFlow Lite runtime.\r\nTraceback (most recent call last):\r\n  File \"pack_example.py\", line 26, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 908, in convert\r\n    inference_output_type)\r\n  File \"/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 200, in _calibrate_quantize_model\r\n    inference_output_type, allow_float)\r\n  File \"/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 78, in calibrate_and_quantize\r\n    np.dtype(output_type.as_numpy_dtype()).num, allow_float)\r\n  File \"/home/jaszha02/Work/venvs/audio/lib/python3.6/site-packages/tensorflow/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 115, in QuantizeModel\r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)\r\nRuntimeError: Quantization not yet supported for op: PACK\r\n```\r\nBoth kTfLiteUInt8 and kTfLiteInt8 version of the PACK operator is already implemented in TFLite (see [pack.cc](https://github.com/tensorflow/tensorflow/blob/186e794d71c17b52deb52ace151ec5add8525f2c/tensorflow/lite/kernels/pack.cc)), so it should be straightforward to support PACK as well in the TFLite Converter.", "comments": ["Any updates?", "Hi, I have a CL in progress to fix this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33572\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33572\">No</a>\n", "Hey, I'm facing the same issue when converting `ssd_mobilenet_v1_fpn_coco` (see [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)) to quantized tflite.\r\nSimple conversion to `float32` tflite works just fine.  \r\n\r\nWith TF 2 I can't even convert the model to tflite proper. \r\n\r\nUsing `tensorflow_gpu` version 1.5.3 on google Colab, Ubuntu 18.04.  \r\nAny help would be much appreciated :pray: \r\n\r\nConversion script looks like this: \r\n```python\r\nimport tensorflow as tf\r\nimport pathlib\r\nimport os\r\nimport cv2\r\nfrom PIL import Image\r\nimport json\r\nimport numpy as np\r\n\r\nfrozen_model = './mobilenet_varroa_w_inputshape/frozen_inference_graph_00/tflite_graph.pb'\r\n# TF 1\r\ninput_shapes = {'normalized_input_image_tensor':(1,896,896,3)}\r\ninput_arrays = ['normalized_input_image_tensor']\r\noutput_arrays = ['TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3']\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(frozen_model, input_arrays, output_arrays, input_shapes)\r\n\r\nconverter.experimental_new_converter = False\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ndef representative_dataset_gen():\r\n    directory_images = \"./rep_dataset/\"\r\n    for img in os.listdir(directory_images):\r\n      tmp_img = Image.open(f\"{directory_images}/{img}\")\r\n      tmp_img = np.array(tmp_img.getdata()).reshape((807, 807, 3)).astype(np.uint8)\r\n      tmp_img = cv2.resize(tmp_img, (896, 896), interpolation=cv2.INTER_AREA)\r\n      input_data = tmp_img.astype('float32')/255.0\r\n      input_data = tf.expand_dims(input_data, 0)\r\n      input_data = tf.convert_to_tensor(input_data, dtype=tf.float32)\r\n      yield [input_data]\r\n\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.allow_custom_ops = True\r\nconverter.inference_input_type = tf.int8 \r\nconverter.inference_output_type = tf.int8 \r\ntflite_quant_model = converter.convert() # crashes on this line\r\nopen(\"mobilenet_test.tflite\", \"wb\").write(tflite_quant_model)\r\n```"]}, {"number": 33571, "title": "Tracing of first batch does not collect compute events", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: unknown\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n**Describe the current behavior**\r\n\r\nUsing `profile_batch=1` for `tf.keras.callbacks.TensorBoard` does not collect any compute calls in the profile/trace\r\n\r\n**Describe the expected behavior**\r\n\r\nSimilar timeline shown as for e.g. `profile_batch=2`.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nimport datetime\r\nimport os\r\n\r\ntf.config.threading.set_inter_op_parallelism_threads(1)\r\n\r\ndatasets, info = tfds.load(name='mnist',\r\n                           with_info=True,\r\n                           as_supervised=True,\r\n                           shuffle_files=False)\r\n\r\nmnist_train, mnist_test = datasets['train'], datasets['test']\r\nstrategy = tf.distribute.OneDeviceStrategy(\"/cpu:0\")\r\n\r\nnum_train_examples = info.splits['train'].num_examples\r\n\r\nBATCH_SIZE_PER_REPLICA = 64\r\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n\r\n\r\ndef scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n    return image, label\r\n\r\n\r\ntrain_dataset = mnist_train.map(scale).cache().shuffle(\r\n    num_train_examples).batch(BATCH_SIZE)\r\neval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\r\n\r\nlog_dir = \"/tmp/tf_logs/fit/\" + datetime.datetime.now().strftime(\r\n    \"%Y%m%d-%H%M%S\")\r\n\r\nwith strategy.scope():\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Conv2D(32,\r\n                               3,\r\n                               activation='relu',\r\n                               input_shape=(28, 28, 1)),\r\n        tf.keras.layers.MaxPooling2D(),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(64, activation='relu'),\r\n        tf.keras.layers.Dense(10, activation='softmax')\r\n    ])\r\n\r\n    model.compile(loss='sparse_categorical_crossentropy',\r\n                  optimizer=tf.keras.optimizers.Adam(),\r\n                  metrics=['accuracy'])\r\n\r\n    callbacks = [\r\n            tf.keras.callbacks.TensorBoard(log_dir=log_dir,\r\n                                           histogram_freq=0,\r\n                                           profile_batch=1)\r\n    ]\r\n    model.fit(train_dataset, epochs=3, steps_per_epoch=20, callbacks=callbacks)\r\n```\r\n\r\n**Other info / logs**\r\n[epoch1.zip](https://github.com/tensorflow/tensorflow/files/3750929/epoch1.zip)\r\n[epoch2.zip](https://github.com/tensorflow/tensorflow/files/3750930/epoch2.zip)\r\n\r\nWhen opening the trace in TensorBoard there is a lot of \"stuff\" in epoch1, but no \"tf_compute\" section as with epoch2", "comments": ["@Flamefire ,\r\nThank you for reporting, when tried to run given i got `NameError: name 'num_train_examples' is not defined`. Can you please provide a complete standalone code to reproduce the issue ?Thanks!\r\n", "Sorry, I cut the code to remove the unnecessary bits, but forgot about that. Added to the above example.", "Was able to reproduce it. Please find the github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/77e75db8bf851b175033e94e4db30f2d/untitled246.ipynb). Thanks!", "Was able to reproduce the issue in TF v2.5 ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/e4d09cb2a2960e6fe319ccfb4bef1b85/untitled23.ipynb)..Thanks !", "Was able to reproduce the issue in TF v2.6 ,please find the gist [`here`](https://colab.research.google.com/gist/kumariko/7f93c660c0b854c9e4b56ed17618cbd5/untitled23.ipynb#scrollTo=X1Zx7UeBKCiq)..Thanks !", "Hi There,\r\n\r\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \r\n\r\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33571\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33571\">No</a>\n"]}, {"number": 33570, "title": " different results in inference between python and c++ ", "body": "\r\nhi, i'm doing a re identification network, implementing a triplet-loss function, at that point everything is fine. the networks works fine in python, I implemented the network on keras with tensorflow as backend, I passed the .hd5 to a .pb file to make inference in tensorflow c++, the probmes is that with the same images the result is difference between python and c++ and I don't know why anyone to help me? \r\nhere is the the model in python: \r\n\r\nimport keras\r\nimport keras.applications\r\nimport keras.layers as layer\r\nimport tensorflow as tf\r\nfrom keras import backend as K\r\nfrom keras.backend.tensorflow_backend import set_session\r\nfrom keras.models import Model as md\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.log_device_placement = True\r\nsess = tf.Session(config=config)\r\nset_session(sess)\r\n\r\n\r\nclass Model:\r\n    def __init__(self, shape):\r\n        self.shape = shape\r\n        self.params = {\r\n            'optimizer': 'sgd',\r\n            'first_neuron': 12,\r\n            'first_max_pooling': 2,\r\n            'second_neuron': 12,\r\n            'second_max_pooling': 2,\r\n            'third_neuron': 20,\r\n            'third_max_pooling': 3,\r\n            'dense_neuron': 64,\r\n            'final_neuron': 128,\r\n        }\r\n        self.feature_model = self.create_features_model()\r\n        self.triplet_model = self.create_model()\r\n\r\n    def create_features_model(self):\r\n        # Define the vision modules\r\n        img_input = layer.Input(shape=(self.shape))\r\n        x = layer.Conv2D(self.params['first_neuron'], (3, 3), activation='relu')(img_input)\r\n        x = layer.MaxPooling2D((self.params['first_max_pooling'], self.params['first_max_pooling']))(x)\r\n        x = layer.Conv2D(self.params['second_neuron'], (3, 3), activation='relu')(x)\r\n        x = layer.MaxPooling2D((self.params['second_max_pooling'], self.params['second_max_pooling']))(x)\r\n\r\n        x = layer.Conv2D(self.params['third_neuron'], (3, 3), activation='relu')(x)\r\n        x = layer.MaxPooling2D((self.params['third_max_pooling'], self.params['third_max_pooling']))(x)\r\n\r\n        x = layer.Flatten()(x)\r\n        x = layer.Dense(self.params['dense_neuron'], activation='relu')(x)\r\n        x = layer.Dense(self.params['final_neuron'], activation='relu')(x)\r\n        out = layer.Lambda(lambda x: K.l2_normalize(x, axis=1), name='t_emb_1_lnorm')(x)\r\n        features_model = md(img_input, out)\r\n\r\n        features_model.summary()\r\n        return features_model\r\n\r\n    def create_model(self):\r\n        base_model = self.feature_model\r\n        # triplet framework, shared weights\r\n        input_shape = (self.shape)\r\n        input_target = layer.Input(shape=input_shape, name='input_target')\r\n        input_positive = layer.Input(shape=input_shape, name='input_pos')\r\n        input_negative = layer.Input(shape=input_shape, name='input_neg')\r\n\r\n        net_target = base_model(input_target)\r\n        net_positive = base_model(input_positive)\r\n        net_negative = base_model(input_negative)\r\n\r\n        # The Lamda layer produces output using given function. Here its Euclidean distance.\r\n        positive_distance = layer.Lambda(self.euclidean_distance, name='pos_dist')([net_target, net_positive])\r\n        negative_distance = layer.Lambda(self.euclidean_distance, name='neg_dist')([net_target, net_negative])\r\n        diference = layer.Lambda(self.euclidean_distance, name='dif')([net_positive, net_negative])\r\n\r\n        # This lambda layer simply stacks outputs so both distances are available to the objective\r\n        distances = layer.Lambda(lambda vects: K.stack(vects, axis=1), name='distance')(\r\n            [positive_distance, negative_distance, diference])\r\n\r\n        model = md([input_target, input_positive, input_negative], distances, name='result')\r\n\r\n        # Setting up optimizer designed for variable learning rate\r\n\r\n        model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=0.00002),\r\n                      loss=self.triplet_loss, metrics=[self.accuracy])\r\n\r\n        return model\r\n\r\n    def triplet_loss(self, _, y_pred):\r\n        margin = K.constant(0.5)\r\n        return K.mean(K.maximum(K.constant(0), K.square(y_pred[:, 0, 0]) - 0.5 * (\r\n                K.square(y_pred[:, 1, 0]) + K.square(y_pred[:, 2, 0])) + margin))\r\n\r\n    def accuracy(self, _, y_pred):\r\n        return K.mean(y_pred[:, 0, 0] < y_pred[:, 1, 0])\r\n\r\n    def lnorm(self, x):\r\n        return K.l2_normalize(x, axis=-1)\r\n\r\n    def euclidean_distance(self, vects):\r\n        x, y = vects\r\n        return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\r\n\r\nand this si how I made inference in python:\r\n\r\n\r\nfrom model import Model as model\r\nfrom keras.utils import HDF5Matrix\r\nimport numpy as np\r\nimport cv2\r\nfrom keras.backend.tensorflow_backend import set_session\r\nimport tensorflow as tf\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.log_device_placement = True\r\nsess = tf.Session(config=config)\r\nset_session(sess)\r\n\r\n\r\ndef load_datasets(in_h5_path, partition='train'):\r\n    if partition == 'train':\r\n        target = HDF5Matrix(datapath=in_h5_path, dataset=\"targets\")\r\n        positive = HDF5Matrix(datapath=in_h5_path, dataset=\"positives\")\r\n        negative = HDF5Matrix(datapath=in_h5_path, dataset=\"negatives\")\r\n        return target, positive, negative\r\n\r\n    else:\r\n        print(\"Invalid 'partition' parameter: Valid values: ['train', 'test']\")\r\n\r\n\r\ntar = cv2.imread(\"/home/amejia/PycharmProjects/triplet_loss/tra1.png\")\r\nnega = cv2.imread(\"/home/amejia/PycharmProjects/triplet_loss/dec1.png\")\r\n\r\ntar = cv2.resize(tar, (32, 32), interpolation=cv2.INTER_CUBIC)\r\nnega = cv2.resize(nega, (32, 32), interpolation=cv2.INTER_CUBIC)\r\nt1 = np.array(tar).reshape((1, 32, 32, 3))\r\nt2 = np.array(nega).reshape((1, 32, 32, 3))\r\ntarget, positive, negative = load_datasets('/home/amejia/PycharmProjects/lossDatasetGenerator/test/test32.h5')\r\nnet = model((32, 32, 3))\r\nnet.triplet_model.load_weights(\"/home/amejia/PycharmProjects/triplet_loss/simple-grande.hdf5\")\r\nenter = [t1, t2, t1]\r\na = net.triplet_model.predict(x=enter, batch_size=1)\r\nprint(a)\r\n\r\nin c++ this si how I made inference:\r\n\r\n tensorflow::Tensor target(tensorflow::DT_FLOAT,\r\n                              tensorflow::TensorShape(\r\n                                      {1, image_size, image_size, 3}));\r\n    tensorflow::Tensor positive(tensorflow::DT_FLOAT,\r\n                                tensorflow::TensorShape(\r\n                                        {1, image_size, image_size, 3}));\r\n\r\n    img_to_float2(tracks, detections, target, positive, frame);\r\n\r\n\r\n    std::vector<std::pair<std::string, tensorflow::Tensor>> Input = {{\"input_target:0\", target},\r\n                                                                     {\"input_pos:0\",    positive},\r\n                                                                     {\"input_neg:0\",    target}};\r\n    std::vector<tensorflow::Tensor> Outputs;\r\n\r\n    tensorflow::Status Status = session->Run(Input, {\"distance/stack:0\"}, {}, &Outputs);\r\n\r\n    auto data = Outputs[0].flat<float>();\r\n\r\n    std::cout << Outputs[0].DebugString() << std::endl;\r\n\r\nand this is the fucntion to put the imges into the tensors:\r\n\r\nvoid LossModel::img_to_float2(Track &tracks, Detection &detections, tensorflow::Tensor &tracksTensor,\r\n                              tensorflow::Tensor &detectionsTensor, cv::Mat &frame) {\r\n\r\n\r\n    auto *tar = tracksTensor.flat<float>().data();\r\n    auto *dec = detectionsTensor.flat<float>().data();\r\n    cv::Mat detectionImg = frame(detections.getBox()).clone();\r\n\r\n    resize(detectionImg, detectionImg, cv::Size(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE), 0, 0,\r\n           cv::INTER_CUBIC);\r\n    cv::Mat resizedImage(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE, CV_32FC3, dec);\r\n    detectionImg.convertTo(resizedImage, CV_32FC3);\r\n\r\n    cv::Mat trackImg = tracks.get_img().clone();\r\n\r\n    resize(trackImg, trackImg, cv::Size(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE), 0, 0,\r\n           cv::INTER_CUBIC);\r\n    cv::Mat resizedImage2(FEATURES_IMG_SIZE, FEATURES_IMG_SIZE, CV_32FC3, tar);\r\n    trackImg.convertTo(resizedImage2, CV_32FC3);\r\n\r\nI hope someone can help me thanks ", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there."]}, {"number": 33569, "title": "tensorflow-1.15.0 manylinux wheel on PyPi is invalid", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.7.1908 (Core)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: virtualenv pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the problem**\r\n\r\nThe published manylinux wheel of tensorflow 1.15.0 on Pypi is invalid:\r\nhttps://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl\r\n\r\n(1.14.0 & 2.0.0 manylinux wheels work fine)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\n[f.horing] ~/tmp $python3.6 -m venv venv\r\n[f.horing] ~/tmp $. venv/bin/activate\r\n(venv) [f.horing] ~/tmp $pip install wheel\r\nCollecting wheel\r\n  Downloading http://build-nexus.prod.crto.in/repository/pypi/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\r\nInstalling collected packages: wheel\r\nSuccessfully installed wheel-0.33.6\r\nYou are using pip version 9.0.3, however version 19.3.1 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n(venv) [f.horing] ~/tmp $python\r\nPython 3.6.8 (default, Aug  7 2019, 17:28:10)\r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from wheel.wheelfile import WheelFile\r\n>>> wf = WheelFile(\"tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl\")\r\n>>> wf.extractall(\"/tmp\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib64/python3.6/zipfile.py\", line 1524, in extractall\r\n    self._extract_member(zipinfo, path, pwd)\r\n  File \"/usr/lib64/python3.6/zipfile.py\", line 1579, in _extract_member\r\n    shutil.copyfileobj(source, target)\r\n  File \"/usr/lib64/python3.6/shutil.py\", line 79, in copyfileobj\r\n    buf = fsrc.read(length)\r\n  File \"/usr/lib64/python3.6/zipfile.py\", line 872, in read\r\n    data = self._read1(n)\r\n  File \"/usr/lib64/python3.6/zipfile.py\", line 962, in _read1\r\n    self._update_crc(data)\r\n  File \"/home/f.horing/tmp/venv/lib64/python3.6/site-packages/wheel/wheelfile.py\", line 91, in _update_crc\r\n    raise WheelError(\"Hash mismatch for file '{}'\".format(native(ef_name)))\r\nwheel.cli.WheelError: Hash mismatch for file 'tensorflow-1.15.0.dist-info/METADATA'\r\n>>> wf = WheelFile(\"tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl\")\r\n>>> wf.extractall(\"/tmp\")\r\n>>> wf = WheelFile(\"tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl\")\r\n>>> wf.extractall(\"/tmp\")\r\n>>>\r\n\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nWe would like to upgrade to tf 1.15 first before upgrading to 2.0.0\r\n", "comments": ["Strange, because `pip install tensorflow==1.15.0` works.", "Yes. But the hash of metadata is still wrong. `pip install` doesn't seem to check that.\r\n\r\nMy use case is that I try to embed the tensorflow wheel in a [pex file](https://github.com/pantsbuild/pex) and that fails. ", "@goldiegadde any idea on what changed between 2.0.0 and 1.15?", "1.15 has the single pip package for CPU/GPU and 2.0 doesn't. As we needed to change pip files for this, it might be the reason for this.", "Can you fix this ?\r\nWe would like to test this single package on GPU/CPU machines before moving on to 2.0.\r\nOtherwise it means we need to upgrade directly to 2.0 which will be more risky.", "2.0 doesn't have a single pip package. @yifeif is working on enabling it for 2.1", "OK. thanks for the info. I wasn't aware of this. That also explains why tf 2.0.0 wheel is so small. \r\n\r\nCan you nevertheless fix this ? I suppose we will have the same issue with 2.1 and we currently use both packages tensorflow-gpu and tensorflow and would like to use only one.\r\n", "Yes, 2.1 should not have this issue again.", "Thanks for reporting @fhoering! Yes we should and will fix this. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33569\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33569\">No</a>\n", "Hi\nJust change the latter part of the file name to py3-none-any.whl then it\nshould work.\n\n2020\ub144 4\uc6d4 10\uc77c (\uae08) 04:35, zpymyyn <notifications@github.com>\ub2d8\uc774 \uc791\uc131:\n\n> wheel pack tensorflow_gpu-1.15.0\n>\n> Hi, thanks for the instructions.\n>\n> I managed to go to step 4, yet my METADATA file is empty, thus can't pack\n> it.\n>\n> Do you mind sharing the METADATA file here?\n>\n> Thanks.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33569#issuecomment-611714819>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AE7D4657KIQ73EN6QXZ2OFTRLYPQNANCNFSM4JC4WDUA>\n> .\n>\n", "> Hi Just change the latter part of the file name to py3-none-any.whl then it should work. 2020\ub144 4\uc6d4 10\uc77c (\uae08) 04:35, zpymyyn <notifications@github.com>\ub2d8\uc774 \uc791\uc131:\r\n> [\u2026](#)\r\n> wheel pack tensorflow_gpu-1.15.0 Hi, thanks for the instructions. I managed to go to step 4, yet my METADATA file is empty, thus can't pack it. Do you mind sharing the METADATA file here? Thanks. \u2014 You are receiving this because you commented. Reply to this email directly, view it on GitHub <[#33569 (comment)](https://github.com/tensorflow/tensorflow/issues/33569#issuecomment-611714819)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AE7D4657KIQ73EN6QXZ2OFTRLYPQNANCNFSM4JC4WDUA> .\r\n\r\nI think I deleted this comment right after posted.\r\nAnyway, thanks."]}, {"number": 33568, "title": "updated code snippets for tensor scatter operation", "body": "Docs code snippets updated to work with TensorFlow 2.0\r\n\r\nDocs updated for following TensorFlow operations : \r\n- `tf.scatter_nd`\r\n- `tf.tensor_scatter_nd_add`\r\n- `tf.tensor_scatter_nd_sub`\r\n- `tf.tensor_scatter_nd_update`\r\n\r\nChanges :\r\n - Removed tf.Session() \r\n - Added `tf.int32` dtype for `tensor` variable as it should be same dtype as `updates` . By default tf.ones() create tensor of dtype `tf.float32`", "comments": []}, {"number": 33567, "title": "Failure to load and remap a 2-D Tensor from checkpoint when variance scaling initializer is used", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution:\r\nos: Darwin\r\nos kernel version: Darwin Kernel Version 17.7.0: Wed Feb 27 00:43:23 PST 2019; root:xnu-4570.71.35~1/RELEASE_X86_64\r\nos release version: 17.7.0\r\nos platform: Darwin-17.7.0-x86_64-i386-64bit\r\nlinux distribution: ('', '', '')\r\nlinux os distribution: ('', '', '')\r\nmac version: ('10.13.6', ('', '', ''), 'x86_64')\r\n- TensorFlow installed from (source or binary): NO\r\n- TensorFlow version (use command below):\r\ntf.version.VERSION = 1.14.0\r\ntf.version.GIT_VERSION = v1.14.0-rc1-22-gaf24dc91b5\r\ntf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)\r\n- Python version:\r\n(major, minor, micro, releaselevel, serial)\r\n(2, 7, 15, 'final', 0)\r\n- Bazel version (if compiling from source): NO\r\n- GCC/Compiler version (if compiling from source): NO\r\n- CUDA/cuDNN version: NO\r\n- GPU model and memory: NO\r\n\r\n**Describe the current behavior**\r\nI train with the estimator api and I wish to warm start a 2d variable (which I use as embedding). My old model has different embedding vocabulary than the new one so I pass a WarmStartSettings structure including tf.estimator.VocabInfo.\r\nIf I pass tf.estimator.VocabInfo without specifying a backup_initializer, the 0 initializer is used as default and the warm start and training finish successfully. However when I pass a backup_initializer, like tf.compat.v1.initializers.variance_scaling, I get a TypeError, which it looks like is caused because the initializer requires that its shape is a non Tensor, but the gen_checkpoint_ops.generate_vocab_remapping returns Tensors which are passed to the initilizer as shape.\r\n\r\n**Describe the expected behavior**\r\nAbility to load and remap a 2-D Tensor from a checkpoint when a custom initializer is used. So eventually be able to warm start whenever my new model embeddings have different vocabularies than the old\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.training import checkpoint_ops\r\n\r\nif __name__ == '__main__':\r\n    initializer = tf.compat.v1.initializers.variance_scaling(scale=0.175, mode=\"fan_in\", distribution='uniform')\r\n\r\n    old_row_vocab_file = './old_vocab_path'  # text file with 2 rows\r\n    new_row_vocab_file = './new_vocab_path'  # text file with 2 rows\r\n\r\n    checkpoint_ops._load_and_remap_matrix(ckpt_path='', old_tensor_name='old_tensor/name', new_row_vocab_offset=0,\r\n                                          num_rows_to_load=2, new_col_vocab_size=3, initializer=initializer,\r\n                                          old_row_vocab_size=-1, old_row_vocab_file=old_row_vocab_file,\r\n                                          new_row_vocab_file=new_row_vocab_file)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nFile \"/env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1365, in _train_with_estimator_spec\r\n    warm_starting_util.warm_start(*self._warm_start_settings)\r\n  File \"/env/lib/python2.7/site-packages/tensorflow/python/training/warm_starting_util.py\", line 460, in warm_start\r\n    axis=vocab_info.axis)\r\n  File \"/env/lib/python2.7/site-packages/tensorflow/python/training/warm_starting_util.py\", line 301, in _warm_start_var_with_vocab\r\n    init(shape=v_shape, partition_info=partition_info))\r\n  File \"/env/lib/python2.7/site-packages/tensorflow/python/training/checkpoint_ops.py\", line 414, in _initializer\r\n    max_rows_in_memory=max_rows_in_memory)\r\n  File \"/env/lib/python2.7/site-packages/tensorflow/python/training/checkpoint_ops.py\", line 179, in _load_and_remap_matrix\r\n    num_rows_present * num_cols_present, 1\r\n  File \"/env/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 515, in __call__\r\n    fan_in, fan_out = _compute_fans(scale_shape)\r\n  File \"/env/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 1447, in _compute_fans\r\n    return int(fan_in), int(fan_out)\r\nTypeError: int() argument must be a string or a number, not 'Tensor'\r\n```\r\n", "comments": ["@mbartzokas, Please provide the minimal standalone code to replicate the issue. Thanks!", "Hi @gadagashwini, the code under \"Code to reproduce the issue\" above is the minimal to reproduce it and give you the traceback below. The code never reaches the point when it reads the checkpoints or the files so it doesn't matter that I don't pass actual checkpoints or files.\r\n```\r\nTraceback (most recent call last):\r\n  File \"...../reproduce.py\", line 122, in <module>\r\n    new_row_vocab_file=new_row_vocab_file)\r\n  File \"...../venv/lib/python2.7/site-packages/tensorflow/python/training/checkpoint_ops.py\", line 179, in _load_and_remap_matrix\r\n    num_rows_present * num_cols_present, 1\r\n  File \"...../venv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 515, in __call__\r\n    fan_in, fan_out = _compute_fans(scale_shape)\r\n  File \"...../venv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 1447, in _compute_fans\r\n    return int(fan_in), int(fan_out)\r\nTypeError: int() argument must be a string or a number, not 'Tensor'\r\n```", "Issue is replicating with Tf 1.14.0. and Tf 1.15.0 as well. Please take a look at gist [TF1.14](https://colab.sandbox.google.com/gist/gadagashwini/3cb2e1c7ab8bfd2e5b56e564d40fe09e/untitled220.ipynb) and [TF1.15](https://colab.sandbox.google.com/gist/gadagashwini/f5b2125bf080bfc7b2d0c2c87bcd50e0/untitled221.ipynb) .Thanks!\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33567\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33567\">No</a>\n"]}, {"number": 33566, "title": "TimeseriesGenerator for labeled time-series such as sensor data", "body": "**System information**\r\n- TensorFlow version: v2.0.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently,  `TimeseriesGenerator` gets `data` and `target` as input and return a generator that can be used for iterating over a time-series with a sliding window.\r\n- If `row` is the current time-point,  then for each time-window of length `[row - self.length, ..., row`] , the  `target` is chosen as the`self.targets[row]`.  This means the `target` (label) for a time-window is chosen to be the last observed label.\r\n\r\nSometimes, this is not the right assumption. For example, consider this time-series and the related labels:\r\n```python\r\ndata    = [a,a,a,a,a,a,a,a,a,a,a,b,b,b,b,b,b,b,b,b,b,b,b,b,c,c,c,c,c,c,c,c]\r\ntarget =  [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2]\r\n```\r\nIf we choose `length=8` and `stride=4`, then it generates these windows:\r\n```python\r\na,a,a,a,a,a,a,a >  0  (Good label!)\r\na,a,a,a,a,a,a,b >  1  (Bad label!)\r\na,a,a,b,b,b,b,b > 1 (Not Good label!)\r\nb,b,b,b,b,b,b,b > 1 (Good label!)\r\nb,b,b,b, c,c,c,c > 2 (Bad label!)\r\nc,c,c,c,c,c,c,c, > 2 (Good label!)\r\n```\r\nSo, as you see, if I use this method in training (e.g. for an activity recognition method based on accelerometer time-seires) then some windows will be labeled in a Not Good way!\r\n\r\n**There should be a feature to choose if we want this behavior or not!**\r\n\r\nThere are two ideas:\r\n1. to simply ignore these windows with an inconsistent label in the beginning and the end! I mean just jump over them until we get a window that label is same for all the time-points. like this:\r\n```python\r\ntargets = np.array([self.targets[row] for row in rows if self.targets[row - self.length] == self.targets[row]])\r\n```\r\n2. Using the `mode` of the target window as the label. like this:\r\n```python \r\ntargets = np.array([ max(set(self.targets[row - self.length:row:self.sampling_rate] ), key=list.count) for row in rows])\r\n```\r\n\r\n**Will this change the current api? How?**\r\nThere are two ways to handle this:\r\n1.  To add more options to the current `TimeseriesGenerator` that will change the current api for this class.\r\n2. To add another class and call it something like \"LabeledTimeseriesGenerator\" that extends the `TimeseriesGenerator` and overrides the `__getitem__` function.\r\n\r\n**Who will benefit with this feature?**\r\nPeople who use Tensorflow for training a classifier on labeled time-series of mobile and wearable sensors or using financial data time-series.", "comments": ["Thanks for the write-up.\r\nI'm not sure I understand the use case here -- this generator are mostly for RNN models, which we do need target to be the label as value of the last time step.\r\nWhat's `sensor_data` in this case and how do you wanna use it?", "> Thanks for the write-up.\r\n> I'm not sure I understand the use case here -- this generator are mostly for RNN models, which we do need target to be the label as value of the last time step.\r\n> What's `sensor_data` in this case and how do you wanna use it?\r\n\r\nThe use case explained here is mostly useful in other kinds of time series (such as mobile and wearable sensor data) or when time series are processed in a sliding window manner.\r\n\r\nIn such a situation, the label is the majority across all the labels in the current window, not the last one.\r\n\r\nBTW, maybe it is much better to have a class extended from this for that purpose.\r\n\r\n`sensor_data` for example is 3-seconds of smartwatch accelerometer readings. ", "@mmalekzadeh I'm confused. Why can't you just shift your target to be however many items ahead you want? Wouldn't that achieve what you want? You can do this in pandas, for example with [pandas.Series.shift(-lookout_period)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.shift.html). `TimeSeriesGenerator` looks back from `dataset[row]` then uses the current `target[row]` as the target... but you get to decide what target is. You can make it anything. To predict 5 periods in the future, just shift if negative five places. You will need to drop any records without a future item, equal to the lookup period of items in your dataset/targets.", "@mmalekzadeh,\r\nSorry for the delayed response. The use that you provided is not completely clear. Confusing part in your use-case is that you are using only one label for a series of Inputs. Please refer the latest [Tutorial on Time Series](https://www.tensorflow.org/tutorials/structured_data/time_series) and let us know if you still need some additional features.\r\n\r\nThanks!", "I agree that there are different interpretations of `target` for a time window.\r\n\r\nWhat I was trying to suggest is that if we consider `length=N`, this means that we generate a window including `N` samples. \r\nWe also have `N` targets associated with each of these `N` samples.\r\n\r\nSo, currently, this method considers the last target as the target of the whole window. \r\n\r\nBut in some applications, users may need to choose the `mode` of the `N` targets.\r\n\r\nThis is not a critical feature though as it depends to the application.", "@mmalekzadeh ,\r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33565, "title": "Keras Model cannot be saved as .h5 when tf.keras.backend.clip is used", "body": "\r\n**System information**\r\n- Tensorflow 2.0.0\r\n- Python 3.7.4\r\n\r\n**Current behavior**\r\nI'm using the `tf.keras.backend.clip` function in a model and cannot save it because of a naming problem: Two layers have the same name (see `tf_op_layer_clib_by_value_16` in the ModelToDot output below). This causes a problem when exporting it to hdf5.\r\n\r\nCouldn't find a workaround or way to rename one of the two layers.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ninput1 = keras.layers.Input(shape = (16,), name = iname)\r\ndense1 = keras.layers.Dense(1, name = 'dense1', activation = None, # relu\r\n                       #kernel_initializer=keras.initializers.constant(dAB1_kernel),\r\n                       #kernel_constraint=keras.constraints.NonNeg(),\r\n                       use_bias=True)(input1)\r\ndense1_clip = tf.keras.backend.clip(dense1,min_value = 0, max_value = 1000)\r\n\r\nmodel1 = keras.Model(input1, dense1_clip)\r\n\r\n```\r\n\r\n![bug](https://user-images.githubusercontent.com/47213738/67195858-0606e700-f3fa-11e9-8ad4-80d6f425fe63.PNG)\r\n\r\n\r\n\r\n**Other info / logs**\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-179-97bae6c176be> in <module>\r\n      7 \r\n      8 model1 = keras.Model(input1, dense1_clip)\r\n----> 9 model1.save('m1.h5')\r\n\r\nd:\\programme\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n    973     \"\"\"\r\n    974     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n--> 975                       signatures, options)\r\n    976 \r\n    977   def save_weights(self, filepath, overwrite=True, save_format=None):\r\n\r\nd:\\programme\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n    110           'or using `save_weights`.')\r\n    111     hdf5_format.save_model_to_hdf5(\r\n--> 112         model, filepath, overwrite, include_optimizer)\r\n    113   else:\r\n    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n\r\nd:\\programme\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)\r\n    107     model_weights_group = f.create_group('model_weights')\r\n    108     model_layers = model.layers\r\n--> 109     save_weights_to_hdf5_group(model_weights_group, model_layers)\r\n    110 \r\n    111     # TODO(b/128683857): Add integration tests between tf.keras and external\r\n\r\nd:\\programme\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py in save_weights_to_hdf5_group(f, layers)\r\n    623 \r\n    624   for layer in layers:\r\n--> 625     g = f.create_group(layer.name)\r\n    626     weights = _legacy_weights(layer)\r\n    627     weight_values = K.batch_get_value(weights)\r\n\r\nd:\\programme\\python37\\lib\\site-packages\\h5py\\_hl\\group.py in create_group(self, name, track_order)\r\n     66             name, lcpl = self._e(name, lcpl=True)\r\n     67             gcpl = Group._gcpl_crt_order if track_order else None\r\n---> 68             gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)\r\n     69             return Group(gid)\r\n     70 \r\n\r\nh5py\\_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py\\_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py\\h5g.pyx in h5py.h5g.create()\r\n\r\nValueError: Unable to create group (name already exists)\r\n```\r\n\r\n", "comments": ["@oholimoli Tried to reproduce your issue in google colab using the lastest version of Tensorflow i.e., 2.1.0-dev20191021 but was not able to reproduce it. Please find the gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/5cf063d9e3509684b288f1839b1252e4/untitled203.ipynb#scrollTo=b9F2THOpllp3).", "If you try model.save('model.h5') instead you will get the same error.", "@oholimoli This is indeed a bug in Tensorflow 2.0. In tensorflow 2.0, you can change \".h5\" to \".tf\" and everything should be saved.\r\n\r\nThere is also a workaround to save the model in.h5 format and its mentioned in this [comment](https://github.com/keras-team/keras/issues/12195#issuecomment-544416524). ", "This is fixed with latest tf nightly '2.2.0-dev20200129'. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33565\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33565\">No</a>\n"]}, {"number": 33564, "title": "TFLite metal delegate can't share MTLDevice", "body": "**System information**\r\n- TensorFlow version (you are using):master branch\r\n- Are you willing to contribute it (Yes/No):Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAs Apple [the official document](https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/PersistentObjects.html) mentioned, all apps should create only one MTLDevice object.\r\n\r\n> All apps should create only one MTLDevice object per GPU and reuse it for all your Metal work on that GPU. Most apps should create only one MTLCommandQueue object per GPU, though you may want more if each command queue represents different Metal work (for example, non-real-time compute processing and real-time graphics rendering)..\r\n\r\nHowever, the current TFLite implementation doesn't have the interface to share MTLDevice as [metal_delegate.mm](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/metal_delegate.mm) shows.\r\n\r\n```mm\r\n  explicit Delegate(const TFLGpuDelegateOptions* options) {\r\n    if (options) {\r\n      options_ = *options;\r\n    } else {\r\n      // Default options.\r\n      options_.allow_precision_loss = false;\r\n      options_.wait_type = TFLGpuDelegateWaitType::TFLGpuDelegateWaitTypePassive;\r\n    }\r\n    metal_device_ = MTLCreateSystemDefaultDevice();\r\n```\r\nThis issue is critical for me since I should integrate TFLite into the existing metal application.\r\nWould you like to improve this initialization function?\r\nOne of my idea is that adds default MTLDevice parameter to TFLGpuDelegateOptions.\r\nIf you need, I will send PR.\r\n", "comments": ["Hi Shintaro, thanks for the request. Yes, we plan (November) to support passing the device into the delegate. It also allows to use multiple devices on macos.", "@NikolayChirkov Any news about this feature ?\r\nI am looking forward to getting updates from you. Thanks again.", "@stakemura \r\n\r\nSorry, @NikolayChirkov has switched teams and isn't working on TFLite GPU anymore.  Thus, we don't have a maintainer for Metal.\r\n\r\n@miaout17 \r\n\r\nIIRC there is some complexities with ObjC and Swift.  How do you feel we should proceed?  I think support of this functionality is now up to you guys, from the API's point of view.", "@miaout17\r\nI have waited for the response for a long time.\r\nWould you like to give me a reply?\r\n", "(I'm sorry for the delay -- Missed these message due to my notification settings)\r\n\r\nDid you run into any real problems with this issue on iOS devices?\r\nIf I understand correctly, [MTLCreateSystemDefaultDevice](https://developer.apple.com/documentation/metal/1433401-mtlcreatesystemdefaultdevice) returns a reference to the preferred default Metal device object, so it's not really creating multiple devices when it's called more than once. \r\n\r\nIf you want to pass a `MTLDevice` for some reasons, I think it's possible to make the change. \r\n\r\nReplying to @impjdi 's question:\r\n\r\n> IIRC there is some complexities with ObjC and Swift. How do you feel we should proceed? I think support of this functionality is now up to you guys, from the API's point of view.\r\n\r\nI think this is possible. The only constraint is that `TFLGpuDelegateOptions` should to be in pure C. We can either define a `void *` or a forward decelerated structure in `TFLGpuDelegateOptions` to represent `MTLDevice`. ", "Yeah, we changed it from C-compatible to ObjC-compatible, because we didn't foresee Swift usage.  I think it's fine to use `void*`.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 33563, "title": "tf.io.GFIle not working correctly with UTF-8 files and Python3", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu\r\n- TensorFlow installed from (source or binary): source internal Google\r\n- TensorFlow version (use command below): 1.5.0, internal Google\r\n- Python version: 3.6.7\r\n\r\n**Describe the current behavior**\r\nCalling 'read(X)' on the text files opened with GFile in python3 doesn't work properly (it fetches X bytes rather than X characters). This often results with the UnicodeDecodeError (as the read can happen in the middle of the unicode character).\r\n\r\n**Describe the expected behavior**\r\nIt should behave like python3: reading the X characters.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python\r\nmy_text = 'B\u00e4ren'\r\nwith open('/tmp/ex1', 'w') as f:\r\n  f.write(my_text)\r\n\r\n// Will read the whole string correctly.\r\nwith open('/tmp/ex1', 'r') as f:\r\n  print(f.read())\r\n\r\n// This will print 2 chars Ba\r\nwith open('/tmp/ex1', 'r') as f:\r\n print(f.read(2))\r\n\r\n// This will print 3 chars: Bar\r\nwith open('/tmp/ex1', 'r') as f:\r\n print(f.read(3))\r\n\r\n// This will print the whole thing.\r\nwith tf.io.gfile.GFile('/tmp/ex1', 'r') as f:\r\n  print(f.read())\r\n\r\n// This will crash.. :-(\r\nwith tf.io.gfile.GFile('/tmp/ex1', 'r') as f:\r\n  print(f.read(2))\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nThe error will be:\r\n```\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 1: unexpected end of data\r\n```\r\n", "comments": ["Confirmed in tf-nightly and python3.7", "I think it is possible to check the utf8 length while reading, and compensate the remaining bytes. Created a PR #33590 for the fix.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33563\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33563\">No</a>\n"]}, {"number": 33562, "title": "symbol \"_SaverDef_default_instance_\" becomes undefined after updating tensorflow from 1.2 to 1.12", "body": "symbol \"_SaverDef_default_instance_\" becomes undefined after updating tensorflow from 1.2 to 1.12\r\n\r\nwhat dependency shoud i add to BUILD file?\r\n\r\n_SaverDef_default_instance_ is in cc file generated by tensorflow/core/framework/saver.proto in 1.2\r\n\r\nin 1.12, saver.proto is not compiled. has the target changed?\r\n\r\nthe dependency targets in BUILD are:\r\n       \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/cc:client_session\",\r\n        \"//tensorflow/core:tensorflow\"\r\n\r\n\r\n\r\nEnv Info:\r\ntensorflow:  HEAD detached at v1.12.1\r\n                    https://github.com/tensorflow/tensorflow.git\r\n\r\n```shell\r\ncommit c20310273f663b1dbf9ca9e68068784d44a95ae2\r\nMerge: cc494ee f303882\r\nAuthor: TensorFlower Gardener <gardener@tensorflow.org>\r\nDate:   Thu Apr 18 06:15:58 2019 -0700\r\n\r\n    Merge pull request #27699 from yongtang:27497-ragged-axis\r\n    \r\n    PiperOrigin-RevId: 244173513\r\n```\r\n\r\nbazel:  get from https://releases.bazel.build/0.25.0/rc3/index.html\r\n\r\nos: centos7 \r\nkernel: 3.10.107 \r\ngcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)\r\ncpu:\r\n```shell\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\nThread(s) per core:    1\r\nCore(s) per socket:    8\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 94\r\nModel name:            Intel(R) Xeon(R) Gold 61xx CPU\r\nStepping:              3\r\nCPU MHz:               2494.140\r\nBogoMIPS:              4988.28\r\nHypervisor vendor:     KVM\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              4096K\r\nNUMA node0 CPU(s):     0-7\r\n```\r\n\r\n\r\ndir structure: tensorflow-1.12(git root)/tensorflow/my_implement/BUILD\r\nBUILD file:\r\n```shell\r\ncc_binary(\r\n    name = \"libMyImplement.so\",\r\n    srcs = [\"my_implement.h\",\r\n            \"my_implement.cc\",\r\n            ],\r\n    linkshared = 1,\r\n    deps = [\r\n        \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/cc:client_session\",\r\n        \"//tensorflow/core:tensorflow\"\r\n        ],\r\n)\r\n```\r\n\r\n\r\n\r\n\r\nit reports symbol \"_SaverDef_default_instance_\" undefined while loading libMyImplement.so which compiled in v1.12.1\r\n\r\ni think maybe something i forget to add to deps list. or should i execute some ./configure command with any special parameter before compiling?\r\n\r\nthere is no errors loading libMyImplement.so compiled in tensorflow v1.2.0\r\n\r\nand i have tried compile libMyImplement.so in tensorflow v1.13, and there is still this error", "comments": ["@RaymondReddington ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "\r\n\r\n\r\n> @RaymondReddington ,\r\n> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n> Make sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n> We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\ni have update my description", "@RaymondReddington ,\r\nRather than upgrading tensorflow version, can you please try building Tensorflow from the scratch for 1.12.1 using this [link](https://www.tensorflow.org/install/source)?Thanks!", "> @RaymondReddington ,\r\n> Rather than upgrading tensorflow version, can you please try building Tensorflow from the scratch for 1.12.1 using this [link](https://www.tensorflow.org/install/source)?Thanks!\r\n\r\nnow i'm on branch r1.12\r\n```shell\r\ncommit 5b900cfe4b3b848f577315a0dde09a729f770e95\r\nAuthor: Mihai Maruseac <mihaimaruseac@google.com>\r\nDate:   Fri Jun 21 09:50:12 2019 -0700\r\n\r\n    Update install_python3.6_pip_packages.sh to use apt.\r\n    \r\n    Now python3.6 can be installed from apt and it will be installed with\r\n    all submodules.\r\n    \r\n    If we're compiling Python from source, during compilation we get:\r\n    \r\n    ```\r\n    The necessary bits to build these optional modules were not found:\r\n    _bz2                  _dbm                  _gdbm\r\n    _lzma                 _sqlite3              _tkinter\r\n    readline\r\n    ```\r\n    \r\n    which then results in\r\n    \r\n    ```\r\n    ==================== Test output for //bazel_pip/tensorflow/contrib/summary:summary_ops_test:\r\n    Running test /tmpfs/src/github/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_kbuilder/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/bazel_pip/tensorflow/contrib/summary/summ\r\n    Traceback (most recent call last):\r\n      File \"/tmpfs/src/github/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_kbuilder/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/bazel_pip/tensorflow/contrib/summary/summary_o\r\n        import sqlite3\r\n      File \"/usr/local/lib/python3.6/sqlite3/__init__.py\", line 23, in <module>\r\n        from sqlite3.dbapi2 import *\r\n      File \"/usr/local/lib/python3.6/sqlite3/dbapi2.py\", line 27, in <module>\r\n        from _sqlite3 import *\r\n    ModuleNotFoundError: No module named '_sqlite3'\r\n    ================================================================================\r\n    ```\r\n    \r\n    and similar failures which then block releasing patch version.\r\n```\r\nand following the steps in the link you give.\r\ni get some error when do this step:\r\n```shell\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nerror is:\r\n```\r\n //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nERROR: /data/tensorflow/tensorflow-r1.12/WORKSPACE:3:1: name 'http_archive' is not defined\r\nERROR: Error evaluating WORKSPACE file\r\nERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package\r\nERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package\r\nINFO: Elapsed time: 1.949s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n```\r\n\r\nmy bazel version is 0.25.0 rc3\r\n./configure command has checked bazel version and no error found.\r\nso how to solve this ?(and i dont know whether the output things of this step will be used for my c++ implement in the future)\r\n\r\nand another question: which verison of python should i use? 2.7 or 3.6? i choose 2.7 in  ./configure", "@oanush \r\ncompiling can be done by using bazel 0.18.0 in branch r1.12.\r\nit occurs this error after removing flag linkshared=1 in my own BUILD file :\r\n```shell\r\nbazel-out/k8-opt/bin/tensorflow/core/_objs/protos_all_proto_text/saved_tensor_slice.pb_text.o:saved_tensor_slice.pb_text.cc:function tensorflow::internal::AppendProtoDebugString(tensorflow::strings::ProtoTextOutput*, tensorflow::SavedSliceMeta const&): error: undefined reference to 'tensorflow::_SavedSliceMeta_default_instance_'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/lstm_kernel:libDeepNlpModelEn.so failed to build\r\n```\r\njust like the error symbol '_SaverDef_default_instance_' becomes undefined when loading libDeepNlpModelEn.so compiled with flag linkshared=1\r\n\r\nand my question is: what is *saver* symbol? i've found it is defined in saver.pb.h/saver.pb.cc\r\nbut saver.pb.o is not found.\r\nany compile dependence should i append to deps list?", "@sukritiramesh @tensorflower-gardener @christisg @jhseu \r\nhow to add saver.pb dependence for c++ implemention?", "@oanush \r\ni have modified BUILD like this:\r\n```shell\r\ncc_binary(\r\n    name = \"myimplement\",\r\n    srcs = [ \"my_implement.h\", \"my_implement.cc\" ],\r\n    data = [\r\n        \"//tensorflow/core:android_proto_srcs\",\r\n        \"//tensorflow/core:protos_all_proto_text\",\r\n    ],\r\n)\r\ncc_proto_library(\r\n    name = \"myproto\",\r\n    deps  = [\r\n        \":myproto_text\",\r\n    ],\r\n)\r\n\r\nproto_library (\r\n    name = \"myproto_text\",\r\n    data = [\r\n        \"//tensorflow/core:protos_all_proto_text\",\r\n    ],\r\n)\r\n```\r\nit seems that it does compiling some more proto,\r\nbut not the proto i need.\r\nit still has the error:\r\n```shell\r\nbazel-out/k8-opt/bin/tensorflow/core/_objs/protos_all_proto_text/saved_tensor_slice.pb_text.o:saved_tensor_slice.pb_text.cc:function tensorflow::internal::AppendProtoDebugString(tensorflow::strings::ProtoTextOutput*, tensorflow::SavedSliceMeta const&): error: undefined reference to 'tensorflow::_SavedSliceMeta_default_instance_'\r\ncollect2: error: ld returned 1 exit status\r\nINFO: Elapsed time: 100.226s, Critical Path: 85.13s\r\n```", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33562\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33562\">No</a>\n"]}]