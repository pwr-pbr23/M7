[{"number": 38805, "title": "TF 2.x Java Binding ", "body": "I am reading this doc - https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary\r\n\r\nThis page tells for TF 2.1.0 java binding is available , however when i check  https://mvnrepository.com/artifact/org.tensorflow where can i find TF 2.1.0 java library ?\r\n\r\n", "comments": ["any ETA on this  ?"]}, {"number": 38804, "title": "model.predict(tensor_array) returns predictions[0] instead of all predictions[:]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nno\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nwin 10 v 1909 b 18363.778\r\n\r\n- TensorFlow installed from (source or binary):\r\npip install \r\n- TensorFlow version (use command below): 2.1.0.\r\n- Python version: v3.6.8:3c6b436a57\r\n- CUDA/cuDNN version:  10.1.243\r\n- GPU model and memory: RTX 2080\r\n\r\n**Describe the current behavior**\r\nThe following code to classify digits returns only one prediction\r\n\r\n![image](https://user-images.githubusercontent.com/12736950/80022234-0b91d680-84dc-11ea-85bf-7f1956d8d742.png)\r\n\r\ninput: [[...],[....],[...],[...],[...]]\r\n\r\n```\r\ndef predict(list_images):\r\n    global model\r\n    predictions = model.predict(list_images)\r\n    return predictions\r\n```\r\noutput: [[...]]\r\n\r\n![image](https://user-images.githubusercontent.com/12736950/80019526-f2872680-84d7-11ea-88cc-9aa0eba2d669.png)\r\n\r\n\r\n**Describe the expected behavior**\r\nthe same function should return the same number of predictions as input tensors (like in jupyter notebooks)\r\n\r\ninput: [[...],[....],[...],[...],[...]]\r\n\r\n```\r\nmodel = tf.keras.models.load_model('number_ocr_v2')\r\n\r\ndef predict(list_images):\r\n    global model\r\n    print(\"length:\")\r\n    print(len(list_images))\r\n    #predictions = model.predict(list_images)\r\n    predictions = model.predict_on_batch(list_images)\r\n    #predictions = model.predict_classes(list_images)\r\n    print(len(predictions))\r\n    print(predictions)\r\n```\r\noutput: [[...],[....],[...],[...],[...]]\r\n![image](https://user-images.githubusercontent.com/12736950/80020860-fe73e800-84d9-11ea-9eb0-6801216718e5.png)\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nhard to do, because same code works perfectly fine in jupyter", "comments": ["nevermind, I found the issue. I was constructing the input tensor in production environment faulty. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38804\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38804\">No</a>\n"]}, {"number": 38803, "title": "[Keras] Support multiple validation sets in Model.fit", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2-rc3\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently there's no way to use multiple validation sets with independent tracking of metrics.\r\n\r\n**Will this change the current api? How?**\r\n\r\nSimplest way I can think of is to accept a list of datasets in the `validation_data` parameter in `Model.fit`. Ideally there should also be a way to specify the name of each set so that the logs indicate what set each validation step corresponds to.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone training with multiple validation sets.\r\n", "comments": ["I really need that feature :)\r\nI'm putting this as a reference https://stackoverflow.com/a/47738812", "Hi, Is this feature request still active?", "This would be nice. I often have several validation sets with varying difficulty. I expect the model to get nearly 100% accuracy on the easiest validation set. If it does not achieve a high accuracy there, there might be a problem in the setup.\r\n\r\nOn the most difficult validation set however, you cannot expect high accuracy.\r\n\r\nWith just one validation set, this difference is not visible.", "@yolpsoftware \nProbably, as a workaround for now you can use a custom callback which `model.evaluate`(s) your extra validation set `on_epoch_end`. \nAn example can be found here: https://github.com/tanzhenyu/image_augmentation/blob/master/image_augmentation/callbacks/extra_eval.py", "Any update on this? If I try a custom callback I get the issue mentioned in [#43262](https://github.com/tensorflow/tensorflow/issues/43262). The only workaround I see is use the callback without validation_data when calling model.fit", "@reuben Is there any actionable item like raising PR? Can you please move this to keras-team/keras repo?\r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues). Thanks!", "Feel free to move/repost at will. All due respect, but you chose to shuffle things around ;)", "Let's track this feature request in keras-team/keras repo https://github.com/keras-team/keras/issues/15757"]}, {"number": 38802, "title": "Remove calls to deprecated cusparse APIs", "body": "This PR replaces calls to cusparse calls that are deprecated in CUDA 10.2.\r\n\r\nCC @pankajkgupta and @sanjoy ", "comments": ["@nluehr thanks a lot for this change. Are the changes to cusparse_10_1.inc all formatting?", "@nluehr Can you please fix build failures ? Thanks!", "Sorry about that. The original cusparse_10_1.inc exactly matched cusparse_10_2.inc which confused me. I updated 10_1.inc to match CUDA 10.1.105. However, it needs to match CUDA 10.1u2 (10.1.243), which happens to exactly match CUDA 10.2 as far as the cusparse API goes. So that explains why the inc files matched to begin with.\r\nShould be fixed in latest commit.", "@nluehr thanks!", "@nluehr Can you please fix build failures ? Thanks.", "@nluehr Can you please resolve conflicts? Thanks!", "@penpornk \r\n\r\nAppreciate you looking into and fixing the ROCm build errors. Thank you.\r\n\r\nHowever there seems to be some discrepancy between\r\n* how G is testing for ROCm, and \r\n* how the ROCm CSB (Community Supported Build) is being run. \r\n\r\nROCm CSB started failing last night as a consequence of this commit \r\n(see log here :  http://ml-ci.amd.com:21096/job/tensorflow-rocm-nightly/289/)\r\n\r\nI will look into the cause of the failures and file a PR to fix them.\r\n\r\nCan we also look into what is different between the ROCm CSB run (which uses this script : https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/linux/rocm/run_csb_tests.sh ) and how G does ROCm testing? \r\n\r\nThanks again.\r\n\r\ndeven\r\n\r\n/cc @dagamayank", "@deven-amd Sorry about this! And thank you for looking into it. Please mention me in the PR and I can review it right away.\r\n\r\nThere was a discrepancy in our presubmit test and continuous test. Somehow the presubmit test didn't fail with [my commit](https://github.com/tensorflow/tensorflow/commit/557bd9e2457b36353cef5cff7f5eec137cd422ae) (but the other test failed after submitting). I actually had another fix ready since yesterday, but was waiting on someone from the build team to help look into this.\r\n\r\nI'll pass your test script along to the build team. Thank you!"]}, {"number": 38801, "title": "Update Year of Copyright", "body": "Changed 2019 to 2020", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38801) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38801) for more info**.\n\n<!-- ok -->", "Thank you very much for proposing this change.\r\nWhile we appreciate your contribution, the years in the copyright statements should be the years they were created/edited. So it should stay as is."]}, {"number": 38800, "title": "ModuleNotFoundError : from tensorflow.compat.v1 import *", "body": "ModuleNotFoundError: No module named `tensorflow.compat.v1` in **tensorflow==2.2.0-rc3**\r\n\r\n**python == 3.6.8** in MacBook Pro", "comments": ["- Can you please share more details. I am able to run [this](https://colab.research.google.com/gist/oke-aditya/33f2a02b7d1ffae5f3b60127d4421cdb/test.ipynb)\r\n", "Hi Aditya,\r\n\r\nThanks for the response, yes I am also able to run it in colab but not in mac book. \r\n\r\nIn colab it is using python 3.6.9.\r\n\r\nbut in python website, python 3.6.9 build is not there for mac so i am using python 3.6.8 and tensorflow==2.2.0-rc3 as it is the same tensorflow version in colab. \r\n\r\nNow I am facing ModuleNotFoundError in macbook but not in colab.", "@ajay-sreeram are other functionalities of TensorFlow working fine? like are you able to\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n```\r\n- Is the issue only with `tensorflow.compat.v1 import *` or with other stuff in the package as well?", "Yes I am able to import tensorflow and all the other functionalities are working fine and I see only .compat.v1 issue for now.", "If the issue is Mac specific. I am unsure of Mac Platform as I haven't used it. Hope someone helps here @ravikyram ", "I am seeing no issues with linux platform and colab.\r\n@ymodak can you please look into this issue.Thanks!", "I am seeing no issues with Windows 7 as well. \r\n![image](https://user-images.githubusercontent.com/47158509/80073358-4ab83a00-8565-11ea-91a8-ce8bbf21400d.png)\r\n\r\n\r\n", "I could successfully import the compat.v1 module in macOS with Python 3.7 and TF 2.2.0-rc3.\r\nAlso I found the [python 3.6.9 version](https://www.python.org/downloads/mac-osx/) you were looking for.\r\nHowever  I doubt that is a reason for failure. May be you can try setting virtual env before importing the modules or use an IDE.\r\nThanks!", "> I could successfully import the compat.v1 module in macOS with Python 3.7 and TF 2.2.0-rc3.\n> Also I found the [python 3.6.9 version](https://www.python.org/downloads/mac-osx/) you were looking for.\n> However  I doubt that is a reason for failure. May be you can try setting virtual env before importing the modules or use an IDE.\n> Thanks!\n\nThankyou Yasir, I will try with python 3.7 then.", "closing the issue as it worked with python 3.6.9 version", "Hi\r\nI am using python 3.6\r\ncuda : 10.1\r\ntensorflow-gpu==2.2.0\r\nUbuntu = 18.04\r\n\r\ni am getting this error : \r\n>>> import tensorflow.compat.v1 as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow.compat.v1'\r\n>>> \r\n\r\nCan anyone please suggest some work around or solution?", "> Hi\n> I am using python 3.6\n> cuda : 10.1\n> tensorflow-gpu==2.2.0\n> Ubuntu = 18.04\n> \n> i am getting this error : \n> >>> import tensorflow.compat.v1 as tf\n> Traceback (most recent call last):\n>   File \"<stdin>\", line 1, in <module>\n> ModuleNotFoundError: No module named 'tensorflow.compat.v1'\n> >>> \n> \n> Can anyone please suggest some work around or solution?\n\nTry with python 3.7 Satish, it might work.", "> Hi\r\n> I am using python 3.6\r\n> cuda : 10.1\r\n> tensorflow-gpu==2.2.0\r\n> Ubuntu = 18.04\r\n> \r\n> i am getting this error :\r\n> \r\n> > > > import tensorflow.compat.v1 as tf\r\n> > > > Traceback (most recent call last):\r\n> > > > File \"\", line 1, in \r\n> > > > ModuleNotFoundError: No module named 'tensorflow.compat.v1'\r\n> \r\n> Can anyone please suggest some work around or solution?\r\n\r\nIf you are running Tensorflow v2.2 and Python 3.6, you can try this workaround:\r\n```python\r\nimport tensorflow._api.v2.compat.v1 as tf\r\n```", "Traceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 108, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"C:\\Users\\ivand\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\ivand\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\absl\\app.py\", line 303, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\ivand\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"generate_tfrecord.py\", line 94, in main\r\n    writer = tf.io.TFRecordWriter(FLAGS.output_path)\r\n  File \"C:\\Users\\ivand\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\lib\\io\\tf_record.py\", line 218, in __init__\r\n    compat.as_bytes(path), options._as_record_writer_options(), status)\r\n  File \"C:\\Users\\ivand\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 548, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Failed to create a NewWriteableFile:  : The system cannot find the path specified.\r\n; No such process\r\n\r\n\r\n\r\ni have an error like this, please help me sir", "i am having this issue please help\r\nTraceback (most recent call last):\r\n  File \"/home/sahasra/jukshio/object_det_rec/TensorFlow/models/research/seq_flow_lite/export_to_tflite.py\", line 24, in <module>\r\n    import tensorflow.compat.v2 as tf\r\nModuleNotFoundError: No module named 'tensorflow.compat'\r\n\r\nim using tensorflow : 2.5.0\r\n                  python : 3.9.6 ", "I think problem is the version specific.", "Hi\r\nI am using:\r\n python 3.6\r\ntensorflow==1.5\r\ni am getting this error :\r\n  File \"C:\\Users\\User\\miniconda3\\envs\\bot\\lib\\site-packages\\tflearn\\__init__.py\", line 4, in <module>\r\n    import tensorflow.compat.v1 as tf\r\nModuleNotFoundError: No module named 'tensorflow.compat\r\n\r\nCan anyone please suggest some work around or solution?"]}, {"number": 38799, "title": "Build Windows Library using Docker", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (1909) x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: v2.1\r\n- Python version: v3.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): v0.29.1\r\n- GCC/Compiler version (if compiling from source): VC2019\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nHow can I build tensorflow windows library using Docker container?\r\nI just built tensorflow linux library using dev Docker.\r\nBut I can't build windows library using dev Docker.\r\nPlease help me. Thank you.\r\n", "comments": ["Docker for Windows build support is unavailable. Please follow the [Build from Source on Windows](https://www.tensorflow.org/install/source_windows) instructions to build without Docker.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38799\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38799\">No</a>\n"]}, {"number": 38798, "title": "tflite: java wrapper for xnnpack delegate", "body": "I've implemented a java wrapper for tflite xnnpack delegate (analogous to gpu delegate)\r\n\r\nUsage example (Kotlin):\r\n```{kotlin} \r\nimport org.tensorflow.lite.xnnpack.XNNPackDelegate\r\n\r\n...\r\n\r\nval xnnOptions = XNNPackDelegate.Options()\r\nxnnOptions.setNumThreads(4) \r\n\r\nval xnnDelegate = XNNPackDelegate(xnnOptions)!! // create the delegate\r\ninterpreter.modifyGraphWithDelegate(xnnDelegate) // register the delegate\r\n```", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38798) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38798) for more info**.\n\n<!-- ok -->", "Hi Denis, thanks for the proposal.\r\n\r\nWe're still exploring how best to expose the XNNPACK delegate. Ideally we want this integrated in an automatic way that doesn't require explicit user interaction. Stay tuned for more details, but for now we probably won't be exposing the Java API directly."]}, {"number": 38797, "title": "overriding `make_train_function` does not work.", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2.X\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nReference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py\r\n\r\nOverriding the `train_step`  function of the Model class works well. But if you want to go a bit deeper down and override ` make_train_function` then it does not work.\r\n\r\nIn the document, it says that it is possible\r\n\r\n`This method can be overridden to support custom training logic.`\r\n\r\nBut when you do that, it gives some errors. I tried to import what it asks for in the errors but it still wants more to import. \r\n\r\nHere is a sample code based on the recent Fran\u00e7ois Chollet's notebook:\r\n\r\nhttps://colab.research.google.com/drive/1pQX2pjXSU1AU182LuQge7xNeBJcFA3yb\r\n\r\nHere you see that when you override it, it gives an error.\r\n\r\n**Will this change the current api? How?**\r\nIt can.\r\n\r\n**Who will benefit with this feature?**\r\nEverybody who wants to write a customized training loop while taking advantage of the Keras `fit`.\r\n\r\nAs Fran\u00e7ois Chollet' says:\r\n\r\n\"what if you need a custom training algorithm, but you still want to benefit from the convenient features of fit(), such as callbacks, built-in distribution support, or step fusing?\"\r\n", "comments": ["@mmalekzadeh Thanks for the issue!\r\n\r\nLooks like there's two things going on in the example provided:\r\n\r\n(1) The code is using code copy & pasted from `Model.make_train_function`. The default `Model.make_train_function` uses internal private TF APIs. To override, you will have to use public APIs\r\n\r\n(2) The code is using the version at HEAD, which contains code that doesn't exist in 2.2 \r\n\r\nIn general, I'd recommend only overriding `Model.make_train_function` if you want very low-level control over the `tf.function` that gets created and used in `Model.fit`. This should only be used for very advanced use cases. Overriding `Model.train_step` should be enough for most use cases. If `Model.make_train_function` is overridden, you will have to return a `tf.function` that accepts an `tf.data.Iterator` and returns a dict of logs, and should construct this `tf.function` using public APIs available in TF2.2", "@omalleyt12  Many thanks for your response.\r\n\r\nI have tried to use public API, but still couldn't manage to build a simple example of overriding `make_train_function`. I agree that `This should only be used for very advanced use cases` and this is what I really wanted to do. \r\n\r\nBtw, It seems the only option, for now, is to manage whatever we need to do in the `Model.train_step` and forget to override `Model.make_train_function` at all. "]}, {"number": 38796, "title": "A high learning rate may cause a nan or an inf loss with tf.keras.optimizers.SGD", "body": "There is a sample which would cause a nan or an inf loss in TFv2.2.0-rc2.\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.applications import VGG16\r\nfrom tensorflow.keras.layers import *\r\n\r\nvgg = tf.keras.applications.VGG16(include_top=False, input_shape=(300, 400, 3))\r\no = Conv2D(512, [1, 1])(vgg.output)\r\nl = tf.keras.losses.MSE(vgg.output, o)\r\nm = Model(vgg.input, l)\r\nm.add_loss(l)\r\nm.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3))\r\nm.fit(np.ones([2, 300, 400, 3]), epochs=10)\r\n```\r\nWhen I decrease the learning rate, it is of less probability to happen.\r\n\r\nCode correction: \r\n```\r\nm.add_loss(o)\r\n```\r\nto \r\n```\r\nm.add_loss(l)\r\n```", "comments": ["i am able to replicate the issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/fc8fde884361678b096f5c9e85bddf78/38776.ipynb). Thanks!", "@gdhy9064 Can you please tell us little more details about your use case that require this architecture? Thanks!", "@jvishnuvardhan I use the similar structure trying to build a faster-rcnn. And the problem here doesn't influence me a lot, I can use another optimizer instead. I am just confused that the high learning rate with SGD would have such a strange behavior. Thanks for your response.", "@gdhy9064 High learning rate is usually the root cause for many NAN problems. You can try with a lower value, or with another adaptive learning rate optimizer such as Adam.", "@tanzhenyu Very sorry for the typos in the sample, the loss should be the varible l, not varible o. I have corrected them in the [gist here](https://colab.research.google.com/gist/gdhy9064/6d0026d2eda9bcd5c1f2dd493cb4d4a8/-38776-ipynb.ipynb). I am not sure whether it is just the problem of the learning rate. Thanks. ", "@gdhy9064 \r\nI tried in colab with TF nightly version(`2.4.0-dev20200805`) and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/b5b4078213e10dd15fc942ed7b52b91f/untitled221.ipynb).\r\nPlease, verify once and close the issue if resolved.Thanks!", "@ravikyram I have tried with TF nightly version (2.4.0-dev20200805), the problem still exists. Maybe the large gradients during training are the cause. Thanks for your kindly reply. I will close the issue now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38796\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38796\">No</a>\n"]}, {"number": 38795, "title": "tf.keras model.fit causes sytem reboot (cpu,centOS)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos-release-7-7.1908.0.el7.centos.x86_64- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.7\r\n- GPU model and memory: running on cpu\r\n- Ram: 64gb\r\n- I'am using a VGG16 model(at least part of it)\r\n\r\n\r\n**Describe the current behavior**\r\nWhen using model.fit or model.fit_generator on models with large amounts of parameters my server reboots and I get a timeout on ssh. The log files don't show any errors, just the execution of my program and then the normal boot sequence. It seems like the issue starts when using over 60000 parameters. If I increase the amount of parameters this phenomena appears faster(earlier in the training process), when using around 200000 parameters it most times happens in the first epoch, but it's not consistent(I managed to train my model with 1million parameters for 10 epochs). Monitoring my Ram usage reveals that I' am just using fractions of what's available (6.5 gb out of 64gb). Furthermore in each epoch I'am getting this warning: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\nMy code (I reduced parameters by removing layers):\r\n<img width=\"2210\" alt=\"Bildschirmfoto 2020-04-22 um 15 26 47\" src=\"https://user-images.githubusercontent.com/37218380/79987429-b17a1c80-84ad-11ea-8cee-f79140f573ad.png\">\r\n\r\nSame code works on Raspbian beside it not having enough RAM\r\n\r\n**Describe the expected behavior**\r\nWorking without a problem or an error warning.  \r\nCould it be a hardware problem?\r\n\r\n\r\n\r\n**Other info / logs** No errors are visible in the log file.\r\n", "comments": ["@g2721 \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "It seems like it's not a problem with TensorFlow. My code runs perfect on my iMac, probably it's a issue with python, CentOS or a hardware problem", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38795\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38795\">No</a>\n"]}, {"number": 38794, "title": "Deploy Sequence to Sequence Model with Tensorflow Serving", "body": "I have created a seq2seq model for question and answering by following the tensorflow tutorial here: https://www.tensorflow.org/tutorials/text/nmt_with_attention\r\n\r\nThe model works well and I want to deploy it with Tensorflow serving. it's not clear how I could do this efficiently because:\r\n- The decoder can only make a prediction for the next word, by taking as input the last predicted word. Surely it's not efficient to send multiple inference requests word by word instead of generating the whole sentence server side?\r\n- is there any way to do the preprocessing server side? (e.g. client only has to send the tensorflow serving text, instead of numpy arrays).\r\n", "comments": ["@psyfb2,\r\nSince this issue is related to TF Serving, could you please close this issue and create a new one in the Serving repo from [this link](https://github.com/tensorflow/serving/issues/new) so that we can track it there. Thanks! "]}, {"number": 38793, "title": "tf.data.Dataset.from_tensor_slices: ValueError: Failed to convert a NumPy array to a Tensor (Unsupported\u2423 ,\u2192object type list), worked on 2.0.0-beta1", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Juniper lab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Notebook\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0-rc3\r\n- Python version: 3.8.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no idea\r\n- GPU model and memory: Geforce GTX 960M\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI get an error when call tf.data.Dataset.from_tensor_slices with\r\nValueError: Failed to convert a NumPy array to a Tensor (Unsupported\u2423\r\n,\u2192object type list), see attachment\r\n[Answer.Tensorflow.pad.sequence.feature.column.DenseFeatures.pdf](https://github.com/tensorflow/tensorflow/files/4515932/Answer.Tensorflow.pad.sequence.feature.column.DenseFeatures.pdf)\r\n\r\n\r\n**Describe the expected behavior**\r\nI tried to use this example\r\nhttps://github.com/EgorBEremeev/SoloLearnML/blob/master/stackoverflow/Answer.%20Tensorflow%20pad%20sequence%20feature%20column.%20DenseFeatures.ipynb\r\n\r\nIt looks like it was running on 2.0.0-beta1, but not more in the current version. You can use this notebook to reproduce the case.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://github.com/EgorBEremeev/SoloLearnML/blob/master/stackoverflow/Answer.%20Tensorflow%20pad%20sequence%20feature%20column.%20DenseFeatures.ipynb\r\nYou need to adapt the path the the csv file which will also be available in the repository.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue with TF v2.1, [TF v2.2.0-rc3](https://colab.research.google.com/gist/amahendrakar/1a8342379761f0312278f18c85d09e65/38793.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/ceb90694563d02400c5870b319001b68/38793-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Can you please provide a small reproducible code to validate the behavior? This will help to troubleshoot faster. Thanks!", "Hello @ymodak,\r\n\r\nexample code can be found in amahendrakas comment. In general I have a pandas dataframe with one column as Bag of word list.\r\n\r\nI tried to use an examplehttps://github.com/EgorBEremeev/SoloLearnML/blob/master/stackoverflow/Answer.%20Tensorflow%20pad%20sequence%20feature%20column.%20DenseFeatures.ipynb and he already give me an solution. He switched\r\n`ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))`\r\nto\r\n`ds = tf.data.Dataset.from_tensor_slices((dataframe .to_dict(orient='list'), labels))`\r\nand then it works.\r\nSo I'm not sure if this still is a bug in TF or not. Because in 2.0 beta it works and in 2.1 and following not.\r\n\r\nThanks\r\n\r\n", "@aaudiber can you please take a look? thanks", "The problem is that `from_tensor_slices` needs to convert its input into a Tensor, but the given input contains variable-length numpy lists, which cannot be converted into tensors (tensors must be rectangular). You can get the same error message by running\r\n\r\n```\r\na = np.array([[1, 2, 3], [4, 5]], dtype=object)\r\nprint(tf.convert_to_tensor(a))\r\n```\r\n\r\nThis error appears to occur even in tensorflow 2.0.0-beta1, so it doesn't look like a regression.\r\n\r\nTo make this work, you need to pad the dataframe's lists so that they are the same length.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38793\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38793\">No</a>\n"]}, {"number": 38792, "title": "Embedding Lookup Sparse behavior with empty ids", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: na\r\n- TensorFlow installed from (source or binary): binar\r\n- TensorFlow version (use command below): 2.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nlist_input = tf.ragged.constant([[], [], [], [1], []], dtype=tf.int32)\r\nlist_input.shape\r\n# TensorShape([5, None])\r\nembedding = tf.Variable(tf.random.truncated_normal([3, 3]))\r\ntf.nn.embedding_lookup_sparse(embedding, list_input.to_sparse(), None, combiner='mean').shape\r\n# TensorShape([4, 3]) # the last row disappeared\r\nlist_input = tf.ragged.constant([[], [], [], [1]], dtype=tf.int32)\r\nlist_input.shape\r\n# TensorShape([4, None]) # correct output shape\r\ntf.nn.embedding_lookup_sparse(embedding, list_input.to_sparse(), None, combiner='mean').shape\r\n# TensorShape([4, 3]) The first 3 vectors are zeroes the last one has the correct value.\r\n```\r\nEmbedding lookup sparse states that it is not usable if one rows does not contains at least 1 id. \r\n\r\n> This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids (i.e. there are no rows with empty features), and that all the indices of sp_ids are in canonical row-major order.\r\n\r\nHowever based on my experiments it does not work at expected if the last item of the list array has no ids. If the first items have no ids it will be filled with zeroes but if the last ones dont have indices its not filled with zeroes and the output shape is not consistant.\r\n\r\n**Describe the expected behavior**\r\nA more consistent behavior i think we should fill every empty items with a zero vector if there are no ids or break explicitely.\r\n\r\nI found safe_embedding_lookup_sparse which solves the issue however its not clear to me what are the differences between the two ? are there any performance issue with safe one ? \r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/gist/tanguycdls/11a399c750ce72b92a002c9b11909e12/embeddingsparse.ipynb\r\n\r\n", "comments": ["i am able to replicate this, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/395fd9c5769ce5690814d4dea1c900a9/untitled147.ipynb)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38792\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38792\">No</a>\n"]}, {"number": 38791, "title": " The _pywrap_tensorflow_internal.so files generated by the two compilations are different\uff0cwhy\uff1f", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from source :\r\n- TensorFlow version:1.15.2\r\n- Python version:3.7\r\n- Installed using pip:\r\n- Bazel version 0.25.0:\r\n- GCC/Compiler version :7.3.0\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@zxin-what \r\n\r\nPlease provide details about what platform you are using (operating system, architecture).Please,provide the exact sequence of commands / steps that you executed before running into the problem.Please, share error log as well.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38791\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38791\">No</a>\n"]}, {"number": 38790, "title": "Tensorflow/keras custom loss problem (external inputs)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- Tensorflow 1.15\r\n- Yes\r\n\r\n\r\n\r\n\r\nLets assume that we have a model model_A and we want to build up a backpropagation based on 3 different loss functions. The first loss (`Loss_1`) should be based on the output of model_A, `Loss_2 `and `Loss_3 `can come from something else. Think about it like a deviation from an unknown source, like in process-automation if you want to build up ur PID-controller. The easiest way is my approach down there, but it actually fails, because the graph isnt constructed the way i want, because X_realB and X_realC have no connection to model_A, and are ignored by keras with tensorflow backend.  \r\n\r\n\r\n**Main Question:** How can i pass new variables in my loss function, without processing them in the model, and stil influencing the minimization problem ?\r\n\r\n```\r\ndef generator_model(model_A):\r\n\r\n  model_A.trainable = True\r\n\r\n# import\r\n  X_realA = Input(shape=image_shape)\r\n  X_realB = Input(shape=image_shape)\r\n  X_realC = Input(shape=image_shape)\r\n\r\n# generate Fake image\r\n  Fake_A=model_A(X_realA)\r\n\r\n\r\n  model = Model([X_realA],[Fake_A,X_realB ,X_realC])\r\n\r\n  opt = Adam(lr=0.0002, beta_1=0.5)\r\n  model.compile(loss=[\"mse\",\"mse\",\"mse\"],loss_weights=[1,1,1], optimizer=opt)\r\n  model.summary()\r\n  return model\r\n```\r\n\r\nI tried something else in the past 2 days. Wrapping `[FakeA,B,C]` in a custom lambda-layer, to calculate combined loss (one value output of that custom layer). Than passing this loss, in a dummy custom loss-function, which just outputs the combined value of the lambda layer. Here is an example:\r\n\r\n```\r\n    # import A,B,C and than pass A into Generator .... and after that:\r\n    \r\n    combined_loss= Lambda(lambda x: combined_loss_func(x))([FakeA,B,C])\r\n\r\n    model=Model([A,B,C],[combined_loss],loss=dummy_loss)\r\n\r\n    def dummy_loss(y_pred,y_true):\r\n      return y_pred\r\n\r\n\r\n`combined_loss` could look like that:\r\n    \r\n    def combined_loss_func(x):\r\n    \r\n      FakeA,B,C=x[0],x[1],x[2]\r\n    \r\n      # transform all inputs into one row-tensors\r\n      shape=tf.shape(FakeA)\r\n      FakeA=tf.reshape(FakeA,[1,shape[0]*shape[1]*shape[2]*shape[3]])   \r\n      shape=tf.shape(B)\r\n      B=tf.reshape(B,[1,shape[0]*shape[1]*shape[2]*shape[3]]) \r\n      shape=tf.shape(C)\r\n      C=tf.reshape(C,[1,shape[0]*shape[1]*shape[2]*shape[3]]) \r\n    \r\n      # build up a hypothetical ground truth\r\n      FakeA_ones=tf.ones_like(FakeA)\r\n      A_ones=tf.ones_like(A)\r\n      B_ones=tf.ones_like(B)\r\n    \r\n      # calculate losses\r\n      loss0=keras.losses.mse(FakeA,FakeA_ones)\r\n      loss1=keras.losses.mse(A,A_ones)\r\n      loss2=keras.losses.mse(B,B_ones)\r\n    \r\n      # sum them up\r\n      summe=tf.math.add(loss0,loss1)\r\n      summe=tf.math.add(summe,loss2)\r\n    \r\n      # average them\r\n      avg=tf.math.truediv(summe,3.0)\r\n      avg=tf.expand_dims(summe,axis=-1)\r\n    \r\n      return avg\r\n```\r\n\r\n\r\nIf i now try, to set the FakeA loss to zero, no backpropagation to `modelA` happens anymore, or at least nothing in the system changes anymore:\r\n\r\n```\r\n       # calculate losses\r\n      loss0=keras.losses.mse(FakeA,FakeA_ones) * 0\r\n      loss1=keras.losses.mse(A,A_ones)\r\n      loss2=keras.losses.mse(B,B_ones)\r\n```\r\n\r\nFirst it seemes really good, but when i go now into the custom-function, and not use `FakeA`, which is the one and only tensor which passed through the generator. Than i stil get a value for my loss function, which seems to be rigth, but actually nothing is happening, my cycle Gan isnt improving at all, and all images passed though stil look the same, even after 100 epochs. \r\n\r\nDoesnt that mean, that the other losses not even really considered, and i stil just use the loss1 over FakeA, and i just get different results because of the typical divergation of GANs dynamic system ?\r\n\r\n", "comments": ["Any ideas ?", "This question is better asked on StackOverflow, where there is a more robust community of users to help. If there is a specific bug you have found, please open a new issue describing the bug."]}, {"number": 38789, "title": "ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'", "body": "Code:-\r\nfrom imageai.Prediction import ImagePrediction\r\nimport tensorflow as tf\r\nimport os\r\nexecution_path=os.getcwd()\r\n\r\nprediction = ImagePrediction()\r\nprediction.setModelTypeAsSqueezeNet() #To select which model we want to use\r\nprediction.setModelPath(os.path.join(execution_path, \"squeezenet_weights_tf_dim_ordering_tf_kernels.h5\"))\r\nprediction.loadModel()\r\n\r\npredictions, probabilities = prediction.predictImage(os.path.join(execution_path, \"photo_2020-04-22_11-05-49.jpg\"), result_count=5 )\r\nfor eachPrediction, eachProbability in zip(predictions, probabilities):\r\n    print(eachPrediction , \" : \" , eachProbability)\r\n\r\n\r\n\r\nError:--\r\n\r\n(ReallysmartBrain) C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain>python brain.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\Akhilu\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"brain.py\", line 1, in <module>\r\n    from imageai.Prediction import ImagePrediction\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\imageai\\Prediction\\__init__.py\", line 2, in <module>\r\n    from tensorflow.python.keras.preprocessing import image\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\Akhilu\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Akhilu\\PycharmProjects\\ReallysmartBrain\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'", "comments": ["I have installed tensor flow still it's showing error.I am new learner in machine learning.I could not understand really what this means", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the [Github new issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose) Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38789\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38789\">No</a>\n"]}, {"number": 38788, "title": "ImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002(The specified module cannot be found(translate from Chinese) )", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):pip install tensorflow===1.14.0\r\n- TensorFlow version (use command below):1.14.0\r\n- Python version:3.7.4\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory:1660ti 16g ram\r\n- Keras version: 2.2.5\r\n\r\n```\r\nPython 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.\r\nPyDev console: using IPython 7.8.0\r\nPython 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] on win32\r\nrunfile('C:/junji/datas.py', wdir='C:/junji')\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-3564911e8277>\", line 1, in <module>\r\n    runfile('C:/junji/datas.py', wdir='C:/junji')\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"C:/junji/datas.py\", line 1, in <module>\r\n    import keras\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"E:\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\hp\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002(The specified module cannot be found(translate from Chinese) )\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/errors\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nI have met this problem when I'm using  lenet-5 model. And \r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@PommesPeter\r\nIs your python 64 bits? Does your CPU support AVX?\r\n\r\nClosing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "@Saduf2019  Yes, my python is 64 bit, But I don't know whether it supports AVX", "@PommesPeter\r\nplease follow the links shared above to resolve.\r\n\r\n\r\nThe easiest way to find that out would be to find out the CPU model number from system information and to look it up on the manufacturers website. Another quick way would be to look at how old the CPU is as processors with AVX support were mainly launched in 2011.\r\n\r\n\r\n[link1](https://www.quora.com/How-can-I-determine-if-my-CPU-supports-AVX-instructions)\r\n[link2](https://stackoverflow.com/questions/37480071/how-to-tell-if-a-linux-machine-supports-avx-avx2-instructions)", "@Saduf2019 Thanks a lot. I have solved the problem just now. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38788\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38788\">No</a>\n"]}, {"number": 38787, "title": "Error: tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- LG G8\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: pip3\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): 8.3.0\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n**Describe the problem**\r\nI trying to test the tflite model according to  [OVIC Benchmarker for LPCV 2020](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java/ovic). \r\nI installed Bazel 3.0.0 using Bazel's apt repository.\r\nI installed Android ndk17c.\r\nI installed Android SDK using android-sdk_r24.4.1-linux.tgz by the sequent command:\r\n`tar -zxvf android-sdk_r24.4.1-linux.tgz`\r\nchanged path for android SDK\r\nused `android update sdk -u -a -t 8,213,58 ` to install SDK platform, build-tools and SDK API.\r\nThen I use` ./configure` to config WORKSPACE for bazel.\r\nMy .tf_configure.bazelrc is like this:\r\n\r\n> build --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\n> build --action_env PYTHON_LIB_PATH=\"/usr/lib/python3/dist-packages\"\r\n> build --python_path=\"/usr/bin/python3\"\r\n> build --config=xla\r\n> build:opt --copt=-march=native\r\n> build:opt --copt=-Wno-sign-compare\r\n> build:opt --host_copt=-march=native\r\n> build:opt --define with_default_optimizations=true\r\n> build --action_env ANDROID_NDK_HOME=\"/mnt/d/Share/software/android-ndk-r17c\"\r\n> build --action_env ANDROID_NDK_API_LEVEL=\"21\"\r\n> build --action_env ANDROID_BUILD_TOOLS_VERSION=\"28.0.3\"\r\n> build --action_env ANDROID_SDK_API_LEVEL=\"23\"\r\n> build --action_env ANDROID_SDK_HOME=\"/mnt/d/Share/software/android-sdk-linux\"\r\n> test --flaky_test_attempts=3\r\n> test --test_size_filters=small,medium\r\n> test:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial\r\n> test:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu\r\n> test:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only\r\n> test:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only\r\n> build --action_env TF_CONFIGURE_IOS=\"0\"\r\n\r\nThen I run\r\n`bazel build -c opt --cxxopt=-Wno-all //tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary`\r\n\r\nError occurred.\r\n\r\n> ERROR: \r\n> /mnt/e/research/model_compression/proj/tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'\r\n> ERROR: /mnt/e/research/model_compression/proj/tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'\r\n> ERROR: Analysis of target '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary' failed; build aborted: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package.\r\n> INFO: Elapsed time: 7.424s\r\n> INFO: 0 processes.\r\n> FAILED: Build did NOT complete successfully (18 packages loaded, 28 targets configured)\r\n\r\nI have no idea how to fix this problem. And I tried to install Android Studio, it doesn't help either.\r\n", "comments": ["I'm meeting the same issue with similar setting (instead i am using Ubuntu 18.04 but not windows), I manually installed the NDK r17c and install SDK via Android Studio.", "You need to run \"./configure\" first to configure Android NDK & SDK for build system.\r\n\r\nDuring the configuration, you should answer \"Yes\" for the following question.\r\n```\r\n\"Would you like to interactively configure ./WORKSPACE for Android builds?\"\r\n```\r\nThen, you'll be asked for min Android NDK API level and Android SDK API level to use.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38787\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38787\">No</a>\n", "> You need to run \"./configure\" first to configure Android NDK & SDK for build system.\r\n> \r\n> During the configuration, you should answer \"Yes\" for the following question.\r\n> \r\n> ```\r\n> \"Would you like to interactively configure ./WORKSPACE for Android builds?\"\r\n> ```\r\n> \r\n> Then, you'll be asked for min Android NDK API level and Android SDK API level to use.\r\n\r\nOf course I've done that... and only after doing that ```build --action_env ANDROID_NDK_HOME=\"/mnt/d/Share/software/android-ndk-r17c\"``` could apppear in my .tf_configure.bazelrc", "Which branch did you use?\r\nYou said you used \"TensorFlow version: 1.14.0\" but it requires Bazel 0.26.2.", "> Which branch did you use?\r\n> You said you used \"TensorFlow version: 1.14.0\" but it requires Bazel 0.26.2.\r\n\r\nSorry, my version differs a little with @xinziXu's, I used Tensorflow version:1.15.0 with bazel 0.25.1(within the requirement range in configure.py) on Ubuntu 18.04", "> Which branch did you use?\r\n> You said you used \"TensorFlow version: 1.14.0\" but it requires Bazel 0.26.2.\r\n\r\nAlso, i'm a bit confused about when building the ovic example(running ```bazel build -c opt --cxxopt=-Wno-all //tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary```), should i follow [this tutorial](https://s0www0tensorflow0org.icopy.site/lite/guide/android?hl=it) to build the tf-lite.aar and add it into the project via modifying the build.gradle(which iIdid and the build for the tf-lite.aar succeeded, however it sitll couldnt find the android sdk when building the apk )", "Do you still have the issue?\r\nIf you do, could you share .tf_configure.bazelrc?", "I am having the same issue but I am using Tensorflow 2.1.0 with Bazel 3.1.0. Do we have to add the tf-lite.aar file? I did build the TFLite using `bazel build -c opt --config=android_arm64 //tensorflow/lite:libtensorflowlite.so`. Could you please help me resolve it soon?", "@dipendra009 The ovic_benchmarker_binary should be built with bazel. You don't need to care of the library dependency since bazel handles it. ", "It is really weird, I have the android sdk and ndk installed and WORKSPACE configured, but it gives the same error: Projects/tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'\r\n\r\nWhat would you suggest to resolve this error? I tried reinstalling multiple times, but I have no idea why it is giving the error.", "> It is really weird, I have the android sdk and ndk installed and WORKSPACE configured, but it gives the same error: Projects/tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @AndroidSDK. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'\r\n> \r\n> What would you suggest to resolve this error? I tried reinstalling multiple times, but I have no idea why it is giving the error.\r\n\r\n* After unbelievable trails and error, I found a weird solution, with sdk and ndk properly installed and added into tensorflow build .bazelrc,  just comment out the com.android.support in ovic apk BUILD, I could successfully build it this way, **However, no related tutorial or post mentions any related operation, so I'm not sure whether its the right way. (To be frank, its rather weird, even Im surprised it worked)**\r\n* ![](https://github.com/A-suozhang/MyPicBed/raw/master//img/20200616183720.png)", "Thank you, A-suozhang. That worked for me.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38787\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38787\">No</a>\n"]}, {"number": 38786, "title": "AttributeError: type object 'TFLiteConverter' has no attribute 'from_keras_model'", "body": "ubuntu18.04 use [jupyter notebook]\r\ntensorflow (1.14.0)\r\ntensorflow-estimator (1.14.0)\r\ntensorflow-gpu (1.14.0)\r\n\r\nI follow[https://www.tensorflow.org/lite/performance/post_training_integer_quant]   can do\r\nbut I follow [https://www.tensorflow.org/lite/convert/python_api]Converting a Keras model There is such an error \uff1a \r\n\uff08AttributeError: type object 'TFLiteConverter' has no attribute 'from_keras_model'\uff09\r\n", "comments": ["I have the impression that from_keras_model is an API of 2.x, so it is recommended that you upgrade to tf2.x version, or use from_keras_model_file API", "Hello @LINYOUWEI0804 .\r\nThe notebook given in https://www.tensorflow.org/lite/performance/post_training_integer_quantl is running on tensorflow v2 API.\r\n\r\nPlease have a look at [compatibility](https://www.tensorflow.org/lite/convert/1x_compatibility) if you wished to work with 1.x API.\r\n", "@LINYOUWEI0804,\r\nCould you please try running the code with TensorFlow 2.x. I was able to run the code without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/0fda9c42859c33b3c852105eabe5915c/38786.ipynb). Thanks!", "Thank ,I update tf to 2.0 and it will run", "> Thank ,I update tf to 2.0 and it will run\r\n\r\nPlease feel free to close the issue if resolved. Thanks!", "l\u00e0m \u01a1n gi\u00fap t\u00f4i chuy\u1ec3n qua file TFlite"]}, {"number": 38785, "title": "xla kernel load error", "body": "W0422 13:19:03.825152 25290 tf_model.cpp:326] TF error: 2 root error(s) found.\r\n(0) Internal: Unable to load kernel 'fusion_22'\r\n[[{{node cluster_86_1/xla_run}}]]\r\n[[cluster_86_1/merge_oidx_0/_3]]\r\n(1) Internal: Unable to load kernel 'fusion_22'\r\n[[{{node cluster_86_1/xla_run}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\nW0422 13:19:04.673285 25290 tf_model.cpp:326] TF error: 2 root error(s) found.\r\n(0) Internal: Unable to load kernel 'fusion_22'\r\n[[{{node cluster_86_1/xla_run}}]]\r\n[[cluster_86_1/merge_oidx_0/_3]]\r\n(1) Internal: Unable to load kernel 'fusion_22'\r\n[[{{node cluster_86_1/xla_run}}]]\r\n\r\n========================\r\nwe used c api to load model from graph_def. the tf version is 1.14. this error ocurs when the online system try to load new model to replace the old one.the online system update the tf model for every two hours. we can't replicate this issue on our offline system.", "comments": ["closing this as duplicate of #38784"]}, {"number": 38784, "title": "xla kernel load error", "body": "W0422 13:19:03.825152 25290 tf_model.cpp:326] TF error: 2 root error(s) found.\r\n  (0) Internal: Unable to load kernel 'fusion_22'\r\n         [[{{node cluster_86_1/xla_run}}]]\r\n         [[cluster_86_1/merge_oidx_0/_3]]\r\n  (1) Internal: Unable to load kernel 'fusion_22'\r\n         [[{{node cluster_86_1/xla_run}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\nW0422 13:19:04.673285 25290 tf_model.cpp:326] TF error: 2 root error(s) found.\r\n  (0) Internal: Unable to load kernel 'fusion_22'\r\n         [[{{node cluster_86_1/xla_run}}]]\r\n         [[cluster_86_1/merge_oidx_0/_3]]\r\n  (1) Internal: Unable to load kernel 'fusion_22'\r\n         [[{{node cluster_86_1/xla_run}}]]", "comments": ["SunNy820828449 \r\ncould you please share simple standalone code and tensorflow version for us to replicate the issue", "we used c api to load model from graph_def. the tf version is 1.14. this error ocurs when the online system try to load new model to replace the old one.the online system update the tf model for every two hours.  we can't replicate this issue on our offline system."]}, {"number": 38783, "title": "Issues running jupyter notebook to do object detection api", "body": "Hi i have facing this issues and i am using tensorflow 2 cpu version and i have  AMD radeon graphics card in my laptop\r\n%%bash\r\ncd models/research/\r\nprotoc object_detection/protos/*.proto --python_out=.\r\nCouldn't find program: 'bash'\r\n%%bash \r\ncd models/research\r\npip install .\r\nCouldn't find program: 'bash'\r\n\r\nImportError                               Traceback (most recent call last)\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-6-cdfb01024084> in <module>\r\n      4 import sys\r\n      5 import tarfile\r\n----> 6 import tensorflow as tf\r\n      7 import zipfile\r\n      8 \r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "What is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the[ latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nAlso, refer similar issues.\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "CPU intel core i7-6500u  and currently using the google colab for my project as gpu requires nividia support which my laptop does not support", "@theman162 \r\n\r\nIn order to expedite the trouble-shooting process, please provide colab link or  minimal standalone code to reproduce the issue reported here. Thanks!", "```\r\n%%bash\r\ncd models/research/\r\nprotoc object_detection/protos/*.proto --python_out=.\r\nCouldn't find program: 'bash'\r\n%%bash\r\ncd models/research\r\npip install .\r\nCouldn't find program: 'bash'\r\n```\r\n\r\nPlease change to\r\n```\r\n\r\n%cd models/research/\r\n! protoc object_detection/protos/*.proto --python_out=.\r\n\r\n%cd models/research\r\n! pip install .\r\n\r\n\r\n\r\n```\r\n\r\n\r\n- Since you are using google colab using %cd to change directory and ! when you use linux commands.", "@theman162 \r\n\r\nwas this resolved by following @oke-aditya suggestion? Please close the issue if it was resolved already. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38783\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38783\">No</a>\n"]}, {"number": 38782, "title": "Import error traceback(most recent call last", "body": "Hi this issue is perisisting me when i try to run the object detection api on jupyter notebook .I am using tensorflow  2 cpu version \r\n\r\nImportError                               Traceback (most recent call last)\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-6-cdfb01024084> in <module>\r\n      4 import sys\r\n      5 import tarfile\r\n----> 6 import tensorflow as tf\r\n      7 import zipfile\r\n      8 \r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "Hi my laptop uses AMD radeon graphics can i install CUDA,CUPTI AND cuDNN", "I am having this issue also is the solution the same\r\n%%bash\r\ncd models/research/\r\nprotoc object_detection/protos/*.proto --python_out=.\r\nCouldn't find program: 'bash'\r\n%%bash \r\ncd models/research\r\npip install .\r\nCouldn't find program: 'bash'", "> \r\n> \r\n> Hi my laptop uses AMD radeon graphics can i install CUDA,CUPTI AND cuDNN\r\n\r\n- No CudNN is supported by NVIDIA for specific GPUs only. Please check with NVIDIA CuDNN guide. I guess it's not for AMD", "> \r\n> \r\n> I am having this issue also is the solution the same\r\n> %%bash\r\n> cd models/research/\r\n> protoc object_detection/protos/*.proto --python_out=.\r\n> Couldn't find program: 'bash'\r\n> %%bash\r\n> cd models/research\r\n> pip install .\r\n> Couldn't find program: 'bash'\r\n\r\nHere bash refers to linux kernel. Please consider running this on linux system. Alternatively you can use git bash and run externally.", "@theman162,\r\nCould you please check if the issue is with importing TensorFlow?\r\n\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from a similar issue and let us know if it works. Thanks!", "hi i am currently using google colab and it works for now as per the online tutorials ", "i will update if i face other issues", "> \r\n> \r\n> I am having this issue also is the solution the same\r\n> %%bash\r\n> cd models/research/\r\n> protoc object_detection/protos/*.proto --python_out=.\r\n> Couldn't find program: 'bash'\r\n> %%bash\r\n> cd models/research\r\n> pip install .\r\n> Couldn't find program: 'bash'\r\n\r\nIf you are running the above in Colab please change to\r\n\r\n```\r\n%cd models/research/\r\n! protoc object_detection/protos/*.proto --python_out=.\r\n\r\n```\r\n\r\n", "> hi i am currently using google colab and it works for now as per the online tutorials\r\n\r\nAny updates regarding this? Please feel free to close the issue if resolved. Thanks!", "> Any updates regarding this? Please feel free to close the issue if resolved. Thanks!\r\n\r\n@theman162,\r\nIs this still an issue? Thanks!", "HI i tried to run again the jupyter notebook and i still get this error \r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-a8f0741d1f6f>\", line 14, in <module>\r\n    if tf.__version__ < '1.4.0':\r\nAttributeError: module 'tensorflow' has no attribute '__version__'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'AttributeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-a8f0741d1f6f>\", line 14, in <module>\r\n    if tf.__version__ < '1.4.0':\r\nAttributeError: module 'tensorflow' has no attribute '__version__'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'AttributeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\vilsuresh\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38782\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38782\">No</a>\n"]}, {"number": 38780, "title": "gather nd op does not support string input", "body": "As the title.\r\nThanks for your help.", "comments": ["@lizhen2017 \r\n please provide a code snippet to reproduce the issue reported here,Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\n\r\nMake sure you also include the exact details if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@abattery,\r\nCan you confirm this?", "Hi lizhen2017,\r\n\r\nCould you try the nightly build? In the nightly build, GatherNdOp supports string input tensors.\r\n\r\nBest regards,\r\nJaesung", "@lizhen2017\r\nplease update as per above commenets", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38779, "title": "can't use adadelta", "body": "tensorflow.python.framework.errors_impl.NotFoundError: No registered 'ResourceSparseApplyAdadelta' OpKernel for 'GPU' devices compatible with node {{node ResourceSparseApplyAdadelta}}\r\n\t.  Registered:  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]\r\n  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]\r\n [Op:ResourceSparseApplyAdadelta]\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the [Github new issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38779\">No</a>\n", "@qniguoym did you solve your problem, I encountered this problem as well."]}, {"number": 38777, "title": "Blank outputs when using CTC loss on TensorFlow 2", "body": "Hello.\r\n\r\nI'm trying to use Tensorflow's ``tf.nn.ctc_loss`` for a speech recognition problem, but it seems it's causing the network to learn that the best way to reduce loss is to output blank. I've tried other implementations, like [this](https://github.com/igormq/ctc_tensorflow_example) and [this](https://github.com/ysoullard/CTCModel), but they have the same problem.\r\n\r\n[Here](https://gist.github.com/Victor-Almeida/df1d0dc2cea318216d320d029dc8e64f) is the gist for my own implementation and [here](https://drive.google.com/open?id=1bgGte_wVyaYAycBntQA8uQWmVQZqhPYH) is the link to my Google Drive folder with the files used.\r\n\r\nI'm using Google Colab's high-RAM runtime with GPU and Tensorflow version 2.2.0-rc3.\r\n\r\nAlso, for some reason I get this error ``    ValueError: Dimension must be 2 but is 3 for '{{node transpose}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](model_52/Placeholder, transpose/perm)' with input shapes: [1200,29], [3].`` when trying to use ``tf.function`` on the ``train_step`` method from the ``CTC_SR`` class when using the ``Encoder_Decoder`` class, but not when using the actual Keras' layers. \r\nWhen using ``tf.function`` with Keras layers, though, training takes waaaaaay longer. Why is that?", "comments": ["@Victor-Almeida \r\n\r\nIn order to expedite the trouble-shooting process, please provide colab link or minimal standalone code to reproduce the issue reported here. It helps us in localizing the issue faster.Thanks!", "I did. \r\n\r\nThe gist --> https://gist.github.com/Victor-Almeida/df1d0dc2cea318216d320d029dc8e64f\r\nThe Google Drive folder --> https://drive.google.com/open?id=1bgGte_wVyaYAycBntQA8uQWmVQZqhPYH", "I have tried on colab with TF version 2.2-rc3 .Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/9561c6e032c864a0f20fa5c6f3078367/untitled807.ipynb).Is this the expected behavior?Thanks!", "Yes, that's what's happening. Predictions are all blank, and you can see that during training because the LER is always 1. ", "Modeling questions are a better fit for StackOverflow, instead of github issues.  However, from experience the typical explanation here is that the model is in an intermediate stage of training.  The typical progression with CTC is first it learns to emit just blanks; then it starts learning the outer edges of tokens to emit, then after more epochs learns to emit the intermediate tokens.  This assumes you have enough model capacity and the architecture of the underlying RNN has enough capacity to do so.\r\n\r\nTo summarize: probably you haven't run training for long enough, or your model capacity is too low, or your optimizer isn't tuned well.\r\n\r\nI'll close this for now; probably you will want to follow the convergence question up on StackOverflow, reddit, or similar.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38777\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38777\">No</a>\n"]}, {"number": 38776, "title": "[RNN] [TFLiteConverter.] Input tensors containing unknown dimensions fails when coupled with LSTM", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux-4.19.104+-x86_64-with-Ubuntu-18.04-bionic (Google Colab's default environment)\r\n- TensorFlow installed from (source or binary):\r\npip install tf-nightly\r\n- TensorFlow version (or github SHA if from source):\r\n2.2.0-dev20200421\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1-hjOM3qW5gY1PAqEZhFGHj7FFY5BaZsm\r\n\r\n```\r\nfrom tensorflow.lite.python import lite\r\nfrom tensorflow.python import keras\r\nimport numpy as np\r\n\r\ninput_a = keras.layers.Input(shape=(3,3,), name='input_a')\r\ninterm_b = tf.keras.layers.LSTM(4, name='interm_1')(input_a)\r\noutput_c = keras.layers.Dense(1, name='dense_1')(interm_b)\r\n\r\nmodel = tf.keras.models.Model(inputs=[input_a], outputs=[output_c])\r\nmodel.compile(optimizer='sgd', loss='mean_squared_error')\r\nmodel.summary()\r\n\r\nbatch_size = 10\r\nsample_input = np.ones((batch_size,3,3),dtype=np.float32)\r\n\r\nexpected_value = model.predict(sample_input)\r\n\r\nconverter = lite.TFLiteConverterV2.from_keras_model(model = model)\r\nconverter.experimental_new_converter = True\r\nwith open(\"model.tflite\", \"wb\") as f:\r\n    f.write(converter.convert())\r\n\r\ninterpreter = lite.Interpreter(model_path=\"model.tflite\")\r\nprint(interpreter.get_input_details())\r\ninterpreter.resize_tensor_input(0,[batch_size, 3,3])\r\ninterpreter.allocate_tensors()\r\ninterpreter.set_tensor(0, sample_input)\r\ninterpreter.invoke()\r\ninterpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nModel: \"model_2\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_a (InputLayer)         [(None, 3, 3)]            0         \r\n_________________________________________________________________\r\ninterm_1 (LSTM)              (None, 4)                 128       \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 1)                 5         \r\n=================================================================\r\nTotal params: 133\r\nTrainable params: 133\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n[{'name': 'input_a', 'index': 0, 'shape': array([1, 3, 3], dtype=int32), 'shape_signature': array([-1,  3,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-3-492497848c68> in <module>()\r\n     27 interpreter.allocate_tensors()\r\n     28 interpreter.set_tensor(0, sample_input)\r\n---> 29 interpreter.invoke()\r\n     30 interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py in invoke(self)\r\n    512     \"\"\"\r\n    513     self._ensure_safe()\r\n--> 514     self._interpreter.Invoke()\r\n    515 \r\n    516   def reset_all_variables(self):\r\n\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (10 != 1)Node number 50 (CONCATENATION) failed to prepare.\r\nNode number 10 (WHILE) failed to invoke.\r\n```\r\n\r\n**Failure details**\r\nThe conversion is successful, but the generated model cannot be resized to variable batch size.\r\nInput tensors containing unknown dimensions fails when coupled with LSTM\r\nSame script would work just fine if one removes creation of _interm_b_ and pass _input_a_ as the input to generate the _output_c_.\r\n", "comments": ["i am able to replicate this, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/cb2397d9ff19fd13d921c7ea63f2851b/untitled145.ipynb) as well as [on nightly](https://colab.sandbox.google.com/gist/Saduf2019/39c8c5377203ea508ccc8d1a368f5ca5/38776.ipynb)", "Currently we need all dimensions are known.\r\n\r\nThanks.", "Okay, thanks @renjie-liu.\r\nDo I close the issue, or is it better to remain open as a feature request?", "our fused ops will need the dimensions to be known because the states are maintained inside the kernel. so it is wai. :(\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38776\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38776\">No</a>\n"]}, {"number": 38775, "title": "tf.executing_eagerly returns False in TensorFlow 2 without using tf.function", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.5\r\n\r\n**Describe the current behavior**\r\n\r\nThe following statement\r\n\r\n    print(tf.executing_eagerly())\r\n\r\nprints `False` inside a function of a custom layer WHILE BUILDING THE MODEL, so before `compile` is called. None of those functions has the decorator `@tf.function`. In [the documentation](https://www.tensorflow.org/api_docs/python/tf/executing_eagerly) it says that the only time where the statement above can produce false is when either we are using `@tf.function` (which is not the case), \"Executing inside a transformation function for tf.dataset\" (which is not the case) or `tf.compat.v1.disable_eager_execution()` is called (which is not the case).\r\n\r\n**Describe the expected behavior**\r\n\r\nThe statement above should return True.\r\n\r\nSee [the related Stack Overflow question](https://stackoverflow.com/q/61355474/3924118).", "comments": ["@nbro \r\n\r\nEager execution is enabled by default in TF 2.x.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/7fdf0fc92a215578b6f2b2319ae8e122/untitled799.ipynb).Thanks!", "@ravikyram Yes, I know, but have you tried to run `tf.executing_eagerly()` inside a custom layer before the model is created or compiled?", "@nbro \r\n\r\nCan you help me with simple standalone code to reproduce the issue. It helps us in localizing the issue faster.Thanks!", "@ravikyram Here's a standalone code that reproduces the issue. \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass MyLayer(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        tf.print(\"tf.executing_eagerly() =\", tf.executing_eagerly())\r\n        return inputs\r\n\r\n\r\ndef get_model():\r\n    inp = tf.keras.layers.Input(shape=(1,))\r\n    out = MyLayer(8)(inp)\r\n    model = tf.keras.Model(inputs=inp, outputs=out)\r\n    model.summary()\r\n    return model\r\n\r\n\r\ndef train():\r\n    model = get_model()\r\n    model.compile(optimizer=\"adam\", loss=\"mae\")\r\n    x_train = [2, 3, 4, 1, 2, 6]\r\n    y_train = [1, 0, 1, 0, 1, 1]\r\n    model.fit(x_train, y_train)\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```\r\n\r\nThis produces `tf.executing_eagerly() = False`.\r\n\r\nI used TF 2.1.", "I have tried on colab with TF version 2.1.0, 2.2.0-rc3 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/b74a0b49a8e79d3789aa55c7e512cc5d/untitled804.ipynb).Thanks!", "@ravikyram If you execute the following statement on top of the script.\r\n\r\n```\r\ntf.config.experimental_run_functions_eagerly(True)\r\n```\r\n\r\nthe output of the script will be `tf.executing_eagerly() = True`.\r\n\r\nAccording to [the documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/config/experimental_run_functions_eagerly), `tf.config.experimental_run_functions_eagerly(True)` will make all functions run eagerly, which means, if I understood correctly, that they are not converted to an underlying graph first, so they run dynamically whenever you call them.\r\n\r\nThe problem is then that certain functions are first converted/compiled to the underlying graph and become static.\r\n\r\nHOWEVER, using `tf.config.experimental_run_functions_eagerly(True)` can cause other annoying issues/bugs. See https://github.com/tensorflow/tensorflow/issues/38836.", "when an input to a custom layer is symbolic input, then the layer is executed in graph (non-eager) mode. However, if your input to the custom layer is an eager tensor (as in the following example #1, then the custom layer is executed in the eager mode. So your model's output tf.executing_eagerly() = False is expected.\r\n\r\n### Example 1\r\n```\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass Linear(layers.Layer):\r\n\r\n  def __init__(self, units=32, input_dim=32):\r\n    super(Linear, self).__init__()\r\n    w_init = tf.random_normal_initializer()\r\n    self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),\r\n                                              dtype='float32'),\r\n                         trainable=True)\r\n    b_init = tf.zeros_initializer()\r\n    self.b = tf.Variable(initial_value=b_init(shape=(units,),\r\n                                              dtype='float32'),\r\n                         trainable=True)\r\n\r\n  def call(self, inputs):\r\n    print(\"tf.executing_eagerly() =\", tf.executing_eagerly())\r\n    return tf.matmul(inputs, self.w) + self.b\r\n\r\nx = tf.ones((1, 2)) # returns tf.executing_eagerly() = True\r\n#x = tf.keras.layers.Input(shape=(2,)) #tf.executing_eagerly() = False\r\nlinear_layer = Linear(4, 2)\r\ny = linear_layer(x)\r\nprint(y) \r\n#output in graph mode: Tensor(\"linear_9/Identity:0\", shape=(None, 4), dtype=float32)\r\n#output in Eager mode: tf.Tensor([[-0.03011466  0.02563028  0.01234017  0.02272708]], shape=(1, 4), dtype=float32)\r\n```\r\n\r\nHere is another example with Keras functional API where custom layer was used (similar to you). This model is executed in graph mode and prints tf.executing_eagerly() = False as in your case.\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nclass CustomDense(layers.Layer):\r\n  def __init__(self, units=32):\r\n    super(CustomDense, self).__init__()\r\n    self.units = units\r\n\r\n  def build(self, input_shape):\r\n    self.w = self.add_weight(shape=(input_shape[-1], self.units),\r\n                             initializer='random_normal',\r\n                             trainable=True)\r\n    self.b = self.add_weight(shape=(self.units,),\r\n                             initializer='random_normal',\r\n                             trainable=True)\r\n\r\n  def call(self, inputs):\r\n    print(\"tf.executing_eagerly() =\", tf.executing_eagerly())\r\n    return tf.matmul(inputs, self.w) + self.b\r\n\r\n\r\ninputs = keras.Input((4,))\r\noutputs = CustomDense(10)(inputs)\r\n\r\nmodel = keras.Model(inputs, outputs) \r\n```\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38775\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38775\">No</a>\n"]}, {"number": 38774, "title": "Fix test to run on all filesystem", "body": "@mihaimaruseac \r\n- Add argument `cloud_path` which is the path for cloud filesystem (nodename for hdfs, bucket for s3/gcs)\r\n- Change `Setup()` to use `CreateDir()` instead of `mkdir()`", "comments": []}]