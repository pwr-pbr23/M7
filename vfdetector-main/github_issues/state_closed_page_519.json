[{"number": 38167, "title": "make_csv_dataset ValueError: Received a feature column from TensorFlow v1", "body": "**System information** \r\n- OS Platform and Distribution: Mac Os 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): pip install \r\n- TensorFlow version (use command below):  2.1.0 (v2.1.0-rc2-17-ge5bf8de410 2.1.0)\r\n- Python version: 3.6\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWhen trying to train a DNNRegressor using a dataset from make_csv_dataset, I obtain a very strange error message:\r\n\r\n```python\r\nValueError: Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.\r\n```\r\n\r\n**Describe the expected behavior**\r\nI was expecting that this would work directly. \r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```python\r\ndef train_input_fn():\r\n    df = tf.data.experimental.make_csv_dataset(\r\n        file_pattern, batch_size, column_names=None, column_defaults=None,\r\n        label_name=label_name[0], select_columns=column_names, field_delim=',',\r\n        use_quote_delim=True,\r\n        na_value='', header=True, num_epochs=None, shuffle=True,\r\n        shuffle_buffer_size=10000, shuffle_seed=None,\r\n        prefetch_buffer_size=None,\r\n        num_parallel_reads=None, sloppy=False,\r\n        num_rows_for_inference=100,\r\n        compression_type=None, ignore_errors=False\r\n        )\r\n    df_batches = (\r\n        df.cache().repeat().shuffle(500)\r\n        .prefetch(tf.data.experimental.AUTOTUNE))\r\n    return df_batches\r\n\r\ntf.keras.backend.set_floatx('float32')\r\n\r\nnfeat = len(feature_names)\r\nncovs = nfeat * (nfeat + 1) // 2\r\nmodel = tf.estimator.DNNRegressor([ncovs, ],\r\n                                  # feature_names,\r\n                                  # activation_fn = tf.nn.relu,\r\n                                  dropout=0.3,\r\n                                  optimizer=\"Adam\",\r\n                                  weight_column='weights'\r\n                                  )\r\n\r\nhistory = model.train(train_input_fn, steps=40000)\r\n```\r\n\r\nI do not understand how to make this work honestly. I cannot find a end-to-end minimal example that uses a CSV input data file that is too large to fit in memory.", "comments": ["@mfouesneau,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also a sample of the csv file you are using. Thanks!", "I believe one key is to use \r\n```feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]```\r\n\r\ninstead of a list of strings here.\r\n\r\nHere is the code\r\n\r\n```python\r\n'''\r\nTrying to train DNN regressor with batch mode\r\n'''\r\nimport tensorflow as tf\r\nimport tf_csv_dataset as tfcsv\r\n\r\n# Which file\r\nfile_pattern = 'make_models/models_20190510.csv'\r\n# batch size for reading\r\nbatch_size = 100_000\r\n\r\n# Load the interface to the data.\r\nds = tfcsv.make_csv_dataset(\r\n    file_pattern, batch_size, column_names=None, column_defaults=None,\r\n    label_name=None, select_columns=None, field_delim=',',\r\n    use_quote_delim=True,\r\n    na_value='', header=True, num_epochs=None, shuffle=True,\r\n    shuffle_buffer_size=10000, shuffle_seed=None,\r\n    prefetch_buffer_size=None,\r\n    num_parallel_reads=None, sloppy=False,\r\n    num_rows_for_inference=100,\r\n    compression_type=None, ignore_errors=False\r\n    )\r\n\r\n\r\ndef show_batch(dataset):\r\n    \"\"\" Show the batch content \"\"\"\r\n    for batch in dataset.take(1):\r\n        try:\r\n            keys = []\r\n            values = []\r\n            for key, value in batch.items():\r\n                print(\"{:20s}: {}\".format(key, value.numpy()))\r\n                keys.append(key)\r\n                values.append(value)\r\n            return dict(zip(keys, values))\r\n\r\n        except AttributeError:\r\n            keys = []\r\n            values = []\r\n            features, labels = batch\r\n            for key, value in features.items():\r\n                print(\"{:20s}: {}\".format(key, value.numpy()))\r\n                keys.append(key)\r\n                values.append(value)\r\n            print(\"{:20s}: {}\".format(\"labels\", labels))\r\n            return dict(zip(keys, values)), labels\r\n\r\n\r\ncolumn_names = [key for key in [batch.items() for batch in ds.take(1)]]\r\ncolumn_names = [k[0] for k in column_names[0] if k[0] != '']\r\n\r\n\r\nfeature_names = 'logL logT logg Z A0 R0'.split()\r\nlabel_name = [k for k in column_names if k not in feature_names]\r\n\r\nprint(\"Features: {}\".format(feature_names))\r\nprint(\"Label: {}\".format(label_name))\r\n\r\n\r\n# Load the interface to the data.\r\nds = tfcsv.make_csv_dataset(\r\n    file_pattern, batch_size, column_names=None, column_defaults=None,\r\n    label_name=label_name, select_columns=column_names, field_delim=',',\r\n    use_quote_delim=True,\r\n    na_value='', header=True, num_epochs=None, shuffle=True,\r\n    shuffle_buffer_size=10000, shuffle_seed=None,\r\n    prefetch_buffer_size=None,\r\n    num_parallel_reads=None, sloppy=False,\r\n    num_rows_for_inference=100,\r\n    compression_type=None, ignore_errors=False\r\n    )\r\n\r\n\r\ndef pack(features, label):\r\n    return tf.stack(list(features.values()), axis=-1), label\r\n\r\n\r\ndef train_input_fn():\r\n    df = tfcsv.make_csv_dataset(\r\n        file_pattern, batch_size,\r\n        label_name=label_name,\r\n        select_columns=column_names, field_delim=',',\r\n        use_quote_delim=True,\r\n        )\r\n    df_batches = (\r\n        df.cache().prefetch(tf.data.experimental.AUTOTUNE))\r\n    return df_batches\r\n\r\n\r\ntf.keras.backend.set_floatx('float32')\r\n\r\nfeature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]\r\nnfeat = len(feature_names)\r\nncovs = nfeat * (nfeat + 1) // 2\r\nmodel = tf.estimator.DNNRegressor([ncovs, ],\r\n                                  feature_columns,\r\n                                  # activation_fn = tf.nn.relu,\r\n                                  dropout=0.3,\r\n                                  optimizer=\"Adam\",\r\n                                  )\r\nhistory = model.train(train_input_fn, steps=40000)\r\n```", "Just to be clearer, my goal is to train a DNN regressor with multidimensional labels in batch mode to be able to handle large training sets. \r\n\r\nMaybe my approach is not the most adapted, but I cannot find an example with batch training with csv datasets. I have a different approach if my training set is small and fits in memory.\r\n", "@mfouesneau,\r\nCould you please share the `models_20190510.csv` file you are using in the code. I was unable to reproduce the issue reported here due to the missing files. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a99616465c7f7d967fe4b5b85b978fb6/38167.ipynb). Thanks!", "> @mfouesneau,\r\n> Could you please share the `models_20190510.csv` file you are using in the code. I was unable to reproduce the issue reported here due to the missing files. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a99616465c7f7d967fe4b5b85b978fb6/38167.ipynb). Thanks!\r\n\r\nAny updates regarding this? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38167\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38167\">No</a>\n", "I have this problem too\r\nI'm new to machine learning and this problem is pretty frustrating\r\nI'm using my feature column in an  estimator.DNNClassifier \r\n\r\n\r\n"]}, {"number": 38166, "title": "how can I pass logits before I fit and predict model?", "body": "Since I need to train a model with multiple labels, I need to use loss function `tf.nn.sigmoid_cross_entropy_with_logits`. This function has two parameters: `logits` and `loss`.\r\nDoes parameter `logits`is the value of predicted y? How can I pass this value before I compile model? I cannot predict y before I compile and fit model, right?\r\n\r\nThis is my code:\r\n\r\n```\r\nm_part1 = keras.Sequential([keras.layers.Dense(50, activation='tanh', input_shape=[100]), \r\n                            keras.layers.Dense(30, activation='relu'),\r\n                            keras.layers.Dense(50, activation='tanh'),\r\n                            keras.layers.Dense(100, activation='relu')])\r\nm_part2 = keras.Sequential([keras.layers.Dense(8, input_shape=[100])])\r\nmodel = keras.Sequential([m_part1, m_part2])\r\n\r\nmodel.compile(optimizer='rmsprop', \r\n              loss=tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred), labels=y),   # <---How to figure out y_pred?\r\n              metrics=['accuracy'])\r\nmodel.fit(x, y, epochs=10, batch_size=32)\r\ny_pred = model.predict(x)  # <--- Now I got y_pred\r\n```\r\n\r\nHow to calculate `y_pred` even before compiling model?", "comments": ["@OnlyBelter, Can you share the full standalone code and also the Tensorflow version which you are using. Thanks", "```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nmodel = keras.Sequential([keras.layers.Dense(50, activation='tanh', input_shape=[100]), \r\n                            keras.layers.Dense(30, activation='relu'),\r\n                            keras.layers.Dense(50, activation='tanh'),\r\n                            keras.layers.Dense(100, activation='relu'),\r\n                            keras.layers.Dense(8)])\r\n\r\nmodel.compile(optimizer='rmsprop', \r\n              loss=tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred), labels=y),   # <---How to figure out y_pred?\r\n              metrics=['accuracy'])\r\nmodel.fit(x, y, epochs=10, batch_size=32)\r\ny_pred = model.predict(x)  # <--- Now I got y_pred\r\n```\r\nI use tensorflow v2.1.0\r\n\r\nIt's a simple code fragment, I just don't know how to pass `logits`. I searched some examples, all of them need to construct a custom class to wrap loss function. such as this one: https://tensorflow.google.cn/tutorials/generative/cvae\r\n\r\n", "@OnlyBelter Please take a look at this [article](https://towardsdatascience.com/sigmoid-activation-and-binary-crossentropy-a-less-than-perfect-match-b801e130e31) which clearly explains how to pass logits.\r\nAlso please post questions related to support on stack overflow as there is a wider community to respond. Thanks!", "I got it, thanks a lot! This link can help:\r\nhttps://stackoverflow.com/questions/61012727/how-can-i-pass-logits-to-sigmoid-cross-entropy-with-logits-before-i-fit-and-pred"]}, {"number": 38165, "title": "tf 2 vs tf 1 - different behaviour: model.evaluate(..., batch_size=...)", "body": "Consider the following code (you can run it [here](https://colab.research.google.com/drive/1H04RM9TsFpQf8_8ZbExMkW-jWLzMi7eL) on colab):\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nx_train = np.array([[1],[20],[3]],\r\n                   dtype=np.float32)\r\n\r\ny_train = np.array([[0.1],[0.2],[0.7]],\r\n                   dtype=np.float32)\r\n\r\nmodel = keras.Sequential([\r\n                          keras.layers.Dense(1,input_shape=[1], activation='sigmoid',kernel_initializer='ones')\r\n])\r\nmodel.compile(\r\n    loss=keras.losses.binary_crossentropy,\r\n    optimizer=keras.optimizers.Adam(),\r\n    metrics=['binary_crossentropy']\r\n)\r\n\r\nx_train.shape\r\nmodel.evaluate(x_train,y_train,batch_size=3)\r\nmodel.evaluate(x_train,y_train,batch_size=2)\r\nmodel.evaluate(x_train[:2],y_train[:2],batch_size=2)\r\nmodel.evaluate(x_train[2:],y_train[2:],batch_size=2)\r\n```\r\n\r\nIn TF 2: it gives:\r\n\r\n> **1/1** [==============================] - 0s 2ms/step - loss: 6.0539 - binary_crossentropy: 6.0539\r\n**2/2** [==============================] - 0s 1ms/step - loss: **4.7776** - binary_crossentropy: 6.0539\r\n**1/1** [==============================] - 0s 1ms/step - loss: 8.6066 - binary_crossentropy: 8.6066\r\n1/1 [==============================] - 0s 1ms/step - loss: 0.9486 - binary_crossentropy: 0.9486\r\n[0.9485874176025391, 0.9485874176025391]\r\n\r\nIn TF 1: it gives:\r\n\r\n> **3/3** [==============================] - 0s 4ms/sample - loss: 6.0539 - binary_crossentropy: 6.0539\r\n**3/3** [==============================] - 0s 2ms/sample - loss: **6.0539** - binary_crossentropy: 6.0539\r\n**2/2** [==============================] - 0s 321us/sample - loss: 8.6066 - binary_crossentropy: 8.6066\r\n1/1 [==============================] - 0s 713us/sample - loss: 0.9486 - binary_crossentropy: 0.9486\r\n[0.9485874176025391, 0.9485874]\r\n\r\n1. So, in tf 1 the evaluation is computed correctly irrespective of the batch_size, but in tf 2 it is not the case. Why?\r\n\r\n2. Why the loss and metric are not the same: '2/2 [==============================] - 0s 1ms/step - loss: **4.7776** - binary_crossentropy: 6.0539' ?", "comments": ["\r\nplease find the gist for [tf nightly](https://colab.sandbox.google.com/gist/Saduf2019/107819b6a366ec2054ba831e49805406/2tf.ipynb) and [tf 1.x](https://colab.sandbox.google.com/gist/Saduf2019/ac58dbfe93c0dc4c8d9dc96ff9d313ee/1.ipynb), could you please let us know what is not computed correctly.", "Yes. As far as I see the outputs are the same as in my first post. The difference I found is in bold: 4.7776  vs 6.0539.", "I have a similar issue and would really be interested in the solution.\r\nThe validation loss should in general be independent of the batch size/order of data within batches, as long as it is evaluated on the entire dataset, right?", "Please take a look at issue #38596, linked above. I believe this is the underlying issue for why the Keras `model.evaluate()` method produces different values for different `batch_size` argument values.", "@bentyeh This was resolved in recent tf-nightly. It will be available in stable TF2.2 in near future. [Here](https://colab.research.google.com/gist/jvishnuvardhan/8bbb847311468302c9ae99dd56e29590/untitled131.ipynb) is the gist for your reference. Thanks!\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if the issue persists again. Thanks!"]}, {"number": 38164, "title": "Dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory;", "body": "**System information**\r\n- OS Platform and Distribution: nvidia/cuda:10.1-base-ubuntu18.04 docker base\r\n- TensorFlow installed from (source or binary): Custom\r\n- TensorFlow version: 2.2rc2\r\n- Python version: 3.73\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: 10.1, 7.x\r\n- GPU model and memory: 1050M\r\n\r\n**Describe the problem**\r\nHi,\r\n\r\nI am trying to create my own Docker container for Tensorflow on the GPU.\r\n\r\nMy base is: \r\n```\r\nFROM nvidia/cuda:10.1-base-ubuntu18.04\r\nLABEL authors=\"Lukas Heumos (lukas.heumos@posteo.net)\" \\\r\n      description=\"Docker image containing all requirements for running machine learning on CUDA enabled GPUs\"\r\n\r\n# Install some basic utilities\r\nRUN apt-get update && apt-get install -y \\\r\n    curl \\\r\n    wget \\\r\n    ca-certificates \\\r\n    sudo \\\r\n    git \\\r\n    bzip2 \\\r\n    libx11-6 \\\r\n && rm -rf /var/lib/apt/lists/*\r\n\r\n# Create a working directory and set it as default\r\nRUN mkdir /app\r\nRUN chmod 777 /app\r\nWORKDIR /app\r\n\r\n# Create a non-root user and switch to it\r\nRUN adduser --disabled-password --gecos '' --shell /bin/bash user \r\nRUN echo \"user ALL=(ALL) NOPASSWD:ALL\" > /etc/sudoers.d/90-user\r\nUSER user\r\n\r\n# All users can use /home/user as their home directory\r\nENV HOME=/home/user\r\nRUN chmod 777 /home/user\r\n\r\n # Install Miniconda\r\nRUN curl -so ~/miniconda.sh https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh \\\r\n && chmod +x ~/miniconda.sh \\\r\n && ~/miniconda.sh -b -p ~/miniconda \\\r\n && rm ~/miniconda.sh\r\nENV PATH=/home/user/miniconda/bin:$PATH\r\nENV CONDA_AUTO_UPDATE_CONDA=false\r\n\r\n# Update Conda\r\nRUN conda update conda\r\n```\r\n\r\n\r\n\r\nAnd my tensorflow container is: \r\n\r\n```\r\nFrom mlflowcore/base:1.0.0\r\n\r\n# Install the conda environment\r\nCOPY tensorflow_environment.yml .\r\nRUN conda env create -f tensorflow_environment.yml && conda clean -a\r\n\r\n# Activate the environment\r\nRUN echo \"source activate tensorflow-2.1-cuda-10.1\" > ~/.bashrc\r\nENV PATH /opt/conda/envs/env/bin:$PATH\r\n\r\n# Dump the details of the installed packages to a file for posterity\r\nRUN conda env export --name tensorflow-2.1-cuda-10.1 > tensorflow-2.1-cuda-10.1.yml\r\n```\r\nwith the environment.yml:\r\n\r\n```\r\nname: tensorflow-2.1-cuda-10.1\r\nchannels:\r\n    - conda-forge\r\n    - defaults\r\ndependencies:\r\n    - defaults::cudatoolkit=10.1\r\n    #- defaults::tensorflow=2.1.0 -> distribute.MirroredStrategy API changed in 2.2 -> https://www.tensorflow.org/tutorials/distribute/custom_training\r\n    - conda-forge::graphviz=2.40.1\r\n    - conda-forge::python-graphviz=0.13.2\r\n    - pip\r\n    - pip:\r\n      - tensorflow==2.2.0rc2\r\n```\r\n\r\nHowever, when trying to run stuff on the GPU I get:\r\n\r\n> 2020-04-02 09:39:54.522822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n> 2020-04-02 09:39:54.570821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n> 2020-04-02 09:39:54.572960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n> 2020-04-02 09:39:54.573491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n> 2020-04-02 09:39:54.577211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n> 2020-04-02 09:39:54.578817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n> 2020-04-02 09:39:54.579250: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\r\n> 2020-04-02 09:39:54.579268: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. \r\n> Skipping registering GPU devices...\r\n\r\nWhy does it not find that file? Where is it?\r\n\r\nHelp would be highly appreciated.\r\nThank you very much!\r\nBest\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nSimple \r\n\r\n`tf.config.list_physical_devices('GPU')`\r\n\r\nAlso ran an MNIST example. Without success.\r\n\r\n**Any other info / logs**\r\nI am using the very same Base & Docker image structure for Pytorch and XGBoost and it works flawlessly and uses the GPU. Hence, this is a Tensorflow issue.\r\n", "comments": ["Oh, and using one of the already existing Tensorflow docker images is **not** an option for me. And yes, I've read all GPU installation guides for Tensorflow, but they're not helpful regarding my issue.", "Added\r\n\r\n```\r\nENV LD_LIBRARY_PATH \u201c$LD_LIBRARY_PATH:/usr/local/cuda/lib64\u201d\r\nENV LD_LIBRARY_PATH \u201c$LD_LIBRARY_PATH:/usr/local/cuda-10.1/compat\u201d\r\n```\r\n\r\nAnd now get:\r\n\r\n  ```\r\n  2020-04-03 08:50:37.180018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n    2020-04-03 08:50:37.181533: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\r\n    2020-04-03 08:50:37.181612: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 64683ab6f51a\r\n    2020-04-03 08:50:37.181642: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 64683ab6f51a\r\n    2020-04-03 08:50:37.181816: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.87.1\r\n    2020-04-03 08:50:37.181877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0\r\n    2020-04-03 08:50:37.181898: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 440.64.0 does not match DSO version 418.87.1 \u2013 cannot find working devices in this configuration\r\n```\r\n\r\nI need to somehow update the Nvidia drivers maybe? I cannot reboot however in a Docker container...", "All right.\r\nSo the solution/issue is that installing tensorflow-gpu is required BEFORE installing  tensorflow==2.2.0rc2\r\n\r\nSo tensorflow-gpu must contain some packages or installation instructions that tensorflow==2.2.0rc2 does not have anymore.\r\n\r\n", "Hello everyone,\r\nI solved the error by installing cuDNN 7.6. I followed these steps;\r\n\r\n1. Remove cuda tool kit from anaconda environment using command `conda remove cudatoolkit`\r\n\r\n2. Download **cuDNN v7.6.4** (September 27, 2019), **for CUDA 10.1** [(https://developer.nvidia.com/rdp/cudnn-archive)](https://developer.nvidia.com/rdp/cudnn-archive)\r\n              cuDNN _Runtime_ Library for Ubuntu18.04 (Deb)\r\n              cuDNN _Developer_ Library for Ubuntu18.04 (Deb) \r\n              cuDNN _Code Samples_ and User Guide for Ubuntu18.04 (Deb)\r\n\r\n2. Installed the above 3 files _in the same sequence_. ", "> So the solution/issue is that installing tensorflow-gpu is required BEFORE installing tensorflow==2.2.0rc2\r\n\r\n@Zethson,\r\nIs this still an issue?\r\n\r\nAlso, please take a look at @engrmz's comment and check if it helps. Thanks!", "> > So the solution/issue is that installing tensorflow-gpu is required BEFORE installing tensorflow==2.2.0rc2\r\n> \r\n> @Zethson,\r\n> Is this still an issue?\r\n> \r\n> Also, please take a look at @engrmz's comment and check if it helps. Thanks!\r\n\r\nHonestly I don't know anymore because since then I moved on with my containers. Running into similar issues with libcudnn.so.8 atm. It's just a mess with Tensorflow. The same containers always, always, always run smoothly with Pytorch. But well it's difficult to get this smoothly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38164\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38164\">No</a>\n"]}, {"number": 38163, "title": "Import fail in Tensorflow", "body": "\r\n**System information**\r\n- OS Platform: Windows \r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.2.0rc2, Build: pypi_0 , Channel: pypi\r\n- Python version:3.8.2\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version:10.2\r\n- GPU model and memory: Nvidia GeForce RTX 2060\r\nGPU memory:13.9GB\r\nDedicated GPU memory:6GB\r\nShared GPU Memory:7.9GB\r\n\r\nI installed TensorFlow in a new anaconda environment was working fine later that day I installed keras, while installation processes I completed 3 prerequisites,cuDNN ,HDF5 and h5py,graphviz and pydot (used by visualization utilities to plot model graphs). Then while trying to import Keras and Tensorflow simultaneously Kernal keep getting restarted\r\n![image](https://user-images.githubusercontent.com/31595943/78250744-f396ea80-750d-11ea-94fd-e86c8d14f591.png)\r\n Later in only Tensorflow installation\r\nThen the following error occurred\r\n![image](https://user-images.githubusercontent.com/31595943/78250929-335dd200-750e-11ea-8c53-e71ddf3bb6e7.png)\r\n![image](https://user-images.githubusercontent.com/31595943/78250973-4375b180-750e-11ea-93e9-bf7549a2a181.png)\r\n\r\n\r\nIf possible please let me know the exact suitable version to install for\r\npython\r\nTensorFlow\r\nKeras\r\ncuDNN\r\nand other libraries so that I could easily use TensorFlow and Keras using my GPU\r\nThanks in advance", "comments": ["@Vatsal-Malaviya \r\n\r\nPlease, see [tested builded configurations](https://www.tensorflow.org/install/source_windows#gpu) from here.\r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) from here.\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Thanks!", "Please don't post screenshots of errors but post the error directly. This way, the errorsare easily searchable and automated triage tools can function properly.", "Also, can you post the output of `pip list` from *the same environment* as that used by the IDE?", "> @Vatsal-Malaviya\r\n> \r\n> Please, see [tested builded configurations](https://www.tensorflow.org/install/source_windows#gpu) from here.\r\n> \r\n> What is make/model of your cpu?\r\n> I suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\n> Make sure to download the [latest microsoft visual c++ redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) from here.\r\n> .Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n> \r\n> Please, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Thanks!\r\n\r\nCPU : AMD ryzen 7 3750h with radeon vega mobile gfx 2.30 ghz", "> Please don't post screenshots of errors but post the error directly. This way, the errorsare easily searchable and automated triage tools can function properly.\r\n\r\nPlease share a way to copy output from Jupyter lab", "> @Vatsal-Malaviya\r\n> \r\n> Please, see [tested builded configurations](https://www.tensorflow.org/install/source_windows#gpu) from here.\r\n> \r\n> What is make/model of your cpu?\r\n> I suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\n> Make sure to download the [latest microsoft visual c++ redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) from here.\r\n> .Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n> \r\n> Please, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Thanks!\r\n\r\nAfter going through prerequisites again, in a new anaconda env \r\nusing the command \"pip install tensorflow\" with python 3.7.7\r\nand got Internal root error\r\n\r\n```\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-64156d691fe5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-64156d691fe5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-64156d691fe5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1415, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1315, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-64156d691fe5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1415, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1315, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2043                         # in the engines. This should return a list of strings.\r\n-> 2044                         stb = value._render_traceback_()\r\n   2045                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3346             if result is not None:\r\n   3347                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3348             self.showtraceback(running_compiled_code=True)\r\n   3349         else:\r\n   3350             outflag = False\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2045                     except Exception:\r\n   2046                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2047                                             value, tb, tb_offset=tb_offset)\r\n   2048 \r\n   2049                     self._showtraceback(etype, value, stb)\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1413             self.tb = tb\r\n   1414         return FormattedTB.structured_traceback(\r\n-> 1415             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1416 \r\n   1417 \r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1313             # Verbose modes need a full traceback\r\n   1314             return VerboseTB.structured_traceback(\r\n-> 1315                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1316             )\r\n   1317         elif mode == 'Minimal':\r\n\r\nc:\\users\\vatsal\\appdata\\local\\continuum\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1181         exception = self.get_parts_of_chained_exception(evalue)\r\n   1182         if exception:\r\n-> 1183             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1184             etype, evalue, etb = exception\r\n   1185         else:\r\n```", "Did you download the [MSVC redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n\r\nCPU seems to support AVX2 and is 64 bits\r\n\r\nYou can always used Google's codelab, there TF is guaranteed to work (as it doesn't run on your computer)", "Thanks for your help, reinstalling x64 solved the error ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38163\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38163\">No</a>\n"]}, {"number": 38162, "title": "Provide a tensorflow maven package for AWS Lambda or lighter builds in general", "body": "The current build size of tensorflow 1.14.0 makes it impossible to use the library on AWS Lambda without further steps to reduce the depedency size.\r\n\r\nIt would be great to have for example a tensorflow dependency for AWS Lambda specifically.\r\n\r\nWhat would also work, would be a separate module for tensorflow without all native libraries and a module per native implementation. This way the overhead of the darwin and windows native code is gone and reduces the dependency significantly (~200MB).", "comments": ["This request is not valid with latest versions , so closing this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38162\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38162\">No</a>\n"]}, {"number": 38161, "title": "tflite model crashes before loading .tflite file, with no error or exception", "body": "**System information** \r\n- Have I written custom code: \r\n\r\nYes I have:\r\n\r\nIn Activity.java:\r\n\r\n=======================================================================\r\n\r\n```\r\ngpuDelegate = new GpuDelegate();\r\nInterpreter.Options tfliteOptions = (new Interpreter.Options()\r\n          .addDelegate(gpuDelegate));\r\ntfliteModel\r\n        = FileUtil.loadMappedFile(myContext,\r\n        \"my_model.tflite\");\r\ntfliteInterpreter = new Interpreter(tfliteModel, tfliteOptions);\r\n```\r\n...\r\n\r\n```\r\nimageProcessor =\r\n        new ImageProcessor.Builder()\r\n                .add(new NormalizeOp(MY_MEAN, MY_STDDEV))\r\n                .build();\r\n\r\ninputImageBuffer.load(bitmap);\r\nimageProcessor.process(inputImageBuffer);\r\n```\r\n\r\n...\r\n\r\n`tfliteInterpreter.run(inputImageBuffer.getBuffer(), outputBuffer.getBuffer().rewind());`\r\n\r\n=======================================================================\r\n\r\nIn build.gradle:\r\n\r\n=======================================================================\r\n```\r\nimplementation 'org.tensorflow:tensorflow-lite:+'\r\nimplementation 'org.tensorflow:tensorflow-lite-gpu:+'\r\nimplementation 'org.tensorflow:tensorflow-lite-support:+'\r\n```\r\n=======================================================================\r\n\r\n- OS Platform and Distribution: \r\n\r\nLinux Ubuntu 16.04\r\n\r\n- Mobile device: \r\n\r\nSamsung Galaxy S10\r\n\r\n- TensorFlow installed:\r\n\r\nFrom binary (pip)\r\n\r\n- TensorFlow version: \r\n\r\nTensorFlow 2.0\r\n\r\n- Python version:\r\n\r\nPython 3.6\r\n\r\n- GCC/Compiler version:\r\n\r\nWasn't compiled from source, but gcc 7.4.0\r\n\r\n- CUDA/cuDNN version:\r\n\r\nCUDA 10.0\r\n\r\n- GPU model and memory:\r\n\r\nGeForce RTX 2080 Ti\r\n11GB\r\n\r\n**Describe the current behavior**\r\n\r\nModel input is a 1MP image.\r\nI'm trying to run the model via CPU (tfliteOptions are default), GPU (GPU delegate) and NNAPI (NNAPI delegate).\r\n\r\n1MP runs with the GPU delegate only - the other two options crash.\r\nWhen crashing - the debug process is detached from Android.\r\nThere are no exceptions, errors or hints regarding what happened.\r\n\r\nAfter that, I take the same exact model, and I only change the input size, from 1MP to 10MP (in python it's just changing the HxW of the input image). From the 10MP model I create a new .tflite file.\r\nWhen trying to run the 10MP model - it doesn't even load.\r\n\r\nIs it a memory issue? and if so - how can I check that? What can I do to reduce the impact?\r\n\r\n**Describe the expected behavior**\r\n\r\nHave some exceptions, error messages or any other hint as to what's going on.\r\nLet's say it's a memory issue - how can I handle that? Which part fails exactly?\r\n\r\n**Other info / logs**\r\n\r\n- Debugging the 1MP model on CPU (the issue is that the app crashes):\r\n\r\nLast debugger frames:\r\n\r\ngetRuntime:166, VMRuntime (dalvik.system)\r\n<init>:69, DirectByteBuffer$MemoryRef (java.nio)\r\nallocateDirect:258, ByteBuffer (java.nio)\r\nallocateMemory:352, TensorBuffer (org.tensorflow.lite.support.tensorbuffer)\r\n<init>:304, TensorBuffer (org.tensorflow.lite.support.tensorbuffer)\r\n<init>:38, TensorBufferFloat (org.tensorflow.lite.support.tensorbuffer)\r\ncreateDynamic:96, TensorBuffer (org.tensorflow.lite.support.tensorbuffer)\r\ngetTensorBuffer:297, TensorImage$ImageContainer (org.tensorflow.lite.support.image)\r\ngetTensorBuffer:213, TensorImage (org.tensorflow.lite.support.image)\r\napply:52, TensorOperatorWrapper (org.tensorflow.lite.support.image.ops)\r\n\r\nProcess is detached when calling ByteBuffer.allocateDirect (in allocateMemory function):\r\n```\r\n    private void allocateMemory(int[] shape) {\r\n        SupportPreconditions.checkNotNull(shape, \"TensorBuffer shape cannot be null.\");\r\n        SupportPreconditions.checkArgument(isShapeValid(shape), \"Values in TensorBuffer shape should be non-negative.\");\r\n        int newFlatSize = computeFlatSize(shape);\r\n        if (this.flatSize != newFlatSize) {\r\n            this.flatSize = newFlatSize;\r\n            this.shape = (int[])shape.clone();\r\n            this.buffer = ByteBuffer.allocateDirect(this.flatSize * this.getTypeSize()); <<<< HERE <<<<\r\n            this.buffer.order(ByteOrder.nativeOrder());\r\n        }\r\n    }\r\n```\r\n\r\n- Debugging the 1MP model on NNAPI (the issue is that the app crashes):\r\n\r\nProcess is detached when calling applyDelegate (in applyDelegates function, in NativeInterpreterWapper.class):\r\n```\r\nwhile(var6.hasNext()) {\r\n                Delegate delegate = (Delegate)var6.next();\r\n                applyDelegate(this.interpreterHandle, this.errorHandle, delegate.getNativeHandle()); <<<< HERE <<<<\r\n                this.delegates.add(delegate);\r\n            }\r\n```\r\n\r\n- Debugging the 10MP model on GPU (the issue is that the .tflite model doesn't even gets loaded):\r\n\r\nI see that the Asset Manager gets closed.\r\nLast debugger frames:\r\n\r\nget:145, ClosedGuard (dalvik.system)\r\n<init>:104, ParcelFileDescriptor (android.os)\r\n<init>:184, ParcelFileDescriptor (android.os)\r\nnativeOpenAssetFd:-1, AssetManager (android.content.res)\r\nopenFd:848, AssetManager (android.content.res)\r\nloadMappedFile:154, FileUtil (org.tensorflow.lite.support.common)\r\n", "comments": ["@orangesomethingorange Can you please share the code to create model and converting it to tflite model? It is difficult to find root-cause of the issue without model. I will check the model and resolve the issue. Thanks!", "@jvishnuvardhan Thanks! I already changed the whole design since I couldn't get pass the memory issue. Now the Interpreter instance is running, but I have different issues regarding batch image processing and converting byte, float and int values. I'll open a new issue if I'll find a bug or post on stackoverflow :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38161\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38161\">No</a>\n", "> @jvishnuvardhan Thanks! I already changed the whole design since I couldn't get pass the memory issue. Now the Interpreter instance is running, but I have different issues regarding batch image processing and converting byte, float and int values. I'll open a new issue if I'll find a bug or post on stackoverflow :)\r\n\r\nhello,How did you solve your problem\uff1fI ran into the same problem", "I would be very grateful if you could explain briefly", "@WindowsDriver Please create a new issue with a standalone code to reproduce the error. Thanks!"]}, {"number": 38160, "title": "AttributeError: module 'tensorflow.keras.optimizers' has no attribute '\u0391dam'", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Google Colab\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): 2.2.0-rc2\r\n\r\n**Describe the current behavior**\r\nTensorflow 2.2.0-rc2 cannot find Adam in tf.keras.optimizers.\r\n\r\n**Standalone code to reproduce the issue** \r\noptimizer = tf.keras.optimizers.\u0391dam(2e-4)\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38160\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38160\">No</a>\n"]}, {"number": 38159, "title": "modify num_frames if no padding on the 147 line in shape_ops.py", "body": "In [https://www.tensorflow.org/api_docs/python/tf/signal/frame](https://www.tensorflow.org/api_docs/python/tf/signal/frame), the explanation is followed by\r\n\r\n```\r\n# A batch size 3 tensor of 9152 audio samples.\r\naudio = tf.random.normal([3, 9152])\r\n\r\n# Compute overlapping frames of length 512 with a step of 180 (frames overlap\r\n# by 332 samples). By default, only 50 frames are generated since the last\r\n# 152 samples do not form a full frame.\r\nframes = tf.signal.frame(audio, 512, 180)\r\nframes.shape.assert_is_compatible_with([3, 50, 512])\r\n```\r\n\r\nbut  if `pad_end` is False, on the 147 line in `shape_ops.py`:\r\n\r\n```\r\nnum_frames = math_ops.maximum(\r\n          0, 1 + (length_samples - frame_length) // frame_step)\r\n```\r\nthis is incorrect because num_frames is calculated as 1+(9152-50) // 180 =  51.\r\nso, i replaced  `1 + (length_samples - frame_length) // frame_step` with `length_samples//frame_step`.\r\nthe result is equal to what is written in [the api_docs](https://www.tensorflow.org/api_docs/python/tf/signal/frame), for example, 9152//180 = 50.\r\n\r\nThank you.", "comments": []}, {"number": 38158, "title": "Unable to batch tensorflowLite object detection model", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): MacOSX\r\n- TensorFlow installed from (source or\r\nbinary): Binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nI'm using the TfLite object detection models in python and upon trying to resize the input to increase the batch size; I'm getting an error as follows: \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_cropped_face.py\", line 70, in <module>\r\n    interpreter.allocate_tensors()\r\n  File \"/Users/harshitdwivedi/Desktop/tf_env/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py\", line 73, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/Users/harshitdwivedi/Desktop/tf_env/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: tensorflow/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements (3276800 != 65536)Node number 88 (RESHAPE) failed to prepare.\r\n```\r\n\r\n**Describe the expected behavior**\r\nSetting a custom batch size for an image classification model works without any issues; so I expect the same thing to happen here as well.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\ninterpreter = tf.contrib.lite.Interpreter(model_path=\"cropped_face.tflite\")\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# resize the input to run inference on more than 1 image at a time; the default size is [1,512,512,3]\r\ninterpreter.resize_tensor_input(input_details[0]['index'], [50, 512, 512, 3])\r\ninterpreter.allocate_tensors()\r\n\r\n```\r\nHere's the model I'm using. I have trained it via the GCP's Cloud Vision Dashboard.\r\nhttps://drive.google.com/file/d/1teJ34GvWmd-1aZBqNLeqIy-owOj5_RDS/view?usp=sharing", "comments": ["@harshithdwivedi \r\nplease refer to this [comment](https://github.com/tensorflow/tensorflow/issues/16216#issuecomment-358685965) and issues with similar error for reference and let us know if it helps.\r\n\r\n\r\n#25549 #22377 #23600  #23399", "Nope, doesn't help.\r\nI've gone through these issues already and none of them has a solution to this problem. \r\n\r\nP. S. Do note that I'm trying to resize the input to increase the batch size and not the input image size.\r\nSome answers outlined that the image size can't be changed for mobilenet on the fly so that's not what I'm trying to do anyways. ", "Hi @Saduf2019 any update on this?", "cc: @jvishnuvardhan ", "@harshithdwivedi I suspect dynamic batching was not implemented in TF1.x. Can you please try `TF2.x`?. While converting the model, define the shape as `[None,512,512,3]` and convert the model to tflite model and test the converted model with interpreter. Check [this](https://github.com/tensorflow/tensorflow/issues/38036) issue which is similar to you. Thanks!", "Hey @jvishnuvardhan thanks for the reply.\r\n\r\nI'm getting this model from Cloud AutoML object detection so it's already in tflite format.\r\nI doubt if it's possible to reconvert a tflite model.\r\n\r\nI tried TF2.0 but I keep getting the same error.\r\nI also tried to set the shape as [None, 512, 512, 3] from python code but it fails to accept that as a valid size: \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_cropped_face.py\", line 69, in <module>\r\n    None, 512, 512, 3])\r\n  File \"/Users/harshitdwivedi/Desktop/tf_2.0/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py\", line 402, in resize_tensor_input\r\n    tensor_size = np.array(tensor_size, dtype=np.int32)\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\r\n```\r\n\r\nMy Python code: \r\n\r\n```py\r\ninterpreter = tf.lite.Interpreter(model_path=\"cropped_face.tflite\")\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# resize the input to run inference on more than 1 image at a time; the default size is [1,512,512,3]\r\ninterpreter.resize_tensor_input(input_details[0]['index'], [None, 512, 512, 3])\r\ninterpreter.allocate_tensors()\r\n\r\n```", "Hi, I have the same problem. I trained the SSD MobileNet V2 FPNLite 320x320 model, converted it to tflite and after I try to give it a batch of images allocate_tensors() returns an error num_input_elements! = num_output_elements. From the above I understand that I need to re-convert my TF2 model to tflight and I need to set the dynamic shape during conversion. I use tf_nightley (version 2.5.0-dev20201107)for training and conversion, I think I can set the shape using concrete_func .inputs [0] .set_shape ([None, 320, 320, 3]). Here is my code for conversion:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nmodel = tf.saved_model.load(\"saved_model/\")\r\nconcrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\nconcrete_func.inputs[0].set_shape([None, 320, 320, 3])\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func]) \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n\r\nwith open('batch_q_model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\nThe conversion code is executed without error but in the end I get  464 byte tflite model. I think it's too little even for tflight. Where am I wrong? Thank you.\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "> Hi, I have the same problem. I trained the SSD MobileNet V2 FPNLite 320x320 model, converted it to tflite and after I try to give it a batch of images allocate_tensors() returns an error num_input_elements! = num_output_elements. From the above I understand that I need to re-convert my TF2 model to tflight and I need to set the dynamic shape during conversion. I use tf_nightley (version 2.5.0-dev20201107)for training and conversion, I think I can set the shape using concrete_func .inputs [0] .set_shape ([None, 320, 320, 3]). Here is my code for conversion:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> import numpy as np\r\n> \r\n> model = tf.saved_model.load(\"saved_model/\")\r\n> concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n> concrete_func.inputs[0].set_shape([None, 320, 320, 3])\r\n> converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func]) \r\n> converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n> tflite_model = converter.convert()\r\n> \r\n> with open('batch_q_model.tflite', 'wb') as f:\r\n>   f.write(tflite_model)\r\n> ```\r\n> \r\n> The conversion code is executed without error but in the end I get 464 byte tflite model. I think it's too little even for tflight. Where am I wrong? Thank you.\r\n\r\nHi @asimeonovMLPS \r\nIs your model working well in mobile app?", "@Siddhijain16 Just checking if you tried [this guide](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md) for converting SSD models?", "Yes I tried this [notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb) mention in that guide.", "Do you want all the COCO classes, or have you retrained the model for your dataset?", "I want to retrained the model for my own custom classes", "I see. Did you get the trained model from the notebook? If yes, what error do you see when running it on Java/Android?", "Just have a look \r\nhttps://github.com/tensorflow/models/issues/9694#issuecomment-770725095", "Hi @Siddhijain16 , I never converted the model, once I found out that the SSD is not optimized for batch inference, I stopped trying to resize the input to increase the batch size.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38158\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38158\">No</a>\n"]}, {"number": 38157, "title": "TF Lite build missing .lib", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: NA\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): msvc 142 (vs2019)\r\n- CUDA/cuDNN version: 10 / 7\r\n- GPU model and memory: GTX 1080\r\n\r\n\r\n\r\n**Describe the problem**\r\nTrying to build Tensorflow ( lite only ) with bazel in windows using the provide rule\r\n```c++\r\ntflite_cc_shared_object(\r\n    name = \"tensorflowlite\",\r\n...\r\n)\r\n```\r\nThere are many outputs and the tensorflowlite.dll. Yet there aint the corresponding tensorflowlite.lib ? Where can I find it or special configuration is needed ? \r\n\r\nThe partial output log for compilation\r\n\r\n```cmd\r\nINFO: From Linking tensorflow/lite/tensorflowlite.dll:\r\nLINK : warning LNK4044: unrecognized option '/s'; ignored\r\n   Creating library bazel-out/x64_windows-opt/bin/tensorflow/lite/libtensorflowlite.dll.ifso and object bazel-out/x64_windows-opt/bin/tensorflow/lite/libtensorflowlite.dll.exp\r\nTarget //tensorflow/lite:tensorflowlite up-to-date:\r\n  bazel-bin/tensorflow/lite/tensorflowlite.dll\r\nINFO: Elapsed time: 112.240s, Critical Path: 50.53s\r\nINFO: 308 processes: 308 local.\r\nINFO: Build completed successfully, 440 total actions\r\n\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nSince the missing .lib, simple code will give unresolved external symbol link error. E.g.\r\n```c++\r\n#include <c_api.h>\r\n#include <iostream>\r\n\r\nint main(int argc, char *argv[])\r\n{\r\n  std::cout << TfLiteVersion() << std::endl;\r\n  return 0;\r\n}\r\n```\r\nWhich gives\r\n\r\n``error LNK2019: unresolved external symbol __imp_TfLiteVersion``\r\n\r\n-----------------------------------------------\r\n\r\n\r\n**Any other info / logs**\r\n--------------------------------------------\r\n![image](https://user-images.githubusercontent.com/56542376/78237947-92234b80-750e-11ea-88fe-1f39af92b8d8.png)\r\n", "comments": ["What's the compile command you used for the sample?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38157\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38157\">No</a>\n", "![image](https://user-images.githubusercontent.com/23637856/87774869-bf92cb80-c857-11ea-9f62-b1ee135688b2.png)\r\nI got tensorflowlite.dll(17M), no lib file"]}, {"number": 38156, "title": "TFLM: add run-time check that statically allocated buffers are sufficiently large", "body": "It would be great to have a simple run-time check that the statically allocated buffer is sufficient.\r\n\r\nThis is as simple as adding one line:\r\n```\r\nTFLITE_DCHECK_LE(output_channels, kMaxChannels);\r\n```\r\nafter this one:\r\nhttps://github.com/tensorflow/tensorflow/blob/83e974b61c7b65ee8de87774addf1a0dc6b24c9a/tensorflow/lite/micro/kernels/conv.cc#L99\r\n", "comments": ["There is no reference to above code in current version here https://github.com/tensorflow/tflite-micro ,I will be closing this issue as the tflite-mirco repo is now separate and further issues should be opened there. Thank you."]}, {"number": 38155, "title": "tf.keras.Model subclassing: when check inputs size inside the model, the size display \"batch number\" as None", "body": "Hello. I am new to deep learning with the tf2.0 . And I am currently working on the cifar 10 dataset. \r\nRecently I encounter a problem with the model subclassing. The sample code is given as \r\n\r\n1. assign inputs from the processing, the batch size is [500, 32, 32, 3] with channel_last format. So each batch has 500 images. \r\n2. define a CNN model\r\n```\r\nclass CNN(tf.keras.Model)\r\n        def __init__(self):\r\n            super(CNN, self).__init__()\r\n            self.conv1 = layers.conv2d(......)\r\n            # and other layers definition\r\n         def call(self, inputs):\r\n             # here i try to test the size of inputs, using tf.shape(inputs) and inputs.shape()\r\n             # however, tf.shape returns (4,) and inputs.shape returns [None, 32, 32, 3]\r\n             #    I don't know why. The inputs should be 500 images. \r\n              #   And it looks like it only contains one image. \r\n```\r\n3. I call the model, such as \r\n``` \r\nmodel = CNN()\r\ny = model.predict(inputs)\r\n```\r\n\r\nThe sample codes are stated above. \r\nThe problem is i cannot input 500 images all in once to the model subclassing. I do not quite sure what is wrong with it. I tried the \"def build(self, input_shapes)\" as listed on the doc to define the input_shapes as [500, 32, 32, 3] but it still fails. I found a similar issue #36991. In one discussion, someone says \"then use batch number = 1\". But i would like to know if there is anyway to fix my code so that i can feed mini batch into the model. \r\nThe full code is below. When you run this code, there will be errors. But I simply would like to address the issue with the batch number dimension. Since if the \"inputs\" inside the model does not have that dimension, i cannot do the 500 images flatten process. \r\nThank you ~~\r\n```\r\n# for github issue use\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.datasets import cifar10\r\n\r\n\r\nif __name__ == '__main__':\r\n    (x_train, y_train), (x_label, y_label) = cifar10.load_data()\r\n    x_train = x_train.astype(np.float32)\r\n\r\n    class CNN(tf.keras.Model):\r\n        def __init__(self):\r\n            super(CNN, self).__init__()\r\n\r\n            self.conv1 = layers.Conv2D(\r\n                filters=32,\r\n                kernel_size=[5, 5],\r\n                strides=(1, 1),\r\n                padding='same',\r\n                activation=tf.nn.relu,\r\n                kernel_initializer=tf.random_normal_initializer(\r\n                    mean=0.0, stddev=0.01\r\n                ),\r\n                bias_initializer=tf.zeros_initializer(),\r\n                data_format='channels_last'\r\n            )\r\n            # the above output is [n, 32, 32, 32]\r\n            # from the book, the channel number 3 disappears after process\r\n            # \u6c60\u5316\u8f93\u51fa\u5927\u5c0f=[\uff08\u8f93\u5165\u5927\u5c0f-\u5377\u79ef\u6838\uff08\u8fc7\u6ee4\u5668\uff09\u5927\u5c0f\uff09\uff0f\u6b65\u957f]+1\r\n\r\n            self.pool1 = layers.MaxPool2D(\r\n                pool_size=[3, 3], strides=2,\r\n                data_format='channels_last',\r\n                padding='VALID'\r\n            )\r\n            # the output above is [n, 15, 15, 64]\r\n\r\n            # self.lrn1 = LRNLayer(\r\n            #     depth_radius=5,\r\n            #     bias=1,\r\n            #     alpha=1,\r\n            #     beta=0.5\r\n            # )\r\n            # during class call, add the lrn layer, output size not change\r\n\r\n            self.conv2 = layers.Conv2D(\r\n                filters=64,\r\n                kernel_size=[5, 5],\r\n                strides=(1,1),\r\n                kernel_initializer=tf.random_normal_initializer(\r\n                    mean=0, stddev=0.01\r\n                ),\r\n                bias_initializer=tf.zeros_initializer(),\r\n                padding='same',\r\n                activation=tf.nn.relu,\r\n                data_format='channels_last'\r\n            )\r\n            # padding = same, so output is [n, 15, 15, 64]\r\n            # self.lrn2 = LRNLayer(\r\n            #     depth_radius=5,\r\n            #     bias=1,\r\n            #     alpha=1,\r\n            #     beta=0.5\r\n            # )\r\n\r\n            self.pool2 = layers.MaxPool2D(\r\n                pool_size=[3, 3], strides=2,\r\n                data_format='channels_last',\r\n                padding=\"VALID\"\r\n            )\r\n            # output size = [N, 7, 7, 64]\r\n\r\n            # self.flatten = layers.Reshape(target_shape=(-1, 7*7*64))\r\n\r\n            self.dense1 = layers.Dense(\r\n                units=784,\r\n                activation=tf.nn.relu,\r\n                kernel_initializer=tf.random_normal_initializer(\r\n                    mean=0.0, stddev=0.05\r\n                ),\r\n                bias_initializer=tf.zeros_initializer()\r\n            )\r\n            # output is [n, 784]\r\n            self.batchNorm = layers.BatchNormalization()\r\n\r\n            self.dense2 = layers.Dense(\r\n                units=10,\r\n                activation=tf.nn.relu,\r\n                kernel_initializer=tf.random_normal_initializer(\r\n                    mean=0.0, stddev=0.05\r\n                ),\r\n                bias_initializer=tf.zeros_initializer()\r\n            )\r\n            # output is 10\r\n\r\n        # def build(self, input_shape):\r\n        #         #     super(CNN, self).build(input_shape)\r\n\r\n        def call(self, inputs):\r\n            # print(inputs[0, ::])\r\n            print(\"here inside the model\")\r\n            print(\"inputs.shape = {}\".format(inputs.shape)) # (None, 32, 32, 3)\r\n            print(\"tf.shape = {}\".format(tf.shape(inputs)))\r\n            print(\"type(inputs) = {}\".format(type(inputs)))\r\n\r\n\r\n            x = self.conv1(inputs) # (None, 32, 32, 32)\r\n            print(\"x.shape = {}\".format(x.shape))\r\n            print(\"tf.shape = {}\".format(tf.shape(x)))\r\n\r\n            # not useful for this issue.\r\n            # x = self.pool1(x)\r\n            # # x = self.lrn1(x)\r\n            # x = self.conv2(x)\r\n            # # x = self.lrn2(x)\r\n            # x = self.pool2(x)\r\n            # x = tf.reshape(tensor=x, shape=(x.shape[0], -1))\r\n            # x = self.dense1(x)\r\n            # x = self.batchNorm(x)\r\n            # x = self.dense2(x)\r\n            # y = tf.nn.softmax(x)\r\n\r\n            return y\r\n\r\n\r\n    iteration = 500\r\n    batch_size = 500\r\n    learning_rate = 0.001\r\n\r\n    model = CNN()\r\n    # model.build(input_shape=(None, 32, 32, 3))\r\n    # # print(model.conv1.input_spec())\r\n\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n\r\n    print(\"Here try to predict\")\r\n    y = model.predict(x_train[:500, ::])\r\n\r\n    # for i in range(iteration + 1):\r\n    #     batch = batch(train, batch_size)\r\n    #\r\n    #     print(batch.data.shape, batch.label.shape) # (500, 32, 32, 3) (500,)\r\n    #     print(type(batch.data))\r\n    #\r\n    #    # get some accuracy to examine\r\n    #     if i % 100 == 0:\r\n    #         batch_predict = model.predict(batch.data)\r\n    #         test_predict = model.predict(test.data)\r\n    #\r\n    #         acc_train = accuracy(\r\n    #             prediction=batch_predict, label=batch.label\r\n    #         )\r\n    #\r\n    #         acc_test = accuracy(\r\n    #             prediction=test_predict, label=test.label\r\n    #         )\r\n    #\r\n    #         train_acc_list.append(acc_train)\r\n    #         test_acc_list.append(acc_test)\r\n    #\r\n    #         print(\"Iter {} of {}: train_acc={}, test_acc={}\".format(i, iteration, acc_train, acc_test))\r\n    #\r\n    #     # now do the training\r\n    #     with tf.GradientTape() as tape:\r\n    #         batch_predict = model(batch.data)\r\n    #         loss = tf.keras.losses.sparse_categorical_crossentropy(\r\n    #             y_pred=batch_predict, y_true=batch.label\r\n    #         )\r\n    #         loss = tf.reduce_mean(loss)\r\n    #\r\n    #     train_loss_list.append(loss)\r\n    #\r\n    #     grads = tape.gradient(loss, model.variables)\r\n    #     optimizer.apply_gradients(\r\n    #         grads_and_vars=zip(grads, model.variables)\r\n    #     )\r\n```", "comments": ["In the last part of my statement, i do not mean \"I cannot do the 500 images flatten process\". I mean i would like to input 500 images at once so that to achieve a mini batch process. Thank you.  ", "Although the model is not trained before i call the \"predict\", i would like to address the batch dimension appears as None in this issue. Thank you ~~", "Hello. I would like to present a simpler code for this issue. \r\n```\r\n# for github issue use\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\nif __name__ == '__main__':\r\n\r\n    class CNN2(tf.keras.Model):\r\n        def __init__(self):\r\n            super(CNN2, self).__init__()\r\n            print(\"initialized successfully\")\r\n\r\n        def build(self, input_shape):\r\n            super(CNN2, self).build(input_shape)\r\n\r\n        def call(self, inputs):\r\n            # print(inputs[0, ::])\r\n            print(\"here inside the model\")\r\n            print(\"inputs.shape = {}\".format(inputs.shape)) # (None, 32, 32, 3)\r\n            print(\"tf.shape = {}\".format(tf.shape(inputs)))\r\n            print(\"type(inputs) = {}\".format(type(inputs)))\r\n\r\n            # just return something\r\n            return inputs\r\n\r\n\r\n\r\n    model = CNN2()\r\n    model.build(input_shape=(500, 32, 32, 3))\r\n    # # print(model.conv1.input_spec())\r\n\r\n    print(\"Here try to predict\")\r\n    var = tf.zeros(shape=[500, 32, 32, 3])\r\n    print(var[0, 0, 0, :])\r\n    y = model.predict(var)\r\n```\r\n\r\nSo the problem is when the model is called, it prints that \r\n```\r\ninputs.shape = (None, 32, 32, 3)\r\n```\r\nwhich is very strange as i actually put a 500 in the first dim. \r\nThank you. ~~", "Hello. I found that, if i use \r\n```\r\ny = model(x) \r\n```\r\nto train the model, everything works fine. The shape of \"inputs\" inside the model is [500, 32, 32, 3].\r\nBut if i use \r\n```\r\ny = model.predict(x)\r\n```\r\nx does not support for batch input. If i input a whole batch of 500 images, inside the model it only has shape [None, 32, 32, 3]. How to fix for batch input? Do i have to input all images one by one for prediction? \r\nThank you and looking forward for your help~~", "@luke-mao, Keras functional model allows to input in batch size. Set the batch size accordingly. Please refer the Tensorflow [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=nightly#predict) for more. Thanks!", "That's wonderful. Thank you a lot. Now my model is up and running!! Thank you for the help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38155\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38155\">No</a>\n"]}, {"number": 38154, "title": "Add 6 layers of Octave Convolutions to tensorflow keras layers (issue author's implementation)", "body": "Hi,\r\nThis pull request is an implementation of issue #37576 I'm the author of.\r\nI implemented 7 classes of Octave Convolutions: 1 abstract OctaveConv layer, 5 octave convolution layers (OctaveConv1D, OctaveConv2D, OctaveConv3D, OctaveConv2DTranspose, OctaveConv3DTranspose) and 1 OctaveConvAdd class to add the octave convolution layers.\r\nThe reference paper and description of these features are given in the issue (#37576 ) so I invite you to look at it.\r\nI also attached a python file to give you an example usage of OctaveConv2D, OctaveConv2DTranspose and OctaveConvAdd on the MNIST dataset.\r\n\r\nPS. Pull request #38052 was opened a few days ago by another developer to fix the issue but it is incomplete (only 2 layers of octave convolutions) and has some bugs (for instance, setting the trainable attribute of the octave convolution layers won't freeze the weights) so I invite you to look at this pull request instead.\r\n\r\n[AchilleMascia_mnist_octconv2D_2DTranspose.zip](https://github.com/tensorflow/tensorflow/files/4419653/AchilleMascia_mnist_octconv2D_2DTranspose.zip)\r\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38154) for more info**.\n\n<!-- need_author_cla -->", "@AchilleMascia Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I fixed it, it is signed. Waiting for the corporate CLA to be processed.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38154) for more info**.\n\n<!-- ok -->", "Thanks for the contribution.\r\n\r\nBefore we dive into details, I would like to have @fchollet as API owner to see if this is a good fit for the core Keras API. You might also want to check with tf-addons repository and it might be a better fit for this new extension.", "Thank you for your feedback, I'll go along with whatever you think is the most appropriate for this feature.", "I believe it's better for it to go in Addons first. If we see a very wide adoption, we can migrate it to core. I suggest closing this pull request and follow up at https://github.com/tensorflow/addons/pull/1782 ", "Thanks Gabriel. Closing this PR for now and will follow up in addons."]}, {"number": 38153, "title": "[tf.data] _pywrap_server_lib.so breaks nightly packages", "body": "Our in-house nightly builds were broken since 2020-03-31 when auditwheel tries to repair the nightly packages. The reason under the hood seems to be an incorrect link from the recent change of adding tf.data service support in 0b63458060d7f8400c7e5b37ccdd7ca89c2ffbe1 and enabled in nightly packages in 503179f662708e730fd0a0c98261e9678975e3b8.\r\n\r\nInstall the latest nightly, and check the dynamic linker:\r\n\r\n```\r\n$ ldd /usr/local/lib/python3.8/dist-packages/tensorflow/core/data/service/python/_pywrap_server_lib.so\r\n\tlinux-vdso.so.1 (0x00007ffd621f4000)\r\n\tlibtensorflow_framework.so.2 => /usr/local/lib/python3.8/dist-packages/tensorflow/core/data/service/python/../../../../libtensorflow_framework.so.2 (0x00007fda32b70000)\r\n\t_pywrap_tensorflow_internal.so => not found\r\n\tlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fda32b5a000)\r\n\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fda32b39000)\r\n\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fda329f2000)\r\n\tlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007fda32825000)\r\n\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fda3280b000)\r\n\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fda32648000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x00007fda34bfd000)\r\n\tlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fda3263d000)\r\n```\r\n\r\nObviously it links to `_pywrap_tensorflow_internal.so` but it is not found with the relative path.\r\n\r\nPS: we are using `auditwheel==3.0.0` to produce manylinux2014 builds, but the official tf-nightly uses an older version which fails to catch this.\r\n\r\nPing @aaudiber @mihaimaruseac. We had met a similar issue in #36067. As mentioned there, the reason seems to be that ``tf_python_pybind_extension`` should only be used for packages in ``//tensorflow/python/...`` but it is used in ``//tensorflow/core/..``  in this case.\r\n\r\nAny idea how to avoid this in the future? Also cc @av8ramit.", "comments": ["Thank you @byronyi for investigating this. I just put out a CL to move the usage of `tf_python_pybind_extension` under `//tensorflow/python`. I will validate the fix and merge it as soon as possible.", "@aaudiber Thanks for the prompt fix! Can't wait to try out tf.data service :)", "This should be fixed by 8434a67458fe52ffb9f978960bc81e2396ad76d3. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38153\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38153\">No</a>\n"]}, {"number": 38152, "title": "Java SavedModelBundle import LookupTable core dump", "body": "I use `libtensorflow.jar` to load a model with `saved_model` format. The core dump occurs in `LookupTableImportOp` computation stage. However, this model could be loaded successfully via `c++ tensoflow-serving executable` or `python tf.saved_model.loader`.\r\n\r\n* tensorflow 1.12.\r\n* mac os. cpu only.\r\n\r\n```\r\npublic static void main(String[] args) {\r\n    System.out.println(TensorFlow.version());\r\n    SavedModelBundle b = SavedModelBundle.load(\"./model/\", \"serve\");\r\n    b.close();\r\n}\r\n```\r\n\r\nError message:\r\n```\r\n1.12.0\r\n2020-04-02 12:09:07.285904: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: ./model/\r\n2020-04-02 12:09:07.295754: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n2020-04-02 12:09:07.342467: I tensorflow/cc/saved_model/loader.cc:162] Restoring SavedModel bundle.\r\n[thread 23555 also had an error][thread 42243 also had an error]#\r\n\r\n# A fatal error has been detected by the Java Runtime Environment:\r\n#\r\n#  SIGSEGV\r\n (0xb) at pc=0x00000001163dec0e[thread 23299 also had an error], pid=93091\r\n, tid=0x000000000000a103[thread 41475 also had an error]\r\n\r\n#\r\n[thread 41731 also had an error]# JRE version: Java(TM) SE Runtime Environment (8.0_201-b09) (build 1.8.0_201-b09)\r\n[thread 42499 also had an error]\r\n\r\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.201-b09 mixed mode bsd-amd64 compressed oops)\r\n# Problematic frame:\r\n# C  [libtensorflow_framework.so+0x44c0e]  tensorflow::lookup::LookupInterface::CheckKeyAndValueTensorsHelper(tensorflow::Tensor const&, tensorflow::Tensor const&)+0x6e\r\n#\r\n# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n\r\n```\r\n\r\nStack message:\r\n```\r\nStack: [0x000070000e240000,0x000070000e2c0000],  sp=0x000070000e2bf4b0,  free space=509k\r\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\r\nC  [libtensorflow_framework.so+0x44c0e]  tensorflow::lookup::LookupInterface::CheckKeyAndValueTensorsHelper(tensorflow::Tensor const&, tensorflow::Tensor const&)+0x6e\r\nC  [libtensorflow_framework.so+0x44e2e]  tensorflow::lookup::LookupInterface::CheckKeyAndValueTensorsForImport(tensorflow::Tensor const&, tensorflow::Tensor const&)+0xe\r\nC  [libtensorflow_jni.dylib+0x10454e0]  tensorflow::LookupTableImportOp::Compute(tensorflow::OpKernelContext*)+0x140\r\nC  [libtensorflow_framework.so+0x23b362]  tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)+0x1f12\r\nC  [libtensorflow_framework.so+0x2434ba]  std::__1::__function::__func<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&>, std::__1::allocator<std::__1::__bind<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long), tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode const&, long long&> >, void ()>::operator()()+0x3a\r\nC  [libtensorflow_framework.so+0x29c58f]  Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)+0x54f\r\nC  [libtensorflow_framework.so+0x29bf3f]  std::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()()+0x2f\r\nC  [libtensorflow_framework.so+0x2c0990]  void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*)+0x30\r\nC  [libsystem_pthread.dylib+0x3305]  _pthread_body+0x7e\r\nC  [libsystem_pthread.dylib+0x626f]  _pthread_start+0x46\r\nC  [libsystem_pthread.dylib+0x2415]  thread_start+0xd\r\n\r\n```", "comments": ["fixed", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38152\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38152\">No</a>\n", "Recently, I also meet with this problem. I load my pb model in java and build with maven. But when I execute my jar file, it would  throw core dump error about jvm.\r\n\r\nHow does you figure out this problem? @ formath", "@cgpeter96 For me the reason is that `libtensorflow_framework.so` is not matched between training and prediction.", "@formath \r\nIs this still an issue"]}, {"number": 38151, "title": "Test deterministic cuDNN CTC loss", "body": "@sanjoy added deterministic cuDNN CTC loss, enabled via `TF_DETERMINISTIC_OPS`, with [this commit](https://github.com/tensorflow/tensorflow/commit/9e096debc4a0909deb69970f38bee7b77e5e5f7d). This issue is a reminder to add test for it in [tensorflow/python/kernel_tests/cudnn_deterministic_base.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/cudnn_deterministic_base.py).\r\n\r\nThis issue is a replacement for PR [38089](https://github.com/tensorflow/tensorflow/pull/38089).", "comments": ["Please will someone with the authority assign this issue to me?", "@duncanriach \r\n\r\nAny update on this issue please. Thanks!\r\n", "@ravikyram no update. I have not yet gotten to this.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Still on my radar. Please keep this open.", "This issue is closed by PR [52227](https://github.com/tensorflow/tensorflow/pull/52227)."]}, {"number": 38150, "title": "Extra metric added to model.metrics in TF 2.2", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nUbuntu 18.04 (running on Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nRunning on Colab\r\n- TensorFlow version (use command below): \r\n2.2.0-rc2\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\nRunning on Colab\r\n- GCC/Compiler version (if compiling from source): \r\nRunning on Colab\r\n- CUDA/cuDNN version:\r\nNo GPU\r\n- GPU model and memory:\r\nNo GPU\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I compile my model with `model.compile(..., metrics=[\"mae\"])` I end up with an extra metric in the first position. This breaks my existing code (for example when accessing `model.metrics[0]`, now I get another metric than the one that was excepted).\r\n\r\n**Describe the expected behavior**\r\n\r\nWhen I compile the model with N metrics, I expect `model.metrics` to return a list with N metrics, not 1+N.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nYou can run the following code in [this colab](https://colab.research.google.com/drive/1yKy-TC5PyE6ImQemE89SDSiQkFniXIcb).\r\n\r\n```python\r\nimport numpy as np\r\nfrom tensorflow import keras\r\n\r\nX_train = np.random.rand(100, 10)\r\ny_train = np.random.rand(100, 1)\r\n\r\nmodel = keras.models.Sequential([\r\n    keras.layers.Dense(2, activation=\"relu\", input_shape=[10]),\r\n    keras.layers.Dense(1)\r\n])\r\nmodel.compile(loss=\"mse\", optimizer=\"sgd\", metrics=[\"mae\", \"mse\"])\r\nmodel.fit(X_train, y_train, epochs=2)\r\n\r\nassert len(model.metrics) == 2\r\n```\r\n\r\nThe assertion fails.\r\n\r\n**Other info / logs**\r\n\r\nThis may be related to issue #37990 , but it feels more severe.\r\n\r\nThere's another behavior change that really confuses me: the `model.metrics` list is empty until `model.fit()` is called.\r\n\r\nIn short, `model.metrics` seems really broken and unintuitive now.\r\n", "comments": ["@ageron, I think there is always one matrix corresponding to loss and there will extra as many as arguments passed in `metrics`.\r\nYou can check their names with `model.metrics_names`.\r\nIn your example there will be three metrics first for `loss`, second for `mae` and third for `mse`.\r\nHope it helps you.", "Was able to reproduce the issue. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/d7806dd77e70c4bb2dcaa00914f11012/38150.ipynb). Thanks!", "The refactor breaks strike again...\r\n\r\nGood luck.", "@ageron This was an intended change which was part of a refactor as @briannemsick mentioned. I have updated the docs for metrics in https://github.com/tensorflow/tensorflow/commit/a822fa93da3f8e2484df2d030ddbef24b06cbe07\r\n\r\nModel loss and output losses are now tracked as part of metrics. Earlier metrics_names included model loss and output losses but the metrics property did not. Now they are consistent.\r\n\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38150\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38150\">No</a>\n"]}, {"number": 38149, "title": "test", "body": "Traceback (most recent call last):\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\nreturn _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile \"generate_tfrecord.py\", line 17, in\r\nimport tensorflow as tf\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_init_.py\", line 41, in\r\nfrom tensorflow.python.tools import module_util as module_util\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python_init.py\", line 50, in\r\nfrom tensorflow.python import pywrap_tensorflow\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in\r\nraise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\nreturn _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38149\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38149\">No</a>\n"]}, {"number": 38148, "title": "test ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38148\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38148\">No</a>\n"]}, {"number": 38147, "title": "`tf_http_archive` in RC breaks with Bazel 2.2.0", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18 (https://hub.docker.com/r/dmadisetti/nvidia-ibazel)\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: tensorflow-2.2.0-rc2\r\n- Bazel version (if compiling from source): 2.2.0\r\n- GCC/Compiler version (if compiling from source): clang-9\r\n- CUDA/cuDNN version: 10.1\r\n\r\n\r\n**Describe the problem**\r\n\r\nTensorflow will not compile as an external repositiory, as `tf_http_repository` fails on sourcing other libraries. I investigated a little but want to post here.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nIn my WORKSPACE\r\n```starlark\r\nhttp_archive(\r\n    name = \"org_tensorflow\",\r\n    strip_prefix = \"tensorflow-2.2.0-rc2\",\r\n    sha256 = \"3e0cffc98ad3767dd16a09b7f25a99961e21d65cfcad67ed3a9b1a01318c7e94\",\r\n    urls = [\"https://github.com/tensorflow/tensorflow/archive/v2.2.0-rc2.tar.gz\"],\r\n)\r\n```\r\n\r\nAttempting to run a test from my workspace, and no cache (or .bazelrc):\r\n`bazel  test --experimental_repo_remote_exec repo/cc:all repo/python:all`\r\n\r\nYields:\r\n```\r\nStarting local Bazel server and connecting to it...\r\nERROR: /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/tensorflow/workspace.bzl:653:5: no such target '@org_tensorflow//third_party:zlib.BUILD': target 'zlib.BUILD' not declared in package 'third_party'; however, a source file of this name exists.  (Perhaps add 'exports_files([\"zlib.BUILD\"])' to third_party/BUILD?) defined by /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/third_party/BUILD and referenced by '//external:zlib'\r\nERROR: /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/tensorflow/workspace.bzl:653:5: no such target '@org_tensorflow//third_party/systemlibs:zlib.BUILD': target 'zlib.BUILD' not declared in package 'third_party/systemlibs'; however, a source file of this name exists.  (Perhaps add 'exports_files([\"zlib.BUILD\"])' to third_party/systemlibs/BUILD?) defined by /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/third_party/systemlibs/BUILD and referenced by '//external:zlib'\r\n```\r\n\r\nCool, cool. So I added `export_files(glob([\"*.BUILD\"]))` to `third_party/systemlibs/BUILD` and `third_party/BUILD` which gives me:\r\n\r\n```\r\nStarting local Bazel server and connecting to it...\r\nERROR: /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/tensorflow/workspace.bzl:653:5: in build_file attribute of tf_http_archive rule //external:zlib: source file '@org_tensorflow//third_party:zlib.BUILD' is misplaced here (expected no files)\r\nERROR: /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/tensorflow/workspace.bzl:653:5: in system_build_file attribute of tf_http_archive rule //external:zlib: source file '@org_tensorflow//third_party/systemlibs:zlib.BUILD' is misplaced here (expected no files)\r\nINFO: Call stack for the definition of repository 'remotejdk11_linux' which is a http_archive (rule definition at /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/bazel_tools/tools/build_defs/repo/http.bzl:296:16):\r\n - <builtin>\r\n - /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/bazel_tools/tools/build_defs/repo/utils.bzl:201:9\r\n - /DEFAULT.WORKSPACE.SUFFIX:235:1\r\nERROR: Analysis of target '//repo/cc:cc_proto' failed; build aborted: Analysis of target '//external:zlib' failed; build aborted\r\n```\r\nMakes sense, `tf_http_archive` isn't set to allow source files. So I changed: `third_party/repo.bzl`, such that the attributes have the `allow_single_file` option.\r\n\r\n```starlark\r\ntf_http_archive = repository_rule(\r\n    attrs = {\r\n        \"sha256\": attr.string(mandatory = True),\r\n        \"urls\": attr.string_list(\r\n            mandatory = True,\r\n            allow_empty = False,\r\n        ),\r\n        \"strip_prefix\": attr.string(),\r\n        \"type\": attr.string(),\r\n        \"delete\": attr.string_list(),\r\n        \"patch_file\": attr.label(allow_single_file = True),\r\n        \"build_file\": attr.label(allow_single_file = True),\r\n        \"system_build_file\": attr.label(allow_single_file = True),\r\n        \"system_link_files\": attr.string_dict(),\r\n        \"additional_build_files\": attr.string_dict(),\r\n    },\r\n    environ = [\r\n        \"TF_SYSTEM_LIBS\",\r\n    ],\r\n    implementation = _tf_http_archive,\r\n)\r\n```\r\n\r\nBut I guess not? This yields:\r\n```\r\nStarting local Bazel server and connecting to it...\r\nERROR: /tmp/build_cache/_bazel_root/a08c2e4811c846650b733c6fc815a920/external/org_tensorflow/tensorflow/workspace.bzl:653:5: in tf_http_archive rule //external:zlib: Found reference to a workspace rule in a context where a build rule was expected; probably a reference to a target in that external repository, properly specified as @reponame//path/to/package:target, should have been specified by the requesting rule.\r\nERROR: Analysis of target '//repo/python:repo' failed; build aborted: Analysis of target '//external:zlib' failed; build aborted\r\nINFO: Elapsed time: 5.150s\r\nINFO: 0 processes.\r\n```\r\n\r\nAt this point I figure I'd just ask. tensorflow-2.1.0 works perfectly, except for a bug that I addressed here: https://github.com/tensorflow/tensorflow/pull/36830\r\n\r\n**Any other info / logs**\r\n\r\nDone in my docker container! So hopefully repeatable. Altered source in `bazel-workspace/external/org_tensorflow/` as a quick hack", "comments": ["Afaik, we haven't yet tested if our code builds with this version of Bazel. We only test with versions specified in `./configure.py`", "This might be more of using \"tensorflow as a bazel dep\" than a bazel version problem. I just tried building my project with the following commands:\r\n\r\n`env USE_BAZEL_VERSION=2.0.0 ~/go/bin/bazelisk test --experimental_repo_remote_exec repo/cc:all repo/python:all`\r\n`env USE_BAZEL_VERSION=2.1.0 ~/go/bin/bazelisk test --experimental_repo_remote_exec repo/cc:all repo/python:all`\r\n\r\nTo the same result. I believe usage the way I laid out is the recommended way for creating custom tf ops, and tf is also commonly used like this throughout a variety of open-source google projects and beyond.\r\n\r\nHowever, I just made a minimal example and it ran! It looks like there may be a conflict with my other deps and TF. Will investigate a bit more when I get some bandwidth, but the error still has me thinking it's still a TF problem. I'll publish the example and update here once I can reliably produce the bug.", "Cool! Finally had a chance to look at this. I have conflicting dependencies with zlib.\r\n\r\nIt looks like I'm using `zlib 1.2.11` across the board, so it makes me wonder if one of the build files diverged somewhere. I'm not sure why my setup worked with `2.1.0`, and I didn't go too far down the git blame rabbit hole.\r\n\r\nI went over the bazel docs and tried using a `repo_mapping` [as described here](https://docs.bazel.build/versions/master/external.html) to no avail. It looks like this may be a bug in `tf_http_archive`. Quick and dirty solution was to combine using `repo_mapping` with a check for the dependency before adding it:\r\n\r\nin `tensorflow/workspace.bzl`\r\n```starlark\r\n    if \"zlib\" not in native.existing_rules():\r\n        tf_http_archive(\r\n            name = \"zlib\",\r\n            ...\r\n        )\r\n```\r\n\r\nand in my WORKSPACE\r\n```starlark\r\nhttp_archive(\r\n    name = \"org_tensorflow\",\r\n    repo_mapping = {\"@zlib\": \"@_zlib\"},\r\n)\r\n```\r\n\r\nI'll close this out once I can come up with a nice solution. Best case: TF should respect `repo_mapping`, Worst case: A more informative error should be provided.\r\n\r\nThis might be more the fault of whatever dep I have than tf. I'll see if I can track it down. I have a hunch that it's (rules_proto)[https://github.com/stackb/rules_proto/blob/master/deps.bzl#L136]", "This should be solved now, afaik", "This seems to have stalled and afaik it  has been solved. Closing this but please reopen if the issue still manifest with the latest Bazel and a latest commit.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38147\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38147\">No</a>\n"]}, {"number": 38146, "title": "Test Squeeze op converter in dynamic shape mode", "body": "This PR adds tests for dynamic shape mode for TF-TRT ConvertSqueeze. \r\n\r\n- The BuildAndRun method is extended with a profile generation step.\r\n- ConvertSqueeze is refactored: all test use TestParams\r\n- All previous test in ConvertSqueeze run both in implicit and explicit batch mode\r\n- Added new dynamic shapes tests (those run only in explicit batch mode)\r\n\r\nPR #38118 is required for of this PR, please review that first. Tagging @bixia1 for review.", "comments": ["@tfeher Can you please check @bixia1 comments and keep us posted. Thanks!", "Thanks @bixia1 for the review. I am working on fixing the issues, I will update soon."]}, {"number": 38145, "title": "bug issue", "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 17, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\r\n\r\n* For TF-GPU - See point 1\r\n* For TF-CPU - See point 2\r\n\r\n-----------------------------------------------------------------------------------------------\r\n\r\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\r\n\r\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\r\n\r\n* If you have above configuration and using _**Windows**_ platform -\r\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\r\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\r\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\r\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\r\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\r\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\r\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\r\n\r\n-----------------------------------------------------------------------------------------------\r\n\r\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\r\n\r\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\r\n\r\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\r\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\r\n\r\n* Try Google Colab to use TensorFlow.\r\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\r\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\r\n  * All you need is a good internet connection and you are all set.\r\n* Try to build TF from sources by changing CPU optimization flags.\r\n\r\n*Please let us know if this helps.*", "@mekhaaa,\r\nCould you please check [this](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) comment on a similar issue and let us know if it helps. Thanks!\r\n", "i am creating tfrecords by running this command: \r\npython generate_tfrecord.py --csv_input=data\\train_labels.csv --image_dir=images\\train --output_path=train.record \r\nbut it didn't work\r\n", "@mekhaaa,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here along with the supporting files and also the TensorFlow version you are using.\r\n\r\nAlso, please check if you are able to run the below code snippet \r\n```\r\nimport tensorflow as tf\r\nfloating = tf.Variable(3.14159265359, tf.float64)\r\n```\r\n\r\nThanks!", "Any updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38145\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38145\">No</a>\n"]}, {"number": 38144, "title": "bug issue", "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 17, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>cd C:\\tensorflow1\\models\\research\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research>cd\\\r\n\r\n(tensorflow1) C:\\>set PYTHONPATH=C:\\tensorflow1\\models;C:\\tensorflow1\\models\\research;C:\\tensorflow1\\models\\research\\slim\r\n\r\n(tensorflow1) C:\\>set PATH=%PATH%;PYTHONPATH\r\n\r\n(tensorflow1) C:\\>\r\n\r\n(tensorflow1) C:\\>cd users\r\n\r\n(tensorflow1) C:\\Users>cd ahmed\r\n\r\n(tensorflow1) C:\\Users\\ahmed>cd documents\r\n\r\n(tensorflow1) C:\\Users\\ahmed\\Documents>set PYTHONPATH=C:\\tensorflow1\\models;C:\\tensorflow1\\models\\research;C:\\tensorflow1\\models\\research\\slim\r\n\r\n(tensorflow1) C:\\Users\\ahmed\\Documents>set PATH=%PATH%;PYTHONPATH\r\n\r\n(tensorflow1) C:\\Users\\ahmed\\Documents>echo %PYTHONPATH%\r\nC:\\tensorflow1\\models;C:\\tensorflow1\\models\\research;C:\\tensorflow1\\models\\research\\slim\r\n\r\n(tensorflow1) C:\\Users\\ahmed\\Documents>python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record\r\npython: can't open file 'generate_tfrecord.py': [Errno 2] No such file or directory\r\n\r\n(tensorflow1) C:\\Users\\ahmed\\Documents>cd object_detection\r\nThe system cannot find the path specified.\r\n\r\n(tensorflow1) C:\\Users\\ahmed\\Documents> cd C:\\tensorflow1\\models\\research\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research>cd object_detetction\r\nThe system cannot find the path specified.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research>cd object_detetcation\r\nThe system cannot find the path specified.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research>cd object_deteaction\r\nThe system cannot find the path specified.\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research>cd object_detection\r\n\r\n(tensorflow1) C:\\tensorflow1\\models\\research\\object_detection>python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 17, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\ahmed\\miniconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38144\">No</a>\n"]}, {"number": 38143, "title": "WideDeepModel cannot be serialized with tf.saved_model.save", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  No\r\n[I used an example script, then tried to save it]\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source): v2.1.0-rc2-17-ge5bf8de \r\n- GCC/Compiler version (if compiling from\r\nsource):  N/A\r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nSerialization fails, apparently because optimizer is a list, rather than a single optimizer.\r\n\r\n**Describe the expected behavior**\r\nSerialization works.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\n\r\nlinear_model = tf.keras.experimental.LinearModel()\r\nlinear_model.compile('adagrad', 'mse')\r\ndnn_model = tf.keras.Sequential([tf.keras.layers.Dense(units=1)])\r\ndnn_model.compile('rmsprop', 'mse')\r\ncombined_model = tf.keras.experimental.WideDeepModel(dnn_model, linear_model)\r\ncombined_model.compile(optimizer=['adagrad', 'rmsprop'], loss='mse')\r\ntf.saved_model.save(combined_model, \"/tmp/saved_model\")\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-10-15923fe78379> in <module>\r\n      7 combined_model = tf.keras.experimental.WideDeepModel(dnn_model, linear_model)\r\n      8 combined_model.compile(optimizer=['adagrad', 'rmsprop'], loss='mse')\r\n----> 9 tf.saved_model.save(combined_model, \"/tmp/saved_model\")\r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)\r\n    921       compat.as_str(constants.SAVED_MODEL_FILENAME_PB))\r\n    922   object_graph_proto = _serialize_object_graph(\r\n--> 923       saveable_view, asset_info.asset_index)\r\n    924   meta_graph_def.object_graph_def.CopyFrom(object_graph_proto)\r\n    925 \r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py in _serialize_object_graph(saveable_view, asset_file_def_index)\r\n    651 \r\n    652   for obj, obj_proto in zip(saveable_view.nodes, proto.nodes):\r\n--> 653     _write_object_proto(obj, obj_proto, asset_file_def_index)\r\n    654   return proto\r\n    655 \r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py in _write_object_proto(obj, proto, asset_file_def_index)\r\n    690           version=versions_pb2.VersionDef(\r\n    691               producer=1, min_consumer=1, bad_consumers=[]),\r\n--> 692           metadata=obj._tracking_metadata)\r\n    693       # pylint:enable=protected-access\r\n    694     proto.user_object.CopyFrom(registered_type_proto)\r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _tracking_metadata(self)\r\n   2410   @property\r\n   2411   def _tracking_metadata(self):\r\n-> 2412     return self._trackable_saved_model_saver.tracking_metadata\r\n   2413 \r\n   2414   def _list_extra_dependencies_for_serialization(self, serialization_cache):\r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py in tracking_metadata(self)\r\n     55     # object is in the python property)\r\n     56     return json.dumps(\r\n---> 57         self.python_properties,\r\n     58         default=serialization.get_json_type)\r\n     59 \r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py in python_properties(self)\r\n     38   def python_properties(self):\r\n     39     # TODO(kathywu): Add python property validator\r\n---> 40     return self._python_properties_internal()\r\n     41 \r\n     42   def _python_properties_internal(self):\r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py in _python_properties_internal(self)\r\n     36     metadata.update(\r\n     37         saving_utils.model_metadata(\r\n---> 38             self.obj, include_optimizer=True, require_config=False))\r\n     39     return metadata\r\n     40 \r\n\r\n/pay/src/zoolander/vendor3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py in model_metadata(model, include_optimizer, require_config)\r\n    207         optimizer_config = {\r\n    208             'class_name': model.optimizer.__class__.__name__,\r\n--> 209             'config': model.optimizer.get_config()}\r\n    210       metadata['training_config']['optimizer_config'] = optimizer_config\r\n    211   return metadata\r\n```\r\n", "comments": ["@bmc2-stripe, you don't required to compile `combined_model` as you have already compiled individual model. and  I think you can't compile single model with two optimizer like you have done for `combined_model`. Correct code is:\r\n```\r\nimport tensorflow as tf\r\n\r\nlinear_model = tf.keras.experimental.LinearModel()\r\nlinear_model.compile('adagrad', 'mse')\r\ndnn_model = tf.keras.Sequential([tf.keras.layers.Dense(units=1)])\r\ndnn_model.compile('rmsprop', 'mse')\r\ncombined_model = tf.keras.experimental.WideDeepModel(dnn_model, linear_model)\r\ntf.saved_model.save(combined_model, \"/tmp/saved_model\")\r\n```", "@khimraj Thank you for the reply!\r\n\r\nYour snippet does work to serialize the model, but unfortunately compilation seems necessary to actually train the combined model. Note that in both examples in the WideDeepModel documentation, the combined model is compiled with two optimizers:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/WideDeepModel\r\n\r\nAdditionally, if I remove the compilation step from those tutorials, I get the following error:\r\n```\r\nRuntimeError: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\r\n```\r\n\r\nHere's a more complete reproducing example --- it's essentially just the second example from the WideDeepModel documentation, but fleshed out with a bit more boilerplate so that it can be executed:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nfeatures = np.random.uniform(size=[100, 50])\r\nlabels = np.random.uniform(size=[100])\r\n\r\nlinear_model = tf.keras.experimental.LinearModel()\r\nlinear_model.compile('adagrad', 'mse')\r\nlinear_model.fit(features, labels)\r\ndnn_model = tf.keras.Sequential([tf.keras.layers.Dense(units=1)])\r\ndnn_model.compile('rmsprop', 'mse')\r\ndnn_model.fit(features, labels)\r\ncombined_model = tf.keras.experimental.WideDeepModel(dnn_model, linear_model)\r\n# Uncomment the following line to test without compilation:\r\ncombined_model.compile(optimizer=['adagrad', 'rmsprop'], loss='mse')\r\ncombined_model.fit(features, labels)\r\ntf.saved_model.save(combined_model, \"/tmp/saved_model\")\r\n```\r\n\r\nThis example fails with the same error as in the original bug report.", "@bmc2-stripe, Yes you are correct. As given in WideDeepModel documentation, the combined model is compiled with two optimizers. I have tried to save model using `save_weights` and i have successfully saved it. For your reference link of gist is [here](https://gist.github.com/khimraj/63b9e4a7951647e1fde922b5b31b8495).", "> @bmc2-stripe, Yes you are correct. As given in WideDeepModel documentation, the combined model is compiled with two optimizers. I have tried to save model using `save_weights` and i have successfully saved it. For your reference link of gist is [here](https://gist.github.com/khimraj/63b9e4a7951647e1fde922b5b31b8495).\r\n\r\n@bmc2-stripe,\r\nCould you please check @khimraj's comment and let us know if it works? Thanks!", "Hi @amahendrakar:\r\n\r\nThe solution @khimraj provides does execute without error, but I don't believe it really solve the issue. Specifically, save_weights (which is used that solution) is great for checkpointing, but the tf.saved_model.save call is needed to get a model we can serve with TF Serving.\r\n\r\n", "Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/4347ee5de8bb96db02699a34aa42034d/38143-2-1.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/cb24acd1e718e5aba3cdfe2ba6848367/38143-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@bmc2-stripe I agree `tf.saved_model.save` has an issue in saving the `WideDeepModel` that has multiple optimizers added from compile. One approach is to delete optimizer from the model like  `combined_model.optimizer = []`, and then save the model `tf.saved_model.save(combined_model, \"./saved_model\")`\r\n\r\nLater If you want load the model and train, then you can load the model and then compile again  and train as follows\r\n```\r\nloaded_model = tf.keras.models.load_model('./saved_model')\r\n# compile the loaded model\r\nloaded_model.compile(optimizer=['adagrad','rmsprop'], loss=['mse','mse'])\r\n# restart training\r\nloaded_model.fit([features,features], labels,epochs=10)\r\n```\r\n\r\n[Here is the gist](https://colab.research.google.com/gist/jvishnuvardhan/34dbdb808d0737040d6397ad2df676aa/widedeepmodel.ipynb) for y/our reference. Thanks!", "@bmc2-stripe Can you verify once and close the issue if this was resolved for you. Thanks!", "I am closing this issue as I think it was resolved. But, please let me know if I'm mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38143\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38143\">No</a>\n", "Seems like a reasonable workaround, thanks"]}, {"number": 38142, "title": "Fix <unknown> shape issue for sparse.transpose", "body": "This PR tries to address the issue raised in #37638 where\r\nthe shape after sparse.transpose is <unknown> even though\r\nthe input shape's rank is known. This PR relexed the shape\r\nto only use rank (vs. is_fully_defined) to populate the shape.\r\n\r\nThe other issue raised about `sparse.reduce_sum` is a little challanging\r\nas the shape is inference from C++ `SparseReduceSumSparse` ops which\r\nwill output unknown shape anyway. For that reason this PR does not\r\naddress the `sparse.reduce_sum` issue.\r\n\r\nThis PR fixes #37638.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@mdanatg Thanks for the review. I have updated the PR to add a test case to cover the change. Since the issue only happens in graph mode (inside tf.function), not eager mode, I have added `@test_util.run_all_in_graph_and_eager_modes` to make sure the test runs in both cases.\r\n\r\nPlease take a look and let me know if there are any issues.", "@mdanatg Thanks for the review! The PR has been updated. Please take a look."]}, {"number": 38141, "title": "TensorFlow Developer Certificate", "body": "Does the  TensorFlow exam include Keras?\r\n\r\nAre there any sample tests available for review?", "comments": ["The certificate program requires an understanding of building basic TensorFlow models using Computer Vision, Sequence modeling, and Natural Language Processing. So I think TF Keras is necessary. \r\nThis course https://www.coursera.org/specializations/tensorflow-in-practice can be a good prep for the exam.\r\nTo know more see [TensorFlow Blog](https://blog.tensorflow.org/2020/03/introducing-tensorflow-developer-certificate.html)  and [candidate handbook](https://www.tensorflow.org/site-assets/downloads/marketing/cert/TF_Certificate_Candidate_Handbook.pdf). Thanks!", "@Bstrum36 \r\nplease update as per above comment", "Thank you for the information\n\nOn Wed, Apr 1, 2020 at 8:00 PM Yasir Modak <notifications@github.com> wrote:\n\n> The certificate program requires an understanding of building basic\n> TensorFlow models using Computer Vision, Sequence modeling, and Natural\n> Language Processing. So I think TF Keras is necessary.\n> This course\n> https://www.coursera.org/specializations/tensorflow-in-practice can be a\n> good prep for the exam.\n> To know more see\n> https://blog.tensorflow.org/2020/03/introducing-tensorflow-developer-certificate.html\n> and candidate handbook\n> <https://www.tensorflow.org/site-assets/downloads/marketing/cert/TF_Certificate_Candidate_Handbook.pdf>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38141#issuecomment-607547312>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AI2XRUKLYAS5AJTVOGYOSG3RKPITJANCNFSM4LZQKY4A>\n> .\n>\n", "@Bstrum36 \r\nplease let us know if we may move this to closed status", "I really did not get an answer to my question.\n\nAre there sample tests available?\nIs Keras included in the scope of the exam?\n\nreal questions with yes or no answers.\n\nOn Mon, Apr 6, 2020 at 6:39 AM Saduf2019 <notifications@github.com> wrote:\n\n> @Bstrum36 <https://github.com/Bstrum36>\n> please let us know if we may move this to closed status\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38141#issuecomment-609716026>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AI2XRUJLGCLCQI2EJSPB2FLRLGWODANCNFSM4LZQKY4A>\n> .\n>\n", "@Bstrum36 \r\nplease refer to [this link](https://www.infoq.com/news/2020/03/google-tensorflow-certification/) for tensorflow related certification", "@Bstrum36\r\nplease update as per above comment", "Thanks,\r\nThis still does not answer my basic question which is: are there any sample tests avaible for review?", "Please see the checklist in the [Candidate Handbook](https://www.tensorflow.org/site-assets/downloads/marketing/cert/TF_Certificate_Candidate_Handbook.pdf) for the list of things you need to know before taking the TensorFlow Developer Certificate exam.\r\n\r\nPlease see the section \"Don't feel ready to take the exam?\" at [tensorflow.org/certificate ](tensorflow.org/certificate) for resources for learning.\r\n\r\nDuring the exam you will need to define and train models using TensorFlow.\r\n\r\nWe do not have sample questions.\r\n\r\nWe regret we are not able to further discuss the contents of the exam.\r\n\r\nRegards\r\n\r\nTensorFlow Certificate team\r\n", "Closing this issue since it's been addressed. Thanks!", "Can we refer some resources like stackover flow(for any errors) or our noted material while taking the exam?", "@gharshini From the [TF Certificate Candidate Handbook](https://www.tensorflow.org/extras/cert/TF_Certificate_Candidate_Handbook.pdf), \"Resources allowed during exam: You may use whatever learning resources you would normally use during your ML development work\".\r\n\r\n[Exam setup instructions](https://www.tensorflow.org/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf) has additional hints to avoid getting errors. Today it's Python 3.7 and TF 2.0. The exam env will be upgraded to TensorFlow 2.3 soon.", "https://github.com/Afvanjaffer/dlaicourse   \r\n\r\nthis is best for the exam"]}, {"number": 38140, "title": "AttributeError: 'list' object has no attribute 'items'", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10 \r\n- TensorFlow installed from (source or\r\nbinary): pip\r\n- TensorFlow version (use command below): tensorflow 2.1.0\r\n- Python version: Python 3.7.7 \r\n**Describe the current behavior**\r\nwhen run the file : app.py , this error happens.\r\n for key, item in cls_config.items(): AttributeError: 'list' object has no attribute 'items'\r\nhow could i solve it ?", "comments": ["@suu98 \r\n\r\nPlease, provide colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38140\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38140\">No</a>\n"]}, {"number": 38139, "title": "Fix the typo when calling to model quantizer", "body": "", "comments": []}, {"number": 38138, "title": "Fix the typo in the flag", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38138) for more info**.\n\n<!-- need_author_cla -->", "close this one because of the cla issue. Please refer to\r\nhttps://github.com/tensorflow/tensorflow/pull/38139"]}]