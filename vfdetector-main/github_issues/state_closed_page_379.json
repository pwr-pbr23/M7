[{"number": 42630, "title": "Fix messy rendering of docs for tf.image.extract_patches", "body": "While working on using tf.image.extract_patches, noticed\r\nthat the docs rendering of tf.image.extract_patches was messed.\r\nThe issue was the missing backtick (\"`\") at the first line of args section.\r\n\r\nSee  https://www.tensorflow.org/api_docs/python/tf/image/extract_patches\r\n\r\n<img width=\"888\" alt=\"Screen Shot 2020-08-24 at 11 42 10 AM\" src=\"https://user-images.githubusercontent.com/6932348/91083330-f9958100-e5fe-11ea-95cd-617d7c1fabeb.png\">\r\n\r\n\r\nThis PR fixes the docs rendering issue.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 42629, "title": "Size 1 must be non-negative error when using boolean mask tensorflow", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Maybe?\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: N/A using IPU, poplar version 1.2.100\r\n- GPU model and memory: MK1 IPU\r\n\r\n**Describe the current behavior**\r\n\r\nWhen working with too big arrays, boolean crashes probably because of using int32 internally for indexing.\r\nIf I change the first dimension in the example below to 20000, processing is not an issue.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe input arrays for the boolean mask function have the same size as the expected output of the boolean mask.\r\nHence, I would expect that either the inputs objects get not created with an error that their size exceeds the limits or that it just works. Also, it would be better to have an internal size check to provide more meaningful output.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nt_vector = tf.ones([8,35583,100000], dtype=tf.float32)\r\nacceptance_vector = tf.cast(tf.ones([35583, 100000]), tf.bool)\r\neval_vector = tf.boolean_mask(t_vector, acceptance_vector, axis=1)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n[boolean_mask_error.log](https://github.com/tensorflow/tensorflow/files/5119308/boolean_mask_error.log)\r\n\r\n\r\n\r\n", "comments": ["Does the issue reproduce against `tf-nightly`. I tried to do that myself and I got an OOM error, as expected.", "@mihaimaruseac Its crashing even in tf-nightly. Please find my [gist](https://colab.research.google.com/gist/gowthamkpr/e7820465446677c256945271c45c179f/untitled309.ipynb) ", "If you separate the lines, the crash happens on the first line, when trying to allocate memory that clearly gets outside of the interpreter's available memory.\r\n![yH0qjPS7gNn](https://user-images.githubusercontent.com/323199/91485313-88083d80-e85f-11ea-889d-578922c490ee.png)\r\n", "@MMKrell Can you please respond to the above comment so that we can take the discussion forward. Thanks!", "I did two tests. I tried to reproduce my error in the collab notebook but its memory is too limited and it will always create an OOM error. It needs at least 110GB, probably more around 220GB, given that the boolean mask probably also needs some space. I installed the nightly (2.4.0-dev20201020) on my own machine with 739GB RAM and it crashed with the error related to the boolean mask. The trace looked the same, but I can upload it again if that helps.", "Do you need any other information from my side?", "I ran the code and it crashes on nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/237f45f580bd7b91b26e0d497ab28cc5/untitled499.ipynb)", "@MMKrell Looks like crash is not due to `tf.boolean_mask` but the huge memory. When I tried smaller input size (like [8,35583,1000]), everything worked as expected. Is there any data pipeline you can use to avoid memory issue? Thanks! \r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/d1ac9a5fcf4af7bf35128fdc84e8a257/untitled499.ipynb) is a gist for reference. Thanks!", "@jvishnuvardhan This issue cannot be tested/reproduced on gist because the gist server has too little memory and will result in a crash due to memory. I am getting the following error, when I use a sufficient amount of RAM:\r\n\r\n`In [4]: eval_param_vector = tf.boolean_mask(t_vector, acceptance_vector, axis=1)\r\n2020-08-24 09:03:43.882188: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at reshape_op.h:53 : Invalid argument: Size 1 must be non-negative, not -736667296`\r\n`InvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-4-1d3d606238ed> in <module>\r\n----> 1 eval_param_vector = tf.boolean_mask(t_vector, acceptance_vector, axis=1)`\r\n\r\nYou can see the full logging in the main issue description. This is not an out of memory error but an error that indicates an integer overflow or something else.\r\n\r\nAs a workaround, I iterated over the data and produced small chunks that do not give the index error. However, figuring out why I get the \"Size 1 must be non-negative, not -736667296\" error took me quite a while and from a usability perspective, it would be good to avoid this for other users. If there is an intended size limit for arrays, it should be resulting in a respective error when creating the array. In fact, negative sizes should not be possible at all.\r\n\r\nMaybe, the easiest approach would be to add a message to the provided error that says: \"You might have to reduce your tensor size.\"?\r\n\r\n", "This seems to be an integer overflow caused by a tensor too large.  TF uses int32 for shapes. A tensor of shape [8,35583,100000] has 28,466,400,000 elements, larger than 2^31=2,147,483,648, so when this tensor is flattened (probably by some ops internally), the resulting dimension size is too large for an int32. This behavior seems to be WAI. We may add a check to disallow any tensor with more than 2^31 elements, but that may be too restrictive since creating such a tensor is OK as long as you don't flatten it.", "Maybe, it is possible to check internally before flattening what the size is? Or maybe give a warning, when a data structure gets too big?", "@MMKrell As mentioned by @wangpengmit tensor is too large. With the most recent `tf-nightly`, code is not crashing. It is throwing `ResourceExhaustedError` as shown below. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/eecc7484971c963fa42c0f92ad987a99/untitled499.ipynb).\r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-2-17d1ab0502a4> in <module>()\r\n      1 import tensorflow as tf\r\n----> 2 t_vector = tf.ones([8,35583,100000], dtype=tf.float32)\r\n      3 # 8,35583,100000\r\n\r\n6 frames\r\n/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[8,35583,100000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\r\n```\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42629\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42629\">No</a>\n"]}, {"number": 42628, "title": "[INTEL MKL] oneDNN build fix", "body": "This PR fixes a change to the oneDNN jit profile utils path.", "comments": []}, {"number": 42627, "title": "tf.keras.activations.deserialize document refers `x` as a parameter", "body": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/activations/deserialize\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe document of `tf.keras.activations.deserialize` refers `x` as a parameter in the **Argument** section. But it is not in the signature and not accepted by the function.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/24580222/91073972-e6d47980-e609-11ea-835d-4a1c17ead171.png)\r\n\r\n\r\n\r\n### Usage example\r\n\r\n~~~python\r\nimport tensorflow as tf\r\ntf.keras.activations.deserialize(x='softmax')\r\n~~~\r\n\r\nRunning the code above gives exception:\r\n\r\n~~~\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: deserialize() got an unexpected keyword argument 'x'\r\n~~~\r\n\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.0.0\r\n- **Python version**: 3.6.9", "comments": ["This is now fixed with the above commit. Thanks!"]}, {"number": 42625, "title": "Add training call argument for MultiHeadAttention", "body": "Miss `training` call argument for dropout layer. /cc @tanzhenyu for visibility.", "comments": ["Hi @tanzhenyu, sorry for bothering you. Can you review this when time allows? We are going to deprecate `MultiHeadAttention` in addons, and this will give us a full spectrum and more stable API during deprecation.", "Is the training argument required? I thought keras will automatically inject training from models.\r\nSomething would not work if it is inside a tf.module?", "> Is the training argument required? I thought keras will automatically inject training from models.\r\n> Something would not work if it is inside a tf.module?\r\n\r\nHi @saberkun It will be injected when using it inside `tf.keras.Model` or `tf.keras.layers.Layer` but will not work inside `tf.Module`. I think this is not an usually case actually.\r\n\r\n"]}, {"number": 42624, "title": "- added missing momentum in ApplyCenteredRMSProp and ResourceApplyCenteredRMSProp doc", "body": "Deals with #42502 for changes.", "comments": ["\r\n[Updated discussion ](https://github.com/tensorflow/tensorflow/issues/42502#issuecomment-679229073)", "> This files are autogenerated, we should instead fix the bug in the generation code.\r\n\r\nSure, could you please elaborate on how I can make changes to the generation code? Do you mean I need to change the source file for the implementation of the said code? I had also asked similar about this in the issue and was awaiting reply.", "@mihaimaruseac it apperas that training_ops.h and training_ops.cc are the files that refer the  missing momentum in ApplyCenteredRMSProp and ResourceApplyCenteredRMSProp, \r\n\r\nThere seems to be no docstring directly mentioned in these files, how should I go ahead with generating docstrings from source code?", "Apologies, seems I was wrong, these files are manually written, not autogenerated. Sorry for the confusion", "Thank you."]}, {"number": 42623, "title": "Retrain a TensorFlow model from a .pb file", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: MacOS Catalina\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.15.0 \r\n- Python version: 3.6\r\n\r\n**I was trying to retrain a TensorFlow model from a .pb file**. I'm using the following function to retrieve it and load the graph in Python:\r\n\r\n```\r\n# Load protobuf as graph, given filepath\r\ndef load_pb(path_to_pb):\r\n    with tf.gfile.GFile(path_to_pb, 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n    with tf.Graph().as_default() as graph:\r\n        tf.import_graph_def(graph_def, name='')\r\n        return graph\r\n```\r\nFrom here, I try to list its trainable variables and operations:\r\n```\r\nwith tf.Session(graph=tf_graph) as sess:\r\n    print(\"Trainable variables: {}\".format(tf.trainable_variables())) \r\n    variables = [op for op in tf_graph.get_operations()]\r\n    for var in variables:\r\n        print(\"{}\".format(var.name), end = ' ,')\r\n```\r\nThis is the output from the above code:\r\n[Code output][1]\r\n\r\n\r\nAs shown above, it says that there are no variables that can be trained, and when I try the following code to train the graph:\r\n\r\n```\r\nwith tf.Session() as sess:\r\n    random_input  = tf.convert_to_tensor(np.random.rand(1, 3, 2848, 4256)) # Input dimensions\r\n    random_output = sess.run(random_input) \r\n\r\n    random_y0 = tf.convert_to_tensor(np.random.rand(1, 3, 2848, 4256))\r\n\r\n    loss = tf.reduce_sum(tf.square(random_y0 - random_output))\r\n    train = tf.train.GradientDescentOptimizer(1e-4).minimize(loss)\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    print(\"Training\")\r\n\r\n    for step in range(1):\r\n        sess.run(train)\r\n\r\n```\r\n\r\nIt gives me the error: \r\n\r\n```\r\ntrain = tf.train.GradientDescentOptimizer(1e-4).minimize(loss)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/training/optimizer.py\", line 410, in minimize\r\n    ([str(v) for _, v in grads_and_vars], loss))\r\nValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables\r\n```\r\n\r\nI believe there is an issue with the conversion such that it is failing to find the training variables, could someone please clarify this? I can also provide the exact .pb file if needed. Thanks a lot!\r\n\r\n  [1]: https://i.stack.imgur.com/SNkBk.png", "comments": ["@kaustav-aarish \r\nIs there any particular reason for using 1.15, can you try in later versions and see if you still face the issue.\r\nAlso, the code is incomplete for us to replicate, if possible share a colab gist with the issue reported for us to analyse.\r\n\r\nwith respect to the error reported, please refer to: #23621 #28792 [link](https://github.com/tensorflow/tensorflow/issues/1511) [link1](https://github.com/tensorflow/tensorflow/issues/14894) [link2](https://stackoverflow.com/questions/41689451/valueerror-no-gradients-provided-for-any-variable) [link](https://stackoverflow.com/questions/42498876/tensorflow-no-gradients-provided-for-any-variable-and-partial-run/42504176) ", "@Saduf2019 ,\r\n\r\nThanks for your reply! I upgraded to TensorFlow 2.x (still using v1 functions) and I get the same problems.\r\n\r\nThe colab file with the complete code is here: \r\n\r\nhttps://colab.research.google.com/drive/1Lo4ycD7tp5GrD1jYvXNbPEyZEHlG01-h?usp=sharing\r\n\r\nYou also will need a sample .pb file, which is located here (you would need to upload it to the colab server, since it deletes the file everytime a new runtime is created):\r\n\r\nhttps://drive.google.com/file/d/14A9Z0F4t15pbyHXGx2BB9ztz7CHcVvfi/view?usp=sharing\r\n", "@kaustav-aarish \r\nI ran the code shared on 2.3 and face a different error, please find the[ gist here](https://colab.research.google.com/gist/Saduf2019/99d4aeea8a5acfb8270f351e4374b385/untitled400.ipynb) and gist on [tf 2.2](https://colab.research.google.com/gist/Saduf2019/acd6e7e9dc0904df9fb48e60644857f7/untitled400.ipynb)\r\nAre you trying to optimise a loss function with out any variables, please refer to this link and let us know if it helps [[link](https://stackoverflow.com/questions/46246556/valueerror-no-variables-to-optimize)]\r\n", "@Saduf2019,\r\n\r\nI added to [here](https://colab.research.google.com/drive/1Lo4ycD7tp5GrD1jYvXNbPEyZEHlG01-h?usp=sharing) to show that the loaded graph does have trainable variables, but they are not being recognised? The StackOverflow link you provided says:\r\n\r\n     To solve the problem, you have to think again about the graph you are trying to construct. You have to define \r\n     variables...\r\n\r\nThe issue is that the variables were defined elsewhere, then saved, and now need to be read and recongised which I believe TensorFlow is not able to do.", "Our recommended way of retraining models is to use saved models. As far as I understand, we do not support going directly through protobufs as persistence mechanisms. I'll close this bug, feel free to open another one if the saved model approach does not work.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42623\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42623\">No</a>\n"]}, {"number": 42622, "title": "Tensorflow lite: Failed to run on the given Interpreter", "body": "I am using tflite for semantic segmentation. I have a model trained to segment objects from background, this model is trained on deeplab.\r\nI have converted this model(frozen inference graph) into tflite format using the below code:\r\n```\r\ntflite_convert \\\r\n  --output_file=test.lite \\\r\n  --graph_def_file=frozen_inference_graph.pb \\\r\n  --input_arrays=ImageTensor \\\r\n  --output_arrays=SemanticPredictions \\\r\n  --input_shapes=1,513,513,3 \\\r\n  --inference_input_type=QUANTIZED_UINT8 \\\r\n  --inference_type=FLOAT \\\r\n  --mean_values=128 \\\r\n  --std_dev_values=128 \r\n```\r\nThe model loads on android, but when I try to run inference it gives me this error:\r\n```\r\nCaused by:java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/unpack.cc:71 output->type != input->type (FLOAT32 != INT32)\r\nNode number 22 (UNPACK) failed to prepare.\r\n```\r\nHow do I resove this error? Is there anyone who can solve my problem\uff1f\r\nhere is my model\r\n[deeplabv3_513_mv2_gpu.zip](https://github.com/tensorflow/tensorflow/files/5118434/deeplabv3_257_mv_gpu.zip)\r\n\r\n\r\n", "comments": ["@1095560081,\r\nCan you please let us know what is the version of Tensorflow that you are using? Thanks! ", "@rmothukuru Hi , I am using the version of 1.14", "@rmothukuru You may be able to reproduce it with this Android project\r\n\r\n[android.zip](https://github.com/tensorflow/tensorflow/files/5124793/android.zip)\r\n", "@1095560081 Did you try with recent TF1.x version (TF1.15.3)? Did you try `tf-nightly` for the conversion? Thanks!\r\n\r\nI think the root-cause of the issue is incompatibility between output data type of `unpack` layer to the next layer that expects `int32`. Please check the screenshot below. The output dtype of `unpack` is `float32` whereas the input of `sub` layer is `int32`. In the model you need to cast the data so that you can change dtype of output variable from `float32` to `int32`.\r\n\r\n<img width=\"729\" alt=\"Screen Shot 2020-09-10 at 5 51 20 PM\" src=\"https://user-images.githubusercontent.com/46058173/92834297-b5d8a080-f38e-11ea-9751-ead800e6fece.png\">\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42620, "title": "CUDA 11.0 Build with tensorflow master on Win 10 : Link error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 Pro 2004 Edition\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3 (master)\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: Directly installed to C:\\Python3\\\r\n- Bazel version (if compiling from source): 3.4.1\r\n- GCC/Compiler version (if compiling from source): MSVC VS 2019 v 16.7.2\r\n- CUDA/cuDNN version: 11.0/cuDNN 8.0.2.39\r\n- GPU model and memory: GTX 2080 (Cuda Compute : 7.5) 8 GB RAM on Graphics card, 32 GB on System\r\n\r\n\r\n\r\n**Describe the problem**\r\nAt outset, I admit that the version 11.0 is **NOT** yet supported. However, since I managed to compile the C++ library with identical parameters successfully (issue #42340) , I attempted to compile for a Python tensorflow implementation. These \"issues\" being reported are just to help the team as the compilation results may be of some value to the build management team.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nThe build process ran slowly but surely. Observations\r\n 1. Selecting any of the noaws,nogcp,nohdf5 etc resulted into a build error as some variable or the other was not found to be duplicated.\r\nHowever, not opting to reject any of these additional features continued the compilation smoothly.\r\n2. The compilation went smooth, but the linking step resulted into fairly large count of warnings, and thereafter, failed since one extern variable not found. The output is in the attached file.\r\n\r\n[py_build_results.txt](https://github.com/tensorflow/tensorflow/files/5117877/py_build_results.txt)\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@quasar66,\r\n\r\nCan you try updating to the latest stable version `2.6.0` and let us know if the issue still persists? `CUDA 11.0` is supported from `TF 2.4.0` and you can check this [link](https://www.tensorflow.org/install/source#gpu) for tested build configurations. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42620\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42620\">No</a>\n"]}, {"number": 42619, "title": "[T.F 2.0 API Docs] Modifying python math_ops.py documentation", "body": "PR for issue #25802.\r\n\r\nModifying the following existing functions:\r\n-  `math.subtract`\r\n\r\nAdding new functions:\r\n- `math.acos`\r\n- `math.add`\r\n- `math.floor`", "comments": ["Sorry about the random approval, that was a mistake on my part.  Please ignore", "Just finished making all the requested changes. I took your advice and removed the `# ... tensors have shape ..` to avoid confusion.", "@Harsh188 can you please check ubuntu sanity build failures ?", "I'm not too sure if fixing the pylint issues will fix the Ubuntu Sanity build failure. I went through the logs and saw that they were causing an error so that's what I ended up fixing. I'm still new contributing so, please forgive me for my small mistakes :)", "I still can't figure out why I'm getting these build failures and if they are fatal or if I should just ignore them. The build that's failing is `tensorflow/tools/ci_build/builds:gen_win_out` but I'm not sure how that relates to the files that I have made changes to. \r\n\r\n@rthadur can you help me sort this out?", "I am not sure about the errors , @mihaimaruseac can you please help ?", "Looks like an import failure. Let's try again and if this still does not work let's try rebasing back on master. If that still does not work, we might need to manually import", "@mihaimaruseac I rebased to master.", "> Looks like an import failure. Let's try again and if this still does not work let's try rebasing back on master. If that still does not work, we might need to manually import\r\n\r\n@mihaimaruseac how should I go about and manually import? It doesn't look like rebasing back on master has been effective.", "I am going to import it manually, there are some steps that need to be done from inside Google. Sorry for the delay.", "Found the issue. You also needed to change `tensorflow/core/api_def/python_api/api_def_Add.pbtxt` and for the other ops you add the entire glue code in Python (see the example for `Sub`)\r\n\r\nI did the changes manually on import, so no need to do anything here now. It is pending review now, though likely this would be Wednesday.", "> Found the issue. You also needed to change `tensorflow/core/api_def/python_api/api_def_Add.pbtxt` and for the other ops you add the entire glue code in Python (see the example for `Sub`)\r\n> \r\n> I did the changes manually on import, so no need to do anything here now. It is pending review now, though likely this would be Wednesday.\r\n\r\n@mihaimaruseac awesome!\r\n\r\nRegarding the changes in `tensorflow/core/api_def/python_api/api_def_Add.pbtxt` I'm assuming I have to remove the endpoints and add `visibility: HIDDEN`? That's what the other .pbtxt files seem to do but I'm not too sure.\r\n\r\nIs glue code the [`@deprecation.deprecated`](https://github.com/tensorflow/tensorflow/blob/712fd5cfe4a5de420a4226c874664423eba4cb1a/tensorflow/python/ops/math_ops.py#L557) section in `sub`?\r\n\r\nI'm new to contributing to open source and to the field in general, I apologize for the trouble.\r\n", "Sorry again for the delayed response.\r\n\r\nBy glue code I meant the python function which has the docstring and just returns from `gen_*_ops`.\r\n\r\nThe dispatch decorator seems to be causing another test to fail, I'll try to debug by end of the week", "> By glue code I meant the python function which has the docstring and just returns from `gen_*_ops`.\r\n> \r\n> The dispatch decorator seems to be causing another test to fail, I'll try to debug by end of the week\r\n\r\nGreat, thank you! I could definitely learn quite a lot from you :)", "Unfortunately, due to the way `add` is used in dispatch (something internal, not yet exported externally), I had to remove that from the PR, during manual import.\r\n\r\nOnce dispatch is fixed, we'll add back documentation for add."]}, {"number": 42618, "title": "Pipenv EagerExecution", "body": "I've written an object detection framework with Tensorflow 2 Keras and now I'm implementing some new functionalities. I noticed that eager_execution is not enabled if I run my code via `pipenv run python3 .../folder/main.py` ( tf tf.executing_eagerly() returns False) where as in `pipenv run python3 .... import tensorflow as tf tf.executing_eagerly()` returns True also in jupyter notebooks  tf tf.executing_eagerly() returns true.\r\nWhy does this behavior happen? I can't wrap my head around this.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42618\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42618\">No</a>\n"]}, {"number": 42617, "title": "`OOM when allocating tensor with shape[320000,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc`", "body": "`OOM when allocating tensor with shape[320000,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc`\r\nI got this message while training CNN\r\nSpecifying batch_size 16, 32, 64, 128 did not help\r\n\r\n_Originally posted by @Ritaprava95 in https://github.com/tensorflow/tensorflow/issues/16768#issuecomment-448324351_", "comments": ["@yangyoungyang,\r\nIn order to expedite the trouble-shooting process, could you please provide the TensorFlow version, the complete code to reproduce the issue and the dataset you are using. \r\n\r\nAlso, try limiting GPU memory growth as per [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps. \r\n\r\nThanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42615, "title": "Fix DynamicPartitionOpGPU when running on multiple GPUs", "body": "Previously, a callback in DynamicPartitionOpGPU was running outside the correct GPU context and crashed when using a non-default GPU device. This adds a reactivation of the correct context when the callback runs.\r\n\r\nFixes #42500", "comments": ["@drebain can you please fix Ubuntu Sanity build failures ?"]}, {"number": 42613, "title": "TF 2.3 Saved model | Experimental features not working properly", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**:\r\nWhile serving a TF 2.3 trained saved model created with tf.keras.layers.experimental.preprocessing features, TMS(Tensorflow model server ) gives error on prediction. However predict method on the model runs absolutely fine without any error, seems to be something specific to TMS. Does TMS currently not support the new experimental pre-processing features that were added in TF 2.3.\r\n\r\nI also noticed that saved_model_cli also throws error that Op type not registered 'DenseBincount' in binary but that could be related to saved_model_cli not yet updated in Colab with TF 2.3 support.\r\n\r\nBug has also been opened on TMS but it seems that the bug is not in serving but in TF runtime: https://github.com/tensorflow/serving/issues/1720#issuecomment-678842670 ( FYI: @christisg  )\r\n\r\n**Describe the expected behavior**:\r\nSaved model should work properly in Tensorflow serving and also show up properly in saved_model_cli\r\n\r\n**Standalone code to reproduce the issue**\r\nRun GIST - https://gist.github.com/rafiqhasan/6f00aecf1feafd83ba9dfefef8907ee8#file-dl-e2e-taxi-dataset-tf2-keras-ipynb\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nimport json\r\nimport requests\r\n\r\n#Create payload\r\ndata_py = {\"instances\":[{'dropoff_latitude': [41.920452],\r\n                         'dropoff_longitude': [-87.679955],\r\n                         'pickup_latitude': [41.952823],\r\n                         'pickup_longitude': [-87.653244],\r\n                         'trip_start_day': [\"1\"],\r\n                         'trip_start_hour': [\"5\"],\r\n                         'trip_start_month': [\"6\"]}]}\r\n\r\ndata = json.dumps(data_py)\r\nprint(\"payload: \", data)\r\n\r\n#Run request on TMS\r\nheaders = {\"content-type\": \"application/json\"}\r\njson_response = requests.post('http://localhost:8507/v1/models/model:predict', data=data, headers=headers)\r\njson_response.text\r\n```\r\n\r\nError message:\r\n\r\n```\r\n{\r\n    \"error\": \"Missing 0-th output from {{node functional_3/category_encoding_13/bincount/DenseBincount}}\"\r\n}\r\n```\r\n\r\nBut model prediction standalone code works:\r\n```\r\n# ##Prediction on model\r\n# ## BUT HERE ALL FEATURES HAVE TO BE PASSED, EVEN THE Calculated ones\r\ndata = tf.data.Dataset.from_tensor_slices({'dropoff_latitude': [[41.920452]],\r\n                         'dropoff_longitude': [[-87.679955]],\r\n                         'pickup_latitude': [[41.952823]],\r\n                         'pickup_longitude': [[-87.653244]],\r\n                         'trip_start_day': [[\"1\"]],\r\n                         'trip_start_hour': [[\"5\"]],\r\n                         'trip_start_month': [[\"6\"]],\r\n                         'distance':[[0.02]]})\r\n\r\nm_.predict(data)\r\n```", "comments": ["Was able to reproduce the issue with TF v2.3. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/2449c4a116ca8306a754bcf9f700df07/42613.ipynb). Thanks!", "do we know the root cause now ?", "Team, any response ? Can't deploy an \"experimental features\" saved model to TMS.", "Infact, upon careful investigation of the error message from saved_model_cli - it says as below and inline with the error that TMS is raising for the saved model.\r\n\r\n```\r\nc_api.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type), buf)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'DenseBincount' in binary running on 5e1999aea28d. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n```", "Open since 25 days , no response !", "@k-w-w @amahendrakar  : Should we stop expecting a resolution on this ? This is a production issue and is escalating more than ever as we are not able to deploy models using these feature engineering options.", "TF 2.4 has fixed this problem specifically for the in-model inferencing, however tensorflow_model_server based inferencing issue still persists and is open here - tensorflow/serving#1720", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42613\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42613\">No</a>\n"]}, {"number": 42612, "title": "Mismatch in number of weights when loading quantized model (activation layer)", "body": "**Describe the bug**\r\n\r\nSaving and subsequently loading a quantized model results in the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 37, in <module>\r\n    model = tf.keras.models.load_model('MinimalExample.h5')\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\", line 182, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 181, in load_model_from_hdf5\r\n    load_weights_from_hdf5_group(f['model_weights'], model.layers)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 706, in load_weights_from_hdf5_group\r\n    str(len(weight_values)) + ' elements.')\r\nValueError: Layer #121 (named \"quant_y_a_relu\" in the current model) was found to correspond to layer quant_y_a_relu in the save file. However the new layer quant_y_a_relu expects 3 weights, but the saved weights have 1 elements.\r\n```\r\n\r\nThe error can be reproduced using this code (test.py):\r\n**Please note that there is no error when setting `quantize_model = False`**\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_model_optimization as tfmot\r\nfrom tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_configs\r\n\r\nquantize_model = True\r\n\r\n# Build model\r\nbase_model = tf.keras.applications.MobileNetV2(input_shape=(480,640,3),classes=2,weights='imagenet',include_top=False)\r\nx = base_model.get_layer('block_12_add').output\r\n\r\ny_a = tf.keras.layers.Conv2D(256,1,padding='same',dilation_rate=1,use_bias=False,kernel_initializer='he_normal',name='y_a_conv2d')(x)\r\ny_a = tf.keras.layers.BatchNormalization(name='y_a_bn')(y_a)\r\ny_a = tf.keras.layers.Activation('relu',name='y_a_relu')(y_a)\r\n\r\ny_b = tf.keras.layers.Conv2D(256,3,padding='same',dilation_rate=6,use_bias=False,kernel_initializer='he_normal',name='y_b_conv2d')(x)\r\ny_b = tf.keras.layers.BatchNormalization(name='y_b_bn')(y_b)\r\ny_b = tf.keras.layers.Activation('relu',name='y_b_relu')(y_b)\r\n\r\noutput_tensor = tf.keras.layers.Concatenate(name='aspp_concat')([y_a,y_b])\r\n\r\nmodel = tf.keras.models.Model(inputs=base_model.input,outputs=output_tensor,name='MinimalExample')\r\n\r\n# Save model\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\r\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\nmetrics = ['accuracy']\r\nif quantize_model:\r\n    with tf.keras.utils.custom_object_scope({'NoOpQuantizeConfig':default_8bit_quantize_configs.NoOpQuantizeConfig}):\r\n        model = tfmot.quantization.keras.quantize_model(model)\r\nmodel.compile(optimizer=optimizer,loss=loss,metrics=metrics)\r\nmodel.save('MinimalExample.h5')\r\ndel model\r\n\r\n# Load model\r\nif quantize_model:\r\n    with tfmot.quantization.keras.quantize_scope():\r\n        model = tf.keras.models.load_model('MinimalExample.h5')\r\nelse:\r\n    model = tf.keras.models.load_model('MinimalExample.h5')\r\n\r\n# Convert model\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n\r\n# Export model\r\nopen('MinimalExample.tflite','wb').write(tflite_model)\r\n```\r\n\r\n**System information**\r\n\r\nTensorFlow version (installed from source or binary): 2.3.0 (Docker image)\r\n\r\nTensorFlow Model Optimization version (installed from source or binary): 0.4.1 (Docker image)\r\n\r\nPython version: 3.6.9 (Docker image)\r\n\r\n**Describe the expected behavior**\r\nCode should not crash\r\n\r\n**Describe the current behavior**\r\nCode crashes", "comments": ["@Lotte1990 \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/4267a3e18ed328736d11415cf8173af4/untitled387.ipynb)", "Did you `pip install tensorflow_model_optimization`? It is required for the quantization.", "I am able to replicate the issue, Please find the [gist here](https://colab.research.google.com/gist/Saduf2019/0008c56147be9d931e7881a406c58e38/untitled387.ipynb)", "@jvishnuvardhan @nutsiepully Any updates on this?", "Issue still exists in TF 2.5 . Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/136c10317a34ec37ffc9c30380be0994/untitled387.ipynb).Thanks!", "@Lotte1990 Can you please try running training and then save and load the model. \r\n\r\nAlso, can you also try saving the model in 'tf' format as `model.save('MinimalExample_tf', save_format='tf')` and load the model. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42612\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42612\">No</a>\n"]}, {"number": 42611, "title": "how to change the specific value of tensor?", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\nI want to change the \r\n`D.object_for_each_prior-> tf.Tensor([0 0 0 ... 0 0 0], shape=(8732,), dtype=int64)\r\n`want to change the position 8700 and 8701 to the 1 value \r\nsince the assign value is no longer available how should I assign spicific value to the specific location? ", "comments": ["@SlowMonk Please provide a standalone code to reproduce the issue at our end. Thanks!", "Perhaps you can use [`assign`](https://www.tensorflow.org/api_docs/python/tf/Variable?version=nightly#assign) method from `tf.Variable`.\r\nFor example;\r\n```python\r\nv = tf.Variable(1.)\r\nprint(v)\r\nv.assign(2.)\r\nprint(v)\r\n#Output \r\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\r\n<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>\r\n```", "@SlowMonk \r\n\r\nCan you please confirm if @ymodak 's workaround is working for you.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42611\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42611\">No</a>\n"]}, {"number": 42610, "title": "I've got a build error for \"Build a handwritten digit classifier app with TensorFlow Lite\"", "body": "**System information**\r\n- OS Platform: WIndows10\r\n- Mobile device: AVD (Android 10.0(Google Play) API:29)\r\n- TensorFlow installed from (source or binary): Google Colabo\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: Preinstalled in Google Colabo\r\n- Bazel version (if compiling from source): \r\n> Android Studio 4.0\r\n> Build #AI-193.6911.18.40.6514223, built on May 21, 2020\r\n> Runtime version: 1.8.0_242-release-1644-b01 amd64\r\n> VM: OpenJDK 64-Bit Server VM by JetBrains s.r.o\r\n> Windows 10 10.0\r\n> GC: ParNew, ConcurrentMarkSweep\r\n> Memory: 1237M\r\n> Cores: 8\r\n> Registry: ide.new.welcome.screen.force=true\r\n> Non-Bundled Plugins: org.jetbrains.kotlin\r\n\r\n**Describe the problem**\r\nI followed TF lite trial site and at step 5(https://codelabs.developers.google.com/codelabs/digit-classifier-tflite/#5), \r\nafter pressing a \"Run 'app'\" button on Android Studio, I got the following error in Android Studio.\r\n\r\nOnly safe (?.) or non-null asserted (!!.) calls are allowed on a nullable receiver of type interpreter?\r\nFollowing **interpreter** the right side of val inputShape = is highlighted.\r\n\r\nprivate fun initializeInterpreter() {\r\n\r\n    // TODO: Read the model input shape from model file.\r\n    // Read input shape from model file\r\n    val inputShape = interpreter.getInputTensor(0).shape()\r\n    inputImageWidth = inputShape[1]\r\n    inputImageHeight = inputShape[2]\r\n\r\nI'm a newbie of Android Studio, thus I have not been able to find any wrong configuration in it.\r\nCould you give me any clue?\r\nThank you.\r\n\r\n**Any other info / logs**\r\nAt the very first try, when I press the \"Run 'app'\" button, Android Studio attempted to install something version 28.0.3(maybe SDK?). However, it was not able to fetch the version.\r\nI have never seen the same message, even if I delete all \"example_master\" folder and change the location and try again.\r\n\r\nOne more info.\r\nAlthough I don't know the difference b/w 'start' project and 'finish' project, I tried 'finish' project w/ same \"mnist.tflite\" too.\r\nThen, Android studio spitted **\"Compatible side by side NDK version was not found. Default is 21.0.6113669.\"** error.\r\n\r\n\r\nMy build.gradle is below by the way.\r\n> apply plugin: 'com.android.application'\r\n> apply plugin: 'kotlin-android'\r\n> apply plugin: 'kotlin-android-extensions'\r\n> \r\n> android {\r\n>     compileSdkVersion 29\r\n>     defaultConfig {\r\n>         applicationId \"org.tensorflow.lite.codelabs.digitclassifier\"\r\n>         minSdkVersion 21\r\n>         targetSdkVersion 29\r\n>         versionCode 1\r\n>         versionName \"1.0\"\r\n>         testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\r\n>     }\r\n> \r\n>     // TODO: Add an option to avoid compressing TF Lite model file\r\n>     aaptOptions {\r\n>         noCompress \"tflite\"\r\n>     }\r\n> \r\n>     buildTypes {\r\n>         release {\r\n>             minifyEnabled false\r\n>             proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\r\n>         }\r\n>     }\r\n> }\r\n> \r\n> // Sanity check if you have trained and downloaded TF Lite model.\r\n> preBuild.doFirst {\r\n>     assert file(\"./src/main/assets/mnist.tflite\").exists() :\r\n>             \"mnist.tflite not found. Make sure you have trained and \" +\r\n>                     \"downloaded your TensorFlow Lite model to assets/ folder\"\r\n> }\r\n> \r\n> dependencies {\r\n>     implementation fileTree(dir: 'libs', include: ['*.jar'])\r\n>     implementation \"org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version\"\r\n> \r\n>     // Support Libraries\r\n>     implementation 'androidx.appcompat:appcompat:1.1.0'\r\n>     implementation 'androidx.core:core-ktx:1.1.0'\r\n>     implementation 'androidx.constraintlayout:constraintlayout:1.1.3'\r\n> \r\n>     // AndroidDraw Library\r\n>     implementation 'com.github.divyanshub024:AndroidDraw:v0.1'\r\n> \r\n>     // Task API\r\n>     implementation \"com.google.android.gms:play-services-tasks:17.0.0\"\r\n> \r\n>     //TODO: Add TF Lite\r\n>     implementation 'org.tensorflow:tensorflow-lite:2.0.0'\r\n> \r\n>     testImplementation 'junit:junit:4.12'\r\n>     androidTestImplementation 'androidx.test:runner:1.2.0'\r\n>     androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0'\r\n> }\r\nI changed TF version, but each of them ended up w/ same error.\r\n    implementation 'org.tensorflow:tensorflow-lite:2.3.0'\r\n    implementation 'org.tensorflow:tensorflow-lite:2.2.0'\r\n\r\n", "comments": ["Is this still an issue?\r\nAlso see https://stackoverflow.com/questions/61157024/compatible-side-by-side-ndk-version-was-not-found-default-is-20-0-5594570", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42610\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42610\">No</a>\n"]}, {"number": 42609, "title": "tensorflow is not installing", "body": "ImportError                               Traceback (most recent call last)\r\n~\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\lenovo\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\lenovo\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\lenovo\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\nusing windows 8.1(64-bit)\r\npython 3.8 Anaconda Navigator\r\ntrying to install tensorflow\r\n\r\n\r\n\r\n\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "@TappetaMallikarjunaReddy \r\nPlease verify if you have any compatibly issues as mentioned above, you may also refer to:\r\n\r\n#42058 #39007 #40476", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42609\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42609\">No</a>\n"]}, {"number": 42608, "title": "CUDA_ERROR_LAUNCH_FAILED - possible memory issue", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n  I have modified an example keras project (https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py) by just removing the dataset size loaded.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  Windows 10 Pro\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n  N/A\r\n\r\n- TensorFlow installed from (source or binary):\r\n  tensorflow-gpu installed through pip\r\n\r\n- TensorFlow version (use command below):\r\n   Git Version: v2.3.0-rc2-23-gb36436b087\r\n   Version: 2.3.0\r\n\r\n- Python version:\r\n   3.8.5 64-bit\r\n\r\n- Bazel version (if compiling from source):\r\n   N/A\r\n\r\n- GCC/Compiler version (if compiling from source):\r\n   N/A\r\n\r\n- CUDA/cuDNN version:\r\n   CUDA: 10.1\r\n   cuDNN: 7.6\r\n\r\n- GPU model and memory:\r\n   GPU: GTX 1080 Ti\r\n   Memory: 11GB (9.5 GB effective from log)\r\n\r\n-System Memory:\r\n  32GB\r\n\r\n**Describe the current behavior**\r\nUsing the script here (https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py) to start learning a bit about LSTM's and Sequence2Sequence learning. The result is when training starts I have ~16 GB allocated by CPU side over the epoch it gradually raises itself until it nearly maxes out the system memory. Sometimes I can complete a few epochs but eventually I get the following error:\r\n\r\n\"CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1892): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\r\n2020-08-23 21:11:43.812986: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\"\r\n\r\nMy assumption is this has to do something with the memory allocation going a bit crazy and eventually triggering an OOM under the hood, but I'm not 100% sure how to get anymore data to help determine what is going on.\r\n\r\nI have tested it at 100k items and everything works as expected, but not 124k. My assumption is something is moving everything over to the GPU and thus crazy allocations are happening once the entire dataset won't fit into GPU memory.\r\n\r\n If there is something dumb I didn't do to prevent the memory from scaling crazy I apologize, but hadn't got an answer on stackoverflow so figured asking here might be better.\r\n\r\n**Describe the expected behavior**\r\nI would expect the memory usage to scale only on batch_size, not total dataset size. I would expect if I can complete an epoch once I should be be able to complete the remaining ones without an error. I have built a generator to see if maybe the issue was all the memory being allocated, but that also didn't fix the issue. I could see adding more memory but seems like the issue is more that memory use scales by total dataset size. When doing image training I haven't ever seen anything like that, only with this LSTM network.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py \r\nRun this script but set the total size to 124000.\r\n\r\nOutput\r\n(.venv) PS C:\\Dev\\CompressedMemory>  cd 'c:\\Dev\\CompressedMemory'; & 'c:\\Dev\\CompressedMemory\\.venv\\Scripts\\python.exe' 'c:\\Users\\ChaseRLewis\\.vscode\\extensions\\ms-python.python-2020.8.103604\\pythonFiles\\lib\\python\\debugpy\\launcher' '50370' '--' 'c:\\Dev\\CompressedMemory\\train.py' \r\n2020-08-23 20:59:49.133632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\nv2.3.0-rc2-23-gb36436b087\r\n2.3.0\r\nNumber of samples: 124325\r\nNumber of unique input tokens: 91\r\nNumber of unique output tokens: 114\r\n2020-08-23 21:08:54.280683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-08-23 21:08:54.314777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-08-23 21:08:54.322233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-23 21:08:54.355314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-23 21:08:54.386173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-23 21:08:54.398183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-08-23 21:08:54.419257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-23 21:08:54.439330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-23 21:08:54.550070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-23 21:08:54.554182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-23 21:08:54.567696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-23 21:08:54.662347: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b911c0e2b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-23 21:08:54.667058: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-23 21:08:54.671211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-08-23 21:08:54.686125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-23 21:08:54.699127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-23 21:08:54.702580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-23 21:08:54.716295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-08-23 21:08:54.719900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-23 21:08:54.733723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-23 21:08:54.737621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-23 21:08:54.749712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-23 21:08:55.792500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-23 21:08:55.796084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-08-23 21:08:55.798310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-08-23 21:08:55.801223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9525 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)\r\n2020-08-23 21:08:55.821954: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b938950590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-23 21:08:55.832406: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\nEpoch 1/300\r\n2020-08-23 21:09:07.991819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-23 21:09:08.422643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n3108/3108 [==============================] - ETA: 0s - loss: 0.21842020-08-23 21:11:43.812127: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1892): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\r\n2020-08-23 21:11:43.812986: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\r\n2020-08-23 21:11:43.839269: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 114, 256, 1, 280, 32, 256]\r\n2020-08-23 21:11:43.853074: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:220] Unexpected Event status: 1", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608\">No</a>\n", "I am also experiencing the same issue, however, I am a beginner with TensorFlow so it's likely my code's fault.\r\nMy system also uses a GTX 1080 Ti.\r\nI have tried a couple configurations according to [this](https://www.tensorflow.org/install/source_windows):\r\n          Version             | Python version | Compiler     | Build tools              | cuDNN | CUDA\r\n-----------------------|------------------|--------------|----------------------|---------|-------\r\ntensorflow_gpu-2.3.0 |      3.8         | MSVC 2019 | Bazel 3.1.0              |     7.4    | 10.1\r\ntensorflow_gpu-2.1.0 |      3.7         | MSVC 2019 | Bazel 0.27.1-0.29.1 |     7.4    | 10.1\r\n\r\nI have written custom code, use Win10 Home x64, IntelliJ IDE.\r\n\r\n", "@ChaseLewis \r\nCould you please provide the complete code to reproduce the issue reported here?\r\n\r\nAlso, please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/35950#issuecomment-577427083) from a similar issue and let us know if it helps. \r\nAlso refer to [link](https://github.com/tensorflow/tensorflow/issues/41169#issuecomment-673346093),[link1](https://github.com/tensorflow/tensorflow/issues/33848#issuecomment-558839064),  #34695 #37932 #39264\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608\">No</a>\n"]}, {"number": 42607, "title": "Failed precondition: Could not find required function definition __inference_tf_data_experimental_parallel_interleave_<class 'abc.ABCMeta'>", "body": "Hey, I am trying to convert the code from tensorflow=1.9 to tensorflow=1.14 and I am getting the following error: \r\n\r\nFailed precondition: Could not find required function definition __inference_tf_data_experimental_parallel_interleave_<class 'abc.ABCMeta'>_40\r\n\t [[{{node OptimizeDataset/create_dataset/ExperimentalParallelInterleaveDataset}}]]\r\n2020-08-23 15:34:01.711575: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at iterator_ops.cc:973 : Failed precondition: Could not find required function definition __inference_tf_data_experimental_parallel_interleave_<class 'abc.ABCMeta'>_40\r\n\t [[{{node OptimizeDataset/create_dataset/ExperimentalParallelInterleaveDataset}}]]\r\nTraceback (most recent call last):\r\n  File \"/home/jay/Documents/Reconstraction/DeepRecon/dl-inavJayV2/TV2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"/home/jay/Documents/Reconstraction/DeepRecon/dl-inavJayV2/TV2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/jay/Documents/Reconstraction/DeepRecon/dl-inavJayV2/TV2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.\r\n  (0) Failed precondition: Could not find required function definition __inference_tf_data_experimental_parallel_interleave_<class 'abc.ABCMeta'>_40\r\n\t [[{{node OptimizeDataset/create_dataset/ExperimentalParallelInterleaveDataset}}]]\r\n\t [[OneShotIterator]]\r\n\t [[IteratorGetNext/_711]]\r\n  (1) Failed precondition: Could not find required function definition __inference_tf_data_experimental_parallel_interleave_<class 'abc.ABCMeta'>_40\r\n\t [[{{node OptimizeDataset/create_dataset/ExperimentalParallelInterleaveDataset}}]]\r\n\t [[OneShotIterator]]\r\n\r\n\r\nMay you please me with this issue? ", "comments": ["@jaykumar16,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to v2.3 and check if it works. \r\n\r\nPlease take a look at this code [migration guide](https://www.tensorflow.org/guide/migrate) for more information. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 42605, "title": "Difference in batchnorm outputs when converting from TF model to Pytorch", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.2.2\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nI described the issue here. https://discuss.pytorch.org/t/difference-in-batchnorm-outputs-when-converting-from-tf-model-to-pytorch/93811", "comments": ["@slala2121 Can you please share a simple standalone code to reproduce the issue? I tried running your code, it throws the following error. GitHub gist is [here](https://colab.research.google.com/gist/jvishnuvardhan/1d3328e4cfe84dae668b4f2ebefb498e/untitled13.ipynb) for a reference.\r\n\r\n> OSError: File model-1.meta does not exist.\r\n", "The relevant model file is available at this link (from the post): https://figshare.com/articles/Trained_neural_network_models/8312183", "@slala2121 Can you please create a simple standalone code to reproduce the issue? You could use simple public datasets to demonstrate the issue. Thanks!", "@jvishnuvardhan The model in the above link is public. Could you please try with that?  ", "Hi @slala2121, can you share more about the TF inceptionv3 model you're using? Is that a keras model?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42605\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42605\">No</a>\n"]}, {"number": 42604, "title": "Wrong link for JNI download on website", "body": "https://www.tensorflow.org/install/lang_java\r\n\r\n\r\nThe JNI download link on the Java page is still points to 1.14.0, it should be updated to 2.3.0.\r\n\r\npage source:\r\n```\r\n<td>Linux CPU only</td>\r\n\u00a0 | <td class=\"devsite-click-to-copy\"><a href=\"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-cpu-linux-x86_64-1.14.0.tar.gz\">https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-cpu-linux-x86_64-2.3.0.tar.gz</a></td>\r\n\u00a0 | </tr>\r\n\u00a0 | <tr>\r\n\u00a0 | <td>Linux GPU support</td>\r\n\u00a0 | <td class=\"devsite-click-to-copy\"><a href=\"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-gpu-linux-x86_64-1.14.0.tar.gz\">https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-gpu-linux-x86_64-2.3.0.tar.gz</a></td>\r\n\u00a0 | </tr>\r\n\u00a0```", "comments": ["Thanks for the issue. Closing since the PR is merged. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42604\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42604\">No</a>\n"]}, {"number": 42603, "title": "NotImplementedError: TPUStrategy.run(fn, ...) does not support pure eager execution. please make sure the function passed into `strategy.run` is a `tf.function` or `strategy.run` is called inside a `tf.function` if eager behavior is enabled.", "body": "Hi, I pretty new at this. The following is  my code and the error. Thank you for your help. Posted on stackoverflow too.\r\n\r\n`\r\n#WITH TPU\r\n\r\nlatent_dim = 2 #number of latent variables to learn\r\nhidden_size = 32\r\ninput_dim = x_train.shape[1]\r\nlatent_dim = 3 # d, dimensionality of the latent code t.\r\nintermediate_dim = 256 # Size of the hidden layer.\r\n\r\n\r\ndef create_model():\r\n  x = Input(shape=(input_dim,))\r\n  t = BatchNormalization()(x)\r\n  t = Dense(intermediate_dim, activation='relu' , name='encoder_hidden')(t)\r\n  t = BatchNormalization()(t)\r\n\r\n  z_mean = Dense(latent_dim, name='z_mean')(t)\r\n  z_log_var = Dense(latent_dim, name='z_log_var')(t)\r\n\r\n  def sampling(args):\r\n      z_mean, z_log_var = args\r\n      epsilon = tf.random.normal(shape=tf.shape(z_mean), mean=0., stddev=1.,name=\"epsilon\")\r\n      return z_mean + tf.exp(z_log_var / 2) * epsilon\r\n\r\n  z = Lambda(sampling, name='z_sampled')([z_mean, z_log_var])\r\n\r\n  t = Dense(intermediate_dim, activation='relu', name='decoder_hidden')(z)\r\n\r\n  decoded_mean = Dense(input_dim, activation=None, name='decoded_mean')(t)\r\n\r\n  def kl_loss(y_true, y_pred):\r\n    return - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n\r\n  def rec_loss(y_true, y_pred):\r\n    return tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)   \r\n\r\n  def vae_loss(x, decoded_mean):\r\n    rec_loss = tf.reduce_sum(tf.square(x - decoded_mean), axis=-1)\r\n    kl_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n    return K.mean((rec_loss + kl_loss) / 2)\r\n\r\n  vae = Model(x, decoded_mean)\r\n\r\n  return vae\r\n  \r\n\r\nwith strategy.scope():\r\n  vae = create_model()\r\n  #vae.compile(optimizer=tf.keras.optimizers.Nadam(), loss=negloglik)\r\n  vae.compile(optimizer=Adam(lr=1e-2), loss=vae_loss, metrics=[rec_loss, kl_loss])\r\n  vae.summary()\r\n  n_epochs = 30\r\n  batch_size = 128\r\n\r\n  early_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=1e-5) #stop training if loss does not decrease with at least 0.00001\r\n  reduce_lr = ReduceLROnPlateau(monitor='loss', patience=5, min_delta=1e-5, factor=0.2) #reduce learning rate (divide it by 5 = multiply it by 0.2) if loss does not decrease with at least 0.00001\r\n\r\n  callbacks = [early_stopping, reduce_lr]\r\n\r\n  tf.config.experimental_run_functions_eagerly(True)\r\n\r\n  tf_train = tf.data.Dataset.from_tensor_slices((x_train, x_train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\r\n  tf_val = tf.data.Dataset.from_tensor_slices((x_val, x_val)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\r\n\r\n  hist = vae.fit(tf_train,\r\n                 validation_data=tf_val,\r\n                 shuffle=True,\r\n                 verbose=0,\r\n                 #batch_size=batch_size, \r\n                 epochs=n_epochs,\r\n                 callbacks=callbacks)\r\n  \r\n  plot_loss(hist)\r\n\r\n`\r\n`\r\nModel: \"functional_39\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_21 (InputLayer)           [(None, 30)]         0                                            \r\n__________________________________________________________________________________________________\r\nbatch_normalization_40 (BatchNo (None, 30)           120         input_21[0][0]                   \r\n__________________________________________________________________________________________________\r\nencoder_hidden (Dense)          (None, 256)          7936        batch_normalization_40[0][0]     \r\n__________________________________________________________________________________________________\r\nbatch_normalization_41 (BatchNo (None, 256)          1024        encoder_hidden[0][0]             \r\n__________________________________________________________________________________________________\r\nz_mean (Dense)                  (None, 3)            771         batch_normalization_41[0][0]     \r\n__________________________________________________________________________________________________\r\nz_log_var (Dense)               (None, 3)            771         batch_normalization_41[0][0]     \r\n__________________________________________________________________________________________________\r\nz_sampled (Lambda)              (None, 3)            0           z_mean[0][0]                     \r\n                                                                 z_log_var[0][0]                  \r\n__________________________________________________________________________________________________\r\ndecoder_hidden (Dense)          (None, 256)          1024        z_sampled[0][0]                  \r\n__________________________________________________________________________________________________\r\ndecoded_mean (Dense)            (None, 30)           7710        decoder_hidden[0][0]             \r\n==================================================================================================\r\nTotal params: 19,356\r\nTrainable params: 18,784\r\nNon-trainable params: 572\r\n__________________________________________________________________________________________________\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\r\n  \"Even though the tf.config.experimental_run_functions_eagerly \"\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-34-57c2ae5c49b9> in <module>()\r\n     68                  #batch_size=batch_size,\r\n     69                  epochs=n_epochs,\r\n---> 70                  callbacks=callbacks)\r\n     71 \r\n     72   plot_loss(hist)\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py in validate_run_function(fn)\r\n     95       and not (callable(fn) and isinstance(fn.__call__, def_function.Function)):\r\n     96     raise NotImplementedError(\r\n---> 97         \"TPUStrategy.run(fn, ...) does not support pure eager \"\r\n     98         \"execution. please make sure the function passed into \"\r\n     99         \"`strategy.run` is a `tf.function` or \"\r\n\r\nNotImplementedError: TPUStrategy.run(fn, ...) does not support pure eager execution. please make sure the function passed into `strategy.run` is a `tf.function` or `strategy.run` is called inside a `tf.function` if eager behavior is enabled.\r\n`", "comments": ["https://stackoverflow.com/questions/63548506/notimplementederror-tpustrategy-runfn-does-not-support-pure-eager-execut", "Hi @sagar-m, as the error message states TPUStrategy does not work with pure eager execution. As a first step, try commenting out the line `tf.config.experimental_run_functions_eagerly(True)`", "Ok I did comment out that line. I am getting a new error. Please can you guide why. Thank you!\r\n\r\n```\r\n#WITH TPU\r\n\r\nlatent_dim = 2 #number of latent variables to learn\r\nhidden_size = 32\r\ninput_dim = x_train.shape[1]\r\nlatent_dim = 3 # d, dimensionality of the latent code t.\r\nintermediate_dim = 256 # Size of the hidden layer.\r\n\r\n\r\ndef create_model():\r\n  x = Input(shape=(input_dim,))\r\n  t = BatchNormalization()(x)\r\n  t = Dense(intermediate_dim, activation='relu' , name='encoder_hidden')(t)\r\n  t = BatchNormalization()(t)\r\n\r\n  z_mean = Dense(latent_dim, name='z_mean')(t)\r\n  z_log_var = Dense(latent_dim, name='z_log_var')(t)\r\n\r\n  def sampling(args):\r\n    z_mean, z_log_var = args\r\n    epsilon = tf.random.normal(shape=tf.shape(z_mean), mean=0., stddev=1.,name=\"epsilon\")\r\n    return z_mean + tf.exp(z_log_var / 2) * epsilon\r\n\r\n  z = Lambda(sampling, name='z_sampled')([z_mean, z_log_var])\r\n\r\n  t = Dense(intermediate_dim, activation='relu', name='decoder_hidden')(z)\r\n\r\n  decoded_mean = Dense(input_dim, activation=None, name='decoded_mean')(t)\r\n\r\n  def kl_loss(y_true, y_pred):\r\n    kl_loss_ = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n    return kl_loss_\r\n\r\n  def rec_loss(y_true, y_pred):\r\n    rec_loss_ = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)\r\n    return rec_loss_   \r\n\r\n  def vae_loss(x, decoded_mean):\r\n    rec_loss_ = tf.reduce_sum(tf.square(x - decoded_mean), axis=-1)\r\n    kl_loss_ = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n    vae_loss_ = K.mean((rec_loss + kl_loss) / 2)\r\n    return vae_loss_\r\n\r\n  vae = Model(x, decoded_mean)\r\n\r\n  return vae\r\n  \r\n\r\nwith strategy.scope():\r\n  vae = create_model()\r\n  vae.compile(optimizer=Adam(lr=1e-2), loss=vae_loss_, metrics=[rec_loss, kl_loss])\r\n  #vae.compile(optimizer=tf.keras.optimizers.Nadam(), loss=negloglik)\r\n  vae.summary()\r\n  n_epochs = 30\r\n  batch_size = 128\r\n\r\n  early_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=1e-5) #stop training if loss does not decrease with at least 0.00001\r\n  reduce_lr = ReduceLROnPlateau(monitor='loss', patience=5, min_delta=1e-5, factor=0.2) #reduce learning rate (divide it by 5 = multiply it by 0.2) if loss does not decrease with at least 0.00001\r\n\r\n  callbacks = [early_stopping, reduce_lr]\r\n\r\n  #tf.config.experimental_run_functions_eagerly(True)\r\n\r\n  tf_train = tf.data.Dataset.from_tensor_slices((x_train, x_train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\r\n  tf_val = tf.data.Dataset.from_tensor_slices((x_val, x_val)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\r\n\r\n  hist = vae.fit(tf_train,\r\n                 validation_data=tf_val,\r\n                 shuffle=True,\r\n                 verbose=0,\r\n                 #batch_size=batch_size, \r\n                 epochs=n_epochs,\r\n                 callbacks=callbacks)\r\n  \r\n  plot_loss(hist)\r\n```\r\n\r\nError...\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nNameError                                 Traceback (most recent call last)\r\n<ipython-input-14-a9d277df43a1> in <module>()\r\n     49 with strategy.scope():\r\n     50   vae = create_model()\r\n---> 51   vae.compile(optimizer=Adam(lr=1e-2), loss=vae_loss_, metrics=[rec_loss, kl_loss])\r\n     52   #vae.compile(optimizer=tf.keras.optimizers.Nadam(), loss=negloglik)\r\n     53   vae.summary()\r\n\r\nNameError: name 'vae_loss_' is not defined\r\n```\r\n", "The error message says `vae_loss_ is not defined` and you'll notice that you have not defined `vae_loss_` in your program. You have a function called `vae_loss` (ie without the extra underscore at the end), so perhaps you meant to pass `vae_loss`  to your compile function instead of `vae_loss_`. ", "Hi, thank you so much for pointing out... I fixed the above vae loss error now. Yet, it is getting stuck.\r\n\r\n```\r\n#WITH TPU\r\n\r\nlatent_dim = 2 #number of latent variables to learn\r\nhidden_size = 32\r\ninput_dim = x_train.shape[1]\r\nlatent_dim = 3 # d, dimensionality of the latent code t.\r\nintermediate_dim = 256 # Size of the hidden layer.\r\n\r\n\r\ndef create_model():\r\n  x = Input(shape=(input_dim,))\r\n  t = BatchNormalization()(x)\r\n  t = Dense(intermediate_dim, activation='relu' , name='encoder_hidden')(t)\r\n  t = BatchNormalization()(t)\r\n\r\n  z_mean = Dense(latent_dim, name='z_mean')(t)\r\n  z_log_var = Dense(latent_dim, name='z_log_var')(t)\r\n\r\n  def sampling(args):\r\n    z_mean, z_log_var = args\r\n    epsilon = tf.random.normal(shape=tf.shape(z_mean), mean=0., stddev=1.,name=\"epsilon\")\r\n    return z_mean + tf.exp(z_log_var / 2) * epsilon\r\n\r\n  z = Lambda(sampling, name='z_sampled')([z_mean, z_log_var])\r\n\r\n  t = Dense(intermediate_dim, activation='relu', name='decoder_hidden')(z)\r\n\r\n  decoded_mean = Dense(input_dim, activation=None, name='decoded_mean')(t)\r\n\r\n  def kl_loss(y_true, y_pred):\r\n    kl_loss_ = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n    return kl_loss_\r\n\r\n  def rec_loss(y_true, y_pred):\r\n    rec_loss_ = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)\r\n    return rec_loss_   \r\n\r\n  def vae_loss(x, decoded_mean):\r\n    rec_loss_ = tf.reduce_sum(tf.square(x - decoded_mean), axis=-1)\r\n    kl_loss_ = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\r\n    vae_loss_ = K.mean((rec_loss + kl_loss) / 2)\r\n    return vae_loss_\r\n\r\n  vae = Model(x, decoded_mean)\r\n\r\n  return vae\r\n  \r\n\r\nwith strategy.scope():\r\n  vae = create_model()\r\n  vae.compile(optimizer=Adam(lr=1e-2), loss=vae_loss, metrics=[rec_loss, kl_loss])\r\n  #vae.compile(optimizer=tf.keras.optimizers.Nadam(), loss=negloglik)\r\n  vae.summary()\r\n  n_epochs = 30\r\n  batch_size = 128\r\n\r\n  early_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=1e-5) #stop training if loss does not decrease with at least 0.00001\r\n  reduce_lr = ReduceLROnPlateau(monitor='loss', patience=5, min_delta=1e-5, factor=0.2) #reduce learning rate (divide it by 5 = multiply it by 0.2) if loss does not decrease with at least 0.00001\r\n\r\n  callbacks = [early_stopping, reduce_lr]\r\n\r\n  #tf.config.experimental_run_functions_eagerly(True)\r\n\r\n  tf_train = tf.data.Dataset.from_tensor_slices((x_train, x_train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\r\n  tf_val = tf.data.Dataset.from_tensor_slices((x_val, x_val)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\r\n\r\n  hist = vae.fit(tf_train,\r\n                 validation_data=tf_val,\r\n                 shuffle=True,\r\n                 verbose=0,\r\n                 #batch_size=batch_size, \r\n                 epochs=n_epochs,\r\n                 callbacks=callbacks)\r\n  \r\n```\r\n\r\nError\r\n\r\n```\r\nModel: \"functional_5\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_3 (InputLayer)            [(None, 30)]         0                                            \r\n__________________________________________________________________________________________________\r\nbatch_normalization_4 (BatchNor (None, 30)           120         input_3[0][0]                    \r\n__________________________________________________________________________________________________\r\nencoder_hidden (Dense)          (None, 256)          7936        batch_normalization_4[0][0]      \r\n__________________________________________________________________________________________________\r\nbatch_normalization_5 (BatchNor (None, 256)          1024        encoder_hidden[0][0]             \r\n__________________________________________________________________________________________________\r\nz_mean (Dense)                  (None, 3)            771         batch_normalization_5[0][0]      \r\n__________________________________________________________________________________________________\r\nz_log_var (Dense)               (None, 3)            771         batch_normalization_5[0][0]      \r\n__________________________________________________________________________________________________\r\nz_sampled (Lambda)              (None, 3)            0           z_mean[0][0]                     \r\n                                                                 z_log_var[0][0]                  \r\n__________________________________________________________________________________________________\r\ndecoder_hidden (Dense)          (None, 256)          1024        z_sampled[0][0]                  \r\n__________________________________________________________________________________________________\r\ndecoded_mean (Dense)            (None, 30)           7710        decoder_hidden[0][0]             \r\n==================================================================================================\r\nTotal params: 19,356\r\nTrainable params: 18,784\r\nNon-trainable params: 572\r\n__________________________________________________________________________________________________\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: z_log_var/BiasAdd:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n_SymbolicException                        Traceback (most recent call last)\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     72       raise core._SymbolicException(\r\n     73           \"Inputs to eager execution function cannot be Keras symbolic \"\r\n---> 74           \"tensors, but found {}\".format(keras_symbolic_tensors))\r\n     75     raise e\r\n     76   # pylint: enable=protected-access\r\n\r\n_SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'z_log_var/BiasAdd:0' shape=(None, 3) dtype=float32>, <tf.Tensor 'z_mean/BiasAdd:0' shape=(None, 3) dtype=float32>]\r\n```", "Hi @sagar-m, I don't think this is a bug. It's difficult to tell where the error is in your code since it's not fully reproducible. But here are a few tips: firstly, I would suggest making sure your code runs properly without TPU strategy, that will help narrow down where the problem is. Secondy, I suggest you swap out your lambda layer for a custom layer. Lambda layers are good for experimentation and simple operations, but for a more complicated case subclassing tf.keras.layers.Layer is preferred.\r\n\r\nAs for the error you're seeing, I suspect that it's caused because you're passing in x (which is the model.input, and a symbolic tensor) to your loss function, which is expecting an eager tensor. Hope this helps you to debug the issue!", "Hi @nikitamaia  thank you for all the tips! FYI - the code does run properly without TPU, i have tested it. Was really hoping to use the TPU!", "Hi @nikitamaia  could you please share the exact line of code I could use to replace the Lambda. Thank you!", "@sagar-m \r\nCan you please let us know the tf version you are facing this issue on.", "print(tf.__version__)\r\nprint(tfp.__version__)\r\n\r\n2.3.0\r\n0.11.0", "@sagar-m it's difficult to provide the exact lines without having fully reproducible code. You can [follow this tutorial](https://www.tensorflow.org/tutorials/customization/custom_layers) on how to write a custom layer in Tensorflow. In your custom layer you will compute the same thing you are computing with the lambda layer. Additionally, as I mentioned before, I suspect that the error you're seeing caused because you're passing in x (which is the model.input, and a symbolic tensor) to your loss function, which is expecting an eager tensor.\r\n\r\nGithub is a place for filing bugs. Since you are not facing a bug, you might have better luck on Stack Overflow as there is a larger community to provide support.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42603\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42603\">No</a>\n"]}, {"number": 42602, "title": "[Bug] tf.sqrt Inconsistent behaviour", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: V10.1.243\r\n- GPU model and memory: RTX2070 MaxQ, 8GB\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I run this code, I get the result and gradients\r\n\r\n```py\r\nx = tf.Variable([[1.0, 0.0]])\r\n\r\nwith tf.GradientTape() as tape:\r\n    x = tf.square(x)\r\n    x = tf.sqrt(x)\r\n    z = tf.reduce_sum(x, axis=-1)\r\n    loss = tf.nn.l2_loss(z)\r\n\r\ntf.print(z, loss)\r\ntf.print(tape.gradient(loss,x))\r\n'''\r\nOutput:\r\n[1] 0.5\r\n[[1 1]]\r\n'''\r\n```\r\n\r\nHowever, when I refactor the three lines inside a function, the gradient becomes NaN\r\n\r\n```py\r\n@tf.function # Happens in both eager and graph\r\ndef fun(v):\r\n    v = tf.square(v)\r\n    v = tf.sqrt(v)\r\n    return tf.reduce_sum(v, axis=-1)\r\n\r\nx = tf.Variable([[1.0, 0.0]])\r\nwith tf.GradientTape() as tape:\r\n    z = fun(x)\r\n    loss = tf.nn.l2_loss(z)\r\n\r\ntf.print(z, loss)\r\ntf.print(tape.gradient(loss, x))\r\n\r\n'''\r\nOutput:\r\n[1] 0.5\r\n[[1 nan]]\r\n'''\r\n```\r\n\r\nChanging `x = tf.sqrt(x)` to `x = tf.sqrt(x + 1e-7)` makes the gradient non NaN.\r\n\r\n**Describe the expected behavior**\r\n\r\nEither result is acceptable as long as the behaviour is consistent.\r\n", "comments": ["I am able to replicate the issue faced, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/b8f0c0f7a15aec8140a6a8c3925bb309/untitled385.ipynb)", "The failure in `tf.function` looks reasonable but it is unclear to me how this works without `tf.function`. The problem basically is that we are unable to fold the computation `x * 1/x = 1` in the gradients path. This fails when x is `0`.", "The eager version of the code overwrites the `x` Python local variable. I assume that's the only reason they're giving different results.\r\n\r\nSo far we've decided not to do anything smart with backprop regarding inverse functions canceling etc. (it's been discussed several times).", "While using an epsilon is a reasonable workaround here, you may also want to check out `tf.custom_gradient` to implement numerically stable gradient functions for cases such as this one.", "I think the refactoring inadvertently changes the logic.\r\n\r\nIf we make sure the codes are equivalent by just removing the tf.function decorator, then the outputs seem to be actually consistent:\r\n\r\n```\r\n# Same result with or without @tf.function\r\ndef fun(v):\r\n    v = tf.square(v)\r\n    v = tf.sqrt(v)\r\n    return tf.reduce_sum(v, axis=-1)\r\n\r\nx = tf.Variable([[1.0, 0.0]])\r\nwith tf.GradientTape() as tape:\r\n    z = fun(x)\r\n    loss = tf.nn.l2_loss(z)\r\n\r\ntf.print(z, loss)\r\ntf.print(tape.gradient(loss, x))\r\n```\r\n\r\n```\r\n[1] 0.5\r\n[[1 -nan]]\r\n```", "@allenlavoie It happens in both eager and graph. You can comment out the `tf.function`. I dont think this is being caused by XLA optimization. \r\n\r\nAlso we should not forget that `square(sqrt(x)) =/= sqrt(square(x))` for float. \r\n\r\n@saxenasaurabh The problem is that the same code behaves differently when it is inside a function (eager or not) than if it is outside the function (at root level). As long as it is consistent, I think either result is fine. ", "@Ghost---Shadow the two pieces of code that you originally included don't calculate the same thing. If you correct the eager version, you will also get nan, as expected:\r\n\r\n```\r\nx_var = tf.Variable([[1.0, 0.0]])\r\nx = x_var  # avoid calling tape.gradient wrt intermediate outputs\r\n\r\nwith tf.GradientTape() as tape:\r\n    x = tf.square(x)\r\n    x = tf.sqrt(x)\r\n    z = tf.reduce_sum(x, axis=-1)\r\n    loss = tf.nn.l2_loss(z)\r\n\r\ntf.print(z, loss)\r\ntf.print(tape.gradient(loss, x_var))\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42602\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42602\">No</a>\n", "It doesn't, and it's not expected to, because it's not taking a gradient with respect to the non-differentiable `sqrt` function. Let's rename the variables to make that clearer:\r\n\r\n```\r\nx = tf.Variable([[1.0, 0.0]])\r\n\r\nwith tf.GradientTape() as tape:\r\n    x = tf.square(x)\r\n    wrong_x = tf.sqrt(x)\r\n    z = tf.reduce_sum(wrong_x, axis=-1)\r\n    loss = tf.nn.l2_loss(z)\r\n\r\ntf.print(z, loss)\r\ntf.print(tape.gradient(loss, wrong_x))\r\n```\r\n\r\nSo you might as well write this with the same effect:\r\n\r\n```\r\nwith tf.GradientTape() as tape:\r\n    wrong_x = tf.constant([[1.0, 0.0]])\r\n    tape.watch(wrong_x)\r\n    z = tf.reduce_sum(wrong_x, axis=-1)\r\n    loss = tf.nn.l2_loss(z)\r\n\r\ntf.print(z, loss)\r\ntf.print(tape.gradient(loss, wrong_x))\r\n```"]}, {"number": 42601, "title": "The command line is too long", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  windows 10 education\r\n- TensorFlow installed from (source or binary):  source\r\n- TensorFlow version:  r1.14\r\n- Python version:  3.7.4\r\n- Installed using virtualenv? pip? conda?:  conda\r\n- Bazel version (if compiling from source):  0.25.2\r\n- GCC/Compiler version (if compiling from source): vs2017\r\n- CUDA/cuDNN version:  10.0/7.4\r\n- GPU model and memory:  NVIDIA GeForce RTX2070 with Max-Q Design 16GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nError happend when running:\r\nD:/ProgramData/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/bin/tensorflow/tf_python_api_gen_v1.genrule_script.sh\r\nThe error is: The command line is too long.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1. Open Developer Command Prompt for VS 2017.\r\n2. Run cmd lines:\r\n     cmd.exe \"/K\" D:\\ProgramData\\Anaconda3\\Scripts\\activate.bat\r\n     conda activate tf_gpu114\r\n     bazel --output_user_root=d:/bazel_out build  --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\n(tf_gpu114) D:\\newTf114\\tensorflow>bazel --output_user_root=d:/bazel_out build  --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/python/BUILD:3469:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/python/BUILD:102:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/contrib/metrics/BUILD:16:1: in py_library rule //tensorflow/contrib/metrics:metrics_py: target '//tensorflow/contrib/metrics:metrics_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: D:/newtf114/tensorflow/tensorflow/contrib/BUILD:12:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: D:/newtf114/tensorflow/tensorflow/BUILD:745:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash.exe failed: error executing command\r\n  cd D:/bazel_out/73kxojlr/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET PATH=D:\\ProgramData\\msys64\\usr\\bin;D:\\ProgramData\\msys64\\bin;D:\\ProgramData\\Anaconda3;D:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;D:\\ProgramData\\Anaconda3\\Library\\usr\\bin;D:\\ProgramData\\Anaconda3\\Library\\bin;D:\\ProgramData\\Anaconda3\\Scripts;D:\\ProgramData\\Anaconda3\\bin;D:\\ProgramData\\Anaconda3\\condabin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x86;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft SDKs\\TypeScript\\3.1;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x86;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.0\\bin;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.0\\libnvvp;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.1\\bin;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.1\\libnvvp;d:\\ProgramData\\Anaconda3;d:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;d:\\ProgramData\\Anaconda3\\Library\\usr\\bin;d:\\ProgramData\\Anaconda3\\Library\\bin;d:\\ProgramData\\Anaconda3\\Scripts;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Users\\bolix\\.dnx\\bin;C:\\Program Files\\Microsoft DNX\\Dnvm;C:\\Program Files\\Microsoft SQL Server\\120\\Tools\\Binn;C:\\Program Files\\CMake\\bin;D:\\Program Files\\MATLAB\\R2018b\\runtime\\win64;D:\\Program Files\\MATLAB\\R2018b\\bin;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\dotnet;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn;D:\\Program Files\\Git\\cmd;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;D:\\ProgramData\\msys64\\usr\\bin;D:\\ProgramData\\msys64\\usr\\bin\\bash.exe;D:\\ProgramData\\msys64;C:\\Users\\bolix\\AppData\\Local\\Microsoft\\WindowsApps;D:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.4\\bin;D:\\texlive\\2019\\bin\\win32;C:\\Users\\bolix\\.dotnet\\tools;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PYTHON_BIN_PATH=d:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=d:/ProgramData/Anaconda3/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TF_NEED_TENSORRT=0\r\n  D:/ProgramData/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/bin/tensorflow/tf_python_api_gen_v1.genrule_script.sh\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nThe command line is too long.\uff08\uff09\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 21.007s, Critical Path: 12.47s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["I did some change , shorten some pathes , such as modify tmp file to \u201cD : /T\u201d . Downgrade bazel to 0.24.1 , some one said it's good even with tf 1.15 . And then build tf in a new folder . The problem above not comes out yet , but there goes another similar problem\uff1a\r\n\r\n\r\nERROR: D:/x14/tensorflow/tensorflow/python/BUILD:400:1: C++ compilation of rule '//tensorflow/python:py_func_lib' failed (Exit 1): python.exe failed: error executing command\r\n  cd D:/out14/2evjwl57/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET INCLUDE=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n    SET PATH=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\;D:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=d:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=d:/ProgramData/Anaconda3/lib/site-packages\r\n    SET TEMP=d:\\T\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TF_NEED_TENSORRT=0\r\n    SET TMP=d:\\T\r\n  d:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/grpc /Ibazel-out/x64_windows-opt/genfiles/external/grpc /Ibazel-out/x64_windows-opt/bin/external/grpc /Iexternal/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb /Iexternal/boringssl /Ibazel-out/x64_windows-opt/genfiles/external/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/cub_archive /Ibazel-out/x64_windows-opt/genfiles/external/cub_archive /Ibazel-out/x64_windows-opt/bin/external/cub_archive /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/lmdb /Ibazel-out/x64_windows-opt/genfiles/external/lmdb /Ibazel-out/x64_windows-opt/bin/external/lmdb /Iexternal/icu /Ibazel-out/x64_windows-opt/genfiles/external/icu /Ibazel-out/x64_windows-opt/bin/external/icu /Iexternal/org_sqlite /Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/org_sqlite /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cupti_headers_virtual /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/numpy_include /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/grpc/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/include /Ibazel-out/x64_windows-opt/bin/external/grpc/include /Iexternal/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/genfiles/external/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/bin/external/icu/icu4c/source/common /Iexternal/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DSQLITE_OMIT_DEPRECATED /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/python/_objs/py_func_lib/py_func.o /c tensorflow/python/lib/core/py_func.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nThe command line is too long.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 3946.378s, Critical Path: 729.37s\r\nINFO: 5035 processes: 5035 local.\r\nFAILED: Build did NOT complete successfully", "There goes two similar errors, finally build stuck here:\r\n\r\n\r\nERROR: D:/x14/tensorflow/tensorflow/python/BUILD:4501:1: C++ compilation of rule '//tensorflow/python:cpp_shape_inference' failed (Exit 1): python.exe failed: error executing command\r\n  cd D:/out14/2evjwl57/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET INCLUDE=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n    SET PATH=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\;D:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=d:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=d:/ProgramData/Anaconda3/lib/site-packages\r\n    SET TEMP=d:\\T\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TF_NEED_TENSORRT=0\r\n    SET TMP=d:\\T\r\n  d:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/grpc /Ibazel-out/x64_windows-opt/genfiles/external/grpc /Ibazel-out/x64_windows-opt/bin/external/grpc /Iexternal/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb /Iexternal/boringssl /Ibazel-out/x64_windows-opt/genfiles/external/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/cub_archive /Ibazel-out/x64_windows-opt/genfiles/external/cub_archive /Ibazel-out/x64_windows-opt/bin/external/cub_archive /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/lmdb /Ibazel-out/x64_windows-opt/genfiles/external/lmdb /Ibazel-out/x64_windows-opt/bin/external/lmdb /Iexternal/icu /Ibazel-out/x64_windows-opt/genfiles/external/icu /Ibazel-out/x64_windows-opt/bin/external/icu /Iexternal/org_sqlite /Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/org_sqlite /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cupti_headers_virtual /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/numpy_include /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/grpc/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/include /Ibazel-out/x64_windows-opt/bin/external/grpc/include /Iexternal/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/genfiles/external/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/bin/external/icu/icu4c/source/common /Iexternal/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DSQLITE_OMIT_DEPRECATED /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/python/_objs/cpp_shape_inference/cpp_shape_inference.o /c tensorflow/python/framework/cpp_shape_inference.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nThe command line is too long.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6307.831s, Critical Path: 1767.88s\r\nINFO: 4633 processes: 4633 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n==================================================\r\n\r\n\r\nERROR: D:/x14/tensorflow/tensorflow/python/BUILD:4588:1: C++ compilation of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): python.exe failed: error executing command\r\n  cd D:/out14/2evjwl57/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET INCLUDE=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n    SET PATH=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\;D:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=d:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=d:/ProgramData/Anaconda3/lib/site-packages\r\n    SET TEMP=d:\\T\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TF_NEED_TENSORRT=0\r\n    SET TMP=d:\\T\r\n  d:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/grpc /Ibazel-out/x64_windows-opt/genfiles/external/grpc /Ibazel-out/x64_windows-opt/bin/external/grpc /Iexternal/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb /Iexternal/boringssl /Ibazel-out/x64_windows-opt/genfiles/external/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/cub_archive /Ibazel-out/x64_windows-opt/genfiles/external/cub_archive /Ibazel-out/x64_windows-opt/bin/external/cub_archive /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/lmdb /Ibazel-out/x64_windows-opt/genfiles/external/lmdb /Ibazel-out/x64_windows-opt/bin/external/lmdb /Iexternal/icu /Ibazel-out/x64_windows-opt/genfiles/external/icu /Ibazel-out/x64_windows-opt/bin/external/icu /Iexternal/org_sqlite /Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/org_sqlite /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Iexternal/gemmlowp /Ibazel-out/x64_windows-opt/genfiles/external/gemmlowp /Ibazel-out/x64_windows-opt/bin/external/gemmlowp /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cupti_headers_virtual /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/numpy_include /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/grpc/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/include /Ibazel-out/x64_windows-opt/bin/external/grpc/include /Iexternal/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/genfiles/external/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/bin/external/icu/icu4c/source/common /Iexternal/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DSQLITE_OMIT_DEPRECATED /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/python/_objs/_pywrap_tensorflow_internal.so/pywrap_tensorflow_internal.o /c bazel-out/x64_windows-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nThe command line is too long.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 59.695s, Critical Path: 1.75s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully", "@faerysword,\r\nTensorFlow v1.14 is not actively supported. Could you please update TensorFlow to v2.3 and check if you are facing the same issue. \r\n\r\nAlso, please provide the exact sequence of commands/complete code you have executed before running into this issue. Thanks!", "@amahendrakar\uff0c\r\nI turn to tf 1.15 and meet some similar errors as I provide above, also \"The command line is too long\".\r\nI use \"Developer Command Prompt for VS 2017\" to run commands, is MSYS2 no such problems?\r\n\r\n**The sequence of commands:**\r\ncmd.exe \"/K\" D:\\ProgramData\\Anaconda3\\Scripts\\activate.bat\r\nd:\r\ncd \\\r\ncd x15/tensorflow\r\nconda activate x15\r\nbazel --output_user_root=d:/o5 build  --config=opt --config=cuda --copt=-nvcc_options=disable-warnings --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n=============\r\n**Here's the .tf_configure.bazelrc, I add TF_CUDA_VERSION and TF_CUDNN_VERSION manually to solve some problems, is there any thing needing to add too ??:**\r\nbuild --action_env PYTHON_BIN_PATH=\"d:/ProgramData/Anaconda3/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"d:/ProgramData/Anaconda3/lib/site-packages\"\r\nbuild --python_path=\"d:/ProgramData/Anaconda3/python.exe\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,7.0\"\r\nbuild --action_env TF_CUDA_VERSION=\"10.0\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --config=cuda\r\nbuild:opt --copt=/arch:AVX\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --config monolithic\r\nbuild --copt=-w --host_copt=-w\r\nbuild --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI\r\nbuild --verbose_failures\r\nbuild --distinct_host_configuration=false\r\nbuild --define=override_eigen_strong_inline=true\r\nbuild:v2 --define=tf_api_version=2\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-no_windows,-gpu\r\ntest --build_tag_filters=-no_windows,-gpu\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n\r\n=================================\r\n**ERRORS IN TF 1.15:**\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:406:1: C++ compilation of rule '//tensorflow/core/distributed_runtime/rpc:grpc_session' failed (Exit 1): python.exe failed: error executing command\r\n  cd D:/o5/vtdphgt7/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET INCLUDE=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n    SET PATH=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\;D:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=d:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=d:/ProgramData/Anaconda3/lib/site-packages\r\n    SET TEMP=d:\\T\r\n    SET TF2_BEHAVIOR=0\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=d:\\T\r\n  d:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/grpc /Ibazel-out/x64_windows-opt/genfiles/external/grpc /Ibazel-out/x64_windows-opt/bin/external/grpc /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb /Iexternal/boringssl /Ibazel-out/x64_windows-opt/genfiles/external/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/cub_archive /Ibazel-out/x64_windows-opt/genfiles/external/cub_archive /Ibazel-out/x64_windows-opt/bin/external/cub_archive /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/lmdb /Ibazel-out/x64_windows-opt/genfiles/external/lmdb /Ibazel-out/x64_windows-opt/bin/external/lmdb /Iexternal/icu /Ibazel-out/x64_windows-opt/genfiles/external/icu /Ibazel-out/x64_windows-opt/bin/external/icu /Iexternal/org_sqlite /Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cupti_headers_virtual /Iexternal/grpc/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/include /Ibazel-out/x64_windows-opt/bin/external/grpc/include /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/genfiles/external/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/bin/external/icu/icu4c/source/common /Iexternal/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DSQLITE_OMIT_DEPRECATED /showIncludes /MD /O2 /DNDEBUG -w -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/core/distributed_runtime/rpc/_objs/grpc_session/grpc_session.o /c tensorflow/core/distributed_runtime/rpc/grpc_session.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nThe command line is too long.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 842.272s, Critical Path: 478.65s\r\nINFO: 307 processes: 307 local.\r\nFAILED: Build did NOT complete successfully\r\n-------------------------------------------------\r\n\r\n\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/python/eager/BUILD:13:1: C++ compilation of rule '//tensorflow/python/eager:pywrap_tfe_lib' failed (Exit 1): python.exe failed: error executing command\r\n  cd D:/o5/vtdphgt7/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET INCLUDE=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n    SET PATH=d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\;D:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=d:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=d:/ProgramData/Anaconda3/lib/site-packages\r\n    SET TEMP=d:\\T\r\n    SET TF2_BEHAVIOR=0\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=d:\\T\r\n  d:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/grpc /Ibazel-out/x64_windows-opt/genfiles/external/grpc /Ibazel-out/x64_windows-opt/bin/external/grpc /Iexternal/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb /Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb /Iexternal/boringssl /Ibazel-out/x64_windows-opt/genfiles/external/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/cub_archive /Ibazel-out/x64_windows-opt/genfiles/external/cub_archive /Ibazel-out/x64_windows-opt/bin/external/cub_archive /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/lmdb /Ibazel-out/x64_windows-opt/genfiles/external/lmdb /Ibazel-out/x64_windows-opt/bin/external/lmdb /Iexternal/icu /Ibazel-out/x64_windows-opt/genfiles/external/icu /Ibazel-out/x64_windows-opt/bin/external/icu /Iexternal/org_sqlite /Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite /Ibazel-out/x64_windows-opt/bin/external/org_sqlite /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cupti_headers_virtual /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/grpc/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/include /Ibazel-out/x64_windows-opt/bin/external/grpc/include /Iexternal/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting/include /Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/png_archive /Ibazel-out/x64_windows-opt/genfiles/external/png_archive /Ibazel-out/x64_windows-opt/bin/external/png_archive /Iexternal/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/genfiles/external/icu/icu4c/source/common /Ibazel-out/x64_windows-opt/bin/external/icu/icu4c/source/common /Iexternal/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/extras/CUPTI/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/numpy_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/numpy_include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DSQLITE_OMIT_DEPRECATED /showIncludes /MD /O2 /DNDEBUG -w -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/python/eager/_objs/pywrap_tfe_lib/pywrap_tensor.o /c tensorflow/python/eager/pywrap_tensor.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nThe command line is too long.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 243.833s, Critical Path: 65.89s\r\nINFO: 585 processes: 585 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "**I set \"LongPathsEnabled\" to 1, it seems sovle some errors maybe. But after 8514.973s building, got the same problem, some of them listed below. How to modify the BUILD files to avoid the too long command line?:**\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/python/BUILD:4894:1: C++ compilation of rule '//tensorflow/python:tf_session_helper' failed (Exit 1): python.exe failed: error executing command\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/python/BUILD:393:1: C++ compilation of rule '//tensorflow/python:py_func_lib' failed (Exit 1): python.exe failed: error executing command\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:406:1: C++ compilation of rule '//tensorflow/core/distributed_runtime/rpc:grpc_session' failed (Exit 1): python.exe failed: error executing command\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/c/BUILD:247:1: C++ compilation of rule '//tensorflow/c:c_api_experimental' failed (Exit 1): python.exe failed: error executing command\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/python/BUILD:4935:1: C++ compilation of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): python.exe failed: error executing command\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/python/BUILD:4847:1: C++ compilation of rule '//tensorflow/python:cpp_shape_inference' failed (Exit 1): python.exe failed: error executing command\r\n\r\nERROR: D:/x15/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:279:1: C++ compilation of rule '//tensorflow/core/distributed_runtime/rpc:grpc_server_lib' failed (Exit 1): python.exe failed: error executing command", "The too long command line has lots of pathes, some of them seems useless and some of them even duplicated, such as **/Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive** :\r\n\r\nd:/ProgramData/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 \r\n/I. \r\n/Ibazel-out/x64_windows-opt/genfiles \r\n/Ibazel-out/x64_windows-opt/bin \r\n/Iexternal/com_google_absl \r\n/Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl \r\n/Ibazel-out/x64_windows-opt/bin/external/com_google_absl \r\n/Iexternal/eigen_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/eigen_archive \r\n/Iexternal/local_config_sycl \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_sycl \r\n/Iexternal/nsync \r\n/Ibazel-out/x64_windows-opt/genfiles/external/nsync \r\n/Ibazel-out/x64_windows-opt/bin/external/nsync \r\n/Iexternal/gif_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/gif_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/gif_archive \r\n/Iexternal/jpeg \r\n/Ibazel-out/x64_windows-opt/genfiles/external/jpeg \r\n/Ibazel-out/x64_windows-opt/bin/external/jpeg \r\n/Iexternal/com_google_protobuf \r\n/Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf \r\n/Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf \r\n/Iexternal/com_googlesource_code_re2 \r\n/Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 \r\n/Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 \r\n/Iexternal/farmhash_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/farmhash_archive \r\n/Iexternal/fft2d \r\n/Ibazel-out/x64_windows-opt/genfiles/external/fft2d \r\n/Ibazel-out/x64_windows-opt/bin/external/fft2d \r\n/Iexternal/highwayhash \r\n/Ibazel-out/x64_windows-opt/genfiles/external/highwayhash \r\n/Ibazel-out/x64_windows-opt/bin/external/highwayhash \r\n/Iexternal/zlib_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/zlib_archive \r\n/Iexternal/double_conversion \r\n/Ibazel-out/x64_windows-opt/genfiles/external/double_conversion \r\n/Ibazel-out/x64_windows-opt/bin/external/double_conversion \r\n/Iexternal/snappy \r\n/Ibazel-out/x64_windows-opt/genfiles/external/snappy \r\n/Ibazel-out/x64_windows-opt/bin/external/snappy \r\n/Iexternal/local_config_cuda \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda \r\n/Iexternal/local_config_tensorrt \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_tensorrt \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt \r\n/Iexternal/local_config_python \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_python \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_python \r\n/Iexternal/grpc \r\n/Ibazel-out/x64_windows-opt/genfiles/external/grpc \r\n/Ibazel-out/x64_windows-opt/bin/external/grpc \r\n/Iexternal/com_github_nanopb_nanopb \r\n/Ibazel-out/x64_windows-opt/genfiles/external/com_github_nanopb_nanopb \r\n/Ibazel-out/x64_windows-opt/bin/external/com_github_nanopb_nanopb \r\n/Iexternal/boringssl \r\n/Ibazel-out/x64_windows-opt/genfiles/external/boringssl \r\n/Ibazel-out/x64_windows-opt/bin/external/boringssl \r\n/Iexternal/mkl_dnn \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn \r\n/Iexternal/jsoncpp_git \r\n/Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git \r\n/Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git \r\n/Iexternal/cub_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/cub_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/cub_archive \r\n/Iexternal/png_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/png_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/png_archive \r\n/Iexternal/lmdb \r\n/Ibazel-out/x64_windows-opt/genfiles/external/lmdb \r\n/Ibazel-out/x64_windows-opt/bin/external/lmdb \r\n/Iexternal\r\n/Icu \r\n/Ibazel-out/x64_windows-opt/genfiles/external\r\n/Icu \r\n/Ibazel-out/x64_windows-opt/bin/external\r\n/Icu \r\n/Iexternal/org_sqlite \r\n/Ibazel-out/x64_windows-opt/genfiles/external/org_sqlite \r\n/Ibazel-out/x64_windows-opt/bin/external/org_sqlite \r\n/Iexternal/gemmlowp \r\n/Ibazel-out/x64_windows-opt/genfiles/external/gemmlowp \r\n/Ibazel-out/x64_windows-opt/bin/external/gemmlowp \r\n/Iexternal/flatbuffers \r\n/Ibazel-out/x64_windows-opt/genfiles/external/flatbuffers \r\n/Ibazel-out/x64_windows-opt/bin/external/flatbuffers \r\n/Iexternal/local_config_mlir \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_mlir \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_mlir \r\n/Iexternal/llvm \r\n/Ibazel-out/x64_windows-opt/genfiles/external/llvm \r\n/Ibazel-out/x64_windows-opt/bin/external/llvm \r\n/Iexternal/bazel_tools \r\n/Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools \r\n/Ibazel-out/x64_windows-opt/bin/external/bazel_tools \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cupti_headers_virtual \r\n/Ibazel-out/x64_windows-opt/bin/external/cub_archive/_virtual_includes/cub \r\n/Iexternal/eigen_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/eigen_archive \r\n/Iexternal/nsync/public \r\n/Ibazel-out/x64_windows-opt/genfiles/external/nsync/public \r\n/Ibazel-out/x64_windows-opt/bin/external/nsync/public \r\n/Iexternal/gif_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/gif_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/gif_archive \r\n/Iexternal/gif_archive/windows \r\n/Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows \r\n/Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows \r\n/Iexternal/com_google_protobuf/src \r\n/Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src \r\n/Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src \r\n/Iexternal/farmhash_archive/src \r\n/Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src \r\n/Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src \r\n/Iexternal/zlib_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/zlib_archive \r\n/Iexternal/double_conversion \r\n/Ibazel-out/x64_windows-opt/genfiles/external/double_conversion \r\n/Ibazel-out/x64_windows-opt/bin/external/double_conversion \r\n/Iexternal/local_config_cuda/cuda \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda \r\n/Iexternal/local_config_cuda/cuda/cuda\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda\r\n/Include \r\n/Iexternal/local_config_python/numpy_include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/numpy_include \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_python/numpy_include \r\n/Iexternal/local_config_python/python_include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_python/python_include \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include \r\n/Iexternal/local_config_cuda/cuda/cublas\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas\r\n/Include \r\n/Iexternal/grpc\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/grpc\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/grpc\r\n/Include \r\n/Iexternal/grpc/third_party/address_sorting\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/grpc/third_party/address_sorting\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/grpc/third_party/address_sorting\r\n/Include \r\n/Iexternal/boringssl/src\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/boringssl/src\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/boringssl/src\r\n/Include \r\n/Iexternal/mkl_dnn\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn\r\n/Include \r\n/Iexternal/mkl_dnn/src \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src \r\n/Iexternal/mkl_dnn/src/common \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common \r\n/Iexternal/mkl_dnn/src/cpu \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu \r\n/Iexternal/mkl_dnn/src/cpu/gemm \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm \r\n/Iexternal/mkl_dnn/src/cpu/xbyak \r\n/Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak \r\n/Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak \r\n/Iexternal/local_config_cuda/cuda/cuda/extras/CUPTI\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/extras/CUPTI\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/extras/CUPTI\r\n/Include \r\n/Iexternal/jsoncpp_git\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/jsoncpp_git\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git\r\n/Include \r\n/Iexternal/png_archive \r\n/Ibazel-out/x64_windows-opt/genfiles/external/png_archive \r\n/Ibazel-out/x64_windows-opt/bin/external/png_archive \r\n/Iexternal\r\n/Icu\r\n/Icu4c/source/common \r\n/Ibazel-out/x64_windows-opt/genfiles/external\r\n/Icu\r\n/Icu4c/source/common \r\n/Ibazel-out/x64_windows-opt/bin/external\r\n/Icu\r\n/Icu4c/source/common \r\n/Itensorflow/lite/schema \r\n/Ibazel-out/x64_windows-opt/genfiles/tensorflow/lite/schema \r\n/Ibazel-out/x64_windows-opt/bin/tensorflow/lite/schema \r\n/Iexternal/flatbuffers\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/flatbuffers\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/flatbuffers\r\n/Include \r\n/Iexternal/local_config_mlir\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/local_config_mlir\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/local_config_mlir\r\n/Include \r\n/Iexternal/llvm\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/external/llvm\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/external/llvm\r\n/Include \r\n/Itensorflow/compiler/mlir/tensorflow\r\n/Include \r\n/Ibazel-out/x64_windows-opt/genfiles/tensorflow/compiler/mlir/tensorflow\r\n/Include \r\n/Ibazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/tensorflow\r\n/Include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /DGRPC_ARES=0 /DPB_FIELD_32BIT=1 /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DSQLITE_OMIT_DEPRECATED /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_CRT_NONSTDC_NO_DEPRECATE /D_CRT_NONSTDC_NO_WARNINGS /D_SCL_SECURE_NO_DEPRECATE /D_SCL_SECURE_NO_WARNINGS /DUNICODE /D_UNICODE /DLLVM_ENABLE_STATS /D__STDC_LIMIT_MACROS /D__STDC_CONSTANT_MACROS /D__STDC_FORMAT_MACROS /DLLVM_BUILD_GLOBAL_ISEL /DTFLITE_BUILD_WITH_MLIR_CONVERTER /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/python/_objs/_pywrap_tensorflow_internal.so/pywrap_tensorflow_internal.o /c bazel-out/x64_windows-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc", "The command \"python configure.py\" can not configure everything, even the promot from this command such as \"--config=noaws\" is not supported at least on win10. Modify .tf_configure.bazelrc yourself, and disable some features not necessary, and then the duplicated command line may not too long.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42601\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42601\">No</a>\n"]}, {"number": 42600, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"g:/Gaze_Dl/fast1.py\", line 6, in <module>\r\n    from tensorflow.keras.models import load_model\r\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Acer\\anaconda3\\envs\\mytfenv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["@kamal2019 \r\n\r\nYou might be facing this issue because of the following reasons\r\n\r\n- You are running 32-bit Python\r\n- Your CPU does not support AVX instructions. Please share the make and model of your CPU, so that we can verify this.\r\n- Please take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n- You need to install the MSVC 2019 redistributable\r\n- There is a library that is in a different location/not installed on your system that cannot be loaded.\r\n\r\nAlso, check these resolved duplicate issues: #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204.\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42600\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42600\">No</a>\n"]}, {"number": 42599, "title": "Fix a bug that the file copied by TF from HDFS to local may be wrong,\u2026", "body": "This is a PR from TaiJi AI platform in Tencent.\r\n\r\nThe file copied by TF from HDFS to local may be wrong, when HDFS file is being overwritten, may be a better way [#42597](https://github.com/tensorflow/tensorflow/issues/42597)\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42599) for more info**.\n\n<!-- need_sender_cla -->", "@yuanbopeng Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42599) for more info**.\n\n<!-- ok -->", "> I don't like that we are removing a test. The test was added to prevent a bug regression\r\n@mihaimaruseac \r\nThanks for the comments. Deleted the test case of data in the file append scene. Because I think that the latest data should not be obtained in READ through the new file handle. This method works well in the file append scenario, but it may cause the file to be wrong when the file is overwritten. Please refer to [the reply](https://github.com/tensorflow/tensorflow/issues/42597#issuecomment-679463880) for more", "This problem is fixed by [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)."]}, {"number": 42598, "title": "Fix a bug that the file copied by TF from HDFS to local may be wrong,\u2026", "body": "This is a PR from TaiJi AI platform in Tencent.\r\n\r\n- The file copied by TF from HDFS to local may be wrong, when HDFS file is being overwritten [#42597](https://github.com/tensorflow/tensorflow/issues/42597)\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42598) for more info**.\n\n<!-- need_sender_cla -->", "@yuanbopeng  Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42598) for more info**.\n\n<!-- ok -->", "@googlebot I signed it!", "@mihaimaruseac Can you help review the code\uff1f In the HDFS scenario, [FileSystemCopyFile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/env.cc#L466) adapted to avoid triggering [HDFSRandomAccessFile READ reopen](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L255).", "@yuanbopeng  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "This problem is fixed by [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)."]}, {"number": 42597, "title": "[Bug]The file copied by TF from HDFS to local may be wrong, when HDFS file is being overwritten", "body": "This is a issue from TaiJi AI platform in Tencent.\r\n\r\n**System information**\r\n- OS Platform and Distribution : Linux version 4.14.105-1-tlinux3-0010\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.13.1\uff08we use\uff09and the latest version also has this problem\r\n- Python version: 3.6\r\n- C++ version: 11\r\n\r\n**Describe the current behavior**\r\nOur training sample data is generated by the spark program and stored on HDFS, an example of a training sample file: `hdfs://xxxx/example/20200822/part-r-0000036.tfr.gz`, and the file data is compressed by gzip.\r\nThe trigger condition of the training program is that the `_SUCCESS` file appears under `hdfs://xxxx/example/20200822/`. The training program first downloads the training samples on HDFS to the local, and then reads the local data for training. When the training program and the spark program are running at the same time, the downloaded HDFS file may be overwritten by the spark program, causing the gzip file downloaded to the local to be damaged. Once the gzip file is wrong, our tensorflow training program will always stay unzipped, and the CPU utilization rate is high. \r\nThe wrong local gzip file is composed of part of the data of the HDFS file before and after overwriting.\r\n\r\ncode:\r\n```\r\n auto env = tensorflow::Env::Default();\r\n auto st = env->CopyFile(src_file, des_file);\r\n```\r\nprocess pstack info\uff1a\r\n![image](https://user-images.githubusercontent.com/70072713/90976846-30be5080-e573-11ea-9f02-dace76b15584.png)\r\ntop info:\r\n![image](https://user-images.githubusercontent.com/70072713/90976850-3fa50300-e573-11ea-90bf-56ccf06172c7.png)\r\n\r\n**Describe the expected behavior**\r\nThe local gzip file is consistent with the data of the HDFS file before overwriting, or the data of the HDFS file after overwriting, instead of containing the data of the HDFS file before and after overwriting\r\n\r\n**issues analysis**\r\nIn order to solve the [issue:5438](https://github.com/tensorflow/tensorflow/issues/5438) that the tensorboard needs to get the latest data written, the HDFS file is reopened in [the HDFSRandomAccessFile Read](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L226): when n>0 r=0, call hdfsOpenFile to reopen the HDFS file. Please refer to this [commit](https://github.com/tensorflow/tensorflow/commit/e6e8d8715552d8890c0dd10f49ec3dff931a9926) for details.\r\nBefore calling hdfsOpenFile, if the HDFS file is overwritten, a new HDFS file is generated.\r\nAfter calling hdfsOpenFile, it will point to the new HDFS file. If the size of the new HDFS file is larger than the size of the old HDFS file, the HDFS file copied to the local file system by FileSystemCopyFile contains part of the data of the new and old HDFS files, causing the local gzip file to be wrong\r\n\r\n**temp solution**: [patch-1](https://github.com/tensorflow/tensorflow/pull/42598)\r\n[FileSystemCopyFile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/env.cc#L466) avoids triggering the hdfsOpenFile operation of the HDFSRandomAccessFile Read. The size of the file copy is based on the file size, not based on kCopyFileBufferSize. The implementation principle of the temporary solution is the same as that of [ReadFileToString](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/env.cc#L423), but it is still possible that the file copied to the local file is wrong. Because `GetFileSize` and `READ` cannot form an atomic operation. For example, when the file size is obtained through GetFileSize, the HDFS file is overwritten, and the data of the new file is read based on the size of the old file. However, the possibility that the local file of the temporary solution is wrong is far less than the original solution. Generally speaking, reading the file data to the end of the file is a time-consuming operation, and the time-consuming operation of obtaining the file size is negligible\r\n\r\n**may be a better solution**: [patch-2](https://github.com/tensorflow/tensorflow/pull/42599)\r\nI'm not sure if this solution is a better solution. In some scenarios I don't know, it may require further discussion. RandomAccessFile READ is an abstraction of the operations supported by each file system, and the specific implementation is transparent to users. Adding the `hdfsOpenFile` to the [HDFSRandomAccessFile READ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L226) to read the latest data is a hidden and dangerous behavior. Because hdfsOpenFile may point to new files, data inconsistencies may occur. More fatally, there are a large number of methods that depend on the READ, which may cause some behaviors that are not what we expect, which is the root of all errors. I think it is better for users to use READ and REOPEN to obtain the latest data in the program.\r\n\r\n**accepted solution**: [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)\r\nQuoting mihaimaruseac's comment:\r\n```\r\nPatch-1 has the issue of breaking separation of concern design principles (what happens if there is a new scheme for hdfs? We would have a bug in there until someone remembers the additional if). \r\nPatch-2 has the issue of removing a test that was added for creating a bug.\r\n```\r\nIn order to overcome the shortcomings of patch-1 and patch-2, a switch is added to [patch-3](https://github.com/tensorflow/tensorflow/pull/42860),  the default HDFS_DISABLE_READ_EOF_RETRIED is false. [patch-3](https://github.com/tensorflow/tensorflow/pull/42860) will not remove the [WriteWhileReading](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system_test.cc#L202) test case, and it can also solve the problem we encountered. If you need to turn off the HDFS_READ_EOF_RETRIED, set the environment variable:\r\n ```\r\nsource HDFS_DISABLE_READ_EOF_RETRIED=1\r\n```\r\nFor more details, please refer to the comments below.\r\n", "comments": ["I think this is an issue that can be solved by [the transaction support introduced by the new RFC](https://github.com/tensorflow/community/pull/245)", "@mihaimaruseac Thanks for the first  comment. I think this issue may have nothing to do with the transaction. Because adding `REOPEN` to [READ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L226) may have destroyed the semantics of HDFS `READ` and easily leads to program execution errors. Especially, `READ` is [the low level filesystem API](https://github.com/tensorflow/community/blob/9c248b5603256c0641a05dd202adb2942c8af500/rfcs/20190506-filesystem-plugin-modular-tensorflow.md#low-level-filesystem-api), users will not know that this will be different from HDFS READ.\r\n\r\nThe reopen operation is added to [HDFSRandomAccessFile READ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L226)  to solve the problem of reading the latest data in the [issue:5438](https://github.com/tensorflow/tensorflow/issues/5438). I think that the reopen operation should not be added to [the low level filesystem API](https://github.com/tensorflow/community/blob/9c248b5603256c0641a05dd202adb2942c8af500/rfcs/20190506-filesystem-plugin-modular-tensorflow.md#low-level-filesystem-api), and it should be consistent with the HDFS file system. Because this has destroyed the semantics of READ provided by HDFS, **READ reads data through the current file handle, not through a specific file name.** If the file is just appended, this will work very well, like adding a retry to read, and getting the latest data through a new file handle. But the file is overwritten, and the data read may be wrong.**(The data read is a mixture of before and after the overwritten file)**\r\n\r\nFurthermore, I think it is more reasonable to implement HDFS's `WriteWhileReading` feature to read the latest data in the convenience API or the application layer utils API.\r\n\r\n![image](https://user-images.githubusercontent.com/70072713/91115229-573bd300-e6bc-11ea-8c9f-04ed27005a9e.png)\r\n", "One more, my understanding about [the transaction support introduced by the new RFC](https://github.com/tensorflow/community/pull/245) I have read.\r\nAs [vnno2409 commented](https://github.com/tensorflow/community/pull/245#issuecomment-628380634), HDFS does not support transaction, and transaction require file system support, such as s3 or gcs. Therefore, to less intrusive, [Moving rest of the filesystems to Transactional API about HDFS](https://github.com/tensorflow/tensorflow/pull/42050/commits/46a8319ee74337182c7aadf80acbeb7f01eb7ffd) only pass the transaction parameters, and there is no transaction implementation.\r\nBecause HDFS does not support transactions, I think the reopen method is used in [the HDFS read method](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L255) to support simultaneous reading and writing scenarios, and data accuracy cannot be guaranteed. We should circumvent this [read implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L226), which undermines the semantics provided by HDFS and causes the read data to be wrong.\r\n\r\nFinally, because this question is very important to us, I look forward to @mihaimaruseac  your comments, thanks :).", "So the big issue is that the PRs remove an existing test that was added for a different issue. This is not good, we should not break existing behavior if possible.\r\n\r\nFrom what I gather, you want to support the scenario where you started reading from a file but it got overwritten. This is a classic TOCTOU scenario, not even POSIX handles it by itself:\r\n\r\n```c\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <unistd.h>\r\n\r\nint main() {\r\n\tFILE *f = fopen(\"file\", \"r\");\r\n\tchar buffer[10];\r\n\tfgets(buffer, 10, f);\r\n\tprintf(\"Got \\\"%s\\\"\\n\", buffer);\r\n\tsleep(10);\r\n\tfgets(buffer, 10, f);\r\n\tprintf(\"Got \\\"%s\\\"\\n\", buffer);\r\n\treturn 0;\r\n}\r\n```\r\n\r\n```console\r\n[mm] \u03bb gcc -Wall -Wextra test.c -o ./test\r\n[mm] \u03bb echo \"asdf\" > file\r\n[mm] \u03bb ./test \r\nGot \"asdf\r\n\"\r\nGot \"asdf\r\n\"\r\n```\r\n\r\nvs with overwriting the file during the 10s sleep:\r\n\r\n```console\r\n[mm] \u03bb ./test \r\nGot \"asdf\r\n\"\r\nGot \"fghijklmn\"\r\n```\r\n\r\nvs appending to the file\r\n\r\n```console\r\n[mm] \u03bb ./test \r\nGot \"asdf\r\n\"\r\nGot \"abcdefghi\"\r\n```\r\n\r\nI think that if we want to handle these scenarios we need to add transaction support to the filesystem implementation. Even if HDFS itself does not support transactions, we can add this layer as a middleware on top of it.", "@mihaimaruseac \r\nOk. I agree with you that to solve this problem and delete the test may cause other issues. Therefore, [patch-1](https://github.com/tensorflow/tensorflow/pull/42598) may be better. According to your suggestionIn, in the HDFS scenario, [FileSystemCopyFile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/env.cc#L466) adapted to avoid calling [HDFSRandomAccessFile READ reopen](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L255).\r\n\r\nIn addition, I made some modifications and tests based on your POSIX test example, and I am not sure whether my conclusion is the same as yours. In POSIX, the appended data can be read, but the overwritten data cannot be read; but in HDFS read with reopen, both the appended data and the overwritten data can be read. The read data is a mixture before and after the overwrite file.\r\n\r\n```c\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <unistd.h>\r\n\r\nint main() {\r\n\tFILE *f = fopen(\"file\", \"r\");\r\n\tchar buffer[10];\r\n\tchar *first = fgets(buffer, 10, f);\r\n        printf(\"Got \\\"%s\\\"\\n\", first);\r\n\tsleep(20);\r\n\tchar *second = fgets(buffer, 10, f);\r\n        printf(\"Got \\\"%s\\\"\\n\", second);\r\n\treturn 0;\r\n}\r\n```\r\n```\r\n$ echo \"asdf\" > file\r\n$ ./test_read\r\nGot \"asdf\r\n\"\r\nGot \"(null)\"\r\n```\r\nvs with overwriting the file during the 20s sleep:\r\n```\r\n./test_read\r\nGot \"aaa\r\n\"\r\nGot \"(null)\"\r\n```\r\n\r\n```\r\n$ echo \"aaa\" > file\r\n--------during the 20s sleep--------\r\n$ echo \"bbb\" > file\r\n$ cat file\r\nbbb\r\n```\r\n\r\nvs appending to the file during the 20s sleep:\r\n```\r\n./test_read\r\nGot \"aaa\r\n\"\r\nGot \"bbb\r\n\"\r\n```\r\n```\r\n$ echo \"aaa\" > file\r\n--------during the 20s sleep--------\r\n$ echo \"bbb\" >> file\r\n$ cat file\r\naaa\r\nbbb\r\n```", "@mihaimaruseac \r\nSince I did not receive your comment, it may be because my previous reply was not clear enough. Let me add one more thing. \r\n\r\nI think [patch-1](https://github.com/tensorflow/tensorflow/pull/42598) can solve the problem of copying the file being overwritten, **and the existing test will not be removed**. Because the bug of reading the overwritten file is caused by calling  [reopen](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L255). The size of the copied HDFS file is determined. You can avoid calling  [reopen](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L255) by passing the size, and solve the bug of reading the overwritten file. In addition, I think [patch-1](https://github.com/tensorflow/tensorflow/pull/42598) will not add additional issues, because [patch-1](https://github.com/tensorflow/tensorflow/pull/42598) only restricts the copy scenario from reading appended data. The copied file is similar to a snapshot file and should not be modified. So if you want to read additional data in real time, it is strange to use the copy method.\r\n\r\nThe problem I want to solve is to avoid reading data from the overwritten file when copying the HDFS file. I think the biggest problem I need to emphasize is that **POSIX will not read the overwritten file, but the [HDFS read API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L226) encapsulated by tensorflow will read the overwritten file**. The original [libhdfs](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/LibHdfs.html) read does not support reading the content of the appended file. Tensorflow uses [reopen](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L255) to read the appended file, but it will cause the overwritten file to be read. If the file is being overwritten, the final read data is wrong, mixing the file data before and after overwriting. Therefore, we need to fix it urgently. For details, please refer to the previous comment. \r\n\r\nCan you help review the [patch-1](https://github.com/tensorflow/tensorflow/pull/42598)? I look forward to @mihaimaruseac your comments, thanks :).", "We have the exact same test for POSIX behavior with exactly the same results.\r\n\r\nPOSIX reads from the overwritten file, from the current cursor position.\r\n\r\nThis should be solved via transaction support, I think. Patch-1 has the issue of breaking separation of concern design principles (what happens if there is a new scheme for hdfs? We would have a bug in there until someone remembers the additional if). Patch-2 has the issue of removing a test that was added for creating a bug.\r\n\r\nIf anything, I'd prefer patch 2 to patch 1 but I'd prefer adding transactional support instead of either of the two patches.", "@mihaimaruseac  \r\nI want to confirm that the `via transaction support ` here means: to migrate data from HDFS to the transaction file system, and then read and write data from the transaction file system to avoid the problem of overwritten files?\r\n\r\nIf not, maybe I misunderstood what you mean. Can you show me specific HDFS examples?  If it is, it may not be suitable for solving our issue, because all our training data is stored on HDFS, it is almost impossible for us to switch other transaction file systems. And our data volume is very huge, at least petabytes or more, storing in HDFS is a better choice.\r\n [Reading EOF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L260) will try to open the file again. This is a serious bug in our scenario. For details, please refer to the previous comment.\r\n\r\nHow about [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)? \r\nIn order to overcome the shortcomings of patch-1 and patch-2, a switch is added to [patch-3](https://github.com/tensorflow/tensorflow/pull/42860),  the default DISABLE_HDFS_READ_EOF_RETRIED is false. [patch-3](https://github.com/tensorflow/tensorflow/pull/42860) will not remove the [WriteWhileReading](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system_test.cc#L202) test case, and it can also solve the problem we encountered. If you need to turn off the HDFS_READ_EOF_RETRIED, set the environment variable:\r\n ```\r\nsource DISABLE_HDFS_READ_EOF_RETRIED=1\r\n```\r\n\r\nCan you help review [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)? I look forward to @mihaimaruseac your comments, thanks :).\r\n\r\n", "@mihaimaruseac \r\nUpdate [patch-3](), refer to the naming of [S3_DISABLE_MULTI_PART_DOWNLOAD](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L482), `DISABLE_HDFS_READ_EOF_RETRIED ` was renamed to `HDFS_DISABLE_READ_EOF_RETRIED`.\r\n\r\nCan you help review [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)? I look forward to @mihaimaruseac  your comments, thanks :).\r\n", "> @mihaimaruseac\r\n> I want to confirm that the `via transaction support ` here means: to migrate data from HDFS to the transaction file system, and then read and write data from the transaction file system to avoid the problem of overwritten files?\r\n\r\nI meant submitting a patch to convert the HDFS support to https://github.com/tensorflow/community/pull/245.\r\n\r\n> \r\n> If not, maybe I misunderstood what you mean. Can you show me specific HDFS examples? If it is, it may not be suitable for solving our issue, because all our training data is stored on HDFS, it is almost impossible for us to switch other transaction file systems. And our data volume is very huge, at least petabytes or more, storing in HDFS is a better choice.\r\n\r\nYou won't need to change your data storage. All I am saying is that the best fix here is to implement transaction support to HDFS layer in TF.\r\n\r\n> Can you help review [patch-3](https://github.com/tensorflow/tensorflow/pull/42860)? I look forward to @mihaimaruseac your comments, thanks :).\r\n\r\nLooking over the patch now", "> You won't need to change your data storage. All I am saying is that the best fix here is to implement transaction support to HDFS layer in TF.\r\n\r\n@mihaimaruseac Thank you so much for your reply, I figured out your suggestion. Our disagreement may be that I think that HDFS itself has no transactions, so it is impossible to implement transactions on Tensorflow side. I am not sure if you have more information to prove that it is possible to implement transactions on the Tensorflow side. If so, can you share it?\r\n\r\n I look forward to @mihaimaruseac your comments, thanks :).\r\n", "Basically, what you are doing with the retries is a component of transactions. TF could use the transaction token to know when to do the transaction retry, in all operations. A transaction is nothing more than a set of files which either all change at the same time or not.\r\n\r\nIn the end, it's the same as how TCP protocol is implemented over the IP protocol. TCP is connection oriented, requires handshakes, checksums, has a lot of flow control. IP has none of these, is just best-effort. The TCP implementation contains all the code needed to implement the additional layers. Contrast with UDP which just encapsulates the data and throws it over to the IP layer.", "> Basically, what you are doing with the retries is a component of transactions. TF could use the transaction token to know when to do the transaction retry, in all operations. A transaction is nothing more than a set of files which either all change at the same time or not.\r\n\r\n@mihaimaruseac \r\nI have a doubt whether this implementation requires a third-party stateful central service to keep and check the transaction token, or implement it in HDFS NameNode. In addition, the HDFS protocol may also need to support restricting other client processes to read and write files in transactions, etc.\r\n\r\n> In the end, it's the same as how TCP protocol is implemented over the IP protocol. TCP is connection oriented, requires handshakes, checksums, has a lot of flow control. IP has none of these, is just best-effort. The TCP implementation contains all the code needed to implement the additional layers. Contrast with UDP which just encapsulates the data and throws it over to the IP layer.\r\n\r\nAs far as I know, the TCP protocol requires the client and server to implement the TCP protocol. If Tensorflow implements HDFS transaction, I guess Tensorflow is equivalent to the client, but does not sure what the server is?\r\n\r\nI look forward to @mihaimaruseac your comments, thanks :).\r\n", "This has been solved by the third patch", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42597\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42597\">No</a>\n"]}, {"number": 42596, "title": "Protobuf MergeFrom errors when tensorflow and python protobuf share a libprotobuf copy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): master\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source): 3.4.1\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nWhen compiling tensorflow from source against a system installed protobuf with a dynamically linked python protobuf (i.e., tensorflow and python protobuf sharing a single libprotobuf), strange errors occur.\r\n\r\nHere is an example\r\n\r\n```\r\n$ python3 -c \"from tensorflow.keras.applications.resnet50 import ResNet50; model = ResNet50()\"\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.summary API due to missing TensorBoard installation.\r\n2020-08-23 02:12:12.645582: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-23 02:12:12.651545: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3700065000 Hz\r\n2020-08-23 02:12:12.653098: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2478a30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-23 02:12:12.653110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\", line 474, in ResNet50\r\n    return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\", line 171, in ResNet\r\n    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 921, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 2474, in _maybe_build\r\n    self.build(input_shapes)  # pylint:disable=not-callable\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 179, in build\r\n    self.kernel = self.add_weight(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 579, in add_weight\r\n    variable = self._add_variable_with_custom_getter(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 738, in _add_variable_with_custom_getter\r\n    new_variable = getter(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\", line 134, in make_variable\r\n    return tf_variables.VariableV1(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 260, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 206, in _variable_v1_call\r\n    return previous_getter(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 199, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 2583, in default_variable_creator\r\n    return resource_variable_ops.ResourceVariable(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1425, in __init__\r\n    self._init_from_args(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1579, in _init_from_args\r\n    handle = eager_safe_variable_handle(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 242, in eager_safe_variable_handle\r\n    return _variable_handle_from_shape_and_dtype(\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 180, in _variable_handle_from_shape_and_dtype\r\n    cpp_shape_inference_pb2.CppShapeInferenceResult.HandleShapeAndType(\r\nTypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto.\r\n```\r\n\r\nAfter then pip-installing protobuf (i.e., switching to a statically linked python protobuf and introducing a new libprotobuf instance), the error goes away.\r\n\r\n```\r\n$ pip3 install --force --no-deps protobuf\r\nCollecting protobuf\r\n  Using cached protobuf-3.13.0-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\r\nInstalling collected packages: protobuf\r\nSuccessfully installed protobuf-3.13.0\r\n$ python3 -c \"from tensorflow.keras.applications.resnet50 import ResNet50; model = ResNet50()\"\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nWARNING:root:Limited tf.summary API due to missing TensorBoard installation.\r\n2020-08-23 02:25:07.778252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-23 02:25:07.784258: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3700065000 Hz\r\n2020-08-23 02:25:07.785881: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1dc2cc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-23 02:25:07.785894: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorflow and python protobuf should be able to share the same libprotobuf instance.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nSee example above.\r\n\r\n**Other info / logs**\r\n\r\nI was able to bisect the bug back to 5498a3c. Re-adding the line below to `tensorflow/python/__init__.py` appears to resolve the issue, though I have not tested extensively.\r\n```\r\nfrom tensorflow.python import pywrap_tensorflow\r\n```\r\n\r\nNote that you will need #42591 to compile master against a system protobuf install.\r\n\r\n", "comments": ["Here's a dockerfile for testing this configuration. Adjust the arguments as needed.\r\n\r\n```\r\nFROM ubuntu:20.04\r\n\r\nARG bazel_version=3.4.1\r\nARG protobuf_version=3.12.4\r\nARG tensorflow_commit=65da7b8\r\nARG compile_jobs=32\r\n\r\nWORKDIR /tensorflow-test\r\n\r\n# Install build dependencies\r\nRUN apt-get update && \\\r\n        DEBIAN_FRONTEND=noninteractive apt-get install -y \\\r\n                build-essential \\\r\n                autoconf \\\r\n                libtool-bin \\\r\n                zlib1g-dev \\\r\n                unzip \\\r\n                wget \\\r\n                git \\\r\n                openjdk-8-jdk-headless \\\r\n                python-is-python3 \\\r\n                python3-all-dev \\\r\n                python3-setuptools \\\r\n                python3-pip \\\r\n                python3-six \\\r\n                python3-numpy && \\\r\n        rm -rf /var/lib/apt/lists/*\r\n\r\n# Install Bazel 3.4.1\r\nRUN wget https://storage.googleapis.com/bazel-apt/pool/jdk1.8/b/bazel-${bazel_version}/bazel-${bazel_version}_${bazel_version}_amd64.deb && \\\r\n        dpkg -i bazel-*.deb\r\n# Compile and install protobuf\r\nRUN wget -O protobuf-${protobuf_version}.tar.gz \\\r\n                https://github.com/protocolbuffers/protobuf/archive/v${protobuf_version}.tar.gz && \\\r\n        tar xvf protobuf-${protobuf_version}.tar.gz && \\\r\n        cd protobuf-${protobuf_version} && \\\r\n        ./autogen.sh && \\\r\n        ./configure --prefix=/usr && \\\r\n        make -j${compile_jobs} install && \\\r\n        ldconfig && \\\r\n        cd python && \\\r\n        python3 setup.py install --cpp_implementation\r\n\r\n# Install tensorflow python dependencies\r\nRUN pip3 install \\\r\n                absl-py \\\r\n                astunparse \\\r\n                flatbuffers \\\r\n                gast \\\r\n                google-pasta \\\r\n                keras-preprocessing \\\r\n                opt-einsum \\\r\n                wrapt \\\r\n                termcolor\r\n\r\n# Compile and install tensorflow\r\nRUN git clone https://github.com/tensorflow/tensorflow && \\\r\n        cd tensorflow && \\\r\n        git checkout ${tensorflow_commit} && \\\r\n        echo \"build --action_env PYTHON_BIN_PATH=\\\"/usr/bin/python3.8\\\"\" >> .tf_configure.bazelrc && \\\r\n        echo \"build --action_env PYTHON_LIB_PATH=\\\"/usr/lib/python3/dist-packages\\\"\" >> .tf_configure.bazelrc && \\\r\n        echo \"build --python_path=\\\"/usr/bin/python3.8\\\"\" >> .tf_configure.bazelrc && \\\r\n        echo \"build --action_env TF_SYSTEM_LIBS=\\\"com_google_protobuf\\\"\" >> .tf_configure.bazelrc && \\\r\n        bazel-3.4.1 build --jobs=${compile_jobs} //tensorflow/tools/pip_package:build_pip_package && \\\r\n        ./bazel-bin/tensorflow/tools/pip_package/build_pip_package .. && \\\r\n        pip3 install --no-deps ../tensorflow-*.whl\r\n```", "Thank you for detailed instructions and bisecting! I can repro the issue and how it happens due to `pywrap_tensorflow` import removal. I will send a change to re-add it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42596\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42596\">No</a>\n", "I seem to have a similar error since my update from tensorflow 2.4 to 2.5:\r\n```\r\nTraceback (most recent call last):\r\n  File \"./tf_train_inv25.py\", line 706, in <module>\r\n    model = tf.keras.models.Sequential([\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\", line 114, in __init__\r\n    super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 318, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 326, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 244, in _variable_v2_call\r\n    return previous_getter(\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 2662, in default_variable_creator_v2\r\n    return resource_variable_ops.ResourceVariable(\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1584, in __init__\r\n    self._init_from_args(\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1738, in _init_from_args\r\n    handle = eager_safe_variable_handle(\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 237, in eager_safe_variable_handle\r\n    return _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name,\r\n  File \"/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 177, in _variable_handle_from_shape_and_dtype\r\n    cpp_shape_inference_pb2.CppShapeInferenceResult.HandleShapeAndType(\r\nTypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto.\r\n\r\n```\r\n\r\nThis is the line the error occurs which worked fine in tensorflow 2.4:\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Input(shape=(mat_size_aug,mat_size_red,1)),\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(units = out_size,  name=\"dense_out\",\r\n    activation = 'linear', use_bias=False)\r\n])\r\n```", "The ipynb example from https://www.tensorflow.org/tutorials/keras/classification also returns this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-22-16231aa6b55c> in <module>\r\n----> 1 model = tf.keras.Sequential([\r\n      2     tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n      3     tf.keras.layers.Dense(128, activation='relu'),\r\n      4     tf.keras.layers.Dense(10)\r\n      5 ])\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    520     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    521     try:\r\n--> 522       result = method(self, *args, **kwargs)\r\n    523     finally:\r\n    524       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    112     \"\"\"\r\n    113     # Skip the init in FunctionalModel since model doesn't have input/output yet\r\n--> 114     super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call\r\n    115         name=name, autocast=False)\r\n    116     base_layer.keras_api_gauge.get_cell('Sequential').set(True)\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    520     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    521     try:\r\n--> 522       result = method(self, *args, **kwargs)\r\n    523     finally:\r\n    524       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in __init__(self, *args, **kwargs)\r\n    316     self._steps_per_execution = None\r\n    317 \r\n--> 318     self._init_batch_counters()\r\n    319     self._base_model_initialized = True\r\n    320 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    520     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    521     try:\r\n--> 522       result = method(self, *args, **kwargs)\r\n    523     finally:\r\n    524       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _init_batch_counters(self)\r\n    324     # `evaluate`, and `predict`.\r\n    325     agg = variables.VariableAggregationV2.ONLY_FIRST_REPLICA\r\n--> 326     self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n    327     self._test_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n    328     self._predict_counter = variables.Variable(\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    260       return cls._variable_v1_call(*args, **kwargs)\r\n    261     elif cls is Variable:\r\n--> 262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    242     if aggregation is None:\r\n    243       aggregation = VariableAggregation.NONE\r\n--> 244     return previous_getter(\r\n    245         initial_value=initial_value,\r\n    246         trainable=trainable,\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)\r\n    235                         shape=None):\r\n    236     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    239       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)\r\n   2660   shape = kwargs.get(\"shape\", None)\r\n   2661 \r\n-> 2662   return resource_variable_ops.ResourceVariable(\r\n   2663       initial_value=initial_value,\r\n   2664       trainable=trainable,\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n--> 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    265 \r\n    266 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n   1582       self._init_from_proto(variable_def, import_scope=import_scope)\r\n   1583     else:\r\n-> 1584       self._init_from_args(\r\n   1585           initial_value=initial_value,\r\n   1586           trainable=trainable,\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\r\n   1736           else:\r\n   1737             shape = initial_value.shape\r\n-> 1738           handle = eager_safe_variable_handle(\r\n   1739               initial_value=initial_value,\r\n   1740               shape=shape,\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in eager_safe_variable_handle(initial_value, shape, shared_name, name, graph_mode)\r\n    235   \"\"\"\r\n    236   dtype = initial_value.dtype.base_dtype\r\n--> 237   return _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name,\r\n    238                                                graph_mode, initial_value)\r\n    239 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value)\r\n    175     handle_data.is_set = True\r\n    176     handle_data.shape_and_type.append(\r\n--> 177         cpp_shape_inference_pb2.CppShapeInferenceResult.HandleShapeAndType(\r\n    178             shape=shape.as_proto(), dtype=dtype.as_datatype_enum))\r\n    179 \r\n\r\nTypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto.\r\n```"]}]