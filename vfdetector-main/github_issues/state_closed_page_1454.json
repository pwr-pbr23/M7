[{"number": 9336, "title": "tflearn Incorrect Comment", "body": "In the tflearn quick start guide here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/tflearn.md\r\n\r\nBelow the section \"Describe the training input pipeline {#train-input}\"\r\n\r\nThe first snippet:\r\n\r\n```python\r\n# Define the test inputs\r\ndef get_train_inputs():\r\n  x = tf.constant(training_set.data)\r\n  y = tf.constant(training_set.target)\r\n\r\n  return x, y\r\n```\r\n\r\nShould be\r\n\r\n```python\r\n# Define the training inputs\r\ndef get_train_inputs():\r\n  x = tf.constant(training_set.data)\r\n  y = tf.constant(training_set.target)\r\n\r\n  return x, y\r\n```\r\nwhere \r\n\r\n```python\r\n# Define the test inputs -> # Define the training inputs\r\n```\r\nIn the overall listing at the top of this file, it appears to have the correct comment. It's just here in this section where the comment is incorrect. \r\n\r\n", "comments": ["Thanks! Please send a PR to correct this."]}, {"number": 9335, "title": "tf.train.Saver: be verbose about ckpt load errors", "body": "I've just had an AbortedError which resulted in the following log:\r\n```\r\nWARNING:tensorflow:/path/to/checkpoint\r\nWARNING:tensorflow:/path/to/checkpoint: Checkpoint ignored\r\n```\r\n\r\nWith this addition, I get\r\n\r\n```\r\nWARNING:tensorflow:tensorflow.python.framework.errors_impl.AbortedError: /path/to/checkpoint\r\nWARNING:tensorflow:/path/to/checkpoint: Checkpoint ignored\r\n```\r\n\r\nwhich is a bit nicer.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "I think it would be better to fill the OpError with better information (or fix its str() to provide proper information) -- just the checkpoint path is a bit silly.", "Disagree. The problem is that there are many inherited errors. Combined exc type and message is the standard way of reporting (see how python reports uncaught exceptions). This allows the exact diagnosis of the problem. Besides, that would break `logging.exception` since it explicitly includes the exception type - the standard practice. `tf.logging` is based on `logging`.\r\n\r\nHaving extra information for every `OpError` inheriter goes out of the scope of this PR.", "Even `AbortedError: /path/to/checkpoint` is a pretty useless error description. This change is fine, but it does not address the real failure: The error should contain a useful message. What was the problem with the path contained in it? File not found? Path not found? Permission denied? I haven't tracked down where this error is emitted, but wherever it is, it should set a proper message.\r\n\r\n", "I agree that errors should contain useful messages. Again, this goes out of the scope of this PR. Let me put it straight: I am not going to code anything extra here. If you feel this change is useless, please reject it. If you merge it, then next time people hit `AbortedError` in that place, they will be able to crate a triageable issue with a meaningful title, including myself.", "I agree this is an incremental step towards understanding what's going on, so this looks fine to me for now.\r\n\r\nHopefully this allows someone to figure out what is going wrong (I did a search for an empty Aborted error message being thrown in C++ and couldn't find any...)"]}, {"number": 9334, "title": "Custom operator can't define list(type)", "body": "hi, I am writing my custom operator, need to pass a list of int tensor into it, according to https://www.tensorflow.org/extend/adding_an_op and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/io_ops.cc#L59, I wrote the following code:\r\nREGISTER_OP(\"MyOwnOp\").Input(\"my_variables: dtypes\").Attr(\"dtypes: list(int)\")....\r\nand build the code into one shared library, however error occurred when loading it through tf.load_op_library.\r\nHere is the error message:\r\n\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Reference to attr 'dtypes' with type list(int) that isn't type or list(type) from Input(\"my_variables: dtypes\") for Op MyOwnOp\r\n\r\nenvironment:\r\ngcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)\r\nPython 2.7.6\r\ntensorflow '1.0.1'", "comments": ["We don't support lists as inputs. You can use sparse tensors.", "@drpngx I am confused, you mean custom operator doesn't support lists as inputs? Kernel SaveV2 operator uses lists tensor as input:\r\n\r\n> REGISTER_OP(\"SaveV2\")\r\n    .Input(\"prefix: string\")\r\n    .Input(\"tensor_names: string\")\r\n    .Input(\"shape_and_slices: string\")\r\n    .Input(\"tensors: dtypes\")\r\n    .Attr(\"dtypes: list(type)\")\r\n\r\nIf custom operator doesn't support this, could you guys change the document of https://www.tensorflow.org/extend/adding_an_op?", "Did you mean a list of valid types or a list type? If it's the list of types, you have to enumerate them. If it's a list, it won't work, you have to use sparse tensors for now.", "@drpngx  I mean a list of types, just like SaveV2.", "`\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n#include \"tensorflow/core/framework/tensor_shape.h\"\r\n#include \"tensorflow/core/framework/types.h\"\r\n#include \"tensorflow/core/lib/core/errors.h\"\r\n#include \"tensorflow/core/platform/cpu_info.h\"\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n#include \"tensorflow/core/framework/common_shape_fns.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n#include \"tensorflow/core/platform/file_system.h\"\r\n\r\nnamespace tensorflow {\r\nusing shape_inference::DimensionHandle;\r\nusing shape_inference::InferenceContext;\r\nusing shape_inference::ShapeHandle;\r\n\r\nREGISTER_OP(\"MyConcat\")\r\n  .Input(\"tensors: dtypes\")\r\n  .Attr(\"dtypes: list(int)\")\r\n  .SetShapeFn([] (InferenceContext* c) {\r\n      return Status::OK();\r\n  })\r\n  .Doc(R\"doc(\r\nconcat a list of tensors\r\n)doc\");\r\n\r\nclass MyConcatOp : public OpKernel {\r\npublic:\r\n  explicit MyConcatOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n  }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"MyConcat\").Device(DEVICE_CPU), MyConcatOp);\r\n}\r\n\r\n`\r\nThis code refereed to the two links i pasted and  complied successfully, but failed to load. I think there is something wrong.\r\n\r\n> >>> m = tf.load_op_library(\"./test_list.so\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py\", line 64, in load_op_library\r\n    None, None, error_msg, error_code)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Reference to attr 'dtypes' with type list(int) that isn't type or list(type) from Input(\"tensors: dtypes\") for Op MyConcat\r\n", "@drpngx changing Attr(\"dtypes: list(int)\") to Attr(\"dtypes: list(type)\") works, but I don't know why.\r\nThe \"Adding new op\" page said that:\r\n\r\n`list(<type>): A list of <type>, where <type> is one of the above types. Note that list(list(<type>)) is invalid.`\r\nlist(int) should work, if not, the official document is wrong.", "The list of types is just used for polymorphism. If you just want to pass a scalar, or tensor, of a single type, you can just use the type, like `tensors: int32`.", "@drpngx can you please expand on this a little more? The documentation still says this should be valid:\r\n\r\n`REGISTER_OP(\"MyOp\")\r\n    .Attr(\"myAttr: list(tensor)\")\r\n    .Input(\"in: int32\")\r\n    .Output(\"out: int32\");`\r\n\r\nWhen I call `context->GetAttr` on \"myAttr\", what type am I supposed to pass in for the second argument to get the list of TensorProtos? The documentation does not say. I have tried a pointer to `std::vector<TensorProto>` but that doesn't seem to work.", "There are a number of examples in the code. You as `.Attr(\"dilations: list(int32)` in the op registration and the kernel code uses `GetAttr(...)` into an `std::vector<int32>`.", "This seems to work with `std::vector<int>` but not `std::vector<TensorProto>`. Is that expected?", "Yes, the `TensorProto>` is used for serialized protos. The `GetAttr` is to just get some tensors of a given type. You can, however, pass the dtype to know which type you want, if that's useful. You can also pass dimensions separately. At this point, though, it might be better to use an input rather than an argument."]}, {"number": 9333, "title": "gpu build not displaying cuda libs loading", "body": "TF 1.1.0-rc1, CUDA 8.0 cuDNN8-0-v5.1, macOS 10.12\r\n\r\nI built the  GPU version from source, but when I import tensorflow I don't get the usual loading cuda library messages like I would if I use the prebuilt tensorflow-gpu from pip. That said, it does appear to be using the GPU...\r\n\r\n`~/Drive/project/image_keras$ python3 demo.py \r\nUsing TensorFlow backend.\r\nFound 2125 images belonging to 2 classes.\r\nFound 832 images belonging to 2 classes.\r\ndemo.py:64: UserWarning: Update your fit_generator call to the Keras 2 API: fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=128, epochs=25, validation_steps=832)\r\n  nb_val_samples=nb_validation_samples)\r\nEpoch 1/25\r\n2017-04-13 08:39:24.542434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:865] OS X does not support NUMA - returning NUMA node zero\r\n2017-04-13 08:39:24.542538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \r\nname: GeForce GT 750M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.77GiB\r\n2017-04-13 08:39:24.542551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-04-13 08:39:24.542557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-04-13 08:39:24.542566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\r\n 49/128 [==========>...................] - ETA: 18s - loss: 0.7352 - acc: 0.5166 `\r\n\r\nDoes this look normal output or not? I can't find an answer anywhere.", "comments": ["Yes, the warnings are OK. If you want to see where the operators are placed, use `log_device_placement`.", "Okay, but why wouldn't I get the output of the CUDA libraries? ", "Not sure. Did you set `tf.logging.set_verbosity_level(tf.logging.INFO)`?", "`\"AttributeError: module 'tensorflow.python.platform.tf_logging' has no attribute 'set_verbosity_level'\"`\r\nI think something is up because the build from source is slower than the pip gpu version...", "Sorry, it's `set_verbosity`."]}, {"number": 9332, "title": "Cannot get Conv1D layer to work", "body": "For the life of me, I cannot get Conv1D layer to work.  I am on windoze7 with theano backend and using MKL multithreading.  No issues with other layer types whatsoever.\r\n\r\nThe error I get is: convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)\r\nTypeError: __init__() takes at least 3 arguments (2 given)\r\n\r\nModel code as below:\r\nembedding_layer = Embedding(nb_words,\r\n                            EMBEDDING_DIM,\r\n                            weights=[embedding_matrix],\r\n                            input_length=MAX_SEQUENCE_LENGTH,\r\n                            trainable=False)\r\nsequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')\r\nembedded_sequences_1 = embedding_layer(sequence_1_input)\r\n\r\nsequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')\r\nembedded_sequences_2 = embedding_layer(sequence_2_input)\r\n\r\nconvx =[]\r\nfor sz in filter_sizes:\r\n    convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(embedded_sequences_1)\r\n    convx1 = GlobalMaxPooling1D(pool_size=2)(convx1)\r\n    convx1 = Flatten()(convx1)\r\n    convx.append(convx1)   \r\nx1 = merge(convx, mode='concat')\r\n\r\nconvy =[]\r\nfor sz in filter_sizes:\r\n    convy1 = Conv1D(filters=num_filters,kernel_size=sz,padding=\"valid\",activation=\"relu\",strides=1)(embedded_sequences_2)\r\n    convy1 = GlobalMaxPooling1D(pool_size=2)(convy1)\r\n    convy1 = Flatten()(convy1)\r\n    convy.append(convy1)   \r\ny1 = merge(convy, mode='concat')                   \r\n\r\nmerged = merge([x1,y1], mode='concat')\r\nmerged = Dropout(0.5)(merged)\r\nmerged = BatchNormalization()(merged)\r\nmerged = Dense(num_dense, activation='relu')(merged)\r\nmerged = Dropout(0.15)(merged)\r\nmerged = BatchNormalization()(merged)\r\npreds = Dense(1, activation='sigmoid')(merged)\r\nmodel = Model(input=[sequence_1_input,sequence_2_input], output=preds)\r\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])", "comments": ["Sorry, this is the tensorflow site, which is not theano. Please find the appropriate channels on their web site. I would suggest stackoverflow."]}, {"number": 9331, "title": "When I used keras to train a very large model, it was already done, but I found that the outputdim of the all-join layer was wrong, and what should I do? The The Without having to re-train the model #", "body": "When I used keras to train a very large model, it was already done, but I found that the outputdim of the all-join layer was wrong, and what should I do? The The Without having to re-train the model #", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 9330, "title": "Getting error: Number of tensor does not match the number of lines in metadata", "body": "Even though my metadata.tsv have 100k line but it still show up this message. I have try different amount of tensor and its work fine (eg. 40k, 50k). The problem occurred when the tensor values are roughly more than 70k. \r\nBeside, i try other data set and its work fine for 100k tensor values. Just doubt what makes the problem above happend.\r\n![default](https://cloud.githubusercontent.com/assets/27762422/25224049/cfe357ec-25ef-11e7-96f0-6a7eb4242375.PNG)\r\n![default](https://cloud.githubusercontent.com/assets/27762422/25224162/25ce4dd8-25f0-11e7-88d3-80d6b6849363.PNG)\r\n", "comments": ["It is probably and end of line missing.\r\n\r\nThis question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I'm also getting this error in TF version 1.1.0. Everything works fine on 0.12.1 using the exact same code.\r\n\r\nI've verified that my embedding tensor and metadata file have the same length.", "I also verified that if i truncate my embeddings to start from the second index, the names and embeddings will match up correctly in the tensorboard embedding visualization.", "eg. this hack makes it work for me with the current release (1.1.0):\r\n\r\n```\r\nembeddings = [i[1] for i in name_and_embedding][1:]\r\nnames = [i[0] for i in name_and_embedding]\r\n```", "Hi @markostam ,\r\nI found that it skip my blank line on metadata file, so basically what i did is to check whether the query is blank or not before writing into the metadata file. Anyway, thanks for the hack.", "> Even though my metadata.tsv have 100k line but it still show up this message. I have try different amount of tensor and its work fine (eg. 40k, 50k). The problem occurred when the tensor values are roughly more than 70k.\r\n> Beside, i try other data set and its work fine for 100k tensor values. Just doubt what makes the problem above happend.\r\n> ![default](https://cloud.githubusercontent.com/assets/27762422/25224049/cfe357ec-25ef-11e7-96f0-6a7eb4242375.PNG)\r\n> ![default](https://cloud.githubusercontent.com/assets/27762422/25224162/25ce4dd8-25f0-11e7-88d3-80d6b6849363.PNG)\r\n\r\nI've had a similar problem when using the online embedding projector (https://projector.tensorflow.org/). \r\n\r\nI am uploading a vector file of 16-dimensional embeddings and a metadata file of labels, with one label per embedding. When more than 60289 rows are uploaded (say 60290), I receive the error \r\n\r\n`Number of tensors (60290) do not match the number of lines in metadata (60289).`\r\n\r\nThis does not seem to be a problem of incorrectly formatted files, since the upload works fine when fewer rows are uploaded. Maybe re-open the issue, since this seems to be a bug?", "I am having the same problem as above.", "This error hasn't really gone away, why was this issue closed?\r\nI have an embedding layer of size 100 and my metadata file also has 100 rows, but I get an error that says \"Number of tensors (99) do not match the number of lines in the metadata (100)\".\r\nIt does not appear to be counting the lines properly, I have not supplied any header row either.\r\n\r\nI am on Tensorflow 2.2.0 and Tensorboard 2.2.1\r\n\r\nIt is basically truncating the last entry in the metadata file that I supply, whether there is a new line or not, whether there is a header or not. It is really strange.", "This might sound ridiculous but it appears like tensorboard did not like me using my Google Drive folder for logs (`/Users/me/Google Drive/logs`). When I switched it to something without a space (ex: `/tmp/me/logs`) it works alright. Ugh!", "The problem is still present.  It's a problem in tensorboard.\r\nTensorboard is caching the first tensor it gets. It's not updating when refreshing the page, even after deleting the whole log folder. The **workaround** is to close the tensorboard server and run it again.", "I created an issue [here](https://github.com/tensorflow/tensorboard/issues/4439)\r\n"]}, {"number": 9329, "title": "Getting Error - Exception: No data provided for \"activation_2\"  Need data for each key in: ['input2', 'aux_input', 'input1']", "body": "I am trying to concatenate auxiliary inputs with a siamese lstm.  I have verified the siamese lstm works fine, but cannot add in the auxiliary inputs.  Pleae see code below.\r\n\r\nembedding_layer = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)\r\n                            \r\nshared_lstm = Bidirectional(LSTM(num_lstm))\r\n\r\nsequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input1')\r\nembedded_sequences_1 = embedding_layer(sequence_1_input)\r\nx1 = shared_lstm(embedded_sequences_1)\r\n\r\nsequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32',name='input2')\r\nembedded_sequences_2 = embedding_layer(sequence_2_input)\r\ny1 = shared_lstm(embedded_sequences_2)\r\n\r\nmerged_lstm = merge([x1,y1], mode='concat')\r\nmerged_lstm = Dropout(rate_drop_dense)(merged_lstm)\r\nmerged_lstm = BatchNormalization()(merged_lstm)\r\n\r\nauxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(merged_lstm)\r\n\r\nauxiliary_input = Input(shape=(aux_train.shape[1],),name='aux_input')\r\nfoo = Activation('linear')(auxiliary_input)\r\n\r\nmerged = merge([merged_lstm,foo],mode='concat')\r\nmerged = Dropout(rate_drop_dense)(merged)\r\nmerged = BatchNormalization()(merged)\r\nmerged = Dense(num_dense, activation=act)(merged)\r\nmerged = Dropout(rate_drop_dense)(merged)\r\nmerged = BatchNormalization()(merged)\r\n\r\nfinal = Dense(1, activation='sigmoid', name='main_output')(merged)\r\n\r\ntrain = aux_train.as_matrix()\r\n\r\nmodel = Model(input=[sequence_1_input,sequence_2_input,auxiliary_input], output=[final,auxiliary_output])\r\nmodel.compile(loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'}, optimizer='nadam', metrics=['acc'], loss_weights=[1., 0.2])\r\n\r\nhist = model.fit({'input1': data_1, 'input2': data_2, 'aux_input': train}, {'main_output':labels, 'aux_output':labels}, validation_split=VALIDATION_SPLIT, nb_epoch=50, batch_size=1024, shuffle=True,class_weight=class_weight,callbacks=[early_stopping, model_checkpoint])", "comments": ["This looks like theano. Please go ahead and use the theano support channels for that."]}, {"number": 9328, "title": "Error in `python`: free(): invalid pointer", "body": "TensorFlow Version: 1.0 and 1.0.1 (whl package)\r\nKubernetes Version: 1.5.1\r\nDocker Version: 1.12.5\r\nContainer OS: ubuntu 14.04\r\n\r\nI run tensorflow applications, say mnist_replica.py, in the kubernetes cluster and this error occured everytime when finishing the whole train step.\r\n\r\nI attached the log of mnist_replica.py as below:\r\n```\r\n1492616963.574406: Worker 0: training step 5045 done (global step: 9999)\r\n1492616963.583257: Worker 0: training step 5046 done (global step: 10001)\r\nTraining ends @ 1492616963.583282\r\nTraining elapsed time: 54.435048 s\r\nAfter 10000 training step(s), validation cross entropy = 1170.07\r\n*** Error in `/usr/bin/python': free(): invalid pointer: 0x0000000001e16c50 ***\r\n```\r\nAnd everything goes well when I run the mnist_replica.py in a physical machine with RHEL 7.0. I Guess the problem is that your google's environment is different with me. So the whl package that you compiled can not run well in the ubuntu 14.04 container, especially when it comes to the C program calling Python program ", "comments": ["It could be wrong even on your own machine, just going undetected. Could you run a version with more instrumentation? Maybe a debug version with asan? Or maybe valgrind on the last step?\r\n\r\n/CC @yifeif ", "It's not only an unique case, but also happened in other ubuntu 14.04 in physical machine with TensorFlow v1.0, but it has different error log:\r\n```\r\nError in `python': double free or corruption (!prev): 0x00000000016b43c0\r\n```", "Can you reproduce with a build from source on a recent version? If so, can you try asan?", "@drpngx I pulled the TensorFlow r1.0 branch and built the whl package from source.  Getting the same error and then I would like to try official docker image. ", "@drpngx I pulled the official docker image tagged as `tensorflow/tensorflow:1.0.1`, and it works well. I do not yet know what's wrong with my self-built image. I attached my [Dockerfile](https://gist.github.com/DjangoPeng/ce00add09714f247fe211c1dcff708aa).", "@DjangoPeng Let us know if you figure out additional information.  My only wild guess is something to do with incompatible versions of Python.", "@girving Thanks for your attention. The problem is the incompatible of `malloc`, I think the library of `malloc` in Google is different with us. If I install the `libtcmalloc-minimal4` in Dockerfile everything goes well . I've updated my [Dockerfile](https://gist.github.com/DjangoPeng/ce00add09714f247fe211c1dcff708aa#file-dockerfile-L29) and commented the line 29.", "@caisq Can we incorporate this fix?", "@girving I noticed @DjangoPeng is using ubuntu:14.04, but the official TF Docker images are on ubuntu:16.04 now. So there is no need to incorporate any changes to TF code. Am I understanding it correctly?", "If we are talking about updating the old release branch (r1.0), that SGTM.", "PS, we are observing same error message with PyTorch on Ubuntu 14.04, and LD_PRELOAD=tcmalloc fixes it there too", "@girving  @caisq I'm not sure if `tensorflow/tensorflow:1.0` is based on Ubuntu:14.04. If so, I think it's necessary to fix it, cause 1.0 is the first stable released version.\r\n@yaroslavvb Do you mean add the environment `LD_PRELOAD` in Dockerfile?", "@caisq What can I do for fixing the issue? I'm willing to contribute it to TensorFlow community.", "@DjangoPeng Thanks. Can you please send a PR to these files in branch r1.0:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/tools/docker/Dockerfile\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/tools/docker/Dockerfile.devel\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/tools/docker/Dockerfile.devel-gpu\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/tools/docker/Dockerfile.gpu?\r\n\r\n", "@caisq Sure thing, I'm on it.", "Merged pull request, so I close the issue. @caisq @girving ", "I encountered this problem because I used torch and tensorflow at same time."]}, {"number": 9327, "title": "Include UGRNNCell and IntersectionRNNCell to the tf.contrib.rnn module.(#9303)", "body": "@ebrevdo", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it! @googlebot ", "CLAs look good, thanks!\n\n<!-- ok -->", "LGTM, thanks!\n\nOn Thu, Apr 20, 2017 at 1:09 AM, googlebot <notifications@github.com> wrote:\n\n> CLAs look good, thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/9327#issuecomment-295623635>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim0F4s7vXi-xus8obNEAz5et40cxfks5rxxKzgaJpZM4NCrSC>\n> .\n>\n", "Jenkins, test this please."]}, {"number": 9326, "title": "Update op_def_registry.py", "body": "I am hoping that you can make an update to tensorflow/python/framework/op_def_registry.py (https://github.com/tensorflow/tensorflow/pull/9235/commits/133debe1e805e8d2a78600a9d5014900d429479c). \r\n\r\nI discovered this issue when I was building a seq2seq model with attention. Specifically, I believe the issue stems from tf.contrib.seq2seq.prepare_attention() (https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/prepare_attention) because the error message is: \"ValueError: No op named attn_add_fun_f32f32f32 in defined operations\" when I use \"bahdanau\" as my attention_option. When I used \"luong\" for the attention_option, the error is: \"ValueError: No op named attn_mul_fun_f32f32 in defined operations\".\r\n\r\nThis issue was also brought up here: http://stackoverflow.com/questions/42494695/tf-train-import-meta-graphmodel-meta-cannot-handle-seq2seq-models-with-atten. However, with my issue, I was using python3. \r\n\r\nThanks for your help!", "comments": ["Your problem is that the file is an auto-generated file and you failed to generate it during the build. Please try either install from binary or follow the \"Install From Source\" instructions carefully.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 9325, "title": "Cannot find python and other modules", "body": "When I am running the code with `tf.python.framework.tensor_shape.scalar()` , I get the error message `AttributeError: 'module' object has no attribute 'python'`\r\n\r\n\r\n### Source Code / Logs\r\n\r\nGiven below are minimum reproducible examples. \r\n\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.python'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'python'\r\n```\r\n\r\nThis works\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.contrib'\r\n```\r\n\r\nOthers donot work\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.core'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'core'\r\n```\r\n\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.examples'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'examples'\r\n```\r\n\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.include'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'include'\r\n```\r\n\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.tools'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'tools'\r\n```\r\n\r\nBut when I also tried importing python module. \r\n\r\n```\r\n(tf1_0rc1_cpu) $python -c'import tensorflow.python'\r\n```\r\n\r\n\r\n\r\n### System Information\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No\r\n- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: MacOS Sierra \r\n- *TensorFlow installed from (source or binary)?*:Binary \r\n- *TensorFlow version* (use command below): ('v1.0.0-65-g4763edf-dirty', '1.0.1')\r\n- *Bazel version (if compiling from source)*: n/a\r\n- *CUDA/cuDNN version*: release 8.0, V8.0.61\r\n- *GPU Model and Memory*:NVIDIA GeForce GT 650M 1024 MB\r\n- *Exact command to reproduce*:python -c \"import tensorflow as tf; tf.python\"\r\n\r\n", "comments": ["I was able to use `tf.python.framework.tensor_shape.scalar()` shape by following code\r\n\r\n```python\r\nfrom tensorflow.python.framework.tensor_shape import scalar\r\nscalar()\r\n```", "There is no `tf.python`, by design. Neither is there tools, include, etc. You can use `dir(tf)` to find out the contents of the package that you can use.\r\n\r\n`tensor_shape` is currently only for internal use. We are recommending for people to use the C++ API."]}, {"number": 9324, "title": "Tensorflow build error: not able to find ar in the compiler", "body": "I'm trying to build Tensorflow from source, and I follow the instruction here:\r\nhttps://gist.github.com/taylorpaul/3e4e405ffad1be8355bf742fa24b41f0#file-buildtf-sh-L118\r\n\r\nBut I fail to build it, and below are the command and error info. Could any one help me out?\r\n\r\n```\r\n$ bazel build -c opt --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n```\r\nWARNING: Output base '/home/xruan/.cache/bazel/_bazel_xruan/b83ca1b6fcc10c08548ef5b8ff5c75d2' is on NFS. This may lead to surprising failures and undetermined behavior.\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nWARNING: /home/xruan/tmp/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING: /home/xruan/tmp/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/xruan/tmp/tensorflow/tensorflow/core/BUILD:1268:1: Linking of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: ar failed: error executing command /opt/gcc/4.9.2/bin/ar @bazel-out/host/bin/tensorflow/core/liblib_hash_crc32c_accelerate_internal.a-2.params: com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nprocess-wrapper: execvp(\"/opt/gcc/4.9.2/bin/ar\", ...): No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2.925s, Critical Path: 0.25s\r\n```\r\n\r\n\r\n------------------------\r\n\r\n### System Information\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:No\r\n- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:Centos 6.5 Cluster\r\n- *TensorFlow installed from (source or binary)?*:source\r\n- *TensorFlow version* (use command below):r1.1\r\n- *Bazel version (if compiling from source)*:0.4.5\r\n- *CUDA/cuDNN version*:8.0\r\n- *GPU Model and Memory*:GTX1080\r\n\r\n", "comments": ["We don't support centos below 7, so support here will be best effort.\r\n\r\nIt looks like it cannot find the compiler. Did you check that it exists?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 9323, "title": "Fix typo in LINE#471", "body": "change cell_input_fn to probability_fn, bug reported in https://github.com/tensorflow/tensorflow/issues/9312", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "@caisq  Ignoring unrelated failure in queue runner."]}, {"number": 9322, "title": "TensorFlow 60-80% slower than PyTorch on training Wide ResNet", "body": "cc @tfboyd\r\n\r\nFrom https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-295502315\r\n\r\nOn an AWS p2.xlarge, using the `tensorflow/tensorflow:1.0.1-devel-gpu` Docker image as a base, I see ~270 ms per epoch while training a WRN-16-4 without dropout on CIFAR-10.\r\n\r\nUsing a PyTorch implementation from https://github.com/xternalz/WideResNet-pytorch, I see instead ~150 ms per epoch for the same.\r\n\r\nMy implementation of Wide ResNets uses NCHW and fused batch norm. It does use `feed_dict` for data loading, but I've observed with `nvidia-smi` that my GPU utilization stays near 100%.\r\n\r\n-----\r\n\r\nTo reproduce:\r\n\r\n- Clone https://github.com/4Catalyzer/dl-papers, and go to that directory.\r\n- Check out the [`benchmark`](https://github.com/4Catalyzer/dl-papers/tree/benchmark) branch.\r\n- Build the Docker image, which is based on the Docker hub image above:\r\n```\r\n$ docker build -t dl-papers .\r\n```\r\n- Run the Docker image using NVIDIA Docker:\r\n```\r\n$ nvidia-docker run --rm -it dl-papers /bin/bash\r\n```\r\n- Run the TF WRN-16-4 training:\r\n```\r\n# python -m dl_papers.wide_resnet.train cifar10\r\n```\r\n- Observe the logged batch timings, then kill the process.\r\n- In the same Docker container up the PyTorch Wide ResNet example:\r\n```\r\n# cd ..\r\n# pip install http://download.pytorch.org/whl/cu80/torch-0.1.11.post5-cp27-none-linux_x86_64.whl\r\n# pip install torchvision tensorboard_logger\r\n# git clone https://github.com/xternalz/WideResNet-pytorch.git\r\n# cd WideResNet-pytorch\r\n```\r\n- Run PyTorch training:\r\n```\r\n# python train.py --dataset cifar10 --layers 16 --widen-factor 4 -p 1\r\n```\r\n- Observe logged batch timings.", "comments": ["To rule out issues with my use of `feed_dict`, I've added a [`benchmark-constant`](https://github.com/4Catalyzer/dl-papers/tree/benchmark-constant) branch to my repo that uses constant tensors for the batch inputs and outputs, and removes all the actual data loading logic.\r\n\r\nOn this branch, on the same AWS instance, I see batch times of ~246 ms, which is still over 60% slower than what I see with the PyTorch example (and this is non-apples-to-apples, since the PyTorch example is doing real data loading).", "I doubt I can be helpful on this one.  I am having a hard time following all of the code references, e.g. wrappers around everything.  I am not doubting it is correct but about about 30 minutes of scanning through the code I know it is beyond me to follow. This is a shot in the dark but if you are trying things to see if they impact the time, I would remove feed_dic completely.  You can decrease/decay the learning rate (even on a set schedule) via the optimizer combined with global_step, which is the way I normally see it done.  I am not saying that will fix your issue, that is just the only thing I see that sticks out to me.  Sorry.  Maybe someone else will take a look.  I know we are working on a wide&deep model to open source but it may not be your exact one.  I will try to check on that, it might also give me an idea of what might be causing you problems.  Thank you for sharing.  ", "Would it help if I inlined the non-TF layer helpers into a single module? As you can probably tell, we pulled this out from a larger internal repo, where things were organized to optimize code reuse.\r\n\r\nIf I take out `feed_dict` entirely, I get ~241 ms. I suspect this is largely from eliding the conditional checks on `training`, though.", "Yeah that did not save much.  :-(    I understand this may sound like I am deflecting the question but how do you know your model is exactly the same as the pytorch version?  \r\n\r\nRemoving the wrappers and inlining seems painful, I would hate to have you do it and then not get time to dig in.  This might be a fun side project for me to look at in regards to checking out the timeline.  I am also asking internally about a wide&deep model as I would like to start from something where I have more experts to poke.  I will try to find time to ask around.  I sent an email but I suspect I will need to ask a few people.  ", "I believe they're the same. The two models have the same number of parameters, and I can't see anything different on inspection.\r\n\r\nAlso, the performance delta I see here is broadly consistent with those reported for ResNet-50 and ResNet-56 in the paper linked in the OP on https://github.com/tensorflow/tensorflow/issues/7187.", "One thing to keep in mind and it is something common in most of the code from the HK benchmark.   1) put your input pipeline on the CPU (I fixed this for another simpler CIFAR example and the person got more than a 5x improvement from ~700 imgs/sec to ~3800 imgs/sec on a K80. \r\n https://github.com/tensorflow/models/issues/1264\r\n\r\n2) Queues and following best practices for them.  Feed_dict is just for messing around it is very slow.  Next week we should release code what is even faster than queues but queues can still get a lot of performance.  \r\n\r\nI know some of the sample code and published model code did not follow those best practices.  \r\n\r\n\r\n", "Since it's slow even with a constant fake input and 100% GPU util, it's probably not a problem with feed_dict or input, right? \r\n\r\nAlso I'm able to reproduce the 60% performance difference with my own TF code written fully independently from the above TF code. So it's unlikely to be a problem of model definition, unless both of us interpret the pytorch code in the wrong way.\r\n\r\nSlow speed at high GPU util may be a result of using inefficient kernels. For example by setting `cudnn.benchmark=False` (disable autotuner) I can make the above pytorch code 2x slower, while still taking 100% GPU utilization -- maybe that's something to look at.", "No idea, someone else will have to pick this up.  I know very little and even less about this model.  I am sure it will come back around when we focus on these types of models (and thus the ops and kernels they are using) in a couple weeks.  ", "To clarify:\r\n\r\n- Even when using `feed_dict` for the data, I'm seeing 95%-100% GPU utilization, so I'm fairly confident that I'm not starving my GPU, even when using `feed_dict` (data augmentation/&c. are still happening in a separate thread)\r\n- When I remove all placeholders and just use constant fake training data (i.e. to remove all GPU memory or whatever pressure from moving data around), I still see TF as ~60% slower than the PyTorch model that's doing actual fitting\r\n- I intentionally wrote this Wide ResNet model from scratch; the ResNet models in `tensorflow/models` have a number of problems, from inefficiency for the non-TF-Slim versions (using NHWC and not using fused batch norm) to actually implementing the model incorrectly in the TF-Slim versions (not dropping biases on convolutions before batch norms and not using beta and gamma on the batch norm operations, plus the same inefficiencies as above)", "I know this version also has issues but at a glance if I comment this in (and use a factor of 4 instead of 10 for the widening) and comment the other filter out.  \r\n\r\nhttps://github.com/tensorflow/models/blob/master/resnet/resnet_model.py#L87\r\n\r\nYes, I can ask someone on the team, but asking you might save me time and get this moving.  \r\n\r\nWill that give me the same model in general we are discussing.  It is much easier me to \"package\" this up and get people to look at it than code with a lot of extra \"wrappers\".  I can then get it cleaned up so the community can have a nice version to use.  I am pretty sure they team is working on a version of this to go with Estimators and it would be great to flush out any issues sooner rather than later.  \r\n\r\nI hope I was clear.  I am not super experienced with the models.  I know a few things and try to help with simple problems.  I saw feed_dict and wanted to make sure you did not have a simple problem.  The danger is trying to help (I hope to stop in the future) is I end up in a situation where I cannot help directly and people get unfriendly.    \r\n\r\nThank you for helping me try to help you.\r\n\r\nEdited:  to add that I need to adjust the widening.", "Here are the results on a GTX 1080 (which I also use as my main display card):\r\n\r\nNot apples-to-apples due to TF using a constant.  I used git checkout benchmark-constant with the following commands on Ubuntu 14.04 (a custom internal google build) with CUDA 8.0 and 5.1 cuDNN as one would expect:\r\n- python -m dl_papers.wide_resnet.train cifar10\r\n- python train.py --dataset cifar10 --layers 16 --widen-factor 4 -p 1\r\n\r\n.069 vs .055.  I am running TF 1.1rc2 compiled with CUDA and compute 6.1 as well as avx (which I doubt matters in this instance).\r\n\r\nTensorFlow with the constant\r\n[2017-04-20 00:15:48,235] INFO in train: epoch 0, batch 176: 0.068s\r\n[2017-04-20 00:15:48,303] INFO in train: epoch 0, batch 177: 0.068s\r\n[2017-04-20 00:15:48,372] INFO in train: epoch 0, batch 178: 0.068s\r\n[2017-04-20 00:15:48,440] INFO in train: epoch 0, batch 179: 0.068s\r\n[2017-04-20 00:15:48,510] INFO in train: epoch 0, batch 180: 0.069s\r\n[2017-04-20 00:15:48,581] INFO in train: epoch 0, batch 181: 0.071s\r\n[2017-04-20 00:15:48,649] INFO in train: epoch 0, batch 182: 0.068s\r\n\r\n\r\nPyTorch with real data\r\nEpoch: [0][83/391]\tTime 0.055 (0.069)\tLoss 1.5680 (1.8102)\tPrec@1 42.188 (31.343)\r\nEpoch: [0][84/391]\tTime 0.054 (0.069)\tLoss 1.6633 (1.8084)\tPrec@1 39.062 (31.434)\r\nEpoch: [0][85/391]\tTime 0.053 (0.069)\tLoss 1.6345 (1.8064)\tPrec@1 39.844 (31.532)\r\nEpoch: [0][86/391]\tTime 0.056 (0.069)\tLoss 1.4338 (1.8021)\tPrec@1 46.875 (31.708)\r\nEpoch: [0][87/391]\tTime 0.056 (0.069)\tLoss 1.4923 (1.7986)\tPrec@1 43.750 (31.845)\r\nEpoch: [0][88/391]\tTime 0.057 (0.068)\tLoss 1.6836 (1.7973)\tPrec@1 45.312 (31.996)\r\n\r\nToby\r\n", "If I turn on WINOGRAD I get another small bump still using the same branch.  \r\n\r\nexport TF_ENABLE_WINOGRAD_NONFUSED=1;python -m dl_papers.wide_resnet.train cifar10\r\n\r\n[2017-04-20 00:37:44,189] INFO in train: epoch 0, batch 192: 0.062s\r\n[2017-04-20 00:37:44,251] INFO in train: epoch 0, batch 193: 0.062s\r\n[2017-04-20 00:37:44,313] INFO in train: epoch 0, batch 194: 0.062s\r\n[2017-04-20 00:37:44,375] INFO in train: epoch 0, batch 195: 0.062s\r\n[2017-04-20 00:37:44,438] INFO in train: epoch 0, batch 196: 0.062s\r\n[2017-04-20 00:37:44,499] INFO in train: epoch 0, batch 197: 0.062s\r\n[2017-04-20 00:37:44,561] INFO in train: epoch 0, batch 198: 0.062s\r\n[2017-04-20 00:37:44,623] INFO in train: epoch 0, batch 199: 0.062s\r\n[2017-04-20 00:37:44,688] INFO in train: epoch 0, batch 200: 0.065s\r\n[2017-04-20 00:37:44,750] INFO in train: epoch 0, batch 201: 0.062s\r\n\r\n", "On the K80 (AWS p2.xlarge).  TF 1.1rc2+ (built from head earlier today) CUDA 8.0, avx2, cuDNN 5.1 and compute 3.7.  \r\n\r\nWINOGRAD did not help much on K80.  \r\n\r\nexport TF_ENABLE_WINOGRAD_NONFUSED=1;python -m dl_papers.wide_resnet.train cifar10\r\n[2017-04-20 07:52:13,740] INFO in train: epoch 0, batch 91: 0.168s\r\n[2017-04-20 07:52:13,909] INFO in train: epoch 0, batch 92: 0.169s\r\n[2017-04-20 07:52:14,079] INFO in train: epoch 0, batch 93: 0.170s\r\n[2017-04-20 07:52:14,248] INFO in train: epoch 0, batch 94: 0.169s\r\n[2017-04-20 07:52:14,417] INFO in train: epoch 0, batch 95: 0.169s\r\n[2017-04-20 07:52:14,587] INFO in train: epoch 0, batch 96: 0.169s\r\n[2017-04-20 07:52:14,756] INFO in train: epoch 0, batch 97: 0.169s\r\n[2017-04-20 07:52:14,925] INFO in train: epoch 0, batch 98: 0.169s\r\n[2017-04-20 07:52:15,094] INFO in train: epoch 0, batch 99: 0.169s\r\n\r\nwithout WINOGRAD\r\n[2017-04-20 07:53:38,301] INFO in train: epoch 0, batch 40: 0.169s\r\n[2017-04-20 07:53:38,470] INFO in train: epoch 0, batch 41: 0.168s\r\n[2017-04-20 07:53:38,639] INFO in train: epoch 0, batch 42: 0.169s\r\n[2017-04-20 07:53:38,808] INFO in train: epoch 0, batch 43: 0.169s\r\n[2017-04-20 07:53:38,977] INFO in train: epoch 0, batch 44: 0.169s\r\n[2017-04-20 07:53:39,147] INFO in train: epoch 0, batch 45: 0.169s\r\n[2017-04-20 07:53:39,316] INFO in train: epoch 0, batch 46: 0.169s\r\n[2017-04-20 07:53:39,485] INFO in train: epoch 0, batch 47: 0.169s\r\n[2017-04-20 07:53:39,654] INFO in train: epoch 0, batch 48: 0.169s\r\n\r\n\r\n**EDIT:**  After further testing, I had exported the environment variable and had not to set it back to zero thus the lack of difference. ", "And now with real data on K80 WINOGRAD on and the rest the same, but WINOGRAD did very little on K80.  \r\n\r\n[2017-04-20 08:03:47,636] INFO in train: epoch 0, batch 383: 0.174s\r\n 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 49152/50000 [01:07<00:01, 739.85ex/s][2017-04-20 08:03:47,810] INFO in train: epoch 0, batch 384: 0.173s\r\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 49280/50000 [01:07<00:00, 739.13ex/s][2017-04-20 08:03:47,983] INFO in train: epoch 0, batch 385: 0.173s\r\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 49408/50000 [01:07<00:00, 739.33ex/s][2017-04-20 08:03:48,156] INFO in train: epoch 0, batch 386: 0.173s\r\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 49536/50000 [01:07<00:00, 739.21ex/s][2017-04-20 08:03:48,330] INFO in train: epoch 0, batch 387: 0.173s\r\n 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 49664/50000 [01:07<00:00, 738.45ex/s][2017-04-20 08:03:48,504] INFO in train: epoch 0, batch 388: 0.173s\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 49792/50000 [01:07<00:00, 737.94ex/s][2017-04-20 08:03:48,675] INFO in train: epoch 0, batch 389: 0.172s\r\n\r\n\r\nI like your graphic with the progress bar.  Kind of fun but not so much fun to cut and paste.  \r\n\r\n**EDIT:**  After further testing, I had exported the environment variable and had not to set it back to zero thus the lack of difference. ", "Let me know if I did something wrong.  I am going to bed.", "Actually with ` TF_ENABLE_WINOGRAD_NONFUSED=1`, I saw only 5% difference between pytorch and tensorflow. \r\n\r\nMy code: https://gist.github.com/ppwwyyxx/43c75cd5a949fc1617be55ded7506f00\r\nIt's meant to be an equivalent model of the `train.py` in pytorch (without other arguments).\r\nI'm on Tesla M40, tensorflow nightly, cuda8.0, cudnn5.1", "I managed to get a set of traces from pytorch and tensorflow about what convolution algorithm and shapes they use:\r\npytorch:\r\n```\r\nInput: 128 3 32 32 0 Weight: 16 3 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 1\r\nInput: 128 16 32 32 0 Weight: 160 16 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 6\r\nInput: 128 160 32 32 0 Weight: 160 160 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 6\r\nInput: 128 16 32 32 0 Weight: 160 16 1 1 0 pad: 0 0 0 Stride: 1 1 0 -> Algo: 1\r\nInput: 128 160 32 32 0 Weight: 320 160 3 3 0 pad: 1 1 0 Stride: 2 2 0 -> Algo: 1\r\nInput: 128 320 16 16 0 Weight: 320 320 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 7\r\nInput: 128 160 32 32 0 Weight: 320 160 1 1 0 pad: 0 0 0 Stride: 2 2 0 -> Algo: 1\r\nInput: 128 320 16 16 0 Weight: 640 320 1 1 0 pad: 0 0 0 Stride: 2 2 0 -> Algo: 1\r\nInput: 128 320 16 16 0 Weight: 640 320 3 3 0 pad: 1 1 0 Stride: 2 2 0 -> Algo: 1\r\nInput: 128 640 8 8 0 Weight: 640 640 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 7\r\n\r\nbd Input: 128 640 8 8 0 Weight: 640 640 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 5\r\nbf Input: 128 640 8 8 0 Weight: 640 640 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 5\r\n\r\nbd Input: 128 320 16 16 0 Weight: 640 320 3 3 0 pad: 1 1 0 Stride: 2 2 0 -> Algo: 0\r\nbf Input: 128 320 16 16 0 Weight: 640 320 3 3 0 pad: 1 1 0 Stride: 2 2 0 -> Algo: 1\r\n\r\nbd Input: 128 320 16 16 0 Weight: 640 320 1 1 0 pad: 0 0 0 Stride: 2 2 0 -> Algo: 0\r\nbf Input: 128 320 16 16 0 Weight: 640 320 1 1 0 pad: 0 0 0 Stride: 2 2 0 -> Algo: 3\r\n\r\nInput: 128 320 16 16 0 Weight: 320 320 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 5\r\nInput: 128 320 16 16 0 Weight: 320 320 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 5\r\n\r\nInput: 128 160 32 32 0 Weight: 320 160 1 1 0 pad: 0 0 0 Stride: 2 2 0 -> Algo: 0\r\nInput: 128 160 32 32 0 Weight: 320 160 1 1 0 pad: 0 0 0 Stride: 2 2 0 -> Algo: 0\r\n\r\nInput: 128 160 32 32 0 Weight: 320 160 3 3 0 pad: 1 1 0 Stride: 2 2 0 -> Algo: 0\r\nInput: 128 160 32 32 0 Weight: 320 160 3 3 0 pad: 1 1 0 Stride: 2 2 0 -> Algo: 3\r\n\r\nInput: 128 160 32 32 0 Weight: 160 160 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 4\r\nInput: 128 160 32 32 0 Weight: 160 160 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 5\r\n\r\nbd Input: 128 16 32 32 0 Weight: 160 16 1 1 0 pad: 0 0 0 Stride: 1 1 0 -> Algo: 1\r\nbf Input: 128 16 32 32 0 Weight: 160 16 1 1 0 pad: 0 0 0 Stride: 1 1 0 -> Algo: 3\r\n\r\nbd Input: 128 16 32 32 0 Weight: 160 16 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 4\r\nbf Input: 128 16 32 32 0 Weight: 160 16 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 3\r\n\r\nbf Input: 128 3 32 32 0 Weight: 16 3 3 3 0 pad: 1 1 0 Stride: 1 1 0 -> Algo: 0\r\n```\r\n\r\nTensorFlow:\r\n```\r\nConv accepts: 128, 3, (32, 32), 16, (3, 3), (1, 1), (2, 2), 1, 0 -> (1, 0)\r\nConv accepts: 128, 16, (32, 32), 160, (3, 3), (1, 1), (2, 2), 1, 0 -> (6, 0)\r\nConv accepts: 128, 160, (32, 32), 160, (3, 3), (1, 1), (2, 2), 1, 0 -> (6, 0)\r\nConv accepts: 128, 16, (32, 32), 160, (1, 1), (1, 1), (0, 0), 1, 0 -> (1, 0)\r\nConv accepts: 128, 160, (33, 33), 320, (3, 3), (2, 2), (1, 1), 1, 0 -> (1, 0)\r\nConv accepts: 128, 320, (16, 16), 320, (3, 3), (1, 1), (2, 2), 1, 0 -> (7, 0)\r\nConv accepts: 128, 160, (32, 32), 320, (1, 1), (2, 2), (0, 0), 1, 0 -> (1, 0)\r\nConv accepts: 128, 320, (16, 16), 640, (1, 1), (2, 2), (0, 0), 1, 0 -> (1, 0)\r\nConv accepts: 128, 320, (17, 17), 640, (3, 3), (2, 2), (1, 1), 1, 0 -> (1, 0)\r\nConv accepts: 128, 640, (8, 8), 640, (3, 3), (1, 1), (2, 2), 1, 0 -> (7, 0)\r\n\r\nConvBwdData accepts: 128, 640, (8, 8), 640, (3, 3), (1, 1), (2, 2), 1, 0 -> (5, 0)\r\nConvBwdFilter accepts: 128, 640, (8, 8), 640, (3, 3), (1, 1), (2, 2), 1, 0 -> (5, 0)\r\n\r\nConvBwdData accepts: 128, 320, (17, 17), 640, (3, 3), (2, 2), (1, 1), 1, 0 -> (0, 0)\r\nConvBwdFilter accepts: 128, 320, (17, 17), 640, (3, 3), (2, 2), (1, 1), 1, 0 -> (1, 0)\r\n\r\nConvBwdData accepts: 128, 320, (16, 16), 640, (1, 1), (2, 2), (0, 0), 1, 0 -> (0, 0)\r\nConvBwdFilter accepts: 128, 320, (16, 16), 640, (1, 1), (2, 2), (0, 0), 1, 0 -> (3, 0)\r\n\r\nConvBwdData accepts: 128, 320, (16, 16), 320, (3, 3), (1, 1), (2, 2), 1, 0 -> (5, 0)\r\nConvBwdFilter accepts: 128, 320, (16, 16), 320, (3, 3), (1, 1), (2, 2), 1, 0 -> (5, 0)\r\n\r\nConvBwdData accepts: 128, 160, (32, 32), 320, (1, 1), (2, 2), (0, 0), 1, 0 -> (0, 0)\r\nConvBwdFilter accepts: 128, 160, (32, 32), 320, (1, 1), (2, 2), (0, 0), 1, 0 -> (0, 0)\r\n\r\nConvBwdData accepts: 128, 160, (33, 33), 320, (3, 3), (2, 2), (1, 1), 1, 0 -> (0, 0)\r\nConvBwdFilter accepts: 128, 160, (33, 33), 320, (3, 3), (2, 2), (1, 1), 1, 0 -> (3, 0)\r\n\r\nConvBwdData accepts: 128, 160, (32, 32), 160, (3, 3), (1, 1), (2, 2), 1, 0 -> (4, 0)\r\nConvBwdFilter accepts: 128, 160, (32, 32), 160, (3, 3), (1, 1), (2, 2), 1, 0 -> (5, 0)\r\n\r\nConvBwdData accepts: 128, 16, (32, 32), 160, (1, 1), (1, 1), (0, 0), 1, 0 -> (1, 0)\r\nConvBwdFilter accepts: 128, 16, (32, 32), 160, (1, 1), (1, 1), (0, 0), 1, 0 -> (3, 0)\r\n\r\nConvBwdData accepts: 128, 16, (32, 32), 160, (3, 3), (1, 1), (2, 2), 1, 0 -> (4, 0)\r\nConvBwdFilter accepts: 128, 16, (32, 32), 160, (3, 3), (1, 1), (2, 2), 1, 0 -> (3, 0)\r\n\r\nConvBwdFilter accepts: 128, 3, (32, 32), 16, (3, 3), (1, 1), (2, 2), 1, 0 -> (0, 0)\r\n# batch size, input chan, (input shape), out chan, (kernel shape), (stride), (padding), _, _ -> algo\r\n```\r\n\r\nWith `TF_ENABLE_WINOGRAD_NONFUSED=1`, tensorflow always chooses the same algorithm as pytorch. But the log shows that tensorflow sometimes calls cudnn with **irregular input shapes when stride=2**. Maybe it can cause some performance issue.", "When it comes to 5% difference if you are not doing 10 plus tests (stop and start the process) and then on multiple machines it could easily just be an anomaly.  Also don't just look at every 10, you need to average it all together correctly.  Not doubting the 5% and it could be real but I have been excited about perf improvements and they were just luck of the machine.  I have also noticed that if you get a p2.8xlarge and just use 1 GPU it is faster than the p2.xlarge.  It could be the CPU difference, it could be a lot of things.  Just interesting and not really worth a deep dive.  \r\n\r\n@ppwwyyxx is this is a bug?  I am not sure I follow your sentence.  Is TF calling the wrong thing with or without WINOGRAD?  Is it wrong and a problem?  I got confused between your use of the word always and then sometimes.  Can you let me know which version of TF and general hardware you were using when you were getting the 60%-80% difference and the actual numbers even if just estimates?\r\n\r\n>But the log shows that tensorflow sometimes calls cudnn with irregular input shapes and paddings when stride=2.\r\n\r\n\r\n", "If you are doing actual research, I would increase the batch-size (PyTorch as well) unless you think it will harm accuracy.  I did not check memory usage but if you want to train as fast as possible that is sometimes overlooked.  \r\n\r\nHere are also some other flags we use in the benchmarks.  They did not seem to have an impact on K80 but I did not extensively.  \r\n\r\n  config = tf.ConfigProto()\r\n  config.allow_soft_placement = True\r\n  config.intra_op_parallelism_threads = 1\r\n  config.inter_op_parallelism_threads = 0  <-- let the system figure it out\r\n  config.gpu_options.force_gpu_compatible = True  <-- requires master head from the past few days\r\n\r\nThis env variable might be of interest.\r\nos.environ['TF_AUTOTUNE_THRESHOLD'] \r\nIt defaults to 1 if I understand the underlying code so there is likely no need to set it but it might be interesting.  \r\n\r\n\r\n\r\n\r\n", "I posted an issue before about TF logging the conv algorithm in use (pytorch has an option for this): https://github.com/tensorflow/tensorflow/issues/8941 \r\n\r\nThis probably isn't a huge issues, but one issues is that TF will have to transpose the weights on each forward / backward pass: https://github.com/tensorflow/tensorflow/issues/8287 (and https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-285191193).\r\n\r\n@Yangqing also had some comments on workspace size (`TF_CUDNN_WORKSPACE_LIMIT_IN_MB`?): https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-290209116 that I don't fully understand.", "@cancan101  Thank you Alex those are some items I can ask about and thank you for linking them in one chunk.  I would 100% build TF 1.1 (not the branch just build from master) from source.  I have not gone back to see when the algorithm picking (if that is what closed the gap) got better but my guess is toward the end of March.  That is a wild guess based on not understanding the code I am reading the the diff history.  ", "I would also add that the following env var don't seem documented:\r\n* `TF_AUTOTUNE_THRESHOLD`\r\n* `TF_ENABLE_WINOGRAD_NONFUSED`\r\n* `TF_CUDNN_WORKSPACE_LIMIT_IN_MB`", "@tfboyd \r\n\r\nSorry about that progress bar. It works a lot better in actual use when we're not logging out timings after every batch. \ud83d\ude1b \r\n\r\nI'm working on using a modified version of the data pipeline from the tutorial (modified to use 32x32 and NCHW) to get a more apples-to-apples comparison. Though, is `feed_dict` expected to be slower even if GPU utilization is in the 95%-100% range?\r\n\r\nI'll take a look at TF 1.1 RCs and master as well. We've been holding off on that upgrade because of some TensorBoard regressions, but we weren't aware that there was a potential performance boost.", "@taion   I thought your progress bars were cool, they are kind of fun when logging that often.  It was  1am when I ran it and my terminal was like a black and white explosion of moving stuff.  My first thought was that my scripts need to be much cooler.  \r\n\r\nYeah that TensorBoard thing got me as well.  I don't want to talk about it.  :-)  \r\n\r\nApologies again.  When I said apples-to-apples, I meant in the first post I was running TF with a constant and PyTorch with real data.  Turns out the results were similar.  I honestly do not know if the queues will help over `feed_dict` with the GPU at 100%.  I do know that every time I see it I assume it is a problem and it is good practice to just not use the `feed_dict` approach.  I hope I am being clear that I don't know in this instance.  I would do it just so I knew it was not a problem.  If I was faster with TF, I would \"hack\" it in and try it.  \r\n\r\nThank you for all the feedback Jimmy, you are a nice person.  It is really hard to work through this stuff with \"strangers\" and trying to get on the same page.  You likely know way more than I do but I have access to some code and happen to be connected to recent changes.\r\n\r\n@cancan101 Yup.  Once we are sure WINOGRAD is working in all instances it will just be the default.  The AUTOTUNE is not really needed but you could play with it.  TF_CUDNN_WORKSPACE_LIMIT_IN_MB is not something I have used.  I will include them in the perf guide update next week and the ones we use in the benchmark is embedded in the code.  I shared them with this group because all of you were curious and I felt knowledgeable enough (more than me in many ways) to turn them on or off if you have issues, e.g. things don't converge or things \"explode\".  \r\n\r\nThis is great feedback.  Yes, I type too much.  ", "The queue-based data loading from the tutorial appears to be comparable to what I had before with `feed_dict`.\r\n\r\nUsing the same setup as above (TF 1.0.1 from the Docker image on a p2.xlarge).\r\n\r\nQueue (https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue):\r\n```\r\n[2017-04-20 15:16:30,871] INFO in train: epoch 0, batch 200: 0.268s\r\n[2017-04-20 15:16:31,141] INFO in train: epoch 0, batch 201: 0.269s\r\n[2017-04-20 15:16:31,416] INFO in train: epoch 0, batch 202: 0.275s\r\n[2017-04-20 15:16:31,691] INFO in train: epoch 0, batch 203: 0.274s\r\n[2017-04-20 15:16:31,966] INFO in train: epoch 0, batch 204: 0.275s\r\n[2017-04-20 15:16:32,239] INFO in train: epoch 0, batch 205: 0.273s\r\n[2017-04-20 15:16:32,513] INFO in train: epoch 0, batch 206: 0.274s\r\n[2017-04-20 15:16:32,791] INFO in train: epoch 0, batch 207: 0.277s\r\n[2017-04-20 15:16:33,066] INFO in train: epoch 0, batch 208: 0.275s\r\n[2017-04-20 15:16:33,335] INFO in train: epoch 0, batch 209: 0.269s\r\n```\r\n\r\n`feed_dict` (https://github.com/4Catalyzer/dl-papers/tree/benchmark-feed-data-only):\r\n```\r\n[2017-04-20 15:18:00,192] INFO in train: epoch 0, batch 200: 0.275s\r\n[2017-04-20 15:18:00,470] INFO in train: epoch 0, batch 201: 0.278s\r\n[2017-04-20 15:18:00,751] INFO in train: epoch 0, batch 202: 0.281s\r\n[2017-04-20 15:18:01,029] INFO in train: epoch 0, batch 203: 0.277s\r\n[2017-04-20 15:18:01,309] INFO in train: epoch 0, batch 204: 0.280s\r\n[2017-04-20 15:18:01,583] INFO in train: epoch 0, batch 205: 0.274s\r\n[2017-04-20 15:18:01,859] INFO in train: epoch 0, batch 206: 0.276s\r\n[2017-04-20 15:18:02,138] INFO in train: epoch 0, batch 207: 0.279s\r\n[2017-04-20 15:18:02,414] INFO in train: epoch 0, batch 208: 0.275s\r\n[2017-04-20 15:18:02,690] INFO in train: epoch 0, batch 209: 0.276s\r\n```\r\n\r\nThis doesn't say anything on TF v PyTorch, but it's consistent with what we saw earlier in there not being a huge performance gap between `feed_dict` and queues.", "Turns out I don't need to re-build TF after all. In fact it looks like all I need to do is to set `TF_ENABLE_WINOGRAD_NONFUSED=1`.\r\n\r\nI get comparable numbers to what you report above when using the 1.0.1 Docker image, and when installing 1.1.0rc2 from pip.\r\n\r\nAgainst https://github.com/4Catalyzer/dl-papers/tree/benchmark-queue as above:\r\n\r\n```\r\n[2017-04-20 15:25:47,770] INFO in train: epoch 0, batch 200: 0.162s\r\n[2017-04-20 15:25:47,934] INFO in train: epoch 0, batch 201: 0.164s\r\n[2017-04-20 15:25:48,100] INFO in train: epoch 0, batch 202: 0.165s\r\n[2017-04-20 15:25:48,266] INFO in train: epoch 0, batch 203: 0.166s\r\n[2017-04-20 15:25:48,431] INFO in train: epoch 0, batch 204: 0.164s\r\n[2017-04-20 15:25:48,594] INFO in train: epoch 0, batch 205: 0.164s\r\n[2017-04-20 15:25:48,761] INFO in train: epoch 0, batch 206: 0.167s\r\n[2017-04-20 15:25:48,926] INFO in train: epoch 0, batch 207: 0.164s\r\n[2017-04-20 15:25:49,089] INFO in train: epoch 0, batch 208: 0.163s\r\n[2017-04-20 15:25:49,254] INFO in train: epoch 0, batch 209: 0.165s\r\n```\r\n\r\nI can see the comment in the source code regarding testing, but this seems to make a significant difference in performance when using common model types that heavily use 3x3 convolutions.\r\n\r\nHow can we get this added to the TF documentation?", "@tfboyd is there an open ticket tracking the progress on (ie making this work):\r\n> Once we are sure WINOGRAD is working in all instances it will just be the default. \r\n\r\nI created: https://github.com/tensorflow/tensorflow/issues/9339", "@tfboyd Currently I don't have other machines to test on, but I ran both several times. TF is always within 5% slower. It's 1.94it/s for TF and around 1.99it/s for pytorch (without extra arguments to change the widen factor, etc). Before enabling the NONFUSED algorithm (cudnn algo No.7, as you can see in the log), TF is about 1.25it/s. \r\nI'm using Tesla M40, E5-2680v3, tensorflow nightly downloaded yesterday, cuda8.0, cudnn5.1. pytorch also uses cudnn5.1 \r\n\r\nI modified my TF code to use constant input and the results are the same. I'm looking at 10-step average time, but the number is quite stable after the warm-up.\r\n\r\nTo clarify a bit, my log shows that\r\n1. although TF and pytorch use different methods to choose cudnn algo, they chose the same algo for all the convolutions in this model.\r\n2. But in some convolution, they invoke cudnn with different shapes. I think that's because TF padding convention is different from others.\r\nAccording to the doc, for Conv32x32 kernel3 stride2 padSAME, TF will pad 0 at left/top and 1 at right/bottom. If I'm not mistaken, cudnn pad in the opposite way. This explains this line from TF VLOG:\r\n```\r\nConv accepts: 128, 160, (33, 33), 320, (3, 3), (2, 2), (1, 1), 1, 0 -> (1, 0)\r\n```\r\nwhere TF pre-pad the image to become (33,33) and then call cudnn ([code here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/conv_ops.cc#L562)). I'm just wondering could that be a possible performance issue, because 33 doesn't look like a good number for cache.\r\n\r\n", "@ppwwyyxx that is good data.  I am not super worried about 5% although I would like to close the gap. \r\n I will try to followup on this and get a bunch of the items mentioned above documented.    ", "I'd like to highlight that I think the biggest gap here is in DX. We started migrating from Theano to TensorFlow the first week of this year. This is partly my frustration speaking, but the process looked something like this:\r\n\r\n1. Write naive model implementations, which end up using NHWC and unfused batch norm.\r\n2. See documentation that suggests NCHW is faster for convolutions (this predates the perf guide). Refactor models to support both NCHW and NHWC, because we still need to support CPU inference. Observe that the models run ~6x slower. Give up on this for a bit.\r\n3. See documentation that fused batch norm is faster. Switch back from `tf.layers.batch_normalization` to `tf.contrib.layers.batch_norm`. This shows a performance improvement.\r\n4. Try NCHW again, and now see a performance improvement.\r\n  a. Realize earlier issue was due to https://github.com/tensorflow/tensorflow/issues/7551\r\n5. See the performance guide. Convert input pipeline to use queues instead of `feed_dict`. See negligible speedup.\r\n6. Compare to straightforward PyTorch impl, and observe that the PyTorch impl runs much faster.\r\n7. Learn through this issue that we need to enable an undocumented environment flag to access the fastest cuDNN mode for 3x3 convolutions.\r\n\r\nAs a developer, this is a really suboptimal experience.\r\n\r\nMy impression is that the modal TF example or published code is at something like our step (1) above, in that it uses NHWC, uses unfused batch norm, and doesn't enable the non-fused Winograd convolution. Correspondingly, performance is quite far from optimal.\r\n\r\nBy contrast, though with a smaller sample size, the PyTorch examples I've seen generally seem to do \"the right thing\" performance-wise, and seem to run quickly out-of-the-box. (Also, the status of the built-in PyTorch layer API makes separate PyTorch examples far more consistent in terms of how the code reads.)\r\n\r\nI'm very grateful for your help in tracking down these issues, but I really wish the out-of-the-box experience were better, and that it didn't take so much work to get to this point.", "I feel your pain.\r\n\r\nOn the plus side TF 1.1 gives you very similar performance of the \"secret flag\" that I should not have shared.  One step at a time.  I do not want to argue your points as I do understand the frustration.  On the feed_dict issue, even if it was not helpful to remove in this instance it is not normally a good practice for scaling.  Thank you for the feedback.  I consider this item closed and I will try to followup on the requests and items in the various comments.  ", "@tfboyd \r\n\r\nCan you double-check the timings you got against master without `TF_ENABLE_WINOGRAD_NONFUSED=1`?\r\n\r\nI just built TF by hand against master, with compute 3.7 and all the CPU stuff enabled, and without setting `TF_ENABLE_WINOGRAD_NONFUSED=1`, I still see:\r\n```\r\n[2017-04-20 20:27:27,056] INFO in train: epoch 0, batch 200: 0.284s\r\n[2017-04-20 20:27:27,340] INFO in train: epoch 0, batch 201: 0.284s\r\n[2017-04-20 20:27:27,616] INFO in train: epoch 0, batch 202: 0.276s\r\n[2017-04-20 20:27:27,898] INFO in train: epoch 0, batch 203: 0.282s\r\n[2017-04-20 20:27:28,175] INFO in train: epoch 0, batch 204: 0.277s\r\n```\r\n\r\nWith `TF_ENABLE_WINOGRAD_NONFUSED=1`, I see as expected:\r\n```\r\n[2017-04-20 20:29:37,525] INFO in train: epoch 0, batch 200: 0.170s\r\n[2017-04-20 20:29:37,695] INFO in train: epoch 0, batch 201: 0.169s\r\n[2017-04-20 20:29:37,861] INFO in train: epoch 0, batch 202: 0.166s\r\n[2017-04-20 20:29:38,028] INFO in train: epoch 0, batch 203: 0.166s\r\n[2017-04-20 20:29:38,195] INFO in train: epoch 0, batch 204: 0.167s\r\n```\r\n\r\nNaively this makes sense to me. The non-fused Winograd operation should still be the fastest for 3x3 convolutions, so it'd be odd to see a performance gain without enabling it.", "yeah I will.  It was late at night and it is possible I exported the variable and did not clear it.  I will include the sha-hash as well.  ", "@taion  Hey, I want to do a short write up for tensorflow-discuss covering your model and the flags we used to improve performance.  I know you are frustrated by the churn and these Flags are far from your or my ideal of \"awesome\".  That said and understood,  I want to provide others with these tips so they can get improved performance while we continue to bring the feature into the core.  I did not want to reference your Github without your permission.  I also would like to reference your github username as well if that is ok with you.   Obviously I need to work out if WINOGRAD is still needed as a FLAG in TF 1.1.  I ran out of time today.  I need to spin up my AWS instance (from an image) again and pull down the repos.  \r\n\r\nEdited for commas.", "Thanks again for your help.\r\n\r\nFeel free to reference our repo. We'd been meaning to open source some of our paper repros anyway, since there didn't seem to be many TF examples in the wild that supported flexible `data_format` and used fused batch norm.\r\n\r\nI personally don't mind churn at all; if anything I'd be quite happy to see e.g. defaults updated so that the fast way and the default way were the same.", "Feel free to reference me and/or the repo, I mean.", "Cool and thank you.  ", "@taion   I am finally back to doing a write up and I hope to send it this week but I suspect that means next week.  Also I confirmed what you saw.  Regardless of version, even the latest head of master, you need WINOGRAD on for the boost.  I am sure we have an internal bug to make that on by default or on when it makes sense, but I am going to start obnoxiously asking about it.  ", "Thanks, looking forward to it. We've since done some of that benchmarking on Pascal GPUs and verified that enabling non-fused Winograd wasn't as big a deal here, but it'd be great to see that massive speedup on 3x3 convolutions by default on Kepler. 3x3 convolutions are extremely common, and most cloud vendors are still only providing Kepler hardware."]}, {"number": 9321, "title": "Maximum points displaying on embedding", "body": "Hi, \r\nI got a embedding file with 1.5 million points, its that possible to show all 1.5 million points instead of the first 100 thousand points only? I have been asking around Stackoverflow but no one can answer that question. Trying to check all those documentation but dosent help at all.\r\n", "comments": ["Stackoverflow is the appropriate place to ask. This channel is reserved for bugs and feature requests.", "@drpngx Hi, i has been asking around stackoverflow but no one can answer that question. Its either a 'yes' or 'no' question.", "I would suggest looking at the code."]}, {"number": 9320, "title": "Don't work. Please fix your install script.", "body": "Please go to Stack Overflow for help and support. http://stackoverflow.com/questions/tagged/tensorflow\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g. fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### System Information\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:\r\n- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:\r\n- *TensorFlow installed from (source or binary)?*:\r\n- *TensorFlow version* (use command below):\r\n- *Bazel version (if compiling from source)*:\r\n- *CUDA/cuDNN version*:\r\n- *GPU Model and Memory*:\r\n- *Exact command to reproduce*:\r\n\r\nYou can collect some of this information using our environment capture script https://github.com/tensorflow/tensorflow/blob/master/tools/\r\nYou can collect the TensorFlow version with\r\n```sh\r\npython -c \"import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)\"\r\n```\r\n\r\n\r\n### Describe the problem clearly\r\n\r\n### Source Code / Logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem\r\n", "comments": ["Please fix your install script. Make it work. Documentation is the worst I have ever seen."]}, {"number": 9319, "title": "[feature] Mobile Integration with NNPACK", "body": "Caffe2 use can use [NNPACK](https://github.com/Maratyszcza/NNPACK) for [which it says](http://caffe2.ai/docs/mobile-integration.html#null__performance-considerations):\r\n>NNPACK, which specifically optimizes convolutions on ARM\r\n\r\n>Currently Caffe2 is optimized for ARM CPUs with NEON (basically any ARM CPU since 2012). Perhaps surprisingly, ARM CPUs outperform the on-board GPUs (our NNPACK ARM CPU implementation outperforms Apple\u2019s MPSCNNConvolution for all devices except the iPhone 7). \r\n\r\n>For a convolutional implementation, it is recommended to use NNPACK since that\u2019s substantially faster (~2x-3x) than the standard im2col/sgemm implementation used in most frameworks. \r\n\r\nThe readme for NNPACK lists Tensorflow as a framework that could potentially use it, though [that has not yet happened](https://github.com/Maratyszcza/NNPACK/issues/1).\r\n\r\nI believe that TF also avoids using the im2col/sgemm approach on mobile and instead uses the Eigen TensorConvolution. It would be good to benchmark these two options against each other and see if TF performance can be improved by using the `NNPACK` conv instead of the eigen conv. There is an open ticket to do this benchmarking: https://github.com/Maratyszcza/NNPACK/issues/30.\r\n\r\nAs a feature I suggest offering an `NNPACK` backed kernel to allow comparing vs Eigen.", "comments": ["@rmlarsen what do you think?", "Ping!\r\nAny updates here?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@aselle or @petewarden maybe?", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Any thoughts @aselle @petewarden on NNPACK?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Has anyone heard of progress integrating TensorFlow with NNPack?  I would love to use DarkFlow with NNPack on Raspberry Pi.  Currently, there is a Darknet version of NNPack for YOLO, but I'd like to optimize YOLO on another popular framework.  Or should I convert Darknet weights for use on another platform already compatible?  Recommendations?", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@tatianashp has been looking at CPU performance of kernels and may have some thoughts here (on Intel CPUs, MKL is an option)\r\n\r\n@aselle for some thoughts particularly for TFLite.\r\n\r\n", "Nagging Assignees @aselle, @tatianashp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @aselle, @tatianashp: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @aselle, @tatianashp: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @aselle, @tatianashp: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @aselle, @tatianashp: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We don't have anybody working on integration of NNPACK in TensorFlow. If somebody in the community wants to take a stub at it, contributions are most welcome. Let us know if you need any guidance.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "please check the latest developments here https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html."]}, {"number": 9318, "title": "Not all image ops accept image tensors with batch dimension", "body": "It appears that only some of the image ops (e.g. `tf.image.random_saturation()`) only accept single images (rank-3 tensors), while others allow batches of images (rank-4 tensors). Should this be made more consistent so that all image ops allow for higher-rank tensors? There doesn't seem to be much about this in the API documentation (some ops just say that the last dimension needs to be 3).\r\n\r\n### System Information\r\n- *Have I written custom code?*: Yes\r\n- *OS Platform and Distribution*: Ubuntu 16\r\n- *TensorFlow installed from (source or binary)?*: binary\r\n- *TensorFlow version*: 1.0.1\r\n- *Bazel version (if compiling from source)*: N/A\r\n- *CUDA/cuDNN version*: N/A\r\n- *GPU Model and Memory*: N/A\r\n- *Exact command to reproduce*:\r\n```python\r\nimport tensorflow as tf\r\nimages = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='images')\r\n# This is OK\r\nx = tf.image.random_contrast(images, lower=0.5, upper=1.0)\r\n# Throws an exception because `images` is rank-4\r\nx = tf.image.random_saturation(images, lower=0.5, upper=1.0)\r\n```", "comments": ["That sounds like a good idea.\r\n\r\n@tatatodd may have some comment.", "See also: https://github.com/tensorflow/tensorflow/issues/8926", "Ah, thanks @cancan101 I must've missed that. I'll go ahead and close this since it seems to be a duplicate."]}, {"number": 9317, "title": "Explain what tf.nn.softplus does to integers", "body": "[`tf.nn.softplus`](https://www.tensorflow.org/api_docs/python/tf/nn/softplus) computes `log(1 + exp(x))`.  Naively, I wouldn't expect this to work for integers, but it does.  On integers, it seems to degenerate to a poorly named version of `tf.relu`: it computes `max(0, x)`.\r\n\r\nWe probably can't eliminate the integer versions for backward compatibility reasons, but we should at least explain what they do.", "comments": ["/CC @wolffg for documentation.\r\n\r\n", "Hmm, there seems to be more of this in `core/ops/nn_ops.cc`.  E.g., `softsign` is the same.\r\n\r\nI added it to the doc fixit spreadsheet.", "`tf.nn.softsign` on ints is rather less useful: it's the constant zero function.\r\n\r\n@martinwicke: Maybe we should drop these?  Arguably they're just bugs.", "I'm a little reluctant to remove the functionality since that will break graphs (and code) that worked before. But a warning (deprecation?) would be nice."]}, {"number": 9316, "title": "MultiRNNcell expected state to tuple but its a tensor", "body": "i have define my lstm_cell as \r\n\r\n`def lstm(state, input_data, num_steps, hidden_size, num_layers, name):`\r\n   ` # Input: (B, T, N) `\r\n     `with tf.variable_scope(name) as scope: `\r\n        ` multi_lstm = MultiRNNCell([BasicLSTMCell(hidden_size)] * num_layers) `\r\n         `outputs = [] `\r\n         `for t in range(num_steps): `\r\n             `output, state = multi_lstm(input_data[:, t, :], state) `\r\n            ` output = batch_normalization(output, [0, 1], \"batch\") `\r\n            ` outputs.append(output) `\r\n            ` scope.reuse_variables() `\r\n         `return outputs`\r\n\r\nNow after defining my inputs for lstm_cell as\r\n`lstm_input = tf.reshape(c13, [B, M, -1])`\r\n`lstm_state = tf.reduce_mean(lstm_input, [1])`\r\n\r\n and passing my values to lstm() , i am getting the following error \r\n` Expected state to be a tuple of length 6, but received: Tensor(\"Mean:0\", shape=(25, 1568), dtype=float32)`", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 9315, "title": "Utilize InlinedVector::emplace_back", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 9314, "title": "tf.get_collection documentation: argument description is confusing", "body": "From https://www.tensorflow.org/api_docs/python/tf/get_collection:\r\n\r\n\"Items without a name attribute are never returned if a scope is supplied and the choice or re.match means that a scope without special tokens filters by prefix.\"\r\n\r\nWhat does this mean? Is there a typo here?", "comments": ["I think that's \"of\" rather than \"or\". Let me check internally.", "@sguada @martinwicke who reviewed 120141411.", "Yes, that should be an \"of\", and we should probably also insert a comma before \"and the choice\" to make the structure clearer.", "@dmonopoly would you care to send a PR?", "Sure thing", "Thanks! Make sure you put `Fixes #9314` in the commit message & CC me on the PR.", "I'll get to this later this week. Looking around for other fixes as well. Feel free to assign to me."]}, {"number": 9313, "title": "`Evaluable` docs: name, checkpoint_path, and hooks should be new bullets.", "body": "See https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Evaluable - final params for evaluate() are not bullets, making reading the documentation less readable. I've seen this in other docs too (can comment if I come across more of them).\r\n\r\nI wonder if the parser has some bug that causes it to not bullet-ify some params for functions.", "comments": ["It's typically an error in the MD format, like missing spaces in front the bullet.", "Where are the instructions on how to generate the docs?\r\n\r\nI could make this fix here and in multiple other places if I can just generate the docs to check that my changes fix things like this.", "Nm found it here via #1574  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/community/documentation.md", "I think the issue is the extra line in `metrics:` args description in python code. PR #10423 "]}, {"number": 9312, "title": "Typo in seq2seq.attention_wrapper.py", "body": "Hi,\r\n I think there is a small typo in contrib.seq2seq.attention_wrapper.py, would someone like to check it?\r\ncode url: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L471]\r\nI guess it should be _probability_fn_ rather than _cell_input_fn_ to be checked.\r\n\r\nThanks.", "comments": ["Yes, could you send a PR to fix this?\r\n\r\n/CC: @ebrevdo ", "yes please!\n\nOn Wed, Apr 19, 2017 at 9:57 AM, drpngx <notifications@github.com> wrote:\n\n> Yes, could you send a PR to fix this?\n>\n> /CC: @ebrevdo <https://github.com/ebrevdo>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/9312#issuecomment-295343911>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim3R_dvUJtttYzVdb_zSrz70zJrTgks5rxjzugaJpZM4NBuTr>\n> .\n>\n", "I have sent a PR, please let me know if any questions.", "Merged."]}, {"number": 9311, "title": "Update README.md", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@av8ramit does this look good to you (note it is targeting the r1.1 branch)"]}, {"number": 9310, "title": "Is tf.train.import_meta_graph() contextual with tf.global[local]_variables_initializer() ?", "body": "**I can use these pieces of codes to continue my training with pre-trained model**:\r\n\r\n     tf.reset_default_graph() \r\n     new_saver = tf.train.import_meta_graph(\"xxx.meta\")\r\n     new_saver.restore(sess, \"xxx.ckpt-yyy\")\r\n\r\nHere the 'tf.reset_default_graph() is necessary'  to solve the 'redefine of ops' issues.But,**when I  launched  forward pass(in another .py file) like** :\r\n\r\n     tf.reset_default_graph() \r\n     new_saver = tf.train.import_meta_graph(\"xxx.meta\")\r\n     new_saver.restore(sess, \"xxx.ckpt-yyy\")\r\n     images_placeholder = tf.get_default_graph().get_tensor_by_name(\"image_batch:0\")\r\n     embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n\r\n**with 'tf.reset_default_graph()' I got** :\r\n\"Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph\"\r\n**without 'tf.reset_default_graph()'  and with 'tf.global[local]_variables_initializer()' before or without it** like:\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(tf.local_variables_initializer())\r\n     new_saver = tf.train.import_meta_graph(\"xxx.meta\")\r\n     new_saver.restore(sess, \"xxx.ckpt-yyy\")\r\n     images_placeholder = tf.get_default_graph().get_tensor_by_name(\"image_batch:0\")\r\n     embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n #Without initializer\r\n #sess.run(tf.global_variables_initializer())\r\n #sess.run(tf.local_variables_initializer())\r\n     new_saver = tf.train.import_meta_graph(\"xxx.meta\")\r\n     new_saver.restore(sess, \"xxx.ckpt-yyy\")\r\n     images_placeholder = tf.get_default_graph().get_tensor_by_name(\"image_batch:0\")\r\n     embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n\r\nI got : \"**FailedPreconditionError: Attempting to use uninitialized value...**\".But like:\r\n   new_saver = tf.train.import_meta_graph(\"xxx.meta\")\r\n   new_saver.restore(sess, \"xxx.ckpt-yyy\")\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(tf.local_variables_initializer())\r\n   images_placeholder = tf.get_default_graph().get_tensor_by_name(\"image_batch:0\")\r\n   embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\nI got neither warnings nor errors info,but the result is all features of embeddings is 0.Maybe 'tf.global[local]_variables_initializer()' has cleared the loaded weights ?\r\nAfter that I **used the  frozen graph which was produced by pre-trained model to launch forward,like**:\r\n with tf.Graph().as_default():\r\n        graph_def_ = graph_pb2.GraphDef()\r\n        print('Model directory: %s' % os.path.expanduser(args.modelpb_file))\r\n        with open(os.path.expanduser(args.modelpb_file),'rb') as f:\r\n             graph_def_.ParseFromString(f.read())\r\n             _ = importer.import_graph_def(graph_def_,name=\"\")\r\n        with tf.Session() as sess:         \r\n            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"image_batch:0\")\r\n            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\nI still got the \"**FailedPreconditionError: Attempting to use uninitialized value...**\" issues.\r\nReally confusing,who can help ?\r\n\r\n\r\n", "comments": ["Does your checkpoint contain values for all variables? Which is the variable that's is missing initialization?", "Hi,@drpngx \r\nIf I use \r\n\r\n> \r\n\r\nnew_saver = tf.train.import_meta_graph(\"xxx.meta\")\r\nnew_saver.restore(sess, \"xxx.ckpt-yyy\")\r\n\r\n> \r\n\r\n to run forward pass the only cannot uninitialized value is \".../moments/moments_1/mean/ExponentialMovingAverage\" .This is \"batch_norm\" codes as \r\n\r\n> \r\n    with tf.variable_scope(name):\r\n        phase_train = tf.convert_to_tensor(phase_train, dtype=tf.bool)\r\n        n_out = int(x.get_shape()[3])\r\n        beta = tf.Variable(tf.constant(0.0, shape=[n_out], dtype=x.dtype),\r\n                           name=name+'/beta', trainable=True, dtype=x.dtype)\r\n        gamma = tf.Variable(tf.constant(1.0, shape=[n_out], dtype=x.dtype),\r\n                            name=name+'/gamma', trainable=True, dtype=x.dtype)      \r\n        batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\r\n        ema = tf.train.ExponentialMovingAverage(decay=0.9)\r\n        def mean_var_with_update():\r\n            ema_apply_op = ema.apply([batch_mean, batch_var])\r\n            with tf.control_dependencies([ema_apply_op]):\r\n                return tf.identity(batch_mean), tf.identity(batch_var)\r\n        mean, var = control_flow_ops.cond(phase_train,\r\n                                          mean_var_with_update,\r\n                                          lambda: (ema.average(batch_mean), ema.average(batch_var)))\r\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\r\n    return normed\r\n> \r\nIf I use \r\n> \r\n\r\n\r\nslim.arg_scope([slim.conv2d],\r\n                        weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\r\n                        weights_regularizer=slim.l2_regularizer(weight_decay),\r\n                        normalizer_fn=slim.batch_norm,\r\n                        normalizer_params=batch_norm_params)\" \r\n\r\n\r\n> \r\n\r\nto replace my code no issue occurred.\r\nThank you anyway."]}, {"number": 9309, "title": "Tensorflow slim - TypeError: softmax_cross_entropy() got an unexpected keyword argument 'weight' ", "body": "Hi ,\r\n\r\nI am using slim/train_image_classifier.py to train inception V1 model from scratch on my own dataset and fine-tuning inception V1 model from the link: https://github.com/tensorflow/models/blob/master/slim/README.md#Pretrained\r\n\r\n**System Information:**\r\nRAM : 4GB\r\nTensorFlow Version : 1.0\r\nOS  : Linux 14.04 \r\n\r\nI am using following command for training from scratch but ended up in Error\r\n\r\n\r\n```\r\npython train_image_classifier.py     \r\n     --train_dir=${TRAIN_DIR}\r\n     --dataset_name=mydataset \r\n     --dataset_split_name=train\r\n     --dataset_dir=${DATASET_DIR}\r\n     --model_name=inception_v1 \r\n\r\n```\r\n\r\n**Note:** Here mydataset is same as flower.py except:\r\n\r\nSPLITS_TO_SIZES = {'train': 4310. 'validation': 350}\r\n\r\n\r\n**Error:**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_image_classifier.py\", line 585, in <module>\r\n    tf.app.run()\r\n File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"train_image_classifier.py\", line 482, in main\r\n    clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])\r\n  File \"/home/purushoth/Downloads/models-master/slim/deployment/model_deploy.py\", line 195, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\nFile \"train_image_classifier.py\", line 476, in clone_fn\r\n    logits, labels, label_smoothing=FLAGS.label_smoothing, weight=1.0)\r\n File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 117, in new_func\r\n    return func(*args, **kwargs)\r\nTypeError: softmax_cross_entropy() got an unexpected keyword argument 'weight'\r\n```\r\n\r\n\r\nI have tried \r\n      \r\n- upgrading **train_image_classifier.py** file \r\n\r\n- fine - tuning the inception V1 model from existing checkpoint \r\n  \r\nbut still I am facing same error.\r\n\r\nAm I doing something wrong ?? Thanks for any help.\r\n", "comments": ["The correct parameter name is `weights`, not `weight`."]}, {"number": 9308, "title": "Trying to use tensorflow to classify multi-class data", "body": "tensorflow is a new tool for me and this is my first try. I'm trying to train my model using jupyter notebook in 'mac' for a Multi-class problem (Bike Sharing Demand | Kaggle). I am using '1.0.1' tensorflow version and Python 3.5. I have this error: \r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-364-b19ec441d9ef> in <module>()\r\n      5 tf.global_variables_initializer().run()\r\n      6 for _ in range(1000):\r\n----> 7     sess.run(train_step, feed_dict={x: X, y_: Y})\r\n\r\nValueError: Cannot feed value of shape (10, 10886) for Tensor 'Placeholder_66:0', which has shape '(?, 10)'\r\n```\r\n\r\nMy Feature size= (10886,10) & Label size= (10886,1).\r\n\r\nMy goal is to predict how many customers will rent the bike per day. I found 822 different number in the labels. I used this number to fix number of classes to fit the code. I am wondering if I did something wrong in the code or tensorflow doesn't work for this kind of problems?  \r\n\r\nyou can find my code written below:\r\n\r\n```\r\nX = np.array(train[['season','weather','temp','weekday','month','humidity','new_windspeed','hours','year','atemp']]) #My train input features\r\nX = np.transpose(X)\r\nY = np.array(train['count']) # label\r\nY=np.reshape(Y,(1,10886))\r\nlearning_rate= 0.000001\r\ntraining_epochs= 2000\r\ndisplay_step= 50\r\nn_samples= Y.size\r\nx= tf.placeholder(tf.float32,[None,10])\r\nW = tf.Variable(tf.zeros([10,822])) \r\nb = tf.Variable(tf.zeros([822]))\r\ny = tf.nn.softmax(tf.matmul(x,W)+b)\r\ny_ = tf.placeholder(tf.float32, [None,822])\r\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\r\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\r\nsess = tf.InteractiveSession()\r\ntf.global_variables_initializer().run()\r\nfor _ in range(1000):\r\n    sess.run(train_step, feed_dict={x: X, y_: Y})\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nThat said, your problem is that you have to transpose the features, or change the network so that it expects transposed features."]}, {"number": 9307, "title": "Segmentation fault in tensorflow::FileSystemRegistryImpl::Register", "body": "Syntaxnet package was built, tf package ver 1.01 was installed from repo by pip as dependency. Fortunately tf installed following these instructions https://www.tensorflow.org/versions/r0.10/get_started/os_setup#create_the_pip_package_and_install works fine.\r\n```\r\n[New LWP 31764]\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\nCore was generated by `python2 -c from syntaxnet import load_parser_ops'.\r\nProgram terminated with signal SIGSEGV, Segmentation fault.\r\n#0  0x00007f3303cf0d47 in std::_Hash_bytes(void const*, unsigned long, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n(gdb) bt\r\n#0  0x00007f3303cf0d47 in std::_Hash_bytes(void const*, unsigned long, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#1  0x00007f33065f509c in tensorflow::FileSystemRegistryImpl::Register(std::string const&, std::function<tensorflow::FileSystem* ()>) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#2  0x00007f33065f26b3 in tensorflow::Env::RegisterFileSystem(std::string const&, std::function<tensorflow::FileSystem* ()>) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#3  0x00007f3328d327b5 in _GLOBAL__sub_I_env.cc () from /usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so\r\n#4  0x00007f3332df04ea in call_init (l=<optimized out>, argc=argc@entry=3, argv=argv@entry=0x7ffe61a27428, env=env@entry=0x265a8b0) at dl-init.c:72\r\n#5  0x00007f3332df05fb in call_init (env=0x265a8b0, argv=0x7ffe61a27428, argc=3, l=<optimized out>) at dl-init.c:30\r\n#6  _dl_init (main_map=main_map@entry=0x2a41360, argc=3, argv=0x7ffe61a27428, env=0x265a8b0) at dl-init.c:120\r\n#7  0x00007f3332df5712 in dl_open_worker (a=a@entry=0x7ffe61a263e0) at dl-open.c:575\r\n#8  0x00007f3332df0394 in _dl_catch_error (objname=objname@entry=0x7ffe61a263d0, errstring=errstring@entry=0x7ffe61a263d8, mallocedp=mallocedp@entry=0x7ffe61a263cf, \r\n    operate=operate@entry=0x7f3332df5300 <dl_open_worker>, args=args@entry=0x7ffe61a263e0) at dl-error.c:187\r\n#9  0x00007f3332df4bd9 in _dl_open (file=0x7f332e1634cc \"/usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so\", mode=-2147483646, \r\n    caller_dlopen=0x7f33065fa9ea <tensorflow::internal::LoadLibrary(char const*, void**)+26>, nsid=-2, argc=<optimized out>, argv=<optimized out>, env=0x265a8b0)\r\n    at dl-open.c:660\r\n#10 0x00007f33325f6f09 in dlopen_doit (a=a@entry=0x7ffe61a26610) at dlopen.c:66\r\n#11 0x00007f3332df0394 in _dl_catch_error (objname=0x252e0d0, errstring=0x252e0d8, mallocedp=0x252e0c8, operate=0x7f33325f6eb0 <dlopen_doit>, args=0x7ffe61a26610)\r\n    at dl-error.c:187\r\n#12 0x00007f33325f7571 in _dlerror_run (operate=operate@entry=0x7f33325f6eb0 <dlopen_doit>, args=args@entry=0x7ffe61a26610) at dlerror.c:163\r\n#13 0x00007f33325f6fa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87\r\n#14 0x00007f33065fa9ea in tensorflow::internal::LoadLibrary(char const*, void**) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#15 0x00007f33065f9b97 in tensorflow::(anonymous namespace)::PosixEnv::LoadLibrary(char const*, void**) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#16 0x00007f33064f6f93 in tensorflow::LoadLibrary(char const*, void**, void const**, unsigned long*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#17 0x00007f3304e11e67 in TF_LoadLibrary () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#18 0x00007f3304d1206a in _wrap_TF_LoadLibrary () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\r\n#19 0x00000000004c468a in PyEval_EvalFrameEx ()\r\n#20 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#21 0x00000000004ca8d1 in PyEval_EvalFrameEx ()\r\n#22 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#23 0x00000000004c2509 in PyEval_EvalCode ()\r\n#24 0x00000000004c061b in PyImport_ExecCodeModuleEx ()\r\n#25 0x00000000004bd6ee in ?? ()\r\n#26 0x00000000004afbad in ?? ()\r\n#27 0x00000000004af7e9 in PyImport_ImportModuleLevel ()\r\n#28 0x00000000004b0f78 in ?? ()\r\n#29 0x00000000004b0cb3 in PyObject_Call ()\r\n#30 0x00000000004ce5d0 in PyEval_CallObjectWithKeywords ()\r\n#31 0x00000000004c6ed6 in PyEval_EvalFrameEx ()\r\n#32 0x00000000004c2765 in PyEval_EvalCodeEx ()\r\n#33 0x00000000004c2509 in PyEval_EvalCode ()\r\n#34 0x0000000000521186 in PyRun_StringFlags ()\r\n#35 0x0000000000521dfc in PyRun_SimpleStringFlags ()\r\n#36 0x000000000049de94 in Py_Main ()\r\n#37 0x00007f333281a830 in __libc_start_main (main=0x49dab0 <main>, argc=3, argv=0x7ffe61a27428, init=<optimized out>, fini=<optimized out>, \r\n    rtld_fini=<optimized out>, stack_end=0x7ffe61a27418) at ../csu/libc-start.c:291\r\n#38 0x000000000049d9d9 in _start ()\r\n```", "comments": ["@keveman I think it's yet another case of overriding symbols with different underlying static variables.\r\n\r\n@inferrna I think it's a known bug with tensorflow that wherein external ops outside of the main tensorflow code are unstable. Try linking against `_pywrap_tensorflow` instead.\r\n\r\n/CC: @nealwu ", "/CC: @skye ", "friendly ping: is this still an issue?", "Yes, I believe this is a case of #9525", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@calberti @andorardo @bogatyy @markomernick any idea?", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Closing this out as a duplicate of #9525.  Follow-up there with additional details."]}]