[{"number": 50632, "title": "Test //tensorflow/compiler/mlir/lite/tests/end2end:quant_stats.pbtxt.test succeeds regardless of check patterns", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installation (pip package or built from source):\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): a4dfb8d1a71385bd6d122e4f27f86dcebb96712d (v2.5.0)\r\n\r\n### 2. Code\r\n\r\n`bazel test //tensorflow/compiler/mlir/lite/tests/end2end:quant_stats.pbtxt.test`\r\n\r\nalways passes regardless of the check patterns in \r\n\r\n`tensorflow/compiler/mlir/lite/tests/end2end/quant_stats.pbtxt`\r\n\r\nE.g. even when this file is replaced with the deliberately mangled version the test still passes.\r\n\r\n[mangled_quant_stats.pbtxt.txt](https://github.com/tensorflow/tensorflow/files/6770259/mangled_quant_stats.pbtxt.txt)\r\n\r\n[always_passes.log](https://github.com/tensorflow/tensorflow/files/6770295/always_passes.log)\r\n\r\n### 3. (optional) Any other info / logs\r\n\r\nRunning the relevant FileCheck command-line manually fails in the expected way.\r\n\r\n[always_passes.log](https://github.com/tensorflow/tensorflow/files/6770295/always_passes.log)\r\n\r\nThe committed version of the test will also fail if run manually in this way (minor changes in operator attribute).", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50632\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50632\">No</a>\n"]}, {"number": 50631, "title": "Container __per_step_0 does not exist", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10\r\n- TensorFlow version (use command below):  2.3.1\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version:  library cudart64_101.dll v2.3.0-54-gfcc4b966f1 2.3.1\r\n\r\n**Describe the current behavior**\r\n\r\nWhile running multiple object detection inference in parallel the session crashed and the below error occurred.\r\n\r\nTraceback (most recent call last):\r\n    output_dict = model(input_tensor)\r\n  File \"/home//.conda/envs//lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1605, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/home//.conda/envs//lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1645, in _call_impl\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"/home//.conda/envs//lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home//.conda/envs//lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 598, in call\r\n    ctx=ctx)\r\n  File \"/home//.conda/envs//lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.NotFoundError:  Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysBatchMultiClassNonMaxSuppression/map/TensorArray_11_950)\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/TensorArrayWrite_5/TensorArrayWriteV3 (defined at /home/workspace//utils/field_detection.py:15) ]] [Op:__inference_pruned_41885]\r\n\r\nFunction call stack:\r\npruned\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nReproducing the issue was not possible.\r\n\r\n", "comments": ["@DaliaJaber \r\n\r\nCould you please refer the [comment](https://github.com/tensorflow/tensorflow/issues/28287#issuecomment-495005162)        ,hope it helps.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50630, "title": "How can i know the order of multiple inputs when i use TrtGraphConverterV2 build. ", "body": "tensorflow version: tensorflow-gpu 2.0.4\r\ncuda version: 10.0\r\ncudnn version: 7.4\r\ntensorrt version: 5.1.5\r\n\r\nWhen i use tensorrt converter to convert my model, i can't know the order of multiple inputs. Such as:\r\n\r\n```\r\nconverter = trt.TrtGraphConverterV2(***)\r\nconverter.convert()\r\ndef my_inp_fn():\r\n    inp_1 = np.zeros((2000, 120), np.int32)\r\n    inp_2 = np.zeros((1, 47), np.int32)\r\n    inp_3 = np.zeros((2000, 178), np.int32)\r\n    inp_4 = np.zeros((1, 1493), np.int32)\r\n    inp_5 = np.zeros((2000, 12), np.int32)\r\n    inp_6 = np.zeros((1, 54), np.int32)\r\n    inp_7 = np.zeros((2000, 178), np.float32)\r\n    inp_8 = np.zeros((1, 1493), np.float32)\r\n    inp_9 = np.zeros((2000, 93), np.float32)\r\n    inp_10 = np.zeros((1, 12), np.float32)\r\n    yield [inp_1, inp_2, inp_3, inp_4, inp_5, inp_6, inp_7, inp_8, inp_9, inp_10]\r\nconverter.build(input_fn=my_inp_fn)\r\n```\r\n\r\nI use saved_model_cli tool to check the signature input. But the signature input order is not true order for trt convert build function. Build function will report error with wrong order. Like:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute __inference_pruned_26473 as input #8(zero-based) was expected to be a int32 tensor but is a float tensor [Op:__inference_pruned_26473]\r\n```\r\nI can't analyse the order with the too simple error log.\r\n\r\nThanks very much!", "comments": ["So, how can i know the order of multiple inputs when i use TrtGraphConverterV2 build ?", "You may use TensorBoard to visualize TF-TRT graph\r\nhttps://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#tensorboard", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50629, "title": "Confusing about GPU state when ran out of memory", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7 (Core)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not mobile device\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==1.15\r\n- TensorFlow version (use command below): tensorflow-gpu==1.15\r\n- Python version: 3.6.12\r\n- Bazel version (if compiling from source): 0.18.0-\r\n- GCC/Compiler version (if compiling from source):4.8.5\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nMy GPU model ran out of memory during training process, it reports the GPU state as follows:\r\n\r\n![\u622a\u5c4f2021-07-06 \u4e0b\u53486 51 53](https://user-images.githubusercontent.com/5723913/124589692-dc6f4700-de8c-11eb-868f-f0365e989bdd.png)\r\n\r\nAs shown above, \"Limit\" indicates that the total memory of my GPU is  22,676,357,120 bytes, which is equal to my Tesla P40 GPU's 22G memory. \"InUse\" means the GPU has allocated 11,866,777,088 bytes. Thus the remaining memory should be 22,676,357,120 - 11,866,777,088 = 10,809,580,032 bytes. Now the process need to allocate 5,352,895,488 bytes, which is less than 10,809,580,032 bytes. So why does it report the process ran out memory?\r\n\r\nAnd what is the meaning of \"MaxInUse\" and \"MaxAllocSize\" ?\r\n", "comments": ["@lonway \r\nCould you please upgrade the tensorflow version to 2.x and let us know if you face the issue as 1.x is not actively supported.\r\n\r\nIn 2.x you may try:\r\n[You may try limiting gpu memory growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) in this case.\r\nPut following snippet on top of your code;\r\n\r\n```import tensorflow as tf```\r\n```gpus = tf.config.experimental.list_physical_devices('GPU')```\r\n```tf.config.experimental.set_memory_growth(gpus[0], True)```\r\n```# your code```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Saduf2019 Our online system does not support tensorflow 2.x :(", "@lonway \r\nAs we have active support for 2.x now, please create this issue on tf discuss forum as there is a larger community to support there.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50626, "title": "TensorFlow 2.3.0 does not respect no_proxy environment variable", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.5 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binay\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version: Python 3.6.2\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nTensorFlow does not recognize environment variable `no_proxy` and `no_grpc_proxy`. \r\nWe have set `http_proxy` and `no_proxy` in the environment variable, and tf seems only pickup http_proxy, use the http_proxy for the inter worker grpc communication and got error like this\r\n> {\"created\":\"@1625564310.040212700\",\"description\":\"Error received from peer ipv4:proxy_ip:8080\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Socket closed\",\"grpc_status\":14} [Op:CollectiveBcastRecv] \r\n\r\nThis is the TF_CONFIG: \r\n> TF_CONFIG={\"cluster\": {\"worker\": [\"10.0.0.7:45661\", \"10.0.0.7:46771\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}, \"environment\": \"cloud\"}\r\n\r\nThis is proxy_related env:\r\n> http_proxy=http://proxy-ip:8080/\r\nno_proxy=proxy-ip,localhost,10.0.0.4,10.0.0.5,10.0.0.6,10.244.0.0/16,10.0.0.0/8\r\n\r\n\r\n**Describe the expected behavior**\r\nGRPC should not use proxy since we have defined the ip not to use proxy.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["What is the grpc version used by TensorFlow? Since I saw a similar [issue ](https://github.com/grpc/grpc/issues/9989) in GRPC repo and it was fixed in v1.13.0.", "I missed an IP in `no_proxy`, after adding `10.0.0.7` into `no_proxy` the job finished with no error.\r\nThanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50626\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50626\">No</a>\n"]}, {"number": 50625, "title": "Make layers from `tensorflow.keras.layers.experimental.preprocessing` usable in TF Lite", "body": "**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIt would be awesome if layers from `tensorflow.keras.layers.experimental.preprocessing` like `Resizing` would be convertable to TF Lite without implementing custom ops.\r\n\r\nCurrently a custom op definition is needed for (some of) them to work.\r\nEspecially Lanczos3 for Resizing would be nice.\r\n\r\n**Will this change the current api? How?**\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\nIt would be very easy to add preprocessing inside a model. Therefore people who want to use those models do not need information about what input format should be used.\r\n", "comments": ["@CaptainDario \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "Thank you!\nI did not know that keras and TensorFlow are separated repos now.\nI will open the issue in that repo than."]}, {"number": 50624, "title": "tensorflow lite compiling failed on docker", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\nI compile tensorflow lite in android mode according to the online guide: https://www.tensorflow.org/lite/guide/build_android\r\n\r\n- the docker file provided by tflite can not be built successfully by docker\r\n    - https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/dockerfiles/tflite-android.Dockerfile\r\n\r\n![image](https://user-images.githubusercontent.com/45189361/124571655-927d6580-de7a-11eb-9297-02e55932a6f7.png)\r\n\r\n- However, I modified the docker file and rebuilt the docker successfully. I entered into docker container but tflite compiling still failed.\r\n   - jdk version: 1.8\r\n   - command : `bazel build -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a   --host_crosstool_top=@bazel_tools//tools/cpp:toolchain   //tensorflow/lite/java:tensorflow-lite`\r\n\r\n![image](https://user-images.githubusercontent.com/45189361/124571996-dbcdb500-de7a-11eb-8190-1d498580b2fb.png)\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Sorry. the \"install default-jdk\" is introduced by me to fix the error you mentioned below.", "I sent a fix for that.\r\nChanging:\r\n`sudo apt install default-jdk`\r\nto:\r\n`RUN apt-get install -y --no-install-recommends default-jdk`", "The fix is merged in the master branch. You can sync and try it now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50624\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50624\">No</a>\n"]}, {"number": 50623, "title": "[PluggableDevice] add DEVICE_DEFAULT for session/transpose ops", "body": "Add DEVICE_DEFAULT for session/transpose ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you help to review it? there are also several other PRs related with DEVICE_DEFAULT, thanks.\r\n```\r\nhttps://github.com/tensorflow/tensorflow/pull/50623\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50610\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50609\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50608\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50605\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50604\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50603\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50602\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50601\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50600\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50581\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50580\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/50578\r\n```\r\n\r\n", "Hey @jzhoulon, \r\n\r\n> @saxenasaurabh Can you help to review it? there are also several other PRs related with DEVICE_DEFAULT, thanks.\r\n> \r\n> ```\r\n> https://github.com/tensorflow/tensorflow/pull/50623\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50610\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50609\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50608\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50605\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50604\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50603\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50602\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50601\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50600\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50581\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50580\r\n> \r\n> https://github.com/tensorflow/tensorflow/pull/50578\r\n> ```\r\n\r\nHey @jzhoulon, these are on my radar. I will try to review this week or next. Thanks for the patience!"]}, {"number": 50621, "title": "Fix issue with collective_nccl_test.", "body": "This issue was caught by our internal CI.\r\n\r\n/cc @cheshire @jpienaar ", "comments": ["I'm a bit confused as to how we were able to check in the code which does not build.", "@cheshire same", "@rsanthanam-amd can you please update your branch ", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50621) for more info**.\n\n<!-- need_author_cla -->", "@rthadur I have updated my branch.", "The change is empty, I think this has been merged already.", "@cheshire @jpienaar Confirmed that the fix has already been made in this commit: https://github.com/tensorflow/tensorflow/commit/8557ca660aa7b1d5853d3a1f2fe19cae5be4b589"]}, {"number": 50620, "title": "tf.math.sigmoid/tanh for RaggedTensor", "body": "I was surprised to see that two common activation functions, sigmoid and tanh, are not provided in `tf.ragged` module. Makes me wonder how many people are actually using RaggedTensor features with no feature requests for these.\r\n\r\nI am currently calculating both via mathematical identities. However, I still think the API's between regular Tensor and RaggedTensor should be as close as possible, as ideally you should be able to just swap in a RaggedTensor and have everything just work.", "comments": ["To apply elementwise ops (or other elementwise functions) to ragged tensors, you can generally use `tf.ragged.map_flat_values`.  E.g., `tf.ragged.map_flat_values(tf.math.tanh, x)`.\r\n\r\nThough I agree that you shouldn't have to do that -- where possible, ops should just work w/ ragged tensors.  I'm not sure why these two ops were left off the list of elementwise ops to dispatch for.  \r\n\r\nIt looks like dispatch for `sigmoid` was added recently (bc5eddee3dda337c5b9287691b55d7a363b65c7b), but `tanh` hasn't been added yet.  ", "I went through the ops under `tf.math`, and checked for any elementwise ops that didn't already have dispatch.  I'll send a PR to add dispatch for these ops.  The ops I identified were:\r\n\r\n* tf.math.atan2\r\n* tf.math.erfcinv\r\n* tf.math.nextafter\r\n* tf.math.recipricol_no_nan\r\n* tf.math.softplus\r\n* tf.math.tanh\r\n* tf.math.bessel_i0 \r\n* tf.math.bessel_i0e\r\n* tf.math.bessel_i1\r\n* tf.math.bessel_i1e\r\n\r\nLet me know if you notice any other elementwise ops that should have dispatch enabled.\r\n", "Fixed by 99f145872e474a603472e5d096631906bba86912."]}, {"number": 50618, "title": "error reporting model(x) vs model.predict(x)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\n\r\nThe error and warning messages seem to be different when `model(x)` is used instead of `model.predict(x)`  to make a prediction.\r\nIs this intentional and documented somewhere? \r\nFor example, in the following simple model there is a warning when `model.predict(x)` is used, but none for `model(x)`. \r\nMoreover, it would be generally good to know which warnings (or errors) might not occur when a specific prediction method is used and also which warnings will be the same.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\nmodel = keras.Sequential([\r\nkeras.layers.ReLU(threshold=3,  input_shape=(2,))])\r\nx = tf.constant([[[[1,2,3,4,5]]]])\r\nprint (np.array2string(model(x).numpy(), separator=', '))\r\n#print (np.array2string(model.predict(x), separator=', '))\r\n```\r\n", "comments": ["Hi @saikumarchalla I'd like to contribute towards fixing this bug. Could you maybe point me in the right direction?", "@i-seesharp  It looks like your Issue relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. As ([previously announced](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999/)), all future development of Keras is expected to happen in the [github.com/keras-team/keras](github.com/keras-team/keras) repository. If your issue lies with the TF-Core area please comment back with your explanation and we can look into it further. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "This Issue was moved to keras repo. So, closing the issue here. Thanks"]}, {"number": 50617, "title": "How to access elements of an input tensor in custom layers ?", "body": "System: Python 3.8.3 64-bit | Qt 5.12.9 | PyQt5 5.12.3 | Linux 5.8.0-55-generic\r\ntensorflow version: 2021-07-05 20:04:06.422679\r\nkeras version: 2021-07-05 20:04:06.422679\r\n\r\nI wanted to assign an element of input tensor X to an element of an output tensor Y inside a custom layer like\r\n\r\nY[0,0,0,0] = X[0,1,1,1]\r\n\r\nFor example:\r\n\r\n```\r\nfrom keras.layers import Layer\r\nimport numpy as np\r\nfrom keras.layers import Input\r\nfrom keras.models import Model \r\n\r\nImages = [[[[255,0,0],[255,0,0]],[[255,0,0],[0,144,0]]]]\r\n\r\nInputTensor = np.array(Images)\r\n\r\nclass MyLayer(Layer):\r\n    def __init__(self, **kwargs):\r\n        super(MyLayer, self).__init__(**kwargs)\r\n    def build(self, input_shape):\r\n        self.built = True\r\n        super(MyLayer,self).build(input_shape)\r\n\r\n    def call(self, X):\r\n        Y = [[[[0,0,0,0]]]] # Output tensor\r\n        Y = np.array(Y)\r\n        Y[0,0,0,0] = X[0,1,1,1]   # <------ does not work because X[0,1,1,1] is a sequence instead a scalar\r\n        return np.ndarray.tolist(Y)\r\n    \r\ninputlayer = Input(shape = InputTensor[0].shape)\r\nlayer = MyLayer()(inputlayer)\r\n\r\nmodel = Model(inputlayer, layer ) \r\nmodel.summary()\r\n\r\nOutput = model.predict(InputTensor)\r\nOutput = np.array(Output)\r\nprint(\"Output = \"+str(Output))\r\n```\r\nIf the call-function returns X , then X[0,1,1,1] is not anymore a sequence after it passed the modell.\r\nIt make not sense to use custom layers if you have no access to the elements of an input tensor as expected.\r\nFor example:\r\n```\r\nfrom keras.layers import Layer\r\nimport numpy as np\r\nfrom keras.layers import Input\r\nfrom keras.models import Model \r\n\r\nImages = [[[[255,0,0],[255,0,0]],[[255,0,0],[0,144,0]]]]\r\n\r\nInputTensor = np.array(Images)\r\n\r\nclass MyLayer(Layer):\r\n    def __init__(self, **kwargs):\r\n        super(MyLayer, self).__init__(**kwargs)\r\n    def build(self, input_shape):\r\n        self.built = True\r\n        super(MyLayer,self).build(input_shape)\r\n\r\n    def call(self, X):\r\n        return X\r\n    \r\ninputlayer = Input(shape = InputTensor[0].shape)\r\nlayer = MyLayer()(inputlayer)\r\n\r\nmodel = Model(inputlayer, layer ) \r\nmodel.summary()\r\n\r\nOutput = model.predict(InputTensor)\r\nOutput = np.array(Output)\r\nprint(\"Output = \"+str(Output))\r\n```\r\nThe Output is:\r\n\r\n```________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_78 (InputLayer)        [(None, 2, 2, 3)]         0         \r\n_________________________________________________________________\r\nmy_layer_77 (MyLayer)        (None, 2, 2, 3)           0         \r\n=================================================================\r\nTotal params: 0\r\nTrainable params: 0\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nOutput = [[[[255.   0.   0.][255.   0.   0.]][[255.   0.   0.][  0. 144.   0.]]]]\r\n```", "comments": ["@Oezkan23 \r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues) as it is related to keras issue\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50615, "title": "[TFLite] Avoid passing negative quantized multipliers to MultiplyByQuantizedMultiplier", "body": "Hello,\r\n\r\nThis PR updates the SUB and DIV kernels to avoid passing negative quantized multipliers to the `MultiplyByQuantizedMultiplier` method.\r\n\r\nIt allows us to later on add a restriction on the quantized multiplier of the int32 `MultiplyByQuantizedMultiplier` similar to the one already present in the int64 version. \r\n\r\nThibaut", "comments": ["@daverim could you review this?", "This PR doesn't solve a bug per se and should be reviewed with #50290 as context as the current changes were initially part of this PR. The single-rounding PR adds a new requirement to the `quantized_multiplier` parameter of the int32 version of `MultiplyByQuantizedMultiplier`, it must now be a positive integer similar to the requirement for the int64 version.\r\n\r\nThe PR fixes the negative quantize multipliers by forcing `input2_inv` to be positive for the div kernel and `input2_multiplier` for the sub kernel. \r\n\r\nAs we don't reuse the add kernels, the PR may slightly increase the binary size but it should be really minor. There should be no change regarding the performance except for the uint8 version of the sub operator as I didn't add an optimized version for it  as I think it isn't useful with de deprecation of uint8 quantization (the optimized add kernel was used before).\r\n\r\n", "@daverim @renjie-liu  It seems the change was merged but then reverted by https://github.com/tensorflow/tensorflow/commit/befc25bd0916f927505ba35b52c0b20249fc3e4d Was there an internal problem that caused the revert?", "The CL was reverted since it broke TFMicro test\r\n`tflite_micro/tensorflow/lite/micro/kernels:sub_test`\r\nhttps://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/kernels/sub_test.cc", "Thank you for the information. With TFLite Micro being now in a stand-alone repository our CI missed that.\r\n\r\nThe problem was that I renamed `BroadcastSubSlow` to `BroadcastQuantSubSlow` to avoid a name clash now that the function is templated. I would need to modify https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/kernels/sub.cc and change `BroadcastSubSlow` for (u)int8 to  `BroadcastQuantSubSlow`. We also need to modify the int16 version of the operator to also avoid using the add kernel.\r\n\r\nWhat is the best way to proceed? As the change I need to do in tflite-micro depends on the change in tflite I am not sure if I can raise a PR in tflite-micro that changes https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/kernels/internal/reference/sub.h as the code is part of tflite.", "Sorry, fell off my radar -- could you submit a PR to micro and link it here? I'll try to merge both in a single patch on our side.", "@daverim Thank you, I created the necessary PR in tfllite-micro (linked above). Let me know if there is any problem.", "Google-Internal change that can be merged as one atomic commit : http://cl/405510094\r\n\r\nThis includes changes from the current PR as well as the corresponding PR in tflite-micro (https://github.com/tensorflow/tflite-micro/pull/665).\r\n\r\nOnce the internal change is in, the TFLM infra will sync the code to TFLM and then https://github.com/tensorflow/tflite-micro/pull/665 can also be merged.", "The changes from this PR are now merged. I will get the TFLM repo up to date with this change as well."]}, {"number": 50614, "title": "Tensorflow GPU installation don't want to run this code", "body": "**System information**\r\n- Ubuntu 18.04 LTS\r\n- Deep learning SageMaker with pre installed drivers and etc.\r\n- AWS EC2 g4dn.xlarge\r\n\r\n**ERORR**\r\n\r\n\r\n**Describe the current behavior**\r\n- Tensorflow GPU installation don't want to run this code\r\n- while the CPU installation (other anaconda environment, built in AWS SageMaker anaconda evironment: \"tensorflow2_p36\") runs this code no problem (it is just slow as expected)\r\n\r\n**Describe the expected behavior**\r\n- Tensorflow GPU installation run this code withouth error\r\n\r\n**Standalone code to reproduce the issue**\r\n- https://github.com/NioushaR/LSTM-TensorFlow-for-Timeseries-forecasting\r\n- Final Code bit\r\n```\r\n# Create GRU model\r\ndef create_gru(units):\r\n    model = Sequential()\r\n    # Input layer \r\n    model.add(GRU (units = units, return_sequences = True, \r\n                 input_shape = [X_train.shape[1], X_train.shape[2]]))\r\n    model.add(Dropout(0.2)) \r\n    # Hidden layer\r\n    model.add(GRU(units = units))                 \r\n    model.add(Dropout(0.2))\r\n    model.add(Dense(units = 1)) \r\n    #Compile model\r\n    model.compile(optimizer='adam',loss='mse')\r\n   \r\n    return model\r\nmodel_gru = create_gru(64)\r\n\r\n# Create BiLSTM model\r\ndef create_bilstm(units):\r\n    model = Sequential()\r\n    # Input layer\r\n    model.add(Bidirectional(LSTM(units = units, return_sequences=True), \r\n                            input_shape=(X_train.shape[1], X_train.shape[2])))\r\n    # Hidden layer\r\n    model.add(Bidirectional(LSTM(units = units)))\r\n    model.add(Dense(1))\r\n    #Compile model\r\n    model.compile(optimizer='adam',loss='mse')\r\n    return model\r\n\r\nmodel_bilstm = create_bilstm(64)\r\n\r\ndef fit_model(model):\r\n    early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss',\r\n                                               patience = 10)\r\n    history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.2,\r\n                    batch_size = 16, shuffle = False, callbacks = [early_stop])\r\n    return history\r\n\r\nhistory_gru = fit_model(model_gru)\r\nhistory_bilstm = fit_model(model_bilstm)\r\n```\r\n\r\n**ERROR Message**\r\n```\r\nEpoch 1/100\r\n---------------------------------------------------------------------------\r\nUnknownError                              Traceback (most recent call last)\r\n<ipython-input-14-ac9269b205d7> in <module>\r\n     38     return history\r\n     39 \r\n---> 40 history_gru = fit_model(model_gru)\r\n     41 history_bilstm = fit_model(model_bilstm)\r\n\r\n<ipython-input-14-ac9269b205d7> in fit_model(model)\r\n     35                                                patience = 10)\r\n     36     history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.2,\r\n---> 37                     batch_size = 16, shuffle = False, callbacks = [early_stop])\r\n     38     return history\r\n     39 \r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1181                 _r=1):\r\n   1182               callbacks.on_train_batch_begin(step)\r\n-> 1183               tmp_logs = self.train_function(iterator)\r\n   1184               if data_handler.should_sync:\r\n   1185                 context.async_wait()\r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    887 \r\n    888       with OptionalXlaContext(self._jit_compile):\r\n--> 889         result = self._call(*args, **kwds)\r\n    890 \r\n    891       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    948         # Lifting succeeded, so variables are initialized and we can run the\r\n    949         # stateless function.\r\n--> 950         return self._stateless_fn(*args, **kwds)\r\n    951     else:\r\n    952       _, _, _, filtered_flat_args = \\\r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   3022        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n   3023     return graph_function._call_flat(\r\n-> 3024         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   3025 \r\n   3026   @property\r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1959       # No tape is watching; skip to running the function.\r\n   1960       return self._build_call_outputs(self._inference_function.call(\r\n-> 1961           ctx, args, cancellation_manager=cancellation_manager))\r\n   1962     forward_backward = self._select_forward_and_backward_functions(\r\n   1963         args,\r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    594               inputs=args,\r\n    595               attrs=attrs,\r\n--> 596               ctx=ctx)\r\n    597         else:\r\n    598           outputs = execute.execute_with_cancellation(\r\n\r\n~/anaconda3/envs/tfall/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nUnknownError:    Fail to find the dnn implementation.\r\n\t [[{{node CudnnRNN}}]]\r\n\t [[sequential/gru/PartitionedCall]] [Op:__inference_train_function_7423]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function -> train_function\r\n```\r\n\r\n\r\n**Tried Already**\r\n\r\n- https://github.com/tensorflow/tensorflow/issues/24496\r\n- https://github.com/tensorflow/tensorflow/issues/36508\r\n- https://www.tensorflow.org/guide/gpu", "comments": ["@stormal I tired to reproduce the issue but  unable to load  the data. Could you please share the dataset  so that we can help you in a better way. Thanks!\r\n ", "@saikumarchalla \r\nI can not share the data set but it looks like as follows\r\n\r\n<html>\r\n<body>\r\n<!--StartFragment-->\r\n\r\n\u00a0 | a| b| c| d| e| TARGET VALUE | g\r\n-- | -- | -- | -- | -- | -- | -- | --\r\n0 | -2000 | 900.0 | 100.0 | 300.0 |  86.672575 | 45 | 0\r\n1 | -1999 | 5000.0 | 1500.0 | 400.0 | 45.688947 | 690 | 1\r\n2 | -1998 | 7000.0 | 1600.0 | 600.0 | 75.688947 | 1200 | 2\r\n\r\n<!--EndFragment-->\r\n</body>\r\n</html>\r\n\r\nit is about 1000 rows and 7 columns", "@stromal \r\nYou can run on colab with dummy dataset and let us know if the issue persist.\r\nPlease refer [this link](https://stackoverflow.com/questions/54473254/cudnnlstm-unknownerror-fail-to-find-the-dnn-implementation) and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50614\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50614\">No</a>\n"]}, {"number": 50613, "title": "`tensorflow/python/keras` leads to inconsistencies when mixed with new Keras pip package in 2.6.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 11\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6.0rc0\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\n\r\nStarting with TF 2.6.0rc0 [keras-team/keras](https://github.com/keras-team/keras) is replacing the code which previously located in `tensorflow/python/keras`. This changes the `tf.keras` endpoint to use the code from the OSS Keras pip package. \r\n\r\nUnfortunately the old code is still shipped with the TensorFlow pip package which can lead to very subtle inconsistencies in user code. This occurs especially in library code that tries to support different TF versions, which might be forced to rely on private imports since some functions might not be available in certain TF version. (E.g. `is_keras_tensor` has been only a public API since 2.1).\r\n\r\nThis duplicated code can lead to very weird behaviours since `isinstance` checks or similar will now break if users mix and match code. E.g. take these lines which previously where equivalent:\r\n```python\r\nfrom keras.engine.keras_tensor import KerasTensor  # imported from keras-team/keras\r\n\r\nfrom tensorflow.python.keras.engine.keras_tensor import KerasTensor as KerasTensorFromTF # This import should not exist anymore\r\n\r\nassert KerasTensorFromTF == KerasTensor   # This breaks!!!\r\n```\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras.backend import is_keras_tensor\r\nfrom tensorflow.python.keras.backend import is_keras_tensor as is_keras_tensor_tf  # this import should not exist anymore\r\n\r\nassert is_keras_tensor(tf.keras.Input([10]))\r\nassert is_keras_tensor_tf(tf.keras.Input([10])) # This breaks!!!\r\n```\r\nCheckout [this notebook](https://colab.research.google.com/drive/1-TcroLTdI4fx4dk5P3Cq_vk5AfiYuVOo?usp=sharing) for a full reproduction.\r\n\r\n**Describe the expected behavior**\r\n\r\nSince the intention to switch to keras-team/keras is clear I think the only way to get rid of this weirdness is to remove the `tensorflow/python/keras` code completely from the shipped pip package. This will likely frustrate some users relying on internal functions, but at least it won't lead to unintended behaviour or silent bugs that might be very hard to debug for inexperienced users. Also since `tensorflow.python` always has been a private API, I don't think breaking users of it will be a big problem. @fchollet @mihaimaruseac What do you think?", "comments": ["@lgeiger \r\n\r\nI was not able to access the notebook provided, Could you please provide the access .Thanks", "> I was not able to access the notebook provided, Could you please provide the access .Thanks\r\n\r\nSorry about that. @UsharaniPagadala you should be able to access it now.", "@rmothukuru \r\n\r\nI was able to replicate the issue reported here.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/03fbde228c60a553ca3ee294e9fc9713/untitled40.ipynb).Thanks", "@lgeiger Thank you for the issue!\r\n`import keras` is not a standard usage after Keras became a dependency of TensorFlow.\r\nWe expect the users to only use `from tensorflow import keras`.\r\nWe may add additional guide to make sure the users are aware of this.\r\n\r\nRegarding the duplication of the code, we will remove the code in tensorflow repo in the future.\r\n@qlzh727 may have more info about this issue.", "> `import keras` is not a standard usage after Keras became a dependency of TensorFlow.\r\n\r\n@haifeng-jin I am aware of that. But unfortunately some APIs are not yet exposed via `tensorflow.keras` which means users and library authors are sometimes required to either rely on `tensorflow.python.keras` or `keras` directly. And as detailed above mixing and matching doesn't work as it is not the same code which can lead to not obvious issues. For more info checkout #44613 which e.g. also impacts TensorFlow Addons [here](https://github.com/tensorflow/addons/pull/2516/files#diff-bc6fb95c9ed9c45a0c8c0640531e3316ddb7894cc64f6d433c3dd1c013a0a44aR23-R26).\r\n\r\n> Regarding the duplication of the code, we will remove the code in tensorflow repo in the future.\r\n\r\nI don't think having duplicate code in the repo necessarily is a big problem for users. But having it shipped in the PIP package could lead to some weird behaviour in cases where users rely on private APIs that potentially stop working.", "Thanks for reporting this issue and we are aware of this.\r\n\r\nWe leave the tensorflow.python.keras code in the release for now since we want to give user some time window (1 release) to migrate their code to use the new location if needed (although they shouldn't use the private APIs). Deleting the code will require immediate user action when they switch to TF 2.6. The code in tensorflow.python.keras and keras PIP are almost identical, and the only side effects are the `isinstance` type checking, which could lead to some user confusion. \r\n\r\nWe think this shouldn't impact too many user since they should rely on TF public API only.", "As a workaround, you could replace any \"tensorflow.python.keras.xxx\" imports with \"keras.xxx\" for 2.6 release, and it should work for you. For TF Addon, we probably will work with Addon to expose necessary endpoints as \\_\\_internal__ API, so that ppl can avoid using private API and have some level of API guarantee.  ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50613\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50613\">No</a>\n"]}, {"number": 50612, "title": "cropping layer additional error message ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nWhen a cropping layer (Cropping1D, Cropping2D,Cropping3D) is used, it can happen that the cropping value is accidentally selected too big. Then, the output is just an empty list. It would be good to have an error or warning message for this case, since such an issue can be really cumbersome to find when it occurs deep in a complex graph model.\r\nThe issue is illustrated in the simplified example below.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\nin0Cro69514 = tf.keras.layers.Input(shape=([1, 2]))\r\nCro69514 = keras.layers.Cropping1D(cropping=((5, 5)), name = 'Cro69514', )(in0Cro69514)\r\nmodel = tf.keras.models.Model(inputs=[in0Cro69514], outputs=Cro69514)\r\nin0Cro69514 = tf.constant([[[1.6058, 1.8537]]])\r\nprint (np.array2string(model.predict([in0Cro69514],steps=1), separator=', '))\r\n```\r\n", "comments": ["@Saduf2019 ,\r\nI was able to reproduce the issue in tf v2.4 and v2.5.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/6297e9900e309ab8d8bf02612967ab87/untitled50612.ipynb).", "Hi @ymodak do you want to solve this issue? Can I work on it?\r\n\r\nIf your asnwer is \"yes\". I think it should raise a `ValueError` I don't see a warning because have zero data in the Tensor have no sense (at least in my knowledge).\r\n\r\n", "@arubiales Feel free to take stab on this. Thanks!", " Keras project has moved to new repository in https://github.com/keras-team/keras\r\nYou may want to raise this PR on keras-team/keras repo.\r\nSee [TensorFlow Forum Announcement](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) to know more.\r\nThanks for your PR and apologies for the overhead.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50612\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50612\">No</a>\n"]}, {"number": 50611, "title": "GPU memory usage does not increase when using multithreading in python ", "body": "Hi, I am working on deploy some yolo v3 models (keras) on the GPU of our server. However, I found that, when I use multithreading programming in python to deploy multiple models and let them predict in parallel, the GPU memory usage does not increase, the GPU memory usage is almost as much as one single model, which makes me very confused. Could someone help me?  \r\n\r\nload and predict one by one: \r\n**model 0\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 859.56 MB\uff0c unused 15421.31 MB\r\nmodel 1\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1371.56 MB\uff0c unused 14909.31 MB\r\nmodel 2\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1371.56 MB\uff0c unused 14909.31 MB\r\nmodel 3\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1371.56 MB\uff0c unused 14909.31 MB\r\n\r\n2021-07-05 16:45:00.227119: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\n**\r\n\r\nload one by one and predict through multithread: \r\n**model 0\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 861.56 MB\uff0c unused 15419.31 MB\r\nmodel 1\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1373.56 MB\uff0c unused 14907.31 MB\r\nmodel 2\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1373.56 MB\uff0c unused 14907.31 MB\r\nmodel 3\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 2397.56 MB\uff0c unused 13883.31 MB\r\n\r\n2021-07-05 17:06:22.285915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n\r\nthread 0 gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\nthread 1 gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\nthread 2 gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\nthread 3gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\n**", "comments": ["@Neronjust2017 Could you please fill the issue template.Also Please provide the simple standalone code/ colab link to reproduce the issue at our end.Thanks", "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat Enterprise Linux Server release 7.9 (Maipo)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): gpu 1.14.0\r\n- Python version: 3.7.10\r\n- CUDA/cuDNN version: cuda 10.2 cudnn 8.2\r\n- GPU model and memory: Tesla P100-PCIE 16GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI am working on deploy some yolo v3 models (keras) on the GPU of our server. However, I found that, when I use multithreading programming in python to deploy multiple models and let them predict in parallel, the GPU memory usage does not increase, the GPU memory usage is almost as much as one single model, which makes me very confused. \r\n\r\nload models one by one and measure the gpu memory: \r\n\r\n```\r\nmodel 0\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 859.56 MB\uff0c unused 15421.31 MB\r\nmodel 1\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1371.56 MB\uff0c unused 14909.31 MB\r\nmodel 2\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1371.56 MB\uff0c unused 14909.31 MB\r\nmodel 3\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 1371.56 MB\uff0c unused 14909.31 MB\r\n```\r\n\r\ninfer one by one and measure the gpu memory: \r\n\r\n```\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\ngpu usage\uff1atotal 16280.88 MB\uff0c used 6649.56 MB\uff0c unused 9631.31 MB\r\n```\r\n\r\ninfer with multithreading and measure the gpu memory: \r\n\r\n```\r\nthread 0  gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\nthread 1  gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\nthread 2  gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\nthread 3 gpu usage\uff1atotal 16280.88 MB\uff0c used 6651.56 MB\uff0c unused 9629.31 MB\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nload and predict one by one:\r\n\r\n```python\r\n  import os\r\n  import time\r\n  import numpy as np\r\n  from keras.models import Model, load_model\r\n  import tensorflow as tf\r\n  from keras.backend.tensorflow_backend import set_session\r\n  import pynvml\r\n  import cv2\r\n  \r\n  os.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n  config = tf.ConfigProto()\r\n  config.gpu_options.allow_growth = True\r\n  sess = tf.Session(config=config)\r\n  set_session(tf.Session(config=config))\r\n  \r\n  pynvml.nvmlInit()\r\n  handler = pynvml.nvmlDeviceGetHandleByIndex(0)\r\n  \r\n  model_files= [\r\n      '/data/yolo_1',\r\n      '/data/yolo_2',\r\n      '/data/yolo_3',\r\n      '/data/yolo_4'\r\n  ]\r\n  \r\n  models = []\r\n  for i in range(len(model_files)):\r\n      model = load_model(model_files[i])\r\n      models.append(model)\r\n      print(i)\r\n      meminfo = pynvml.nvmlDeviceGetMemoryInfo(handler)\r\n      gpu_mem_total = round(meminfo.total / 1024 / 1024, 2)\r\n      gpu_mem_used = round(meminfo.used / 1024 / 1024, 2)\r\n      gpu_mem_free = round(meminfo.free / 1024 / 1024, 2)\r\n      print(r'gpu memory\uff1atotal {} MB\uff0c used {} MB\uff0c unused {} MB'.format(gpu_mem_total, gpu_mem_used, gpu_mem_free))\r\n  \r\n  image_paths = []\r\n  \r\n  input_path = \"/data/testing/\"\r\n  \r\n  if os.path.isdir(input_path):\r\n      for inp_file in os.listdir(input_path):\r\n          image_paths += [input_path + inp_file]\r\n  else:\r\n      image_paths += [input_path]\r\n  \r\n  image_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\r\n  \r\n  new_w, new_h = 832, 832\r\n  \r\n  t1 = time.time()\r\n  \r\n  for i ,model in enumerate(models):\r\n  \r\n      for image_path in image_paths:\r\n          image = cv2.imread(image_path)\r\n          image = cv2.resize(image / 255., (new_w, new_h))\r\n          image = np.expand_dims(image, axis=0)\r\n          boxes = model.predict(image)\r\n  \r\n      meminfo = pynvml.nvmlDeviceGetMemoryInfo(handler)\r\n      gpu_mem_total = round(meminfo.total / 1024 / 1024, 2)\r\n      gpu_mem_used = round(meminfo.used / 1024 / 1024, 2)\r\n      gpu_mem_free = round(meminfo.free / 1024 / 1024, 2)\r\n      print(r'gpu memory\uff1atotal {} MB\uff0c used {} MB\uff0c unused {} MB'.format(gpu_mem_total, gpu_mem_used, gpu_mem_free))\r\n  \r\n  t2 = time.time()\r\n  print(t2-t1)\r\n```\r\n\r\n\r\npredict with multi threading:\r\n\r\n```python\r\nimport os\r\nimport numpy as np\r\nfrom keras.models import Model, load_model\r\nimport tensorflow as tf\r\nfrom keras.backend.tensorflow_backend import set_session\r\nimport pynvml\r\nimport cv2\r\nimport threading\r\nimport time\r\n\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\nset_session(tf.Session(config=config))\r\n\r\npynvml.nvmlInit()\r\nhandler = pynvml.nvmlDeviceGetHandleByIndex(0)\r\n\r\nmodel_files= [\r\n    '/data/yolo_1',\r\n    '/data/yolo_2',\r\n    '/data/yolo_3',\r\n    '/data/yolo_4'\r\n]\r\n\r\nimage_paths = []\r\n\r\ninput_path = \"/data/testing/\"\r\n\r\nif os.path.isdir(input_path):\r\n    for inp_file in os.listdir(input_path):\r\n        image_paths += [input_path + inp_file]\r\nelse:\r\n    image_paths += [input_path]\r\n\r\nimage_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\r\nprint(len(image_paths))\r\n\r\nmodels = []\r\nfor i in range(len(model_files)):\r\n    model = load_model(model_files[i])\r\n    model._make_predict_function()\r\n    models.append(model)\r\n    print(i)\r\n    meminfo = pynvml.nvmlDeviceGetMemoryInfo(handler)\r\n    gpu_mem_total = round(meminfo.total / 1024 / 1024, 2)\r\n    gpu_mem_used = round(meminfo.used / 1024 / 1024, 2)\r\n    gpu_mem_free = round(meminfo.free / 1024 / 1024, 2)\r\n    print(r'gpu memory\uff1atotal {} MB\uff0c used {} MB\uff0c unused {} MB'.format(gpu_mem_total, gpu_mem_used, gpu_mem_free))\r\n\r\n\r\ndef infer(i):\r\n\r\n    new_w, new_h = 832, 832\r\n\r\n    for image_path in image_paths:\r\n        image = cv2.imread(image_path)\r\n        image = cv2.resize(image / 255., (new_w, new_h))\r\n        image = np.expand_dims(image, axis=0)\r\n        boxes = models[i].predict(image)\r\n\r\n    meminfo = pynvml.nvmlDeviceGetMemoryInfo(handler)\r\n    gpu_mem_total = round(meminfo.total / 1024 / 1024, 2)\r\n    gpu_mem_used = round(meminfo.used / 1024 / 1024, 2)\r\n    gpu_mem_free = round(meminfo.free / 1024 / 1024, 2)\r\n    print(r'{} gpu memory\uff1atotal {} MB\uff0c used {} MB\uff0c unused {} MB'.format(i, gpu_mem_total, gpu_mem_used, gpu_mem_free))\r\n\r\n\r\nthreads = []\r\nfor i, model_file in enumerate(model_files):\r\n    threads.append(threading.Thread(target=infer, args=(i,)))\r\n\r\nfor thread in threads:\r\n    thread.start()\r\n```", "@Neronjust2017 \r\nWe see that you are using a old version of tensorflow [1.x] that is not supported now, please upgrade to tensorflow 2.x and let us know if you face any issues.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50611\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50611\">No</a>\n"]}, {"number": 50610, "title": "[PluggableDevice] add DEVICE_DEFAULT for debug/stage ops", "body": "Add DEVICE_DEFAULT for debug/stage ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "Thanks @penpornk , feel free to let us if anything need update from our side. "]}, {"number": 50609, "title": "[PluggableDevice] add DEVICE_DEFAULT for collective/bcast ops", "body": "Add DEVICE_DEFAULT for collective/bcast ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!"]}, {"number": 50608, "title": "[PluggableDevice] add DEVICE_DEFAULT for ScopedAllocator/AddN ops", "body": "Add DEVICE_DEFAULT for scopedallocator/shape ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "@quintinwang5 Can you please resolve conflicts? Thanks!", "@penpornk Can you please review this PR ? Thanks!"]}, {"number": 50606, "title": "InternalError:  dnn PoolBackward launch failed in average_pooling2d/AvgPool/AvgPoolGrad", "body": "[Link to Full notebook of training](https://github.com/RushilVerma/different-cats/blob/911b9c1d6cb4439626323697c6f634d4cce9701d/Training%20model_.ipynb) \r\nI have recently run into an error after I enabled XLA devices  in tensor flow by :\r\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\r\nAfter ward I was able to run predictions over the GPU but it gave following errors when I was fitting the model\r\n\r\n**Code:**\r\n\r\n```\r\nhistory = model.fit(X_train, [y_train, y_train, y_train],\r\n                    validation_split=0.1,\r\n                    epochs=epochs, batch_size=256, )#callbacks=[lr_sc]\r\nmodel.save('model.model')\r\n```\r\n\r\n**Result:**\r\n```\r\n\r\nEpoch 1/2\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-8-b1480782523a> in <module>\r\n----> 1 history = model.fit(X_train, [y_train, y_train, y_train],\r\n      2                     validation_split=0.1,\r\n      3                     epochs=epochs, batch_size=256, )#callbacks=[lr_sc]\r\n      4 model.save('model.model')\r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    886         # Lifting succeeded, so variables are initialized and we can run the\r\n    887         # stateless function.\r\n--> 888         return self._stateless_fn(*args, **kwds)\r\n    889     else:\r\n    890       _, _, _, filtered_flat_args = \\\r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   2940       (graph_function,\r\n   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n-> 2942     return graph_function._call_flat(\r\n   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   2944 \r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1916         and executing_eagerly):\r\n   1917       # No tape is watching; skip to running the function.\r\n-> 1918       return self._build_call_outputs(self._inference_function.call(\r\n   1919           ctx, args, cancellation_manager=cancellation_manager))\r\n   1920     forward_backward = self._select_forward_and_backward_functions(\r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n    553       with _InterpolateFunctionError(self):\r\n    554         if cancellation_manager is None:\r\n--> 555           outputs = execute.execute(\r\n    556               str(self.signature.name),\r\n    557               num_outputs=self._num_outputs,\r\n\r\nc:\\users\\rushi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     57   try:\r\n     58     ctx.ensure_initialized()\r\n---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nInternalError:  dnn PoolBackward launch failed\r\n\t [[node gradient_tape/inception_v1/average_pooling2d/AvgPool/AvgPoolGrad (defined at <ipython-input-8-b1480782523a>:1) ]] [Op:__inference_train_function_5930]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```", "comments": ["@RushilVerma ,\r\n\r\nOn running the given code snippet, I am facing an error stating **FileNotFoundError: [Errno 2] No such file or directory: 'X.pickle'** Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/ffc1496cae53844040171ef4584a1073/untitled50606.ipynb).Also please let us know the tensorflow version you are using.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50606\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50606\">No</a>\n"]}, {"number": 50605, "title": "[PluggableDevice] add DEVICE_DEFAULT for iterator/optional ops", "body": "Add DEVICE_DEFAULT for iterator/optional ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "Hi @quintinwang5, \r\n\r\nSorry for the long silence! We have been having an internal discussion about this.\r\n \r\n@jsimsa doesn't think `tf.data` kernels are \"device independent\". He said that while they register the same kernel for each device, the registration used different priorities to override default placement decisions. In other words, tf.data kernels should not be run on any device.\r\n\r\nI'm closing this PR now. If you have questions, please feel free to ask @jsimsa here directly.  "]}, {"number": 50604, "title": "[PluggableDevice] add DEVICE_DEFAULT for map_stage ops", "body": "Add DEVICE_DEFAULT for map_stage ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!"]}, {"number": 50603, "title": "[PluggableDevice] add DEVICE_DEFAULT for batch_kernel/concat/fact/partioned_function ops", "body": "Add DEVICE_DEFAULT for batch_kernel/concat/fact/partioned_function ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!"]}, {"number": 50602, "title": "[PluggableDevice] add DEVICE_DEFAULT for python ops", "body": "Add DEVICE_DEFAULT for python ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!"]}, {"number": 50601, "title": "[PluggableDevice] add DEVICE_DEFAULT for Mutex/DestroyResource/Sequence ops", "body": "Add DEVICE_DEFAULT for Mutex/DestroyResource/Sequence ops. This PR is for PluggableDevice.", "comments": []}, {"number": 50600, "title": "[PluggableDevice] add DEVICE_DEFAULT for datasets ops", "body": "Add DEVICE_DEFAULT for datasets ops. This PR is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "The placement of tf.data ops does not follow standard placement and should not rely on `DEFAULT_DEVICE`. Same rationale as https://github.com/tensorflow/tensorflow/pull/50605."]}, {"number": 50599, "title": "ConvLSTM2D layer wrong computation", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\n\r\nThere seems to be something wrong with the computation of the ConvLSTM2D layer. I tried to do the computation manually for a simplified example and I come to a different result. I think there might be a bug in the last round of the layer.  The issue is illustrated in the example below. \r\n\r\n**Describe the expected behavior**\r\nThe output that I expected from the simple example model is `[[[[[   0.], [   8.]]], [[[ 0.],[1053.]]]]]`, but instead the actual output is `[[[[[   0.], [   8.]]], [[[ 512.],[1053.]]]]]`.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\ntf.keras.backend.set_floatx('float64')\r\nmodel = keras.Sequential([\r\nkeras.layers.ConvLSTM2D(1, (1, 2), return_sequences=True, padding='valid', strides=(1,1),recurrent_activation='linear', activation='linear',  input_shape=(2, 1, 3, 1))])\r\nw = model.get_weights()\r\nw[0] = np.array([[[[1, 1, 1, 1]],[[1, 1, 1, 1]]]])\r\nw[1] = np.array([[[[1, 1, 1, 1]],[[1, 1, 1, 1]]]])\r\nw[2] = np.array([0, 0, 0, 0])\r\nmodel.set_weights(w)\r\nx = tf.constant([[[[[0], [0], [2]]], [[[0], [0], [1]]]]])\r\nprint (np.array2string(model.predict(x,steps=1), separator=', '))\r\n```\r\n", "comments": ["@rschumi0 It looks like your Issue relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. As ([previously announced](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999/)), all future development of Keras is expected to happen in the [github.com/keras-team/keras](github.com/keras-team/keras) repository. If your issue lies with the TF-Core area please comment back with your explanation and we can look into it further. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50599\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50599\">No</a>\n", "@saikumarchalla it's now in the keras repo: https://github.com/keras-team/keras/issues/15224"]}, {"number": 50598, "title": "TFLite conversion of LSTM model does not work with multiple batch size", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Kaggle Notebook (standard ubuntu)\r\n- TensorFlow installed from (source or binary): Pip install tensorflow==2.5.0\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: CPU Only\r\n- GPU model and memory: CPU Only\r\n\r\n**Describe the current behavior**\r\n\r\nI trained (on gpu) and saving an LSTM model in keras and converted it to tflite. \r\n```\r\nmodel = Sequential()\r\nmodel.add(Masking(mask_value=-1, input_shape=(n_timesteps, n_features))) # This layer is used in the final model\r\nmodel.add(LSTM(64, input_shape=(n_timesteps,n_features))) # This layer is used in the final model\r\nmodel.add(RepeatVector(n_timesteps))\r\nmodel.add(LSTM(64, return_sequences=True))\r\nmodel.add(TimeDistributed(Dense(n_features)))\r\noptimizer = Adam(learning_rate=0.001, epsilon=1e-04)\r\nmodel.compile(optimizer= optimizer, loss='mse')\r\nmodel.fit(x_train, x_train, epochs=1000, verbose=2)\r\n\r\n# Saving\r\nencoder = Model(inputs=model.inputs, outputs=model.layers[1].output)\r\nencoder.save('encoder.h5')\r\n```\r\n![image](https://user-images.githubusercontent.com/5482978/124398609-6ff91a00-dccb-11eb-81e2-55bdaecc8b1f.png)\r\n\r\n\r\nUsing both experimental and non-experimental converter, I was able to convert the model to tflite where the shape signature is (-1, X, Y) where the first dimension is batch size.\r\n\r\n```\r\nfrom tensorflow.keras.models import load_model\r\nencoder = load_model('encoder.h5')\r\n\r\n# Following code from https://www.tensorflow.org/lite/convert/rnn\r\nrun_model = tf.function(lambda x: encoder(x))\r\nBATCH_SIZE = None\r\nSTEPS = 6952\r\nINPUT_SIZE = 20\r\nconcrete_func = run_model.get_concrete_function(tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], encoder.inputs[0].dtype))\r\nencoder.save('/encoder', save_format=\"tf\", signatures=concrete_func)\r\n```\r\n\r\nSaving the model as tflite:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('/encoder')\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\nwith open('encoder.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\nNow when I use the model:\r\n```\r\ninterpreter = tf.lite.Interpreter(model_path='encoder.tflite')\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ndata = np.vstack([a,a]).astype(np.float32) # Shape: (2, 6952, 20)\r\ninterpreter.resize_tensor_input(input_details[0]['index'], data .shape) # Shape: (2, 6952, 20)\r\ninterpreter.resize_tensor_input(output_details[0]['index'], (data .shape[0], 64)) # Shape: (2, 64)\r\ninterpreter.allocate_tensors()\r\ninterpreter.set_tensor(input_details[0]['index'], data )\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\n```\r\n\r\nI get the following error on invoke:\r\n```\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:80 t->dims->data[d] != t0->dims->data[d] (2 != 1)Node number 26 (CONCATENATION) failed to prepare.\r\nNode number 28 (WHILE) failed to invoke.\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nAn output of size (2,64)\r\n\r\n\r\nRelated issues that I've looked at https://github.com/tensorflow/tensorflow/issues/34620 https://github.com/tensorflow/tensorflow/issues/24607 https://github.com/tensorflow/tensorflow/issues/37012 ", "comments": ["Currently the fusion only works if the input shape is fixed, can you try to set the batch_size to 1? thanks!", "In my memory, the masking related issue has been fixed at the tf-nightly.", "> Currently the fusion only works if the input shape is fixed, can you try to set the batch_size to 1? thanks!\r\n\r\nHi i am still relatively new to tf.  What do you mean by fusion? Also i would like to use dynamic batch size and not fixed input size of 1.  Setting input size to 1 works perfectly fine but my goal is to use dynamic input size since I could have varying number of samples to run the model on.", "> In my memory, the masking related issue has been fixed at the tf-nightly.\r\n\r\nIs there a way for me to see which layer that the issue with fixed input size occurs on? The error messages indicate node 33 and 28 so i assumed that is the index of the list when you call `get_tensor_details()` but it doesn't seem to be correct in terms of output information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50598\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50598\">No</a>\n"]}, {"number": 50597, "title": "adjust abseil version to be compatible between cmake tensorflowlite and bazel", "body": "At the moment version of libabseil library defined in bazel and cmake scripts are different:\r\n\r\nBazel will add those namespace prefix `lts_2020_09_23` and cmake this one `lts_2020_02_25`.\r\n\r\nIn case you compile tensorflowlite library via cmake and build remaining libraries for tensorflow lite using bazel (for example `libmetal-delegate`) you can't use link them later as you will get unresolved symbols:\r\n\r\nUnresolved symbol:\r\n```bash\r\nabsl::lts_2020_09_23::UnknownError(absl::lts_2020_09_23::string_view), \r\nreferenced from: tflite::gpu::metal::(anonymous namespace)::AllocateTensorMemory(\r\nid<MTLDevice>,tflite::gpu::StrongShape<(tflite::gpu::Layout)12> const&, tflite::gpu::TensorDescriptor const&, void const*, id<MTLBuffer> __autoreleasing*, id<MTLTexture> __autoreleasing*) \r\nin libmetal_spatial_tensor.a(metal_spatial_tensor.o)\r\n```\r\n\r\nBut, for libraries compiled by cmake (and used in tf lite):\r\n```bash\r\nnm ./tensorflow/lite/tf_build/_deps/abseil-cpp-build/absl/status/libabsl_status.a | grep UnknownError\r\n0000000000003110 T __ZN4absl14lts_2020_02_2512UnknownErrorENS0_11string_viewE\r\n```\r\n\r\n`absl::lts_2020_09_23::UnknownError(absl::lts_2020_09_23::string_view`\r\nvs\r\n`absl::lts_2020_02_25::UnknownError string_view`", "comments": ["We don't accept new change for 2.5 branch except cherry-picks. Could you check if the cherry-pick of https://github.com/tensorflow/tensorflow/commit/8348b348ac509c70a8730416be773781ddd6e2ed resolves the issue?", "I've cloned TF from scratch, switch on `v2.5.0` and run \r\n```bash\r\ngit cherry-pick 8348b348ac509c70a8730416be773781ddd6e2ed\r\n```\r\n\r\nAfter that file\r\n- tensorflow/lite/tools/cmake/modules/abseil-cpp.cmake\r\ncontains this hash:\r\n`GIT_TAG 997aaf3a28308eba1b9156aa35ab7bca9688e9f6`\r\nwhich resolved to\r\n```bash\r\ngit describe --tags\r\n20210324.0\r\n```\r\n- third_party/absl/workspace.bzl  \r\ncontains this hash:\r\n`ABSL_COMMIT = \"6f9d96a1f41439ac172ee2ef7ccd8edf0e5d068c\"`\r\nwhich is resolved to \r\n```bash\r\ngit describe --tags\r\n20200923.3\r\n```\r\n\r\ni.e. unfortunately it will still lead to mismatched symbols.\r\n\r\nJust in case I've compiled libs for usage of metal delegate bia bazel and build tensorflowlite itself via cmake. \r\n\r\nDuring compilation I've got unresolved symbols:\r\n\r\n```bash\r\nUndefined symbols for architecture arm64:\r\n  \"absl::lts_2020_09_23::UnknownError(absl::lts_2020_09_23::string_view)\", referenced from:\r\n      tflite::gpu::metal::(anonymous namespace)::AllocateTensorMemory(id<MTLDevice>, tflite::gpu::StrongShape<(tflite::gpu::Layout)12> const&, tflite::gpu::TensorDescriptor const&, void const*, id<MTLBuffer> __autoreleasing*, id<MTLTexture> __autoreleasing*) in libmetal_spatial_tensor.a(metal_spatial_tensor.o)\r\n```\r\n\r\n```bash\r\nfind tf_cherry_pick/_deps/ -iname '*.a' -exec nm -A {} \\; | grep UnknownError\r\ntf_cherry_pick/_deps//libabsl_status.a:status.cc.o: 0000000000002dc4 T __ZN4absl12lts_2021032412UnknownErrorENS0_11string_viewE\r\n```\r\n\r\nand tensorflowlite itself contains symbols from abseil `20210324` namespace\r\n\r\n```bash\r\nnm tf_cherry_pick/libtensorflow-lite.a | grep 20210324 | grep UnknownError\r\n                 U __ZN4absl12lts_2021032412UnknownErrorENS0_11string_viewE\r\n```", "We can merge this but only when we do a patch release on TF 2.5", "Linking Bazel generated binary with CMake looks strange a use-case.\r\nIf you can use the Bazel, why do you need to use CMake?", "Thats a good question!\r\n\r\nBazel was a new beast for our team so we have started with old(?) good(?) cmake.\r\n\r\nAlong the way, specifically when we try to adopt delegates, we realise that not all artefacts are buildable by it,\r\n- so I've to build missing dependencies using bazel and tried to figure out why they not match each other.\r\n\r\n\r\nps Thats probably offtopic here, but I would be more then happy to see how to \r\nproperly generate `coreml` related dependencies, as I've end up by building coremltool libs with specific version of protobuf\r\nand patch few things to include missing symbols into libraries in order to get it working on device."]}]