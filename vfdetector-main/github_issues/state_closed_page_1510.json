[{"number": 7630, "title": "Poor Constant Propagation", "body": "Running on the 1.0.0 Docker image.\r\n\r\nCompare this:\r\n```\r\ntensor_util.constant_value_as_shape(ops.convert_to_tensor((tf.constant(15),16)))\r\n> TensorShape([Dimension(15), Dimension(16)])\r\n```\r\nto:\r\n```\r\ntensor_util.constant_value_as_shape(ops.convert_to_tensor((tf.constant(15) * 1,16)))\r\n> TensorShape([Dimension(None), Dimension(16)])\r\n```\r\nIt seems to me that constant propagation should happen in the latter. This leads to size information being lost in certain cases such as image upsampling / downsampling where constant size is multiplied and then fed to something like `resize_images`.", "comments": ["I vaguely remember similar issues being fixed by modifying `tensor_util.constant_value` function. One possibility is that it works for tf.constant(15), but gives up when it sees a tf.mul", "Should be solvable by adding a case to [`_ConstantValue`](https://github.com/tensorflow/tensorflow/blob/a0d784bdd31b27e013a7eac58a86ba62e86db299/tensorflow/python/framework/tensor_util.py#L577) (this can be used for any binary operator). This is rough solution, might not handle various tensor types quite right:\r\n```python\r\n  elif tensor.op.type == \"Mul\":\r\n    left = constant_value(tensor.op.inputs[0])\r\n    if left is None:\r\n      return None\r\n    right = constant_value(tensor.op.inputs[1])\r\n    if right is None:\r\n      return None\r\n    return left * right\r\n```\r\n", "I think ideally, XLA and other more general optimization efforts will handle some of this better constant folding. CCing @prb12 for comment. I'd hate to have to put special cases like that in every Tensor, especially since that optimization would only benefit the python bindings and not any other languages.", "The issue that I am dealing with _is_ on the Python side, where the shape information gets lost when calling `resize_images` with something like `2x` the current size, etc.", "Sorry for the confusion. Yes, it looks like it would be good to propagate these cases into constantvalue, especially if they are happening in common functions. Could you please provide a PR. You might consider it checking for all binary operators that it can be done on in a generic way.\r\n", "If you do this in python, you might also want to implement the same logic in this C++ function: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/shape_refiner.cc#L356 (with tests) -- it's possible in C++ the else clause already handles this case, whereas in python it doesn't, but it would be good to make sure they are consistent.", "Unfortunately the `mul` fix proposed by @cancan101 makes `constant_value` linear time in the size of the whole graph in the worse case.  Therefore, I don't think we can support it in that form.  I'll close this issue as now as out of reach of simple contributions (and for lack of activity)."]}, {"number": 7629, "title": "Branch 147845195", "body": "", "comments": []}, {"number": 7628, "title": "Added non-inverse hyperbolic functions.", "body": "The functions sinh and cosh are imported from the Eigen library,\r\nsimilarly to other trigonometric functions.", "comments": ["Can one of the admins verify this patch?", "Thanks for the contribution -- have you tested this out yourself already?\r\n\r\nAlso, I would recommend adding tests to cwise_ops_test.py so that we can validate its correctness ongoing.  Take a look at similar tests for ops in cwise_ops.h", "Following from http://stackoverflow.com/questions/42314317/eigen-functor-undeclared-when-building-tensorflow.\r\n\r\nJenkins, test this please.", "The error appears to be that `cosh` (at least) is not defined for `Eigen::half`, only double and long double.", "@vrv I did not initially test it. Turns out it was not as simple (refer to the link supplied by @drpngx ). I now got it to compile, but the sinh and cosh functions are not available in Python after TF import.\r\nI think this PR should be dropped. I will continue working on it and make another PR eventually.", "Exporting to python should be relatively easy once the op is registered.\nI'll outline the steps\n\nOn Feb 19, 2017 7:51 AM, \"acjak\" <notifications@github.com> wrote:\n\n> @vrv <https://github.com/vrv> I did not initially test it. Turns out it\n> was not as simple (refer to the link supplied by @drpngx\n> <https://github.com/drpngx> ). I now got it to compile, but the sinh and\n> cosh functions are not available in Python after TF import.\n> I think this PR should be dropped. I will continue working on it and make\n> another PR eventually.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7628#issuecomment-280927652>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbaZ4s8QLlLMGgNflkCmPteDi19-Bks5reGUegaJpZM4MEasA>\n> .\n>\n", "OK, there is some documentation here, but it's for adding an op outside of the code base.\r\nhttps://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/\r\n\r\nThe steps are: build the kernel, as you did. You should `REGISTER_KERNEL` for the various devices and data types that you want to support. Second, create an op and call `REGISTER_OP`. That is the wrapper \"declaration\" of the op that will cause some python code to be generated. BTW, you'll also need a gradient for best results. The op should now be imported like the other math ops, supposing you put them in the same place as `sin`. Finally, you should declare the ops as part of the public API (which will require review), [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L50). I would suggest exporting as `tf.sinh` rather than `tf.nn.sinh` even though we have `tf.nn.tanh`.", "Ok, thanks a lot for the pointer. I've been looking a little more into it when I've had the time. All in all I have now:\r\n\r\n- Added the sinh and cosh templates to `cwise_ops.h`.\r\n- Added the files (kernel files) `cwise_op_sinh.cc` and `cwise_op_cosh.cc`.\r\n- Corrected the data types in the input arguments to be just float and double.\r\n- Added `REGISTER_OP` for both 'Cosh' and 'Sinh' in `math_ops.cc`.\r\n- Added op definitions of 'Cosh' and 'Sinh' in ops.pbtxt (I don't know if this is necessary).\r\n\r\nIt compiles now although I have not tried with CUDA and openCL yet. I can also import tensorflow in Python, but `tf.sinh` and `tf.cosh` are still not available.\r\n\r\nHOWEVER: I can import them with `from tensorflow.python.ops.gen_math_ops import cosh sinh`. And they work. I just can't figure out why they are not picked up along with the other functions from gen_math_ops.py, where I can find cosh and sinh along with the other trigonometric functions. ", "You need to add them [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L50) as well.", "Jenkins, test this please.", "This doesn't link on Linux GPU (at least).\r\n\r\n```\r\ncwise_op_cosh.cc:(.text._ZN10tensorflow7UnaryOpIN5Eigen9GpuDeviceENS_7functor4coshIfEEE7ComputeEPNS_15OpKernelContextE[_ZN10tensorflow7UnaryOpIN5Eigen9GpuDeviceENS_7functor4coshIfEEE7ComputeEPNS_15OpKernelContextE]+0x143): undefined reference to `tensorflow::functor::UnaryFunctor<Eigen::GpuDevice, tensorflow::functor::cosh<float> >::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer>)'\r\n```", "Yeah, that look like the same problem as for CPU, `cosh` and `sinh` are not defined for the data types in the kernels.", "Or rather, it's the Eigen::half that's the problem again.", "That link is dead for me.\n\nOn Wed, Feb 22, 2017 at 7:14 PM, drpngx <notifications@github.com> wrote:\n\n> Oh, since this is an API change, you'll need to modify the API goldens\n> <https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/api/golden/tensorflow.pbtxt#L1589>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7628#issuecomment-281753537>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AGBdL2sLb1eTTcFjQ6ry-Cy6ZYacrGWXks5rfHsVgaJpZM4MEasA>\n> .\n>\n", "Never mind this.\n\nOn Feb 22, 2017 11:57 AM, \"acjak\" <notifications@github.com> wrote:\n\n> That link is dead for me.\n>\n> On Wed, Feb 22, 2017 at 7:14 PM, drpngx <notifications@github.com> wrote:\n>\n> > Oh, since this is an API change, you'll need to modify the API goldens\n> > <https://www.github.com/tensorflow/tensorflow/blob/\n> master/tensorflow/tools/api/golden/tensorflow.pbtxt#L1589>\n> >\n> > \u2014\n> > You are receiving this because you authored the thread.\n> > Reply to this email directly, view it on GitHub\n> > <https://github.com/tensorflow/tensorflow/pull/\n> 7628#issuecomment-281753537>,\n> > or mute the thread\n> > <https://github.com/notifications/unsubscribe-auth/AGBdL2sLb1eTTcFjQ6ry-\n> Cy6ZYacrGWXks5rfHsVgaJpZM4MEasA>\n> > .\n> >\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7628#issuecomment-281783939>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbRg58NQG0zl1upAZPTV_3vYQEVJjks5rfJMQgaJpZM4MEasA>\n> .\n>\n", "Jenkins, test this please.", "```\r\nERROR: /workspace/tensorflow/core/kernels/BUILD:2098:1: C++ compilation of rule '//tensorflow/core/kernels:cwise_op' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /var/lib/jenkins/workspace/tensorflow-pull-requests-gpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/cwise_op/tensorflow/core/kernels/cwise_op_cosh.d '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/cwise_op/tensorflow/core/kernels/cwise_op_cosh.o' -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-opt/genfiles/external/local_config_sycl -iquote external/jemalloc -iquote bazel-out/local_linux-opt/genfiles/external/jemalloc -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/local_linux-opt/genfiles/external/local_config_cuda -iquote external/curl -iquote bazel-out/local_linux-opt/genfiles/external/curl -iquote external/boringssl -iquote bazel-out/local_linux-opt/genfiles/external/boringssl -iquote external/jsoncpp_git -iquote bazel-out/local_linux-opt/genfiles/external/jsoncpp_git -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/jemalloc/include -isystem bazel-out/local_linux-opt/genfiles/external/jemalloc/include -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/gif_archive/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda/include -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda/include -isystem external/local_config_cuda/cuda -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda -isystem external/curl/include -isystem bazel-out/local_linux-opt/genfiles/external/curl/include -isystem external/boringssl/src/include -isystem bazel-out/local_linux-opt/genfiles/external/boringssl/src/include -isystem external/jsoncpp_git/include -isystem bazel-out/local_linux-opt/genfiles/external/jsoncpp_git/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-DGOOGLE_CUDA=1' -msse3 -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/core/kernels/cwise_op_cosh.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/cwise_op/tensorflow/core/kernels/cwise_op_cosh.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ntensorflow/core/kernels/cwise_op_cosh.cc:33:61: error: macro \"REGISTER3\" requires 7 arguments, but only 6 given\r\n REGISTER3(UnaryOp, GPU, \"Cosh\", functor::cosh, float, double);\r\n                                                             ^\r\ntensorflow/core/kernels/cwise_op_cosh.cc:33:1: error: 'REGISTER3' does not name a type\r\n REGISTER3(UnaryOp, GPU, \"Cosh\", functor::cosh, float, double);\r\n ^\r\n```", "Jenkins, test this please.\r\n\r\nIt would probably be faster if you tested this on your end first.", "I compiled it locally, but it's on a laptop so I don't have CUDA support. This error seems to be something new: \r\n\r\n> Error checking context: 'no permission to read from '/var/lib/jenkins/workspace/tensorflow-pull-requests-makefile/tensorflow/contrib/makefile/downloads/eigen/Eigen/src/Core/arch/CUDA/Complex.h''.", "The GPU error is:\r\n\r\n```\r\ncwise_op_cosh.cc:(.text._ZN10tensorflow7UnaryOpIN5Eigen9GpuDeviceENS_7functor4coshIfEEE7ComputeEPNS_15OpKernelContextE[_ZN10tensorflow7UnaryOpIN5Eigen9GpuDeviceENS_7functor4coshIfEEE7ComputeEPNS_15OpKernelContextE]+0x163): undefined reference to `tensorflow::functor::UnaryFunctor<Eigen::GpuDevice, tensorflow::functor::cosh<float> >::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer>)'\r\n```\r\n\r\nYou can still install the toolchain on your machine (or a docker) and build for GPU.", "Any luck with that? BTW, we also need to register the derivatives (`cosh <-> sinh`) for best results.", "Jenkins, test this please.\r\n\r\nTesting if makefile is a transient error.", "Please add the corresponding cuda files, aping the [cos](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_op_gpu_cos.cu.cc#L18) version.", "Any luck with this?", "Adding the stalled label since it's been two weeks without a response. @acjak if you can't get to this soon we'll close it to keep our list of open PRs manageable, but you'd be welcome to open a new PR with the same changes when you have time to focus on it.", "Closing now. Feel free to reopen any time with identical changes (and add the cuda files so it'll link for GPU)"]}, {"number": 7627, "title": "wrong code fix", "body": "maybe slip of a pen", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Let us know if you can sign the CLA -- I'll close by the end of the day if i don't hear back, but thanks for the contribution effort!", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 7626, "title": "Add description how to generate ops wrapper", "body": "Generating instruction of ops wrapper is useful for development of go binding.", "comments": ["Can one of the admins verify this patch?", "@asimshankar Thanks for review. I updated accordingly. \r\n\r\n> might I ask what led you to have to generate your own wrappers?\r\n\r\nJust for development. I tried to find which API is not generated as wrappers. And there seems to be some diffs between current `wrappers.go` and regenerated one. When is `wrappers.go` generated usually?", "We currently update `wrappers.go` with a cron job, which you'll see in the [file history](https://github.com/tensorflow/tensorflow/commits/master/tensorflow/go/op/wrappers.go)", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@tensorflow-jenkins test this please", "Jenkins, test this please.", "@maciekcc : The CLA failure is just because it's being cautious about my typo fixes. I believe this is good to merge.", "We should merge this. Currently I'm not able to do so, due to the red status from CLAbot, even though we've verified that we have CLA consent."]}, {"number": 7625, "title": "tf.train.import_meta_graph should be parallelized", "body": "Hey guys, I've been wondering whether it's possible the `tf.train.import_meta_graph` to be parallelized across multiple cores. When I load a complex model it takes too long and I only see one of my 24 cores being utilized to 100%.\r\n\r\n### Environment info\r\nOperating System: CentOS\r\n\r\nInstalled version of CUDA and cuDNN: \r\nNot applicable\r\n\r\nMinimal example:\r\n```\r\nsess = tf.Session()\r\nnew_saver = tf.train.import_meta_graph('my-model.meta')\r\nnew_saver.restore(sess, tf.train.latest_checkpoint('./'))\r\nall_vars = tf.get_collection('vars')\r\nfor v in all_vars:\r\n    v_ = sess.run(v)\r\n    print(v_)\r\n```\r\n\r\nAny plans on changing that in the near future?", "comments": ["When I see one core being utilized, my first suspicion is that work is done in Python. Python has chosen to remain in the punch-card age and only use 1 core for its processing, citing GIL issues. So the way to troubleshoot this is:\r\n\r\n```\r\npython -m cProfile -o slow.prof script.py\r\npip install snakeviz\r\nsnakeviz slow.prof\r\n```\r\n\r\nThis may help you find a bottleneck, possibly something obviously inefficient is being done in Python (I used this technique to speed up session.run from 120 usec to 60 usec by cutting out some unneeded Python calls). Longer term solution may be to rewrite metagraph loading in C++, someone from TF team may know if there are plans", "@yaroslavvb thanks for the input. I'll definitely have a look into it.", "PS, we also run into MetaGraph slowness issue (on the saving side), we have to turn it off in our reinforcement learning scripts -- https://github.com/openai/universe-starter-agent/blob/master/worker.py#L18", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7624, "title": "tensorflow codes totally different result with PyTorch's", "body": "Hi, I'm new to tensorflow and trying to refactor one of my project originally in (Py)Torch. However, though the two codes has the same network, the same loss function, the same optimizer parameters, the result is totally different. Is any one have any idea about such issue?\r\n\r\nThanks.", "comments": ["This question may be better suited for stackoverflow. In general there's no magic solution short of comparing results line by line -- because there's no standard, neural network primitives have slightly different implementations across frameworks. Since SGD is unstable, (sometimes single backprop pass is numerically unstable), slight differences can cause a dramatic difference in the end. This is a common problem that people have reported on stackoverflow when transferring between frameworks", "Thanks. However, the result is stable. In fact, I'm training a conditional VAE, and for the  tensorflow model, the category label hardly influence the image generated while the PyTorch's run smoothly. So it is likely that something is going wrong.\r\n\r\nCurrently, I'm trying to test the model with an older version of tensorflow, and to check is this would only occur in tensorflow 1.0.", "If you are able to isolate it to a specific operation that gives an incorrect result, it would be worth filing an issue with reproduction instructions. I've seen examples of networks not training when transferring to new framework (ie, distbelief->tensorflow) because of some slight differences in op semantics", "In addition to @yaroslavvb suggesting we need a reproducible test case, please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks! You could also try with and without GPU.", "The code can be viewed at https://github.com/Response777/Tensorflow-VAEs.\r\n\r\nThe tensorflow code's generated result of conditional VAE is in [Tensorflow-VAEs//misc/condition_generated_imgs/cvae-mlp-mnist/](https://github.com/Response777/Tensorflow-VAEs/tree/master/misc/condition_generated_imgs/cvae-mlp-mnist)\r\n\r\nWhile the PyTorch's is in [Tensorflow-VAEs/PyTorch/CVAE.py/](https://github.com/Response777/Tensorflow-VAEs/tree/master/PyTorch/CVAE.py)\r\n\r\nIt seems that the label can hardly influence the generated images, while in PyTorch, the code just runs smoothly.", "The PyTorch and Tensorflow network shares the same network structure.\r\nAnd I use the same loss function, the same Optimizer, the same learning_rate.\r\n\r\nAnd I have checked the weights initializer of **tensorflow.contrib.layers.fully_connected** and PyTorch's **torch.nn.modules.linear**.\r\n\r\nNow, the tensorflow's layer is using **variance_scaling_initializer(factor = 0.3, mode = 'FAN_IN', uniform = True)**, which is the same as the one in PyTorch's(this could be examined at http://pytorch.org/docs/_modules/torch/nn/modules/linear.html#Linear)", "Can you isolate the difference to a specific op? (Ie it's not clear if this\nis caused by a bug, or by difference in op semantics which is not a bug)\n\nOn Feb 18, 2017 10:20 PM, \"Tianjian Jiang\" <notifications@github.com> wrote:\n\n> The code can be viewed at https://github.com/Response777/Tensorflow-VAEs.\n>\n> The tensorflow code's generated result of conditional VAE is in\n> Tensorflow-VAEs//misc/condition_generated_imgs/cvae-mlp-mnist/\n> <https://github.com/Response777/Tensorflow-VAEs/tree/master/misc/condition_generated_imgs/cvae-mlp-mnist>\n>\n> While the PyTorch's is in Tensorflow-VAEs/PyTorch/CVAE.py/\n> <https://github.com/Response777/Tensorflow-VAEs/tree/master/PyTorch/CVAE.py>\n>\n> It seems that the label can hardly influence the generated images, while\n> in PyTorch, the code just runs smoothly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7624#issuecomment-280899166>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHJck6v85VR7cJUJLhc78U_uIfEipks5rd98qgaJpZM4MEWSb>\n> .\n>\n", "Also, if you are using random initialization, you might want to switch to constant initialization, followed by seeded initialization. \r\n", "@yaroslavvb It seems that the results are different even if I kept all the conditions the same, so I'm having difficulty control a specific op, since PyTorch and Tensorflow are two distinct framework.\r\n\r\nOr you means I should not use the layer in **tensorflow.contrib.layers**? If so, I'm trying it at the same time, but coming across with a new problem...", "@aselle It seems that I need to see if the PyTorch and Tensorflow are using the same random function first, or it won't help even if the seed is the same.", "@aselle I found that the PyTorch's `uniform_(from=0, to=1) \u2192 Tensor` does not have seed as an input", "@yaroslavvb I'm trying to isolate the difference to an op by writing layers ([module/mnist/cvae/mlp2.py](https://github.com/Response777/Tensorflow-VAEs/blob/master/modules/mnist/cvae/mlp2.py)).\r\n\r\nThe training procedure runs smoothly, but the sampling procedure is coming across with some problem: they are not sharing variables, even if I have added\r\n\r\n```\r\n# modules/mnist/cvae/mlp2.py class Decoder\r\nwith tf.variable_scope(self.name) as vs:\r\n            if reuse == True:\r\n                vs.reuse_variables()\r\n```\r\n\r\nAccording to the output of `tf.all_variables()`, the program have created another decoder named `CVAE/Decoder_1`, but I have set `reuse = True` in `CVAE::__init__`, and the code didn't throw any exception", "Fixed. This is caused by `fully_connected`.", "@Response777 What was your problem with fully_connected layer and how did you fix it? I was transferring a model from PyTroch to TensorFlow and observed a decrease in performance. I also used the tf.contrib.layers.fully_connected to replace the Pytorch nn.Linear, so I wonder if I ran into the same issue.", "Hi @JingHuang81 , I believe they are two distinct issues -- I was training new model from scratch at that time rather than just transfering the parameters. As far as I am concerned, your problem might be related to some differences in implementation or numerical unstablility. I think you might want to  compare intermediate results layer by layer(or you can try binary search to locate the causes).", "@Response777 Hi, can you please tell me what was your problem with fully_connected layer. I encounter a performance drop when I convert a torch version model to a tensorflow version model. "]}, {"number": 7623, "title": "Error in pywrap_tensorflow.py after installing succesful tensorflow", "body": "Hello,\r\n\r\ntrying to install tensorflow in Windows7 without GPU, I follow the guidelines:\r\n\r\nI install python 3.5, then:\r\n\r\npip3 install --upgrade tensorflow\r\n\r\nimport tensorflow as tf\r\n\r\nand I obtain the following error:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Impossibile trovare il modulo specificato.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Impossibile trovare il modulo specificato.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nthank you for any help", "comments": ["Please check the **NOTE** under [Pip Installation on Windows](https://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation_on_windows) and follow up if you still have any doubts. Thanks", "Thank you! It imported correctly.\r\nI landed on thath page but for some reason I skipped the NOTE, maybe because I thougth it was for version 0.12.  ", "Thanks @carmezim! Glad you got it working @dandarm, closing for now.\r\n\r\n", "Ok, still a newbee problem here ... I have what seems like the same error. Reading this chain I tried to install the Visual C++ 2015 redistributable (x64 version) per @Carmezim. However that simply tosses an installer error that it cannot install over a newer version already on my system. So I also tried manually putting the existing msvcp140.dll into my User Variables %PATH% (as C:\\Windows\\System32\\msvcp140.dll) which similarly fails to solve the problem. Suggestions? Full stack trace from Python below.\r\n\r\nC:\\Users\\jeffh>python\r\nPython 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as foo\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>", "@Jeffh2 hey Jeff, can you provide all the relevant info as TF version, using GPU/CPU etc? \r\nAs it notified you of a newer version it might be a different cause. \r\nCould you try running this [script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c)? It will help diagnosing the issue.", "Hi Ardiano,\n\n\nLet's see ... following is the info. After running tensorflow_self_check.py I see that it doesn't find a couple of cud*.dll needed for the GPU version of tensorflow. That's probably because I assumed I already had that installed as part of the NVIDIA software that comes with this PC. That's what I get for assuming!\n\n\nNVIDIA GeForce GTX 960, 2GB\n\nIntel Core i7-6700K @ 4.0GHz\n\n\nC:\\Users\\jeffh>pip list | findstr tensorflow\ntensorflow-gpu (1.2.1)\n\nRun tensorflow_self_check.py script (note - syntax error line 111 of https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c ):\n\nC:\\Users\\jeffh\\Downloads>python tensorflow_self_check.py\nERROR: Failed to import the TensorFlow module.\n\n- Python version is 3.5.\n\n- TensorFlow is installed at: C:\\Users\\jeffh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\n\n- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow\n  requires that this DLL be installed in a directory that is named in\n  your %PATH% environment variable. Download and install CUDA 8.0 from\n  this URL: https://developer.nvidia.com/cuda-toolkit\n\n- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow\n  requires that this DLL be installed in a directory that is named in\n  your %PATH% environment variable. Note that installing cuDNN is a\n  separate step from installing CUDA, and it is often found in a\n  different directory from the CUDA DLLs. You may install the\n  necessary DLL by downloading cuDNN 5.1 from this URL:\n  https://developer.nvidia.com/cudnn\nTraceback (most recent call last):\n  File \"tensorflow_self_check.py\", line 137, in <module>\n    main()\n  File \"tensorflow_self_check.py\", line 108, in main\n    if not cudnn5_found or not cudnn6_found:\nUnboundLocalError: local variable 'cudnn5_found' referenced before assignment\n\n\n\n\n________________________________\nFrom: Adriano Carmezim <notifications@github.com>\nSent: Saturday, July 29, 2017 8:10 PM\nTo: tensorflow/tensorflow\nCc: Jeffh2; Mention\nSubject: Re: [tensorflow/tensorflow] Error in pywrap_tensorflow.py after installing succesful tensorflow (#7623)\n\n\n@Jeffh2<https://github.com/jeffh2> hey Jeff, can you provide all the relevant info as TF version, using GPU/CPU etc?\nAs it notified you of a newer version it might be a different cause.\nCould you try running this (script)[https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c]? It will help diagnosing the issue.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/7623#issuecomment-318874751>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AdJFwckHWvqpPX-DpyBGQUwpuE1WtDxQks5sS_QtgaJpZM4MEWMJ>.\n", "Solved ... thanks @Carmezim for the assistance!\r\n\r\nTLDR; NVIDIA CUDA toolkit and cuDNN were _not_ installed as required by tensorflow GPU version; corrected and it works now. Problem solved.\r\n\r\nAfter running tensorflow_self_check.py I see that it doesn't find a couple of cud*.dll needed for the GPU version of tensorflow. That's because I assumed I already had that installed as part of the NVIDIA software that comes with this PC. That's what I get for assuming! \r\n\r\nSo then, I installed both cuda-toolkit and cuDNN from the supplied NVIDIA URL's. After updating %PATH% to include the install path that seemed to work (i.e. re-running tensorflow_self_check.py reported \"TensorFlow successfully installed. The installed version of TensorFlow includes GPU support.\"). And ... drum roll ... start up the python interpreter and try importing tensorflow. IT WORKS! Issued solved and thanks for the assistance.\r\n\r\nAlso - this post (https://nitishmutha.github.io/tensorflow/2017/01/22/TensorFlow-with-gpu-for-windows.html) has some good info for other beginners that struggle with the Windows install.\r\n\r\nJeff", "One additional note that helped me figure things out (after reading all of the other advice and still having issues). This note may be useful for either the CPU or the GPU version of tensorflow.\r\n\r\nOn Windows, there is a Python dynamic library called `_pywrap_tensorflow_internal.pyd` in a location similar to this one:\r\n\r\n`C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd`\r\n\r\nThis library in turn has dependencies on other libraries, which you can print out with the `dumpbin.exe` command that comes with Visual Studio:\r\n\r\n`\"c:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\dumpbin.exe\" /dependents C:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd`\r\n\r\nThe output will include something like this:\r\n\r\n`\r\n    KERNEL32.dll\r\n    WSOCK32.dll\r\n    WS2_32.dll\r\n    SHLWAPI.dll\r\n    nvcuda.dll\r\n    cublas64_80.dll\r\n    cufft64_80.dll\r\n    curand64_80.dll\r\n    cudnn64_6.dll\r\n    python36.dll\r\n    MSVCP140.dll\r\n    VCRUNTIME140.dll\r\n`\r\n\r\nAt this point you can simply use the `where` command to make sure you have all these libraries, e.g.:\r\n\r\n`where kernel32.dll`\r\n`where nvcuda.dll`\r\n\r\nEtc.\r\n\r\nIf the `where` command fails, then the library is either not on `%PATH%` or it is missing altogether.\r\n\r\nIn my case, I did everything right, but had a newer version of the cudnn library (I had `cudnn64_7.dll` but it was looking for `cudnn64_6.dll`).\r\n\r\nAlmost all of the problems I have seen with this issue come down to checking that these libraries exist and can be found.\r\n\r\n", "I just Installed tensorflow for anaconda.\r\nAnd I'm getting this Error..\r\nThe Previous Solutions Was Not Useful....\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"tf.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\n\r\n", "@lucifer6666 Could you try to run [this script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) and see what it points you to?", "ERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.6.\r\n\r\n- TensorFlow is installed at: C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Download and install CUDA 8.0 from\r\n  this URL: https://developer.nvidia.com/cuda-toolkit\r\n\r\n- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Note that installing cuDNN is a\r\n  separate step from installing CUDA, and it is often found in a\r\n  different directory from the CUDA DLLs. You may install the\r\n  necessary DLL by downloading cuDNN 5.1 from this URL:\r\n  https://developer.nvidia.com/cudnn\r\n\r\n- Could not find cuDNN.\r\n\r\n\r\nit is serching for cuda 8.0 but i have installed cuda9.0", "@lucifer6666 CUDA 9 is not supported neither cuDNN 7. For all requirements details please check the installation docs.", "I Installed CUDA 8.0 and CuDNN 6.0 and now it is working....\r\n      Thanks For The Help......@Carmezim", "Can Anyone tell me how to train my own classifier in tensorflow using my own image files\r\n\r\nand how to set up a trainer...", "@lucifer6666 github issues are only for bugs and feat. requests. You can ask on stackoverflow.com under the TensorFlow tag for community support. I think TF has an tutorial on that, if it's not what you looking there's a lot of tutorials out there on image classification.", "Traceback (most recent call last):\r\n  File \"classify_image.py\", line 227, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"classify_image.py\", line 193, in main\r\n    run_inference_on_image(image)\r\n  File \"classify_image.py\", line 141, in run_inference_on_image\r\n    image_data = tf.gfile.FastGFile(image, 'rb').read()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 118, in read\r\n    self._preread_check()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 78, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.UnknownError: NewRandomAccessFile failed to Create/Open: I:/projects/py/tf_files/flower_photos : Access is denied.\r\n; Input/output error", "@lucifer6666 Could you please elaborate on the problem adding all other relevant information to your log? Formatting your stack-trace in code blocks helps as well.\r\nCheck the Issue template for reference on how you could provide that so we can better help you.\r\n\r\nWith the limited information I can only conclude by looking at your log that you seem to not have the right permissions to access `flower_photos` locally, so it's not a TensorFlow bug but a permission issue on your side. \r\nI could give a wild guess to run your prompt as administrator so you can have read/write permissions over those files when executing the scripts.\r\nIf it's not that make sure your user in your machine have the correct permissions or your talk to its administrator to concede it to you. ", "I:\\projects\\py>python -m scripts.retrain \\--bottleneck_dir=tf_files/bottlenecks \\--how_many_training_steps=500 \\--model_dir=tf_files/models/ \\--summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\--output_graph=tf_files/retrained_graph.pb \\--output_labels=tf_files/retrained_labels.txt \\--architecture=\"${ARCHITECTURE}\" \\--image_dir=tf_files/flower_photos\r\nERROR:tensorflow:Image directory '' not found.\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 1257, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 920, in main\r\n    class_count = len(image_lists.keys())\r\nAttributeError: 'NoneType' object has no attribute 'keys'", "I Corrected the previous error ,\r\nNow it is showing this error\r\n\r\n\r\nC:\\Users\\welcomepc>python -m scripts.retrain \\--bottleneck_dir=tf_files/bottlenecks \\--how_many_training_steps=500 \\--model_dir=tf_files/models/ \\--summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\--output_graph=tf_files/retrained_graph.pb \\--output_labels=tf_files/retrained_labels.txt \\--architecture=\"${ARCHITECTURE}\" \\--image_dir=tf_files/flower_photos\r\nINFO:tensorflow:Looking for images in 'daisy'\r\nINFO:tensorflow:Looking for images in 'dandelion'\r\nINFO:tensorflow:Looking for images in 'roses'\r\nINFO:tensorflow:Looking for images in 'sunflowers'\r\nINFO:tensorflow:Looking for images in 'tulips'\r\n2017-11-03 18:58:10.063270: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-11-03 18:58:10.063373: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-11-03 18:58:10.665628: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:955] Found device 0 with properties:\r\nname: GeForce 940M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.176\r\npciBusID 0000:0a:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.66GiB\r\n2017-11-03 18:58:10.665757: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:976] DMA: 0\r\n2017-11-03 18:58:10.670487: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:986] 0:   Y\r\n2017-11-03 18:58:10.676387: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940M, pci bus id: 0000:0a:00.0)\r\nINFO:tensorflow:Creating bottleneck at /tmp/bottleneck\\daisy\\100080576_f52e8ee070_n.jpg_inception_v3.txt\r\nCRITICAL:tensorflow:File does not exist daisy\\100080576_f52e8ee070_n.jpg\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 1259, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 958, in main\r\n    bottleneck_tensor, FLAGS.architecture)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 437, in cache_bottlenecks\r\n    resized_input_tensor, bottleneck_tensor, architecture)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 382, in get_or_create_bottleneck\r\n    bottleneck_tensor)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\scripts\\retrain.py\", line 333, in create_bottleneck_file\r\n    image_data = gfile.FastGFile(image_path, 'rb').read()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 118, in read\r\n    self._preread_check()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 78, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: NewRandomAccessFile failed to Create/Open: daisy\\100080576_f52e8ee070_n.jpg : The system cannot find the path specified.", "you can check the system path, because I had this problem. for example, add my path to system path \"C:\\ProgramData\\Anaconda3\\envs\\T\\Library\\bin\"", "Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Maithri\\Anaconda2\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Maithri\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Maithri\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Maithri\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Maithri\\Anaconda2\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nImportError: No module named _pywrap_tensorflow\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n------------\r\ni tried installing microsoft visual c++ also after seeing your reply but its not working the same error is repeating.\r\nI have installed tensorflow using this pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.1-py2-none-any.whl in anaconda prompt because none other  command is working \r\nI got this error when i tried to run a piece of code on anaconda prompt after typing python  later import tensorflow as tf.\r\n Can you tell what should i do.\r\n", "i am using tensorflow for cpu but i got this following error msg when i tried to run my code. if anyone have solution to this error kindly help me out. thnx\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n\r\n", "@Saira05 could you try running [this script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) and see what it points you to?\r\n", "**System information**\r\n**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n**OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 64bit service pack 1\r\n**TensorFlow installed from (source or binary)**:source\r\n**TensorFlow version (use command below)**: 1.6\r\n**Python version**: Python 3.5.2\r\n**Bazel version (if compiling from source)**: N/A\r\n**GCC/Compiler version (if compiling from source)**: N/A\r\n**CUDA/cuDNN version**: N/A\r\n**GPU model and memory**: No GPU model\r\n**Exact command to reproduce**:import tensor flow\r\n\r\n**Describe the problem**\r\nI'm getting the following error when importing tensorflow after following the pip install directions here [](https://www.tensorflow.org/install/install_windows) . When I try to verify the installation, I receive the following error when I try to import tensorflow. \r\n\r\n> Traceback (most recent call last):\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n>     return importlib.import_module(mname)\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n>   File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n>   File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n>   File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n>   File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n>   File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n>   File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n>   File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n> ImportError: DLL load failed with error code -1073741795\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n>     from tensorflow.python.pywrap_tensorflow_internal import *\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n>     _pywrap_tensorflow_internal = swig_import_helper()\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n>     return importlib.import_module('_pywrap_tensorflow_internal')\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n> ImportError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"<pyshell#0>\", line 1, in <module>\r\n>     import tensorflow\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n>     from tensorflow.python import *\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n>     from tensorflow.python import pywrap_tensorflow\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n>     raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n>     return importlib.import_module(mname)\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n>   File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n>   File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n>   File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n>   File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n>   File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n>   File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n>   File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n> ImportError: DLL load failed with error code -1073741795\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n>     from tensorflow.python.pywrap_tensorflow_internal import *\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n>     _pywrap_tensorflow_internal = swig_import_helper()\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n>     return importlib.import_module('_pywrap_tensorflow_internal')\r\n>   File \"C:\\Users\\Nhan\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n> ImportError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n> \r\n> for some common reasons and solutions.  Include the entire stack trace\r\n> above this error message when asking for help.\r\n", "https://www.youtube.com/watch?v=ZNWQN_g_ZsI\r\n\r\n@thenumber23 if you are using tensorflow without gpu then this video might help you just follow these step, it help me alot\r\n\r\n", "Thankyou for your response I got it now\n\nOn Mar 12, 2018 2:35 PM, \"Saira05\" <notifications@github.com> wrote:\n\n> https://www.youtube.com/watch?v=ZNWQN_g_ZsI\n>\n> if you are using tensorflow without gpu then this video might help you\n> just follow these step, it help me alot\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7623#issuecomment-372236640>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AWb6DuS4zDXZm1-EvleO4vCZ3ZCP6RnZks5tdjpKgaJpZM4MEWMJ>\n> .\n>\n", "@Saira05 Thanks for the video, but I followed the steps and still got the same error at when I tried to import.  ", "thanks alot for slove my problem. ", "**I have installed tensorflow with anaconda(python 3.6)\r\n(system config.\r\nRam-2gb , 64bit , windows 8)\r\nwhen i try to import tensorflow I an getting this Error**\r\nCan anyone help me...\r\n\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import\r\n_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine fa\r\niled.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import\r\n_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line\r\n 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\r\n\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import\r\n_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine fa\r\niled.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tens\r\norflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import\r\n_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>", "I have the same problem as above. Installed env:\r\n\r\nPython 3.6.5 |Anaconda, Inc 5.2.2 64 bit.\r\n\r\nTensor flow fails to load with error above", "import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\dipta\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.", "Traceback (most recent call last):\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load\r\n_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load\r\n_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified procedure could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\_\r\n_init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im\r\nport\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load\r\n_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Shoaib\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load\r\n_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified procedure could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_probl\r\nems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "Upgraded TF-GPU from 1.12 to 1.13 and started getting this error.  Windows 10.\r\n\r\nI updated CUDA/cuDNN, etc, but forgot to set the new environmental path for CUDA.  Doing so fixed the issue:\r\nie) from the prompt,\r\n`SET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include;%PATH%`", "I installed tensorflow in anaconda and running it on CPU. But when I tried importing the tensorflow it is giving me following error.\r\nTraceback (most recent call last):\r\n\r\n\r\n  File \"<ipython-input-1-64156d691fe5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\raiyani\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Invalid access to memory location.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "> Please check the **NOTE** under [Pip Installation on Windows](https://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation_on_windows) and follow up if you still have any doubts. Thanks\r\n\r\ni don't understand your mean", "i found this error while working with tensorflow\r\ncan someone tell me what to do?\r\n\r\n\r\nImportError                               Traceback (most recent call last)\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     17         try:\r\n---> 18             fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n     19         except ImportError:\r\n\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py in find_module(name, path)\r\n    295     else:\r\n--> 296         raise ImportError(_ERR_MSG.format(name), name=name)\r\n    297 \r\n\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)\r\n---> 41   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     42   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     19         except ImportError:\r\n---> 20             import _pywrap_tensorflow_internal\r\n     21             return _pywrap_tensorflow_internal\r\n\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-4-1476394eccf4> in <module>\r\n      4 import sys\r\n      5 import numpy as np\r\n----> 6 import tensorflow as tf\r\n      7 import os\r\n\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\nc:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     50 for some common reasons and solutions.  Include the entire stack trace\r\n     51 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 52   raise ImportError(msg)\r\n     53 \r\n     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"c:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\prashasti\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "Hi guys solved the above importing tensor flow error on my CPU after i downloaded and install\r\nMicrosoft Visual C++ 2015-2019 Redistributable (x64)\r\nVC_redist.x64 version on my laptop.. hope this help someone out there.\r\nI had initially installed Anaconda 3.7 python version, then i now using the conda command prompt\r\ninstalled the tensor flow successfully from Anaconda and it worked. But on importing tensorflow i ran into the above issues.\r\ni even installed msv140dll still did not work until i downloaded and run\r\nVC_redist.x64 version everything worked after then\r\ncheers", "I got this problem in import tensorflow. None of the above could help. Any help would be much appreciated!\r\n\r\nImportError                               Traceback (most recent call last)\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     63   try:\r\n---> 64     from tensorflow.python._pywrap_tensorflow_internal import *\r\n     65   # This try catch logic is because there is no bazel equivalent for py_extension.\r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-2-93dd4568dde0> in <module>\r\n----> 1 import tensorflow as tf\r\n      2 from tensorflow import keras\r\n      3 tf.__version__\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\r\n     39 \r\n---> 40 from tensorflow.python.eager import context\r\n     41 \r\n     42 # pylint: enable=wildcard-import\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py in <module>\r\n     33 from tensorflow.core.protobuf import config_pb2\r\n     34 from tensorflow.core.protobuf import rewriter_config_pb2\r\n---> 35 from tensorflow.python import pywrap_tfe\r\n     36 from tensorflow.python import tf2\r\n     37 from tensorflow.python.client import pywrap_tf_session\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tfe.py in <module>\r\n     26 \r\n     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\r\n---> 28 from tensorflow.python import pywrap_tensorflow\r\n     29 from tensorflow.python._pywrap_tfe import *\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     81 for some common reasons and solutions.  Include the entire stack trace\r\n     82 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 83   raise ImportError(msg)\r\n     84 \r\n     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\phess\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n"]}, {"number": 7622, "title": "tf.pad does not support SparseTensor in r1.0", "body": "This works \r\n```\r\nimport tensorflow as tf\r\nsession = tf.InteractiveSession()\r\npad = tf.pad([[1,2]], [[0,0],[0,150]], mode='CONSTANT')\r\npad.eval()\r\n```\r\n\r\nBut this doesn't work\r\n\r\n```\r\nimport tensorflow as tf\r\nsession = tf.InteractiveSession()\r\ntensor = tf.SparseTensor(indices=[[0, 0], [0, 1]], values=[1, 2], dense_shape=[1, 2])\r\npad = tf.pad(tensor, [[0,0],[0,150]], mode='CONSTANT')\r\npad.eval()\r\n```\r\n\r\nThe following error is thrown\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/sromano/Dropbox/uba/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1646, in pad\r\n    return gen_array_ops._pad(tensor, paddings, name=name)\r\n  File \"/Users/sromano/Dropbox/uba/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2083, in _pad\r\n    name=name)\r\n  File \"/Users/sromano/Dropbox/uba/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 494, in apply_op\r\n    raise err\r\nTypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x116288450>\r\n```\r\n\r\nMy use case is that I'm reading a csv file where each row has a different amount of elements and I want to turn it into a matrix of a fixed length. I use string split in each row and I get a SparseTensor, so then I need a different padding in each row to complete the expected width.\r\n\r\nI'm using Python 2.7 and Tensorflow r1.0", "comments": ["Did this work for you  previously?", "No. I updated from r0.10 to r1.0 to see if it will get solved. But it did not work in any of the two versions", "Yes, unfortunately, it is difficult to support every operation for sparse tensors, and currently it is only supported by a few special ops. With the current sparse form this is unlikely to be a super efficient operation, since to produce paded values, you'd need random access to access values for a gather based approach to producing padded values. It's definitely possible, but we haven't found a need for it yet. What is your use case. Would you be willing to work on a PR to add support?\r\nThanks for posting this issue!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7621, "title": "After installation error", "body": "Im getting this output \r\n>>> import tensorflow as tf\r\nhello = tf.constant('Hello, TensorFlow!')\r\nsess = tf.Session()\r\nprint(sess.run(hello))\r\n \r\n \r\n\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') fo\r\nr unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_t\r\nype: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"')\r\n for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for\r\nunknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_ty\r\npe: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"')\r\nfor unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"'\r\n) for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') fo\r\nr unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') fo\r\nr unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"\r\n') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\r\n\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"C\r\nPU\"') for unknown op: UpdateFertileSlots\r\nb'Hello, Tensorflow'\r\n\r\n\r\nBut when i run\r\n>>> import tensorflow as tf\r\n>>>\r\n>>>\r\n>>>#4 line gap\r\n>>>\r\n>>>hello = tf.constant('Hello, TensorFlow!')\r\n>>>sess = tf.Session()\r\n>>>print(sess.run(hello))\r\n\r\nthen the output is \r\n>>>b'Hello, TensorFlow!'\r\n\r\n\r\nso i think its a bug in Tensorflow", "comments": ["Duplicate with https://github.com/tensorflow/tensorflow/issues/7500", "Thanks for pointing this out as a dup @kaufManu .  I'm closing it since #7500 is resolved in nightlies.\r\n", "Python sux"]}, {"number": 7620, "title": "Tensorboard Embedding with t-SNE Crash", "body": "When I run t-SNE on my datasets (on smallest or bigger one) with tensorboard embedding , the app crash all the times (after thereabout 500 iterations). I can't re-run or stop the operation to change the parameters, the iteration number freeze and the other functionalities on embedding part crash also.\r\n\r\nAnyone have the same problem ? Other curiosity is if I run on [online tensorboard](http://projector.tensorflow.org/) embedding I have the same problem.\r\n", "comments": ["Not sure you are the right person to ask, @dsmilkov, but could you  please take a look at this?\r\nThanks so much in advance!\r\n", "Thanks @aselle !", "Hi @smar10,\r\n\r\nThanks for reporting. We'll need some info to help us reproduce the problem.\r\n\r\n1. What browser and OS are you using?\r\n2. What is the size of your dataset (number of points and dimensionality)?\r\n3. If (some of) your datasets are public, can you share it with us?\r\n\r\nThanks!", "Hi @dsmilkov, \r\nAfter reading your questions and get more problems on audio tab on tensorboard, I realized what the issue might be... I was using Safari instead of Chrome. \r\nI make some tests with same dataset and it's all ok on Chrome. \r\n\r\nThanks !", "Hi @smar10,\r\n\r\nCan you share the size (number of points) of the dataset and the dimensionality of the embeddings, so that we have a sense of what the crash on Safari might be related to?\r\n\r\nThanks!", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 7619, "title": "Are there any restrictions for TF r1.0 to support C++?", "body": "The previous versions need generate graph by python firstly. For 1.0, based on the doc, we can construct the graph by c++.\r\n\r\nIs the C++ supporting totally the same as python now?", "comments": ["You should be able to author a graph, but you cannot automatically compute gradients which is the major limitation of not using python to construct the model."]}, {"number": 7618, "title": "Windows 7 build problem. \"Release\" folder is missing from protoc.exe path", "body": "I'm trying to build tensorflow 1.0 on windows 7, using cmake.\r\n\r\nI have generated the project, but when I try to build it I get this error: \r\n\r\n> Error\tMSB6006\t\"cmd.exe\" exited with code 9009.\ttf_protos_cc\tC:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets\t171\t\r\n\r\nThe output logs says:\r\n\r\n> 1>------ Build started: Project: zlib, Configuration: Release x64 ------\r\n> 1>  Performing update step for 'zlib'\r\n> 2>------ Build started: Project: protobuf, Configuration: Release x64 ------\r\n> 2>  Performing update step for 'protobuf'\r\n> 3>------ Build started: Project: tf_protos_cc, Configuration: Release x64 ------\r\n> 3>  Building Custom Rule D:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n> 3>  CMake does not need to re-run because D:/tensorflow/cmake_build/CMakeFiles/generate.stamp is up-to-date.\r\n> 3>  Running C++ protocol buffer compiler on tensorflow/core/debug/debug_service.proto\r\n> 3>  'protobuf\\src\\protobuf\\\\protoc.exe' is not recognized as an internal or external command,\r\n> 3>  operable program or batch file.\r\n> 3>C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exited with code 9009.\r\n> ========== Build: 2 succeeded, 1 failed, 1 up-to-date, 0 skipped ==========\r\n\r\nWhat I noticed is that it's looking for protoc.exe at the location: `protobuf\\src\\protobuf\\\\protoc.exe` and I can confirm that the real location is: `protobuf\\src\\protobuf\\Release\\protoc.exe`\r\n\r\nThe double \\\\ makes it seem like the path was suppose to include \"Release\" but didn't for some reason.\r\n\r\nIf you need any additional info please let me know.\r\n", "comments": ["Nevermind - I found the issue.\r\n\r\nI did not add -DCMAKE_BUILD_TYPE=Release as a cmake argument."]}, {"number": 7617, "title": "fix windows build", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please\r\n\r\nThanks for the fix!"]}, {"number": 7616, "title": "Change device Placement of existing variable", "body": "How do I change the device placement of a tf.Variable() ?\r\nI tried two methods \r\n```\r\na = tf.Variable(1,name = 'a')  # a's device is not set\r\nwith tf.device('/gpu:0'):\r\n       a = tf.get_variable('a',1)   \r\n# this creates a new variable on the gpu and doesn't change device assignment for a\r\n```\r\nI tried enforcing variable reuse by using tf.get_variable_scope().reuse_variables()\r\n```\r\na = tf.Variable(1,name = 'a')  # a's device is not set\r\ntf.get_variable_scope().reuse_variables()\r\nwith tf.device('/gpu:0'):\r\n       a = tf.get_variable('a',1)   \r\n# this creates a new variable on the gpu and doesn't change device assignment for a\r\n```\r\nThis time, I get an error saying the variable 'a' did not exist in the gpu.\r\n\r\nAny help on changing-device-placement or lazy-device-assignment would be appreciated. Thanks\r\n\r\n\r\n\r\n", "comments": ["This is not a bug, right? Make a thread on StackOverflow and people will want to answer! :smiley: ", "here is the link to the stackoverflow question i posted : \r\nhttps://stackoverflow.com/questions/42300475/change-device-placement-of-an-existing-tensorflow-variable\r\nPlease have a look. ", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 7615, "title": "tfdbg Dump root directory does not exist", "body": "I run \r\npython -m tensorflow.python.debug.examples.debug_mnist --debug\r\non my laptop.which has windows 10 and gtx1070.but after I type first run,it return an exception like this:\r\nTraceback (most recent call last):\r\n  File \"d:\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\examples\\debug_mnist.py\", line 138, in <module>\r\n    tf.app.run()\r\n  File \"d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\examples\\debug_mnist.py\", line 131, in main\r\n    acc = sess.run(accuracy, feed_dict=feed_dict(False))\r\n  File \"d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\framework.py\", line 419, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 262, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\debug_data.py\", line 328, in __init__\r\n    raise IOError(\"Dump root directory %s does not exist\" % dump_root)\r\nOSError: Dump root directory C:\\Users\\tony8\\AppData\\Local\\Temp\\tfdbg_cvtcdnhl does not exist\r\n\r\n\r\nhow can I fix it?Thank you", "comments": ["Thanks for reporting this issue. I can reproduce it in 1.0.0 on Windows. It appears that this is because the core/debug module was not linked for the Windows cmake build (despite the fact that it is built for the Windows bazel build, but cmake is the one used in building the release binary). I'll fix it and the fix will be reflected in nightly builds and the next release. Sorry about the inconvenience it has caused.\r\n\r\ncc @mrry, @gunan ", "This is fixed by https://github.com/tensorflow/tensorflow/commit/d82e42ca3a0b06d768a439d84ff74741de7e092d\r\n\r\nPlease use our [Windows nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/) and/or wait for the next release.", "I am having this issue on Ubuntu 14.04 & TF 0.12.1 (01/2017 version of Bitfusion Tensorflow AMI to be exact).", "TF debugger is only officially released with TF 1.0.\r\nIt not working with 0.12 version is expected.", "@atilaorh , can you confirm that you are experiencing this problem on Windows? The Windows-specific issue has been fixed in the master branch and the fix will be available in the next release (r1.1).", "@atilaorh , OK. Just realized that Bitfusion TensorFlow AMI is not Windows - it is Ubuntu Linux. Does the [example](https://www.tensorflow.org/programmers_guide/debugger) work for you? I'd like to rule out the possibility that the reason for the issue you are seeing is something specific to your model or the way you are using tfdbg.\r\n\r\n```\r\npython -m tensorflow.python.debug.examples.debug_mnist --debug\r\n```", "Sorry for the false alarm. This only happened once. Second run for the exact same script ran seamlessly. Example works as well..", "TensorFlow 1.1.0rc0 has just come out. tfdbg should be working on Windows 7 and up now. Please give it a try. \r\n\r\nNote: the default CLI of tfdbg on Linux and Mac uses curses. But there is no official curses support on Windows. So tfdbg CLI uses the less interactive readline on Windows, which does not have the mouse interaction and history navigation available on Linux and Mac.", "I am getting this same issue on TF 1.3.0, Fedora 25 64-bit installed from pip. "]}, {"number": 7614, "title": "Update gmm_ops.py", "body": "It should be int64 instead of int32", "comments": ["Can one of the admins verify this patch?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Jenkins, test this please.", "The relevant tests fail with the cast removed. @agarwal-ashish is this expected?", "Jenkins, test this please.", "Jenkins, test this please.", "@agarwal-ashish could you take a look at the failing tests?", "Please refer to my earlier comment. You need to cast num_data to int64 in\ngmm_ops.py.\n\nOn Fri, Apr 14, 2017 at 8:08 PM, drpngx <notifications@github.com> wrote:\n\n> @agarwal-ashish <https://github.com/agarwal-ashish> could you take a look\n> at the failing tests?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7614#issuecomment-294268239>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AScKdoJn4gQ-2Qku3o_By1oSftorcV9hks5rwDTGgaJpZM4MD8RG>\n> .\n>\n", "Sorry @agarwal-ashish , I meant @gautam1858 . Thanks for the hint!", "what should I do ?", "Jenkins, test this please.", "Jenkins, test this please.", "```\r\nCMakeFiles/iron_validatable_behavior.dir/build.make:89: recipe for target 'iron_validatable_behavior/src/iron_validatable_behavior-stamp/iron_validatable_behavior-download' failed\r\nmake[2]: *** [iron_validatable_behavior/src/iron_validatable_behavior-stamp/iron_validatable_behavior-download] Error 1\r\nCMakeFiles/Makefile2:7918: recipe for target 'CMakeFiles/iron_validatable_behavior.dir/all' failed\r\nmake[1]: *** [CMakeFiles/iron_validatable_behavior.dir/all] Error 2\r\nmake[1]: *** Waiting for unfinished jobs....\r\n```\r\n\r\nSeems like a transient download error.\r\n\r\nJenkins, test this please."]}, {"number": 7613, "title": "build failed", "body": "Build fails with\r\n```\r\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nbut succeeds with\r\n```\r\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nI have used the following configurations:\r\n```\r\nPlease specify the location of python: /home/mark/.pyenv/shims/python\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified: -march=native\r\nDo you wish to use jemalloc as the malloc implementation? y\r\nDo you wish to build TensorFlow with Google Cloud Platform support? n\r\nDo you wish to build TensorFlow with Hadoop File System support? y\r\nDo you wish to build TensorFlow with CUDA support? y\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? n\r\nPlease input the desired Python library path to use: /home/mark/.pyenv/versions/3.6.0/lib/python3.6/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? n\r\nDo you wish to build TensorFlow with CUDA support? y\r\nPlease specify which gcc should be used by nvcc as the host compiler: /usr/bin/gcc-5\r\nPlease specify the CUDA SDK version you want to use: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed: /usr/local/cuda\r\nPlease specify the Cudnn version you want to use: 5.1.10\r\nPlease specify the location where cuDNN 5.1.10 library is installed: /usr/local/cuda\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with: 6.1\r\n```\r\n\r\non the following system:\r\n\r\n- **Operating System**: Debian Sid\r\n- **Installed version of CUDA and cuDNN**: \r\n```\r\nls -l /usr/local/cuda/lib64/libcud*\r\n\r\n-rw-r--r-- 1 root staff   556000 Feb 16 23:37 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root staff       16 Feb 16 23:37 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root staff       19 Feb 16 23:37 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rwxr-xr-x 1 root staff   415432 Feb 16 23:37 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root staff   775162 Feb 16 23:37 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 mark mark        13 Nov  7 02:00 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 mark mark        18 Nov  7 02:00 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\r\n-rwxr-xr-x 1 mark mark  84163560 Nov  7 01:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10\r\n-rw-r--r-- 1 mark mark  70364814 Nov  7 01:47 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n- **The commit hash (`git rev-parse HEAD`)**: b6f16b8166e3a7761f607be66d46acbd37dfaf43\r\n- **The output of `bazel version`**: \r\n\r\nthe build command\r\n```\r\nbazel build -c opt --verbose_failures --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nfails with the following error message:\r\n```\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nINFO: Found 1 target...\r\nERROR: /home/mark/.cache/bazel/_bazel_mark/b8826e9bec4f8f69428cde0a6fac46ac/external/com_googlesource_code_re2/BUILD:11:1: C++ compilation of rule '@com_googlesource_code_re2//:re2' failed: crosstool_wrapper_driver_is_not_gcc failed:error executing command\r\n  (cd /home/mark/.cache/bazel/_bazel_mark/b8826e9bec4f8f69428cde0a6fac46ac/execroot/tensorflow && \\\r\n  exec env - \\\r\n    PATH=/home/mark/bin:/home/mark/.pyenv/shims:/home/mark/.pyenv/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/mark/bin:/usr/local/scala/bin:/usr/local/go/bin:/srv/hadoop/bin \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -MD -MF bazel-out/host/bin/external/com_googlesource_code_re2/_objs/re2/external/com_googlesource_code_re2/re2/prefilter_tree.d '-frandom-seed=bazel-out/host/bin/external/com_googlesource_code_re2/_objs/re2/external/com_googlesource_code_re2/re2/prefilter_tree.o' -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/genfiles/external/com_googlesource_code_re2 -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -pthread -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c external/com_googlesource_code_re2/re2/prefilter_tree.cc -o bazel-out/host/bin/external/com_googlesource_code_re2/_objs/re2/external/com_googlesource_code_re2/re2/prefilter_tree.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ngcc-5: error trying to exec 'cc1plus': execvp: No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n\r\nHow should I proceed from here? Any tip would be appreciated.", "comments": ["Do you have g++ installed. What happens if you type `g++` at the prompt?", "`g++ --version` gives me the following:\r\n```\r\ng++ (Debian 6.3.0-6) 6.3.0 20170205\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\n```\r\n", "@jart, do you have any ideas on this? \r\n\r\n@markhkim. It seems like you are using unstable debian, so it is not something we officially support. \r\nSee these for more information.\r\nhttps://github.com/tensorflow/tensorflow/issues/3550\r\nhttp://stackoverflow.com/questions/38017982/gcc-error-trying-to-exec-cc1plus-execvp-no-such-file-or-directory-on-cent", "It turns out merely installing [g++-5](https://packages.debian.org/sid/amd64/g++-5/download) solves the bazel build issue for me. The setup for Python 3.6 went through just fine afterwards, so I'm all set! Thanks for your help, @aselle."]}, {"number": 7612, "title": "R1.0", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 7611, "title": "How to associate more than one labels with an image in TFRecord file for training purpose?", "body": "", "comments": ["Ask on StackOverflow with the tag #tensorflow: http://stackoverflow.com/questions/tagged/tensorflow", "Thanks. I got that working. Closing this."]}, {"number": 7610, "title": "3D convolutions unnaturally slow on CPU", "body": "3D convolutions on CPU seem unnaturally slow. \r\nI can't use GPU due to memory limit, so I'm looking at CPU execution. \r\n\r\n2D convolutions in TensorFlow seem to be well-optimized, all CPU cores are used, performance is just few times below GPU.\r\n\r\nWith 3D convolutions - the difference is orders of magnitude. \r\n\r\nAlso, I've compared with Theano. Theano 3D convolutions run on single core but still are 10 times faster.\r\n\r\nStrangely, TF uses all cores on CPU with 3Dconv,  so there must be some bug or extreme inefficiency in implementation.\r\n\r\nWith the same small test model (just couple of 3d conv layers) I get 1 second epoch time on GPU (both TF and Theano, theano just a bit faster), 5 seconds on CPU Theano single threaded, and 50 seconds with (seemingly) multi-threded TF\r\n\r\n### Environment info\r\nI've tried different TF versions from 0.12 to 1.00, installed from pip. Latest one from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-linux_x86_64.whl\r\n\r\nThe OS is CentOS Linux release 7.2.1511 (Core) , kernel 3.10.0-327.18.2.el7.x86_64\r\n\r\nI'm using Keras back-end, so I can't be 100% sure if the problem is not in the way Keras translates Convolution3D call into TF primitives, but it does not seem likely. \r\n\r\ncheers\r\nAlex", "comments": ["cc @daeyun who added conv3d_transpose\r\n\r\n(ps: who maintains core/kernels/conv_3d.h  ?)", "@mjanusz might know, I think he implemented / uses Conv3D, possibly even on CPU.", "Eigen's conv3d is not optimized to the same level as conv2d, but the speed you are observing seems to be particularly bad. I will take a look at this.", "I can confirm this problem exists. I've experienced an unnatural 100X factor between a latest mac and a gpu machine. On other tasks I got used to seeing 5-20X at most with 2d convolutions and matrix multiplications. ", "@mjanusz Did you get a chance to look at this?", "Building from sources (MKL enabled) seems to help a lot with this issue. Compared to the pip binary, almost 10x faster.", "@girving Yes. The commit a999474 fixes a regression that should provide a 3x-5x speedup, depending on the exact configuration. The next step to improve performance is to write a contraction mapper in eigen_cuboid_convolutions.h, but I haven't had the chance to do that yet.\r\n", "Observing the same problem here on macOS with CPU. Unnaturally slow and extreme memory requirements (50-100x more compared to conv2d).", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@mjanusz Are you still planning on writing a contraction mapper in eigen_cuboid_convolutions.h? I am keeping this issue open for tracking purposes in case you do.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7609, "title": "Maybe  a bug: Different eval step between CPU and GPU", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nubuntu 14.04\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n`-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\r\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\r\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\r\n-rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Oct 20 14:34 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Oct 20 14:33 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.3\r\n-rwxr-xr-x 1 root root 60696704 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn.so.5.1.3\r\n-rw-r--r-- 1 root root 59715990 Oct 20 14:28 /usr/local/cuda/lib64/libcudnn_static.a`\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`): 16485a3fb5ffcbaa244e55c388e43279d2770982\r\n2. The output of `bazel version`: \r\n.........\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI'm sorry that I can't reproduce it in minimal (mnist) example(it seems to be all right), but in my code, the global_step would pulse agin in the eval stage:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nimport random\r\nimport tensorflow.contrib.slim as slim\r\nimport time\r\nimport logging\r\nimport numpy as np\r\nimport pickle\r\nfrom PIL import Image\r\n\r\n\r\nlogger = logging.getLogger('Training a chinese write char recognition')\r\nlogger.setLevel(logging.INFO)\r\n# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\r\nch = logging.StreamHandler()\r\nch.setLevel(logging.INFO)\r\nlogger.addHandler(ch)\r\n\r\n\r\ntf.app.flags.DEFINE_boolean('random_flip_up_down', False, \"Whether to random flip up down\")\r\ntf.app.flags.DEFINE_boolean('random_brightness', True, \"whether to adjust brightness\")\r\ntf.app.flags.DEFINE_boolean('random_contrast', True, \"whether to random constrast\")\r\n\r\ntf.app.flags.DEFINE_integer('charset_size', 120, \"Choose the first `charset_size` character to conduct our experiment.\")\r\ntf.app.flags.DEFINE_integer('image_size', 64, \"Needs to provide same value as in training.\")\r\ntf.app.flags.DEFINE_boolean('gray', True, \"whether to change the rbg to gray\")\r\ntf.app.flags.DEFINE_integer('max_steps', 12002, 'the max training steps ')\r\ntf.app.flags.DEFINE_integer('eval_steps', 50, \"the step num to eval\")\r\ntf.app.flags.DEFINE_integer('save_steps', 50, \"the steps to save\")\r\n\r\ntf.app.flags.DEFINE_string('checkpoint_dir', './checkpoint/', 'the checkpoint dir')\r\ntf.app.flags.DEFINE_string('train_data_dir', '../data/train/', 'the train dataset dir')\r\ntf.app.flags.DEFINE_string('test_data_dir', '../data/test/', 'the test dataset dir')\r\ntf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')\r\n\r\ntf.app.flags.DEFINE_boolean('restore', False, 'whether to restore from checkpoint')\r\ntf.app.flags.DEFINE_boolean('epoch', 1, 'Number of epoches')\r\ntf.app.flags.DEFINE_boolean('batch_size', 128, 'Validation batch size')\r\ntf.app.flags.DEFINE_string('mode', 'train', 'Running mode. One of {\"train\", \"valid\", \"test\"}')\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\n\r\nclass DataIterator:\r\n    def __init__(self, data_dir):\r\n        # Set FLAGS.charset_size to a small value if available computation power is limited.\r\n        truncate_path = data_dir + ('%05d' % FLAGS.charset_size)\r\n        print(truncate_path)\r\n        self.image_names = []\r\n        for root, sub_folder, file_list in os.walk(data_dir):\r\n            if root < truncate_path:\r\n                self.image_names += [os.path.join(root, file_path) for file_path in file_list]\r\n        random.shuffle(self.image_names)\r\n        self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\r\n\r\n    @property\r\n    def size(self):\r\n        return len(self.labels)\r\n\r\n    @staticmethod\r\n    def data_augmentation(images):\r\n        if FLAGS.random_flip_up_down:\r\n            images = tf.image.random_flip_up_down(images)\r\n        if FLAGS.random_brightness:\r\n            images = tf.image.random_brightness(images, max_delta=0.3)\r\n        if FLAGS.random_contrast:\r\n            images = tf.image.random_contrast(images, 0.8, 1.2)\r\n        return images\r\n\r\n    def input_pipeline(self, batch_size, num_epochs=None, aug=False):\r\n        images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\r\n        labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\r\n        input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\r\n\r\n        labels = input_queue[1]\r\n        images_content = tf.read_file(input_queue[0])\r\n        images = tf.image.convert_image_dtype(tf.image.decode_png(images_content, channels=1), tf.float32)\r\n        if aug:\r\n            images = self.data_augmentation(images)\r\n        new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\r\n        images = tf.image.resize_images(images, new_size)\r\n        image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=50000,\r\n                                                          min_after_dequeue=10000)\r\n        # print 'image_batch', image_batch.get_shape()\r\n        return image_batch, label_batch\r\n\r\n\r\ndef build_graph(top_k):\r\n    keep_prob = tf.placeholder(dtype=tf.float32, shape=[], name='keep_prob')\r\n    images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1], name='image_batch')\r\n    labels = tf.placeholder(dtype=tf.int64, shape=[None], name='label_batch')\r\n\r\n    conv3_1 = slim.conv2d(images, 64, [3, 3], 1, padding='SAME', scope='conv3_1')\r\n    max_pool_1 = slim.max_pool2d(conv3_1, [2, 2], [2, 2], padding='SAME')\r\n    conv3_2 = slim.conv2d(max_pool_1, 128, [3, 3], padding='SAME', scope='conv3_2')\r\n    max_pool_2 = slim.max_pool2d(conv3_2, [2, 2], [2, 2], padding='SAME')\r\n    conv3_3 = slim.conv2d(max_pool_2, 256, [3, 3], padding='SAME', scope='conv3_3')\r\n    max_pool_3 = slim.max_pool2d(conv3_3, [2, 2], [2, 2], padding='SAME')\r\n    # conv3_4 = slim.conv2d(max_pool_3, 512, [3, 3], padding='SAME', scope='conv3_4')\r\n    # max_pool_4 = slim.max_pool2d(conv3_4, [2, 2], [2, 2], padding='SAME')\r\n\r\n    flatten = slim.flatten(max_pool_3)\r\n    fc1 = slim.fully_connected(slim.dropout(flatten, keep_prob), 1024,\r\n    activation_fn=tf.nn.tanh, scope='fc1')\r\n    logits = slim.fully_connected(slim.dropout(fc1, keep_prob), FLAGS.charset_size,activation_fn=None, scope='fc2')\r\n    # logits = slim.fully_connected(flatten, FLAGS.charset_size, activation_fn=None, reuse=reuse, scope='fc')\r\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\r\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\r\n\r\n    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0.0), trainable=False)\r\n    rate = tf.train.exponential_decay(2e-4, global_step, decay_steps=2000, decay_rate=0.8, staircase=True)\r\n    train_op = tf.train.AdamOptimizer(learning_rate=rate).minimize(loss, global_step=global_step)\r\n    probabilities = tf.nn.softmax(logits)\r\n\r\n    tf.summary.scalar('loss', loss)\r\n    tf.summary.scalar('accuracy', accuracy)\r\n    merged_summary_op = tf.summary.merge_all()\r\n    predicted_val_top_k, predicted_index_top_k = tf.nn.top_k(probabilities, k=top_k)\r\n    accuracy_in_top_k = tf.reduce_mean(tf.cast(tf.nn.in_top_k(probabilities, labels, top_k), tf.float32))\r\n\r\n    return {'images': images,\r\n            'labels': labels,\r\n            'keep_prob': keep_prob,\r\n            'top_k': top_k,\r\n            'global_step': global_step,\r\n            'train_op': train_op,\r\n            'loss': loss,\r\n            'accuracy': accuracy,\r\n            'accuracy_top_k': accuracy_in_top_k,\r\n            'merged_summary_op': merged_summary_op,\r\n            'predicted_distribution': probabilities,\r\n            'predicted_index_top_k': predicted_index_top_k,\r\n            'predicted_val_top_k': predicted_val_top_k}\r\n\r\n\r\ndef train():\r\n    print('Begin training')\r\n    train_feeder = DataIterator(data_dir='../data/train/')\r\n    test_feeder = DataIterator(data_dir='../data/test/')\r\n    with tf.Session() as sess:\r\n        train_images, train_labels = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\r\n        test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\r\n        graph = build_graph(top_k=1)\r\n        sess.run(tf.global_variables_initializer())\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n        saver = tf.train.Saver()\r\n\r\n        train_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\r\n        test_writer = tf.summary.FileWriter(FLAGS.log_dir + '/val')\r\n        start_step = 0\r\n        if FLAGS.restore:\r\n            ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\r\n            if ckpt:\r\n                saver.restore(sess, ckpt)\r\n                print(\"restore from the checkpoint {0}\".format(ckpt))\r\n                start_step += int(ckpt.split('-')[-1])\r\n\r\n        logger.info(':::Training Start:::')\r\n        try:\r\n            i = 0\r\n            while not coord.should_stop():\r\n                i += 1\r\n                start_time = time.time()\r\n                train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\r\n                feed_dict = {graph['images']: train_images_batch,\r\n                             graph['labels']: train_labels_batch,\r\n                             graph['keep_prob']: 0.8}\r\n                _, loss_val, train_summary, step = sess.run(\r\n                    [graph['train_op'], graph['loss'], graph['merged_summary_op'], graph['global_step']],\r\n                    feed_dict=feed_dict)\r\n                train_writer.add_summary(train_summary, step)\r\n                end_time = time.time()\r\n                logger.info(\"the step {0} takes {1} loss {2}\".format(step, end_time - start_time, loss_val))\r\n                if step > FLAGS.max_steps:\r\n                    break\r\n                if step % FLAGS.eval_steps == 1:\r\n                    test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\r\n                    feed_dict = {graph['images']: test_images_batch,\r\n                                 graph['labels']: test_labels_batch,\r\n                                 graph['keep_prob']: 1.0}\r\n                    accuracy_test, test_summary, step = sess.run(\r\n                        [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\r\n                        feed_dict=feed_dict)\r\n                    test_writer.add_summary(test_summary, step)\r\n                    logger.info('===============Eval a batch=======================')\r\n                    logger.info('the step {0} test accuracy: {1}'\r\n                                .format(step, accuracy_test))\r\n                    logger.info('===============Eval a batch=======================')\r\n\r\n                    for tt in range(10):\r\n                        _, _, step = sess.run(\r\n                            [graph['accuracy'], graph['merged_summary_op'], graph['global_step']],\r\n                            feed_dict=feed_dict)\r\n                        logger.info('eval step again: step = {}'.format(step))\r\n\r\n\r\n                if step % FLAGS.save_steps == 1:\r\n                    logger.info('Save the ckpt of {0}'.format(step))\r\n                    saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'),\r\n                               global_step=graph['global_step'])\r\n        except tf.errors.OutOfRangeError:\r\n            logger.info('==================Train Finished================')\r\n            saver.save(sess, os.path.join(FLAGS.checkpoint_dir, 'my-model'), global_step=graph['global_step'])\r\n        finally:\r\n            coord.request_stop()\r\n        coord.join(threads)\r\n\r\n\r\n\r\ndef main(_):\r\n    print(FLAGS.mode)\r\n    if FLAGS.mode == \"train\":\r\n        train()\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n\r\n```\r\nJust focus on the block after `if step % FLAGS.eval_steps == 1:`  It is all right\uff08the step shouldn't  add one\uff09 to run on CPU(add line `with tf.device(\"/cpu:0\")`  after`with tf.Session() as sess:` ) , But as show the below image, it will add one when we use GPU:\r\nOn CPU:\r\n![image](https://cloud.githubusercontent.com/assets/3112825/23053809/dcc5d930-f516-11e6-8797-6701370c4da3.png)\r\n\r\nOn GPU:\r\n![image](https://cloud.githubusercontent.com/assets/3112825/23053823/ee505298-f516-11e6-8b92-954b3da4d34f.png)\r\n\r\nIt's very strange for me! And I try to reproduce it on MNIST but i seem to be all right both On CPU and GPU.\r\n\r\nAnyone could help me with  it ?\r\nIf you want to run the code just download the dataset from the url [data download](https://pan.baidu.com/s/1o84jIrg#list/path=%2F) \r\n", "comments": ["Hi, this list is for bugs in TensorFlow itself, and it's not clear that this is the case here, could you ask on stackoverflow?", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 7608, "title": "Branch 147800865", "body": "", "comments": ["it looks like we will never have a green build :("]}, {"number": 7607, "title": "Update text_classification.py", "body": "Adding  x_transform_train = vocab_processor.fit_transform(x_train),   x_transform_test = vocab_processor.transform(x_test) so that it would be easy for programmers to understand", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 7606, "title": "Update random_forest_mnist.py", "body": "Calling x and y outside once, it will be clean and helpful for the programmers to understand quickly, x = mnist.train.images and y = mnist.train.labels has been called multiple times instead calling those once with the variable x and y assigned would be helpful for programmers", "comments": ["Can one of the admins verify this patch?", "Sorry made a mistake"]}, {"number": 7605, "title": "Add missing typename to fix Windows build", "body": "#7592 \r\n", "comments": ["Can one of the admins verify this patch?", "It has been fixed internally"]}, {"number": 7604, "title": "the use of MultiRNNCell?", "body": "doc is in https://www.tensorflow.org/tutorials/recurrent\r\n\r\nI found the line\r\nstacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm] * number_of_layers,\r\n\r\nI need to use MultiRNNCell\r\n\r\nbut,I write those lines\r\n\r\na = [tf.nn.rnn_cell.BasicLSTMCell(10)]*3\r\n\r\nprint id(a[0]), id(a[1])\r\n\r\nIts output is 4648063696 4648063696\r\n\r\ncan MultiRNNCell use the same object BasicLSTMCell as a list for parameter?\r\n", "comments": ["> can MultiRNNCell use the same object BasicLSTMCell as a list for parameter?\r\n\r\nYes, you'll get separate trainable weights by repeating the list like you're doing. It's a bit confusing to be honest. You should have asked this [here](https://groups.google.com/forum/#!forum/tensorflow) or on StackOverflow though.", "@ebrevdo, do you think we should change the docs in some way to make it clearer?\r\n", "This is indeed confusing and hopefully next week we'll have a push (over a\nmonth in the making) that disallows this behavior.  It's a bit out of scope\nof this bug to describe why this behavior is the way it is, but it's been\nthe TF standard for a long time.  But after this change, you'll have to\nwrite:\n\nMultiRNNCell([BasicLSTMCell(10) for _ in range(3)])\n\notherwise you will get an error when calling dynamic_rnn.\n\nWith this version of the code, you end up creating 3 separate BasicLSTMCell\ninstances, each of which expects to maintain its own parameters.\n\nOn Fri, Feb 17, 2017 at 3:04 PM, Andrew Selle <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo>, do you think we should change the\n> docs in some way to make it clearer?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7604#issuecomment-280790625>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim34fMLpVWgZprthmv-Wuv274ysr3ks5rdidxgaJpZM4MD1hN>\n> .\n>\n", "thank you very much ~", "Don't forget to close your issue @liuyichaosoftware. \ud83d\udc4d ", "Tensorflow 0.9 to 1.0.1 is a big jump. A lot changed. \r\nDetails: https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md \r\n\r\nIn tf 1.0.0, the API has been changed such as:\r\n\r\ntf.nn.seq2seq.sequence_loss_by_example\r\nto\r\ntf.contrib.legacy_seq2seq.sequence_loss_by_example\r\n\r\ntf.nn.rnn_cell.\r\nto\r\ntf.contrib.rnn.\r\n\r\ntf.nn.rnn_cell.MultiRNNCell(\r\nto\r\ntf.contrib.rnn.MultiRNNCell(\r\n\r\n...\r\n", "How to find the API map between the old and new version @tifoit "]}, {"number": 7603, "title": "fix typo", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 7602, "title": "Error importing TensorFlow in Jupyter Notebook", "body": "I am unable to import TensorFlow in Jupyter Notebook. I have attached the error log at the end of the post. I am able to import the CPU Version of the TensorFlow with no issue. I am also able to import TensorFlow in Python Console launched from Terminal. The path to python executable is same in both Console and Jupyter Notebook (`sys.executable` gave the output as `/Users/Aakaash/miniconda3/bin/python` for both).\r\n\r\n## EDIT:\r\nI installed [JupyterLab](https://github.com/jupyterlab/jupyterlab) and to my surprise, TensorFlow imports with no errors when I open the ipynb file in JupyterLab. The problem arises only when I open the ipynb file with Jupyter Notebook.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nI posted a question on StackOverflow and I was told to file an issue on GitHub.\r\n\r\nhttp://stackoverflow.com/questions/42273323/error-importing-tensorflow-gpu-in-jupyter-notebook?noredirect=1#comment71720944_42273323\r\n\r\n### Environment info\r\nOperating System: MacOS Sierra 10.12.3\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n````\r\nlrwxr-xr-x  1 root     wheel        33 Feb 16 15:34 /usr/local/cuda/lib/libcuda.1.dylib -> /usr/local/cuda/lib/libcuda.dylib\r\n-rwxr-xr-x  1 root     wheel     13504 Jan 25 01:28 /usr/local/cuda/lib/libcuda.dylib\r\nlrwxr-xr-x@ 1 root     wheel        45 Nov  4 00:10 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a\r\nlrwxr-xr-x@ 1 root     wheel        50 Nov  4 00:10 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib\r\nlrwxr-xr-x@ 1 root     wheel        46 Nov  4 00:10 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib\r\nlrwxr-xr-x@ 1 root     wheel        49 Nov  4 00:10 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a\r\n-rwxr-xr-x@ 1 Aakaash  staff  82210088 Nov  7 13:28 /usr/local/cuda/lib/libcudnn.5.dylib\r\nlrwxr-xr-x@ 1 Aakaash  staff        16 Nov  7 13:49 /usr/local/cuda/lib/libcudnn.dylib -> libcudnn.5.dylib\r\n-rw-r--r--@ 1 Aakaash  staff  66197088 Nov  7 13:28 /usr/local/cuda/lib/libcudnn_static.a\r\n````\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\nI used `pip install tensorflow-gpu`\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\r\n````\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.8.0.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.5.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.8.0.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.8.0.dylib locally\r\n1.0.0\r\n````\r\n\r\n### Logs or other output that would be helpful\r\n````\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/__init__.py in <module>()\r\n     60     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)\r\n---> 61     from tensorflow.python import pywrap_tensorflow\r\n     62     sys.setdlopenflags(_default_dlopen_flags)\r\n\r\n/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n     25             finally:\r\n\r\n/Users/Aakaash/miniconda3/lib/python3.5/imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n/Users/Aakaash/miniconda3/lib/python3.5/imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: dlopen(/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib\r\n  Referenced from: /Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n  Reason: image not found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-a649b509054f> in <module>()\r\n----> 1 import tensorflow\r\n\r\n/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\n/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/__init__.py in <module>()\r\n     70 for some common reasons and solutions.  Include the entire stack trace\r\n     71 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 72   raise ImportError(msg)\r\n     73 \r\n     74 # Protocol buffers\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n  File \"/Users/Aakaash/miniconda3/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Users/Aakaash/miniconda3/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib\r\n  Referenced from: /Users/Aakaash/miniconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n  Reason: image not found\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n````", "comments": ["Could you run `env | grep LD_LIBRARY_PATH` in your terminal and share the output?", "@carlthome It does not return any output when I run that in the terminal.", "Then TensorFlow is unable to find your CUDA install, most likely. Try adding\r\n```\r\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/lib\"\r\n```\r\nto ~/.bashrc and open a new terminal and try `python -c 'import tensorflow'` and see if it finds CUDA.\r\n\r\nI'm assuming you're using Ubuntu or Debian, and that you've installed CUDA at its default location.\r\n\r\nSemi-related: https://github.com/tensorflow/tensorflow/issues/2626", "I am using Mac OS and it worked. I had done `export DYLD_LIBRARY_PATH=\"$DYLD_LIBRARY_PATH:/usr/local/cuda/lib$DYLD_LIBRARY_PATH` following the CuDNN Install Guide provided by Nvidia. I guess that does not work.\r\n\r\nThank you so much for the help!", "Cool. Have fun building computational graphs! :smile:  Don't forget to close the issue.", "Thank you! Closing the issue now."]}, {"number": 7601, "title": "make tf_upgrade.py more useful", "body": "When we upgrade tf code to version 1.0.0 in a directory tree, some times we also want to copy all the other files from `--intree` to the `--outtree`\uff0cthis makes it easier to upgrade an entire project.\r\n\r\nSo I add an option named `--copyotherfiles` in `tf_upgrade.py`. Hopefully useful!\r\n\r\n```\r\n# just upgrade the .py files\r\ntf_upgrade.py --intree coolcode --outtree coolcode-upgraded\r\n# after upgrade the .py files, then copy all the other files to the outtree\r\ntf_upgrade.py --intree coolcode --outtree coolcode-upgraded --copyotherfiles True\r\n```", "comments": ["Can one of the admins verify this patch?", "gentle ping @aselle", "Thanks for the patch @primetang, LGTM", "@tensorflow-jenkins Test this please.", "Jenkins, test this please", "Jenkins, test this please"]}]