[{"number": 36434, "title": "Improve TensorRT binding index query", "body": "This PR improves the TensorRT binding index query in a way that makes it compatible with optimization profiles. \r\n\r\nCurrently profiles are not used in TF-TRT, therefore this PR does not change any existing behavior. It is just a preparatory step to implement dynamic shapes with profiles. \r\n\r\nTensorRT bindings are an array of pointers to input and output buffers for the network.\r\nTo [execute TensorRT inference](https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/c_api/classnvinfer1_1_1_i_execution_context.html#a84436f784eb3f0ea9089de2678d77954) we have to specify the bindings.\r\n\r\nTo specify the pointers for the bindings, we have to query the binding index for each input and output tensor, and fill the data pointer in the bindings array at the correct location specified by the binding index.\r\n\r\nSince TensorRT 6, an engine can have a optimization profiles, and each profile has it's own set of [bindings](https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/c_api/classnvinfer1_1_1_i_cuda_engine.html#ac78a69ff4fba78c61c90894b74c0826c). This PR make binding index query compatible with multiple optimization profiles.", "comments": []}, {"number": 36433, "title": "No session factory registered for the given session options", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.1.0\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.29.1\r\n- GCC/Compiler version (if compiling from source): g++ 7.4.0\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have built TF from source ([link](https://www.tensorflow.org/install/source)). I have trained a DNN in python, frozen it as a .pb file, and now I would like to load the model and perform the evaluation in m my C++ code ([Gist here](https://gist.github.com/nicolastonon/d03605315f00228ace0a3c2a2621feda)). \r\n\r\nHowever I get a segfault already when trying to create a session : \r\n\r\n```\r\n2020-02-03 11:55:25.001775: E tensorflow/core/common_runtime/session.cc:89] Not found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.\r\nerror while creating session: Not found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.\r\n```\r\n\r\nThere have been similar issues (e.g. #3308), for which the proposed solution is to add the `-Wl,--whole-archive` flag when linking the TF libraries ; however this does not seem to work for me.\r\n\r\nDoes anybody have an idea what I could be doing wrong ?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1) Build TF from source\r\n\r\n2) Compile (successfully) a custom C++ code creating a Session, linking the TF libraries with the relevant option (e.g : `-L/home/ntonon/Documents/Programmes/tensorflow/bazel-bin/tensorflow -Wl,--whole-archive -Wl,--no-as-needed -ltensorflow_framework`)\r\n\r\n3) Running the code gives the error cited above.\r\n\r\nThanks in advance.\r\n", "comments": ["Hi, Have you solved this problem?\r\n\r\nIt has been troubling me for quite a long time until I add a header file in the source cpp in which the main function is compiled.\r\n\r\nYou can try to add \"tensorflow/cc/client/client_session.h\" in your entrance source file.\r\n\r\nThough It has solved this problem, but I still don't know why.", "Hi, yes I managed to solve it, unfortunately I tried so many things I don't remember what helped.\r\nI now link as such (probably an overkill): \r\n`LFLAGS+= -L/home/mypath/tensorflow/bazel-bin/tensorflow -Wl,--allow-multiple-definition -Wl,--whole-archive -ltensorflow_framework -Wl,--whole-archive -Wl,--no-as-needed -ltensorflow_cc #-lprotobuf`\r\n\r\nI think what caused the issue for some reason was this : \r\n`session = tensorflow::createSession((tensorflow::GraphDef*) graphDef);`\r\n\r\nwhich I replaced by manual calls to functions: \r\n`tensorflow::Status status;\r\ntensorflow::SessionOptions sessionOptions;\r\nstatus = NewSession(sessionOptions, &session);\r\nstatus = session->Create(*graphDef);`", "@nicolastonon \r\nI can't find tensorflow_cc library , where is it?"]}, {"number": 36432, "title": "Error when importing tensorflow 2", "body": "Have pip installed tensorflow on my windows. \r\nWhen i try and import it, i get this error message.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: module not found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 6, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\vegar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: module not found\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["@VegardIversen,\r\nCould you please check [this](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) comment on a similar issue and let us know if it helps. Thanks!", "Hi @VegardIversen \r\nFirst install the Microsoft Visual C++ \r\nFrom here : [Microsoft Visual C++](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\nAnd then try to install it again.\r\nThank you", "@VegardIversen,\r\nAny updates regarding this issue? Thanks!", "@amahendrakar Worked when I installed MSVC 2019 redistributable.", "Closing the issue as it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36432\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36432\">No</a>\n", "I have the exact same problem but it didn't work just by installing VS code.... Any other suggestions @amahendrakar ?\r\n\r\nThanks", "Are you sure you have downloaded the correct version. Here is the link I used. https://support.microsoft.com/nb-no/help/2977003/the-latest-supported-visual-c-downloads", "I did! Only Visual Studio Code or the whole IDE package?", "Only this: x64: vc_redist.x64.exe (for 64 bit) via the link i sent\r\n", "Thanks! This solved the problem"]}, {"number": 36431, "title": "TensorFlow2.x should support group convolutions in keras api level.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nGroup convolution has been widely used in various deep learning models, such as ResNeXt(https://arxiv.org/abs/1611.05431). PyTorch has already supported group convolution, while TensorFlow has not. As this issue(https://github.com/tensorflow/tensorflow/issues/34024) says, ```tf.nn.conv2d() ``` supports group convolution on GPU, but not on CPU. Therefore, A keras layer api which supports group convolution is needed for many users. This is a sample code which supports the feature by modifying the keras ```Conv2D``` api:\r\n```\r\nclass Conv2D(tf.keras.layers.Layer):\r\n    def __init__(self,\r\n                 input_channels,\r\n                 output_channels,\r\n                 kernel_size,\r\n                 strides=(1, 1),\r\n                 padding='valid',\r\n                 data_format=None,\r\n                 dilation_rate=(1, 1),\r\n                 activation=None,\r\n                 groups=1,\r\n                 use_bias=True,\r\n                 kernel_initializer='glorot_uniform',\r\n                 bias_initializer='zeros',\r\n                 kernel_regularizer=None,\r\n                 bias_regularizer=None,\r\n                 activity_regularizer=None,\r\n                 kernel_constraint=None,\r\n                 bias_constraint=None,\r\n                 **kwargs):\r\n        super(Conv2D, self).__init__()\r\n\r\n        if not input_channels % groups == 0:\r\n            raise ValueError(\"The value of input_channels must be divisible by the value of groups.\")\r\n        if not output_channels % groups == 0:\r\n            raise ValueError(\"The value of output_channels must be divisible by the value of groups.\")\r\n\r\n        self.kernel_size = kernel_size\r\n        self.strides = strides\r\n        self.padding = padding\r\n        self.data_format = data_format\r\n        self.dilation_rate = dilation_rate\r\n        self.activation = activation\r\n        self.groups = groups\r\n        self.use_bias = use_bias\r\n        self.kernel_initializer = kernel_initializer\r\n        self.bias_initializer = bias_initializer\r\n        self.kernel_regularizer = kernel_regularizer\r\n        self.bias_regularizer = bias_regularizer\r\n        self.activity_regularizer = activity_regularizer\r\n        self.kernel_constraint = kernel_constraint\r\n        self.bias_constraint = bias_constraint\r\n\r\n        self.group_in_num = input_channels // groups\r\n        self.group_out_num = output_channels // groups\r\n        self.conv_list = []\r\n        for i in range(self.groups):\r\n            self.conv_list.append(tf.keras.layers.Conv2D(filters=self.group_out_num,\r\n                                                         kernel_size=kernel_size,\r\n                                                         strides=strides,\r\n                                                         padding=padding,\r\n                                                         data_format=data_format,\r\n                                                         dilation_rate=dilation_rate,\r\n                                                         activation=activations.get(activation),\r\n                                                         use_bias=use_bias,\r\n                                                         kernel_initializer=initializers.get(kernel_initializer),\r\n                                                         bias_initializer=initializers.get(bias_initializer),\r\n                                                         kernel_regularizer=regularizers.get(kernel_regularizer),\r\n                                                         bias_regularizer=regularizers.get(bias_regularizer),\r\n                                                         activity_regularizer=regularizers.get(activity_regularizer),\r\n                                                         kernel_constraint=constraints.get(kernel_constraint),\r\n                                                         bias_constraint=constraints.get(bias_constraint),\r\n                                                         **kwargs))\r\n\r\n    def call(self, inputs, **kwargs):\r\n        feature_map_list = []\r\n        for i in range(self.groups):\r\n            x_i = self.conv_list[i](inputs[:, :, :, i*self.group_in_num: (i + 1) * self.group_in_num])\r\n            feature_map_list.append(x_i)\r\n        out = tf.concat(feature_map_list, axis=-1)\r\n        return out\r\n```\r\n\r\n**Will this change the current api? How?**\r\nThis will change the current keras convolution api . \r\n\r\n**Who will benefit with this feature?**\r\nAnyone who need to use group conolution in their code will benefit.\r\n\r\n**Any Other info.**\r\n", "comments": ["This was discussed in https://github.com/keras-team/governance/pull/16.\r\n\r\nI made a PR #36773 to implement this a few weeks ago.\r\n@tanzhenyu @ymodak it would be really cool to get a review on it.", "> \r\n> \r\n> This was discussed in [keras-team/governance#16](https://github.com/keras-team/governance/pull/16).\r\n> \r\n> I made a PR #36773 to implement this a few weeks ago.\r\n> @tanzhenyu @ymodak it would be really cool to get a review on it.\r\n\r\nThanks for your PR."]}, {"number": 36430, "title": "Bugs padding on Tensorflow Lite Converter", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, GPU GTX 1660\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (or github SHA if from source): 2.1.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\nimport torch\r\nimport torch.nn.functional as F\r\nfrom torch.nn.utils import weight_norm\r\nimport torch.nn as nn\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nimport time\r\n\r\n# tf.compat.v1.disable_eager_execution()\r\n\r\nclass TFReflectionPad1d(tf.keras.layers.Layer):\r\n    def __init__(self, padding_size):\r\n        super(TFReflectionPad1d, self).__init__()\r\n        self.padding_size = padding_size\r\n    \r\n    def call(self, x):\r\n        return tf.pad(x, [[0,0],[self.padding_size,self.padding_size],[0,0]], \"REFLECT\")\r\n    \r\n\r\nclass TFUpsampleConv1d(tf.keras.layers.Layer):\r\n    def __init__(self, upsample_factor, filters, kernel_size,\r\n                 padding='same'):\r\n        super(TFUpsampleConv1d, self).__init__()\r\n        self.upsample1d = tf.keras.layers.UpSampling1D(size=upsample_factor)\r\n        self.conv1d = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding=padding)\r\n    \r\n    def call(self, x):\r\n        x = self.upsample1d(x)\r\n        return self.conv1d(x)\r\n    \r\n    \r\nclass TFResnetBlock(tf.keras.layers.Layer):\r\n    def __init__(self, dim, dilation=1):\r\n        super(TFResnetBlock, self).__init__()\r\n        self.block = [\r\n            tf.keras.layers.LeakyReLU(0.2),\r\n            TFReflectionPad1d(dilation),\r\n            tf.keras.layers.Conv1D(filters=dim, kernel_size=3, dilation_rate=dilation),\r\n            tf.keras.layers.LeakyReLU(0.2),\r\n            tf.keras.layers.Conv1D(filters=dim, kernel_size=1),\r\n        ]\r\n        self.shortcut = tf.keras.layers.Conv1D(filters=dim, kernel_size=1)\r\n    \r\n    def call(self, x):\r\n        _x = tf.identity(x)\r\n        for layer in self.block:\r\n            _x = layer(_x)\r\n        return self.shortcut(x) + _x\r\n\r\nclass TFMelGANGenerator(tf.keras.layers.Layer):\r\n    def __init__(self, ngf, n_residual_layers):\r\n        super(TFMelGANGenerator, self).__init__()\r\n        ratios = [8,8,2,2]\r\n        self.hop_length = np.prod(ratios)\r\n        mult = int(2 ** len(ratios))\r\n        \r\n        model = [\r\n            TFReflectionPad1d(3),\r\n            tf.keras.layers.Conv1D(filters=mult * ngf, kernel_size=7, padding='valid')\r\n        ]\r\n        \r\n        for i, r in enumerate(ratios):\r\n            model += [\r\n                tf.keras.layers.LeakyReLU(0.2),\r\n                TFUpsampleConv1d(\r\n                    upsample_factor=r,\r\n                    filters=mult * ngf // 2,\r\n                    kernel_size=r * 2 - 1,\r\n                    padding='same'\r\n                )\r\n            ]\r\n            \r\n            for j in range(n_residual_layers):\r\n                model += [TFResnetBlock(dim=mult * ngf // 2, dilation=3 ** j)]\r\n            \r\n            mult //= 2\r\n\r\n        model += [\r\n            tf.keras.layers.LeakyReLU(0.2),\r\n            TFReflectionPad1d(3),\r\n            tf.keras.layers.Conv1D(filters=1, kernel_size=7, padding='valid'),\r\n            tf.keras.layers.Activation('tanh')\r\n        ]\r\n        self.model = tf.keras.models.Sequential(model)\r\n    \r\n    def call(self, x):\r\n        return self.model(x)\r\n\r\ninputs = tf.keras.Input(shape=[241, 80], dtype=tf.float32)\r\naudio = TFMelGANGenerator(ngf=32, n_residual_layers=3)(inputs)\r\ntf_melgan = tf.keras.models.Model(inputs, audio)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(tf_melgan)\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.post_training_quantize = True\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n```\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-58-d738e01cc59a> in <module>()\r\n      3 converter.post_training_quantize = True\r\n      4 #converter.experimental_new_converter = True\r\n----> 5 tflite_model = converter.convert()\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    198       stdout = _try_convert_to_unicode(stdout)\r\n    199       stderr = _try_convert_to_unicode(stderr)\r\n--> 200       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    201   finally:\r\n    202     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-02-03 06:48:15.223818: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 303 operators, 48921 arrays (0 quantized)\r\n2020-02-03 06:48:17.886590: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 303 operators, 48921 arrays (0 quantized)\r\n2020-02-03 06:48:18.761673: I tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc:202] Replaced sub-network with Dilated Conv2D op outputting \"model_4/tf_mel_gan_generator_4/sequential_4/tf_resnet_block_41/conv1d_149/conv1d\".\r\n2020-02-03 06:48:18.783229: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:118] Check failed: dim_x == dim_y (1928 vs. 1934)Dimensions must match\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f7e2a8b8780 (most recent call first):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299 in run\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"/usr/local/bin/toco_from_protos\", line 8 in <module>\r\nAborted (core dumped)\r\n\r\n```", "comments": ["Hi, the bug happened when audio = TFMelGANGenerator(ngf=32, n_residual_layers=3)(inputs). But when n_residual_layers=1, it's still ok to convert. So i guess that there is a problem with dilation or tf.pad", "@jvishnuvardhan any update?\r\n", "@dathudeptrai I think this was resolved in recent `tf-nightly`. Can you please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/f734059f02e2d2aad44327775e0f8686/36430.ipynb). When I ran your code with `tf-nightly`, I cannot reproduce the error. \r\n\r\nPlease run yourself and let us know whether it resolved for you or not. If it was resolved, please feel free to close the issue. thanks!", "Thanks, it fixed."]}, {"number": 36429, "title": "Allocation of 10616832 exceeds 10% of system memory.", "body": "Hi. I'm currently having some problems after running the Object_detection.py like:\r\n\r\n2020-02-01 11:57:36.437688: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 10616832 exceeds 10% of system memory.\r\nKilled\r\n\r\nMy device is **Raspberry Pi 3 B+**.\r\nTensorflow Version: **1.14.0**\r\nPython Version: **Python 3.7.3**\r\nGPU: **128**\r\nCurrently using: **faster_rcnn_inception_v2_coco_2018_01_28**\r\n\r\nCan anyone help me with this? I appreciate any response that can fix this problem.", "comments": ["@KoizumiNao This looks like a support issue. GitHub is mainly for Bugs and performance related issues. Your model might be big and cannot fit into the memory. Please post in stackoverflow and provide more details on your hardware. We will resolve it there. Thanks!\r\n\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 36428, "title": "Discrepancy between keras.layers.Reshape and tf.keras.layers.Reshape", "body": "```\r\ntf-version 2.1.0\r\nkeras-version 2.2.4-tf\r\n```\r\n\r\nIn Keras, according to [the documentation](https://keras.io/layers/core/), we expect:\r\n\r\n```python\r\nmodel.add(Reshape((-1, 2, 2)))\r\n# now: model.output_shape == (None, 3, 2, 2)\r\n```\r\n\r\nBut in tf.Keras [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape):\r\n\r\n```python\r\nmodel.add(Reshape((-1, 2, 2)))\r\n# now: model.output_shape == (None, None, 2, 2)\r\n```\r\n\r\nThe second dimension is now `None` instead of the computed value.\r\n\r\nThis makes tf.Keras incompatible with Keras, and makes it harder to write code that is parameterized by of the output shape of an opaque model. Is there a way to get the true output shape?", "comments": ["I could reproduce the issue. [Here is the gist](https://colab.research.google.com/gist/jvishnuvardhan/09cfb560b120cc9c83e93b9378f1ddf6/36428_keras.ipynb) with `keras==2.3.0` and [here is the gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/531ee39cf36accf688a40b4aac667e26/36428_tf.ipynb) with `tf-nightly`. The gists are for our reference. Thanks", "To answer my question, I found I could do `model.compute_output_shape(model.input_shape)`. At the least, this should be noted in the documentation I think.", "@rgov Are you interested in raising PR? Thanks!", "@rgov I have raised a PR. Can you please check whether the way I have used `model.compute_output_shape(model.input_shape)` is correct or not?", "This looks like an issue that needs to be resolved regardless of the keras/tf.keras merge", "This is an issue that happened in eager mode, seems the solution is:\r\n```python\r\nif not tf.executing_eagerly():\r\n      # Set the static shape for the result since it might lost during array_ops\r\n      # reshape, eg, some `None` dim in the result could be inferred.\r\n      result.set_shape(self.compute_output_shape(inputs.shape))\r\n    return result\r\n```\r\n\r\nWe made a commit which was reverted. Waiting for another commit.", "@tanzhenyu Do you have an estimate of when this issue will be resolved?  Is there anything the community can do to help?", "> @tanzhenyu Do you have an estimate of when this issue will be resolved? Is there anything the community can do to help?\r\n\r\nCan you try tf-nightly? There are quite some fix updates on this issue", "@rgov This is resolved in recent `tf-nightly`. [Here](https://colab.research.google.com/gist/jvishnuvardhan/3dc0d61293107949485267d03ebf113c/36428_tf.ipynb) is the gist for your reference. \r\n\r\nI am closing this issue as this was resolved already. Please feel free to reopen if you notice any related issue. thanks!"]}, {"number": 36427, "title": "HadoopFileSystem load error", "body": "this is a build/installation issue.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n```\r\n$ cat /proc/cpuinfo\r\nprocessor\t: 0\r\nmodel name\t: ARMv6-compatible processor rev 7 (v6l)\r\nBogoMIPS\t: 697.95\r\nFeatures\t: half thumb fastmult vfp edsp java tls \r\nCPU implementer\t: 0x41\r\nCPU architecture: 7\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xb76\r\nCPU revision\t: 7\r\n\r\nHardware\t: BCM2835\r\nRevision\t: 0010\r\nSerial\t\t: 00000000\r\nModel\t\t: Raspberry Pi Model B Plus Rev 1.2\r\n$ \r\n```\r\n\r\n```\r\n$ uname -a\r\nLinux raspbari1 4.19.97+ #1293 Wed Jan 22 17:05:40 GMT 2020 armv6l GNU/Linux\r\n```\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nn/a\r\n\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n```\r\nInstalling collected packages: tensorflow-estimator, protobuf, h5py, keras-applications, astor, termcolor, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, absl-py, grpcio, markdown, tensorboard, gast, google-pasta, opt-einsum, wrapt, keras-preprocessing, tensorflow\r\nSuccessfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 opt-einsum-3.1.0 protobuf-3.11.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.0 tensorboard-2.0.2 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.11.2\r\n\r\n```\r\n- Python version:\r\n```\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\n\r\n```\r\n- Installed using virtualenv? pip? conda?:\r\n`python3 -m pip install tensorflow`\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nn/a\r\n- GPU model and memory:\r\nn/a\r\n\r\n**Describe the problem**\r\n`2020-02-02 15:11:00.880396: E tensorflow/core/platform/hadoop/hadoop_file_system.cc:132] HadoopFileSystem load error: libhdfs.so: cannot open shared object file: No such file or directory`\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\n$ python3\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Duplicates #36141, hence closing. Please make sure in the future to search for similar issues.", "I don't have any explicit need for Hadoop. Does your package need Hadoop _libraries_? If so please update your documentation accordingly.\r\n\r\nKind regards."]}, {"number": 36426, "title": "Error:55: Could not load dynamic library 'libcudnn.so.7", "body": "**System information**\r\n- Operating System: 18.04.4 LTS\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.9\r\n- Installed using: virtualenv, and then pip in order to build the wheel as mentionned in the source installation\r\n- Bazel version: bazel-1.2.1 as mentionned in my configure.py file. No other version was possible\r\n- GCC/Compiler: 7.4.0\r\n- CUDA: 10.2.89\r\n- cuDNN: 7.6.5\r\n- GPU model and memory: GeForce RTX 2070, 8 Gb\r\n- NVIDIA-SMI: 440.33.01\r\n- Driver Version: NVIDIA-SMI 440.33.01\r\n\r\n**Describe the problem**\r\nI have followed carefully the installation guide of cuDNN, and tensorflow from source, didn't get any error during the installation, but when I call` tf.test.is_gpu_available()` I get one signle error which is: \r\n`Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory`\r\nI have looked at the posts already dealing with this question, tried there answers, but nothing changes. I have tried: \r\n- `export LD_LIBRARY_PATH=/usr/local/cuda/lib64/` from [this post](https://github.com/tensorflow/tensorflow/issues/4827)\r\n- ` sudo sh -c \"echo '/usr/local/cuda/lib64\\n/usr/local/cuda/lib >> /etc/ld.so.conf.d/nvidia.conf\"`\r\n   `sudo ldconfig` from [here](https://github.com/tensorflow/tensorflow/issues/8898)\r\n- `export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH`\r\n  `export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH` from [here](https://github.com/tensorflow/tensorflow/issues/20271)\r\nAfter rebooting each time, I still get the error mentioned above.\r\n- I have also verified where is the libcudnn.so.7  in the root file and it is in: \r\n`/usr/local/cuda-10.2/targets/x86_64-linux/lib`\r\nand important, also in `/usr/local/cuda-10.2/targets/x86_64-linux/lib` there is a file called: \r\n`libcudnn.so.7.6.5 `\r\n\r\nPlease consider that I am not a very experienced Programmer.\r\nAny help would be extremely appreciated. Thank you for your time. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nActivating my virtual environment, in Python (I have checked that the interpreter is indeed the one in my virtualenv): \r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\ntf.test.is_gpu_available()\r\n```\r\n\r\n**Any other info / logs**\r\nThe entire error I get calling` tf.test.is_gpu_available()` is \r\n```\r\n2020-02-02 20:22:17.488097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 3493375000 Hz\r\n2020-02-02 20:22:17.489597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbde003fa20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-02 20:22:17.489647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-02-02 20:22:17.492686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-02-02 20:22:17.598433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3d91ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-02-02 20:22:17.598490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5\r\n2020-02-02 20:22:17.599531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce RTX 2070 computeCapability: 7.5\r\ncoreClock: 1.815GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-02-02 20:22:17.599953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-02 20:22:17.601575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-02 20:22:17.603388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-02 20:22:17.603663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-02 20:22:17.605504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-02 20:22:17.606545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n\"\"ERROR IS HERE\"\"\r\n2020-02-02 20:22:17.606679: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\r\n\"\"DON'T KNOW IF THIS IS AN ERROR FROM THE PREVIOUS ONE\"\"\r\n2020-02-02 20:22:17.606693: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1595] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-02-02 20:22:17.606721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-02 20:22:17.606729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 \r\n2020-02-02 20:22:17.606736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N \r\n```\r\n", "comments": ["TF 2.1 supports cuda 10.1. Please roll back to cuda 10.1.\r\nSee https://www.tensorflow.org/install/gpu#software_requirements", "@ymodak - I am using cuda 10.1 but no help", "It indeed worked for me, but it wasn't straight forward", "@Lip651 ,\r\nFeel free to close the issue if it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36426\">No</a>\n", "how to roll back cuda 10.1.?", "managed to fix it, my comment is here: https://github.com/tensorflow/tensorflow/issues/20271#issuecomment-622990424", "tensorflow 2.1 requires CUDA 10.1 from [here](https://www.tensorflow.org/install/source), it is better to downgrade you cuda toolkit. ", "Problem is:\r\n` Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory`\r\n\r\nSolution :\r\n1-) download related cudnn from [here](https://developer.nvidia.com/cudnn)\r\n2-) when you inside the extracted folder:\r\n\r\n```\r\n$ sudo cp include/cudnn.h /usr/local/cuda-10.2/include\r\n$ sudo cp lib64/libcudnn* /usr/local/cuda-10.2/lib64\r\n$ sudo chmod a+r /usr/local/cuda-10.2/lib64/libcudnn*\r\n```\r\nBE CAREFULL: Check your cuda installation. I mean im using cuda-10.0\r\nSo:\r\n```\r\n$ sudo cp include/cudnn.h /usr/local/cuda-10.0/include\r\n...\r\n```\r\n\r\n\r\n\r\n"]}, {"number": 36425, "title": "tf-lite update 3rd party repo script r2.1 branch ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux raspbian\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:na\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.1\r\n- Python version: na\r\n- Installed using virtualenv? pip? conda?: na\r\n- Bazel version (if compiling from source): na\r\n- GCC/Compiler version (if compiling from source):na\r\n- CUDA/cuDNN version: na\r\n- GPU model and memory: na\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe update 3rd party repository script craps out because it can't find the EIGEN url. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n./tensorflow/lite/tools/make/download_dependencies.sh\r\n\r\n**Any other info / logs** \r\nIt is fixed in HEAD but wasn't backported to the release branch. \r\n\r\npatch: \r\n[TF-lite-url-patch.txt](https://github.com/tensorflow/tensorflow/files/4145276/TF-lite-url-patch.txt)\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36425\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36425\">No</a>\n"]}, {"number": 36424, "title": "TensorFlow Feature Columns Fail for Keras Model Functional API", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks 6.3- `Linux version 4.4.0-1100-aws (buildd@lgw01-amd64-030) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.12) ) #111-Ubuntu SMP Wed Dec 4 12:20:15 UTC 2019 (Ubuntu 4.4.0-1100.111-aws 4.4.203)`\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: \r\n```\r\n2020-02-02 17:40:54.646833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-02-02 17:40:54.648818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\nv2.1.0-rc2-17-ge5bf8de 2.1.0\r\n```\r\n- **Python version**: 3.7.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: GCC 7.3.0\r\n- **CUDA/cuDNN version**: 10.1\r\n- **GPU model and memory**: AWS p2.xlarge\r\n- **Exact command to reproduce**:\r\n```python\r\nsource_column = tf.feature_column.numeric_column(\"source_name\")\r\ncategorical_column = tf.feature_column.bucketized_column(source_column, [0, 10, 100])\r\nembedding_column = tf.feature_column.embedding_column(categorical_column, 7)\r\nfeature_columns = [ embedding_column ]\r\n\r\nname_schema = tf.feature_column.make_parse_example_spec(feature_columns)\r\ninputs = {\r\n  name: keras.layers.Input(shape=schema.shape, name=name, dtype=schema.dtype)\r\n  for name, schema in name_schema.items()\r\n}\r\n\r\ndense_features = keras.layers.DenseFeatures(feature_columns)\r\ncolumn_tensors = {}\r\ndense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)\r\n```\r\n\r\n### Describe the problem\r\n> Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI believe it should be possible to use Feature Columns with Keras Model Functional API.  Most feature columns work, however, it appears that some combinations of feature columns like the above embedding - bucketized - numeric columns fail.\r\n\r\nIt is not clear how to work around this error or apply the suggested wrapping.\r\n\r\n### Source code / logs\r\n> Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe above code fails with:\r\n```pytb\r\nValueError                                Traceback (most recent call last)\r\n<command-1166953> in <module>\r\n     12 dense_features = keras.layers.DenseFeatures(feature_columns)\r\n     13 column_tensors = {}\r\n---> 14 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    803               kwargs.pop('mask')\r\n    804             inputs, outputs = self._set_connectivity_metadata_(\r\n--> 805                 inputs, outputs, args, kwargs)\r\n    806           self._handle_activity_regularization(inputs, outputs)\r\n    807           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)\r\n   2012     # This updates the layer history of the output tensor(s).\r\n   2013     self._add_inbound_node(\r\n-> 2014         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\r\n   2015     return inputs, outputs\r\n   2016 \r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)\r\n   2042         input_tensors=input_tensors,\r\n   2043         output_tensors=output_tensors,\r\n-> 2044         arguments=arguments)\r\n   2045 \r\n   2046     # Update tensor history metadata.\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/node.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)\r\n    120       if base_layer_utils.needs_keras_history(\r\n    121           tensor_argument, ignore_call_context=True):\r\n--> 122         base_layer_utils.create_keras_history(tensor_argument)\r\n    123 \r\n    124     # Add nodes to all layers involved.\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)\r\n    185     keras_tensors: The Tensors found that came from a Keras Layer.\r\n    186   \"\"\"\r\n--> 187   _, created_layers = _create_keras_history_helper(tensors, set(), [])\r\n    188   return created_layers\r\n    189 \r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    247               constants[i] = backend.function([], op_input)([])\r\n    248       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 249           layer_inputs, processed_ops, created_layers)\r\n    250       name = op.name\r\n    251       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    247               constants[i] = backend.function([], op_input)([])\r\n    248       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 249           layer_inputs, processed_ops, created_layers)\r\n    250       name = op.name\r\n    251       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    247               constants[i] = backend.function([], op_input)([])\r\n    248       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 249           layer_inputs, processed_ops, created_layers)\r\n    250       name = op.name\r\n    251       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    247               constants[i] = backend.function([], op_input)([])\r\n    248       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 249           layer_inputs, processed_ops, created_layers)\r\n    250       name = op.name\r\n    251       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    247               constants[i] = backend.function([], op_input)([])\r\n    248       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 249           layer_inputs, processed_ops, created_layers)\r\n    250       name = op.name\r\n    251       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    221             'Sparse ops are not supported with functional models with built-in '\r\n    222             'layer wrapping. Please wrap the sparse ops in a Lambda layer like'\r\n--> 223             ': \\n{lambda_example}\\n'.format(lambda_example=lambda_example))\r\n    224 \r\n    225       # Recursively set `_keras_history`.\r\n\r\nValueError: Sparse ops are not supported with functional models with built-in layer wrapping. Please wrap the sparse ops in a Lambda layer like: \r\n\r\n        weights_mult = lambda x: tf.sparse.sparse_dense_matmul(x, weights)\r\n        output = tf.keras.layers.Lambda(weights_mult)(input)\r\n```", "comments": ["On Tensorflow 1.15, I get the following error:\r\n```pytb\r\nValueError                                Traceback (most recent call last)\r\n<command-1167185> in <module>\r\n     12 dense_features = keras.layers.DenseFeatures(feature_columns)\r\n     13 column_tensors = {}\r\n---> 14 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    879               kwargs.pop('mask')\r\n    880             inputs, outputs = self._set_connectivity_metadata_(\r\n--> 881                 inputs, outputs, args, kwargs)\r\n    882           self._handle_activity_regularization(inputs, outputs)\r\n    883           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)\r\n   2041     # This updates the layer history of the output tensor(s).\r\n   2042     self._add_inbound_node(\r\n-> 2043         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\r\n   2044     return inputs, outputs\r\n   2045 \r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)\r\n   2071         input_tensors=input_tensors,\r\n   2072         output_tensors=output_tensors,\r\n-> 2073         arguments=arguments)\r\n   2074 \r\n   2075     # Update tensor history metadata.\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/node.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)\r\n    120       if base_layer_utils.needs_keras_history(\r\n    121           tensor_argument, ignore_call_context=True):\r\n--> 122         base_layer_utils.create_keras_history(tensor_argument)\r\n    123 \r\n    124     # Add nodes to all layers involved.\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)\r\n    182     keras_tensors: The Tensors found that came from a Keras Layer.\r\n    183   \"\"\"\r\n--> 184   _, created_layers = _create_keras_history_helper(tensors, set(), [])\r\n    185   return created_layers\r\n    186 \r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n--> 231           layer_inputs, processed_ops, created_layers)\r\n    232       name = op.name\r\n    233       node_def = op.node_def.SerializeToString()\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    227           else:\r\n    228             with ops.init_scope():\r\n--> 229               constants[i] = backend.function([], op_input)([])\r\n    230       processed_ops, created_layers = _create_keras_history_helper(\r\n    231           layer_inputs, processed_ops, created_layers)\r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)\r\n   3642     return nest.pack_sequence_as(\r\n   3643         self._outputs_structure,\r\n-> 3644         [x._numpy() for x in outputs],  # pylint: disable=protected-access\r\n   3645         expand_composites=True)\r\n   3646 \r\n\r\n/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py in <listcomp>(.0)\r\n   3642     return nest.pack_sequence_as(\r\n   3643         self._outputs_structure,\r\n-> 3644         [x._numpy() for x in outputs],  # pylint: disable=protected-access\r\n   3645         expand_composites=True)\r\n   3646 \r\n\r\nValueError: Cannot convert a Tensor of dtype resource to a NumPy array.\r\n```", "Creating the `dense_tensor` with `tf.compat.v1.feature_column.input_layer` fails later when used.\r\n\r\nThe following code runs successfully.\r\n```python\r\ncolumn_tensors = {}\r\ndense_tensor = tf.compat.v1.feature_column.input_layer(\r\n  inputs,\r\n  feature_columns,\r\n  cols_to_output_tensors=column_tensors\r\n)\r\n```\r\n\r\nHowever, the same failure exists when the `dense_tensor` is used:\r\n```python\r\noutput_1 = keras.layers.Dense(64, activation='relu')(dense_tensor)\r\n```\r\n\r\nCan `feature_columns` be used with Keras models?", "@jeisinge Could you please refer tho this [link](https://github.com/tensorflow/docs/blob/b4d8d7096099c2b0a7df6a0564bf6eca8c96c4a0/site/en/tutorials/structured_data/feature_cols_keras.ipynb) , in case you are still unable to resolve the issue,\r\n\r\nCould you please provide us with simple standalone code to reproduce the issue in our environment, Thanks", "@Saduf2019 , I am a bit confused.  The referenced document is from 2018.  It refers to `tensorflow.python.feature_column.feature_column_v2.FeatureLayer`, which I don't think exists anymore.  A more recent document at https://www.tensorflow.org/tutorials/structured_data/feature_columns#create_a_feature_layer refers to `tf.keras.layers.DenseFeatures`, which I use.\r\n\r\nFor standalone code, I created a Google Colab at https://colab.research.google.com/drive/1DVfpU6EoEz5vkMqLxH7JTXHALpa3VoOs .  Is that what you were looking for? \r\n\r\nAlso, I believe it is important to note that this doesn't work on TensorFlow 2 _and_ TensorFlow 1.  I'll try to add the tag.", "@jeisinge I ran with `tf-nightly` and it did throw only deprecation warning and clearly mentioned to use new `feature_column` API. For example changing `tf.feature_column.numeric_column` to `feature_column.numeric_column`. Before that we need to import feature_column API as `from tensorflow import feature_column`. Please check the [tutorial](https://www.tensorflow.org/tutorials/structured_data/feature_columns) on TF website.\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/14728a5879f016c82e320b165ff64dc3/tensorflow-feature-columns-fail-for-keras-model-functional-api.ipynb) is gist for y/our reference. Thanks!\r\n\r\nPlease close the issue if it was resolved for you. Thanks!", "@jvishnuvardhan , I am not an expert in Python.  What is the difference between:\r\n```python\r\nimport tensorflow as tf\r\n\r\nsource_column = tf.feature_column.numeric_column(\"source_name\")\r\n...\r\n```\r\nand\r\n```python\r\nfrom tensorflow import feature_column\r\n\r\nsource_column = feature_column.numeric_column(\"source_name\")\r\n...\r\n```\r\n?\r\n\r\nAre you saying that this defect is fixed in the nightly build?  If so, were you able to reproduce in TF 2.1 or TF 1.15?", "I attempted to install tf-nightly in the colab notebook with `!pip install tf-nightly`.  It also failed.\r\n\r\nAlso, I did try the `from tensorflow import feature_column`.  That failed as well.", "@jeisinge did you try running my colab gist? Thanks!", "Yeah. It fails.\n\nOn Thu, Feb 20, 2020, 11:58 AM Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @jeisinge <https://github.com/jeisinge> did you try running my colab\n> gist? Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/36424?email_source=notifications&email_token=ACDUX2IORQSOELGNCEBTPMTRD3AC5A5CNFSM4KO3C5K2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMPOARI#issuecomment-589226053>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ACDUX2OEXALJPVVFT6WIYNDRD3AC5ANCNFSM4KO3C5KQ>\n> .\n>\n", "@jeisinge It is strange. my Colab gist should run without an issue. Can you please share the error you are facing? Are you running my gist as it is or did you modify anything? Are you running it in Chrome or any other browser? Still not sure what is the root-cause. Thanks!", "I reran the gist and it succeeded.  However, it appears to be on TF 1.15 due to a misspelling on _install_.   After upgrading to TF 2 or TF Nightly, it appears to fail on a rerun with the same error:\r\n```pycon\r\nValueError                                Traceback (most recent call last)\r\n\r\n<ipython-input-6-bed319bac6ce> in <module>()\r\n      1 dense_features = keras.layers.DenseFeatures(feature_columns)\r\n      2 column_tensors = {}\r\n----> 3 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)\r\n\r\n10 frames\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)\r\n    220             'Sparse ops are not supported with functional models with built-in '\r\n    221             'layer wrapping. Please wrap the sparse ops in a Lambda layer like'\r\n--> 222             ': \\n{lambda_example}\\n'.format(lambda_example=lambda_example))\r\n    223 \r\n    224       # Recursively set `_keras_history`.\r\n\r\nValueError: Sparse ops are not supported with functional models with built-in layer wrapping. Please wrap the sparse ops in a Lambda layer like: \r\n\r\n        weights_mult = lambda x: tf.sparse.sparse_dense_matmul(x, weights)\r\n        output = tf.keras.layers.Lambda(weights_mult)(input)\r\n```\r\nThis might be due to restarting the Python Interpereter.  I believe you can see the gist at https://colab.research.google.com/gist/jeisinge/90718acccf943c16b61ec80a2ff3cb66/tensorflow-feature-columns-fail-for-keras-model-functional-api.ipynb .\r\n\r\nIn general, I had to run cell 1.  Click the `Restart` button that appears, rerun everything.\r\n", "@jeisinge  Could you please check with tf-nightly version and let us know if the issue still persists.Thanks!", "I just tested on TF 2.3 and TF Nightly.  TF 2.3 fails, but TF Nightly works.  Also, the resulting model can be serialized.  Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36424\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36424\">No</a>\n"]}, {"number": 36423, "title": "Failed to get device attribute 13 for device 0", "body": "When I'am trying to run Yolo detection examples, I got that error:\r\n\r\n\r\n```\r\n2020-02-02 21:39:00.821721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                  \r\nWARNING:tensorflow:From C:\\Users\\Dominux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.                                                                        \r\nInstructions for updating:                                                                                                       \r\nIf using Keras pass *_constraint arguments to layers.                                                                            \r\n2020-02-02 21:39:03.863436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll                                                                                                                        \r\n2020-02-02 21:39:04.431694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:             \r\npciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1                                                                \r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s                                     \r\n2020-02-02 21:39:04.437212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                  \r\n2020-02-02 21:39:04.444498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll                                                                                                                   \r\n2020-02-02 21:39:04.450110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll                                                                                                                    \r\n2020-02-02 21:39:04.453997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll                                                                                                                   \r\n2020-02-02 21:39:04.459404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll                                                                                                                 \r\n2020-02-02 21:39:04.464501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll                                                                                                                 \r\n2020-02-02 21:39:04.477818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                                     \r\n2020-02-02 21:39:04.480586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0               \r\n2020-02-02 21:39:09.674559: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2                                                                                         \r\n2020-02-02 21:39:09.678508: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error \r\nInternal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error           \r\n```\r\n\r\nMy stack: \r\n* Win 10, \r\n* Tensoflow 2.1, \r\n* Intel Core I5, \r\n* Nvidia GeForce MX230 2GB, \r\n* 8GD DDR4\r\n\r\nI checked similar issues, but they don't have solutions. Just despaired people...\r\nBut it problem was talked about by them only with TF 1.14 - I didn't find other\r\nBut how you could notice at me stack above I'm using TF 2.1 already\r\n\r\nPlease, can you help me!\r\nMaybe I've got problems with drivers or CUDA software?\r\nAny ideas?", "comments": ["@Dominux, Which CUDA version are you using? ", "`Cuda compilation tools, release 10.1, V10.1.243`\r\n\r\nMaybe I installed it badly?\r\nCan I check that?\r\n\r\n\r\n", "@Dominux, Please follow the steps mentioned [here](https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal) to install CUDA. And also check cuda compute compatibility. Thanks! ", "After installing I got that error again:\r\n\r\n```\r\n2020-02-04 21:00:00.724297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                                        \r\nWARNING:tensorflow:From C:\\Users\\Dominux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.                                                                                                         \r\nInstructions for updating:                                                                                                                  \r\nIf using Keras pass *_constraint arguments to layers.                                                                                       \r\n2020-02-04 21:00:12.562035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll  \r\n2020-02-04 21:00:13.179773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:                        \r\npciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1                                                                           \r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s                                                \r\n2020-02-04 21:00:13.184727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                                        \r\n2020-02-04 21:00:13.270202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll                                                                                                                                         \r\n2020-02-04 21:00:13.322267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll                                                                                                                                          \r\n2020-02-04 21:00:13.360063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll                                                                                                                                         \r\n2020-02-04 21:00:13.435546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll                                                                                                                                       \r\n2020-02-04 21:00:13.476880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll                                                                                                                                       \r\n2020-02-04 21:00:13.613113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                                                           \r\n2020-02-04 21:00:13.618279: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error                                                            \r\n```", "So, any ideas?\r\n", "I suspect it is running out of memory really quick. Can you please help by doing some sanity checks,\r\nKill all python sessions/jupyter notebooks and\r\n(1) [Try limiting gpu memory growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)\r\nPut following snippet on top of your code;\r\n```python\r\nimport tensorflow as tf\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpus[0], True)\r\n# your code\r\n```\r\n\r\nKill all python sessions/jupyter notebooks and\r\n(2) [Logging device placement](https://www.tensorflow.org/guide/gpu#logging_device_placement)\r\n```python\r\ntf.debugging.set_log_device_placement(True)\r\n# Create some tensors\r\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b)\r\nprint(c)\r\n```", "Used this:\r\n\r\n```python\r\n\r\nimport tensorflow as tf\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpus[0], True)\r\n# your code\r\n\r\ntf.debugging.set_log_device_placement(True)\r\n# Create some tensors\r\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b)\r\nprint(c)\r\n```\r\n\r\nGot that:\r\n\r\n```\r\n2020-02-07 22:58:22.646355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-07 22:58:24.750350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-02-07 22:58:25.317147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s\r\n2020-02-07 22:58:25.317590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-07 22:58:25.322373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-02-07 22:58:25.326605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-02-07 22:58:25.327991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-02-07 22:58:25.333634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-02-07 22:58:25.337234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-02-07 22:58:25.345594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-02-07 22:58:25.346099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-07 22:58:25.346707: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-02-07 22:58:25.347512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s\r\n2020-02-07 22:58:25.347754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-07 22:58:25.347867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-02-07 22:58:25.347969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-02-07 22:58:25.348210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-02-07 22:58:25.348371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-02-07 22:58:25.348676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-02-07 22:58:25.348838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-02-07 22:58:25.349249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-07 22:58:25.977853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-07 22:58:25.978043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-02-07 22:58:25.978136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-02-07 22:58:25.979012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1354 MB memory) -> physical GPU (device: 0, name: GeForce MX230, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2020-02-07 22:58:25.993615: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-02-07 22:58:25.998778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\ntf.Tensor(\r\n[[22. 28.]\r\n [49. 64.]], shape=(2, 2), dtype=float32)\r\n```", "It's weird\r\n\r\nAfter that I tryed to run this example code from [there](https://www.tensorflow.org/neural_structured_learning), which had not been working before:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport neural_structured_learning as nsl\r\n\r\n# Prepare data.\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\n# Create a base model -- sequential, functional, or subclass.\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.Input((28, 28), name='feature'),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\n# Wrap the model with adversarial regularization.\r\nadv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\r\nadv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)\r\n\r\n# Compile, train, and evaluate.\r\nadv_model.compile(optimizer='adam',\r\n                  loss='sparse_categorical_crossentropy',\r\n                  metrics=['accuracy'])\r\nadv_model.fit({'feature': x_train, 'label': y_train}, batch_size=32, epochs=5)\r\nprint(adv_model.evaluate({'feature': x_test, 'label': y_test}))\r\n```\r\n\r\nAnd I've got fine result!", "But after that I tryed [another example](https://github.com/theAIGuysCode/yolo-v3#downloading-official-pretrained-weights), which is the first code, what I've got this error\r\n\r\nI just write in console\r\n\r\n`python detect.py images 0.5 0.5 data/images/dog.jpg data/images/office.jp`\r\n\r\nAnd again I've got error\r\n\r\nI bealive we are already near the finish of that issue)", "Thanks for the reply. Can you edit the `detect.py` script by limiting gpu memory growth.\r\nKill all python sessions/jupyter notebook and just add following lines on top after you import modules in `detect.py`.\r\n```python\r\nimport tensorflow as tf\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpus[0], True)\r\n##    Put rest of the detect.py code  ##\r\n```", "That doesn't work:\r\n\r\n```2020-02-08 12:22:30.663203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                          \r\n2020-02-08 12:22:32.786705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll                                                                                                                                \r\n2020-02-08 12:22:33.355070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:                 \r\npciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1                                                                    \r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s                                         \r\n2020-02-08 12:22:33.361748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                          \r\n2020-02-08 12:22:33.366524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll                                                                                                                           \r\n2020-02-08 12:22:33.373050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll                                                                                                                            \r\n2020-02-08 12:22:33.376522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll                                                                                                                           \r\n2020-02-08 12:22:33.382554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll                                                                                                                         \r\n2020-02-08 12:22:33.387539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll                                                                                                                         \r\n2020-02-08 12:22:33.397430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                                             \r\n2020-02-08 12:22:33.400498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0                   \r\nWARNING:tensorflow:From C:\\Users\\Dominux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.                                                                                    \r\nInstructions for updating:                                                                                                           \r\nIf using Keras pass *_constraint arguments to layers.                                                                                \r\n2020-02-08 12:22:39.597471: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow \r\nbinary was not compiled to use: AVX2                                                                                                 \r\n2020-02-08 12:22:39.601612: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error   \r\n```\r\n", "Can it be associate with small gpu-ram (I have only 2MB)?", "I suspect MX230 is not CUDA capable, I don't see it listed on https://developer.nvidia.com/cuda-gpus.  @nluehr Any idea?\r\n\r\nFor completeness, attribute 13 is `CU_DEVICE_ATTRIBUTE_CLOCK_RATE`.", "MX230 is a Pascal chip with compute capability 6.1 and does support CUDA. However, for typical TensorFlow workloads, the 2GB of GPU memory is quite small, and could easily be the problem as @ymodak suggests. The fact that the trivial 2x3x2 matrix multiply test above worked further suggests the problem is not related to the GPU or CUDA configuration.\r\n\r\nDepending on what applications you have running, it is also possible that Windows is using some of the GPU memory for rendering. Varying background workloads might explain why certain tasks sometimes fail and other times run successfully. It is a good idea to run nvidia-smi in the command prompt to check the amount of free GPU memory at the time you run your tests.\r\n\r\nAlso, instead of setting allow growth, you can set a hard limit on TensorFlow's GPU allocation as follows.\r\n```\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_virtual_device_configuration(gpus[0],\r\n    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n```\r\n\r\nIncreasing this memory limit from a small value until out-of-memory errors are not observed can help establish the minimum memory requirements of a model more reliably than allow_growth.\r\n", "I have the same message , maybe the same reason .\r\n\r\n- NVidia GTX 1050 with only 2GB memory\r\n- Win10 Ent 1909\r\n- VSCode 1.42.1\r\n- Python 3.7.6 x64\r\n- tf-gpu 2.1.0\r\n- Keras as the front end\r\n\r\nI noticed I have to run the VSCode as administrator , otherwise it will always fail to run my code .\r\n\r\nEven I run the VSCode as administrator , my code can't work every time . When I encountered this issue , I have to restart the terminal to try my luck (No , sometime it still won't work ) .", "@sd3326852 I'm sure the problem don't bind with VSCode\r\n\r\nTry to run code from terminal or even from another code editor", "I ran this:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_virtual_device_configuration(gpus[0],\r\n    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n\r\n# Create some tensors\r\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b)\r\nprint(c)\r\n\r\n```\r\n\r\nAng got that result:\r\n```console\r\n2020-02-22 13:02:04.006847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll     \r\n2020-02-22 13:02:06.106766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-02-22 13:02:06.694376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s\r\n2020-02-22 13:02:06.706289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll     \r\n2020-02-22 13:02:06.712418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll      \r\n2020-02-22 13:02:06.750739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll       \r\n2020-02-22 13:02:06.774249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll      \r\n2020-02-22 13:02:06.785747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll    \r\n2020-02-22 13:02:06.803940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll    \r\n2020-02-22 13:02:06.822030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll        \r\n2020-02-22 13:02:07.971037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-22 13:02:08.114339: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-02-22 13:02:08.137970: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to \r\nget device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error\r\n```", "@Dominux After a brief test , I think my problem does relate to VSCode . \r\nI can run my .py file in the command prompt without any problem , but in VSCode , it is just as my description .\r\n\r\nMy code :\r\n```import matplotlib.pyplot as plt\r\nimport keras\r\nfrom keras.datasets import mnist\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense\r\nfrom keras.optimizers import Adadelta\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nim = plt.imshow(x_train[5], cmap='gray')\r\nplt.show()\r\n\r\nx_train = x_train.reshape(-1, 28, 28, 1)\r\nx_test = x_test.reshape(-1, 28, 28, 1)\r\n\r\nx_train = x_train / 255\r\nx_test = x_test / 255\r\n\r\ny_train = keras.utils.to_categorical(y_train, 10)\r\ny_test = keras.utils.to_categorical(y_test, 10)\r\n\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, (5, 5), activation='relu', input_shape=[28, 28, 1]))\r\nmodel.add(Conv2D(64, (5, 5), activation='relu'))\r\nmodel.add(MaxPool2D(pool_size=(2, 2)))\r\nmodel.add(Flatten())\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(128, activation='relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(10, activation='softmax'))\r\n\r\nmodel.summary()\r\n\r\nstr = input()\r\n\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer=Adadelta(),\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(\r\n    x_train,\r\n    y_train,\r\n    batch_size=64,\r\n    epochs=15,\r\n    # validation_data=(x_test, y_test)\r\n)\r\n\r\nscore = model.evaluate(x_test, y_test)\r\nprint(\"loss:\", score[0])\r\nprint(\"accu:\", score[1])\r\n```\r\n\r\nMy console message is also a little different from yours :\r\n```Using TensorFlow backend.\r\n2020-02-22 20:17:28.222385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-22 20:17:34.482040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-02-22 20:17:35.087860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\r\ncoreClock: 1.493GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-02-22 20:17:35.096790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-22 20:17:35.111742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-02-22 20:17:35.131634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-02-22 20:17:35.139913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-02-22 20:17:35.162752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-02-22 20:17:35.179229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-02-22 20:17:35.210591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-02-22 20:17:35.225324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-22 20:17:35.230182: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-02-22 20:17:35.233624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\r\ncoreClock: 1.493GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-02-22 20:17:35.239249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-22 20:17:35.254127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-02-22 20:17:35.270027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-02-22 20:17:35.287544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-02-22 20:17:35.292623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-02-22 20:17:35.308316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-02-22 20:17:35.322489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-02-22 20:17:35.367374: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error\r\n```\r\n", "@sd3326852 You know\r\nAfter test on my _cmd_ I didn't get this error)\r\n\r\nAnd as I think, maybe _VS Code_'s setting some limit on using computer resources when u run smth in it's bash. Because I doubt _VS Code_ take a lot of Graphical resources for it's needs", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36423\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36423\">No</a>\n", "Same problem.\r\nI know it sounds weird, but if you use a 2nd monitor, try unplugging it to get free memory on the geforce. It works for me.\r\n\r\nOr try:\r\ngpu_options = tf.GPUOptions(allow_growth=True)\r\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\r\n\r\nOrtry:\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.5)\r\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))", "Hello, I got a similar error with Pytorch.\r\nI am new to TensorFlow but have experience with Pytorch. \r\n\r\nI have...\r\n- Windows 10\r\n- NVIDIA GTX 1050 4G and CUDA v10.1 \r\n- PyCharm as IDE\r\n- TensorFlow 2.1.0\r\n\r\nIn my cases, I could solve those errors by simply generating a small tensor on the GPU.\r\nIn this TensorFlow case, I run the following python code on the terminal.\r\n```\r\nimport tensorflow as tf\r\nt = tf.random.uniform([2,2])\r\n```\r\n\r\nUnfortunately, I cannot explain why this happens but hope this helps someone.", "> Thanks for the reply. Can you edit the `detect.py` script by limiting gpu memory growth.\r\n> Kill all python sessions/jupyter notebook and just add following lines on top after you import modules in `detect.py`.\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> gpus = tf.config.experimental.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(gpus[0], True)\r\n> ##    Put rest of the detect.py code  ##\r\n> ```\r\n\r\n", "thanks alot .", "I also encountered this problem after updating to tf 2.1.0. The same code ran fine before. Now it usually gives me the error 13 once. If I execute the code again, it runs fine.\r\n\r\nwindows version: 10.0.18362.778\r\nInstalled via Anaconda\r\nTensorflow Version  2.1.0\r\ncudnn: 7.6.5\r\ncudatoolkit: 10.1.243\r\nPython version:  3.7.7\r\nGPU: Nvidia gtx 960m (2GB VRAM, but it is not unitlized by any other process, the driver still only allows for around 1.3GB to be taken up by tensorflow)\r\n\r\nIf there is anything I can do to help debug this, please let me know.\r\n(also after the update tensorflow has to grab my GPU twice, so it tells me\r\nFound device 0\r\nsucessfully added dynamic libraries\r\n Adding visible gpu devices: 0\r\nThen, that my CPU supports AVX and AVX2, but tensorflow is not compiled to use it.\r\nAfterwards it starts again from the top and then it works (excluding the message about the CPU)", "I am  also getting some error.\r\nwindows version: 10.\r\nInstalled via Anaconda\r\nTensorflow Version 2.1.0\r\ncudnn: 7.6.5\r\ncudatoolkit: 10.1.243\r\nPython version: 3.7\r\nGPU: Geforce GTX 1050\r\nCPU: i5-8300H\r\n\r\n```\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2020-04-30 00:56:49.736576: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-04-30 00:56:49.744231: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown [error]\r\n```", "I have to same problem : \r\n\r\n```\r\n2020-04-30 14:35:33.696341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce MX230 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 44.76GiB/s\r\n2020-04-30 14:35:33.696481: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696541: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696590: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696640: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696681: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696722: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696767: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\r\n2020-04-30 14:35:33.696774: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n\r\n```\r\n\r\n```\r\nThu Apr 30 13:57:54 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce MX230       Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   49C    P8    N/A /  N/A |    460MiB /  2002MiB |      5%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1236      G   /usr/lib/xorg/Xorg                            45MiB |\r\n|    0      1834      G   /usr/lib/xorg/Xorg                           175MiB |\r\n|    0      2088      G   /usr/bin/gnome-shell                         169MiB |\r\n|    0      2570      G   ...uest-channel-token=16623836546497770292    19MiB |\r\n|    0      5676      G   ...quest-channel-token=6248868283127127550    42MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n```\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_virtual_device_configuration(gpus[0],\r\n    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n```\r\n\r\n```\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-6-9a8e0a262b41> in <module>\r\n      1 gpus = tf.config.experimental.list_physical_devices('GPU')\r\n----> 2 tf.config.experimental.set_virtual_device_configuration(gpus[0],\r\n      3     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n\r\nIndexError: list index out of range\r\n```\r\n```", "Now I have this \r\n\r\n```\r\n2020-04-30 15:11:56.079202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-04-30 15:11:56.114737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-30 15:11:56.115000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce MX230 computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 44.76GiB/s\r\n2020-04-30 15:11:56.116109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-04-30 15:11:56.139883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-04-30 15:11:56.152842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-04-30 15:11:56.156429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-04-30 15:11:56.180632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-04-30 15:11:56.185851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-04-30 15:11:56.186157: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\r\n2020-04-30 15:11:56.186185: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n\r\n```", "It's ok after installing libcudnn ;)", "> I am also getting some error.\r\n> windows version: 10.\r\n> Installed via Anaconda\r\n> Tensorflow Version 2.1.0\r\n> cudnn: 7.6.5\r\n> cudatoolkit: 10.1.243\r\n> Python version: 3.7\r\n> GPU: Geforce GTX 1050\r\n> CPU: i5-8300H\r\n> \r\n> ```\r\n> Call initializer instance with the dtype argument instead of passing it to the constructor\r\n> INFO:tensorflow:Done calling model_fn.\r\n> INFO:tensorflow:Create CheckpointSaverHook.\r\n> INFO:tensorflow:Graph was finalized.\r\n> 2020-04-30 00:56:49.736576: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n> 2020-04-30 00:56:49.744231: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown [error]\r\n> ```\r\n\r\nNow it's working perfect after updating NVIDIA driver.\r\nIf you are using conda/Anaconda try to make new environment also.\r\nIt works for me :100: ", "I had the same issue. I solved it by installing the cudnn library for cuda version 10.1 and linked it in my path variable so it can be found.", "Hey, just check that you have included all the required environment variables. Ex: cudnn64_7.dll. It worked for me.", "Try to check whether your antivirus is not blocking any file related to CUDA or python file in that particular environment.\r\nIt worked for me when I added exception for my tensorflow env in my avast antivirus.", "> \r\n> \r\n> When I'am trying to run Yolo detection examples, I got that error:\r\n> \r\n> ```\r\n> 2020-02-02 21:39:00.821721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                  \r\n> WARNING:tensorflow:From C:\\Users\\Dominux\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.                                                                        \r\n> Instructions for updating:                                                                                                       \r\n> If using Keras pass *_constraint arguments to layers.                                                                            \r\n> 2020-02-02 21:39:03.863436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll                                                                                                                        \r\n> 2020-02-02 21:39:04.431694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:             \r\n> pciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1                                                                \r\n> coreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s                                     \r\n> 2020-02-02 21:39:04.437212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                  \r\n> 2020-02-02 21:39:04.444498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll                                                                                                                   \r\n> 2020-02-02 21:39:04.450110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll                                                                                                                    \r\n> 2020-02-02 21:39:04.453997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll                                                                                                                   \r\n> 2020-02-02 21:39:04.459404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll                                                                                                                 \r\n> 2020-02-02 21:39:04.464501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll                                                                                                                 \r\n> 2020-02-02 21:39:04.477818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                                     \r\n> 2020-02-02 21:39:04.480586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0               \r\n> 2020-02-02 21:39:09.674559: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2                                                                                         \r\n> 2020-02-02 21:39:09.678508: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error \r\n> Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error           \r\n> ```\r\n> \r\n> My stack:\r\n> \r\n>     * Win 10,\r\n> \r\n>     * Tensoflow 2.1,\r\n> \r\n>     * Intel Core I5,\r\n> \r\n>     * Nvidia GeForce MX230 2GB,\r\n> \r\n>     * 8GD DDR4\r\n> \r\n> \r\n> I checked similar issues, but they don't have solutions. Just despaired people...\r\n> But it problem was talked about by them only with TF 1.14 - I didn't find other\r\n> But how you could notice at me stack above I'm using TF 2.1 already\r\n> \r\n> Please, can you help me!\r\n> Maybe I've got problems with drivers or CUDA software?\r\n> Any ideas?\r\n\r\nMy issue is same as you, and I don`t kown how to sove it. ", "Had the same issue, but resolved by updating NVIDIA device drivers to the latest (v446.14).\r\nhttps://www.nvidia.com/download/index.aspx?lang=en-us", "javierlg1986 is actually correct. As a matter of fact, if you have a second memory with VGA cable you will have the problem every second run. If you have HDMI cable, you will get it every time. ", "So ..\r\n my friend .. I had the same problem and it was solved this way\r\nclick right in any empty place in Desktop and chose **Nvidia Control Panel**\r\nand the picture explain \r\n![ddd](https://user-images.githubusercontent.com/62519373/88177850-289c8980-cc32-11ea-81e9-b00042c225e2.jpg)\r\n", "I was facing same issue. After updating Nvidia driver its working fine. Updated to GTX  1660 Ti (441.37).", "I wonder why the problem could be solved by updating driver? I have successfully trained a model before, but now when need train another, it needs to update driver..."]}, {"number": 36422, "title": "performance issue when using the function tf.convert_to_tensor()", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nlinux ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNA\r\n- TensorFlow installed from (source or binary):\r\nbinary, loaded from tensorflow docker\r\n- TensorFlow version (use command below):\r\nv2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\nNA\r\n- GCC/Compiler version (if compiling from source):\r\nNA\r\n- CUDA/cuDNN version:\r\nCUDA 10.1\r\n- GPU model and memory:\r\nv100 32 GB\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI'm suspecting a CPU performance issue when converting a numpy array to tensor.\r\nThe duration of the function increased significantly (factor ~4) depends on the data size but not linear and also with large jitters.\r\n\r\nInspecting deeply into number of elements as a graph, we observed jitters and better performance, for some data sizes and bad performance for other data sizes, any ideas why there are large jitters? \r\n\r\nNote: we need to understand in a manner of milliseconds for near real-time application.  \r\nattached:\r\n\r\n- graph of convert_to_tensor depends for 1,000,000 - 60,000,000 elements \r\n- graph of convert_to_tensor depends for 1,000,000 - 7,000,000 elements (deeper scope)\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport time\r\n\r\nfor j in range(100):\r\n    input_data = np.float32(np.random.rand(1125000 + j * 500000))\r\n    start = time.time()\r\n    converted_data = tf.convert_to_tensor(input_data, dtype=np.float32)\r\n    stop = time.time()\r\n    print(\"convert of\", 1125000 + j * 500000, \"took [ms]: \", 1000 * (stop - start))\r\n\r\n\r\n\r\nfor j in range(100):\r\n    input_data = np.float32(np.random.rand(1125000 + j * 50000))\r\n    start = time.time()\r\n    converted_data = tf.convert_to_tensor(input_data, dtype=np.float32)\r\n    stop = time.time()\r\n    print(\"convert of\", 1125000 + j * 50000, \"took [ms]: \", 1000 * (stop - start))\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n![convert_to_tf_graph_1E06_6E07](https://user-images.githubusercontent.com/27951762/73609337-394e3a00-45d5-11ea-8f1e-aaeaa7c71f22.PNG)\r\n![convert_to_tf_graph_1E06_7E06](https://user-images.githubusercontent.com/27951762/73609338-39e6d080-45d5-11ea-95eb-feb1039a71f6.PNG)", "comments": ["i am able to replicate the issue, please find the [gist](https://colab.research.google.com/gist/Saduf2019/a3e9ffb27effa829b30fe9f53c8a985c/36422.ipynb) here.", "I don't think this is a TensorFlow problem: if you replace your `tf.convert_to_tensor` calls with copies of the `np.random.rand` calls above, you'll see that the Numpy calls also take more and more time. So even without TensorFlow involved, you get the same behavior. Example:\r\n\r\n```python\r\n  for j in range(50):\r\n    start = time.time()\r\n    input_data = np.float32(np.random.rand(1125000 + j * 500000))\r\n    stop = time.time()\r\n    print(\"convert of\", 1125000 + j * 500000, \"took [ms]: \", 1000 * (stop - start))\r\n```\r\n\r\nI'll close this as it seems \"normal\" Python behavior. Feel free to reopen if you find otherwise!", "Note: sometimes I see the jitters there without TensorFlow code too. Internally, `convert_to_tensor` does not do much work when given Numpy arrays as in your example, so the variations you are seeing are likely due to Python internals.", "Ah, one more note (sorry, I forgot about this one and it is actually the main point): the timing jitters are due to Python internals, _but_ in TF `master` the problem does not exist anymore: `convert_to_tensor` takes around half a millisecond for any of the conversions in your example, so the \"longer with larger inputs\" behavior is not there anymore."]}, {"number": 36421, "title": "Tensor is unhashable if Tensor equality is enabled", "body": "**System information**\r\nwin10\r\npython 3.6\r\nTF 2.1\r\ntfp 0.9 (have trid 0.8 as well)\r\ntf-hightly-2.9-preview 2.0\r\nshap 0.34\r\nmy code below:\r\nfrom __future__ import print_function\r\n\r\nfrom keras.preprocessing import sequence\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Embedding\r\nfrom keras.layers import LSTM\r\nfrom keras.datasets import imdb\r\n\r\nmax_features = 20000\r\nmaxlen = 80  # cut texts after this number of words (among top max_features most common words)\r\nbatch_size = 16\r\n\r\nprint('Loading data...')\r\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\r\nprint(len(x_train), 'train sequences')\r\nprint(len(x_test), 'test sequences')\r\n\r\nprint('Pad sequences (samples x time)')\r\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\r\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\r\nprint('x_train shape:', x_train.shape)\r\nprint('x_test shape:', x_test.shape)\r\n\r\nprint('Build model...')\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features, 128))\r\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\nprint('Train...')\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=1,\r\n          validation_data=(x_test, y_test))\r\nscore, acc = model.evaluate(x_test, y_test,\r\n                            batch_size=batch_size)\r\nprint('Test score:', score)\r\nprint('Test accuracy:', acc)\r\n\r\nimport shap\r\nexplainer = shap.DeepExplainer(model, x_train[:100])\r\nshap_values = explainer.shap_values(x_test[:10])\r\n\r\n**Describe the current behavior**\r\nTypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n\r\nanyone can help me out??  THX\r\n", "comments": ["@simplezhang57, I changed the imports as follows and its working as expected.\r\n```\r\nfrom tensorflow.keras.preprocessing import sequence\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Embedding\r\nfrom tensorflow.keras.layers import LSTM\r\nfrom tensorflow.keras.datasets import imdb\r\n\r\n```\r\nPlease take a look at [gist](https://colab.research.google.com/gist/gadagashwini/c6484d1b8de46297cdb54f570caebbc2/untitled373.ipynb#scrollTo=gFjBtWAuUYqF). Thanks!", "@simplezhang57, Closing since its resolved. Please feel free to open or comment if issue still persists. Thanks!"]}, {"number": 36420, "title": "Tensorflow2.0 checkpoint restore error", "body": "Here is an error message:\r\n`Exception ignored in: <bound method _CheckpointRestoreCoordinatorDeleter.__del__ of <tensorflow.python.training.tracking.util._CheckpointRestoreCoordinatorDeleter object at 0x0000014FDDC7CFD0>>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\17551\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\", line 140, in __del__    \r\nTypeError: 'NoneType' object is not callable`\r\n\r\nI'm using tensorflow-gpu 2.0, windows10, I imported the following libraries:\r\n    from tensorflow.keras.preprocessing.text import text_to_word_sequence\r\n    import tensorflow as tf\r\n\r\nThis is the code piece of how I restore the checkpoint:\r\n    `checkpoint_dir = gConfig['model_data']\r\n    seq2seqModel.checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))`\r\n", "comments": ["Please fill in the issue template, please use ` ``` ` around code blocks and errors, please make sure you search for duplicates of your issue, in case there is already some solution available.", "@Panshangka, Please provide the information asked in the Template to analyze the issue. ", "Thanks, it's solved. I'll close the issue", "I met the same problem as you do, can you tell me how you solved the problem?", "> I met the same problem as you do, can you tell me how you solved the problem?\r\n\r\nIt's long time ago and I forget. Maybe you can post the code I'll see if I can help", "`if __name__ == '__main__':`\r\n    `model = TransE()`\r\n    `checkpoint = tf.train.Checkpoint(my_model = model)`\r\n    `checkpoint.restore(tf.train.latest_checkpoint('./checkpoint1'))`\r\n    `test_case = [5, 6, 7]`\r\n    `a, b = model.evaluate(test_case)`\r\n    `print (a, b)`\r\n\r\nAnd the output went like \r\n`\r\ntf.Tensor([11028  7542  2595 ...  9127 14509     6], shape=(14951,), dtype=int32) tf.Tensor([ 6383  5011  5887 ...  3105 12434     5], shape=(14951,), dtype=int32)`\r\n`Exception ignored in: <bound method _CheckpointRestoreCoordinatorDeleter.__del__ of <tensorflow.python.training.tracking.util._CheckpointRestoreCoordinatorDeleter object at 0x7f47d1dc2d30>>`\r\n`\r\nTraceback (most recent call last):\r\n  File \"/home/zhx/Paper/CL-KG/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 140, in __del__\r\n`\r\n`TypeError: 'NoneType' object is not callable`", "> tf.train.Checkpoint\r\nI can't really help, but you can probably change the way of save and restore,  [checkpointmanager ](https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager) maybe helpful. \r\nAnd double check the checkpoint directory\r\n", "Thank you all the same\r\n\r\n\r\n\r\n\r\n------------------&nbsp;\u539f\u59cb\u90ae\u4ef6&nbsp;------------------\r\n\u53d1\u4ef6\u4eba: \"klauspa\"<notifications@github.com&gt;; \r\n\u53d1\u9001\u65f6\u95f4: 2020\u5e744\u670826\u65e5(\u661f\u671f\u5929) \u665a\u4e0a6:23\r\n\u6536\u4ef6\u4eba: \"tensorflow/tensorflow\"<tensorflow@noreply.github.com&gt;; \r\n\u6284\u9001: \"zz\"<347862932@qq.com&gt;; \"Comment\"<comment@noreply.github.com&gt;; \r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] Tensorflow2.0 checkpoint restore error (#36420)\r\n\r\n\r\n\r\n\r\n\r\n  \r\ntf.train.Checkpoint\r\n I can't really help, but you can probably change the way of save and restore,  checkpoint manager maybe helpful.\r\n And double check the checkpoint the directory\r\n  \r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub, or unsubscribe.", "I am facing the same issue can any one guide me?\r\n", "# Testing the model performances.\r\n\r\nimport matplotlib\r\nimport matplotlib.pyplot as plt\r\n\r\nimport io\r\nimport os\r\nimport scipy.misc\r\nimport numpy as np\r\nfrom six import BytesIO\r\nfrom PIL import Image, ImageDraw, ImageFont\r\n\r\nimport tensorflow as tf\r\n\r\nfrom object_detection.utils import label_map_util\r\nfrom object_detection.utils import config_util\r\nfrom object_detection.utils import visualization_utils as viz_utils\r\nfrom object_detection.builders import model_builder\r\n\r\n#%matplotlib inline\r\n\r\n\r\ndef load_image_into_numpy_array(path):\r\n  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n  image = Image.open(BytesIO(img_data))\r\n  (im_width, im_height) = image.size\r\n  return np.array(image.getdata()).reshape(\r\n      (im_height, im_width, 3)).astype(np.uint8)\r\n\r\n\r\n#recover our saved model\r\npipeline_config = './exported/pipeline.config'   \r\n#generally you want to put the last ckpt from training in here\r\nmodel_dir = './train_output/ckpt-1'   \r\nconfigs = config_util.get_configs_from_pipeline_file(pipeline_config)\r\nmodel_config = configs['model']\r\ndetection_model = model_builder.build(model_config=model_config, is_training=False)\r\n# Restore checkpoint\r\nckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\r\nckpt.restore(os.path.join('./train_output/ckpt-2'))\r\n\r\ndef get_model_detection_function(model):\r\n  \"\"\"Get a tf.function for detection.\"\"\"\r\n\r\n  @tf.function\r\n  def detect_fn(image):\r\n    \"\"\"Detect objects in image.\"\"\"\r\n\r\n    image, shapes = model.preprocess(image)\r\n    prediction_dict = model.predict(image, shapes)\r\n    detections = model.postprocess(prediction_dict, shapes)\r\n\r\n    return detections, prediction_dict, tf.reshape(shapes, [-1])\r\n\r\n  return detect_fn\r\n\r\ndetect_fn = get_model_detection_function(detection_model)\r\n#map labels for inference decoding\r\nlabel_map_path = configs['eval_input_config'].label_map_path\r\nlabel_map = label_map_util.load_labelmap(label_map_path)\r\nprint(label_map)\r\n      \r\n     \r\n\r\n    \r\n\r\n"]}, {"number": 36419, "title": "ModuleNotFoundError: No module named 'tensorflow.contrib'. Latest version of TensorFlow not working with TFLearn?", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7, 3.6.10 on virtual environment\r\n- Installed using virtualenv? pip? conda?: conda\r\n- CUDA/cuDNN version: CUDA 9.0 / cuDNN 7.6.5\r\n- GPU model and memory: NVIDIA GeForce GTX 1660 SUPER, 16GB\r\n\r\nSo iv'e been trying to install Tensorflow for a while and conda seems like the method that worked best for me, iv'e pretty much got it working in good order, i tried messing around a bit then decided to follow a tutorial which prompted to install tflearn\r\n\r\ntflearn is what seems to be causing the problem, i saw an issue over at their repository. But i'am not certain of the steps i should be taking to resolve the issue, heres the traceback;\r\n```\r\n File \"main.py\", line 6, in <module>\r\n   import tflearn\r\n File \"C:\\Users\\User\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\tflearn\\__init__.py\", line 4, in <module>\r\n   from . import config\r\n File \"C:\\Users\\User\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\tflearn\\config.py\", line 5, in <module>\r\n   from .variables import variable\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\tflearn\\variables.py\", line 7, in <module>\r\n   from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope\r\n \r\nModuleNotFoundError: No module named 'tensorflow.contrib'\r\n```\r\nI'am not certain if i should downgrade tensorflow, but to what version? Or are there steps i need to take to fix the issue?\r\n\r\nThanks in advance,", "comments": ["`tf.contrib` has been removed from TF2.0 onwards, especially since it was not properly maintained\r\n\r\nWe recommend switching to alternatives or downgrading to 1.15", "> `tf.contrib` has been removed from TF2.0 onwards, especially since it was not properly maintained\r\n> \r\n> We recommend switching to alternatives or downgrading to 1.15\r\n\r\n@mihaimaruseac  TF 1.15 seems not to have the tf.contrib module anymore too. It's still available in TF<=1.14, but some models are trained not properly with that version. For example the inputs layer shows following (?,?,?,3). While it should be (None,None,None,3) for image data. It's very frustrating currently because at least for me everything worked perfectly with 1.15 until Tuesday, March,17. \r\nSeems like something broke or someone removed the tf.contrib module in 1.15. ", "1.15 should have it. What error do you get? What is the output of `pip list`?"]}, {"number": 36418, "title": "[Nightly] Distributed dataset/variable regression with dictionary data structures 2.2.0.dev20200130 -> 2.2.0.dev20200131", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Wheel\r\n- **TensorFlow version (use command below)**: 2.2.0.dev20200130, 2.2.0.dev20200131\r\n- **Python version**: 3.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 10.1/7.x\r\n- **GPU model and memory**: Titan XP\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nWhen calling next on an iter made from a distributed dataset (a tf-agents replay buffer), I get the following error on the latest tf-nightly:\r\n\r\n```\r\n  File \"/home/mjlbach/Repositories/box-physics/boxphysics/run/worker.py\", line 238, in train\r\n    inputs = next(self.iter)[0]\r\n  File \"/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 250, in __next__\r\n    return self.get_next()\r\n  File \"/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 271, in get_next\r\n    return values.regroup(replicas)\r\n  File \"/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1185, in regroup\r\n    for i in range(len(v0)))\r\n  File \"/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1185, in <genexpr>\r\n    for i in range(len(v0)))\r\n  File \"/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1202, in regroup\r\n    for key in v0keys\r\nTypeError: __init__() got an unexpected keyword argument 'flex_states'\r\n```\r\n\r\nI did a bisect and found the change was introduced from 20200130 to 20200131. If I had to guess, I would point towards this commit: https://github.com/tensorflow/tensorflow/commit/4c4e3772ae95f17818e1e08cd7d6c33276a6b68f#diff-580627c9b7904095019167ef005a72de\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@mjlbach.\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "The following example fails on the latest nightly, but runs fine on 2.2.0dev20200130\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tf_agents import specs\r\nfrom tf_agents.replay_buffers import episodic_replay_buffer\r\n\r\n\r\nclass EpisodicReplayBuffer:\r\n    def __init__(self, example_len, buffer_size):\r\n        self.example_len = example_len\r\n        self.buffer_size = buffer_size\r\n\r\n        self.episodes_collected = 0\r\n\r\n    def initialize(self, episode):\r\n        spec = dict()\r\n        for key, value in episode.items():\r\n            dtype = str(value.dtype)\r\n            if dtype == \"int32\":\r\n                dtype = tf.int32\r\n            elif dtype == \"int64\":\r\n                dtype = tf.int64\r\n            elif dtype == \"float32\":\r\n                dtype = tf.float32\r\n            elif dtype == \"float64\":\r\n                dtype = tf.float64\r\n            elif dtype == \"bool\":\r\n                dtype = tf.bool\r\n            else:\r\n                print(\"Unknown dtype: {}\".format(dtype))\r\n                quit()\r\n            shape = list(value.shape)[2:]\r\n            spec[key] = specs.TensorSpec(shape, dtype, key)\r\n\r\n        self.replay_buffer = episodic_replay_buffer.EpisodicReplayBuffer(\r\n            spec,\r\n            capacity=self.buffer_size,\r\n            begin_episode_fn=lambda _: False,\r\n            end_episode_fn=lambda _: True,\r\n        )\r\n        # self.add_episode(episode)\r\n\r\n    def add_episode(self, episode):\r\n        print(\"Episode collected: {}\\n\".format(self.episodes_collected))\r\n        self.episodes_collected += 1\r\n        episode_id = self.replay_buffer.create_episode_ids(num_episodes=0)\r\n        episode = tf.nest.map_structure(lambda v: v[0], episode)\r\n        self.replay_buffer.add_sequence(episode, episode_id)\r\n\r\n    def as_dataset(self, batch_size):\r\n        return self.replay_buffer._as_dataset(\r\n            num_steps=self.example_len, sample_batch_size=batch_size\r\n        )\r\n\r\n\r\ndef main():\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    replay_buffer = EpisodicReplayBuffer(4, 4)\r\n    episode = {}\r\n    for key in [\"tensor_1\", \"tensor_2\", \"tensor_3\"]:\r\n        value = np.ones(shape=[1, 4, 4, 4], dtype=np.float32)\r\n        episode[key] = value\r\n\r\n    replay_buffer.initialize(episode)\r\n    with strategy.scope():\r\n        replay_buffer.add_episode(episode)\r\n        replay_buffer.add_episode(episode)\r\n        replay_buffer.add_episode(episode)\r\n        dataset = replay_buffer.as_dataset(4)\r\n        distributed_dataset = strategy.experimental_distribute_dataset(dataset)\r\n        iterator = iter(distributed_dataset)\r\n        data = next(iterator)\r\n        print(data)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```", "I believe this is fixed on the latest nightly.", "@mjlbach Yes. Looks like it was fixed in the `tf-nightly`. I could not see any error when I ran against `tf-nightly`. [Here](https://colab.research.google.com/gist/jvishnuvardhan/2df78b9f5a7eca4d661ca744088c365a/untitled813.ipynb) is the gist for y/our reference. Thanks!", "Closing :) ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36418\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36418\">No</a>\n"]}, {"number": 36417, "title": "Regression: contrib.boosted_trees.estimator_batch modules are not available in 1.15.2", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.15.0-92-g5d80e1e8e6 1.15.2\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nMany modules are simply missing from `tensorflow.contrib.boosted_trees`, including `estimator_batch` and `lib`\r\n```\r\n>>> import tensorflow.contrib.boosted_trees.estimator_batch\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow.contrib.boosted_trees.estimator_batch'\r\n```\r\n \r\n\r\n**Describe the expected behavior**\r\n`import tensorflow.contrib.boosted_trees.estimator_batch` should succeed.\r\n\r\n**Code to reproduce the issue**\r\n`import tensorflow.contrib.boosted_trees.estimator_batch`\r\n\r\n**Other info / logs**\r\nLooks like a regression since 1.15.0\r\n", "comments": ["Issue replicating for latest [tf-1.15.2](https://colab.research.google.com/gist/oanush/a0cdd4f4bc54c60486bf7c1128d2385b/36417.ipynb),Thanks!", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36417\">No</a>\n"]}, {"number": 42783, "title": "Translating into Greek", "body": "Hello there !\r\n\r\nI'm a CSD undergraduate in Greece. I am willing to contribute to this community by translating the TensorFlow docs into Greek . As the language isn't listed , I would like some instructions to begin with . Looking forward to your reply !", "comments": ["Thanks, George. Since we're working on this in https://github.com/tensorflow/docs-l10n/pull/30 will close this."]}, {"number": 36416, "title": "Error while training object detection model", "body": "Hi,\r\nI am gonna to train a model for object detection with ssdlite_mobilenet_v2_coco (training images:30000,testing images:2000). But in almost 24000 itrations, I will be faced a problem.\r\nWhat's the meaning of this error and how can i fix it?\r\n### System information\r\n\r\n- OS Platform and Distribution (Google Colab Ubuntu):\r\n\r\n- TensorFlow version (1.15)\r\n\r\n\r\nINFO:tensorflow:Finished training! Saving model to disk.\r\nI0201 18:58:21.724251 140376424556416 learning.py:785] Finished training! Saving model to disk.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to delete files with this prefix.\r\nW0201 18:58:22.325520 140376424556416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to delete files with this prefix.\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\r\n  warnings.warn(\"Attempting to use a closed FileWriter. \"\r\nTraceback (most recent call last):\r\n  File \"/content/gdrive/My Drive/Tensorflow/3_train_ssdlite.py\", line 185, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/content/gdrive/My Drive/Tensorflow/3_train_ssdlite.py\", line 181, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"/content/models/research/object_detection/legacy/trainer.py\", line 417, in train\r\n    saver=saver)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 790, in train\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/supervisor.py\", line 839, in stop\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/queue_runner_impl.py\", line 257, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1287, in _single_operation_run\r\n    self._call_tf_sessionrun(None, {}, [], target_list, None)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: /content/gdrive/My Drive/Tensorflow/training_data/train.tfrecord; Input/output error\r\n\t [[{{node IteratorGetNext}}]]", "comments": ["@masoudnick,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here.\r\n\r\nYou can also share your Google Colab Gist. Please go to 'File' -> 'Save a copy as a GitHub Gist'  and share the link of the new window with us. Thanks!", "@amahendrakar,\r\nok,here you are.\r\nhttps://gist.github.com/masoudnick/9df13f4b4cb91ea4003a1c80b3a15192", "@masoudnick As the error implies, this is an issue with reading your own dataset's tfrecords. You should first check the integrity of your TFRecords (e.g. see if you can extract the image data from tfrecord -> image tensor -> reading image out in numpy format to verify).", "@gowthamkpr As you said i tried to extract images data from train.tfrecord based on the following code:\r\n[Integrity.py](https://gist.github.com/masoudnick/d6abda37bd236045731e40dc8e4cff57)\r\n\r\nBut 16K images data extracted and i faced to this error:\r\n\r\n<pre><code>\r\nCancelledError\r\n     25   parsed_dataset = parse_tfrecord(tfrecord)\r\n---> 27   for i,example in enumerate(parsed_dataset):\r\n     28     image_decoded = tf.image.decode_image(example['image/encoded']).numpy()\r\n     29     height = example['image/height'].numpy()\r\n\r\nCancelledError: /content/gdrive/My Drive/Tensorflow/training_data/train.tfrecord; Operation canceled [Op:IteratorGetNextSync]\r\n</code></pre>\r\n\r\nIs there a problem with tfrecord file or method of its generation?\r\n\r\nfor generating tfrecord file, I converted images .xml file to .csv file and then used the following code:\r\n[generate_tfrecords.py](https://gist.github.com/masoudnick/6c220db0631f23156a5153cfffd1ccac) ", "@masoudnick Is it still an issue or did you resolve it?", "Closing this issue as its a support issue. Please add additional comments for us to open this issue again. Thanks!"]}, {"number": 36415, "title": "tf 2.1 do not support bazel 0.26?", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/source?hl=en\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIt's said that tensorflow 2.1.0 is built by bazel 0.26.1, but when I use bazel 0.26.1 to build, I get the following error:\r\n```\r\nPlease upgrade your bazel installation to version 0.27.1 or higher to build TensorFlow!\r\n```\r\n\r\nSo, what is the correct bazel version?", "comments": ["I think there is a mistake in the documentation page. Will send an update for that.\r\n\r\nIn any case, the true version is the one mentioned in `./configure`, giving you the above error. Starting past week, `master` has Bazelisk set up so you won't have to manually install Bazel anymore, if building from master.", "Worth mentioning that if you plan to use Ubuntu to build TF 2.1 with TensorRT then you might have to still tweak the 2.1 source to allow bazel 0.26.1 as 0.27.1 seems to fail... (See https://github.com/tensorflow/tensorflow/issues/35115#issuecomment-580860705 for details).\r\n\r\nWithout TensorRT it wouldn't matter, 0.27.1 will be fine.", "Thank you for everyone! I can close this issue now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36415\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36415\">No</a>\n"]}, {"number": 36414, "title": "remove validation_data from docstring of Callback class", "body": "resolves #36375", "comments": ["@rchao Can you please review this PR?", "Can somebody take a look here, please?", "@rchao Any update on this PR? Please. Thanks!", "okay"]}, {"number": 36413, "title": "Image data Generator in input mode is not running", "body": "I tried to create a Deep Learning model kinda like a Autoencoder.\r\nSo i got image inputs and outputs via image data generator.\r\n\r\n`image_dataset = keras.preprocessing.image.ImageDataGenerator(rotation_range=180,validation_split=0.25)`\r\n\r\n`output_image_dataset = keras.preprocessing.image.ImageDataGenerator(rotation_range=180,validation_split=0.25)`\r\n\r\n`train_generator = image_dataset.flow_from_directory(input_data_dir,\r\n                                                    color_mode='grayscale',\r\n                                                    target_size=(image_size, image_size),\r\n                                                    batch_size=batch_size,\r\n                                                    class_mode=None,\r\n                                                    subset='training')`\r\n\r\n`validation_generator = image_dataset.flow_from_directory(input_data_dir,\r\n                                                    color_mode='grayscale',\r\n                                                    target_size=(image_size, image_size),\r\n                                                    batch_size=batch_size,\r\n                                                    class_mode=None,\r\n                                                    subset='validation')`\r\n\r\n`output_train_generator = output_image_dataset.flow_from_directory(output_data_dir,\r\n                                                    target_size=(image_size, image_size),\r\n                                                    batch_size=batch_size,\r\n                                                    class_mode=None,\r\n                                                    subset='training')`\r\n\r\n`output_validation_generator = output_image_dataset.flow_from_directory(output_data_dir,\r\n                                                    target_size=(image_size, image_size),\r\n                                                    batch_size=batch_size,\r\n                                                    class_mode=None,\r\n                                                    subset='validation')`\r\n\r\n\r\n`model_1 = tf.keras.Sequential([\r\n    keras.layers.Conv2D(512,3,2,padding='same'),\r\n    keras.layers.Dropout(0.5),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.Conv2D(512,3,2,padding='same'),\r\n    keras.layers.Dropout(0.5),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.Conv2D(512,3,2,padding='same'),\r\n    keras.layers.Dropout(0.5),\r\n    keras.layers.BatchNormalization(),\r\n])`\r\n\r\n`model_2 = tf.keras.Sequential([\r\n    keras.layers.Conv2DTranspose(512,3,2,padding='same'),\r\n    keras.layers.Dropout(0.5),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.Conv2DTranspose(512,3,2,padding='same'),\r\n    keras.layers.Dropout(0.5),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.Conv2DTranspose(3,3,2,padding='same')\r\n])`\r\n\r\n`model = tf.keras.Sequential([\r\n    keras.layers.Input(shape=(image_size,image_size,2)),\r\n    model_1,\r\n    model_2\r\n])`\r\n\r\n`optimizer = keras.optimizers.Nadam(learning_rate=1.0,clipvalue=0.5)`\r\n\r\n`model.compile(optimizer=optimizer,\r\n             loss='mean_absolute_error',\r\n             metrics=['mean_absolute_error'])`\r\n\r\n`epochs = 10`\r\n`steps_per_epoch = 1.5*(train_generator.n//batch_size)`\r\n`validation_steps = (validation_generator.n//batch_size)`\r\n`print(steps_per_epoch)`\r\n`history = model.fit_generator(generator=(train_generator,output_train_generator),\r\n                             epochs = epochs,\r\n                             steps_per_epoch = steps_per_epoch,\r\n                             workers = 4,\r\n                             validation_data=(validation_generator,output_validation_generator),\r\n                             validation_steps = validation_steps)`\r\n\r\nBut when I ran the code it's not working and giving me an error.\r\n\r\nFile \"C:\\Users\\kirut\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\", line 477, in convert_to_generator_like\r\n    num_samples = int(nest.flatten(data)[0].shape[0])\r\nAttributeError: 'DirectoryIterator' object has no attribute 'shape'`", "comments": ["Found the error.\r\nTry to give autoencoder input and output by different generators."]}, {"number": 36412, "title": "tflite conversion", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):\r\n- TensorFlow installed from (pip3 install tensorflow==1.13.1):\r\n- TensorFlow version (1.13.1):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CAST, MEAN, PACK. Here is a list of operators for which you will need custom implementations: DecisionTreeResourceHandleOp, TreeSize.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n\r\n\r\n", "comments": ["@dimridd,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "These don't seem to be popular TF ops. You might need to implement TFLite [custom ops](https://www.tensorflow.org/lite/guide/ops_custom) to perform their behavior. \r\n\r\nAlso look at our [general advice in the FAQ](https://www.tensorflow.org/lite/guide/faq#why_doesnt_my_model_convert) to handle unsupported ops.\r\n\r\nThanks!"]}, {"number": 36411, "title": "parallel fulfillment of bf162fp32 in sparsematmul op", "body": "Here I see the TODO event: https://github.com/tensorflow/tensorflow/blob/073460df145807ce4968718db793d8e2675b9d7e/tensorflow/core/kernels/sparse_matmul_op.cc#L1001-L1013\r\nfrom **agarwal** to parallel the implementation of BF16TOFP32.\r\nMaybe agarwal will be the the appropriate reviewer?", "comments": ["Add the unit test and benchmark.\r\nIn the origin serial implementation the benchmark result is:\r\n```\r\nBenchmark                    Time(ns) Iterations\r\n------------------------------------------------\r\nBM_FloatToBFloat16            8773570        100         22946.9MB/s 3824.5M items/s\r\nBM_BFloat16ToFloat           14875610        100         13534.0MB/s 2255.7M items/s\r\n```\r\nAfter add the parallel implementation with 4 threads:\r\n```\r\nBenchmark                    Time(ns) Iterations\r\n------------------------------------------------\r\nBM_ParallelFloatToBFloat16    2340032        310         86035.8MB/s 14339.3M items/s\r\nBM_ParallelBFloat16ToFloat    5226723        159         38518.7MB/s 6419.8M items/s\r\n```", "Hi @rmlarsen, Sorry to interrupt. But any comments to this PR? :)", "@ezhulenev Thanks for the review. Change the lambda function name styles.", "Close this one it seems Eigen has the implemented the intrinsics version."]}, {"number": 36410, "title": "[lite] Remove possible redundant/nullptr add_op", "body": "op_producing_add_input can still be null while add_op is not null - due to multiple 'continue' (error cases) statements within the for loop.", "comments": []}, {"number": 36409, "title": "[lite] Remove possible nullptr sum_op", "body": "op_producing_add_input can still be null  while sum_op is not null - due to multiple 'continue' statements within the for loop.", "comments": []}, {"number": 36408, "title": "[lite] pass array_names by const ref", "body": "[Efficiency] Avoid extra copy for read-only. pass array_names by constant reference instead of by value.", "comments": ["@jdduke done. Thank you."]}, {"number": 36407, "title": "ImportError: DLL load failed: The specified module could not be found.  OS Windows 10 , Tensorflow cpu version", "body": "python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\skmishra\\AppData\\Local\\Continuum\\anaconda3\\envs\\FOODRECOGNITION\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["same problem with TF 2.1.0 and cuda10.0 or cuda10.1", "Try these methods :\r\n1. Try using Python 3.7 (Make sure you don't have other higher versions of Python installed)\r\n2. Try using 64 bit version of Python 3.7\r\n3. Use \"conda install tensorflow\" in the specific environment.", "What version of TensorFlow is this? Is this 2.1, nightly, are you building from source etc.?", "Looks like [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) can help and is related?", "Hi @MISSEY,\r\n\r\nDid you install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019?\r\n\r\nAccording to the docs at https://www.tensorflow.org/install/pip,\r\n\r\n> Install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. Starting with the TensorFlow 2.1.0 version, the msvcp140_1.dll file is required from this package (which may not be provided from older redistributable packages). The redistributable comes with Visual Studio 2019 but can be installed separately:\r\n\r\n> Go to the [Microsoft Visual C++ downloads](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads),\r\nScroll down the page to the Visual Studio 2015, 2017 and 2019 section.\r\nDownload and install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 for your platform.\r\nMake sure [long paths](https://superuser.com/questions/1119883/windows-10-enable-ntfs-long-paths-policy-option-missing) are enabled on Windows.\r\n\r\n> Install the [64-bit Python 3 release](https://www.python.org/downloads/windows/) for Windows (select pip as an optional feature).\r\n\r\nTensorflow 2.1.0 is compiled using MSVC 2019, which appears to require an additional DLL.", "I installed C++ 2019 and fixed this problem\r\n"]}, {"number": 36406, "title": "[lite] check index channel before accessing center_frequencies_", "body": "Check index channel before accessing center_frequencies_ since the order of execution for the expression is always left to right.", "comments": []}]