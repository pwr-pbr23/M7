[{"number": 4972, "title": "Verify file_io.create_dir and file_io.list_directory in GCS test .", "body": "", "comments": ["@anand-c-goog, thanks for your PR! By analyzing the history of the files in this pull request, we identified @caisq to be a potential reviewer.\n", "Can one of the admins verify this patch?\n", "@tensorflow-jenkins, test this please.\n"]}, {"number": 4971, "title": "Center loss", "body": "It seems that center loss seems good in the recognition area to minize the variation of cluter. There is a caffe implementation of this loss. \nURL: https://github.com/ydwen/caffe-face/\n\nI wrote some code but it seems not correct:\n\n``` Python\ndef center_loss(features, labels, name):\n    with tf.name_scope(name=name):\n       feat_dim = features.get_shape().as_list()[1]\n       batch_size = features.get_shape().as_list()[0]\n       centers = tf.get_variable('center', shape=[FLAGS.num_classes, feat_dim])\n       # compute loss & update center\n       loss = 0\n       for i in range(batch_size):\n           ft = features[i, :]\n           idx = labels[i]\n           c = tf.gather(centers, idx)\n          loss += tf.reduce_mean(tf.square(tf.sub(ft, c)))\n      loss /= batch_size\n```\n\nIs there can help me to understand better with Tensorflow, I can make a PR.\n", "comments": ["This was tagged as a feature request but you seem to be asking for support. [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) is a better venue for these types of questions. We rely on the community to offer support to our users.\n", "https://github.com/godfanmiao/MNIST_CNN_CENTERLOSS_TENSORFLOW"]}, {"number": 4970, "title": "CRC Error on Retraining Inception_v3", "body": "Hi.\n\nI tried to follow the tutorial given on https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html. I'm on MacOS Sierra and installed a separate version of python via homebrew, which is located in \"/usr/local/bin/python\".\n\nNow, I installed and compiled tensorflow from source and set the python location to \"/usr/local/bin/python\" and the library path to \"/usr/local/lib/python2.7/site-packages\". After compiling the retrain files, I get an error on running \n\n```\nbazel-bin/tensorflow/examples/image_retraining/retrain` --image_dir ~/flower_photos\n```\n\nwhich is\n\n```\nTraceback (most recent call last):\n  File \"/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 1014, in <module>\n    tf.app.run()\n  File \"/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 752, in main\n    maybe_download_and_extract()\n  File \"/Users/marcel/dev/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 314, in maybe_download_and_extract\n    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 2079, in extractall\n    self.extract(tarinfo, path)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 2116, in extract\n    self._extract_member(tarinfo, os.path.join(path, tarinfo.name))\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 2192, in _extract_member\n    self.makefile(tarinfo, targetpath)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 2233, in makefile\n    copyfileobj(source, target)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 266, in copyfileobj\n    shutil.copyfileobj(src, dst)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 49, in copyfileobj\n    buf = fsrc.read(length)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 831, in read\n    buf += self.fileobj.read(size - len(buf))\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 743, in read\n    return self.readnormal(size)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 758, in readnormal\n    return self.__read(size)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/tarfile.py\", line 748, in __read\n    buf = self.fileobj.read(size)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.py\", line 268, in read\n    self._read(readsize)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.py\", line 315, in _read\n    self._read_eof()\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/gzip.py\", line 354, in _read_eof\n    hex(self.crc)))\nIOError: CRC check failed 0x39de13a7 != 0x630e11cfL\n```\n\nAny insights on that? Sounds like the download is corrupted and I already re-downloaded the images several times. I think it actually doesn't rely on the images, because the error is the same no matter what directory I hand to --image_dir.\n\nThanks in advance\n", "comments": ["It seems issues like this have come up before in #3401. Could you try manually downloading with:\n\n```\nwget -O /tmp/imagenet/inception-2015-12-05.tgz http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\n```\n\nAnd see if that solves your problem?\n", "Also can you do me a favor and run:\n\n```\ncurl -I --noproxy '*' http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\n```\n\nAnd paste the output into this issue?\n\nSee also: tensorflow/models#541\n", "First of all, thanks for your help. This is the output of the curl:\n\n```\nHTTP/1.1 200 OK\nX-GUploader-UploadID: AEnB2UpUAytFdWWiywt5qa2nJ7oHtP-1dnGOjhvQtIT57Wumy13dxfddFfIH32dm4LTvdu0eJOb6txr3LjSXUWUmzdzfbeqG_A\nExpires: Mon, 17 Oct 2016 09:02:37 GMT\nDate: Mon, 17 Oct 2016 08:02:37 GMT\nCache-Control: public, max-age=3600\nLast-Modified: Sat, 05 Dec 2015 02:23:10 GMT\nETag: \"28395d1479e87ee86da70419d1ba2c3c\"\nx-goog-generation: 1449282190011000\nx-goog-metageneration: 2\nx-goog-stored-content-encoding: identity\nx-goog-stored-content-length: 88931400\nContent-Type: application/x-compressed-tar\nx-goog-hash: crc32c=ef9Stw==\nx-goog-hash: md5=KDldFHnofuhtpwQZ0bosPA==\nx-goog-storage-class: STANDARD\nAccept-Ranges: bytes\nContent-Length: 88931400\nServer: UploadServer\n```\n\nI'll try to manually download the model now and see if it works, will post back later :)\n\nEdit: Everything seems to work now. I first tried it with the implicit download of the model (so I didn't point it to my manually downloaded file) and it strangely enough worked. The retraining process is running currently and smoothly thus far. I think this can be closed, thanks again!\n"]}, {"number": 4969, "title": "Messy in Python API Docs - state_ops.html#constant_initializer", "body": "https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#constant_initializer\n\nOn Constant Initializer  -> Examples:\n\nThe very large gray box contains the html of other initializer docs. Hope it can be fixed. \n", "comments": ["Error is because https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/python/ops/init_ops.py#L142 isn't closing the code block I think. \n", "This is a duplicate of #4849 which has been corrected at HEAD. The site will be updated shortly.\n", "This is fixed at master and r0.12\r\nWe will not merge the fix back to 0.11, therefore closing the issue."]}, {"number": 4968, "title": "TensorFlow produces arbitrary results without error when using large amounts of GPU memory", "body": "### Environment info\n\nOperating System: Docker container based on `nvidia/cuda:7.5-cudnn5-devel` running on CentOS\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed: `pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp34-cp34m-linux_x86_64.whl`\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\n0.11.0rc0\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n``` python\nimport numpy as np\nimport tensorflow as tf\n\nmb = 100\nsz = int(mb * 1e6 / 4)\ntotal_gb = 11\nn = int(total_gb / mb * 1000)\nx = np.array(np.random.randn(sz), dtype=np.float32)\n\nwith tf.Graph().as_default():\n    place = tf.placeholder(tf.float32, shape=[sz])\n    with tf.device('/gpu:0'):\n        x_gpu = [tf.Variable(place, dtype=tf.float32) for i in range(n)]\n    init = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        sess.run(init, feed_dict={place: x})\n        # I know it's not optimal, but to make it more comparable to the Theano code below\n        x_out = [sess.run(v) for v in x_gpu]\n\ndelta = [np.sum(np.abs(xi - x)) for xi in x_out]\nprint(delta)\n```\n\nExecuted using `python3 memcheck_tensorflow.py`\n#### Expected output:\n\n```\nsome tensorflow output ...\n\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n```\n#### Actual output:\n\n```\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: Tesla K40m\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:81:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:81:00.0)\n[28209880.0, 28208760.0, 28208760.0, 28209880.0, 28206538.0, 28208760.0, 28212806.0, 28209880.0, 28209880.0, 28208760.0, 28211926.0, 28209880.0, 28208760.0, 28209880.0, 28209880.0, 28206538.0, 28206538.0, 28209880.0, 28208760.0, 28212806.0, 28208760.0, 28209880.0, 28209880.0, 28209880.0, 28207726.0, 28208760.0, 28206538.0, 28209880.0, 28206538.0, 28210806.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209880.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28209472.0, 28206602.0, 28209472.0, 28209472.0, 28208760.0, 28208760.0, 28209880.0, 28208760.0, 28207726.0, 28209880.0, 28208760.0, 28208760.0, 28209880.0, 28209880.0, 28206602.0, 28209880.0, 28209880.0, 28208760.0, 28209880.0, 28209880.0, 28209880.0, 28208760.0, 28206538.0, 28209880.0, 28209880.0, 28208760.0, 28208760.0, 28206602.0, 28207726.0, 28209880.0, 28207726.0, 28209880.0, 28209880.0, 28209880.0, 28211926.0, 28209880.0, 28208760.0, 28209880.0, 28208760.0, 28208760.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28206538.0, 28209880.0, 28209880.0, 28209880.0, 28209880.0, 28210806.0, 28209880.0, 28208760.0, 28208760.0, 28209880.0, 28206538.0, 28208760.0, 28209880.0, 28206602.0, 28208760.0, 28208760.0]\n```\n### What other attempted solutions have you tried?\n\nI've verified that this problem exists on at least one other GPU (I've seen it on Nvidia GPUs K40m and K80).\n\nI've run similar code in Theano without any problems (same GPU, same Docker container):\n\n``` python\nimport numpy as np\nimport theano\n\nmb = 100\nsz = int(mb * 1e6 / 4)\ntotal_gb = 11\nn = int(total_gb / mb * 1000)\nx = np.array(np.random.randn(sz), dtype=np.float32)\n\nx_gpu = [theano.shared(x) for i in range(n)]\nx_out = [v.get_value() for v in x_gpu]\n\ndelta = [np.sum(np.abs(xi - x)) for xi in x_out]\nprint(delta)\n```\n\nExecuted using `THEANO_FLAGS=device=gpu,floatX=float32 python3 memcheck_theano.py`\n#### Output\n\n```\nUsing gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5103)\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n```\n", "comments": ["@jonasrauber : Thanks for the report. Unfortunately (or perhaps fortunately :), I've been unable to reproduce this, albeit I tried this on a K40c, not a K40m. \n\nTwo requests of you:\n- Take a look at what I tried below and let me know if (a) the same commands yield different output  for you, and/or (b) If you spot some differences between what I did and what you're doing \n- Does the output consist of all zeros if you use less than 11GB of memory?\n\nHere's what I did:\n\n```\nnvidia-docker run -it nvidia/cuda:7.5-cudnn5-devel\napt-get update\napt-get install -y python3 python3-pip\npip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp34-cp34m-linux_x86_64.whl\n# Created memcheck.py from your code snippet above\npython3 memcheck.py\n```\n\nAnd this is the output:\n\n```\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: Tesla K40c\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:05:00.0\nTotal memory: 11.17GiB\nFree memory: 11.10GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:05:00.0)\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n```\n", "Unfortunately, I see this output:\n\n```\nroot@ce0a1cd826d9:/tmp# python3 memcheck.py \nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: Tesla K40m\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:81:00.0\nTotal memory: 11.25GiB\nFree memory: 11.15GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:81:00.0)\n[28218290.0, 28205566.0, 28205566.0, 28218290.0, 28220230.0, 28218290.0, 28205376.0, 28205566.0, 28218290.0, 28207506.0, 28221894.0, 28221212.0, 28219170.0, 28218290.0, 28218290.0, 28220834.0, 28203484.0, 28207506.0, 28207506.0, 28205566.0, 28221212.0, 28217608.0, 28217608.0, 28204444.0, 28204444.0, 28204184.0, 1418863.9, 28204444.0, 28219348.0, 28222026.0, 28221894.0, 2839692.5, 28220834.0, 0.0, 28218290.0, 28220834.0, 28203254.0, 28218290.0, 28220834.0, 28221894.0, 28204444.0, 28205570.0, 28222026.0, 28221894.0, 28220508.0, 28220834.0, 28204444.0, 28220834.0, 28220834.0, 28221894.0, 28204444.0, 28203254.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 0.0, 28219480.0, 28220508.0, 28204444.0, 0.0, 28205376.0, 28220834.0, 28205376.0, 28205376.0, 2839692.5, 0.0, 28204444.0, 28221894.0, 28203254.0, 4258556.5, 28205376.0, 28221894.0, 28222026.0, 0.0, 2839692.5, 4258556.5, 2839692.5, 28219480.0, 28204184.0, 28204444.0, 28220834.0, 28219348.0, 28221894.0, 28220834.0, 28220834.0, 28221894.0, 28220834.0, 0.0, 28221894.0, 28204184.0, 28221894.0, 3286809.0, 0.0, 26801648.0, 28220834.0, 2839692.5, 28221894.0, 0.0, 0.0, 28220834.0, 28221894.0, 28221894.0, 28220834.0, 25380614.0, 5679584.0, 0.0, 28221894.0, 4258556.5, 0.0]\n```\n\nAt least on one GPU, I get this starting at **5 GB**.\n\nWhen I limit the `per_process_gpu_memory_fraction` to 0.7 (to 8 GB), it works fine until 8 GB (I get zeros!) and for 9 GB and higher, it's out of memory.\n\n```\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\nconfig = tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False)\nwith tf.Session(config=config) as sess:\n```\n\nIn principle, I would think it's a hardware or driver issue, but then I should be able to reproduce it with another framework.\n", "@zheng-xq Any ideas?\n", "Still not sure, but it looks more and more like a hardware issue on some but not all of our GPUs. But we are still investigating, I'll keep you posted. In the meantime, I would be very happy to hear from anyone being able to reproduce this or encountering other related problems. We originally spotted the problem when running VGG-19 evaluations and sometimes obtaining obviously wrong accuracies but no errors. \n", "Not sure what is the root cause of this issue, but wondering if upgrading to CUDA 8.0 and using the latest release 0.11.0rc1(w/ CUDA support) would help?\n", "I have some news to share. After upgrading the nvidia drivers from 352.39 to 367.48, I was not able to reproduce this problem anymore (neither with cuda7.5 nor cuda8.0). When I have some more time, I'll run some additional experiments but until then I consider the upgrade to 367.48 as a solution to this problem and propose to close this issue.\n", "Thanks for the update.\nOld drivers have some known GPU memory issues, so driver update solving this makes sense.\nI will unblock the release on this issue now, but please keep us posted.\n", "@jonasrauber : I'll close this out for now. Do re-open if you start suspecting something other than the driver-version/CUDA-library compatibility. Thanks!\n", "same issue on NVIDIA-SMI 381.22\r\n\r\n\r\n\r\n\r\n\u279c  data_in_446Hz_and_uV nvidia-smi\r\nFri May 11 18:32:08 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 381.22                 Driver Version: 381.22                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 0000:02:00.0     Off |                  N/A |\r\n| 49%   82C    P2   262W / 250W |  10650MiB / 11172MiB |     85%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 0000:03:00.0     Off |                  N/A |\r\n| 23%   38C    P8    17W / 250W |   8166MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      8197    C   python                                        3995MiB |\r\n|    0     19069    C   python                                        6611MiB |\r\n|    1      8197    C   python                                         151MiB |\r\n|    1     19069    C   python                                        7971MiB |\r\n+-----------------------------------------------------------------------------+\r\n\u279c  data_in_446Hz_and_uV \r\n"]}, {"number": 4967, "title": "Update protobuf to get a fix from upstream", "body": "We already have a fix in protbuf https://github.com/google/protobuf/pull/2246\nThis makes TF build with Bazel at HEAD again.\nFix https://github.com/bazelbuild/bazel/issues/1929\n\nI understand TF is currently using a release version of protobuf, is this change acceptable?\n\nBTW @mrry 's fix will also get fetched by this change\nhttps://github.com/google/protobuf/pull/2203\n", "comments": ["@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @kashif, @kirilg and @jart to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Mr. Jenkins: test this please\n", "We'll find out in a moment if it's acceptable.\n", "Approved. I'll let the sync oncall merge this.\n\nTangential: I noticed our protobuf rules don't build with Bazel sandboxing enabled. This seems to be related to the upstream fix. But the problem does go deeper with us. I filed #4974.\n", "I just spotted another issue reporting this @rohan100jain. It might be better if I just go ahead and merge this to fix the build.\n"]}, {"number": 4966, "title": "Android example giving wrong results on Samsung Galaxy A3", "body": "I've built the android demo and installed the same APK on 3 phones: Samsung S6, HTC one M9, and Samsung Galaxy A3. \nOn the Galaxy A3 only the results are wrong; whereas the other phones give sensible results for various things in the office (photocopier, monitor, laptop etc) the A3 produces much lower scores and suggests things like oscillascope and nematode.\n\nAdditionally, the preview window is small and skewed. Suspecting an odd resolution might have confused things, I forced it to 640*480 but the problem persists. \n\nI do not know whether this is unique to the A3 .\n", "comments": ["Hi, would you mind posting a screenshot and the adb log please? Also you can grab the actual image being classified by turning on SAVE_BITMAP in TensorFlowImageListener.java, which could be helpful to see.\n", "Also, what version of Android is your A3 running?\n", "I'm afraid the phones are at work; I'll provide the requested details on Monday. \nSorry.\n", "I believe this is the requested information. \n\nScreenshot (For comparison, most other phones would say photocopier)\n![screenshot_2016-10-17-09-45-59](https://cloud.githubusercontent.com/assets/6673752/19431097/ef44edd6-944e-11e6-8275-14e2d9991b08.png)\n\nPreview image, which seems rather bad!\n![preview](https://cloud.githubusercontent.com/assets/6673752/19431103/f3c0d3b6-944e-11e6-90ee-87ae7a0e20e5.png)\n\nadb log\n[TensorFlow_A3.txt](https://github.com/tensorflow/tensorflow/files/532792/TensorFlow_A3.txt)\n\nI cannot promise that the preview image matches the same run through the network as the screenshot.\n", "Samsung Galaxy A3 comes by default with Android 4.4.4.\n\nAnd it seems that the [ImageUtils.convertYUV420ToARGB8888](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowImageListener.java#L164) function that makes the conversion from raw camera output to RGB format isn't compatible with versions of Android < 5.1.1 due to a [bug on android](https://code.google.com/p/android/issues/detail?id=81984)\n\nSee issues [#4911](https://github.com/tensorflow/tensorflow/issues/4911) and [#306](https://github.com/tensorflow/tensorflow/issues/306)\n\nSo the solution is to update Android to +5.1.1, or adapt YUV2RGB function to this version of Android.\n", "Thank you for the information.\n"]}, {"number": 4965, "title": "Feature request: Hamiltonian Monte Carlo ", "body": "Hamiltonian Monte Carlo (HMC), also known as Hybrid Monte Carlo, is an efficient Markov Chain Monte Carlo (MCMC) method that exploits gradient information to improve on the simpler MCMC methods. See this freely available book chapter by Radford Neal:\n\nhttp://www.mcmchandbook.net/HandbookChapter5.pdf\n\nIt has been successfully applied to Bayesian inference in Neural Networks, again  by Neal. See for instance Neal's thesis which later became a book:\n\nhttp://www.cs.toronto.edu/~radford/ftp/thesis.pdf\n\nHMC is heavily used in modern Bayesian modelling, For instance, HMC and its variants are the primary inference method for Stan, a popular probabilistic programming language:\n\nhttp://mc-stan.org/\n\nIt would be useful to be able to use HMC in TensorFlow much as one is currently able to use Optimizers such as Adam or Momentum optimization. Much of the requisite code would be similar to the optimizer code which can be found here:\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/training\n\nI've raised this feature request as a place to discuss the potential addition of HMC to TensorFlow. \n", "comments": ["@alexggmatthews Interesting. Can you motivate for starting with HMC in particular? Why not plain old MCMC, nested sampling, parallel tempering, etc. etc. etc..?\n\nI'm not convinced that, of all the MC methods, it is in heavy use - am I wrong/do you have examples of applications?\n", "@jtlz2 Thanks for your interest.\n\nI guess by \"plan old MCMC\" you mean the Metropolis-Hastings (MH) algorithm. The MH algorithm uses a random walk and often mixes slower than HMC because it doesn't use gradients. The autodiff in TensorFlow means that gradients would be readily available and it would be a shame to ignore them. \n\nNested sampling and parallel tempering are interesting methods but they are significantly more complex. \n\nI do believe that HMC has been found to be useful in a broad variety of probabilistic modelling tasks. As already stated the popular Stan library uses HMC and its variants. Perhaps have a look at the extensive list of case studies on that web page:\n\nhttp://mc-stan.org/documentation/case-studies.html\n", "@alexggmatthews Sorry yes I did mean MH. Thanks for the link - I think I am biased(..) because in astronomy, where fully bayesian methods have made great leaps, I haven't yet seen a decent, available HMC implementation - that method in particular seems to have been fraught with difficulty - and I haven't understood why.\n\nSo I will watch this space......\n", "Just to add, Alex is completely correct. HMC is the go-to method for sampling when the variables are continuous. Aside from STAN,  pymc uses HMC (https://github.com/pymc-devs/pymc3). Also Edward (https://github.com/blei-lab/edward) and I'm sure there are numerous R packages too.\n\nSome other people who I'm sure would love to see this are @davmre, @dustinvtran, @akucukelbir and @goldingn, who are all working on tensorflow-based software that uses or could use HMC. \n", "cool!\n\njust a note: stan by default uses nuts, which is a powerful adaptive extension of hmc. this algorithm is arguably what makes stan's sampling option work so well \"straight out of the box\". \n\nhere's the paper for nuts (matt d hoffman and andrew gelman): \n\nhttp://www.jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf\n", "Thanks @alexggmatthews, @jameshensman! This discussion is sure to be useful. I'm also looping in a few others who I've chatted about this stuff in detail: @matthewdhoffman, @ebrevdo, @murphyk, @jvdillon (among those who I can find their GitHub username).\n\nFirst, we might want to consider the general problem of how to implement posterior inference algorithms. That is, if we want HMC inside TensorFlow, we'd like an implementation that naturally extends to other algorithms\u2014whether it be other MCMC, variational inference such as BBVI and SVI, or even exact inference such as conjugacy. After all, it can be difficult to predict what algorithms are most applicable in the future. And certainly for inference developers like us, being able to experiment with many algorithms is handy.\n\nVery quickly this runs into open research challenges, in the general scope of probabilistic programming.\n\nFor example, how do we design the interface to inference algorithms? For point estimation, it's clear using TensorFlow optimizers. They simply need a `loss` tensor, and they modify the state of variables in the graph, which serve as parameters. And maybe in the case of HMC and BBVI, it's easy to assume the user passes in a function or class that implements a model's `log_joint(x, z)` density. But this doesn't extend to algorithms which take advantage of structure: for example, Gibbs, SVI, and expectation propagation. \n\nUltimately, my perspective is that a proper implementation of inference first requires a proper modeling language, with structure exposed to the user. And we can't necessarily work with classes and manual methods such as `model.log_joint`, `model.log_lik`, `model.log_prior`, etc.\n\nDesign problems like these are very important. Without solving them, we quickly constrain ourselves on either the class of models or inference algorithms available in the framework. For example, as far as I'm aware, there is no probabilistic programming language that can properly handle data subsampling on global and local latent variables\u2014a crucial property to scale to large datasets.\n\n[Edward](http://edwardlib.org) is one proposed solution for issues like these. (With the caveat of self-advertising, I recommend a relevant [talk I gave at Twitter](https://www.periscope.tv/w/1yNGanvpOPjJj) a month ago.) Another proposed solution is by [`BayesFlow`](https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.bayesflow.variational_inference.html). Both proposals require additional abstractions, and perhaps this necessitates a layer of higher level API that's separate from the lower-level TensorFlow functions.\n", "@dustinvtran Thanks for your perspective. I agree that being able to switch among the different algorithms easily would be very helpful. Sometimes, users just want to approximate some tricky integral as part of a larger model and don't feel tied to any particular method for doing so.  I was wondering if you could expand on what TF needs to add/change to be suitable as a probabilistic modeling language? \n", "Is the language used by Stan not \"a proper modeling language, with structure exposed to the user?\"\n\nObviously it's not perfect by any stretch, and could benefit from a lot of tweaking especially for variable types and manipulation simplifications, but the structure seems correct, at least in theory. (Are there other drawbacks that are more fundamental?)\n", "First a quick correction: Metropolis-Hastings is a general procedure for constructing Markov chains that target a specified distribution using a proposal distribution.  _Random Walk Metropolis_ is the implementation of Metropolis-Hastings using a Gaussian proposal distribution, and it's Random Walk Metropolis that scales so poorly.  The difference is important because even algorithms like Hamiltonian Monte Carlo can be cast as certain Metropolis-Hastings implementations.\n\nHamiltonian Monte Carlo is absolutely critical to scaling Markov chain Monte Carlo up to anything more than O(10) dimensions, and while we could have a long theoretical argument as to why it's probably easier to offer empirical data.  Just search Google scholar for \"mc-stan.org\" or take a look at the papers at http://mc-stan.org/citations/.  Unfortunately there is significant misinformation in many fields, including astronomy, that confounds discussions and comparisons of methods and slows the adoption of techniques like Hamiltonian Monte Carlo.  That said, here are three examples where the analyses would not have worked with any other Markov chain Monte Carlo algorithm: https://arxiv.org/abs/1507.01602, https://arxiv.org/abs/1404.2004, https://arxiv.org/abs/1606.05770.\n\nAll of that said, what is the relevance for Hamiltonian Monte Carlo (or its efficient implementations like the No-U-Turn sampler) in languages like TensorFlow?  As an algorithm, Hamiltonian Monte Carlo takes the target log probability density and its gradient and then generates an extremely efficient Markov transition.  Importantly, there is essentially no room for parallelization in the algorithm itself, and hence no opportunity to exploit the main features of TensorFlow.  Instead, any exploitation would have to come in the calculation of the log probability density and its gradient.  Even then, any potential benefit, as @dustinvtran suggested, depends strongly on the exact structure of the log probability density function.  If TensorFlow is ignorant to this structure then it cannot exploit it, and even it it can identify this structure then it can exploit it only if the structure is appropriate (the more complex the model, the less opportunities for parallelization and other speed ups).\n\nAs a modeling language Stan focuses on specifying the log posterior density as a continuous function amenable to automatic differentiation and does not try to identify any particular structure in that function that could be exploited.  I disagree with @dustinvtran that this makes the language \"improper\", but that's an ill-defined term anyways.  More generally, I am very strongly of the opinion that exploiting bespoke structure of a particular model is not significantly useful for scaling statistical computation.  The kinds of structures required for significant speedups without drastically compromising accuracy are limited to very simple models, essentially models that only weakly deviate from independent Gaussians, which are never really capture the structure in realistic data sets.  I should note that this opinion is backed up by many, many experiments and plenty of theory!\n\nTo summarize: given its automatic differentiation engine, there is no reason why the No-U-Turn sampler cannot be implemented in TensorFlow.  In fact, it would be a straightforward port of the Stan implementation, https://github.com/stan-dev/stan/blob/develop/src/stan/mcmc/hmc/nuts/base_nuts.hpp, as demonstrated by the PyMC developers.  One should not expect a significant performance gain over existing implementations, but that's no reason to provide an implementation to existing TensorFlow users.  If anyone wants to work on an implementation and has any questions, I'm happy to answer.\n\nAs a postscript, I should note that I've always been bitter about the naming of TensorFlow as Hamiltonian Monte Carlo was pushing tensor fields along flows for decades before TensorFlow was released.  \ud83d\ude09\n", "Wow that has certainly generated a lot of interesting discussion very quickly. \n\n@betanalpha Yes I was thinking of what you describe as Random Walk Metropolis. Sorry for the terminology. You make a strong case for the advantages of HMC as always . I agree generally with your summary but am perhaps more optimistic about the possibility of TF HMC running fast in some cases. We shall have to see.\n\n@dustinvtran you make some very interesting points about the interface for probabilistic inference in general. As you point out, in this specific case, it could be done in a way that really isn't that different from the current TF optimizer functionality. Judging by the level of interest on this thread I personally think such an implementation of HMC would be worth considering in parallel to the more complete probabilistic modelling interfaces that you and others work on. \n", "Just to confirm I'm very interested in this, for inference with lots of data and lots of linear algebra. As @betanalpha says, there's really no competitor to HMC in these cases.\n\nFor the use cases I have in mind, I'd want to write out the density in standard TensorFlow then use a TensorFlow method to sample from it with HMC, in much the same way as the current optimisers. I wouldn't be looking for an Edward- or STAN-like language for model specification for this use case (though I think both are awesome).\n\nA suite of samplers would seem like the obvious generalisation to me. HMC with NUTS or other adaptive/non-adaptive procedures; Metropolis-Adjusted Langevin algorithm?; there may even be cases where people want straightforward MH. Gibbs sampling (which requires understanding of conjugacy) doesn't fit in this pattern though. \n", "In other words, ditto @alexggmatthews who beat me to it :) \n", "Thanks @betanalpha for your in-depth comment!\n\nI agree with most of your points. However, I think incorporating structure such as conditional independence is crucial. It's certainly crucial \"for scaling statistical computation\" (see, for example, the many works on scalable MCMC: [Bardenet et al., 2015](https://arxiv.org/abs/1505.02827); [Angelino et al., 2016](https://arxiv.org/abs/1602.05221); [Andrieu and Roberts, 2009](https://projecteuclid.org/euclid.aos/1236693147); [Welling and Teh, 2011](http://www.icml-2011.org/papers/398_icmlpaper.pdf); [Chen et al., 2014](https://arxiv.org/abs/1402.4102); [Gelman et al., 2014](https://arxiv.org/abs/1412.4869); [Maclaurin and Adams, 2014](https://arxiv.org/abs/1403.5693)). Whether you believe in data subsampling is another thing ([Betancourt, 2015](https://arxiv.org/abs/1502.01510)), but I'm not sure if there are good alternative solutions.\n\n@alexggmatthews: Having a standalone HMC algorithm in TensorFlow would be awesome. To avoid becoming part of a higher-level API, its scope has to be deliberately designed, both in what extensions it allows and what it limits.\n", "From @davharris:\n\n> I was wondering if you could expand on what TF needs to add/change to be suitable as a probabilistic modeling language?\n\nThe notion of a random variable.\n", "Thinking about how to make HMC a first-class citizen seems like a great\nidea and I'm happy to help design this.  Naturally I'd have to confer with\nmy team prior to building anything, but I suspect they'd support this\neffort.  Our lack of nontrivial numerical integration tools has already\nimpacted the scope of other projects. Eg, the recently added `Bijector\n<https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distributions/python/ops/bijector.py>`\nAPI is limited to pdf and sample in the absence of numerical integration to\nsupport mean, variance, etc.\n\nOn Fri, Oct 14, 2016 at 4:53 PM, Dustin Tran notifications@github.com\nwrote:\n\n> From @davharris https://github.com/davharris:\n> \n> I was wondering if you could expand on what TF needs to add/change to be\n> suitable as a probabilistic modeling language?\n> \n> The notion of a random variable.\n> \n> Yes this is something I've been an advocate of for some time.  Having said\n> that, I wonder if StochasticTensor (ST) isn't all that we need to support\n> HMC?  Can you imagine needing something from ST that isn't there or worse,\n> that would be hard to add?\n\nFor our purposes, an RV is probably overkill--efficiently supporting a\nsigma-algebra is probably generally impossible.  I wonder if we really just\nneed the ability to compute densities and generate random variates?  (This\nis essentially what ST offers.)\n\nI think the real trick is that we need the variates to have context, ie,\nuse this particular random draw at this stage and use a different draw at a\ndifferent stage.  However this can be solved be requiring the second draw\nto be a different ST (despite having possibly the same parametrization).\nThere may be some performance cost here though, particularly wrt the size\nof the constructed graph.\n\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4965#issuecomment-253945988,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABFZtp1HDgDEuQO8KlunsINyYpkHjM46ks5q0BX_gaJpZM4KW4SN\n> .\n\n## \n\nJoshua V. Dillon, Ph.D.\njvdillon@gmail.com / http://www.almostsure.com\n\"If you work really hard and you're kind, amazing things will happen.\"\n   -- Conan O'Brien\n", "@jvdillon, although I'm really glad all this discussion happened, I don't think it illuminates what you need to get an implementation going. I'll try to describe what's necessary for you to implement HMC as an algorithm.\n\nHMC requires:\n- the evaluation of the log of the joint probability distribution function with respect to data and parameters up to an additive constant (constant with respect to parameters). I usually write this out as:\n  log p(X, theta)\n  where X is data, theta are the parameters, and p(X, theta) is the joint distribution function.\n- the evaluation of the gradients of the log joint distribution function above with respect to the parameters. That is:\n  d log p(X, theta) / d theta\n  usually you have multiple thetas (say 1000), so it's:\n  d log p(X, theta) / d theta_1, d log p(X, theta) / d theta_2, ..., d log p(X, theta) / d theta_1000\n  (You can see why we, at Stan, went with reverse-mode autodiff. This needs to be evaluated for every leapfrog step.)\n- math dictates that the log joint distribution function be continuous and differentiable for HMC to work; ignore this condition at your own risk. You can implement the algorithm and it'll do something, but it won't be guaranteed to do anything correctly.\n\nThings that are good for HMC:\n- transforming parameters using a change of variables so that the parameters have range -infinity to + infinity. If not, you have to implement bouncing, which is slow and hard generally.\n- evaluating the joint distribution function on the log scale due to floating point\n- implementing NUTS\n\nI don't know tensorflow well enough to write up the actual computation necessary, but if you wanted to put up a simple example, I can walk you through exactly what's required in order to implement HMC. Hopefully that clarifies what you need to be able to compute in order to use HMC.\n", "where would this go in the file directory if I wanted to help out? contrib?\n", "Please sync with josh dillon and matt hoffman by email before writing\ncode...\n\nOn Thu, Nov 3, 2016 at 4:20 PM, Christian Ng notifications@github.com\nwrote:\n\n> where would this go in the file directory if I wanted to help out? contrib?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4965#issuecomment-258302981,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim57s1f1NV0ldeUPN6wHoZ8Of_jydks5q6mwjgaJpZM4KW4SN\n> .\n", "HMC is in edward. there are experiments comparing it to stan and pymc3 in our [iclr submission](http://openreview.net/forum?id=Hy6b4Pqee). spoiler: it's _really_ fast. source:\n\nhttps://github.com/blei-lab/edward/blob/master/edward/inferences/hmc.py\n\n> Yes this is something I've been an advocate of for some time.  Having said\n> that, I wonder if StochasticTensor (ST) isn't all that we need to support\n> HMC?  Can you imagine needing something from ST that isn't there or worse,\n> that would be hard to add?\n\nyes that's the only abstraction needed. the hmc implementation in edward only requires a RandomVariable abstraction, which is a simplified version of ST. the question arises in that, should ST be part of tensorflow natively, and to what extent should inference algorithms in tensorflow support the sort of compositionality that's explained in the paper above.\n\nif there's an interest i can help move things from edward's implementation to native tensorflow.\n", "On Sun, Nov 6, 2016 at 8:07 PM, Dustin Tran notifications@github.com\nwrote:\n\n> HMC is in edward. there are experiments comparing it to stan and pymc3 in\n> our iclr submission http://openreview.net/forum?id=Hy6b4Pqee. spoiler:\n> it's _really_ fast. source:\n> \n> https://github.com/blei-lab/edward/blob/master/edward/inferences/hmc.py\n> \n> Yes this is something I've been an advocate of for some time. Having said\n> that, I wonder if StochasticTensor (ST) isn't all that we need to support\n> HMC? Can you imagine needing something from ST that isn't there or worse,\n> that would be hard to add?\n> \n> yes that's the only abstraction needed. the hmc implementation in edward\n> only requires a RandomVariable abstraction, which is a simplified version\n> of ST. the question arises in that, should ST be part of tensorflow\n> natively, and to what extent should inference algorithms in tensorflow\n> support the sort of compositionality that's explained in the paper above.\n> \n> if there's an interest i can help move things from edward's implementation\n> to native tensorflow.\n\nThis is definitely something I'd like to have native support for.  Im happy\nto do the porting or let you drive.  Please let me know how'd you like to\nproceed.\n\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4965#issuecomment-258743245,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABFZtjk37uptwQdLE_mdBhsq3OKdTto3ks5q7qQNgaJpZM4KW4SN\n> .\n", "On Mon, Oct 17, 2016 at 8:18 PM, Daniel Lee <notifications@github.com>\nwrote:\n\n> @jvdillon <https://github.com/jvdillon>, although I'm really glad all\n> this discussion happened, I don't think it illuminates what you need to get\n> an implementation going. I'll try to describe what's necessary for you to\n> implement HMC as an algorithm.\n>\nHi Daniel--thanks for your sharing thoughts. Responses inline.\n\n\n> HMC requires:\n>\n>    - the evaluation of the log of the joint probability distribution\n>    function with respect to data and parameters up to an additive constant\n>    (constant with respect to parameters). I usually write this out as: log\n>    p(X, theta) where X is data, theta are the parameters, and p(X, theta) is\n>    the joint distribution function.\n>    - the evaluation of the gradients of the log joint distribution\n>    function above with respect to the parameters. That is: d log p(X, theta) /\n>    d theta usually you have multiple thetas (say 1000), so it's: d log p(X,\n>    theta) / d theta_1, d log p(X, theta) / d theta_2, ..., d log p(X, theta) /\n>    d theta_1000 (You can see why we, at Stan, went with reverse-mode autodiff.\n>    This needs to be evaluated for every leapfrog step.)\n>\n> This is currently the most painful piece in TF. I'm currently looking into\nthe complexity of supporting a Jacobian op in TF.  Currently tf.gradients\nactually returns the tf.add_n of what would otherwise be the Jacobian.\n\n\n>\n>    - math dictates that the log joint distribution function be continuous\n>    and differentiable for HMC to work; ignore this condition at your own risk.\n>    You can implement the algorithm and it'll do something, but it won't be\n>    guaranteed to do anything correctly.\n>\n> Things that are good for HMC:\n>\n>    - transforming parameters using a change of variables so that the\n>    parameters have range -infinity to + infinity. If not, you have to\n>    implement bouncing, which is slow and hard generally.\n>\n> Part of the delay in supporting HMC is that we wanted to get our\nTransformedDistribution / Bijector API's dialed in.  I believe we're very\nclose to having something which has minimal feature readiness.\n\n>\n>    - evaluating the joint distribution function on the log scale due to\n>    floating point\n>    - implementing NUTS\n>\n> I don't know tensorflow well enough to write up the actual computation\n> necessary, but if you wanted to put up a simple example, I can walk you\n> through exactly what's required in order to implement HMC. Hopefully that\n> clarifies what you need to be able to compute in order to use HMC.\n>\nHmm I don't have a simple example in mind.  Perhaps you can think of a good\nexample?  If not that's ok too; I was planning on doing a light lit survey\nbefore delving in deeper.\n\n\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4965#issuecomment-254395765>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABFZttHabSZQMDpGRkvColm6WplGMbUxks5q1DprgaJpZM4KW4SN>\n> .\n>\n", "The eight schools example? That's small enough to reason about, but complex enough to hit enough weird conditions.", "If you agree, I'll put up the computation of the model in Stan and C++ with variants. ", "Is there movement on this?  Was an implementation ever tested?  Would a straight port of HMC from Edward or Stan be sufficient to proceed (I would submit this if there was interest)", "A more condensed version (i.e., without all the subclassing) of Edward's [`hmc.py`](https://github.com/blei-lab/edward/blob/master/edward/inferences/hmc.py) would be valuable and likely the easiest.\r\n\r\nAn open question is 1. how to represent the model; and 2. how to manage the output of the inferred posterior. \r\n\r\n1. Following [Bayesflow's implementation of variational inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/bayesflow/python/ops/variational_inference_impl.py#L173), a log joint representation makes sense. However, I'm not sure how to define what variables to infer without resorting to [Edward random variables](http://edwardlib.org/api/model) or [Bayesflow stochastic tensors](https://www.tensorflow.org/versions/master/api_docs/python/contrib.bayesflow.stochastic_tensor/).\r\n2. Following [TensorFlow optimizers](https://www.tensorflow.org/versions/master/api_docs/python/train/), Edward, and Bayesflow, I think inference should modify tf.Variables in place, perhaps returning a train op that the user runs in a loop. ", "@dustinvtran I agree with your second point.  As for the first, I have a more specific goal than generic usability, in that I am attempting to speed up a Sparse GP in GPflow that currently uses a vanilla python HMC.  That said, the answer to 1 would be to infer all variables in the feed_dict().  More generally though, I see your point.", "Hi folks. We've started to implement HMC and Metropolis Hastings in tensorflow.contrib.bayesflow.{hmc,metropolis_hastings}.  Please give this a whirl and tell us what works and what doesnt. Thanks!", "Oh, that's brilliant!\r\n\r\nThe ability to pass in a mass matrix for the parameters (a fixed estimate of the posterior variance-covariance matrix) would be really helpful for tuning the samplers.", "Excellent news. Did I remember that @dustinvtran is in Mountain View at the moment? Is he also involved? ", "@goldingn, Let me look into supporting this feature.\r\n@alexggmatthews, @dustinvtran is working with Bayesflow team.  Everyone has been involved in getting HMC implemented but currently Matt Hoffman (and to a much lesser extent, myself) did the work of implementing HMC. Over the coming months we'll all continue to improve and extend its functionality.", "Also as a heads-up: the API is highly subject to change. We're still exploring a few options but at least want to share good core implementations with the public. :-)", "Thanks for the info.  Amongst the options, are you considering an interface similar to a vanilla TF optimizer? We have cases in GPflow where we would want to swap out a TF optimizer, add a prior to the hyperparameter in question and then swap in a TF sampler, so this has always seemed like a natural option to us.", "Eventually we'd like to go that route. For now we're trying to encode this\nfunctionality through python callables.  Once we have a sufficiently rich\ncollection of reasonable callables (feel free to add yours!) then a more\nOptimizer like design seems prudent.\n\nOn Tue, Oct 31, 2017 at 2:33 AM, Alexander G. de G. Matthews <\nnotifications@github.com> wrote:\n\n> Thanks for the info. Amongst the options, are you considering an interface\n> similar to a vanilla TF optimizer? We have cases in GPflow where we would\n> want to swap out a TF optimizer, add a prior to the hyperparameter in\n> question and then swap in a TF sampler, so this has always seemed like a\n> natural option to us.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4965#issuecomment-340707797>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABFZtvpe6InDOy9tdIbPXBbw_ohL5Zlgks5sxulggaJpZM4KW4SN>\n> .\n>\n", "Hello everyone,\r\n\r\nIn _GPflow 1.0_ we had to implement our own _hmc_, [implementation here](https://github.com/GPflow/GPflow/blob/master/gpflow/training/hmc.py). Unfortunately, tensorflow implementation doesn't fit into our requirements.\r\n\r\n1. GPflow logprob function (objective) doesn't really have simple interface `fun(x)`. It is a combination of priors, unconstained and constrained values. Building correctly logprob requires GPflow parameter objects, so that we could pull some extra information, not bare list of tensors.\r\n2. GPflow objective has more than one parameter, therefore the python function should be `fun(x0, x1, ..., xn)`, not `fun(x)`. \r\n\r\nFrom my point of view first item uncovers the issue with pythonic functions which build objective tensor at each scan, map_fn or while_loop iteration in hmc. The interesting fact is that the objective tensor itself is a \"function\" in tensorflow graph and inputs are some tensorflow variables. So, the best option for GPflow now would be having the `tf.train.hmc` optimizer with similar protocol as gradient based optimizers have. I'm very interested  in that solution and ready to find time to implement it, but I'm not really sure where to look first in tensorflow. \r\n\r\nSecond problem can fairly easy be fixed at tensorflow's hmc. Here is a candidate for [PR](https://github.com/awav/tensorflow/blob/awav/hmc-with-multiple-variables/tensorflow/contrib/bayesflow/python/ops/hmc_impl.py#L50).\r\n\r\n_Quick notes about hmc implementation in GPflow_: because we can't create a pythonic function of the form `fun(x0, x1, ...) -> objective_tensor`, in each while_loop iteration we have to reuse same input variables, update them via `tf.assign` and manage execution using `control_dependencies`.\r\n\r\n", "Thanks for the details @awav. We're still thinking about the right design for MCMC in terms of TensorFlow idioms, flexibility, and composability. So far we've settled with two (possibly competing) approaches. One is which you aptly pointed out a few pain points, and another is a [tf.train.Optimizer-style design](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/bayesflow/python/ops/sgld_optimizer.py) which @JasperSnoek is helping lead.\r\n\r\nPerhaps we can discuss with you and other GPflows dev in a video call on how the APIs might suit your applications?", "@dustinvtran that sounds like a good idea thanks for getting back to us. I will talk to the other devs. I suppose another option would be to talk at NIPS. @awav is the one who nicely duked it out through all the \"pain points\". Suspect other devs will be keen too. \r\nI also keep finding Hamiltonian AIS extremely useful in my non GP work. It should be used more. ", "This is a great feature.  Thanks for working on it!\r\n\r\nI tried this out and compared to Matlab's HMC version.  The Matlab one is at the very least an order of magnitude faster, all else the same (see below for code).  I am using the base TF build that doesn't support the additional AVX instructions available for my CPU, but still....that seems like a huge diff.  Actually i run one more loop on the Matlab code even.  Curious if this is expected?\r\n\r\n''' Python Version'''\r\ndef log_joint(x):\r\n    return tf.log(tf.exp(-0.5*tf.square((x + 16)/1)) + tf.exp(-0.5*tf.square((x - 16)/1)))\r\nres = []\r\nfor n in range(1,10):\r\n    chain, acceptance_probs = tf.contrib.bayesflow.hmc.chain(1000, .5, 2, tf.random_uniform([1], -10, 10), log_joint, event_dims=[0])\r\n    # Discard first half of chain as warmup/burn-in\r\n    warmed_up = chain[500:]\r\n    res.extend(sess.run(warmed_up))\r\n\r\ndf = pd.DataFrame(np.concatenate(res))\r\ndf.plot.density()\r\n\r\n%%%%% Matlab\r\nmeans = [16,-16];\r\nstandevs = [1;1];\r\n\r\nsamples = zeros(500,10);\r\n\r\nlogpdf = @(theta)normalDistGrad(theta,means,standevs);\r\nfor n=1:10\r\n    startpoint = 20*rand-10;\r\n    smp = hmcSampler(logpdf,startpoint);\r\n    samples(:,n) = drawSamples(smp, 'burnin', 500, 'NumSamples', 500);\r\nend\r\n\r\nhistogram(samples, 50)\r\n\r\nfunction [lpdf,glpdf] = normalDistGrad(X,Mu,Sigma)\r\nlpdf = log(exp(-0.5*((X + Mu(1))/Sigma(1)).^2) + exp(-0.5*((X + Mu(2))/Sigma(2)).^2));\r\nglpdf = 1./(exp(-0.5*((X + Mu(1))/Sigma(1)).^2) + exp(-0.5*((X + Mu(2))/Sigma(2)).^2)) * ...\r\n(-((X + Mu(1))/Sigma(1))*exp(-0.5*((X + Mu(1))/Sigma(1)).^2)/Sigma(1) - ...\r\n((X + Mu(2))/Sigma(2))*exp(-0.5*((X + Mu(2))/Sigma(2)).^2)/Sigma(2));\r\nend\r\n", "Hi @awav, @johnpjust. Thanks for the feedback!  The Bayesflow team has reached a milestone ([1]) which allows us to allocate substantially more resources to creating high quality tooling for MCMC and other approximate inference functions. Let me digest your fantastic feedback and Ill post back with a revised game-plan ASAP.\r\n\r\n[1] - https://arxiv.org/abs/1711.10604", "Assign to @jvdillon ", "An initial consolidation is available at\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/bayesflow/python/ops/hmc_impl.py\r\n\r\nWe're making further refinements. But the core is ready for people to use. We would love feedback.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Closing this issue as we have a v2 implementation of HMC.  We'll of course further refine this but lets open new issues for any requested refinements."]}, {"number": 4964, "title": "Where is the documentation for contrib/layers? (Docs in general ...)", "body": "In another thread I asked about consolidation of the builder API's for TensorFlow. (https://github.com/tensorflow/tensorflow/issues/3771)\n\nThe response was that contrib/layers was going to be one of the official builder API's to be included in TensorFlow core along with contrib/learn. So I wanted to see how it works and learn how to use it. But the only documentation I could find for contrib/layers was this:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/README.md\n\nhttps://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.layers.html\n\nIs this really all the documentation there is for contrib/layers? Surely there must be more? You couldn't possibly expect people to be able to learn how to use it from these two documents alone? The README doesn't even make any sense. Am I missing something?\n\nPlease allow me a short rant.\n\nI'm sure you're familiar with scikit-learn's beautifully designed API and extensive, polished documentation. It might serve as a good inspiration for TensorFlow. You may think that you don't have time to streamline the TensorFlow API and improve the documentation because there's more important things that must be done. But I believe this is actually the single most important thing you could do to move the project forward. Here's why:\n\nIf each new person wastes 10 hours trying to learn TensorFlow and there's 10,000 people who are learning to use it, then it's 100,000 wasted developer-hours! I actually think those numbers are very conservative. Personally I've probably wasted more than 100 hours trying to figure out how the complicated and poorly documented TensorFlow API works, and it seems there's many more than 10,000 people using TensorFlow. So maybe it's more than 1 million wasted developer-hours in total! That is 500 developer-years (assuming a month is about 160 work-hours)! Imagine if this developer-time was put into more constructive use. All it takes is for the TensorFlow API and docs to be more polished so it would be easier to learn. It would be a tiny investment in time and effort from the dev-team, compared to the return you'll get in productivity from the community. I really wish this is something you would prioritize highly.\n\nThanks!\n", "comments": ["I agree @Hvass-Labs. TensorFlow needs to have world-class documentation that's slick, polished, intuitive, and accessible to everyone. We've got a lot of amazing people who've worked hard to bring our documentation pretty close to that level of quality. Everything else\u2014as @martinwicke pointed out in #3771\u2014goes in contrib.\n\nWe encourage you to get involved and help us improve. TensorFlow is a high impact project. Any time you generously choose to volunteer in improving our documentation will pay dividends for the 10,000 people who read it later.\n", "Thanks for the quick and positive reply.\n\nI have already spent months trying to help explain TensorFlow to a wider audience. This is done on my own time for my own money:\n\nhttps://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ\n\nBut I am frequently stuck and spend days trying to figure out how to do things that should be fairly simple, because there's no example code showing how to do it, and the TensorFlow API is generally quite complicated and lots of features are poorly documented.\n\nThere is a school of thought in software engineering that beginners can help document code as they learn how to use it. I strongly disagree with that notion. It takes a beginner maybe 50x as much time to learn a piece of code as the engineer who wrote it, and it is unlikely that a beginner will understand all the implications of a particular function or class. In my opinion, code is not completed before it is polished and well-documented.\n\nIt is the same with fixing bugs. I previously posted a report here for a bug that occasionally showed itself. The TensorFlow developer couldn't reproduce and hence marked it as community support. Fair enough. Several other individuals later posted they experienced it as well. But the function where it happened wasn't well-documented so I had no idea what the function was supposed to do, and hence I couldn't help fix the bug. It was eventually fixed so all is good, but it demonstrates how difficult it is for the community to help out if the docs don't describe the API very well.\n\nHow many times do you have to ask a co-worker how to do something in TensorFlow? Well, people in the community don't have that extensive and quick support-network. All we can do is post a question on StackOverflow and hope it gets answered (a lot of questions don't even though @mrry is making a valiant effort).\n\nOnce again, I very much appreciate your friendly and welcoming response, but I hope that the TensorFlow team considers the possibility that perhaps you still have quite a way to go before the API and docs are as polished as e.g. scikit-learn. A good place to start would be consolidation and proper documentation of the builder API's (e.g. contrib.layers, contrib.slim and PrettyTensor).\n\nCheers!\n"]}, {"number": 4963, "title": "protoc failed: error executing command", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nNone\n### Environment info\n\nOperating System:\n\n```\nuname -a\nLinux n-62-18-47 2.6.32-573.22.1.el6.x86_64 #1 SMP Tue Mar 22 17:15:28 CDT 2016 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nInstalled version of CUDA and cuDNN: CUDA: 8.0, cuDNN 5.0\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\nls -l /appl/cuda/8.0/lib64/libcud*\n-rw-r--r-- 1 sebo root 560184 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 sebo root     16 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 sebo root     19 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 sebo root 394472 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 sebo root 737516 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart_static.a\n```\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`): 8d1198374477e9c7e01893103233da984f302924\n2. The output of `bazel version`\n\n```\nbazel --batch version\nINFO: Reading 'startup' options from /zhome/ff/2/77654/.bazelrc: --batch --output_user_root=/work1/s123598/.bazel\nBuild label: 0.3.2-2016-10-13 (@2891ec5)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Oct 13 15:05:25 2016 (1476371125)\nBuild timestamp: 1476371125\nBuild timestamp as int: 1476371125\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n```\n# install tensorflow\ngit clone https://github.com/tensorflow/tensorflow\ncd tensorflow\n# set configuration parameters\nexport PYTHON_BIN_PATH=`which python3`\nexport TF_NEED_GCP=0\nexport TF_NEED_HDFS=0\nexport TF_NEED_CUDA=1\nexport GCC_HOST_COMPILER_PATH=`which gcc`\nexport TF_CUDA_VERSION=8.0\nexport CUDA_TOOLKIT_PATH=/appl/cuda/8.0/\nexport TF_CUDNN_VERSION=5\nexport CUDNN_INSTALL_PATH=/appl/cudnn/v5.0-prod\nexport TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2\"\n\ncat > $HOME/.bazelrc <<EOF\n# --batch: always run in batch mode, since there are some firewall issues.\n# --output_user_root: HOME is NFS (filesystem), this will not work with bazel, use WORKDIR instead\nstartup --batch --output_user_root=$WORKDIR/.bazel\nEOF\n\n# one python configuration can't be set directly use yes to accept automatically\nyes \"\" | CC=gcc CXX=g++ ./configure\n\n# build tensorflow\nCC=gcc CXX=g++ bazel build --copt=\"-w\" --ignore_unsupported_sandboxing --spawn_strategy=standalone --verbose_failures \\\n-c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n```\n### What other attempted solutions have you tried?\n\nJust getting here took some time. I had to compile bazel, pcre, swig. Put bazel in batch model and get a workdirectory that wasn't NFS. But this I have no idea how to fix.\n### Logs or other output that would be helpful\n\nfull log: https://gist.github.com/AndreasMadsen/474389dc54efe948e9887eafb78679ef\n\n```\nINFO: From ProtoCompile tensorflow/core/example/example.pb.h [for host]:\nbazel-out/host/genfiles/external/protobuf/src: warning: directory does not exist.\nERROR: /zhome/ff/2/77654/tensorflow/tensorflow/core/debug/BUILD:33:1: null failed: protoc failed: error executing command\n  (cd /work1/s123598/.bazel/48591a606b240b3533e6a6889ad3b508/execroot/tensorflow && \\\n  exec env - \\\n  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-py3-opt/genfiles/' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' '--grpc_out=bazel-out/local_linux-py3-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-py3-opt/genfiles/external/protobuf/src tensorflow/core/debug/debug_service.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nbazel-out/local_linux-py3-opt/genfiles/external/protobuf/src: warning: directory does not exist.\nbazel-out/host/bin/external/grpc/grpc_cpp_plugin: program not found or is not executable\n--grpc_out: protoc-gen-grpc: Plugin failed with status code 1.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nERROR: /zhome/ff/2/77654/tensorflow/tensorflow/tools/pip_package/BUILD:23:1 null failed: protoc failed: error executing command\n  (cd /work1/s123598/.bazel/48591a606b240b3533e6a6889ad3b508/execroot/tensorflow && \\\n  exec env - \\\n  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-py3-opt/genfiles/' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' '--grpc_out=bazel-out/local_linux-py3-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-py3-opt/genfiles/external/protobuf/src tensorflow/core/debug/debug_service.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nINFO: Elapsed time: 189.979s, Critical Path: 68.86s\n```\n", "comments": ["Apparently same problem here:\nI am starting to dig into tensorflow with ruby following the tuto at [https://github.com/somaticio/tensorflow.rb](url)\nEnvironment\nFedora 24\nuname -a\nLinux fedora 4.7.6-200.fc24.x86_64 #1 SMP Mon Oct 3 20:10:24 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nWhen running:\nbazel build //tensorflow:libtensorflow.so\ni get the following error message:\n\nINFO: From ProtoCompile tensorflow/core/kernels/reader_base.pb.h:\nbazel-out/local-py3-fastbuild/genfiles/external/protobuf/src: warning: directory does not exist.\nERROR: /home/workspace/ai/tensorflow/tensorflow/core/debug/BUILD:33:1: null failed: protoc failed: error executing command bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local-py3-fastbuild/genfiles/' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' ... (remaining 5 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nbazel-out/local-py3-fastbuild/genfiles/external/protobuf/src: warning: directory does not exist.\nbazel-out/host/bin/external/grpc/grpc_cpp_plugin: program not found or is not executable\n--grpc_out: protoc-gen-grpc: Plugin failed with status code 1.\nTarget //tensorflow:libtensorflow.so failed to build\n", "Some additional information:\nbazel version\nBuild label: 0.3.2-2016-10-14 (@01906ed)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: ven. oct. 14 10:44:44 2016 (1476441884)\nBuild timestamp: 1476441884\nBuild timestamp as int: 1476441884\n\nprotoc --version\nlibprotoc 2.6.1\n", "Just confirming that I'm able to reproduce this at HEAD. Taking a closer look.\n", "It seems this issue is solved by #4967 which I'm going to merge right now.\n", "I can confirm that this is now fixed. Thanks!\n", "Happy to be of service.\n", "Hello, can you just tell me which build can i use? For the moment i have installed bazel from source with:\ngit clone https://github.com/bazelbuild/bazel.git\ncd bazel\n./compile.sh\n\nThanks in advance.\n", "@BeGe78 we recommend reaching out to the [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) community for support. \n", "Hello, just to let you know, I recompile tensorflow from source and get it working. Thanks a lot.\n", "Glad to hear it @BeGe78. We hope you enjoy using TensorFlow and that it serves you well.\n"]}, {"number": 4962, "title": "Fix too long sentence", "body": "models/rnn/translate.py with --decode option raises exception if input sentence is longer than 20 (default lower bound on last bucket)\n\n> 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n> Traceback (most recent call last):\n> File \"translate_edit.py\", line 298, in\n> tf.app.run()\n> File \"/home/modrymar/venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n> sys.exit(main(sys.argv))\n> File \"translate_edit.py\", line 293, in main\n> decode()\n> File \"translate_edit.py\", line 241, in decode\n> bucket_id = min([b for b in xrange(len(_buckets))\n> ValueError: min() arg is an empty sequence\n", "comments": ["@ofilip, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @benoitsteiner and @keveman to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Warning sounds good. I'm not sure how it works when some change on pull request is required. Who'll add the warning?\n", "Feel free to address @jart's comments and respond.\n", "Sorry for slow reaction. I'm not really used to github review's. Code is updated according to @jart's suggestion.\n", "Mr. Jenkins test this please\n\nThe logging import needs to be defined.\n", "Jenkins, test this please\n"]}, {"number": 4961, "title": "Fix too long sentence", "body": "models/rnn/translate.py with --decode option raises exception if input sentence is longer than 20 (default lower bound on last bucket)\n\n> 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\nTraceback (most recent call last):\n  File \"translate_edit.py\", line 298, in <module>\n    tf.app.run()\n  File \"/home/modrymar/venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"translate_edit.py\", line 293, in main\n    decode()\n  File \"translate_edit.py\", line 241, in decode\n    bucket_id = min([b for b in xrange(len(_buckets))\nValueError: min() arg is an empty sequence\n", "comments": ["@ofilip, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @benoitsteiner and @keveman to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "Accidentally used bad author's email\n"]}, {"number": 4960, "title": "distributed inception was killed", "body": "# problem\n\nwhen I startup a distributed inception on a single machine with one ps and two workers, i.e. `ps:192.168.184.33:9000; worker:192.168.184.33:9001,192.168.184.33:9001`, after a few steps, the ps and workers was killed\n\nps says:\n\n``` shell\n*** Error in `/usr/bin/python': invalid fastbin entry (free): 0x00007fafdd048f30 ***\n======= Backtrace: =========\n/lib64/libc.so.6(+0x7d023)[0x7fb1035cd023]\n/export/wangqingze/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x3e6)[0x7fb0ecf0a466]\n/export/wangqingze/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x22)[0x7fb0ecf09c12]\n/lib64/libstdc++.so.6(+0xb5220)[0x7fb0ea555220]\n/lib64/libpthread.so.0(+0x7dc5)[0x7fb104021dc5]\n/lib64/libc.so.6(clone+0x6d)[0x7fb10364628d]\n======= Memory map: ========\n00400000-00401000 r-xp 00000000 08:02 67430429                           /usr/bin/python2.7\n00600000-00601000 r--p 00000000 08:02 67430429                           /usr/bin/python2.7\n00601000-00602000 rw-p 00001000 08:02 67430429                           /usr/bin/python2.7\n01c63000-0713e000 rw-p 00000000 00:00 0                                  [heap]\n7faf94000000-7faf94103000 rw-p 00000000 00:00 0 \n7faf94103000-7faf98000000 ---p 00000000 00:00 0 \n7faf985c4000-7faf985c5000 ---p 00000000 00:00 0 \n7faf985c5000-7faf98dc5000 rwxp 00000000 00:00 0 \n7faf98dc5000-7fafa0000000 rw-p 00000000 00:00 0 \n7fafa0000000-7fafa1850000 rw-p 00000000 00:00 0 \n7fafa1850000-7fafa4000000 ---p 00000000 00:00 0 \n7fafa4023000-7fafa8000000 rw-p 00000000 00:00 0 \n7fafa8000000-7fafa8768000 rw-p 00000000 00:00 0 \n7fafa8768000-7fafac000000 ---p 00000000 00:00 0 \n7fafac000000-7fafaffff000 rw-p 00000000 00:00 0 \n7fafaffff000-7fafb0000000 ---p 00000000 00:00 0 \n7fafb0033000-7fafb2ffe000 rw-p 00000000 00:00 0 \n7fafb2ffe000-7fafb2fff000 ---p 00000000 00:00 0 \n7fafb2fff000-7fafb37ff000 rwxp 00000000 00:00 0                          [stack:9683]\n7fafb37ff000-7fafb3800000 ---p 00000000 00:00 0 \n7fafb3800000-7fafb4000000 rwxp 00000000 00:00 0                          [stack:9682]\n7fafb4000000-7fafb7fe4000 rw-p 00000000 00:00 0 \n7fafb7fe4000-7fafb8000000 ---p 00000000 00:00 0 \n7fafb8000000-7fafbbf9c000 rw-p 00000000 00:00 0 \n7fafbbf9c000-7fafbc000000 ---p 00000000 00:00 0 \n7fafbc000000-7fafbff77000 rw-p 00000000 00:00 0 \n7fafbff77000-7fafc0000000 ---p 00000000 00:00 0 \n7fafc0000000-7fafc3ff0000 rw-p 00000000 00:00 0 \n7fafc3ff0000-7fafc4000000 ---p 00000000 00:00 0 \n7fafc4000000-7fafc7ffb000 rw-p 00000000 00:00 0 \n7fafc7ffb000-7fafc8000000 ---p 00000000 00:00 0 \n7fafc8000000-7fafcbfee000 rw-p 00000000 00:00 0 \n7fafcbfee000-7fafcc000000 ---p 00000000 00:00 0 \n7fafcc000000-7fafcffc5000 rw-p 00000000 00:00 0 \n7fafcffc5000-7fafd0000000 ---p 00000000 00:00 0 \n7fafd0024000-7fafd07f9000 rw-p 00000000 00:00 0 \n7fafd07f9000-7fafd07fa000 ---p 00000000 00:00 0 \n7fafd07fa000-7fafd0ffa000 rwxp 00000000 00:00 0                          [stack:9681]\n7fafd0ffa000-7fafd0ffb000 ---p 00000000 00:00 0 \n7fafd0ffb000-7fafd17fb000 rwxp 00000000 00:00 0                          [stack:9680]\n7fafd17fb000-7fafd17fc000 ---p 00000000 00:00 0 \n7fafd17fc000-7fafd1ffc000 rwxp 00000000 00:00 0                          [stack:9679]\n7fafd1ffc000-7fafd1ffd000 ---p 00000000 00:00 0 \n7fafd1ffd000-7fafd27fd000 rwxp 00000000 00:00 0                          [stack:9678]\n7fafd27fd000-7fafd27fe000 ---p 00000000 00:00 0 \n7fafd27fe000-7fafd2ffe000 rwxp 00000000 00:00 0                          [stack:9677]\n7fafd2ffe000-7fafd2fff000 ---p 00000000 00:00 0 \n7fafd2fff000-7fafd37ff000 rwxp 00000000 00:00 0                          [stack:9676]\n7fafd37ff000-7fafd3800000 ---p 00000000 00:00 0 \n7fafd3800000-7fafd4000000 rwxp 00000000 00:00 0                          [stack:9675]\n7fafd4000000-7fafd7ff9000 rw-p 00000000 00:00 0 \n7fafd7ff9000-7fafd8000000 ---p 00000000 00:00 0 \n7fafd8000000-7fafdbfdf000 rw-p 00000000 00:00 0 \n7fafdbfdf000-7fafdc000000 ---p 00000000 00:00 0 \n7fafdc000000-7fafdfff4000 rw-p 00000000 00:00 0 \n7fafdfff4000-7fafe0000000 ---p 00000000 00:00 0 \n7fafe0000000-7fafe3f6c000 rw-p 00000000 00:00 0 \n7fafe3f6c000-7fafe4000000 ---p 00000000 00:00 0 \n7fafe4000000-7fafe7f23000 rw-p 00000000 00:00 0 \n7fafe7f23000-7fafe8000000 ---p 00000000 00:00 0 \n7fafe8000000-7fafebfca000 rw-p 00000000 00:00 0 \n7fafebfca000-7fafec000000 ---p 00000000 00:00 0 \n7fafec000000-7fafeffd5000 rw-p 00000000 00:00 0 \n7fafeffd5000-7faff0000000 ---p 00000000 00:00 0 \n7faff002f000-7faff07f9000 rw-p 00000000 00:00 0 \n7faff07f9000-7faff07fa000 ---p 00000000 00:00 0 \n7faff07fa000-7faff0ffa000 rwxp 00000000 00:00 0                          [stack:9674]\n7faff0ffa000-7faff0ffb000 ---p 00000000 00:00 0 \n7faff0ffb000-7faff17fb000 rwxp 00000000 00:00 0                          [stack:9673]\n7faff17fb000-7faff17fc000 ---p 00000000 00:00 0 \n7faff17fc000-7faff1ffc000 rwxp 00000000 00:00 0                          [stack:9672]\n7faff1ffc000-7faff1ffd000 ---p 00000000 00:00 0 \n7faff1ffd000-7faff27fd000 rwxp 00000000 00:00 0                          [stack:9671]\n7faff27fd000-7faff27fe000 ---p 00000000 00:00 0 \n7faff27fe000-7faff2ffe000 rwxp 00000000 00:00 0                          [stack:9670]\n7faff2ffe000-7faff2fff000 ---p 00000000 00:00 0 \n7faff2fff000-7faff37ff000 rwxp 00000000 00:00 0                          [stack:9669]\n7faff37ff000-7faff3800000 ---p 00000000 00:00 0 \n7faff3800000-7faff4000000 rwxp 00000000 00:00 0                          [stack:9668]\n7faff4000000-7faff7fd9000 rw-p 00000000 00:00 0 \n7faff7fd9000-7faff8000000 ---p 00000000 00:00 0 \n7faff8000000-7faffbff6000 rw-p 00000000 00:00 0 \n7faffbff6000-7faffc000000 ---p 00000000 00:00 0 \n7faffc000000-7faffffae000 rw-p 00000000 00:00 0 \n7faffffae000-7fb000000000 ---p 00000000 00:00 0 \n7fb000000000-7fb003ff5000 rw-p 00000000 00:00 0 \n7fb003ff5000-7fb004000000 ---p 00000000 00:00 0 \n7fb004000000-7fb007f7f000 rw-p 00000000 00:00 0 \n7fb007f7f000-7fb008000000 ---p 00000000 00:00 0 \n7fb008000000-7fb00bfee000 rw-p 00000000 00:00 0 \n7fb00bfee000-7fb00c000000 ---p 00000000 00:00 0 \n7fb00c000000-7fb00ffca000 rw-p 00000000 00:00 0 \n7fb00ffca000-7fb010000000 ---p 00000000 00:00 0 \n7fb010000000-7fb013fec000 rw-p 00000000 00:00 0 \n7fb013fec000-7fb014000000 ---p 00000000 00:00 0 \n7fb01402f000-7fb0147f9000 rw-p 00000000 00:00 0 \n7fb0147f9000-7fb0147fa000 ---p 00000000 00:00 0 \n7fb0147fa000-7fb014ffa000 rwxp 00000000 00:00 0                          [stack:9667]\n7fb014ffa000-7fb014ffb000 ---p 00000000 00:00 0 \n7fb014ffb000-7fb0157fb000 rwxp 00000000 00:00 0                          [stack:9666]\n7fb0157fb000-7fb0157fc000 ---p 00000000 00:00 0 \n7fb0157fc000-7fb015ffc000 rwxp 00000000 00:00 0                          [stack:9665]\n7fb015ffc000-7fb015ffd000 ---p 00000000 00:00 0 \n7fb015ffd000-7fb0167fd000 rwxp 00000000 00:00 0                          [stack:9664]\n7fb0167fd000-7fb0167fe000 ---p 00000000 00:00 0 \n7fb0167fe000-7fb016ffe000 rwxp 00000000 00:00 0                          [stack:9663]\n7fb016ffe000-7fb016fff000 ---p 00000000 00:00 0 \n7fb016fff000-7fb0177ff000 rwxp 00000000 00:00 0                          [stack:9662]\n7fb0177ff000-7fb017800000 ---p 00000000 00:00 0 \n7fb017800000-7fb018000000 rwxp 00000000 00:00 0                          [stack:9661]\n7fb018000000-7fb01bfef000 rw-p 00000000 00:00 0 \n7fb01bfef000-7fb01c000000 ---p 00000000 00:00 0 \n7fb01c000000-7fb01fffa000 rw-p 00000000 00:00 0 \n7fb01fffa000-7fb020000000 ---p 00000000 00:00 0 \n7fb020000000-7fb023f75000 rw-p 00000000 00:00 0 \n7fb023f75000-7fb024000000 ---p 00000000 00:00 0 \n7fb024000000-7fb027fb0000 rw-p 00000000 00:00 0 \n7fb027fb0000-7fb028000000 ---p 00000000 00:00 0 \n7fb028000000-7fb02bffa000 rw-p 00000000 00:00 0 \n7fb02bffa000-7fb02c000000 ---p 00000000 00:00 0 \n7fb02c000000-7fb02fe64000 rw-p 00000000 00:00 0 \n7fb02fe64000-7fb030000000 ---p 00000000 00:00 0 \n7fb030000000-7fb033ff8000 rw-p 00000000 00:00 0 \n7fb033ff8000-7fb034000000 ---p 00000000 00:00 0 \n7fb034000000-7fb038000000 rw-p 00000000 00:00 0 \n7fb038044000-7fb0387f9000 rw-p 00000000 00:00 0 \n7fb0387f9000-7fb0387fa000 ---p 00000000 00:00 0 \n7fb0387fa000-7fb038ffa000 rwxp 00000000 00:00 0                          [stack:9660]\n7fb038ffa000-7fb038ffb000 ---p 00000000 00:00 0 \n7fb038ffb000-7fb0397fb000 rwxp 00000000 00:00 0                          [stack:9659]\n7fb0397fb000-7fb0397fc000 ---p 00000000 00:00 0 \n7fb0397fc000-7fb039ffc000 rwxp 00000000 00:00 0                          [stack:9658]\n7fb039ffc000-7fb039ffd000 ---p 00000000 00:00 0 \n7fb039ffd000-7fb03a7fd000 rwxp 00000000 00:00 0                          [stack:9657]\n7fb03a7fd000-7fb03a7fe000 ---p 00000000 00:00 0 \n7fb03a7fe000-7fb03affe000 rwxp 00000000 00:00 0                          [stack:9656]\n7fb03affe000-7fb03afff000 ---p 00000000 00:00 0 \n7fb03afff000-7fb03b7ff000 rwxp 00000000 00:00 0                          [stack:9655]\n7fb03b7ff000-7fb03b800000 ---p 00000000 00:00 0 \n7fb03b800000-7fb03c000000 rwxp 00000000 00:00 0                          [stack:9654]\n7fb03c000000-7fb040000000 rw-p 00000000 00:00 0 \n7fb040000000-7fb043fde000 rw-p 00000000 00:00 0 \n7fb043fde000-7fb044000000 ---p 00000000 00:00 0 \n7fb044000000-7fb044021000 rw-p 00000000 00:00 0 \n7fb044021000-7fb048000000 ---p 00000000 00:00 0 \n7fb048000000-7fb048021000 rw-p 00000000 00:00 0 \n7fb048021000-7fb04c000000 ---p 00000000 00:00 0 \n7fb04c000000-7fb04c021000 rw-p 00000000 00:00 0 \n7fb04c021000-7fb050000000 ---p 00000000 00:00 0 \n7fb050026000-7fb0507f9000 rw-p 00000000 00:00 0 \n7fb0507f9000-7fb0507fa000 ---p 00000000 00:00 0 \n7fb0507fa000-7fb050ffa000 rwxp 00000000 00:00 0                          [stack:9653]\n7fb050ffa000-7fb050ffb000 ---p 00000000 00:00 0 \n7fb050ffb000-7fb0517fb000 rwxp 00000000 00:00 0                          [stack:9652]\n7fb0517fb000-7fb0517fc000 ---p 00000000 00:00 0 \n7fb0517fc000-7fb051ffc000 rwxp 00000000 00:00 0                          [stack:9651]\n7fb051ffc000-7fb051ffd000 ---p 00000000 00:00 0 \n7fb051ffd000-7fb0527fd000 rwxp 00000000 00:00 0                          [stack:9650]\n7fb0527fd000-7fb0527fe000 ---p 00000000 00:00 0 \n7fb0527fe000-7fb052ffe000 rwxp 00000000 00:00 0                          [stack:9649]\n7fb052ffe000-7fb052fff000 ---p 00000000 00:00 0 \n7fb052fff000-7fb0537ff000 rwxp 00000000 00:00 0                          [stack:9648]\n7fb0537ff000-7fb053800000 ---p 00000000 00:00 0 \n7fb053800000-7fb054000000 rwxp 00000000 00:00 0                          [stack:9647]\n7fb054000000-7fb054021000 rw-p 00000000 00:00 0 \n7fb054021000-7fb058000000 ---p 00000000 00:00 0 \n7fb058000000-7fb058021000 rw-p 00000000 00:00 0 \n7fb058021000-7fb05c000000 ---p 00000000 00:00 0 \n7fb05c000000-7fb05c021000 rw-p 00000000 00:00 0 \n7fb05c021000-7fb060000000 ---p 00000000 00:00 0 \n7fb060000000-7fb060021000 rw-p 00000000 00:00 0 \n7fb060021000-7fb064000000 ---p 00000000 00:00 0 \n7fb064000000-7fb064021000 rw-p 00000000 00:00 0 \n7fb064021000-7fb068000000 ---p 00000000 00:00 0 \n7fb068000000-7fb068021000 rw-p 00000000 00:00 0 \n7fb068021000-7fb06c000000 ---p 00000000 00:00 0 \n7fb06c000000-7fb06c021000 rw-p 00000000 00:00 0 \n7fb06c021000-7fb070000000 ---p 00000000 00:00 0 \n7fb070000000-7fb070021000 rw-p 00000000 00:00 0 \n7fb070021000-7fb074000000 ---p 00000000 00:00 0 \n7fb074000000-7fb074021000 rw-p 00000000 00:00 0 \n7fb074021000-7fb078000000 ---p 00000000 00:00 0 \n7fb078000000-7fb078021000 rw-p 00000000 00:00 0 \n7fb078021000-7fb07c000000 ---p 00000000 00:00 0 \n7fb07c000000-7fb07c021000 rw-p 00000000 00:00 0 \n7fb07c021000-7fb080000000 ---p 00000000 00:00 0 \n7fb080000000-7fb080021000 rw-p 00000000 00:00 0 \n7fb080021000-7fb084000000 ---p 00000000 00:00 0 \n7fb084000000-7fb084021000 rw-p 00000000 00:00 0 \n7fb084021000-7fb088000000 ---p 00000000 00:00 0 \n7fb088026000-7fb0887f9000 rw-p 00000000 00:00 0 \n7fb0887f9000-7fb0887fa000 ---p 00000000 00:00 0 \n7fb0887fa000-7fb088ffa000 rwxp 00000000 00:00 0                          [stack:9646]\n7fb088ffa000-7fb088ffb000 ---p 00000000 00:00 0 \n7fb088ffb000-7fb0897fb000 rwxp 00000000 00:00 0                          [stack:9645]\n7fb0897fb000-7fb0897fc000 ---p 00000000 00:00 0 \n7fb0897fc000-7fb089ffc000 rwxp 00000000 00:00 0                          [stack:9644]\n7fb089ffc000-7fb089ffd000 ---p 00000000 00:00 0 \n7fb089ffd000-7fb08a7fd000 rwxp 00000000 00:00 0                          [stack:9643]\n7fb08a7fd000-7fb08a7fe000 ---p 00000000 00:00 0 \n7fb08a7fe000-7fb08affe000 rwxp 00000000 00:00 0                          [stack:9642]\n7fb08affe000-7fb08afff000 ---p 00000000 00:00 0 \n7fb08afff000-7fb08b7ff000 rwxp 00000000 00:00 0                          [stack:9641]\n7fb08b7ff000-7fb08b800000 ---p 00000000 00:00 0 \n7fb08b800000-7fb08c000000 rwxp 00000000 00:00 0                          [stack:9640]\n7fb08c000000-7fb08c021000 rw-p 00000000 00:00 0 \n7fb08c021000-7fb090000000 ---p 00000000 00:00 0 \n7fb090000000-7fb090021000 rw-p 00000000 00:00 0 \n7fb090021000-7fb094000000 ---p 00000000 00:00 0 \n7fb094085000-7fb0947f9000 rw-p 00000000 00:00 0 \n7fb0947f9000-7fb0947fa000 ---p 00000000 00:00 0 \n7fb0947fa000-7fb094ffa000 rwxp 00000000 00:00 0                          [stack:9639]\n7fb094ffa000-7fb094ffb000 ---p 00000000 00:00 0 \n7fb094ffb000-7fb0957fb000 rwxp 00000000 00:00 0                          [stack:9638]\n7fb0957fb000-7fb0957fc000 ---p 00000000 00:00 0 \n7fb0957fc000-7fb095ffc000 rwxp 00000000 00:00 0                          [stack:9637]\n7fb095ffc000-7fb095ffd000 ---p 00000000 00:00 0 \n7fb095ffd000-7fb0967fd000 rwxp 00000000 00:00 0                          [stack:9636]\n7fb0967fd000-7fb0967fe000 ---p 00000000 00:00 0 \n7fb0967fe000-7fb096ffe000 rwxp 00000000 00:00 0                          [stack:9635]\n7fb096ffe000-7fb096fff000 ---p 00000000 00:00 0 \n7fb096fff000-7fb0977ff000 rwxp 00000000 00:00 0                          [stack:9634]\n7fb0977ff000-7fb097800000 ---p 00000000 00:00 0 \n7fb097800000-7fb098000000 rwxp 00000000 00:00 0                          [stack:9633]\n7fb098000000-7fb098021000 rw-p 00000000 00:00 0 \n7fb098021000-7fb09c000000 ---p 00000000 00:00 0 \n7fb09c000000-7fb09c021000 rw-p 00000000 00:00 0 \n7fb09c021000-7fb0a0000000 ---p 00000000 00:00 0 \n7fb0a0000000-7fb0a0021000 rw-p 00000000 00:00 0 \n7fb0a0021000-7fb0a4000000 ---p 00000000 00:00 0 \n7fb0a4000000-7fb0a4021000 rw-p 00000000 00:00 0 \n7fb0a4021000-7fb0a8000000 ---p 00000000 00:00 0 \n7fb0a8000000-7fb0a8021000 rw-p 00000000 00:00 0 \n7fb0a8021000-7fb0ac000000 ---p 00000000 00:00 0 \n7fb0ac000000-7fb0ac021000 rw-p 00000000 00:00 0 \n7fb0ac021000-7fb0b0000000 ---p 00000000 00:00 0 \n7fb0b0000000-7fb0b0021000 rw-p 00000000 00:00 0 \n7fb0b0021000-7fb0b4000000 ---p 00000000 00:00 0 \n7fb0b4000000-7fb0b4021000 rw-p 00000000 00:00 0 \n7fb0b4021000-7fb0b8000000 ---p 00000000 00:00 0 \n7fb0b8000000-7fb0b8021000 rw-p 00000000 00:00 0 \n7fb0b8021000-7fb0bc000000 ---p 00000000 00:00 0 \n7fb0bc000000-7fb0bc021000 rw-p 00000000 00:00 0 \n7fb0bc021000-7fb0c0000000 ---p 00000000 00:00 0 \n7fb0c0000000-7fb0c0021000 rw-p 00000000 00:00 0 \n7fb0c0021000-7fb0c4000000 ---p 00000000 00:00 0 \n7fb0c4000000-7fb0c4021000 rw-p 00000000 00:00 0 \n7fb0c4021000-7fb0c8000000 ---p 00000000 00:00 0 \n7fb0c8000000-7fb0c8021000 rw-p 00000000 00:00 0 \n7fb0c8021000-7fb0cc000000 ---p 00000000 00:00 0 \n7fb0cc045000-7fb0cc046000 ---p 00000000 00:00 0 \n7fb0cc046000-7fb0cc846000 rwxp 00000000 00:00 0                          [stack:9632]\n7fb0cc846000-7fb0cc847000 ---p 00000000 00:00 0 \n7fb0cc847000-7fb0cd047000 rwxp 00000000 00:00 0                          [stack:9631]\n7fb0cd047000-7fb0cd048000 ---p 00000000 00:00 0 \n7fb0cd048000-7fb0cd848000 rwxp 00000000 00:00 0                          [stack:9630]\n7fb0cd848000-7fb0cd849000 ---p 00000000 00:00 0 \n7fb0cd849000-7fb0ce049000 rwxp 00000000 00:00 0                          [stack:9629]\n7fb0ce049000-7fb0ce04a000 ---p 00000000 00:00 0 \n7fb0ce04a000-7fb0ce84a000 rwxp 00000000 00:00 0                          [stack:9621]\n7fb0ce8fc000-7fb0ceffe000 rw-p 00000000 00:00 0 \n7fb0ceffe000-7fb0cefff000 ---p 00000000 00:00 0 \n7fb0cefff000-7fb0cf7ff000 rwxp 00000000 00:00 0                          [stack:9628]\n7fb0cf7ff000-7fb0cf800000 ---p 00000000 00:00 0 \n7fb0cf800000-7fb0d0000000 rwxp 00000000 00:00 0                          [stack:9627]\n7fb0d0000000-7fb0d0021000 rw-p 00000000 00:00 0 \n7fb0d0021000-7fb0d4000000 ---p 00000000 00:00 0 \n7fb0d4045000-7fb0d4046000 ---p 00000000 00:00 0 \n7fb0d4046000-7fb0d4846000 rwxp 00000000 00:00 0                          [stack:9626]\n7fb0d4846000-7fb0d4847000 ---p 00000000 00:00 0 \n7fb0d4847000-7fb0d5047000 rwxp 00000000 00:00 0                          [stack:9625]\n7fb0d5047000-7fb0d5048000 ---p 00000000 00:00 0 \n7fb0d5048000-7fb0d5848000 rwxp 00000000 00:00 0                          [stack:9624]\n7fb0d5848000-7fb0d5849000 ---p 00000000 00:00 0 \n7fb0d5849000-7fb0d6049000 rwxp 00000000 00:00 0                          [stack:9623]\n7fb0d6049000-7fb0d604a000 ---p 00000000 00:00 0 \n7fb0d604a000-7fb0d684a000 rwxp 00000000 00:00 0                          [stack:9622]\n7fb0d684a000-7fb0d684b000 ---p 00000000 00:00 0 \n7fb0d684b000-7fb0d704b000 rwxp 00000000 00:00 0                          [stack:9620]\n7fb0d704b000-7fb0d704c000 ---p 00000000 00:00 0 \n7fb0d704c000-7fb0d784c000 rwxp 00000000 00:00 0                          [stack:9619]\n7fb0d784c000-7fb0d784d000 ---p 00000000 00:00 0 \n7fb0d784d000-7fb0d804d000 rwxp 00000000 00:00 0                          [stack:9618]\n7fb0d804d000-7fb0d804e000 ---p 00000000 00:00 0 \n7fb0d804e000-7fb0d884e000 rwxp 00000000 00:00 0                          [stack:9617]\n7fb0d884e000-7fb0d8856000 r-xp 00000000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so\n7fb0d8856000-7fb0d8a55000 ---p 00008000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so\n7fb0d8a55000-7fb0d8a56000 r--p 00007000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so\n7fb0d8a56000-7fb0d8a57000 rw-p 00008000 08:02 101040862                  /usr/lib64/python2.7/lib-dynload/_json.so\n7fb0d8a57000-7fb0d8d58000 rw-p 00000000 00:00 0 \n7fb0d8d58000-7fb0d8d5c000 r-xp 00000000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0\n7fb0d8d5c000-7fb0d8f5b000 ---p 00004000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0\n7fb0d8f5b000-7fb0d8f5c000 r--p 00003000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0\n7fb0d8f5c000-7fb0d8f5d000 rw-p 00004000 08:02 100710418                  /usr/lib64/libuuid.so.1.3.0\n7fb0d8f5d000-7fb0d9020000 rw-p 00000000 00:00 0 \n7fb0d905a000-7fb0d90dc000 rw-p 00000000 00:00 0 \n7fb0d90dc000-7fb0d90e0000 r-xp 00000000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so\n7fb0d90e0000-7fb0d92df000 ---p 00004000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so\n7fb0d92df000-7fb0d92e0000 r--p 00003000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so\n7fb0d92e0000-7fb0d92e1000 rw-p 00004000 08:02 101040863                  /usr/lib64/python2.7/lib-dynload/_localemodule.so\n7fb0d92e1000-7fb0d9363000 rw-p 00000000 00:00 0 \n7fb0d9363000-7fb0d9376000 r-xp 00000000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so\n7fb0d9376000-7fb0d9575000 ---p 00013000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so\n7fb0d9575000-7fb0d9576000 r--p 00012000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so\n7fb0d9576000-7fb0d957a000 rw-p 00013000 08:02 104223611                  /usr/lib64/python2.7/lib-dynload/_ssl.so\n7fb0d957a000-7fb0d9589000 r-xp 00000000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so\n7fb0d9589000-7fb0d9788000 ---p 0000f000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so\n7fb0d9788000-7fb0d9789000 r--p 0000e000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so\n7fb0d9789000-7fb0d978e000 rw-p 0000f000 08:02 101576783                  /usr/lib64/python2.7/lib-dynload/_socketmodule.so\n7fb0d978e000-7fb0d97cf000 rw-p 00000000 00:00 0 \n7fb0d97cf000-7fb0d97d3000 r-xp 00000000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so\n7fb0d97d3000-7fb0d99d2000 ---p 00004000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so\n7fb0d99d2000-7fb0d99d3000 r--p 00003000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so\n7fb0d99d3000-7fb0d99d5000 rw-p 00004000 08:02 104223823                  /usr/lib64/python2.7/lib-dynload/zlibmodule.so\n7fb0d99d5000-7fb0d9a16000 rw-p 00000000 00:00 0 \n7fb0d9a16000-7fb0db7a3000 r-xp 00000000 08:02 34762224                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcurand.so.7.5.18\n7fb0db7a3000-7fb0db9a3000 ---p 01d8d000 08:02 34762224                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcurand.so.7.5.18\n7fb0db9a3000-7fb0dcd74000 rw-p 01d8d000 08:02 34762224                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcurand.so.7.5.18\n7fb0dcd74000-7fb0dd27e000 rw-p 00000000 00:00 0 \n7fb0dd27e000-7fb0dde60000 r-xp 00000000 08:02 40780306                   /usr/lib64/nvidia/libcuda.so.352.79\n7fb0dde60000-7fb0de05f000 ---p 00be2000 08:02 40780306                   /usr/lib64/nvidia/libcuda.so.352.79\n7fb0de05f000-7fb0de21d000 rw-p 00be1000 08:02 40780306                   /usr/lib64/nvidia/libcuda.so.352.79\n7fb0de21d000-7fb0de233000 rw-p 00000000 00:00 0 \n7fb0de233000-7fb0e4ba3000 r-xp 00000000 08:02 37679427                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcufft.so.7.5.18\n7fb0e4ba3000-7fb0e4da2000 ---p 06970000 08:02 37679427                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcufft.so.7.5.18\n7fb0e4da2000-7fb0e4e47000 rw-p 0696f000 08:02 37679427                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcufft.so.7.5.18\n7fb0e4e47000-7fb0e4e6e000 rw-p 00000000 00:00 0 \n7fb0e4e6e000-7fb0e8780000 r-xp 00000000 08:02 34912963                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudnn.so\n7fb0e8780000-7fb0e897f000 ---p 03912000 08:02 34912963                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudnn.so\n7fb0e897f000-7fb0e8990000 rw-p 03911000 08:02 34912963                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudnn.so\n7fb0e8990000-7fb0e89b9000 rw-p 00000000 00:00 0 \n7fb0e89b9000-7fb0ea082000 r-xp 00000000 08:02 37679451                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcublas.so.7.5.18\n7fb0ea082000-7fb0ea281000 ---p 016c9000 08:02 37679451                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcublas.so.7.5.18\n7fb0ea281000-7fb0ea28d000 rw-p 016c8000 08:02 37679451                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcublas.so.7.5.18\n7fb0ea28d000-7fb0ea298000 rw-p 00000000 00:00 0 \n7fb0ea298000-7fb0ea29f000 r-xp 00000000 08:02 100671127                  /usr/lib64/librt-2.17.so\n7fb0ea29f000-7fb0ea49e000 ---p 00007000 08:02 100671127                  /usr/lib64/librt-2.17.so\n7fb0ea49e000-7fb0ea49f000 r--p 00006000 08:02 100671127                  /usr/lib64/librt-2.17.so\n7fb0ea49f000-7fb0ea4a0000 rw-p 00007000 08:02 100671127                  /usr/lib64/librt-2.17.so\n7fb0ea4a0000-7fb0ea589000 r-xp 00000000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19\n7fb0ea589000-7fb0ea789000 ---p 000e9000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19\n7fb0ea789000-7fb0ea791000 r--p 000e9000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19\n7fb0ea791000-7fb0ea793000 rw-p 000f1000 08:02 100710424                  /usr/lib64/libstdc++.so.6.0.19\n7fb0ea793000-7fb0ea7a8000 rw-p 00000000 00:00 0 \n7fb0ea7a8000-7fb0ea803000 r-xp 00000000 08:02 40780164                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18\n7fb0ea803000-7fb0eaa02000 ---p 0005b000 08:02 40780164                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18\n7fb0eaa02000-7fb0eaa06000 rw-p 0005a000 08:02 40780164                   /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18\n7fb0eaa06000-7fb0f53ba000 r-xp 00000000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so\n7fb0f53ba000-7fb0f55ba000 ---p 0a9b4000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so\n7fb0f55ba000-7fb0f567d000 r--p 0a9b4000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so\n7fb0f567d000-7fb0f5681000 rw-p 0aa77000 08:05 300654753                  /export/wangqingze/bazel_output/505f9aca2a9fc3d10d7d985215ae4971/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow.so\n7fb0f5681000-7fb0f5f6e000 rw-p 00000000 00:00 0 \n7fb0f5fa5000-7fb0f601d000 r-xp 00000000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so\n7fb0f601d000-7fb0f621c000 ---p 00078000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so\n7fb0f621c000-7fb0f621d000 r--p 00077000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so\n7fb0f621d000-7fb0f6258000 rw-p 00078000 08:02 6969005                    /usr/lib/python2.7/site-packages/numpy/random/mtrand.so\n7fb0f6258000-7fb0f629a000 rw-p 00000000 00:00 0 \n7fb0f629a000-7fb0f62a3000 r-xp 00000000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so\n7fb0f62a3000-7fb0f64a2000 ---p 00009000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so\n7fb0f64a2000-7fb0f64a3000 r--p 00008000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so\n7fb0f64a3000-7fb0f64a4000 rw-p 00009000 08:02 105561601                  /usr/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so\n7fb0f64a4000-7fb0f64a5000 r-xp 00000000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so\n7fb0f64a5000-7fb0f66a4000 ---p 00001000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so\n7fb0f66a4000-7fb0f66a5000 r--p 00000000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so\n7fb0f66a5000-7fb0f66a6000 rw-p 00001000 08:02 104223623                  /usr/lib64/python2.7/lib-dynload/future_builtins.so\n7fb0f66a6000-7fb0f66e7000 rw-p 00000000 00:00 0 \n7fb0f66e7000-7fb0f670f000 r-xp 00000000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so\n7fb0f670f000-7fb0f690e000 ---p 00028000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so\n7fb0f690e000-7fb0f690f000 r--p 00027000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so\n7fb0f690f000-7fb0f6910000 rw-p 00028000 08:02 6968988                    /usr/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so\n7fb0f6910000-7fb0f6913000 r-xp 00000000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so\n7fb0f6913000-7fb0f6b13000 ---p 00003000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so\n7fb0f6b13000-7fb0f6b14000 r--p 00003000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so\n7fb0f6b14000-7fb0f6b15000 rw-p 00004000 08:02 6968987                    /usr/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so\n7fb0f6b15000-7fb0f6b56000 rw-p 00000000 00:00 0 \n7fb0f6b56000-7fb0f6b59000 r-xp 00000000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so\n7fb0f6b59000-7fb0f6d58000 ---p 00003000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so\n7fb0f6d58000-7fb0f6d59000 r--p 00002000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so\n7fb0f6d59000-7fb0f6d5a000 rw-p 00003000 08:02 101801477                  /usr/lib64/python2.7/lib-dynload/fcntlmodule.so\n7fb0f6d5a000-7fb0f6d5d000 r-xp 00000000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so\n7fb0f6d5d000-7fb0f6f5c000 ---p 00003000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so\n7fb0f6f5c000-7fb0f6f5d000 r--p 00002000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so\n7fb0f6f5d000-7fb0f6f5e000 rw-p 00003000 08:02 101040906                  /usr/lib64/python2.7/lib-dynload/_randommodule.so\n7fb0f6f5e000-7fb0f6f82000 r-xp 00000000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99\n7fb0f6f82000-7fb0f7181000 ---p 00024000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99\n7fb0f7181000-7fb0f7182000 r--p 00023000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99\n7fb0f7182000-7fb0f7183000 rw-p 00024000 08:02 100710414                  /usr/lib64/liblzma.so.5.0.99\n7fb0f7183000-7fb0f71e3000 r-xp 00000000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0\n7fb0f71e3000-7fb0f73e2000 ---p 00060000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0\n7fb0f73e2000-7fb0f73e3000 r--p 0005f000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0\n7fb0f73e3000-7fb0f73e4000 rw-p 00060000 08:02 100710500                  /usr/lib64/libpcre.so.1.2.0\n7fb0f73e4000-7fb0f7405000 r-xp 00000000 08:02 100710510                  /usr/lib64/libselinux.so.1\n7fb0f7405000-7fb0f7605000 ---p 00021000 08:02 100710510                  /usr/lib64/libselinux.so.1\n7fb0f7605000-7fb0f7606000 r--p 00021000 08:02 100710510                  /usr/lib64/libselinux.so.1\n7fb0f7606000-7fb0f7607000 rw-p 00022000 08:02 100710510                  /usr/lib64/libselinux.so.1\n7fb0f7607000-7fb0f7609000 rw-p 00000000 00:00 0 \n7fb0f7609000-7fb0f761f000 r-xp 00000000 08:02 100671125                  /usr/lib64/libresolv-2.17.so\n7fb0f761f000-7fb0f781f000 ---p 00016000 08:02 100671125                  /usr/lib64/libresolv-2.17.so\n7fb0f781f000-7fb0f7820000 r--p 00016000 08:02 100671125                  /usr/lib64/libresolv-2.17.so\n7fb0f7820000-7fb0f7821000 rw-p 00017000 08:02 100671125                  /usr/lib64/libresolv-2.17.so\n7fb0f7821000-7fb0f7823000 rw-p 00000000 00:00 0 \n7fb0f7823000-7fb0f7826000 r-xp 00000000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5\n7fb0f7826000-7fb0f7a25000 ---p 00003000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5\n7fb0f7a25000-7fb0f7a26000 r--p 00002000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5\n7fb0f7a26000-7fb0f7a27000 rw-p 00003000 08:02 100858119                  /usr/lib64/libkeyutils.so.1.5\n7fb0f7a27000-7fb0f7a34000 r-xp 00000000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1\n7fb0f7a34000-7fb0f7c34000 ---p 0000d000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1\n7fb0f7c34000-7fb0f7c35000 r--p 0000d000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1\n7fb0f7c35000-7fb0f7c36000 rw-p 0000e000 08:02 100930551                  /usr/lib64/libkrb5support.so.0.1\n7fb0f7c36000-7fb0f7c4b000 r-xp 00000000 08:02 104805321                  /usr/lib64/libz.so.1.2.7\n7fb0f7c4b000-7fb0f7e4a000 ---p 00015000 08:02 104805321                  /usr/lib64/libz.so.1.2.7\n7fb0f7e4a000-7fb0f7e4b000 r--p 00014000 08:02 104805321                  /usr/lib64/libz.so.1.2.7\n7fb0f7e4b000-7fb0f7e4c000 rw-p 00015000 08:02 104805321                  /usr/lib64/libz.so.1.2.7\n7fb0f7e4c000-7fb0f7e7b000 r-xp 00000000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1\n7fb0f7e7b000-7fb0f807a000 ---p 0002f000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1\n7fb0f807a000-7fb0f807c000 r--p 0002e000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1\n7fb0f807c000-7fb0f807d000 rw-p 00030000 08:02 104805327                  /usr/lib64/libk5crypto.so.3.1\n7fb0f807d000-7fb0f807e000 rw-p 00000000 00:00 0 \n7fb0f807e000-7fb0f8081000 r-xp 00000000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1\n7fb0f8081000-7fb0f8280000 ---p 00003000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1\n7fb0f8280000-7fb0f8281000 r--p 00002000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1\n7fb0f8281000-7fb0f8282000 rw-p 00003000 08:02 100710526                  /usr/lib64/libcom_err.so.2.1\n7fb0f8282000-7fb0f8357000 r-xp 00000000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3\n7fb0f8357000-7fb0f8557000 ---p 000d5000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3\n7fb0f8557000-7fb0f8564000 r--p 000d5000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3\n7fb0f8564000-7fb0f8567000 rw-p 000e2000 08:02 100930549                  /usr/lib64/libkrb5.so.3.3\n7fb0f8567000-7fb0f85b0000 r-xp 00000000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2\n7fb0f85b0000-7fb0f87b0000 ---p 00049000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2\n7fb0f87b0000-7fb0f87b1000 r--p 00049000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2\n7fb0f87b1000-7fb0f87b3000 rw-p 0004a000 08:02 104805324                  /usr/lib64/libgssapi_krb5.so.2.2\n7fb0f87b3000-7fb0f8971000 r-xp 00000000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e\n7fb0f8971000-7fb0f8b71000 ---p 001be000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e\n7fb0f8b71000-7fb0f8b8b000 r--p 001be000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e\n7fb0f8b8b000-7fb0f8b97000 rw-p 001d8000 08:02 101190859                  /usr/lib64/libcrypto.so.1.0.1e\n7fb0f8b97000-7fb0f8b9b000 rw-p 00000000 00:00 0 \n7fb0f8b9b000-7fb0f8bfe000 r-xp 00000000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e\n7fb0f8bfe000-7fb0f8dfd000 ---p 00063000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e\n7fb0f8dfd000-7fb0f8e01000 r--p 00062000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e\n7fb0f8e01000-7fb0f8e08000 rw-p 00066000 08:02 101190861                  /usr/lib64/libssl.so.1.0.1e\n7fb0f8e08000-7fb0f8e0c000 r-xp 00000000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so\n7fb0f8e0c000-7fb0f900b000 ---p 00004000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so\n7fb0f900b000-7fb0f900c000 r--p 00003000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so\n7fb0f900c000-7fb0f900d000 rw-p 00004000 08:02 101040885                  /usr/lib64/python2.7/lib-dynload/_hashlib.so\n7fb0f900d000-7fb0f900e000 rw-p 00000000 00:00 0 \n7fb0f900e000-7fb0f9013000 r-xp 00000000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so\n7fb0f9013000-7fb0f9212000 ---p 00005000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so\n7fb0f9212000-7fb0f9213000 r--p 00004000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so\n7fb0f9213000-7fb0f9214000 rw-p 00005000 08:02 104223615                  /usr/lib64/python2.7/lib-dynload/binascii.so\n7fb0f9214000-7fb0f9230000 r-xp 00000000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so\n7fb0f9230000-7fb0f942f000 ---p 0001c000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so\n7fb0f942f000-7fb0f9430000 r--p 0001b000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so\n7fb0f9430000-7fb0f943a000 rw-p 0001c000 08:02 101040893                  /usr/lib64/python2.7/lib-dynload/_io.so\n7fb0f943a000-7fb0f947b000 rw-p 00000000 00:00 0 \n7fb0f947b000-7fb0f947d000 r-xp 00000000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so\n7fb0f947d000-7fb0f967c000 ---p 00002000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so\n7fb0f967c000-7fb0f967d000 r--p 00001000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so\n7fb0f967d000-7fb0f967e000 rw-p 00002000 08:02 101801478                  /usr/lib64/python2.7/lib-dynload/grpmodule.so\n7fb0f967e000-7fb0f9682000 r-xp 00000000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so\n7fb0f9682000-7fb0f9881000 ---p 00004000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so\n7fb0f9881000-7fb0f9882000 r--p 00003000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so\n7fb0f9882000-7fb0f9884000 rw-p 00004000 08:02 104223646                  /usr/lib64/python2.7/lib-dynload/timemodule.so\n7fb0f9884000-7fb0f9906000 rw-p 00000000 00:00 0 \n7fb0f9906000-7fb0f9909000 r-xp 00000000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so\n7fb0f9909000-7fb0f9b08000 ---p 00003000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so\n7fb0f9b08000-7fb0f9b09000 r--p 00002000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so\n7fb0f9b09000-7fb0f9b0a000 rw-p 00003000 08:02 101040881                  /usr/lib64/python2.7/lib-dynload/_functoolsmodule.so\n7fb0f9b0a000-7fb0f9b0e000 r-xp 00000000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so\n7fb0f9b0e000-7fb0f9d0d000 ---p 00004000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so\n7fb0f9d0d000-7fb0f9d0e000 r--p 00003000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so\n7fb0f9d0e000-7fb0f9d10000 rw-p 00004000 08:02 104223618                  /usr/lib64/python2.7/lib-dynload/cStringIO.so\n7fb0f9d10000-7fb0f9d22000 r-xp 00000000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so\n7fb0f9d22000-7fb0f9f22000 ---p 00012000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so\n7fb0f9f22000-7fb0f9f23000 r--p 00012000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so\n7fb0f9f23000-7fb0f9f24000 rw-p 00013000 08:02 104223617                  /usr/lib64/python2.7/lib-dynload/cPickle.so\n7fb0f9f24000-7fb0f9f65000 rw-p 00000000 00:00 0 \n7fb0fa026000-7fb0fa0e5000 r-xp 00000000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so\n7fb0fa0e5000-7fb0fa2e5000 ---p 000bf000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so\n7fb0fa2e5000-7fb0fa2e6000 r--p 000bf000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so\n7fb0fa2e6000-7fb0fa2ec000 rw-p 000c0000 08:02 703222                     /usr/lib/python2.7/site-packages/numpy/core/umath.so\n7fb0fa2ec000-7fb0fa32f000 rw-p 00000000 00:00 0 \n7fb0fa32f000-7fb0fa340000 r-xp 00000000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so\n7fb0fa340000-7fb0fa53f000 ---p 00011000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so\n7fb0fa53f000-7fb0fa540000 r--p 00010000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so\n7fb0fa540000-7fb0fa544000 rw-p 00011000 08:02 104223620                  /usr/lib64/python2.7/lib-dynload/datetime.so\n7fb0fa544000-7fb0fa559000 r-xp 00000000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\n7fb0fa559000-7fb0fa758000 ---p 00015000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\n7fb0fa758000-7fb0fa759000 r--p 00014000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\n7fb0fa759000-7fb0fa75a000 rw-p 00015000 08:02 102392267                  /usr/lib64/libgcc_s-4.8.5-20150702.so.1\n7fb0fa75a000-7fb0fa795000 r-xp 00000000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0\n7fb0fa795000-7fb0fa994000 ---p 0003b000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0\n7fb0fa994000-7fb0fa995000 r--p 0003a000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0\n7fb0fa995000-7fb0fa996000 rw-p 0003b000 08:02 100936027                  /usr/lib64/libquadmath.so.0.0.0\n7fb0fa996000-7fb0faab5000 r-xp 00000000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0\n7fb0faab5000-7fb0facb5000 ---p 0011f000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0\n7fb0facb5000-7fb0facb6000 r--p 0011f000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0\n7fb0facb6000-7fb0facb8000 rw-p 00120000 08:02 100936029                  /usr/lib64/libgfortran.so.3.0.0\n7fb0facb8000-7fb0fb712000 r-xp 00000000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10\n7fb0fb712000-7fb0fb911000 ---p 00a5a000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10\n7fb0fb911000-7fb0fb916000 r--p 00a59000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10\n7fb0fb916000-7fb0fb91f000 rw-p 00a5e000 08:02 67246515                   /usr/lib64/atlas/libtatlas.so.3.10\n7fb0fb91f000-7fb0fba2d000 rw-p 00000000 00:00 0 \n7fb0fba2d000-7fb0fbba2000 r-xp 00000000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so\n7fb0fbba2000-7fb0fbda2000 ---p 00175000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so\n7fb0fbda2000-7fb0fbda4000 r--p 00175000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so\n7fb0fbda4000-7fb0fbdb1000 rw-p 00177000 08:02 703221                     /usr/lib/python2.7/site-packages/numpy/core/multiarray.so\n7fb0fbdb1000-7fb0fbdc3000 rw-p 00000000 00:00 0 \n7fb0fbdc3000-7fb0fbdca000 r-xp 00000000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so\n7fb0fbdca000-7fb0fbfc9000 ---p 00007000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so\n7fb0fbfc9000-7fb0fbfca000 r--p 00006000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so\n7fb0fbfca000-7fb0fbfcc000 rw-p 00007000 08:02 104223628                  /usr/lib64/python2.7/lib-dynload/math.so\n7fb0fbfcc000-7fb0fbfcf000 r-xp 00000000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so\n7fb0fbfcf000-7fb0fc1ce000 ---p 00003000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so\n7fb0fc1ce000-7fb0fc1cf000 r--p 00002000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so\n7fb0fc1cf000-7fb0fc1d1000 rw-p 00003000 08:02 101040887                  /usr/lib64/python2.7/lib-dynload/_heapq.so\n7fb0fc1d1000-7fb0fc1db000 r-xp 00000000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so\n7fb0fc1db000-7fb0fc3da000 ---p 0000a000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so\n7fb0fc3da000-7fb0fc3db000 r--p 00009000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so\n7fb0fc3db000-7fb0fc3e0000 rw-p 0000a000 08:02 104223626                  /usr/lib64/python2.7/lib-dynload/itertoolsmodule.so\n7fb0fc3e0000-7fb0fc3e6000 r-xp 00000000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so\n7fb0fc3e6000-7fb0fc5e5000 ---p 00006000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so\n7fb0fc5e5000-7fb0fc5e6000 r--p 00005000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so\n7fb0fc5e6000-7fb0fc5e8000 rw-p 00006000 08:02 101040873                  /usr/lib64/python2.7/lib-dynload/_collectionsmodule.so\n7fb0fc5e8000-7fb0fc5f1000 r-xp 00000000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so\n7fb0fc5f1000-7fb0fc7f0000 ---p 00009000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so\n7fb0fc7f0000-7fb0fc7f1000 r--p 00008000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so\n7fb0fc7f1000-7fb0fc7f3000 rw-p 00009000 08:02 101801483                  /usr/lib64/python2.7/lib-dynload/operator.so\n7fb0fc7f3000-7fb0fc7f8000 r-xp 00000000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so\n7fb0fc7f8000-7fb0fc9f7000 ---p 00005000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so\n7fb0fc9f7000-7fb0fc9f8000 r--p 00004000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so\n7fb0fc9f8000-7fb0fc9fa000 rw-p 00005000 08:02 104223638                  /usr/lib64/python2.7/lib-dynload/stropmodule.so\n7fb0fc9fa000-7fb0fca01000 r-xp 00000000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so\n7fb0fca01000-7fb0fcc00000 ---p 00007000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so\n7fb0fcc00000-7fb0fcc01000 r--p 00006000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so\n7fb0fcc01000-7fb0fcc03000 rw-p 00007000 08:02 104223612                  /usr/lib64/python2.7/lib-dynload/_struct.so\n7fb0fcc03000-7fb0fcc0a000 r-xp 00000000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1\n7fb0fcc0a000-7fb0fce09000 ---p 00007000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1\n7fb0fce09000-7fb0fce0a000 r--p 00006000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1\n7fb0fce0a000-7fb0fce0b000 rw-p 00007000 08:02 100710625                  /usr/lib64/libffi.so.6.0.1\n7fb0fce0b000-7fb0fce25000 r-xp 00000000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so\n7fb0fce25000-7fb0fd024000 ---p 0001a000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so\n7fb0fd024000-7fb0fd025000 r--p 00019000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so\n7fb0fd025000-7fb0fd029000 rw-p 0001a000 08:02 101040877                  /usr/lib64/python2.7/lib-dynload/_ctypes.so\n7fb0fd029000-7fb103550000 r--p 00000000 08:02 34398790                   /usr/lib/locale/locale-archive\n7fb103550000-7fb103706000 r-xp 00000000 08:02 100664204                  /usr/lib64/libc-2.17.so\n7fb103706000-7fb103906000 ---p 001b6000 08:02 100664204                  /usr/lib64/libc-2.17.so\n7fb103906000-7fb10390a000 r--p 001b6000 08:02 100664204                  /usr/lib64/libc-2.17.so\n7fb10390a000-7fb10390c000 rw-p 001ba000 08:02 100664204                  /usr/lib64/libc-2.17.so\n7fb10390c000-7fb103911000 rw-p 00000000 00:00 0 \n7fb103911000-7fb103a12000 r-xp 00000000 08:02 100664212                  /usr/lib64/libm-2.17.so\n7fb103a12000-7fb103c11000 ---p 00101000 08:02 100664212                  /usr/lib64/libm-2.17.so\n7fb103c11000-7fb103c12000 r--p 00100000 08:02 100664212                  /usr/lib64/libm-2.17.so\n7fb103c12000-7fb103c13000 rw-p 00101000 08:02 100664212                  /usr/lib64/libm-2.17.so\n7fb103c13000-7fb103c15000 r-xp 00000000 08:02 100671132                  /usr/lib64/libutil-2.17.so\n7fb103c15000-7fb103e14000 ---p 00002000 08:02 100671132                  /usr/lib64/libutil-2.17.so\n7fb103e14000-7fb103e15000 r--p 00001000 08:02 100671132                  /usr/lib64/libutil-2.17.so\n7fb103e15000-7fb103e16000 rw-p 00002000 08:02 100671132                  /usr/lib64/libutil-2.17.so\n7fb103e16000-7fb103e19000 r-xp 00000000 08:02 100664210                  /usr/lib64/libdl-2.17.so\n7fb103e19000-7fb104018000 ---p 00003000 08:02 100664210                  /usr/lib64/libdl-2.17.so\n7fb104018000-7fb104019000 r--p 00002000 08:02 100664210                  /usr/lib64/libdl-2.17.so\n7fb104019000-7fb10401a000 rw-p 00003000 08:02 100664210                  /usr/lib64/libdl-2.17.so\n7fb10401a000-7fb104030000 r-xp 00000000 08:02 100664326                  /usr/lib64/libpthread-2.17.so\n7fb104030000-7fb104230000 ---p 00016000 08:02 100664326                  /usr/lib64/libpthread-2.17.so\n7fb104230000-7fb104231000 r--p 00016000 08:02 100664326                  /usr/lib64/libpthread-2.17.so\n7fb104231000-7fb104232000 rw-p 00017000 08:02 100664326                  /usr/lib64/libpthread-2.17.so\n7fb104232000-7fb104236000 rw-p 00000000 00:00 0 \n7fb104236000-7fb1043ae000 r-xp 00000000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0\n7fb1043ae000-7fb1045ae000 ---p 00178000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0\n7fb1045ae000-7fb1045af000 r--p 00178000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0\n7fb1045af000-7fb1045ed000 rw-p 00179000 08:02 104223592                  /usr/lib64/libpython2.7.so.1.0\n7fb1045ed000-7fb1045fc000 rw-p 00000000 00:00 0 \n7fb1045fc000-7fb10461d000 r-xp 00000000 08:02 100664197                  /usr/lib64/ld-2.17.so\n7fb10464b000-7fb10474f000 rw-p 00000000 00:00 0 \n7fb104780000-7fb104807000 rw-p 00000000 00:00 0 \n7fb10481b000-7fb10481d000 rw-p 00000000 00:00 0 \n7fb10481d000-7fb10481e000 r--p 00021000 08:02 100664197                  /usr/lib64/ld-2.17.so\n7fb10481e000-7fb10481f000 rw-p 00022000 08:02 100664197                  /usr/lib64/ld-2.17.so\n7fb10481f000-7fb104820000 rw-p 00000000 00:00 0 \n7fff62543000-7fff62562000 rwxp 00000000 00:00 0                          [stack]\n7fff62562000-7fff62564000 rw-p 00000000 00:00 0 \n7fff625ef000-7fff625f1000 r-xp 00000000 00:00 0                          [vdso]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\n```\n\nwork0 says:\n\n``` shell\nE tensorflow/core/distributed_runtime/master_session.cc:1086] Cleanup partition error: Unavailable: {\"created\":\"@1476415738.601085137\",\"description\":\"OS Error\",\"errno\":104,\"file\":\"external/grpc/src/core/lib/iomgr/tcp_posix.c\",\"file_line\":229,\"grpc_status\":14,\"os_error\":\"Connection reset by peer\",\"syscall\":\"recvmsg\"}\nINFO:tensorflow:About to execute sync_clean_up_op!\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.UnavailableError'>, {\"created\":\"@1476415738.601085137\",\"description\":\"OS Error\",\"errno\":104,\"file\":\"external/grpc/src/core/lib/iomgr/tcp_posix.c\",\"file_line\":229,\"grpc_status\":14,\"os_error\":\"Connection reset by peer\",\"syscall\":\"recvmsg\"}\n```\n\nand worker1:\n\n``` shell\nTraceback (most recent call last):\n  File \"/export/wangqingze/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py\", line 65, in <module>\n    tf.app.run()\n  File \"/export/wangqingze/tensorflow/_python_build/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"/export/wangqingze/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py\", line 61, in main\n    inception_distributed_train.train(server.target, dataset, cluster_spec)\n  File \"/export/wangqingze/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_distributed_train.py\", line 279, in train\n    loss_value, step = sess.run([train_op, global_step])\n  File \"/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/export/wangqingze/tensorflow/_python_build/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.UnavailableError: {\"created\":\"@1476415738.601603924\",\"description\":\"OS Error\",\"errno\":104,\"file\":\"external/grpc/src/core/lib/iomgr/tcp_posix.c\",\"file_line\":229,\"grpc_status\":14,\"os_error\":\"Connection reset by peer\",\"syscall\":\"recvmsg\"}\n```\n# configuration\n\ncentos 7\nboth inception model and tensorflow build from source, i.e. tensorflow is 0.11.rc, in fact the inception must be modified in order to run, reference https://github.com/tensorflow/models/pull/520\n", "comments": ["What sort of system are you using? That fastbin free error looks weird. Could it be related to:\n- https://rhn.redhat.com/errata/RHBA-2014-0480.html\n- http://stackoverflow.com/questions/17423535/invalid-fastbin-entry-free\n", "@jart  sorry, I forget to say, I run tensorflow on centos 7\n", "Yeah RHBA-2014-0480 was announced five months after CentOS 7 was released. Is it possible that your CentOS was never updated?\n", "``` shell\n$ rpm -qa | grep glibc\nglibc-common-2.17-106.el7_2.4.x86_64\nglibc-2.17-106.el7_2.4.x86_64\nglibc-headers-2.17-106.el7_2.4.x86_64\nglibc-devel-2.17-106.el7_2.4.x86_64\n```\n\nso I think this is not the centos's bug, and the problem doesn't always arise.\n", "It seems like Red Hat might not have fully overcome this issue. I see an open bug on their issue tracker which seems to pertain to exactly this. https://bugzilla.redhat.com/show_bug.cgi?id=1305406 It has recent activity.\n\nDo me a favor. This is just a crazy hunch I have. But if you were to use [tcmalloc](http://goog-perftools.sourceforge.net/doc/tcmalloc.html), either by adding a Bazel rule for it in the BUILD file, or LD_PRELOAD'ing it, then does the problem go away? That actually might work as a workaround. And you'll get a much better heap allocator in the process.\n\nWe also have a similar issue #2815.\n", "as described in https://bugzilla.redhat.com/show_bug.cgi?id=1305406 \uff0c my machine print like this:\n\n``` shell\n$ objdump -r -d /lib64/libc.so.6 | grep -C 20 _int_free | grep -C 10 cmpxchg | head -21 | grep -A 3 cmpxchg | tail -1 | (grep '%r' && echo \"Your libc is likely buggy.\" || echo \"Your libc looks OK.\")\n   7ca3e:   48 85 c9                test   %rcx,%rcx\nYour libc is likely buggy.\n\n$ objdump -r -d /lib64/libc-2.17.so | grep -C 20 _int_free | grep -C 10 cmpxchg | head -21\n   7ca14:   48 85 c9                test   %rcx,%rcx\n   7ca17:   74 09                   je     7ca22 <_int_free+0xe2>\n   7ca19:   8b 41 08                mov    0x8(%rcx),%eax\n   7ca1c:   c1 e8 04                shr    $0x4,%eax\n   7ca1f:   8d 70 fe                lea    -0x2(%rax),%esi\n   7ca22:   48 89 4b 10             mov    %rcx,0x10(%rbx)\n   7ca26:   48 89 c8                mov    %rcx,%rax\n   7ca29:   64 83 3c 25 18 00 00    cmpl   $0x0,%fs:0x18\n   7ca30:   00 00 \n   7ca32:   74 01                   je     7ca35 <_int_free+0xf5>\n   7ca34:   f0 48 0f b1 1a          lock cmpxchg %rbx,(%rdx)\n   7ca39:   48 39 c1                cmp    %rax,%rcx\n   7ca3c:   75 ca                   jne    7ca08 <_int_free+0xc8>\n   7ca3e:   48 85 c9                test   %rcx,%rcx\n   7ca41:   74 09                   je     7ca4c <_int_free+0x10c>\n   7ca43:   44 39 e6                cmp    %r12d,%esi\n   7ca46:   0f 85 b2 08 00 00       jne    7d2fe <_int_free+0x9be>\n   7ca4c:   48 83 c4 48             add    $0x48,%rsp\n   7ca50:   5b                      pop    %rbx\n   7ca51:   5d                      pop    %rbp\n   7ca52:   41 5c                   pop    %r12\n```\n\nas your say\uff0c this may be a bug of glibc, I will try `tcmalloc` in the future\n", "Thanks for sharing the output of that command. It should be helpful for future troubleshooting.\n", "met the same problem on tensorflow1.4.1  centos7.", "met the same problem on tensorflow1.2.0 centos7", "Same problem with tensorflow 2.0.0, glibc 2.12 on centos 6.5.", "Same problem with tensorflow 2.0.0, glibc 2.17 on centos 7."]}, {"number": 4959, "title": "fix some prompt error", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@guotong1988, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv and @tensorflower-gardener to be potential reviewers.\n"]}, {"number": 4958, "title": "refine quantize_graph.py", "body": "delete .keys()\nno need to get keys()\njust use 'in' instead\n", "comments": ["Can one of the admins verify this patch?\n", "@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden, @tensorflower-gardener and @ilya-edrenkin to be potential reviewers.\n", "@tensorflow-jenkins test this please\n", "Thank you for your contribution @frankfqchen. We love code health improvements, but we'd prefer that it not be done in seven separate one-liner commits. It reduces the signal to noise ratio of our change history and puts stress on our CI system. Please merge this pull request (along with the others) into #4951 since that's the only one with an actionable comment.\n"]}, {"number": 4957, "title": "Testing lstm gpu changes", "body": "", "comments": ["@rohan100jain, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @ebrevdo to be potential reviewers.\n"]}, {"number": 4956, "title": "refine server.py", "body": "delete .keys()\nno need to get keys()\njust use 'in' instead \n", "comments": ["Can one of the admins verify this patch?\n", "@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @danmane, @RenatoUtsch and @jart to be potential reviewers.\n", "LGTM. Thank you for your contribution.\n\nMr. Jenkins: test this please\n", "when this pull can be merged?\n", "I think the code will make it more unreadable.\n", "@frankfqchen Could you combine your other PRs for such small and similar  change?\n", "Good catch @terrytangyuan. Seven one-line code health commits is not something we want in the commit history. @frankfqchen could you please merge this pull request (along with the others) into #4951 since that's the only one with an actionable comment?\n"]}, {"number": 4955, "title": "refine benchmark_test.py", "body": "delete .keys()\nno need to get keys()\njust use 'in' instead\n", "comments": ["Can one of the admins verify this patch?\n", "@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo to be a potential reviewer.\n", "Could you actually merge all these small fixes in one PR? It'll reduce load on the testing framework :)\n", "Thanks for all the fixes btw!\n", "Thank you for your contribution @frankfqchen. We love code health improvements, but we'd prefer that it not be done in seven separate one-liner commits. It reduces the signal to noise ratio of our change history and puts stress on our CI system. Please merge this pull request (along with the others) into #4951 since that's the only one with an actionable comment.\n"]}, {"number": 4954, "title": "refine specs.py", "body": "delete .keys()\nthere is no need to get keys()\njust use 'in' instead\n", "comments": ["@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.\n", "Can one of the admins verify this patch?\n", "Thank you for your contribution @frankfqchen. We love code health improvements, but we'd prefer that it not be done in seven separate one-liner commits. It reduces the signal to noise ratio of our change history and puts stress on our CI system. Please merge this pull request (along with the others) into #4951 since that's the only one with an actionable comment.\n"]}, {"number": 4953, "title": "refine importer.py", "body": "there is no need to get keys()\njust use 'in' instead\n", "comments": ["@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @vrv and @josh11b to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thank you for your contribution @frankfqchen. We love code health improvements, but we'd prefer that it not be done in seven separate one-liner commits. It reduces the signal to noise ratio of our change history and puts stress on our CI system. Please merge this pull request (along with the others) into #4951 since that's the only one with an actionable comment.\n"]}, {"number": 4952, "title": "refine optimize_for_inference_lib.py", "body": "there is no need to get keys()\njust use \"in\" directly\n", "comments": ["@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden to be a potential reviewer.\n", "Can one of the admins verify this patch?\n", "Thank you for your contribution @frankfqchen. We love code health improvements, but we'd prefer that it not be done in seven separate one-liner commits. It reduces the signal to noise ratio of our change history and puts stress on our CI system. Please merge this pull request (along with the others) into #4951 since that's the only one with an actionable comment.\n"]}, {"number": 4951, "title": "Minor Python code health improvements", "body": "replace is with == for len()\n", "comments": ["Can one of the admins verify this patch?\n", "@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @sukritiramesh to be a potential reviewer.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "I'm sad to see this PR closed. These code health improvements would have been nice to have. We hope you'll consider contributing again in the future @frankfqchen.\n", "@jart   see my new pull request #5025 \n"]}, {"number": 4950, "title": "Slim namespace has non-slim symbols", "body": "[tensorflow/contrib/slim/**init**.py](https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/contrib/slim/__init__.py) makes symbols from unrelated namespaces available in its own.\n\n``` py\nfrom tensorflow.contrib.framework.python.ops.arg_scope import *\nfrom tensorflow.contrib.framework.python.ops.variables import *\nfrom tensorflow.contrib.layers.python.layers import *\nfrom tensorflow.contrib.layers.python.layers.initializers import *\nfrom tensorflow.contrib.layers.python.layers.regularizers import *\n```\n\nThis makes it difficult for users to reference names canonically. For example #4887 where a user said `tf.contrib.slim.arg_scope` instead of `tf.contrib.framework.arg_scope`.\n\nWe almost certainly want to refactor this namespace so it only exports symbols belonging to slim.\n\nPTAL @sguada\n", "comments": ["The documents need to be updated as well.\n\n```\n   # inputs has shape [batch, 224, 224, 3]\n   with slim.arg_scope(resnet_v2.resnet_arg_scope(is_training)):\n      net, end_points = resnet_v2.resnet_v2_101(inputs, 1000)\n```\n", "So all those symbols actually belonged initially to slim so users of slim want to keep been able to access them in an unify way, so not sure how to solve this.\n", "I think we may mark it as deprecated and refactor current code to use `framework.arg_scope`? @sguada \n", "We can just create functions in that init file that log a warning and delegate to the actual function. Then in v1.o we remove the delegates. We'll need to refactor the internal codebase after the deprecation is added.\n", "@nathansilberman What do you think?\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "This is something that *should* be done, but we probably don't have time right now and I'd like to clean out this issue."]}, {"number": 4949, "title": "Branch 136105500", "body": "", "comments": ["@rohan100jain, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ebrevdo and @martinwicke to be potential reviewers.\n"]}, {"number": 4948, "title": "Fix error handling for when swig isn't found.", "body": "Currently, if swig is not found, then the configure script fails but\ndoes not print an error because we are redirecting the stderr of `type -p swig`\nto /dev/null, which results in this command failing the configure script\nimmediately and silently before the subsequent error handling code can be\nexecuted.\n\nThis script adds a `|| true` clause so that if swig isn't found, we will\nuse the error handling code below to print an error message.\n\nFixes #4928\n", "comments": ["@davidzchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @meteorcloudy to be potential reviewers.\n"]}, {"number": 4947, "title": "Update load_csv > load_csv_with_header for r 0.11", "body": "", "comments": ["@dmathewwws, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @haosdent and @martinwicke to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "You also need to change the actual code that's being tested\n", "I also found that load_csv() needed to be changed. However, DNNClassifier.fit()'s input has also brought ValueError: metrics. I am still looking forward it.\n", "Any updates @dmathewwws  ?\n", "Closing to clear out backlog, ping this thread and we can reopen (or send a new PR after resolving conflicts).\n"]}, {"number": 4946, "title": "Added list functionality to registry object", "body": "Very small change which I'm personally going to find useful shortly, I think others will too.\n", "comments": ["@klattimer, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman and @vrv to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n", "OK Indentation fixed, my editor is set to 4 spaces.\n", "@tensorflow-jenkins test this please\n", "@rohan100jain is there anything left to do on this?\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n", "Sorry, jenkins broken because of a broken merge. See thread on #5103 \n", "Jenkins, test this please.\n", "Jenkins, test this please.\n"]}, {"number": 4945, "title": "Branch 136063535", "body": "", "comments": ["@rohan100jain, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @dsmilkov and @keveman to be potential reviewers.\n"]}, {"number": 4944, "title": "Tensorflow GPU installation fails due to Bazel build ", "body": "I've been trying to install tensorflow with GPU support using these steps:\nhttp://www.nvidia.com/object/gpu-accelerated-applications-tensorflow-installation.html\n\nThis is the error message that I'm getting when I try to run the bazel build command for building the tensorflow pip package (with the --config-cuda flag set):\n\n`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\n\ni get :  \n    `The specified --crosstool_top '//third_party/gpus/crosstool:crosstool' is not a valid cc_toolchain_suite rule`\n\nWhat's strange is that if i remove the --config=cuda flag, I don't get the error message while building and I'm able to install tensorflow successfully - but without GPU support.\n", "comments": ["The posting guidelines ask for information that could be very helpful such as:\n\n[Similar Posts](https://github.com/tensorflow/tensorflow/issues/4368)\nOperating System\nCuda, CudNN & Bazel Version\n\nThe type of graphic card as well wouldn't hurt.  I may suggest a \"$ bazel clean\" and re-run the \"./configure\" as well.\n", "It seems this issue is a duplicate of http://stackoverflow.com/questions/40010981/tensorflow-with-gpu-support-installation-error-the-specified-crosstool-top-i. We recommend Stack Overflow for support questions. We try to keep this issue tracker focused on bugs and feature requests. Also thanks for helping out with support @wagonhelm.\n", "not solved yet\n", "Since we're getting multiple reports, I'm going to reopen this issue so it can be triaged again.\n", "I normally use Ubuntu 14.04 but I had no problems installing from sources using:\n\nUbuntu 16.04 \nCuda 8\nCudnn 5.1.5\ntensorflow0.11rc1\nBazel 0.3.2\n\nThese are the [steps](http://wp.me/p7GvOc-2H) I took, and I try to keep them up to date with each new version.  I did notice a couple expected problems when trying to build and install using anaconda 3 if you just do conda install pip and use the pip packages from tf's website it works fine. I also notice a couple things that might cause issues with those Nvidia instructions.\n", "The pointed out nvidia documentation (http://www.nvidia.com/object/gpu-accelerated-applications-tensorflow-installation.html) says \n`git reset --hard 70de76e`\n\nThis commit is 4 months old! I assume this is why people need to downgrade their bazel version as well to get it work. Moreover, the documentation is using CUDA 8.0 with that commit. But 8.0 is supported as of r0.11-rc1. Guess, the nvidia documentation should be updated.\n", "this issue was giving me a lot of headache. After talking to a few experienced computer vision engineers, i was told that the 'docker' installation of tensor-flow is the easiest way to get things going\nhttps://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#docker-installation\n\ni tried docker and it saved so much of my time. I run everything on that and do not have to worry about the compatibility issues.\n", "Glad the docker instructions worked for you @Sadrpour \nAs @firolino pointed out, the documentation at the NVIDIA website is asking for a very old version of the TensorFlow source code.\n\nUpdating the Nvidia website is not something the TensorFlow team can do :).\nPlease point this out to the Nvidia folks, and we will try to do the same. Thanks!\n", "I am facing the same issue. I updated the CROSSTOOL file and added `cxx_builtin_include_directory: \"/usr/local/cuda/include\"` But I am still facing the same issue. \nI am using the following:\nUbuntu 14.04 \nCuda 7.5\nCudnn 5.0\nBazel 0.4.0\n\nCan someone guide me as to how to build GPU enabled TensorFlow?\n", "I met the similar problem. Any solution or advice? Thanks.\n", "And anyone knows how to uninstall bazel completely? I suppose it's the bazel problem and want to reinstall it.\n", "I think this issue is not related with bazel version.\r\nI'm facing this issue on bazel 0.4.1 and bazel 0.3.2 also.\r\nAnyone know how to fixed this issue?\r\n>> Update. should be used bazel 0.3.2!!!\r\n \r\n@ian2720 You can remove bazel as the following. (refer link: https://github.com/bazelbuild/bazel/issues/838)\r\nrm -fr ~/.bazel ~/.bazelrc \r\nrm -fr ~/.cache/bazel\r\nAnd you can install manually old version bazel (refer link: https://bazel.build/versions/master/docs/install.html#compiling-from-source)", "I've complete to build tensorflow.\r\nI'm using the latest source version(Not using  git reset --hard 70de76e ) after trying to build then completed.\r\n\r\nSo, try the the following command\r\n$git reset --hard\r\n$git pull\r\n$git reset --hard 287db3a9b0701021f302e7bb58af5cf89fdcd424\r\n\r\nThe commit info is as the following:\r\ncommit 287db3a9b0701021f302e7bb58af5cf89fdcd424\r\nMerge: 50460e9 52c46a7\r\nAuthor: Andrew Harp <andrewharp@users.noreply.github.com>\r\nDate:   Tue Dec 6 23:10:35 2016 -0500\r\n    Merge pull request #6137 from andrewharp/branch_141241224    \r\n    Branch 141241224\r\n", "Folks.\r\nI've written the installation script of the GPU-enabled version of Tensorflow.\r\nPlease see the below link. :)\r\nhttps://github.com/uher/InstallGpuEnableTensorflow", "In my case, --config=cuda7.5 is working", "@dr2mer : tried it your way with both `--config=cuda7.5` and `--config=cuda8.0`. Both eventually resulted in\r\n```\r\nERROR: /home/myname/tensorflow/tensorflow/python/BUILD:1081:1: in cc_library rule //tensorflow/python:tf_session_helper: non-test target '//tensorflow/python:tf_session_helper' depends on testonly target '//tensorflow/python:construction_fails_op' and doesn't have testonly attribute set.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\nINFO: Elapsed time: 1.129s\r\n\r\n```\r\n\r\nThe specs are Ubuntu 17.04 x64, bazel 0.4.2 CUDA 8.0 and cudnn 5.1.", "@StrangeTcy Commenting out `testonly=1` in the target `construction_fails_op` resolved the issue for me.", "@dr2mer worked for cuda8.0. THX!", "@dr2mer I followed your suggestion and the build managed to finish using --config=cuda7.5 . \r\nThe problem is that I tried to run [this example](https://www.tensorflow.org/get_started/os_setup#train_your_first_tensorflow_neural_net_model) but it always runs on the cpu and I have no idea why. ", "I am not sure that setting the flag to something other than --config=cuda gets the job actually done. \r\nCould you double check that you're actually running your code on the gpu?\r\n\r\nI ended up solving my problem like this : https://github.com/tensorflow/tensorflow/issues/7118", "I agree with @Ettrai. In my case --config=cuda8.0 or --config=cuda8 is working, but the code runs on the CPU only.\r\n\r\n", "I tried\r\n`bazel build --config=opt --config=cuda8.0 //tensorflow/tools/pip_package:build_pip_package`\r\nand it says\r\n> WARNING: Config values are not defined in any .rc file: cuda8.0\r\n\r\nSo apparently it just ignore the cuda8.0 option as if it was not there and therefore is equivalent to\r\n`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\nthe command to build CPU only version.", " i had install tensorflow,but it show error in importing tensorflow  due to bazel...! any help that i can get?", "In my case '--config=cuda' not working but '--config=cuda8.0' works. I am using a previous version (v0.9) to run some previous codes while v1.2 is out.", "In my case, I use older bazel version and fix this issue"]}, {"number": 4943, "title": "error building tensorflow example for ios", "body": "Hi,\nI am trying build the ios app detailed in https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\n\nbut it fails with:\n\n**checking whether we are cross compiling... configure: error: in `/projects/tensorflow/tensorflow/tensorflow/contrib/makefile/downloads/protobuf':\nconfigure: error: cannot run C compiled programs.\nIf you meant to cross compile, use`--host'.\nSee `config.log' for more details**\n\nsystem details;\nmacos sierra, 10.12\n\nbrew config output: Any pointers will be appreciated.\n\nMacBook-Pro:tensorflow $ brew config\nHOMEBREW_VERSION: 1.0.6\nORIGIN: https:/\nHEAD: 35ee2831086e923e7fcaf75fb440b01312e3f9c5\nLast commit: 7 days ago\nCore tap ORIGIN: https:/\nCore tap HEAD: 80f18defefc814d60d3799e58835cbeffc8e93c8\nCore tap last commit: 2 hours ago\nHOMEBREW_PREFIX: /usr/local\nHOMEBREW_REPOSITORY: /usr/local/Homebrew\nHOMEBREW_CELLAR: /usr/local/Cellar\nHOMEBREW_BOTTLE_DOMAIN: https:/\nCPU: quad-core 64-bit broadwell\nHomebrew Ruby: 2.0.0-p648\nClang: 8.0 build 800\nGit: 2.8.4 => /Applications/Xcode.app/Contents/Developer/usr/bin/git\nPerl: /usr/bin/perl\nPython: /usr/bin/python\nRuby: /usr/bin/ruby => /System/Library/Frameworks/Ruby.framework/Versions/2.0/usr/bin/ruby\nJava: 1.8.0_60\nmacOS: 10.12-x86_64\nXcode: 8.0\nCLT: 8.0.0.0.1.1472435881\nX11: N/A\n", "comments": ["Sorry, duplicate of #4640 \n"]}]