[{"number": 38076, "title": "R2.1 Update fixes #38075", "body": "Update kernel_size zero for value error", "comments": ["Can you make it on `master` first and then cherry-pick here please?\r\n\r\nWe don't update release branches except when doing releases. After a final release the release branch gets updated only for patch releases (which are only done for security purposes)", "The master branch already has this fixed, user requested it on tf2.1 so I did it on this branch", "In this case, it will have to wait for until we do a patch release (due to security issues). At that point we will run the CI and investigate if we can safely pull this in.", "> \r\n> \r\n> In this case, it will have to wait for until we do a patch release (due to security issues). At that point we will run the CI and investigate if we can safely pull this in.\r\n\r\nOk and Thank you.", "This is invalid\r\n\r\n```\r\nFAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/python/keras/layers/convolutional_test.py:170: [E0001(syntax-error), ] expected an indented block\r\n```"]}, {"number": 38075, "title": "Invalid Output shape to Invalid input", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Yes\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: No\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow 2.1 (source) \r\n- Python version: - 3.7\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:No\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen`kenerl_size=0` the size of image increases\r\n**Describe the expected behavior**\r\nValue error\r\n**Standalone code to reproduce the issue** \r\n`import tensorflow as tf`\r\n`inputs=tf.keras.layers.Input(shape=(32, 32, 3))`\r\n`x=tf.keras.layers.Conv2D(64,kernel_size=0)(inputs)`\r\n`x=tf.keras.layers.Flatten()(x)`\r\n`outputs=tf.keras.layers.Dense(64)(x)`\r\n`model=tf.keras.Model(inputs,outputs)`\r\n`model.summary()`\r\n\r\nOutput:\r\n![issue1](https://user-images.githubusercontent.com/62893143/78043941-98d88400-7391-11ea-99b0-37d10eb84e46.PNG)\r\n\r\n\r\n", "comments": ["Please make the changes in 2.1 version ,being an instructor i am unable to show to people about tensorflow's tiny mistakes", "@soumyadeepabhaumik,\r\nI was able to reproduce the issue with [TF v2.2.0rc2](https://colab.research.google.com/gist/amahendrakar/0d207dfe652f6cb0b0b6291db2bbb7a1/38075-2-2.ipynb). However, the issue seems to be fixed with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/67bfd7bb5ebe4eb7513650dfa4847bd0/38075.ipynb) i.e. TF v2.2.0-dev20200331. Please find the attached gist. Thanks!", "@soumyadeepabhaumik,\r\nAny updates regarding this issue? Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38075\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38075\">No</a>\n"]}, {"number": 38074, "title": "Tf issue", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 17, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\RONAK JAIN\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "You did not fill issue template, you didn't check for duplicates.\r\n\r\nClosing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38074\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38074\">No</a>\n"]}, {"number": 38073, "title": "TFLite conversion coredumps", "body": "**System information** : Ubuntu18.04, CUDA 10\r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): No. Problem exists even when using tflite_convert OR writing custom code as described in [documentation](https://www.tensorflow.org/lite/performance/post_training_quantization)\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): Binary/Tensorflow: 2.0.1\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory: Cuda 10/GTX1070Ti, 8G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nDescribe the current behavior\r\nTensorflow lite conversion dumps core both for 8 bit and 16 bit quantizations and no tflite file is generated when using the from_saved_model converter. The model shape (as can be seen from saved_model_cli) is below. The model is a SSD-mobilenetv2 transfer learned by using tensorflow detection API on Tensorflow 1.14\r\n==\r\n\r\nsignature_def['serving_default']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['inputs'] tensor_info:\r\n        dtype: DT_UINT8\r\n        shape: (-1, 300, 300, 3)\r\n        name: image_tensor:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['detection_boxes'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 30, 4)\r\n        name: detection_boxes:0\r\n    outputs['detection_classes'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 30)\r\n        name: detection_classes:0\r\n    outputs['detection_multiclass_scores'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 30, 5)\r\n        name: detection_multiclass_scores:0\r\n    outputs['detection_scores'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 30)\r\n        name: detection_scores:0\r\n    outputs['num_detections'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1)\r\n        name: num_detections:0\r\n    outputs['raw_detection_boxes'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, -1, 4)\r\n        name: raw_detection_boxes:0\r\n    outputs['raw_detection_scores'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, -1, 5)\r\n        name: raw_detection_scores:0\r\n  Method name is: tensorflow/serving/predict\r\n==\r\n**Describe the expected behavior**\r\n\r\nI expect the tflite file to be generated by following the public documentation on Tensorflow site and don't expect core dumps.\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n2020-03-31 06:46:09.156599: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-03-31 06:46:09.156683: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-03-31 06:46:09.157414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:07:00.0\r\n2020-03-31 06:46:09.157448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-03-31 06:46:09.157459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-03-31 06:46:09.157469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-03-31 06:46:09.157478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-03-31 06:46:09.157487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-03-31 06:46:09.157496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-03-31 06:46:09.157505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-03-31 06:46:09.157937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-03-31 06:46:09.157973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-03-31 06:46:09.157980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-03-31 06:46:09.157986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-03-31 06:46:09.158409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6624 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\r\n2020-03-31 06:46:09.471641: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2020-03-31 06:46:09.471673: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 1765 nodes (-1299), 2239 edges (-1452), time = 191.291ms.\r\n2020-03-31 06:46:09.471681: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 1765 nodes (0), 2239 edges (0), time = 51.045ms.\r\nTraceback (most recent call last):\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/bin/tflite_convert\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 502, in run_main\r\n    _convert_tf2_model(tflite_flags)\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 221, in _convert_tf2_model\r\n    tflite_model = converter.convert()\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 446, in convert\r\n    **converter_kwargs)\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-03-31 06:46:11.117660: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.117740: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128695: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128746: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128807: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128829: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128838: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128846: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128887: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.128899: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128907: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.128914: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128921: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128930: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.128937: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128945: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128951: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128956: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-31 06:46:11.128965: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128972: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.128978: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.128993: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.129001: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.129007: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.129011: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.129022: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-03-31 06:46:11.129035: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.129045: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.129051: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.129066: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-31 06:46:11.129075: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.129086: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.129097: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.129114: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.129123: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.130076: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130091: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130100: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130107: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130115: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130122: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130130: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130136: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130144: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130150: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130158: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130165: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130173: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130179: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130186: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130196: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130202: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130208: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130214: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130220: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-31 06:46:11.130226: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130234: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130240: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130245: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-31 06:46:11.130253: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130259: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130265: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130271: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130276: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-31 06:46:11.130283: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130291: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130297: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130313: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130319: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130323: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130328: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130332: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130336: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-31 06:46:11.130344: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130350: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130354: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-31 06:46:11.130363: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130370: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130376: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130380: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130387: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130395: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130401: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130406: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130412: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-31 06:46:11.130418: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130424: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130435: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130442: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.130455: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-03-31 06:46:11.130474: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.130482: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.130490: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.130499: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.130506: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-31 06:46:11.130514: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.130521: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.130940: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.130952: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-31 06:46:11.130960: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-31 06:46:11.130967: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-31 06:46:11.130974: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-31 06:46:11.130981: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.130988: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-31 06:46:11.130993: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-31 06:46:11.131050: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-31 06:46:11.131059: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.131068: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.131078: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.131091: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.131099: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-31 06:46:11.131105: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-31 06:46:11.131181: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-03-31 06:46:11.131191: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-03-31 06:46:11.131199: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-03-31 06:46:11.131207: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-03-31 06:46:11.131285: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-03-31 06:46:11.131358: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-03-31 06:46:11.131403: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.131510: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.131520: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.131531: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.131538: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-31 06:46:11.157600: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1120 operators, 2034 arrays (0 quantized)\r\n2020-03-31 06:46:11.214243: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1113 operators, 2018 arrays (0 quantized)\r\n2020-03-31 06:46:11.277956: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1113 operators, 2018 arrays (0 quantized)\r\n2020-03-31 06:46:11.340779: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 610 operators, 1209 arrays (0 quantized)\r\n2020-03-31 06:46:11.358315: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 610 operators, 1209 arrays (0 quantized)\r\n2020-03-31 06:46:11.372161: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 610 operators, 1209 arrays (0 quantized)\r\n2020-03-31 06:46:11.401094: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 1080704 bytes, theoretical optimal value: 1080704 bytes.\r\n2020-03-31 06:46:11.404128: F tensorflow/lite/toco/tooling_util.cc:2275] Check failed: array.data_type == array.final_data_type Array \"image_tensor\" has mis-matching actual and final data types (data_type=uint8, final_data_type=float).\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fbd58971740 (most recent call first):\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"/home/vk1z/.virtualenvs/tensorflow-lite-convert/bin/toco_from_protos\", line 8 in <module>\r\nAborted (core dumped)\r\n\r\n==\r\nYes, I am aware of [35376](https://github.com/tensorflow/tensorflow/issues/35736) but I don't think that a coredump is an expected output of any conversion process. ", "comments": ["Sorry about the unexpected capitalization above.", "Follow up; The exact same (coredump) behavior is observed when trying to convert the SSD Mobilenet model from the tensorflow detection Zoo - specifically: ssd_mobilenet_v2_coco_2018_03_29. \r\n\r\nThe model there was also converted to have input shape (None, 300, 300, 3) (since tflite conversions from (None, None, None, 3) fail). Consequently I believe that should be an easy bug to repro and hopefully fix since this makes the export of tensorflow lite models unusable on Tensorflow 2.0.1. \r\n\r\n", "@vk1z \r\n\r\nCan you please share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "Will do so today.", "@vk1z \r\n\r\nAny update on this issue please. Thanks!", "Will do on the weeend. Apologies. ", "@vk1z \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38073\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38073\">No</a>\n"]}, {"number": 38072, "title": "tf2.1 tf.nn.ctc_loss slower\uff0ctakes up a lot of GPU memory", "body": "Please make sure that this is a bug. As per our\r\nGitHub Policy,\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template\r\n\r\nSystem information\r\n\r\nHave I written custom code : yes\r\nOS Platform and Distribution: centos 7, not Distribution\r\nTensorFlow installed from docker: docker pull nvcr.io/nvidia/tensorflow:20.02-tf2-py3 .tensorflow version is 2.1.0\r\nDescribe the current behavior\r\n\r\nJust run the forward algorithm and use watch -n 0.2 nvidia-smi to watch the GPU utilization rate always stay at 86% ~ 95%. However, after calculating tf.nn.ctc_loss, the GPU usage jitter is drastically from 0% to 85%. Seeing the decline in gpu utilization is particularly severe, personally guess that this tf.nn.ctc_loss is implemented by cpu, will there be a switch between gpu memory and memory when calculating loss?\r\n\r\nDescribe the expected behavior\r\n\r\nCalculate the loss and update gradient normally, the GPU usage rate remains at 85%. Currently, the performance of calculating the loss using tf.nn.ctc_loss of tf2.1 does not meet expectations.\r\n\r\nHere is my test code. The run_forward_noloss function is a simple forward calculation function. Run_forward_withloss is forward calculation +loss calculation.\r\n```\r\n# _*_ coding:utf-8 _*_\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport time\r\nimport tensorflow as tf\r\nlayers = tf.keras.layers\r\ntime_func = lambda: time.clock()*1000\r\n\r\nclass CRNNEncoder(tf.keras.Model):\r\n    def __init__(self, configs, name=None):\r\n        super(CRNNEncoder, self).__init__(name=name)\r\n        self.vocab_size = configs['vocab_size']\r\n        self.conv1 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv1')\r\n        self.pool1 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')\r\n        self.conv2 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv2')\r\n        self.pool2 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')\r\n        self.conv3 = layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv3')\r\n        self.conv4 = layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv4')\r\n        self.padd4 = layers.ZeroPadding2D(padding=(0, 1))\r\n        self.pool4 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool3')\r\n        self.conv5 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='conv5')\r\n        self.bncv5 = layers.BatchNormalization(axis=-1, name='bnconv5')\r\n        self.conv6 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='conv6')\r\n        self.bncv6 = layers.BatchNormalization(axis=-1, name='bnconv6')\r\n        self.pddd6 = layers.ZeroPadding2D(padding=(0, 1))\r\n        self.pool6 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool4')\r\n        self.conv7 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='valid', name='conv7')\r\n        self.final_layer = tf.keras.layers.Dense(self.vocab_size, name='ctc_decoder_linear')\r\n\r\n    def get_feature_step(self, widths):\r\n        return tf.cast((tf.cast(widths, tf.float32)/4.0), dtype=tf.int32)\r\n    @tf.function\r\n    def call(self, inputs, widths, training=True):\r\n        tf.print('call input:', inputs.shape)\r\n        features = self.conv1(inputs)\r\n        features = self.pool1(features)\r\n        features = self.conv2(features)\r\n        features = self.pool2(features)\r\n        features = self.conv3(features)\r\n        features = self.conv4(features)\r\n        features = self.padd4(features)\r\n        features = self.pool4(features)\r\n        features = self.conv5(features)\r\n        features = self.bncv5(features, training=training)\r\n        features = self.conv6(features)\r\n        features = self.bncv6(features, training=training)\r\n        features = self.pddd6(features)\r\n        features = self.pool6(features)\r\n        features = self.conv7(features)\r\n        cnn_features = tf.reduce_max(features, axis=1)\r\n        # rnn_features = self.run_bilstm1(rnn_features)\r\n        rnn_features = cnn_features\r\n        final_logits = self.final_layer(rnn_features)\r\n        widths = self.get_feature_step(widths)\r\n        return cnn_features, rnn_features, widths, final_logits\r\n\r\ndef run_forward_noloss():\r\n    batch = 24 \r\n    imgh = 48\r\n    imgw = 1024 \r\n    imgc = 3\r\n    vocab_size = 1424\r\n    configs = {'vocab_size': vocab_size}\r\n    model = CRNNEncoder(configs)\r\n    images = tf.random.uniform([batch, imgh, imgw, imgc], minval=-1, maxval=1)\r\n    widths = tf.fill([batch], imgw)\r\n    logit_mean = tf.keras.metrics.Mean('logit_mean')\r\n    init_time = time_func()\r\n    for i in range(200):\r\n        cnn_features, rnn_features, widths, final_logits = model(images, widths)\r\n        final_logits = tf.reduce_mean(final_logits)\r\n        logit_mean.update_state(final_logits)\r\n    fini_time = time_func()\r\n    print('time:', fini_time-init_time)\r\n    print(logit_mean.result().numpy)\r\n\r\ndef run_forward_withloss():\r\n    batch = 24\r\n    imgh = 48\r\n    imgw = 1024\r\n    imgc = 3\r\n    txtlen = 64\r\n    vocab_size = 1424\r\n    eos_id = vocab_size - 1\r\n    configs = {'vocab_size': vocab_size}\r\n    model = CRNNEncoder(configs)\r\n    images = tf.random.uniform([batch, imgh, imgw, imgc], minval=-1, maxval=1)\r\n    widths = tf.fill([batch], imgw)\r\n    labels = tf.fill([batch, txtlen], 0)\r\n    labels_len = tf.fill([batch], txtlen)\r\n    ctc_loss_mean = tf.keras.metrics.Mean('ctc_loss_mean')\r\n    init_time = time_func()\r\n    for i in range(200):\r\n        cnn_features, rnn_features, widths, final_logits = model(images, widths)\r\n        ctc_loss = tf.nn.ctc_loss(labels=labels,\r\n                                  logits=final_logits,\r\n                                  label_length=labels_len,\r\n                                  logit_length=widths,\r\n                                  blank_index=eos_id,\r\n                                  logits_time_major=False)\r\n\r\n        ctc_loss = tf.reduce_mean(ctc_loss)\r\n        ctc_loss_mean.update_state(ctc_loss)\r\n    fini_time = time_func()\r\n    print('time:', fini_time - init_time)\r\n    print(ctc_loss_mean.result().numpy)\r\n\r\nif __name__ == '__main__':\r\n    run_forward_noloss()\r\n    run_forward_withloss()\r\n```", "comments": ["Another problem is that tf.ctc_loss using tf2.1 will take up a lot of gpu memory. Make training code often OOM, very annoying!\r\n\r\n```\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n```\r\nAdd the above code snippet to the code, we found that when tf.ctc_loss is not calculated, the GPU storage uses 4865MiB, when tf.ctc_loss is turned on, the GPU storage uses 15517MiB", "Since the calculation of ctc_loss is not in tf.function, I worry that there will be additional overhead. Now the code has been re-modified to encapsulate the loss calculation into the function of tf.function. Here is the latest modified code\r\n```\r\n# _*_ coding:utf-8 _*_\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport time\r\nimport tensorflow as tf\r\nlayers = tf.keras.layers\r\ntime_func = lambda: time.clock()*1000\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\nclass CRNNEncoder(tf.keras.Model):\r\n    def __init__(self, configs, name=None):\r\n        super(CRNNEncoder, self).__init__(name=name)\r\n\r\n        self.vocab_size = configs['vocab_size']\r\n        self.conv1 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv1')\r\n        self.pool1 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')\r\n        self.conv2 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv2')\r\n        self.pool2 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')\r\n        self.conv3 = layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv3')\r\n        self.conv4 = layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv4')\r\n\r\n        self.padd4 = layers.ZeroPadding2D(padding=(0, 1))\r\n        self.pool4 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool3')\r\n        self.conv5 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='conv5')\r\n        self.bncv5 = layers.BatchNormalization(axis=-1, name='bnconv5')\r\n        self.conv6 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='conv6')\r\n        self.bncv6 = layers.BatchNormalization(axis=-1, name='bnconv6')\r\n        self.pddd6 = layers.ZeroPadding2D(padding=(0, 1))\r\n        self.pool6 = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool4')\r\n        self.conv7 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='valid', name='conv7')\r\n        self.final_layer = tf.keras.layers.Dense(self.vocab_size, name='ctc_decoder_linear')\r\n\r\n    def get_feature_step(self, widths):\r\n        return tf.cast((tf.cast(widths, tf.float32)/4.0), dtype=tf.int32)\r\n\r\n    @tf.function\r\n    def call(self, inputs, widths, training=True):\r\n        tf.print('call input:', inputs.shape)\r\n        features = self.conv1(inputs)\r\n        features = self.pool1(features)\r\n        features = self.conv2(features)\r\n        features = self.pool2(features)\r\n        features = self.conv3(features)\r\n        features = self.conv4(features)\r\n        features = self.padd4(features)\r\n        features = self.pool4(features)\r\n        features = self.conv5(features)\r\n        features = self.bncv5(features, training=training)\r\n        features = self.conv6(features)\r\n        features = self.bncv6(features, training=training)\r\n        features = self.pddd6(features)\r\n        features = self.pool6(features)\r\n        features = self.conv7(features)\r\n        cnn_features = tf.reduce_max(features, axis=1)\r\n        # rnn_features = self.run_bilstm1(rnn_features)\r\n        rnn_features = cnn_features\r\n        final_logits = self.final_layer(rnn_features)\r\n        widths = self.get_feature_step(widths)\r\n        return cnn_features, rnn_features, widths, final_logits\r\n\r\n\r\ndef run_forward_noloss():\r\n    batch = 24 \r\n    imgh = 48\r\n    imgw = 1024 \r\n    imgc = 3\r\n    vocab_size = 1424\r\n    configs = {'vocab_size': vocab_size}\r\n    model = CRNNEncoder(configs)\r\n    images = tf.random.uniform([batch, imgh, imgw, imgc], minval=-1, maxval=1)\r\n    widths = tf.fill([batch], imgw)\r\n    logit_mean = tf.keras.metrics.Mean('logit_mean')\r\n    init_time = time_func()\r\n    for i in range(2000):\r\n        cnn_features, rnn_features, widths, final_logits = model(images, widths)\r\n        final_logits = tf.reduce_mean(final_logits)\r\n        logit_mean.update_state(final_logits)\r\n\r\n    fini_time = time_func()\r\n    print('time:', fini_time-init_time)\r\n    print(logit_mean.result().numpy)\r\n\r\n\r\ndef run_forward_withloss():\r\n    batch = 24\r\n    imgh = 48\r\n    imgw = 1024\r\n    imgc = 3\r\n    txtlen = 64\r\n    vocab_size = 1424\r\n    eos_id = vocab_size - 1\r\n    configs = {'vocab_size': vocab_size}\r\n    model = CRNNEncoder(configs)\r\n    images = tf.random.uniform([batch, imgh, imgw, imgc], minval=-1, maxval=1)\r\n    widths = tf.fill([batch], imgw)\r\n    labels = tf.fill([batch, txtlen], 0)\r\n    labels_len = tf.fill([batch], txtlen)\r\n    ctc_loss_mean = tf.keras.metrics.Mean('ctc_loss_mean')\r\n\r\n    @tf.function\r\n    def run_step(images_, widths_, labels_, labels_len_):\r\n        cnn_features, rnn_features, widths, final_logits = model(images_, widths_)\r\n\r\n        ctc_loss = tf.nn.ctc_loss(labels=labels_,\r\n                                  logits=final_logits,\r\n                                  label_length=labels_len_,\r\n                                  logit_length=widths,\r\n                                  blank_index=eos_id,\r\n                                  logits_time_major=False)\r\n\r\n        ctc_loss = tf.reduce_mean(ctc_loss)\r\n        ctc_loss_mean.update_state(ctc_loss)\r\n\r\n\r\n    init_time = time_func()\r\n    for i in range(2000):\r\n        run_step(images, widths, labels, labels_len)\r\n\r\n    fini_time = time_func()\r\n    print('time:', fini_time - init_time)\r\n    print(ctc_loss_mean.result().numpy)\r\n\r\n\r\nif __name__ == '__main__':\r\n    #run_forward_noloss()\r\n    run_forward_withloss()\r\n```\r\nrun the above code  we found that when tf.ctc_loss is not calculated, the GPU storage uses 4865MiB, gpu usage at 95%\uff1bwhen tf.ctc_loss is turned on, the GPU storage uses 8961MiB\uff0c GPU usage jitter is drastically from 20% to 50%\r\n", "On TPU and GPU: Only dense padded labels are supported. Are you by any chance using sparse padded labels?", "Closing this issue as it has been inactive for 2 weeks. Please add additional comments for us to open this issue again.", "I think that I also have the issue. I am training a DeepSpeech model from original paper. If tf.nn.ctc_loss calculation is replaced by logits.sum() then GPU RAM consumption stays at 4Gb for a batch of 10. When I actually use tf.nn.ctc_loss I get OOM error on 1080Ti with 12Gb RAM for batch of one example which has logits of length ~1500 and labels of length ~300. \r\nI can provide minimal code for reproduction if neccessary."]}, {"number": 38071, "title": "INT8 quantized model for TF Lite", "body": "Hi, I tried to run INT8 model on my device with TFLite but it seems its inference time is very slow and maybe it could only be run on CPU. While I run UINT8 model, it is very fast. How should I do so that it could be run normally for INT8 model? I noticed that there is an option for convert F16 to F32 by using \"setAllowFp16PrecisionForFp32\". is there any similar setting to convert INT8 to UINT8? thanks.", "comments": ["@noticebo, Can you provide the standalone code to reproduce the issue. Thanks!", "@noticebo,Please provide the complete code to reproduce the issue. Thanks", "hi. due to company information limit, I could not provide the complete code. ", "@noticebo, It will be difficult to trace the issue without code snippet. Can you create sample code and share with us.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@noticebo,\r\nplease update on the above comment", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38070, "title": "/bin/sh: 1: python: not found error when generate projects", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., WSLv1 Ubuntu 18.04 ):\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source):  head\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): n/a\r\n\r\n**Describe the problem**\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nPython is 3.6.9\r\n\r\nAfter clone a fresh repo, run command:\r\n```make -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn generate_projects```\r\n\r\nReported error:\r\n```/bin/sh: 1: python: not found\r\ntensorflow/lite/micro/examples/person_detection_experimental/Makefile.inc:55: recipe for target 'tensorflow/lite/micro/\r\ntools/make/gen/linux_x86_64/prj/person_detection_test_int8/keil/keil_project.uvprojx' failed\r\nmake: *** [tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/person_detection_test_int8/keil/keil_project.uvprojx]\r\nError 127```\r\n\r\n\r\n\r\n", "comments": ["Hi @xiongyu0523 \r\nI have the same issue. \r\nDid you fix it?", "@xiongyu0523 \r\nAs we have the latest stable version 2.6.0, Can you try building TF 2.6.0 or any latest 2.x version and let us know if this is still an issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38070\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38070\">No</a>\n"]}, {"number": 38069, "title": "Colab TPU broken on latest tf-nightly", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  6 lines of adaptation to stock example script from [https://www.tensorflow.org/guide/tpu](https://www.tensorflow.org/guide/tpu)\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Google Colaboratory\r\n- TensorFlow version (use command below): 2.2.0.dev20200330\r\n- Python version: 3.6.9 \r\n\r\n**Describe the current behavior**\r\nOn Google Colaboratory, TPU's no longer work with the tf-nightly builds. I was using the trick as mentioned here to run TPU's on tf-nightly: [https://github.com/tensorflow/tensorflow/issues/34346#issuecomment-598399912](https://github.com/tensorflow/tensorflow/issues/34346#issuecomment-598399912) but it stopped working. \r\n\r\nSuddenly, when doing the same thing as before, it throws an error while trying to initialize the tpu system, giving:\r\n```\r\nInvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is for it to not throw an error so that the TPU works.\r\n\r\n**Standalone code to reproduce the issue** \r\nI have a minimal reproduction based on the [tensorflow TPU tutorial](https://www.tensorflow.org/guide/tpu) with the [trick from above](https://github.com/tensorflow/tensorflow/issues/34346#issuecomment-598399912) added before the first cell: [https://colab.research.google.com/drive/1UzC_KCMkV8LOp7chvhkRsB3orQBlBVef](https://colab.research.google.com/drive/1UzC_KCMkV8LOp7chvhkRsB3orQBlBVef)\r\n\r\n**Other info / logs** \r\nThe NodeDef error occurs at this cell:\r\n```\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\n```\r\nAnd the error it throws is:\r\n```\r\nINFO:tensorflow:Initializing the TPU system: grpc://10.79.85.146:8470\r\nINFO:tensorflow:Initializing the TPU system: grpc://10.79.85.146:8470\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Clearing out eager caches\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-4-f9d179e80e14> in <module>()\r\n      1 resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n      2 tf.config.experimental_connect_to_cluster(resolver)\r\n----> 3 tf.tpu.experimental.initialize_tpu_system(resolver)\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: Current TensorFlow version is 2.2.0-dev20200330. To use TF 1.x instead,\r\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\r\nyou run \"import tensorflow\".\r\n---------------------------------------------------------------------------\r\n```\r\n\r\n\r\nI have been trying to find out in what nightly this was introduced, but I sometimes get errors that I am trying too frequently essentially. Anyway, I will list all the versions I tried.\r\n\r\nTf-nightly versions:\r\n- 2.2.0.dev20200327 works\r\n- Nightlies that fail with NodeDef error\r\n    - 2.2.0.dev20200328\r\n    - 2.2.0.dev20200329\r\n    - 2.2.0.dev20200330\r\n\r\n\r\n\r\n\r\nSome potentially related/useful information but maybe unrelated.\r\nI couldn't directly find which ones were working and which ones weren't, so I also tested older versions first, and noticed there was a lot of versions which had a different error. So maybe this was simply explicitly fixed, or maybe implicitly in which case it could add additional information:\r\n- 2.2.0.dev20200311 works\r\n- Nightlies that fail with a different error, namely a mesh_shape error (see error details below):\r\n    - 2.2.0.dev20200312\r\n    - 2.2.0.dev20200313\r\n    - 2.2.0.dev20200316\r\n    - 2.2.0.dev20200319\r\n    - 2.2.0.dev20200323\r\n\r\nMesh_shape error that occurs on certain nightlies (with same notebook and occurring in the same cell):\r\n```\r\nINFO:tensorflow:Initializing the TPU system: grpc://10.18.110.18:8470\r\nINFO:tensorflow:Initializing the TPU system: grpc://10.18.110.18:8470\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Finished initializing TPU system.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-36e427972e34> in <module>()\r\n      1 resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n      2 tf.config.experimental_connect_to_cluster(resolver)\r\n----> 3 tf.tpu.experimental.initialize_tpu_system(resolver)\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/topology.py in _parse_topology(self, serialized)\r\n    107     if len(self._mesh_shape) != 4 or any(self._mesh_shape < 1):\r\n    108       raise ValueError(\"`mesh_shape` must be a vector of size 4 with positive \"\r\n--> 109                        \"entries; got {}\".format(self._mesh_shape))\r\n    110 \r\n    111     if proto.num_tasks < 0:\r\n\r\nValueError: `mesh_shape` must be a vector of size 4 with positive entries; got [2 2 2]\r\n```", "comments": ["@mgmverburg \r\n\r\nPlease, use TF 2.2.0-rc1 version  (`!pip install tensorflow==2.2-rc1`) and i am not seeing any issue with latest release 2.2.0-rc1 version. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/cb5eaffca3500e3d59af2f04e19a319f/untitled754.ipynb). Thanks!", "Yes I tried TF 2.2.0-rc1 and it works, but I thought it should be possible to use nightly versions too? I know that TF is still very much in development hence I sometimes want to try nightly versions to see if certain performance issues may have been fixed already, but I noticed now for a few days already it wasn't working with the TPU, but I guess this is already known by the TF team then?\r\nI thought in case this was not known yet by the TF team, that this could help them.\r\n\r\nEdit: sorry, I see now, so I should use a nightly on the TPU, but 2.2-rc1 on the host?", "@mgmverburg \r\n\r\n TF 2.2.0-rc1 is latest stable version, TF-nightly is in development stage.We can use TF 2.2rc1 since it is working without any issue.Thanks!", "@mgmverburg \r\n\r\nI am closing this issue since it works fine with latest releases.Please, feel free to reopen if i am mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38069\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38069\">No</a>\n", "Same issue in tf-nightly-gpu 2.3.0-dev20200625"]}, {"number": 38068, "title": "Tensorflow 2.2 Object detection crash while try to detect object from live feed", "body": "The tensorflow object detection crashes while using the below code \r\n\r\n```\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# # Object Detection API Demo\r\n\r\n\r\nimport os\r\nimport pathlib\r\n\r\n\r\nif \"models\" in pathlib.Path.cwd().parts:\r\n  while \"models\" in pathlib.Path.cwd().parts:\r\n    os.chdir('..')\r\nelif not pathlib.Path('models').exists():\r\n  get_ipython().system('git clone --depth 1 https://github.com/tensorflow/models')\r\n\r\n\r\nimport numpy as np\r\nimport os\r\nimport six.moves.urllib as urllib\r\nimport sys\r\nimport tarfile\r\nimport tensorflow as tf\r\nimport zipfile\r\n\r\nfrom collections import defaultdict\r\nfrom io import StringIO\r\nfrom matplotlib import pyplot as plt\r\nfrom PIL import Image\r\nfrom IPython.display import display\r\n\r\n\r\n# Import the object detection module.\r\n\r\n# In[5]:\r\n\r\n\r\nfrom object_detection.utils import ops as utils_ops\r\nfrom object_detection.utils import label_map_util\r\nfrom object_detection.utils import visualization_utils as vis_util\r\n\r\n# Patches:\r\n\r\n# In[6]:\r\n\r\n\r\n# patch tf1 into `utils.ops`\r\nutils_ops.tf = tf.compat.v1\r\n\r\n# Patch the location of gfile\r\ntf.gfile = tf.io.gfile\r\n\r\n\r\n# # Model preparation \r\n\r\n# ## Variables\r\n# \r\n# Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing the path.\r\n# \r\n# By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies.\r\n\r\n# ## Loader\r\n\r\n# In[7]:\r\n\r\n\r\ndef load_model(model_name):\r\n  base_url = 'http://download.tensorflow.org/models/object_detection/'\r\n  model_file = model_name + '.tar.gz'\r\n  model_dir = tf.keras.utils.get_file(\r\n    fname=model_name, \r\n    origin=base_url + model_file,\r\n    untar=True)\r\n\r\n  print('Model Dir', model_dir)\r\n  print('Pathlib', pathlib)\r\n  model_dir = pathlib.Path(model_dir)/\"saved_model\"\r\n  print('Model Dir', model_dir)\r\n\r\n  model = tf.saved_model.load(str(model_dir))\r\n  model = model.signatures['serving_default']\r\n\r\n  return model\r\n\r\n\r\n# ## Loading label map\r\n# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\r\n\r\n# In[8]:\r\n\r\n\r\n# List of the strings that is used to add correct label for each box.\r\nPATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\r\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\r\n\r\n\r\n# For the sake of simplicity we will test on 2 images:\r\n\r\n# In[9]:\r\n\r\n\r\n# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\r\nPATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\r\nTEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\r\nTEST_IMAGE_PATHS\r\n\r\n\r\n# # Detection\r\n\r\n# Load an object detection model:\r\n\r\n# In[10]:\r\n\r\n\r\nmodel_name = 'ssd_mobilenet_v1_coco_2017_11_17'\r\ndetection_model = load_model(model_name)\r\n\r\n\r\n# Check the model's input signature, it expects a batch of 3-color images of type uint8: \r\n\r\n# In[11]:\r\n\r\n\r\nprint(detection_model.inputs)\r\n\r\n\r\n# And retuns several outputs:\r\n\r\n# In[12]:\r\n\r\n\r\ndetection_model.output_dtypes\r\n\r\n\r\n# In[13]:\r\n\r\n\r\nprint(detection_model.output_shapes)\r\n\r\n\r\n# Add a wrapper function to call the model, and cleanup the outputs:\r\n\r\n# In[14]:\r\n\r\n\r\ndef run_inference_for_single_image(model, image):\r\n  image = np.asarray(image)\r\n  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n  input_tensor = tf.convert_to_tensor(image)\r\n  # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n  input_tensor = input_tensor[tf.newaxis,...]\r\n\r\n  # Run inference\r\n  output_dict = model(input_tensor)\r\n\r\n  # All outputs are batches tensors.\r\n  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n  # We're only interested in the first num_detections.\r\n  num_detections = int(output_dict.pop('num_detections'))\r\n  output_dict = {key:value[0, :num_detections].numpy() \r\n                 for key,value in output_dict.items()}\r\n  output_dict['num_detections'] = num_detections\r\n\r\n  # detection_classes should be ints.\r\n  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\r\n   \r\n  # Handle models with masks:\r\n  if 'detection_masks' in output_dict:\r\n    # Reframe the the bbox mask to the image size.\r\n    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n              output_dict['detection_masks'], output_dict['detection_boxes'],\r\n               image.shape[0], image.shape[1])      \r\n    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\r\n                                       tf.uint8)\r\n    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\r\n    \r\n  return output_dict\r\n\r\nimport cv2\r\ncap = cv2.VideoCapture(0)\r\n\r\ndef run_inference(model, cap):\r\n    while True:\r\n        ret, image_np = cap.read()\r\n        # Actual detection.\r\n        output_dict = run_inference_for_single_image(model, image_np)\r\n        # Visualization of the results of a detection.\r\n        vis_util.visualize_boxes_and_labels_on_image_array(\r\n            image_np,\r\n            output_dict['detection_boxes'],\r\n            output_dict['detection_classes'],\r\n            output_dict['detection_scores'],\r\n            category_index,\r\n            instance_masks=output_dict.get('detection_masks_reframed', None),\r\n            use_normalized_coordinates=True,\r\n            line_thickness=8)\r\n        cv2.imshow('object_detection', cv2.resize(image_np, (800, 600)))\r\n        if cv2.waitKey(1) & 0xFF == ord('q'):\r\n            cap.release()\r\n            cv2.destroyAllWindows()\r\n            break\r\n\r\nrun_inference(detection_model, cap) \r\n```\r\n\r\n**Tensorflow-Gpu Version:** \r\ntf.__version__\r\n'2.2.0-rc1'\r\n\r\nWhen I use the above code it shows result  upto 2-3 seconds after that it says not responding", "comments": ["@PonraJS-21 Can you please share a github gist preferably colab with data so that we can reproduce this issue. Thanks!", "> Can you please share a github gist preferably colab with data so that we can reproduce this issue. Thanks!\r\n\r\nSorry what you mean by `github gist preferably colab with data` , are you asking for sample code", "@PonraJS-21 yes", "I just used the code in the description and the whole repo downloaded from tensorflow-object detection  API github, and compiled with protobuf", "Just a clarification. Is it working well with 2.0 and 2.1 versions? @PonraJS-21 ", "`Just a clarification. Is it working well with 2.0 and 2.1 versions? @PonraJS-21`\r\n\r\n@gowthamkpr , I think it is NO!\r\n\r\ncheck it  \ud83d\udc49: https://github.com/tensorflow/models/issues/6423", "@PonraJS-21 As mentioned [here](https://github.com/tensorflow/models/issues/6423#issuecomment-600925072), currently there is no object detection API for 2.0.0. I reopened the issue: tensorflow/models#6423. We will update the progress there as this issue is mainly to do with tensorflow/models not tensorflow/tensorflow itself.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38068\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38068\">No</a>\n", "why  pathlib is showing error and how i can fix ?"]}, {"number": 38067, "title": "Custom Loss: Order of arguments", "body": "I've found a little mistake in the documentation. On the following website, the order of y_true and y_pred are reversed:\r\n\r\nhttps://www.tensorflow.org/tutorials/customization/custom_training\r\n\r\n```\r\ndef loss(predicted_y, target_y):\r\n  return tf.reduce_mean(tf.square(predicted_y - target_y))\r\n```\r\n\r\nIt's usually the other way around:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/\r\n\r\n```\r\nkeras.losses.mean_squared_error(y_true, y_pred)\r\n```\r\nIt makes no difference for MSE since this loss is symmetric. It does make a difference for MMSE (Masked MSE) where random values of the target are mapped to zero.\r\n", "comments": ["@Arktius I don't think this is going to matter as much as we are using MSE as loss function here. ", "That's what I've already written. But people want to know how to write their own custom loss and if the loss is not symmetric, it does matter. ", "Code:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow import math, dtypes\r\nfrom tensorflow import float32 as f32 \r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.layers import Input\r\nimport random\r\nimport numpy as np # linear algebra\r\n\r\nrseed=10\r\nnp.random.seed(rseed)\r\nrandom.seed(rseed)\r\ntf.compat.v1.set_random_seed(rseed)\r\n    \r\ndef MMSE( preds,targets, mask_value=0.0):\r\n    tf.print('\\npred',preds)\r\n    tf.print('target',targets)\r\n    mask = dtypes.cast(tf.not_equal(targets,0),f32) \r\n    num_rating = math.reduce_sum(mask) #count ratings\r\n    loss = math.reduce_sum(math.square(mask*(preds - targets))) / num_rating \r\n    return loss\r\n\r\ndef MMSE2( targets,preds, mask_value=0.0):\r\n    tf.print('\\npred',preds)\r\n    tf.print('target',targets)    \r\n    mask = dtypes.cast(tf.not_equal(targets,0),f32) \r\n    num_rating = math.reduce_sum(mask) #count ratings\r\n    loss = math.reduce_sum(math.square(mask*(preds - targets))) / num_rating \r\n    return loss\r\n\r\ninput_dim = Input(shape = (3, ))\r\nmodel = Sequential()\r\nmodel.add(Dense(3,input_dim=3))\r\nmodel.add(Dense(3))\r\nmodel.compile(optimizer = Adam(lr=0.01),loss=[MMSE]) \r\n            \r\ndata  = tf.math.round(tf.random.normal(shape=[5,3]))\r\nhistory = model.fit(data,data, epochs = 1, batch_size = 5,verbose=0, shuffle=False) \r\nprint(history.history)\r\n\r\n\r\n\r\nnp.random.seed(rseed)\r\nrandom.seed(rseed)\r\ntf.compat.v1.set_random_seed(rseed)\r\n\r\ninput_dim = Input(shape = (3, ))\r\nmodel = Sequential()\r\nmodel.add(Dense(3,input_dim=3))\r\nmodel.add(Dense(3))\r\nmodel.compile(optimizer = Adam(lr=0.01),loss=[MMSE2]) \r\n            \r\ndata  = tf.math.round(tf.random.normal(shape=[5,3]))\r\nhistory = model.fit(data,data, epochs = 1, batch_size = 5,verbose=0, shuffle=False) \r\n\r\n\r\nprint(history.history)\r\n```\r\nResults:\r\n```\r\npred [[0 -2 0]\r\n [-1 -1 1]\r\n [-1 -1 0]\r\n [1 -1 1]\r\n [0 -1 -1]]\r\ntarget [[0.785157084 -0.0453303158 1.38228703]\r\n [-0.0399211645 0.472007155 1.34690034]\r\n [0.533699632 0.0738710314 1.13373435]\r\n [-0.322163254 0.278934747 0.46171847]\r\n [0.966199279 -0.420801282 0.477977633]]\r\n{'loss': [1.431638240814209]}\r\n\r\npred [[0.785157084 -0.0453303158 1.38228703]\r\n [-0.0399211645 0.472007155 1.34690034]\r\n [0.533699632 0.0738710314 1.13373435]\r\n [-0.322163254 0.278934747 0.46171847]\r\n [0.966199279 -0.420801282 0.477977633]]\r\ntarget [[0 -2 0]\r\n [-1 -1 1]\r\n [-1 -1 0]\r\n [1 -1 1]\r\n [0 -1 -1]]\r\n{'loss': [1.5207717418670654]}\r\n```\r\n\r\n", "@Arktius and @MarkDaoust , please close this issue since the PR is merged.", "Tip when submitting a PR that closes a bug.\r\n\r\nIf you put:\r\n\r\n```\r\nfixes: tensorflow/tensorflow#38067\r\n```\r\n\r\nIn the commit message or PR description it will auto-close the bug on merge."]}, {"number": 38066, "title": "ctc loss output\uff1aNo valid path found", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@zgsxwsdxg \r\nCould you please update the template with requested details. (about what platform you are using ,include your TensorFlow version. )\r\nplease provide a code snippet to reproduce the issue reported here. Thanks!\r\n\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\n\r\n", "@zgsxwsdxg\r\nCould you please update as per above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38066\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38066\">No</a>\n"]}, {"number": 38065, "title": "Failed to build the master branch", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04 tensorflow/tensorflow:latest-devel-gpu-py3):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master branch\r\n- Python version:3.6.9\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):Build label: 2.0.0\r\n- GCC/Compiler version (if compiling from source):gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nMaster branch build failed\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nbazel build --jobs=4 --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nNFO: Call stack for the definition of repository 'llvm-project' which is a tf_http_archive (rule definition at /home/tx/Downloads/tensorflow/third_party/repo.bzl:134:19):\r\n - /home/tx/Downloads/tensorflow/tensorflow/workspace.bzl:598:5\r\n - /home/tx/Downloads/tensorflow/WORKSPACE:19:1\r\nERROR: /home/tx/Downloads/tensorflow/tensorflow/lite/toco/BUILD:439:1: Target '//tensorflow/lite/toco:toco' depends on toolchain '@local_config_cc//:cc-compiler-k8', which cannot be found: error loading package '@local_config_cc//': Unable to load file '@local_config_cc//:armeabi_cc_toolchain_config.bzl': file doesn't exist'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: error loading package '@local_config_cc//': Unable to load file '@local_config_cc//:armeabi_cc_toolchain_config.bzl': file doesn't exist\r\nINFO: Elapsed time: 10.477s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (226 packages loaded, 3671 targets configured)\r\n    currently loading: @com_github_grpc_grpc//src/compiler ... (2 packages)\r\n    Fetching @com_google_absl; fetching 4s\r\n```", "comments": ["Provide the exact sequence of commands / steps that you executed before running into the problem.Please provide details about what platform you are using (operating system, architecture).Thanks!", "@ravikyram . Steps \r\n\r\n1. `./configure` (all default)\r\n2.  `bazel build --jobs=4 --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\nThen build fails. Operation system is the same as `tensorflow/tensorflow:latest-devel-gpu-py3` which is Ubuntu 18.04 64bit. ", "Can you sync back to master and try again? Also, please post the commit hash at which you are trying to build.\r\n\r\nIs this a regression? Was there a moment where you were able to build using these steps?\r\n\r\nPS: You should not need `--config=cuda` if you set CUDA related things in `./configure`", "I have tried many times on latest master up to `566c03a749`. I built successfully once a long time ago. But I did `bazel clean` after that. Also tried removing `--config=cuda`, still failed with the same reason.", "@372046933,\r\nIs this still an issue?\r\n\r\nCould you please update TensorFlow to v2.4.1 and let us know if you are facing the same error. Thanks!", "Sorry, I cannot verify v2.4.1 due to insufficient disk space.", "@372046933,\r\nThank you for the update. \r\n\r\nCan we close this issue for now? Please feel free to re-open if you face the same error with TF v2.4.1 as well.", "Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38065\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38065\">No</a>\n"]}, {"number": 38064, "title": "UnboundLocalError: local variable 'logs' referenced before assignment on training with little data", "body": "I found an error caused by an attempt of coping training logs from a not yet assigned variable.\r\nThe error occurred on my machine (Arch linux, tensorflow v2.2rc2 compiled from source) and I managed to reproduce the error on colab, on a stock environment.\r\nIt only happens when the model.fit method is called with very little training / eval data.\r\nThe ```logs``` variable is assigned inside a ```for``` loop that never happens when there is no sufficient data. \r\n\r\nThe code lives here:\r\nhttps://github.com/tensorflow/tensorflow/blob/e6e5d6df2ab26620548f35bf2e652b19f6d06652/tensorflow/python/keras/engine/training.py#L793\r\n\r\nThe notebook gist link for reproducing the bug:\r\nhttps://colab.research.google.com/gist/naripok/8ce09ec9c3e795b3635a6b1ac11ebd4b/tpu_transformer_model.ipynb", "comments": ["Was able to reproduce the issue with TF v2.2.0-rc2. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/88f59bf9ab4c7cd27ef62a49e28162be/38064.ipynb). Thanks!\r\n", "I have the same issue with TF v2.2.0-rc2\r\n\r\n```\r\nEpoch 19/20\r\n18/18 [==============================] - 2s 125ms/step - loss: 0.0035 - accuracy: 1.0000\r\nEpoch 20/20\r\n18/18 [==============================] - 2s 126ms/step - loss: 0.0373 - accuracy: 0.9844\r\n\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 155, in <module>\r\n    main()\r\n  File \"run.py\", line 120, in main\r\n    accuracy, num_of_classes = train_Full_visible(unique_name)\r\n  File \"run.py\", line 78, in train_Full_visible\r\n    acc = neuro.train(picdb, train_ids, test_ids, \"Full body visible\")\r\n  File \"/ssd/200410 3rd Try/neuro.py\", line 232, in train\r\n    test_loss, test_acc = self.model.evaluate(test_generator, verbose=0)\r\n  File \"/home/frank/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/frank/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1028, in evaluate\r\n    logs = tf_utils.to_numpy_or_python_type(logs)\r\nUnboundLocalError: local variable 'logs' referenced before assignment\r\n```", "@Tuxius and others which stuck until this bug is fixed: \r\nI had the same issue  and I found that my validation data set had less samples as the batch_size.  Because I'm working with TFRecords-data-sets which have no meta data about how many records, i.e. samples, are in the data set I check now upfront whether the data set  contains at least batch_size records (samples). \r\n\r\nFor that I use the following helper functions:\r\n\r\n```\r\ndef doesDataSetContainsEnoughDataForBatch(dataset, batch_size):\r\n    return len(list(dataset.take(batch_size).as_numpy_iterator())) == batch_size\r\n  \r\ndef doesDataSetFileContainsEnoughDataForBatch(sampleFileName=\"\", batch_size=100):\r\n    dataset = tf.data.TFRecordDataset(sampleFileName)\r\n    return doesDataSetContainsEnoughDataForBatch(dataset, batch_size=batch_size)\r\n\r\nif __name__ == '__main__':\r\n  dataSetFileName=\"./Samples/validation_data_123.tfrecord\"\r\n  if not doesDataSetFileContainsEnoughDataForBatch(dataSetFileName,batch_size=100):\r\n    raise Exception(f\"Data set file {dataSetFileName} doesn't contain enough data\")\r\n   \r\n  # Now open the data set a second time knowing you have enough data \r\n  # and use it ....\r\n  \"\"\"\r\n  trainDataset = tf.data.TFRecordDataset(dataSetFileName)\r\n  \r\n  model.fit ( trainDataset ... \r\n  \r\n  \"\"\"\r\n\r\n```\r\n\r\nPlease keep in mind that by using the first helper function directly , \r\ni.e. doesDataSetContainsEnoughDataForBatch,  you already read batch_size samples from the data set. So you should recreate the data set after the check.\r\n\r\nBy using the second helper function  you just lose some execution time upfront.\r\n\r\nIf you don't use TFRecord data sets you might have a similar  issue. But then it is also a good idea to check upfront whether you have enough data for at least one batch.", "> @Tuxius and others which stuck until this bug is fixed:\r\n> I had the same issue and I found that my validation data set had less samples as the batch_size. Because I'm working with TFRecords-data-sets which have no meta data about how many records, i.e. samples, are in the data set I check now upfront whether the data set contains at least batch_size records (samples).\r\n> \r\n> For that I use the following helper functions:\r\n> \r\n> ```\r\n> def doesDataSetContainsEnoughDataForBatch(dataset, batch_size):\r\n>     return len(list(dataset.take(batch_size).as_numpy_iterator())) == batch_size\r\n>   \r\n> def doesDataSetFileContainsEnoughDataForBatch(sampleFileName=\"\", batch_size=100):\r\n>     dataset = tf.data.TFRecordDataset(sampleFileName)\r\n>     return doesDataSetContainsEnoughDataForBatch(dataset, batch_size=batch_size)\r\n> \r\n> if __name__ == '__main__':\r\n>   dataSetFileName=\"./Samples/validation_data_123.tfrecord\"\r\n>   if not doesDataSetFileContainsEnoughDataForBatch(dataSetFileName,batch_size=100):\r\n>     raise Exception(f\"Data set file {dataSetFileName} doesn't contain enough data\")\r\n>    \r\n>   # Now open the data set a second time knowing you have enough data \r\n>   # and use it ....\r\n>   \"\"\"\r\n>   trainDataset = tf.data.TFRecordDataset(dataSetFileName)\r\n>   \r\n>   model.fit ( trainDataset ... \r\n>   \r\n>   \"\"\"\r\n> ```\r\n> \r\n> Please keep in mind that by using the first helper function directly ,\r\n> i.e. doesDataSetContainsEnoughDataForBatch, you already read batch_size samples from the data set. So you should recreate the data set after the check.\r\n> \r\n> By using the second helper function you just lose some execution time upfront.\r\n> \r\n> If you don't use TFRecord data sets you might have a similar issue. But then it is also a good idea to check upfront whether you have enough data for at least one batch.\r\n\r\nI added more data. It works well!\r\nThank you!", "Hi there, I change the `batch_size` to smaller so that it could be more evenly divided during training. \r\nFor example, when you have 300 training samples, do not use `batch_size=128`, try `batch_size =10` or `batch_size=20` something, it works for me.", "The issue is still reproducible with 2.2.0rc4, will test with 2.2.0 release.", "2.2 is still reproducible for me", "2.2 is still reproducible indeed", "Are there any other workarounds known yet? The batch size one did not work out for me.", "Same problem: Is there way to fix or alternatives ?", "same problem: Is there way ro fix the issue? ", "Same problem, the root cause for this issue is that the training cannot perform a single step because your dataset is not large enough to fill one training iteration.\r\n\r\nAnyway, there is still a bug here, this is not the expected behavior.", "> Same problem, the root cause for this issue is that the training cannot perform a single step because your dataset is not large enough to fill one training iteration.\r\n> \r\n> Anyway, there is still a bug here, this is not the expected behavior.\r\n\r\nYes. You are right. When i increased training data the error doesnot occure.", "I have also same error arise , even increase the training dataset its not solved. Again i got the same error. kindly share me the solution if anyone knows about this.\r\nThank you ", "> I have also same error arise , even increase the training dataset its not solved. Again i got the same error. kindly share me the solution if anyone knows about this.\r\n> Thank you\r\n\r\nWhat is the size of the dataset you are using?", "512, 512 size and 247 images and masks", "I solved my particular issue setting the batch_size very small, in my case batch_size = 1. I confirm that this happens with small datasets.", "yes  sir, i have also reduced batchsize as 1, but i dont know the reason why the same error arise.", "I had the same error with using `model.fit` it turns out the `validation_steps` or `steps_per_epoch` was zero. By making them >=1, the bug disappeared.", "same problem also. is there a workaround?", "same problem during training BiT. Batch size 128, Steps_per_epoch = 100\r\nEdit: I throw out validation_data and it works. but I want valid model", "Working with a small dataset \r\nchanged batch_size = 64 - worked", "This error also raise when len(traindata) or len(validdata) is 0.", "I found this error while running the training part of vgg16 model\r\n\r\ndef vgg16_model( num_classes=None):\r\n\r\n    model = VGG16(weights='/kaggle/input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(224, 224, 3))\r\n    x=Flatten()(model.output)\r\n    output=Dense(num_classes,activation='softmax')(x)\r\n    model=Model(model.input,output)\r\n    return model\r\n\r\nvgg_conv=vgg16_model(6)\r\n\r\ndef kappa_score(y_true, y_pred):\r\n    \r\n    y_true=tf.math.argmax(y_true)\r\n    y_pred=tf.math.argmax(y_pred)\r\n    return tf.compat.v1.py_func(cohen_kappa_score ,(y_true, y_pred),tf.double)\r\n\r\nopt = SGD(lr=0.001)\r\nvgg_conv.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy',kappa_score])\r\n\r\nnb_epochs = 3\r\nbatch_size = 16\r\nnb_train_steps = train.shape[0]//batch_size\r\nnb_val_steps=validation.shape[0]//batch_size\r\n\r\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))\r\n\r\ncheck_point = ModelCheckpoint('./model.h5',monitor='val_loss',verbose=True, save_best_only=True, save_weights_only=True)\r\n\r\nearly_stop = EarlyStopping(monitor='val_loss',patience=25,verbose=True)\r\n\r\ncallbacks = [check_point,early_stop]\r\n\r\nvgg_conv.fit_generator(\r\n    train_generator,\r\n    verbose=2,\r\n    steps_per_epoch=nb_train_steps,\r\n    epochs=nb_epochs,\r\n    validation_data=validation_generator,\r\n    validation_steps=nb_val_steps,\r\n    callbacks=callbacks,\r\n    use_multiprocessing=True)\r\n\r\n\r\nFound 16 non-validated image filenames belonging to 6 classes.\r\nFound 4 non-validated image filenames belonging to 2 classes.\r\nNumber of training and validation steps: 1 and 0\r\nEpoch 1/3\r\n\r\n---------------------------------------------------------------------------\r\nUnboundLocalError                         Traceback (most recent call last)\r\n<ipython-input-47-721e3d1678a3> in <module>\r\n     63     validation_steps=nb_val_steps,\r\n     64     callbacks=callbacks,\r\n---> 65     use_multiprocessing=True)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    322               'in a future version' if date is None else ('after %s' % date),\r\n    323               instructions)\r\n--> 324       return func(*args, **kwargs)\r\n    325     return tf_decorator.make_decorator(\r\n    326         func, new_func, 'deprecated',\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1477         use_multiprocessing=use_multiprocessing,\r\n   1478         shuffle=shuffle,\r\n-> 1479         initial_epoch=initial_epoch)\r\n   1480 \r\n   1481   @deprecation.deprecated(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n     64   def _method_wrapper(self, *args, **kwargs):\r\n     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n---> 66       return method(self, *args, **kwargs)\r\n     67 \r\n     68     # Running inside `run_distribute_coordinator` already.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n    870               workers=workers,\r\n    871               use_multiprocessing=use_multiprocessing,\r\n--> 872               return_dict=True)\r\n    873           val_logs = {'val_' + name: val for name, val in val_logs.items()}\r\n    874           epoch_logs.update(val_logs)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n     64   def _method_wrapper(self, *args, **kwargs):\r\n     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n---> 66       return method(self, *args, **kwargs)\r\n     67 \r\n     68     # Running inside `run_distribute_coordinator` already.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\r\n   1089       callbacks.on_test_end()\r\n   1090 \r\n-> 1091       logs = tf_utils.to_numpy_or_python_type(logs)\r\n   1092       if return_dict:\r\n   1093         return logs\r\n\r\nUnboundLocalError: local variable 'logs' referenced before assignment", "Can we add tag 2.3 for this issue?", "> Can we add tag 2.3 for this issue?\r\nI am using tensorflow 2.2.0", "I am surprised there is no self-contained code example reproducing this, so here is one:\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow import keras\r\nmodel = keras.models.Sequential([keras.layers.Dense(1, input_shape=(1,))])\r\nmodel.compile(loss=\"mse\", optimizer=\"adam\")\r\nmodel.fit(x=np.ones((1, 1)), y=np.ones((1, 1)), validation_split=0.5)\r\n```\r\n", "This is reproducible in TF 2.3. I am using batch_size of 1 and no validation data.\r\nBy the way, this is working when I ran my custom model eager mode `run_eagerly=True`", "Encountered this error, myself, and thought I'd share my debugging in case others would benefit in some way.\r\n\r\nTracing the calls and returns, it seems that inside `fit`, a local variable `logs` is first defined inside a for loop iterating over `DataHandler.steps()`, which, in many cases, is a number dependent on the cardinality of the Dataset. If the Dataset cardinality is zero, then `DataHandler.steps()` performs 0 iterations, and `logs` will never be created, resulting in the UnboundLocalError we're all getting.\r\n\r\nThe cardinality of my Dataset was being returned as 0 because I had created it from a `.take()` called on a `BatchDataset` that had a batch_size > 1 -- this was an artifact of a previous iteration of my code. (Worth noting that when `.take()` was called on the `BatchDataset` with batch_size of 1, then my `Dataset.cardinality()` was nonzero.)\r\n\r\nAfter cleaning the code (in my case, calling `take` on a Dataset that had not been batched), my Dataset.cardinality() returned a nonzero value, and the error was resolved.", "when turn off validation_data, it works! tf.__version__ == '2.2.0'\r\n```\r\nlogistic_regression.fit(train_dense_x, \r\n          train_label, epochs=100, batch_size=256,\r\n#           validation_data=(val_dense_x, val_label),  \r\n          callbacks=[tbCallBack])\r\n```\r\n\r\n\r\n", "check number of your training data. It might equal to zero", "Looks like this happens when size of the training data is <= batch size", "> check number of your training data. It might equal to zero\r\n\r\nIn my case, I read my tfrecords incorrectly but didn't get any warnings or errors. After reading the record, you can try printing its size as a sanity check.", "@naripok the original issue of \"UnboundLocalError: local variable 'logs' referenced before assignment\" is no longer with the latest tf-nightly. Can you please confirm and if so close the issue ?", "Sorry for the delay,\r\n\r\nConfirmed.\r\n\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38064\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38064\">No</a>\n", "> had less samples as the batch_size\r\n\r\nThe same situation can occur if the train-set has less number of examples than the batch size. In my case my train-set's directory was wrongly given.", "> check number of your training data. It might equal to zero\r\n\r\nThank you! "]}, {"number": 38063, "title": "tflite converter build in ops not support: ResizeNearestNeighbor", "body": "when I convert the keras model to tflite, it is ok when :\r\n     `convert.experimental_new_converter = False`\r\nbut when:\r\n    `conver.experimental_new_converter=True`\r\nit shows the error:\r\n \r\n\r\n> <unknown>:0: error: failed while converting: 'main'\r\n> Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor.\r\n\r\nI use code:\r\n`converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n`\r\nIt is ok, but the resize nearest neighbor should be the buildin ops:\r\n`kTfLiteBuiltinResizeNearestNeighbor = 97,\r\n  kTfLiteBuiltinLeakyRelu = 98,\r\n  kTfLiteBuiltinSquaredDifference = 99,\r\n  kTfLiteBuiltinMirrorPad = 100,`\r\n", "comments": ["@mengjiexu Can you please share a standalone code to reproduce the issue? Also, mention which TF version you are using. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38063\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38063\">No</a>\n"]}, {"number": 38062, "title": "A bug: TFLite post-training quantization with calibration", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): r2.2\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n```\r\nwith qauntize_scope():\r\n  converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n  converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\r\n  converter.representative_dataset = calibration_gen\r\n  tflite_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_minist_qat.py\", line 171, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/mumu/.miniconda3/envs/hyperfast/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 522, in convert\r\n    result, constants.FLOAT, constants.FLOAT)\r\n  File \"/home/mumu/.miniconda3/envs/hyperfast/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 267, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, self.experimental_new_quantizer)\r\nAttributeError: 'TFLiteConverterV2' object has no attribute 'experimental_new_quantizer'\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\nNone\r\n\r\n**Failure details**\r\nFrom commit [e6895b](https://github.com/tensorflow/tensorflow/commit/e6895b3648595080143e8f5dd6f56c16e7852e91), some experimental feature flags were made private.\r\nAnd at line 267, it does not changed properly.\r\nThis introduces bugs when apply post-training quantization using TFLite converter.\r\n(Manually fixing it works well)\r\n\r\n**Any other info / logs**\r\nNone", "comments": ["@kalaluthien \r\ncan you please provide us with complete code for us to replicate the issue", "Modified code from tensorflow/model-optimization mnist examples:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\"\"\" Step0: configure test\r\n\"\"\"\r\nbatch_size = 128\r\nnum_epochs = 10\r\ncalibration_size = 300\r\ninput_shape = (28, 28, 1)\r\nnum_classes = 10\r\n\r\n\"\"\" Step1: prepare dataset\r\n\"\"\"\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n\r\nx_train = x_train.reshape((x_train.shape[0],) + input_shape).astype('float32') / 255\r\nx_test = x_test.reshape((x_test.shape[0],) + input_shape).astype('float32') / 255\r\n\r\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\r\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\r\n\r\n\r\ndef calibration_gen():\r\n    for i in range(calibration_size):\r\n        yield [x_train[i].reshape((1,) + input_shape)]\r\n\r\n\r\n\"\"\" Step2: prepare models\r\n\"\"\"\r\ntrained_models = []\r\nmodel_sequential = tf.keras.Sequential(\r\n    [\r\n        tf.keras.layers.Conv2D(\r\n            32, 5,\r\n            padding='same',\r\n            activation='relu',\r\n            use_bias=False,\r\n            input_shape=input_shape,\r\n        ),\r\n        tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n        tf.keras.layers.Conv2D(\r\n            64, 5,\r\n            padding='same',\r\n            activation='relu',\r\n            use_bias=False,\r\n        ),\r\n        tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(1024, activation='relu'),\r\n        tf.keras.layers.Dropout(0.4),\r\n        tf.keras.layers.Dense(num_classes),\r\n        tf.keras.layers.Softmax(),\r\n    ],\r\n    name='MnistSequential',\r\n)\r\ntrained_models.append(model_sequential)\r\n\r\n\r\n\"\"\" Step3: train models\r\n\"\"\"\r\nfor model in trained_models:\r\n    print(f'Train {model.name}...')\r\n    model.compile(\r\n        loss=tf.keras.losses.categorical_crossentropy,\r\n        optimizer=tf.keras.optimizers.Adadelta(),\r\n        metrics=['accuracy']\r\n    )\r\n    model.fit(\r\n        x_train, y_train,\r\n        validation_data=(x_test, y_test),\r\n        batch_size=batch_size,\r\n        epochs=num_epochs,\r\n        verbose=True,\r\n    )\r\n\r\n\r\n\"\"\" Step4: convert models\r\n\"\"\"\r\nconverted_models = []\r\nfor model in trained_models:\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\r\n\r\n    tflite_model = converter.convert()\r\n    tflite_path = f'./{model.name}.tflite'\r\n    open(tflite_path, \"wb\").write(tflite_model)\r\n    converted_models.append(tflite_path)\r\n\r\nwith quantize_scope():\r\n    for model in trained_models:\r\n        converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n        converter.representative_dataset = calibration_gen\r\n\r\n        tflite_model = converter.convert()\r\n        tflite_path = f'./{model.name}_quantized.tflite'\r\n        open(tflite_path, \"wb\").write(tflite_model)\r\n        converted_models.append(tflite_path)\r\n\r\n\"\"\" Step5: evaluate keras models & tflite models\r\n\"\"\"\r\nx_test = x_test[:calibration_size, :]\r\ny_test = y_test[:calibration_size, :]\r\n\r\nfor model in trained_models:\r\n    total_seen = 0\r\n    num_correct = 0\r\n\r\n    for img, label in zip(x_test, y_test):\r\n        inp = img.reshape((1,) + input_shape)\r\n        total_seen += 1\r\n        predictions = model(inp)\r\n        if np.argmax(predictions) == np.argmax(label):\r\n            num_correct += 1\r\n\r\n    score = float(num_correct) / float(total_seen)\r\n    print(f'{model.name} accuracy: {score}')\r\n\r\nfor tflite_path in converted_models:\r\n    interpreter = tf.lite.Interpreter(model_path=tflite_path)\r\n    interpreter.allocate_tensors()\r\n    input_index = interpreter.get_input_details()[0]['index']\r\n    output_index = interpreter.get_output_details()[0]['index']\r\n\r\n    total_seen = 0\r\n    num_correct = 0\r\n\r\n    for img, label in zip(x_test, y_test):\r\n        inp = img.reshape((1,) + input_shape)\r\n        total_seen += 1\r\n        interpreter.set_tensor(input_index, inp)\r\n        interpreter.invoke()\r\n        predictions = interpreter.get_tensor(output_index)\r\n        if np.argmax(predictions) == np.argmax(label):\r\n            num_correct += 1\r\n\r\n    score = float(num_correct) / float(total_seen)\r\n    print(f'{tflite_path} accuracy: {score}')\r\n```", "@kalaluthien \r\ni ran the code shared by you but face a different error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/deac57fdb0414f1bc02549bae098356a/38062.ipynb) ", "I think `with quantize_scope():` should be deleted:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\"\"\" Step0: configure test\r\n\"\"\"\r\nbatch_size = 128\r\nnum_epochs = 10\r\ncalibration_size = 300\r\ninput_shape = (28, 28, 1)\r\nnum_classes = 10\r\n\r\n\"\"\" Step1: prepare dataset\r\n\"\"\"\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n\r\nx_train = x_train.reshape((x_train.shape[0],) + input_shape).astype('float32') / 255\r\nx_test = x_test.reshape((x_test.shape[0],) + input_shape).astype('float32') / 255\r\n\r\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\r\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\r\n\r\n\r\ndef calibration_gen():\r\n    for i in range(calibration_size):\r\n        yield [x_train[i].reshape((1,) + input_shape)]\r\n\r\n\r\n\"\"\" Step2: prepare models\r\n\"\"\"\r\ntrained_models = []\r\nmodel_sequential = tf.keras.Sequential(\r\n    [\r\n        tf.keras.layers.Conv2D(\r\n            32, 5,\r\n            padding='same',\r\n            activation='relu',\r\n            use_bias=False,\r\n            input_shape=input_shape,\r\n        ),\r\n        tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n        tf.keras.layers.Conv2D(\r\n            64, 5,\r\n            padding='same',\r\n            activation='relu',\r\n            use_bias=False,\r\n        ),\r\n        tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(1024, activation='relu'),\r\n        tf.keras.layers.Dropout(0.4),\r\n        tf.keras.layers.Dense(num_classes),\r\n        tf.keras.layers.Softmax(),\r\n    ],\r\n    name='MnistSequential',\r\n)\r\ntrained_models.append(model_sequential)\r\n\r\n\r\n\"\"\" Step3: train models\r\n\"\"\"\r\nfor model in trained_models:\r\n    print(f'Train {model.name}...')\r\n    model.compile(\r\n        loss=tf.keras.losses.categorical_crossentropy,\r\n        optimizer=tf.keras.optimizers.Adadelta(),\r\n        metrics=['accuracy']\r\n    )\r\n    model.fit(\r\n        x_train, y_train,\r\n        validation_data=(x_test, y_test),\r\n        batch_size=batch_size,\r\n        epochs=num_epochs,\r\n        verbose=True,\r\n    )\r\n\r\n\r\n\"\"\" Step4: convert models\r\n\"\"\"\r\nconverted_models = []\r\nfor model in trained_models:\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\r\n\r\n    tflite_model = converter.convert()\r\n    tflite_path = f'./{model.name}.tflite'\r\n    open(tflite_path, \"wb\").write(tflite_model)\r\n    converted_models.append(tflite_path)\r\n\r\nfor model in trained_models:\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.representative_dataset = calibration_gen\r\n\r\n    tflite_model = converter.convert()\r\n    tflite_path = f'./{model.name}_quantized.tflite'\r\n    open(tflite_path, \"wb\").write(tflite_model)\r\n        converted_models.append(tflite_path)\r\n\r\n\"\"\" Step5: evaluate keras models & tflite models\r\n\"\"\"\r\nx_test = x_test[:calibration_size, :]\r\ny_test = y_test[:calibration_size, :]\r\n\r\nfor model in trained_models:\r\n    total_seen = 0\r\n    num_correct = 0\r\n\r\n    for img, label in zip(x_test, y_test):\r\n        inp = img.reshape((1,) + input_shape)\r\n        total_seen += 1\r\n        predictions = model(inp)\r\n        if np.argmax(predictions) == np.argmax(label):\r\n            num_correct += 1\r\n\r\n    score = float(num_correct) / float(total_seen)\r\n    print(f'{model.name} accuracy: {score}')\r\n\r\nfor tflite_path in converted_models:\r\n    interpreter = tf.lite.Interpreter(model_path=tflite_path)\r\n    interpreter.allocate_tensors()\r\n    input_index = interpreter.get_input_details()[0]['index']\r\n    output_index = interpreter.get_output_details()[0]['index']\r\n\r\n    total_seen = 0\r\n    num_correct = 0\r\n\r\n    for img, label in zip(x_test, y_test):\r\n        inp = img.reshape((1,) + input_shape)\r\n        total_seen += 1\r\n        interpreter.set_tensor(input_index, inp)\r\n        interpreter.invoke()\r\n        predictions = interpreter.get_tensor(output_index)\r\n        if np.argmax(predictions) == np.argmax(label):\r\n            num_correct += 1\r\n\r\n    score = float(num_correct) / float(total_seen)\r\n    print(f'{tflite_path} accuracy: {score}')\r\n```", "@kalaluthien \r\ni ran the above code shared by you, please find [gist here](https://colab.sandbox.google.com/gist/Saduf2019/4fd48325f5575fe79bdccf01402cbddf/untitled123.ipynb), if possible please share a colab gist so we could analyse your issue", "Oh,, it was fixed few hours ago: https://github.com/tensorflow/tensorflow/commit/46055ea64aaf9cdfaf0c218a109770cd851eeb8a\r\n\r\nI'll close this issue. Thanks!", "Hey, The same error is still being encountered in Colab with the official notebook provided here : [https://www.tensorflow.org/lite/performance/post_training_integer_quant](url) . I'm attaching the screenshot of the error. \r\n![Screenshot from 2020-04-03 15-57-53](https://user-images.githubusercontent.com/28225784/78351125-f3592680-75c3-11ea-9425-c8e6f2a483c0.png)\r\n", "@imtoba  It looks fixed https://github.com/tensorflow/tensorflow/commit/46055ea64aaf9cdfaf0c218a109770cd851eeb8a,  just hasn't been merged in yet"]}, {"number": 38061, "title": "GAN Training Loop overriding Model.train_step()", "body": "Hello!\r\n\r\nI was trying to wrap my head around how to make an Adversarial Training Loop for GANs using the recently feature of TF2.2.0, the ability to override Model.train_step(). Right now, i feel that is not possible because a GAN are two separate networks, but maybe there is some way of do this, that is cleaner than a Custom Training Loop.\r\n\r\nMy doubts come to my mind because right now im implementing a GAN for image Deblurring following the Paper of DeblurGANV2, and im feeling frustration because now the performance is poor and maybe i dont plan my implementation very good. I you wish to help me there, this is the repo: https://github.com/ElPapi42/deep-deblurring, im going crazy with this.\r\n\r\n\r\nIf this is a suitable way of creating such implementation, will be awesome to write docs about this.", "comments": ["@ElPapi42 \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps in localizing the issue faster.Thanks!", "Hello! maybe i dont explain my self very well, there is no issue @ravikyram , but im interested in know the viability of implement a GAN training loop overriding `Model.train_step`. Currently i cant find a tutorial about this specific situation in the docs, and the existing one, is implemented using Custom Training Loop and GradientTape.", "Update: Im doing my own advances on this topic, i have a solution, but there is a detail, for train a GAN two optimizers are required, i was checking how the training logic was implemented, and seems like `Model.compile()` can only accept a single Optimizer, not a tuple or list. This is stopping me from reaching the solution, because injecting the extra optimizer using other methods, like class args or something like that, will prevent `Model.save()` from saving the extra optimizer state. Is there something im not seeing? `Model.compile()` accepts a tuple of optimizers?. im looking for a workaround.", "This is a very unofficial answer, but I think you're looking for this: https://twitter.com/fchollet/status/1250622989541838848", "@gabrieldemarmiesse awesome link, in fact, I already implemented the GAN by myself this way, but there is some details this publication helps me to clarify, I will upload the cheat sheet here for future reference!\r\n\r\n![EVsaz1hU4AEoLps](https://user-images.githubusercontent.com/17053461/80309585-f6e76400-87a3-11ea-8de2-daa0fe049784.jpg)\r\n\r\nWorth to mention that test_step() must be overridden too if you want to use cross-validation techniques, and, using this implementation, must be lightly modified for support Keras metrics."]}, {"number": 38060, "title": "pixelwise-loss-weight map", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nU-NET (https://www.nature.com/articles/s41592-018-0261-2) has become a popular way to perform semantic segmentation for cell microscopy.  Instance segmentation requires pixelwise-loss weights.  Currently, model.fit_generator supports only val_sample_weights and class_weight--not pixelwise-loss weights.  \r\n\r\nThere have been several work-arounds proposed for this issue, and I have implemented almost everyone.  Most generated errors except \r\n\r\nhttps://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/keras-users/ue1S8uAPDKU/PzL7Vb0bBQAJ\r\n\r\nIt kind of works, but the Jupyter notework keeps issuing warnings like\r\n\r\nE tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n\r\nWhen I run it, the results change drastically from run to run.\r\n\r\n**Will this change the current api? How?**\r\nIt will add more versatility to the api by incorporating an important aspect of computer vision.  \r\n\r\n**Who will benefit with this feature?**\r\nThose using keras to implement computer vision programs.\r\n\r\n**Any Other info.**\r\nThank you kindly for your consideration.", "comments": ["@shinlin77 Will you be able to try this in the latest version of TF? We have made a number of changes to sample weights behavior and we have very few restrictions on sample weights today.\r\nIn TF2.2 you are not required to specify `sample_weight_mode` in compile API.\r\n\r\nClosing this issue as the use case is expected to work in TF2.0. Please feel free to ping or reopen if you are facing any issues.", "<!--\n/* Font Definitions */\n@font-face\n\t{font-family:\"Cambria Math\";\n\tpanose-1:2 4 5 3 5 4 6 3 2 4;}\n@font-face\n\t{font-family:Calibri;\n\tpanose-1:2 15 5 2 2 2 4 3 2 4;}\n/* Style Definitions */\np.MsoNormal, li.MsoNormal, div.MsoNormal\n\t{margin:0in;\n\tmargin-bottom:.0001pt;\n\tfont-size:11.0pt;\n\tfont-family:\"Calibri\",sans-serif;}\na:link, span.MsoHyperlink\n\t{mso-style-priority:99;\n\tcolor:blue;\n\ttext-decoration:underline;}\ncode\n\t{mso-style-priority:99;\n\tfont-family:\"Courier New\";}\n.MsoChpDefault\n\t{mso-style-type:export-only;}\n@page WordSection1\n\t{size:8.5in 11.0in;\n\tmargin:1.0in 1.0in 1.0in 1.0in;}\ndiv.WordSection1\n\t{page:WordSection1;}\n-->OK, lemme give it a shot.\u00a0I\u2019ll let you know how it goes.\u00a0Shin\u00a0Sent from Mail for Windows 10\u00a0From: Pavithra VijaySent: Thursday, April 2, 2020 10:57 AMTo: tensorflow/tensorflowCc: shinlin77; MentionSubject: Re: [tensorflow/tensorflow] pixelwise-loss-weight map (#38060)\u00a0@shinlin77 Will you be able to try this in the latest version of TF? We have made a number of changes to sample weights behavior and we have very few restrictions on sample weights today.In TF2.2 you are not required to specify sample_weight_mode in compile API.Closing this issue as the use case is expected to work in TF2.0. Please feel free to ping or reopen if you are facing any issues.\u2014You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or unsubscribe.\u00a0", "Hello Pavithra:\n\nI looked at  https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit and\npasted the relevant parts.  These options, I don't think, will be adequate\nfor the weights needed for pixelwise-loss-weights.  For 2D images, weights\nwill need to be shape [None, x_dim, y_dim, 1 or 3 or 4].  You see, the\nweights also need to be passed through  tf.keras.preprocessing.image.\nImageDataGenerator along with X_train, Y_train.  So X_datagen, W_datagen\n(for weights), and Y_datagen all need all to be passed into Model.fit.\n\nShin\n\n\n   - *class_weight*: Optional dictionary mapping class indices (integers)\n   to a weight (float) value, used for weighting the loss function (during\n   training only). This can be useful to tell the model to \"pay more\n   attention\" to samples from an under-represented class.\n   - *sample_weight*: Optional Numpy array of weights for the training\n   samples, used for weighting the loss function (during training only). You\n   can either pass a flat (1D) Numpy array with the same length as the input\n   samples (1:1 mapping between weights and samples), or in the case of\n   temporal data, you can pass a 2D array with shape (samples,\n   sequence_length), to apply a different weight to every timestep of every\n   sample. In this case you should make sure to specify\n   sample_weight_mode=\"temporal\" in compile(). This argument is not\n   supported when x is a dataset, generator, or keras.utils.Sequence\n   <https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence>\ninstance,\n   instead provide the sample_weights as the third element of x.\n\n\nOn Thu, Apr 2, 2020 at 10:57 AM Pavithra Vijay <notifications@github.com>\nwrote:\n\n> @shinlin77 <https://github.com/shinlin77> Will you be able to try this in\n> the latest version of TF? We have made a number of changes to sample\n> weights behavior and we have very few restrictions on sample weights today.\n> In TF2.2 you are not required to specify sample_weight_mode in compile\n> API.\n>\n> Closing this issue as the use case is expected to work in TF2.0. Please\n> feel free to ping or reopen if you are facing any issues.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38060#issuecomment-608012223>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ALVU6EKPUSPEGZOVNDI2RA3RKTGXBANCNFSM4LXDW6DA>\n> .\n>\n", "Sample weights, even if you are using custom generators (as far as I know), need to be 1D or 2D.\r\nFor pixelwise weighting, the ideal would be having something like @shinlin77 is saying (for one-hot encoded and NCHW: [batch_size, n_classes, height, width]). \r\n\r\nThis at the moment is not possible (sample weights can be either one weight per sample in batch or one weight per class of sample in batch).\r\n\r\nEdit: This is what's written in the documentation: \r\n\r\n> Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples)\r\n\r\nCan this be interpreted as some kind of pixelwise approach? If I have a generator yielding y of size (bs, ch, h, w) (4, 1, 128, 128) could I use 1D sample weights of length 65536?"]}, {"number": 38058, "title": "Direct feed from GPU memory in Java, for R1.15", "body": "- PR adds 2 things to Java API:\r\n  - allocating tensor in GPU (GPUBFCAllocator)\r\n  - directly feeding tensors allocated in GPU (makeCallable/runCallable with CallableOptions)\r\n- Originally posted as a feature request [#37909](https://github.com/tensorflow/tensorflow/issues/37909).\r\n- Testing:\r\n```\r\nbazel test //tensorflow/java:GPUTensorTest\r\nbazel test //tensorflow/java:DirectSessionTest\r\n```\r\n\r\nIt might not be the best implementation. Please, review and advise.\r\nThanks", "comments": ["Can you make it a PR against master please? And then cherry-pick on `r1.15` if needed?\r\n\r\nWe don't update the release branches except if we do a patch release and we only do patch releases mostly for security purposes. Thus, PRs against release branches won't get merged and will likely get lost.", "Alright, PRed against master - see [#38083](https://github.com/tensorflow/tensorflow/pull/38083)"]}, {"number": 38057, "title": "MaxPooling1D layer causes ESP32 to crash", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.4\r\n- TensorFlow installed from (source or binary): Installed with pip `pip install --upgrade tensorflow`\r\n- Tensorflow version (commit SHA if source): Version 2.1.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32\r\n\r\n**Describe the problem**\r\nUsing a MaxPooling1D in my model causes the ESP32 to crash. However the model works fine when I remove the MaxPooling1D layer.\r\n\r\nHere is the error from the exception:\r\n```\r\nDidn't find op for builtin opcode 'MAX_POOL_2D' version '2'\r\nFailed to get registration from op code MAX_POOL_2D\r\nAllocateTensors() failed\r\nGuru Meditation Error: Core  1 panic'ed (LoadProhibited). Exception was unhandled.\r\n```\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nHere is my model:\r\n\r\n```python\r\nmodel = Sequential()\r\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timestep,6)))\r\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(MaxPooling1D(pool_size=2))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(100, activation='relu'))\r\nmodel.add(Dense(4, activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])\r\n```\r\n\r\nTo convert the model:\r\n\r\n```python\r\nconverter = lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.optimizations = [lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\ntfmodel = converter.convert()\r\nopen(PATH+'/model.tflite',\"wb\").write(tfmodel)\r\n```\r\n\r\nFor the ops resolver I am using AllOpsResolver:\r\n`static tflite::ops::micro::AllOpsResolver resolver;`\r\n\r\nIf I look in the file all_ops_resolver.cc there is no min/max version for MAX_POOL_2D:\r\n`AddBuiltin(BuiltinOperator_MAX_POOL_2D, Register_MAX_POOL_2D());`\r\n\r\nBest regards,\r\nVictor Douet", "comments": ["It was resolved in bfc8b7cab058402e24219ac1d492a0b8418712e0\r\n\r\nI'm closing the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38057\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38057\">No</a>\n"]}, {"number": 38056, "title": "Error with tensorflow 2: Inputs to eager execution function cannot be Keras symbolic tensors", "body": "Hi everyone,\r\n\r\nThe tensorflow 2 release notes request that an issue be filed when experiencing problems with the new single path execution code.\r\n\r\nI regularly work with custom loss functions that require additional information other than the predictors and observed outcomes. A simple example is estimating a general binomial regression model, where the number of trials are part of the likelihood/loss function, but they are not part of the predictors or observed outcome. Sample R code is provided in https://github.com/rstudio/keras/issues/1008\r\n\r\nWould you please make available a permanent option in tensorflow 2 to pass additional inputs layers into custom loss functions so that we can keep using tensorflow to estimate such models? I guess that setting `experimental_run_tf_function=False` is only a temporary fix.\r\n\r\nThank you", "comments": ["@lutzgruber \r\n\r\nRequest you to share the colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "Below is Python code to reproduce the issue: \r\n\r\n- With tensorflow 1.15.0, the code works as posted.\r\n- With tensorflow 2.1.0, the call to `model.fit` fails unless the option `experimental_run_tf_function=False` is set in `model.compile`.\r\n\r\nThe error is \r\n\r\n```\r\nTrain on 16 samples, validate on 4 samples\r\nEpoch 1/1000\r\n16/16 [==============================] - 0s 14ms/sample\r\nTraceback (most recent call last):\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\r\n    num_outputs)\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: logNchooseK:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 11, in <module>\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 342, in fit\r\n    total_epochs=epochs)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 632, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/home/xxx/anaconda3/envs/tf2python/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 75, in quick_execute\r\n    \"tensors, but found {}\".format(keras_symbolic_tensors))\r\ntensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'logNchooseK:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'N:0' shape=(None, 1) dtype=float32>]\r\n```\r\n\r\nThis is a demo case to estimate a model with a binomial likelihood/loss function, which requires that information on the number of trials is passed through to the custom loss function; this information is neither part of the predictors nor of the observed outcome. I do this by defining this outside information as input layers, and referencing them in my loss function.\r\n\r\nWhile setting `experimental_run_tf_function=False` serves as an intermediate fix by reverting to the old execution path, my reading of the release notes is that this option was only intended as temporary.\r\n\r\nIs there a new way of supplying outside information to custom loss functions in tensorflow 2? If not, I would ask that such an option be made available again.\r\n\r\n```\r\nimport tensorflow.keras as keras\r\nimport numpy as np\r\n\r\npredictors_layer = keras.layers.Input(\r\n    shape = (2, ),\r\n    name = \"predictors\"\r\n)\r\n\r\nN_layer = keras.layers.Input(\r\n  shape = (1, ),\r\n  name = \"N\"\r\n)\r\n\r\nlogNchooseK_layer = keras.layers.Input(\r\n  shape = (1, ),\r\n  name = \"logNchooseK\"\r\n)\r\n\r\noutput_layer = keras.layers.Dense(\r\n  units = 1,\r\n  activation = \"linear\",\r\n  name = \"output\"\r\n)(predictors_layer)\r\n\r\nmodel = keras.models.Model(\r\n    inputs = (predictors_layer, N_layer, logNchooseK_layer),\r\n    outputs = output_layer\r\n)\r\n\r\ndef binomial_loss(y_true, y_pred):\r\n    predicted_prob = keras.backend.exp(y_pred) / (1 + keras.backend.exp(y_pred))\r\n\r\n    neg_loglik = -(logNchooseK_layer + y_true * keras.backend.log(predicted_prob) + (N_layer - y_true) * keras.backend.log(1 - predicted_prob))\r\n\r\n    return neg_loglik\r\n\r\nmodel.compile(\r\n    loss = binomial_loss,\r\n    optimizer = \"adam\"#,\r\n    #experimental_run_tf_function = False\r\n)\r\n\r\n\r\n# train model ----------------------------------------------------------------------------------------------\r\n\r\n# the columns are: predictor1, predictor2, N: number of trials, true success probability as function of predictors 1+2, k: realized number of successes, log(N choose k)\r\nsample_data = np.matrix(\r\n    [\r\n        [0.586\t,0.78\t,88\t,0.706\t,65\t,48.214931],\r\n        [0.709\t,1.46\t,52\t,0.809\t,41\t,24.824317],\r\n        [-0.109\t,-0.644\t,1\t,0.369\t,1\t,0],\r\n        [-0.453\t,-1.55\t,2\t,0.199\t,0\t,0],\r\n        [0.606\t,-1.6\t,15\t,0.29\t,4\t,7.218910],\r\n        [-1.82\t,1.81\t,31\t,0.609\t,15\t,19.521092],\r\n        [0.63\t,-0.482\t,83\t,0.488\t,44\t,54.944102],\r\n        [-0.276\t,0.62\t,51\t,0.581\t,29\t,32.681372],\r\n        [-0.284\t,0.612\t,81\t,0.579\t,45\t,53.223945],\r\n        [-0.919\t,-0.162\t,7\t,0.359\t,2\t,3.044522],\r\n        [-0.116\t,0.812\t,93\t,0.634\t,61\t,57.420880],\r\n        [1.82\t,2.2\t,81\t,0.928\t,75\t,19.597920],\r\n        [0.371\t,2.05\t,8\t,0.848\t,7\t,2.079442],\r\n        [0.52\t,1.63\t,61\t,0.815\t,54\t,19.893774],\r\n        [-0.751\t,0.254\t,72\t,0.454\t,34\t,47.429363],\r\n        [0.817\t,0.491\t,52\t,0.685\t,33\t,31.966485],\r\n        [-0.886\t,-0.324\t,73\t,0.335\t,17\t,37.410978],\r\n        [-0.332\t,-1.66\t,75\t,0.196\t,16\t,36.684713],\r\n        [1.12\t,1.77\t,10\t,0.868\t,8\t,3.806662],\r\n        [0.299\t,0.0258\t,40\t,0.542\t,20\t,25.649407]\r\n    ]\r\n)\r\n\r\nmodel.fit(\r\n  x = {\r\n    'predictors': sample_data[:,(0,1)],\r\n    'N': sample_data[:,2],\r\n    'logNchooseK': sample_data[:,5]\r\n  },\r\n  y = {\r\n    'output': sample_data[:,4]\r\n  },\r\n  validation_split = 0.2,\r\n  epochs = 1000\r\n)\r\n\r\n# evaluate model\r\n\r\npredicted_logodds = model.predict(\r\n    x = {\r\n        'predictors': sample_data[:,(0,1)],\r\n        'N': sample_data[:,2],\r\n        'logNchooseK': sample_data[:,5]\r\n    }\r\n)\r\n\r\npredicted_probs = np.exp(predicted_logodds) / (1 + np.exp(predicted_logodds))\r\n\r\nprint(np.transpose(np.reshape([sample_data[:, 3], predicted_probs], [2, 20])))\r\n```", "I have tried on colab with TF version 2.0 , 2.1,'2.2.0-rc2' and was able to reproduce the issue.PLease, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/d2390bb0ba9663172de91109057bcfec/untitled763.ipynb#scrollTo=1PWWBxaUnbtf). Thanks!", "Thanks @lutzgruber . It sounds like you might be looking for the add_loss API, which allows you to add losses to the model: \r\n\r\nhttps://keras.io/api/losses#the-addloss-api\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#add_loss\r\n\r\n", "@lutzgruber Closing due to lack of recent activity. Please feel free to  reopen the issue if you have any concern. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38056\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38056\">No</a>\n"]}, {"number": 38055, "title": "PiecewiseConstantDecay Keras Learning Rate Scheduler not compatible with XLA Compilation", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThe Keras PieceWiseConstant Decay scheduler currently causes an 'unsupport op' error when used with XLA compilation (i.e. when used with `@tf.function(experimental_compile=True)`).  This happens because [it calls the control_flow_ops `case` function with `exclusive=True`](https://github.com/tensorflow/tensorflow/blob/e3baa0f5b6cb77cbd312f0ad89e46829c073b1ec/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py#L258), which eventually results in [an assertion that is incompatible with XLA](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L3194).\r\n\r\nI would like to add an additional `validate_args=True` parameter to PiecewiseConstantDecay that can be optionally set to False to forgo setting `exclusive=True`, thus making the operation TPU-friendly ([similar to the approach taken elsewhere](https://github.com/tensorflow/probability/pull/771)).\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis will not change beahviour of any existing code, but will provide an additional parameter that can be used to leverage XLA compatibility for running on TPU.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAll users of Cloud TPUs who would like to make complete use of Keras learning rate schedulers.\r\n\r\n**Any Other info.**\r\n\r\nN/A", "comments": ["@ecrows, Sorry for the late response. Is this still an issue for you?\r\n\r\nCan you please try recent TF2.7 or tf-nightly and let us know whether it is persisting. Also, share a simple standalone code to reproduce the issue. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38054, "title": "Unable to access files on S3 with tf.io.gfile.GFile", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): MacOS Mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): 2.0.0\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nExecuting the following code: \r\n\r\n```\r\nwith tf.io.gfile.GFile(\"s3://path/to/my/file\", mode=\"r\") as f:\r\n    data = f.read()\r\n```\r\n\r\nresults in the following error message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 124, in read\r\n    length = self.size() - self.tell()\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 102, in size\r\n    return stat(self.__name).length\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 727, in stat\r\n    return stat_v2(filename)\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 744, in stat_v2\r\n    pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Object s3://[REDACTED]/train.txt does not exist\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\nThe contents of the file should be written to variable `data`\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nThis points to a public s3 file, but still fails:\r\n\r\nhttps://colab.research.google.com/drive/1VSlfzRPdFNSGGI8wd6RdhH9uFj7fkaFG\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n2020-03-30 23:22:36.465054: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /Users/neelabh//.aws/config and using profilePrefix = 1\r\n2020-03-30 23:22:36.465103: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing config loader against fileName /Users/neelabh//.aws/credentials and using profilePrefix = 0\r\n2020-03-30 23:22:36.465129: I tensorflow/core/platform/s3/aws_logging.cc:54] Setting provider to read credentials from /Users/neelabh//.aws/credentials for credentials file and /Users/neelabh//.aws/config for the config file , for use with profile default\r\n2020-03-30 23:22:36.465207: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating AWSHttpResourceClient with max connections2 and scheme http\r\n2020-03-30 23:22:36.465336: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 2\r\n2020-03-30 23:22:36.465391: I tensorflow/core/platform/s3/aws_logging.cc:54] Creating Instance with default EC2MetadataClient and refresh rate 300000\r\n2020-03-30 23:22:36.465427: I tensorflow/core/platform/s3/aws_logging.cc:54] Added EC2 metadata service credentials provider to the provider chain.\r\n2020-03-30 23:22:36.465682: I tensorflow/core/platform/s3/aws_logging.cc:54] Successfully reloaded configuration.\r\n2020-03-30 23:22:36.465889: I tensorflow/core/platform/s3/aws_logging.cc:54] Initializing CurlHandleContainer with size 25\r\n2020-03-30 23:22:36.466559: I tensorflow/core/platform/s3/aws_logging.cc:54] Pool grown by 2\r\n2020-03-30 23:22:36.466586: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2020-03-30 23:22:37.536377: E tensorflow/core/platform/s3/aws_logging.cc:60] HTTP response code: 301\r\nException name: \r\nError message: No response body.\r\n7 response headers:\r\ncontent-type : application/xml\r\ndate : Mon, 30 Mar 2020 17:52:37 GMT\r\nserver : AmazonS3\r\ntransfer-encoding : chunked\r\nx-amz-bucket-region : eu-north-1\r\nx-amz-id-2 : 021phnKX0e6e9R+N9sMrXZHViGoHdzJrTT5rnyHyWsP8d9ErkPMZT02RbTZcjVeCVrI/3hDkWk8=\r\nx-amz-request-id : 7DAC97A633CA370B\r\n2020-03-30 23:22:37.536443: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2020-03-30 23:22:37.536681: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2020-03-30 23:22:37.818954: W tensorflow/core/platform/s3/aws_logging.cc:57] Encountered Unknown AWSError 'PermanentRedirect': The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint.\r\n2020-03-30 23:22:37.819073: E tensorflow/core/platform/s3/aws_logging.cc:60] HTTP response code: 301\r\nException name: PermanentRedirect\r\nError message: Unable to parse ExceptionName: PermanentRedirect Message: The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint.\r\n7 response headers:\r\ncontent-type : application/xml\r\ndate : Mon, 30 Mar 2020 17:52:37 GMT\r\nserver : AmazonS3\r\ntransfer-encoding : chunked\r\nx-amz-bucket-region : eu-north-1\r\nx-amz-id-2 : ob9TL15Q4Y7/idUzUTWvurB3Z4nxfVYRV2V+9ly88HrVGuHytuZA1U02rhcL0vFUpv83vUxeO9o=\r\nx-amz-request-id : 51E3695245C81463\r\n2020-03-30 23:22:37.819138: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 124, in read\r\n    length = self.size() - self.tell()\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 102, in size\r\n    return stat(self.__name).length\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 727, in stat\r\n    return stat_v2(filename)\r\n  File \"/Users/neelabh/opt/anaconda3/envs/tftrt/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 744, in stat_v2\r\n    pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Object s3://[REDACTED]/train.txt does not exist\r\n```", "comments": ["There seems to be a failure before\r\n\r\n```\r\nException name: PermanentRedirect\r\nError message: Unable to parse ExceptionName: PermanentRedirect Message: The bucket you are attempting to access must be addressed using the specified endpoint. Please send all future requests to this endpoint.\r\n```\r\n\r\nCan you also try with TF 2.1? tf-nightly? To bisect where the error comes from.", "Here is what I did:\r\n\r\nI ran the following code in a `tensorflow/tensorflow:nightly` container. TF version was `2.2.0-dev20200402`\r\n\r\n```\r\ntf.io.gfile.stat(\"s3://neelabh-test-public-bucket/train.txt\")\r\n```\r\n\r\nThis produced the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\", line 761, in stat_v2\r\n    return _pywrap_file_io.Stat(path)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Object s3://neelabh-test-public-bucket/train.txt does not exist\r\n```\r\n\r\nNow, when I install `boto3` in the same container and use `s3.Object().get()` I am able to download the file.  Also works with wget and the HTTP link to the file. ", "@nihil0 \r\nIs this still an issue?.\r\nPlease close this thread if the issue was resolved. Thanks!", "Same problem here. Both these API calls (`tf.io.gfile.stat` or `file_io.stat`) fail with `NotFoundError: Object s3://\r\n<bucket_name>/<path/to/file> does not exist`. But if I use `boto3` I can download the files without any issue.\r\n\r\n```python\r\n# Alternative to reproduce the error\r\nfrom tensorflow.python.lib.io import file_io\r\nprint(file_io.stat('s3://<bucket_name>/<path/to/file>'))\r\n```\r\n\r\nIt looks like this issue is hanging [here for a while](https://github.com/tensorflow/tensorflow/issues/24253)...\r\n", "Any news on this? I'm running into a similar issue with tf 2.2 and s3 on ec2. ", "I'm investigating this and similar issues", "For my part it was an SSL problem whenever  I ran TensorFlow on an ec2 instance (curl 77 errors in the logs), I temporarily fixed it by setting `S3_VERIFY_SSL=0`.", "I fixed this issue by adding AWS_REGION and S3_ENDPOINT environment variables. For example:\r\n```\r\nimport os\r\nos.environ['AWS_REGION'] = 'us-west-1'\r\nos.environ['S3_ENDPOINT'] = 'https://s3-us-west-1.amazonaws.com'\r\n```", "@nihil0 \r\nIs this still an issue, can you please check on nightly and move this to closed status if resolved.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">No</a>\n", "hi @Saduf2019 do you mind referencing the commit that is meant to fix this?", "I have tested on the nightly build, and this problem still persists. The solution of @Abhipray does work: However I'd like to note that \r\n- download performance is really poor (100mb files takes over a minute on a connection that should be 10x faster)\r\n- no progress bar works with this", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">No</a>\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">No</a>\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">No</a>\n", "@nihil0 It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38054\">No</a>\n"]}, {"number": 38053, "title": "high thread count", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information** \r\n- Custom inference application written in Python.\r\n- ubuntu 18.04.3, latest\r\n- TensorFlow 1.14\r\n- Python version:  3.7\r\n- CUDA/cuDNN version:10.2\r\n - GPU. Nvidia 5 x T4 16G.\r\n\r\nThis is more of a question related to performance/effeciency  I'm in charge of setting up Ubuntu. I've been ask by a software developper to increase linux DefaultTaskMax to 20000.  The rationnal is that tensorflow create 2000 threads per GPU, there is about 20  models uploaded on 1 card. Yet 2000 seems like a totaly crazy number of threads.  My gut feeling tells me something must be wrong. That tensor flow is set up or used wrong.  I have been trying to find information about this with no luck. I also tried to find information on the effect of increasing DefaultTaskMax on kernel overhead.\r\n\r\nRegards,\r\n- Mario\r\n", "comments": ["I'm told using \r\nconfig.intra_op_parallelism_threads = 1\r\nconfig.inter_op_parallelism_threads = 1\r\n\r\nBrought down the number of threads from 11150 to 4568.\r\n", "Seems like most threads are using around 580K of stacks. With 4000 threads, that means 2.3g of ram consumed just for stack. That seems like a waste of resource and not very cache friendly?  I'm real curious for the rational behind this. ", "What are the names of these threads?", "I did ps H -c python3 -o 'pid tid cmd comm' to get the threads name. ALL the threads are named python3.  I noticed something interesting. We start 5 instances of python3 with our program.  When I run the command ps command mentionned previously I would expect the output to show 5 different pid. Yet there are around 70 with each having around 65 threads.   That would imply some forking !?!\r\n\r\nCan I infer from your question that this is indeed abnormal.   The author of the code tell me they reduce the program down to opening a tensor flow session and there was still lots of threads.  The fact that ALL threads are name python3 thread makes me doubt the operation I did, as again from your question, I assume some of those thread should have a tensor flow related name. Note that as I ran the ps command, the software had been just restarted and had yet to do anything of substance, I will confirme this with the developper tomorrow.\r\n\r\nThanks a lot !", "Thousands of threads is definitely abnormal. You probably see the name of the parent process... or something like that. Tensorflow has few thread pools, and they should have names (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/default/env.cc#L107-L110).\r\n\r\nAll (most?) threads should have some meaningful names, so it should be possible to tell if it's intra/inter op thread pool created multiple times, or something else.", "Eugene,\r\n\r\nI had doubt about the command I used, thus I checked it against some of our process/thread written in C++ in which we do set the thread name and it does show thread name and not parent/process name.\r\n\r\nLooking at the code you linked to, I can't find anything that set the thread name at  the OS level. There's thread_name_registry to keep a map of thread_id and name. The fonction GetCurrentThreadName() will look in the map to get the name, if it can't find the thread name in that registry, it get the thread name from the OS. \r\n\r\nSo the thread name Linux shows me seems to match the code you shown me ;-)\r\n", "Trying to find my way through tensorflow code ( ouf ) and looking at pid/tid/ppid here is my gut feeling:\r\n\r\nI changed the command to display parrent pid ( ppid) and what I'm seing now it there are very few ppid. In fact I can find 5 parent pids that are matching the 5 python programs we start, one per GPU!!! These 5 \"groups\" have about 70 unique pids, and each pid has about 65 unique tids. \r\n\r\n\r\n\r\n", "Ping?", "> Looking at the code you linked to, I can't find anything that set the thread name at the OS level. There's thread_name_registry to keep a map of thread_id and name. The fonction GetCurrentThreadName() will look in the map to get the name, if it can't find the thread name in that registry, it get the thread name from the OS.\r\n> \r\n> So the thread name Linux shows me seems to match the code you shown me ;-)\r\n\r\nI suspect Eugene was proposing that you somehow get the names of the 2000 threads as specified in `GetThreadNameRegistry` to debug why there are so many.\r\n\r\nHowever, it seems like you have multiple TF *processes* running and the problem is that there are a high total number of threads?  If so, that is expected: I don't think multiple TF processes collude to limit the total number of threads across processes.", "> > Looking at the code you linked to, I can't find anything that set the thread name at the OS level. There's thread_name_registry to keep a map of thread_id and name. The fonction GetCurrentThreadName() will look in the map to get the name, if it can't find the thread name in that registry, it get the thread name from the OS.\r\n> > So the thread name Linux shows me seems to match the code you shown me ;-)\r\n> \r\n> I suspect Eugene was proposing that you somehow get the names of the 2000 threads as specified in `GetThreadNameRegistry` to debug why there are so many.\r\n> \r\n\r\nTensorflow 1.4 does not seems to set thread name at the OS level, as I describe in one of my post. I guess it could be possible to get them though tensorflow API, if that is what you mean?\r\n\r\n> However, it seems like you have multiple TF _processes_ running and the problem is that there are a high total number of threads? If so, that is expected: I don't think multiple TF processes collude to limit the total number of threads across processes.\r\n\r\nYes we have 5 processes, but without setting \r\n  config.intra_op_parallelism_threads = 1\r\n  config.inter_op_parallelism_threads = 1\r\nWe get 2200 threads per process. With the sop_parallelism_thread to 1,  it's down to ~820 which is still huge.\r\n\r\n", "Do you use regular TF or TF-MKL? (if I remember correctly TF-MKL is the default in Anaconda for example)", "Regular TF.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 38052, "title": "Add new OctaveConvolution Layer to keras", "body": "In natural images, information is conveyed at different frequencies where higher frequencies are usually encoded with fine details and lower frequencies are usually encoded with global structures. Similarly, the output feature maps of a convolution layer can also be seen as a mixture of information at different frequencies. In this work, we propose to factorize the mixed feature maps by their frequencies and design a novel Octave Convolution (OctConv) opera-tion1to store and process feature maps that vary spatially\u201cslower\u201d at a lower spatial resolution reducing both memory and computation cost.\r\nFixes #37576\r\nhttps://arxiv.org/pdf/1904.05049.pdf\r\nHere is a test code on mnist dataset\r\n\r\n[mnistoctave.zip](https://github.com/tensorflow/tensorflow/files/4404609/mnistoctave.zip)\r\n", "comments": ["Hi,\r\nI'm the author of the issue (#37576 ) mentioned in this PR.\r\nThis PR states that it fixes it but it doesn't for the reasons I give in my PR (#38154) for this issue and also in a comment in the issue.\r\nI therefore invite you and the tensorflow team to look at the code I propose in #38154 instead. ", "I believe this pull request should be closed and that we should group our efforts to work on the pull request in thensorflow addons instead. "]}, {"number": 38051, "title": "Cherrypick from r2.2 to master", "body": "USually cherrypicks should be done in the other way, but this one was done badly so we have to fix.\r\n\r\nWill import manually", "comments": []}, {"number": 38050, "title": "Update callbacks.py corrected term names in doc", "body": "In reference to the issue #34965 \r\nCorrected the \"accuracy\" and \"val_accuracy\" terms as returned by the callback (history object) instead of the short documented versions acc/val_acc .", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38050) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38050) for more info**.\n\n<!-- ok -->", "@Jaskaran170599 Can you please resolve conflicts? Thanks!", "@gbaned conflicts resolved , please review.", "Closing outdated PR, sorry that we weren't able to review it in time."]}, {"number": 38049, "title": "Add new OctaveConvolution Layers in keras", "body": "In natural images, information is conveyed at different frequencies where higher frequencies are usually encoded with fine details and lower frequencies are usually encoded with global structures. Similarly, the output feature maps of a convolution layer can also be seen as a mixture of information at different frequencies. In this work, we propose to factorize the mixed feature maps by their frequencies and design a novel Octave Convolution (OctConv) opera-tion1to store and process feature maps that vary spatially\u201cslower\u201d at a lower spatial resolution reducing both memory and computation cost.\r\nFixes tensorflow#37576\r\nhttps://arxiv.org/pdf/1904.05049.pdf\r\nHere is a test code on mnist dataset\r\n\r\n[mnistoctave.zip](https://github.com/tensorflow/tensorflow/files/4403997/mnistoctave.zip)\r\n", "comments": []}, {"number": 38048, "title": "Add usage examples and improve documentation on tf.keras.applications models", "body": "Related issue: #37996\r\nAdded some basic usage examples for models in Keras.Applications. The arguments were already added to the nightly so the changes made are:\r\n\r\n- Add example of extracting features using premade models\r\n- <del>Fix the issue were argument option sublist was not at the right indent level</del>\r\n- Reworded the pooling mode argument in models' description to be more concise\r\n- Add raises exception list where absent\r\n- Add doctest example of creating a model and what type of model it should return\r\n\r\n", "comments": ["Looks like the tests are failing on doctest\r\n\" ... lacks blank after >>>: '  >>>model = DenseNet121(weights = None)'\"\r\nI'll fix it.", "It also looks like I missed line limits a few 20 times which is failing the sanity check's pylint check.\r\n\"\r\n> ...\r\n> tensorflow/python/keras/applications/vgg16.py:91: [C0301(line-too-long), ] Line too long (83/80)\r\n> tensorflow/python/keras/applications/vgg16.py:92: [C0301(line-too-long), ] Line too long (81/80)\r\n> tensorflow/python/keras/applications/inception_resnet_v2.py:85: [C0301(line-too-long), ] Line too long (81/80)\r\n> ...\r\n\r\n\"\r\nRearranging the lines going over 80 characters, and, while I'm at it, fix the grammar mistake"]}, {"number": 38047, "title": "Launch tensorboard in colab", "body": "i try launch tensorboard on colab, my code:\r\n\r\n```\r\nLOG_DIR = model_dir\r\nget_ipython().system_raw(\r\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6060 &'\r\n    .format(LOG_DIR)\r\n)\r\n\r\nget_ipython().system_raw('./ngrok http 6060 &')\r\n\r\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\r\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\r\n```\r\ntwo days ago everything worked, but now such an error:\r\n\r\n[error](http://puu.sh/FqU8i/62b7eec918.jpg)", "comments": ["@lolpa1n Please share the entire code with data preferably as a gist to reproduce this issue. Thanks!", "> @lolpa1n Please share the entire code with data preferably as a gist to reproduce this issue. Thanks!\r\n\r\nThe code that I attached is entire code, the rest code for object detection", "@lolpa1n Without using ngrok, is the local server running?", "> @lolpa1n Without using ngrok, is the local server running?\r\n\r\ncurl: (7) Failed to connect to localhost port 6006: Connection refused\r\n![ss+(2020-04-05+at+04 05 49)](https://user-images.githubusercontent.com/47947340/78473119-8f676700-7757-11ea-8495-a9c66a3180f6.png)\r\n\r\n", "@lolpa1n Please provide us the colab notebook(gist) for us to reproduce this issue. I am not able to reproduce it.\r\nAlso I am not able to reproduce this error using [starter code](https://www.tensorflow.org/tensorboard/get_started) and I didnt run into any error\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38046, "title": "Added Custom Dense layer specially for SNN's", "body": "Added recursive loss for the custom layer with lecum_uniform kernel initializer.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38046) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38046) for more info**.\n\n<!-- ok -->", "Maybe contribute this to tensorflow addons", "I agree, this should be added to tensorflow/addons. Can you send a PR to the addons repo? Closing this now. Thank you!", "> I agree, this should be added to tensorflow/addons. Can you send a PR to the addons repo? Closing this now. Thank you!\r\n\r\nOkay sure!"]}]