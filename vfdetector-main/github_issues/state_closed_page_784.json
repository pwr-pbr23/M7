[{"number": 30028, "title": "Python package is missing ModuleSpec in tensorflow.__spec__ in tf 1.14.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.9.125-linuxkit-x86_64-with-Ubuntu-18.04-bionic\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): preinstalled in docker image\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nIn TF 1.14.0 the module spec in `tensorflow.__spec__` is None:\r\n```\r\n>>> import tensorflow\r\n>>> print(tensorflow.__spec__)\r\nNone\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThis is different from tf 1.13.1 where it works as expected:\r\n```\r\n>>> import tensorflow\r\n>>> print(tensorflow.__spec__)\r\nModuleSpec(name='tensorflow', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f038cfc3cf8>, origin='/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py', submodule_search_locations=['/usr/local/lib/python3.5/dist-packages/tensorflow'])\r\n```\r\n\r\nMissing spec causes some problems, e.g. pkgutil now fails when trying to find tensorflow. Note that the first call to `find_loader` is successful, it only fails *after* tensorflow is imported:\r\n```\r\nPython 3.6.8 (default, Jan 14 2019, 11:02:34) \r\n[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import pkgutil\r\n>>> pkgutil.find_loader('tensorflow')\r\n<_frozen_importlib_external.SourceFileLoader object at 0x7f62372c7160>\r\n>>> import tensorflow\r\n>>> pkgutil.find_loader('tensorflow')\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/pkgutil.py\", line 490, in find_loader\r\n    spec = importlib.util.find_spec(fullname)\r\n  File \"/usr/lib/python3.6/importlib/util.py\", line 102, in find_spec\r\n    raise ValueError('{}.__spec__ is None'.format(name))\r\nValueError: tensorflow.__spec__ is None\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.6/pkgutil.py\", line 496, in find_loader\r\n    raise ImportError(msg.format(fullname, type(ex), ex)) from ex\r\nImportError: Error while finding loader for 'tensorflow' (<class 'ValueError'>: tensorflow.__spec__ is None)\r\n```\r\n\r\n**Code to reproduce the issue**\r\nSee above\r\n\r\n**Other info / logs**\r\n\r\nI've tested this using official tf docker image (tensorflow/tensorflow:1.14.0-py3) and also using python docker image (python:3.6) with tensorflow installed with pip.", "comments": ["importlib throws the same error. Can't do custom imports in 1.14.\r\n```\r\nTraceback (most recent call last):\r\n  File \"path/test/test_model.py\", line 62, in testTFGraph\r\n    save_tensorflow(sess, path, output=['output'])\r\n  File \"path/model.py\", line 55, in save_tensorflow\r\n    if not is_installed('tensorflow'):\r\n  File \"path/_util.py\", line 18, in is_installed\r\n    if importlib.util.find_spec(p) is None:\r\n  File \"path/lib/python3.7/importlib/util.py\", line 114, in find_spec\r\n    raise ValueError('{}.__spec__ is None'.format(name))\r\nValueError: tensorflow.__spec__ is None\r\n```", "Another data point: this also happens in nightly", "Sorry for the breakage! This is caused by adding a module wrapper that prints deprecation messages. I will send a change to fix it.", "Closing this issue since the associated PR has been merged. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30028\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30028\">No</a>\n", "Is there a work around in the mean time?", "We'll get the 1.14.1 patch release this week.", "Update: Instead of a 1.14.1 patch release, we will get a 1.15 version in a few weeks. Sorry for the extra delay this causes."]}, {"number": 30027, "title": "Update TensorBoard callback in callbacks.py", "body": "See #29958 : Suggested improvements:\r\n\r\n* _Added a TensorBoard example:_\r\n\r\nMaterial used and modified from [TensorBoard in Notebooks](https://www.tensorflow.org/tensorboard/r2/tensorboard_in_notebooks) and [Getting started with TensorBoard](https://www.tensorflow.org/tensorboard/r2/get_started).\r\n\r\nNote the`%`-sign in front of the command line invocations (for Jupyter).\r\n\r\n* _Replaced bullet points `*` with `-` to attempt to fix the way certain bullet points are displayed:_\r\n\r\nPreviously, they were displayed in one \"sentence\" as this Markdown `*` syntax wasn't \"picked up\": `This callback logs events for TensorBoard, including: * Metrics summary plots * Training graph visualization * Activation histograms * Sampled profiling` (For reference, see r1.14 doc [link](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) and r2.0 doc [link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TensorBoard)).", "comments": ["just checking in to see if anything else needs to be done @rchao @gbaned thanks!", "@8bitmp3 Could you please address the reviewer comments. Thanks!", "Can one of the admins verify this patch?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 30026, "title": "error while converting MobileNet SSD tflite_graph.pb file to tflite format using tflite_convert ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version:3.6.5\r\n- Bazel version (if compiling from source):  None\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: none \r\n- GPU model and memory: none\r\n\r\nI am trying to convert a pretrained mobilenetSSD to tflite for deployment which is available in tensorflow detection model zoo.\r\n\r\n**Code to reproduce the issue**\r\ntflite_convert   --graph_def_file=ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync_2018_07_18/tflite_graph.pb    --output_file=ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync_2018_07_18/optimized_graph.lite   --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --input_shape=1,${224},${224},3   --input_array=input   --output_array=final_result   --inference_type=FLOAT   --input_data_type=FLOAT\r\n\r\n\r\n**Other info / logs**\r\nTraceback (most recent call last):\r\n  File \"/home/yash/anaconda3/envs/conversion/bin/tflite_convert\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py\", line 503, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py\", line 499, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py\", line 193, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 904, in convert\r\n    **converter_kwargs)\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 373, in toco_convert_graph_def\r\n    input_data.SerializeToString())\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-06-21 03:51:18.946551: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess\r\n2019-06-21 03:51:18.970221: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: TFLite_Detection_PostProcess\r\n2019-06-21 03:51:18.994542: F tensorflow/lite/toco/tooling_util.cc:918] Check failed: GetOpWithOutput(model, output_array) Specified output array \"final_result\" is not produced by any op in this graph. Is it a typo? This should not happen. If you trigger this error please send a bug report (with code to reporduce this error), to the TensorFlow Lite team.\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f9444831740 (most recent call first):\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py\", line 251 in _run_main\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/absl/app.py\", line 300 in run\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/yash/anaconda3/envs/conversion/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/yash/anaconda3/envs/conversion/bin/toco_from_protos\", line 10 in <module>\r\nAborted (core dumped)\r\n\r\n", "comments": ["Please add the flag `--allow_custom_ops`.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30026\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30026\">No</a>\n"]}, {"number": 30025, "title": "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.", "body": "Version : tensorflow-gpu==2.0.0-beta1\r\nOS : Ubuntu 18.04 LTS\r\n\r\n`W0621 10:32:12.746317 139752995510080 util.py:64] Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.`\r\n\r\nnot something important but do you know how to remove this warning?\r\n\r\nI already included \r\n`import os\r\nimport tensorflow as tf\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'`", "comments": ["Can you add the code which generates this warning? It's hard to say whether it's important without knowing what you were trying to do.", "> Can you add the code which generates this warning? It's hard to say whether it's important without knowing what you were trying to do.\r\n\r\nhttps://github.com/aquadzn/neural-style/blob/master/model.py", "This warning is generated by imageio, not tensorflow: https://github.com/imageio/imageio/blob/ef1f24f23ae959cccf646128dba7b403638d9b5e/imageio/core/util.py\r\n\r\nYou can use tf.convert_image_dtype to make sure that images are properly scaled to 0...255.", "In TF 1.14.0, it's [tf.image.convert_image_dtype](https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype)."]}, {"number": 30024, "title": "Many Keras.applications (e.g. ResNet-101, ResNeXt) missing from default TensorFlow-gpu installation of 1.10 (through 1.14)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.10\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: V8.0.61\r\n- GPU model and memory: Tesla P100-PCIE, 12193MiB\r\n\r\nA lot of the listed [Keras applications](https://keras.io/applications/) are missing from TensorFlow-gpu installations of 1.10 through 1.14. This might as well be a feature request to include those.\r\n\r\nI installed TensorFlow 1.10 through 1.14, and all installations are missing some [Keras applications](https://keras.io/applications/), like ResNet-101, ResNext, etc. I copied the files from the [Keras applications GitHub repository](https://github.com/keras-team/keras-applications/tree/master/keras_applications), and simply pasted them in `site-packages/tensorflow/python/keras/applications/`. However, this results in the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"myscript.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"tensorflow/__init__.py\", line 53, in <module>\r\n    from tensorflow import keras\r\n  File \"tensorflow/keras/__init__.py\", line 13, in <module>\r\n    from tensorflow.keras import applications\r\n  File \"tensorflow/keras/applications/__init__.py\", line 8, in <module>\r\n    from tensorflow.keras.applications import densenet\r\n  File \"tensorflow/keras/applications/densenet/__init__.py\", line 14, in <module>\r\n    from tensorflow.python.keras.applications import DenseNet121\r\nImportError: cannot import name 'DenseNet121'\r\n```\r\n\r\nThis led me to discover another Keras applications folder: `site-packages/tensorflow/keras/applications/`. What is the difference between the two applications folders? Why does not TensorFlow install all applications out-of-the-box? How can I use those applications anyways (preferably without installing Keras separately)?", "comments": ["I meet a similar error importing tensorflow. I'm using tensorflow 1.14.0 in Python 2.7\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/tomheaven/NutstoreFiles/\u6211\u7684\u575a\u679c\u4e91/PycharmProjects/noise_estimation_and_denoise_pytorch/test_drne_and_dn.py\", line 5, in <module>\r\n    from tensorflow.contrib.layers import conv2d, avg_pool2d\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/__init__.py\", line 35, in <module>\r\n    from tensorflow._api.v1 import compat\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/_api/v1/compat/__init__.py\", line 21, in <module>\r\n    from tensorflow._api.v1.compat import v1\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/_api/v1/compat/v1/__init__.py\", line 47, in <module>\r\n    from tensorflow._api.v1.compat.v1 import layers\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/_api/v1/compat/v1/layers/__init__.py\", line 9, in <module>\r\n    from tensorflow.python.keras.api._v1.keras.layers import InputSpec\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/keras/api/__init__.py\", line 8, in <module>\r\n    from tensorflow.python.keras.api import keras\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/keras/api/keras/__init__.py\", line 17, in <module>\r\n    from tensorflow.python.keras.api.keras import applications\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/keras/api/keras/applications/__init__.py\", line 8, in <module>\r\n    from tensorflow.python.keras.api._v1.keras.applications import DenseNet121\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/keras/api/_v1/__init__.py\", line 8, in <module>\r\n    from tensorflow.python.keras.api._v1 import keras\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/keras/api/_v1/keras/__init__.py\", line 17, in <module>\r\n    from tensorflow.python.keras.api._v1.keras import applications\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/keras/api/_v1/keras/applications/__init__.py\", line 8, in <module>\r\n    from tensorflow.python.keras.api._v1.keras.applications import DenseNet121\r\nImportError: cannot import name DenseNet121\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nHowever, the problem disappears when I use Python 3.7. So in my case, the problem is the code is not compatiable with Python 2.7.", "@EmielBoss Could you please confirm if the issue is resolved.", "@EmielBoss \r\nCould you update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "As this issue has already been addressed [here](https://stackoverflow.com/questions/56714015/tensorflow-keras-how-to-get-missing-models-resnet101-resnext-etc-from-kera), I am going ahead and closing this issue. Thanks!"]}, {"number": 30023, "title": "Running tensorflow in Spyder", "body": "An error ocurred while starting the kernel\r\n2019\udae1\udeaa\udae1\udeb9 18:22:35.571373: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019\udae1\udeaa\udae1\udeb9 18:22:36.757865: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 6.00GiB freeMemory: 4.97GiB\r\n2019\udae1\udeaa\udae1\udeb9 18:22:36.775030: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2019\udae1\udeaa\udae1\udeb9 18:22:38.426283: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019\udae1\udeaa\udae1\udeb9 18:22:38.432187: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:958] 0 \r\n2019\udae1\udeaa\udae1\udeb9 18:22:38.436114: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971] 0: N \r\n2019\udae1\udeaa\udae1\udeb9 18:22:38.441378: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4736 MB memory) \u2011> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)", "comments": ["@katherinelyx Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30022, "title": "Update LearningRateScheduler in callbacks.py", "body": "See #30002 : Update the description of LearningRateSchedule, add \"Example:\" to the example, move Arguments below the example", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30022) for more info**.\n\n<!-- need_sender_cla -->", "@8bitmp3 Please sign CLA in order to proceed with next steps. Thank you!", "@gbaned signed it, thanks!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30022) for more info**.\n\n<!-- ok -->", "just checking in to see if anything else needs to be done @rchao @gbaned thanks!", "Can one of the admins verify this patch?", "@8bitmp3 Could you please check reviewer comments and keep us posted. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 30021, "title": "tf.keras.layers.BatchNormalization API does not fully support masking", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): TF 1.13.1\r\n- Python version: 3.6.7\r\n- CUDA/cuDNN version: \r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nTrying to apply a mask when calling a BatchNormalization layer fails with:\r\n*TypeError: call() got an unexpected keyword argument 'mask'*\r\n\r\n**Describe the expected behavior**\r\nMasking should be supported:\r\nhttps://github.com/tensorflow/tensorflow/blob/93dd14dce2e8751bcaab0a0eb363d55eb0cc5813/tensorflow/python/keras/layers/normalization.py#L188\r\n\r\nIf a layer supports masking, it should be a kwarg to __call__. Until all layers support masking, it's not practical to only support masking via an upstream layer. A Masking Layer can't always be inserted into a model because downstream convolution layers don't support it at all. Feeding the mask into the call of a recurrent layer is the only workaround to combine Convolution, LSTM and masking, and it would be great if it worked the same way for BatchNorm:\r\n```encoded = keras.layers.LSTM(10)(input, mask=input_mask)```.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom tensorflow import keras\r\n\r\ndef Works():\r\n    input = keras.layers.Input(shape=(None, 1))\r\n    masked_input = keras.layers.Masking(-1)(input)\r\n    normalized = keras.layers.BatchNormalization(epsilon=1.1e-5)(masked_input)\r\n\r\ndef DoesntWork():\r\n    input = keras.layers.Input(shape=(None, 1))\r\n    mask = keras.layers.Masking(-1).compute_mask(input)\r\n    normalized = keras.layers.BatchNormalization(epsilon=1.1e-5)(input, mask=mask)\r\n\r\nif __name__ == '__main__':\r\n    Works()\r\n```\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a full code snippet to reproduce the issue reported here. Thanks!", "If you run this, you will see the error:\r\n\r\n```\r\nfrom tensorflow import keras\r\n\r\ndef DoesntWork():\r\n    input = keras.layers.Input(shape=(None, 1))\r\n    mask = keras.layers.Masking(-1).compute_mask(input)\r\n    normalized = keras.layers.BatchNormalization(epsilon=1.1e-5)(input, mask=mask)\r\n\r\nif __name__ == '__main__':\r\n    DoesntWork()\r\n```\r\n*TypeError: call() got an unexpected keyword argument 'mask'*", "I have tried on Colab with TF version 1.13.1 and was able to reproduce issue.", "Is the Mask actually used when calculating the mean/variance? The padded values shouldn't be included in the calculations or they are going to bias the mean and lower the variance.", "This is probably part of a bigger issue: #30161\r\nIf the layer incorrectly uses the Mask (ie. ignores it) and causes a model to silently fail, then it shouldn't allow input from a masked layer. The current behavior is even worse than getting an error because it implies that it will operate as expected, when it is most likely impacting performance.", "The way masking works is that we categorize all layers into three categories:\r\n1) producer, that has compute_mask\r\n2) consumer, that takes `mask` inside call()\r\n3) some kind of passenger, that simply pass through the masking.\r\n\r\nfor 3), masking is \"silently\" supported by self.support_masking=True and you don't have to pass `mask` into call(), because we treat batch norm as passing through the mask, not `consuming` the mask. On the other hand, recurrent layers are consumer of mask, i.e., passing `mask` into the call makes sure the output reflects it. recurrent layers will also produce mask as well. Mask layer is merely a producer.\r\n\r\nThat said, in terms of masking, batch norm is just like dense or conv or activation layers, they all fall into 3).\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30021\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30021\">No</a>\n", "In the case of Convolutional layers, that's not true.\r\n\r\n```\r\nfrom tensorflow import keras\r\n\r\nif __name__ == '__main__':\r\n    input = keras.layers.Input(shape=(None, None, 1))\r\n    masked_input = keras.layers.Masking(-1)(input)\r\n    conv = keras.layers.Conv2D(1,3)(masked_input)\r\n    normalized = keras.layers.BatchNormalization(epsilon=1.1e-5)(conv)\r\n```\r\n*TypeError: Layer conv2d does not support masking, but was passed an input_mask: Tensor(\"masking/Any_1:0\", shape=(?, ?, ?), dtype=bool)*\r\n\r\nI'd argue that BatchNorm (and probably Dense layers too if they have bias nodes) also don't support masking because they don't work as expected with it. Conv2d could pass the mask through too, but instead the user is notified that it won't work which is much better behavior in my opinion. At least in my case, I knew I needed to work the mask around my conv layers. I did not know the same thing for BatchNormalization.\r\n\r\nIs the logic that:\r\n1. If a layer has self.support_masking = True, then it passes it through.\r\n2. If a layer also has a `mask` argument in call, then it consumes the mask.\r\n3. If a layer has neither, it will throw an error because it cannot pass the mask and cannot consume it.\r\n\r\nTo be fair I should have looked further than `self.support_masking=True`, but to me it seems that there is either an issue with consistency or with documentation. This is the first time I've seen those 3 categories of Masking you've listed above. Apart from looking at the source, there is no way to know if a mask is passed through or if it is consumed.\r\n\r\nAs a side note, if you stack an RNN layer on a Masking layer, do you still need to pass the mask value in with `call` to the RNN in the Functional API? I assumed that the Masking layer handled that."]}, {"number": 30020, "title": "tf.cond leads to memory leak?", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): conda\r\n- TensorFlow version (use command below): Tf=1.13.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: TITAN RTX 24G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n```python\r\n2019-06-25 10:59:25.073825: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_34339\r\n2019-06-25 10:59:25.073932: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_34340\r\n2019-06-25 10:59:25.073977: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_34395\r\n2019-06-25 10:59:25.074019: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_34396\r\n2019-06-25 10:59:25.074057: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_34482\r\n2019-06-25 10:59:25.074136: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_34483\r\n2019-06-25 10:59:25.074170: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_34568\r\n2019-06-25 10:59:25.074219: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_34569\r\n2019-06-25 10:59:25.074256: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_34568_rewritten\r\n2019-06-25 10:59:25.074353: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_34569_rewritten\r\n2019-06-25 10:59:25.074425: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_34568_grad_34687\r\n2019-06-25 10:59:25.074600: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_34569_grad_34755\r\n2019-06-25 10:59:25.074654: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_34482_rewritten\r\n2019-06-25 10:59:25.074817: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_34483_rewritten\r\n2019-06-25 10:59:25.074884: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_34482_grad_34822\r\n2019-06-25 10:59:25.075129: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_34483_grad_34926\r\n2019-06-25 10:59:25.075177: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_34395_grad_34994\r\n2019-06-25 10:59:25.075268: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_34396_grad_35015\r\n2019-06-25 10:59:25.075303: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_34339_grad_35033\r\n2019-06-25 10:59:25.075362: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_34340_grad_35044\r\n```\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@tsing-cv In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "## 1. model call function\r\n```python\r\n    def call(self, inputs, training=True):\r\n        if self.mode == \"training\":\r\n            input_image, input_image_meta, input_gt_class_ids, input_gt_boxes, input_gt_rboxes, input_gt_global_mask, input_gt_masks, input_gt_masks_score,input_rpn_match, input_rpn_bbox = inputs\r\n        else:\r\n            # Anchors in normalized coordinates\r\n            input_image, input_image_meta = inputs\r\n        gt_boxes = norm_boxes_graph(input_gt_boxes, tf.shape(input_image)[1:3])\r\n        gt_rboxes = norm_rboxes_graph(input_gt_rboxes, tf.shape(input_image)[1:3])\r\n        if self.config.BACKBONE == \"resnet101\":\r\n            C2, C3, C4, C5 = self.backbone(input_image)\r\n        P2, P3, P4, P5, P6 = self.fpn([C2, C3, C4, C5])\r\n        # Note that P6 is used in RPN, but not in the classifier heads.\r\n        rpn_feature_maps = [P2, P3, P4, P5, P6]\r\n        mrcnn_feature_maps = [P2, P3, P4, P5]\r\n        rpn_class_logits, rpn_class, rpn_bbox = self.rpn(rpn_feature_maps)\r\n        anchors = build_anchors(self.config, image_shape=self.config.IMAGE_SHAPE, norm=True, to_tensor=True)\r\n        rpn_rois = self.proposal([rpn_class, rpn_bbox, anchors])\r\n        if self.mode == \"training\":\r\n            active_class_ids = parse_image_meta_graph(input_image_meta, self.config)[\"active_class_ids\"]\r\n            target_rois = rpn_rois if self.config.USE_RPN_ROIS else norm_boxes_graph(input_rois, input_image.shape.as_list()[1:3])\r\n            output_rois, target_class_ids, target_bbox, \\\r\n                target_embed_length, target_rbox = self.detect_target([target_rois, input_gt_class_ids, gt_boxes, \r\n                    input_gt_masks, input_gt_rboxes])\r\n            # Network Heads\r\n            # TODO: verify that this handles zero padded ROIs\r\n            mrcnn_box_outputs = self.classifier([output_rois, input_image_meta, mrcnn_feature_maps], True)\r\n            mrcnn_mask = self.masker([output_rois, input_image_meta, mrcnn_feature_maps], True)\r\n            \r\n            return rpn_class_logits, rpn_bbox, mrcnn_box_outputs, mrcnn_mask, target_class_ids, target_bbox, target_mask, active_class_ids\r\n\r\n        else:\r\n            mrcnn_box_outputs = self.classifier([rpn_rois, input_image_meta, mrcnn_feature_maps])\r\n            # Detections\r\n            # output is [batch, num_detections, (y1, x1, y2, x2, class_id, score)] in\r\n            # normalized coordinates\r\n            detections = self.detect(\r\n                [rpn_rois, mrcnn_box_outputs[\"mrcnn_class_logits\"], \r\n                mrcnn_box_outputs[\"mrcnn_bbox\"], input_image_meta])\r\n            mrcnn_mask = self.masker([detections[..., :4], input_image_meta, mrcnn_feature_maps])\r\n            return detections, mrcnn_mask\r\n```\r\n## 2. training loop\r\n```python\r\n        train_dataset = DataLoader(self.train_dataset, self.config, self.augmentation)\r\n        train_generator = DataGenerator(train_dataset)\r\n        train_generator = tf.data.Dataset.from_generator(train_generator, \r\n                                                        (tf.float32, tf.float32, \r\n                                                        tf.int32, \r\n                                                        tf.float32, tf.float32, \r\n                                                        tf.bool, tf.bool, tf.float32, \r\n                                                        tf.int32, tf.float32))\r\n        train_generator = train_generator.padded_batch(self.config.BATCH_SIZE, \r\n                                                    padded_shapes=([self.config.IMAGE_SHAPE[0], self.config.IMAGE_SHAPE[1], self.config.IMAGE_SHAPE[2]], [None], \r\n                                                                    [None], \r\n                                                                    [None, 4], [None, 5], \r\n                                                                    [None, None], [None, None, None], [None],\r\n                                                                    [None, 1], [None, 4]))\r\n        train_generator = train_generator.prefetch(20)\r\n        mrcnn = MRCNN(config=self.config, mode='training')\r\n        tf.debugging.get_log_device_placement()\r\n\r\n        optimizer = tf.train.MomentumOptimizer(1e-3, 0.9, use_nesterov=True)\r\n        checkpoint_path = self.config.MODEL_DIR\r\n        ckpt = tf.train.Checkpoint(mrcnn=mrcnn, optimizer=optimizer)\r\n        losses = Loss_tower(self.config)\r\n\r\n        ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\r\n        start_epoch = 0\r\n        if ckpt_manager.latest_checkpoint:\r\n            ckpt.restore(ckpt_manager.latest_checkpoint)\r\n            start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\r\n            print ('Latest checkpoint restored!!')\r\n        @tf.function\r\n        def train_step(inputs):\r\n            with tf.GradientTape() as tape:\r\n                rpn_class_logits, rpn_bbox, mrcnn_box_outputs, mrcnn_mask, target_class_ids, target_bbox, target_mask, active_class_ids = mrcnn(inputs)\r\n                rpn_class_loss = losses.rpn_cla_loss(inputs[-2], rpn_class_logits)\r\n                rpn_bbox_loss = losses.rpn_bbox_loss(inputs[-1], inputs[-2], rpn_bbox)\r\n                mrcnn_class_loss = losses.mrcnn_cla_loss(target_class_ids, mrcnn_box_outputs[\"mrcnn_class_logits\"], active_class_ids)\r\n                mrcnn_bbox_loss = losses.mrcnn_bbox_loss(target_bbox, target_class_ids, mrcnn_box_outputs[\"mrcnn_bbox\"])\r\n                mrcnn_mask_loss = losses.mrcnn_mask_loss(target_mask, target_class_ids, mrcnn_mask)\r\n\r\n                total_loss = rpn_bbox_loss+rpn_class_loss+mrcnn_class_loss+mrcnn_bbox_loss+mrcnn_mask_loss\r\n                tf.get_default_graph().get_collection(tf.GraphKeys.LOSSES)\r\n            grads = tape.gradient(total_loss, ood_str.trainable_variables)   \r\n            optimizer.apply_gradients(zip(grads, ood_str.trainable_variables))\r\n            print(\"================\",len(tf.get_default_graph().get_collection(tf.GraphKeys.LOSSES)))\r\n            return total_loss,rpn_class_loss,rpn_bbox_loss,mrcnn_class_loss,mrcnn_bbox_loss,mrcnn_mask_loss\r\n\r\n        def eval_step(inputs):\r\n            with tf.GradientTape() as tape:\r\n                detections, mask = mrcnn(inputs)\r\n            \r\n        \r\n        for epoch in range(start_epoch, 400):\r\n            for (batch, inputs) in enumerate(train_generator):\r\n                # print (inputs)\r\n                print (f\"batch num: {batch}\")\r\n                total_loss,rpn_class_loss,rpn_bbox_loss,mrcnn_class_loss,mrcnn_bbox_loss,mrcnn_mask_loss = train_step(inputs)\r\n                print (f\"collection: {gc.collect()}\")\r\n                print (f\"Total Loss: {total_loss.numpy():.6f}\")\r\n                print (f\"RPN Loss:   class_loss={rpn_class_loss.numpy():.6f} \\tbbox_loss={rpn_bbox_loss.numpy():.6f}\")\r\n                print (f\"MRCNN Loss: class_loss={mrcnn_class_loss.numpy():.6f} \\tbbox_loss={mrcnn_bbox_loss.numpy():.6f}\\tmask_loss={mrcnn_mask_loss.numpy():.6f}\")\r\n                tf.keras.backend.clear_session()\r\n            # ckpt_manager.save()\r\n```\r\n## 3. Loss_tower class\r\n```python\r\nclass Loss_tower():\r\n    def __init__(self, config):\r\n        self.config = config\r\n\r\n    def rpn_cla_loss(self, rpn_match, rpn_class_logits):\r\n        \"\"\"RPN anchor classifier loss.\r\n        Params:\r\n        -----------------------------------------------------------\r\n            rpn_match:        [batch, anchors, 1]. Anchor match type. 1=positive,\r\n                            -1=negative, 0=neutral anchor.\r\n            rpn_class_logits: [batch, anchors, 2]. RPN classifier logits for BG/FG.\r\n        \"\"\"\r\n        # Squeeze last dim to simplify\r\n        rpn_match = tf.squeeze(rpn_match, -1)\r\n        # Get anchor classes. Convert the -1/+1 match to 0/1 values.\r\n        anchor_class = tf.cast(tf.equal(rpn_match, 1), tf.int32)\r\n        # Positive and Negative anchors contribute to the loss,\r\n        # but neutral anchors (match value = 0) don't.\r\n        indices = tf.where(tf.not_equal(rpn_match, 0))\r\n        # Pick rows that contribute to the loss and filter out the rest.\r\n        rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)\r\n        anchor_class = tf.gather_nd(anchor_class, indices)\r\n        if self.config.RPN_CLASS_LOSS_TYPE == 'cross_entropy':\r\n            # Cross entropy loss -------------------------------------------\r\n            loss = tf.losses.sparse_softmax_cross_entropy(labels=anchor_class,\r\n                                                          logits=rpn_class_logits)\r\n            # --------------------------------------------------------------\r\n        elif self.config.RPN_CLASS_LOSS_TYPE == 'focal_loss':\r\n            # Focal loss ---------------------------------------------------\r\n            loss = focal_loss(prediction_tensor=rpn_class_logits, \r\n                            target_tensor=tf.cast(tf.one_hot(anchor_class, 2), tf.float32))\r\n            # --------------------------------------------------------------\r\n        loss = tf.reduce_mean(loss) if tf.size(loss) > 0 else tf.constant(0.0)\r\n        # loss = tf.cond(tf.size(loss) > 0, lambda:tf.reduce_mean(loss), lambda:tf.constant(0.0))\r\n        \r\n        return loss\r\n    \r\n    @staticmethod\r\n    def batch_pack_graph(x, counts, num_rows):\r\n        \"\"\"Picks different number of values from each row\r\n        in x depending on the values in counts.\r\n        \"\"\"\r\n        outputs = []\r\n        for i in range(num_rows):\r\n            outputs.append(x[i, :counts[i]])\r\n        return tf.concat(outputs, axis=0)\r\n\r\n    def rpn_bbox_loss(self, target_bbox, rpn_match, rpn_bbox):\r\n        \"\"\"Return the RPN bounding box loss graph.\r\n        Params:\r\n        -----------------------------------------------------------\r\n            config:      the model config object.\r\n            target_bbox: [batch, max positive anchors, (dy, dx, log(dh), log(dw))].\r\n                        Uses 0 padding to fill in unsed bbox deltas.\r\n            rpn_match:   [batch, anchors, 1]. Anchor match type. 1=positive,\r\n                        -1=negative, 0=neutral anchor.\r\n            rpn_bbox:    [batch, anchors, (dy, dx, log(dh), log(dw))]\r\n        \"\"\"\r\n        # Positive anchors contribute to the loss, but negative and\r\n        # neutral anchors (match value of 0 or -1) don't.\r\n        rpn_match = tf.squeeze(rpn_match, -1)\r\n        indices = tf.where(tf.equal(rpn_match, 1))\r\n\r\n        # Pick bbox deltas that contribute to the loss\r\n        rpn_bbox = tf.gather_nd(rpn_bbox, indices)\r\n\r\n        # Trim target bounding box deltas to the same length as rpn_bbox.\r\n        batch_counts = tf.reduce_sum(tf.cast(tf.equal(rpn_match, 1), tf.int32), axis=1)\r\n        target_bbox = self.batch_pack_graph(target_bbox, batch_counts, self.config.IMAGES_PER_GPU)\r\n        loss = smooth_l1_loss(y_true=target_bbox, y_pred=rpn_bbox, config=self.config)\r\n        loss = tf.reduce_mean(loss) if tf.size(loss) > 0 else tf.constant(0.0)\r\n        # loss = tf.cond(tf.size(loss) > 0, lambda:tf.reduce_mean(loss), lambda:tf.constant(0.0))\r\n        return loss\r\n\r\n    def mrcnn_cla_loss(self, target_class_ids, pred_class_logits, active_class_ids):\r\n        \"\"\"Loss for the classifier head of Mask RCNN.\r\n        Params:\r\n        -----------------------------------------------------------\r\n            target_class_ids:  [batch, num_rois]. Integer class IDs. Uses zero\r\n                               padding to fill in the array.\r\n            pred_class_logits: [batch, num_rois, num_classes]\r\n            active_class_ids:  [batch, num_classes]. Has a value of 1 for\r\n                               classes that are in the dataset of the image, and 0\r\n                               for classes that are not in the dataset.\r\n        \"\"\"\r\n        # During model building, Keras calls this function with\r\n        # target_class_ids of type float32. Unclear why. Cast it\r\n        # to int to get around it.\r\n        target_class_ids = tf.cast(target_class_ids, 'int64')\r\n\r\n        # Find predictions of classes that are not in the dataset.\r\n        pred_class_ids = tf.argmax(pred_class_logits, axis=2)\r\n        # TODO: Update this line to work with batch > 1. Right now it assumes all\r\n        #       images in a batch have the same active_class_ids\r\n        pred_active = tf.gather(active_class_ids[0], pred_class_ids)\r\n\r\n        if self.config.RCNN_CLASS_LOSS_TYPE == 'cross_entropy':\r\n            # CE_Loss --------------------------------------------------\r\n            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n                labels=target_class_ids, logits=pred_class_logits)\r\n            # ----------------------------------------------------------\r\n        elif self.config.RCNN_CLASS_LOSS_TYPE == 'focal_loss':\r\n            # Focal_Loss -----------------------------------------------\r\n            loss = focal_loss(prediction_tensor=pred_class_logits, \r\n                            target_tensor=tf.cast(tf.one_hot(target_class_ids, \\\r\n                                tf.cast(active_class_ids[1][0], \"int32\")), \"float32\"))\r\n            loss = tf.reduce_sum(loss, axis=-1)\r\n            # ----------------------------------------------------------\r\n\r\n        # Erase losses of predictions of classes that are not in the active\r\n        # classes of the image.\r\n        loss = loss * pred_active\r\n\r\n        # Computer loss mean. Use only predictions that contribute\r\n        # to the loss to get a correct mean.\r\n        loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\r\n        return loss\r\n\r\n\r\n    def mrcnn_bbox_loss(self, target_bbox, target_class_ids, pred_bbox):\r\n        \"\"\"Loss for Mask R-CNN bounding box refinement.\r\n        Params:\r\n        -----------------------------------------------------------\r\n            target_bbox:      [batch, num_rois, (dy, dx, log(dh), log(dw))]\r\n            target_class_ids: [batch, num_rois]. Integer class IDs.\r\n            pred_bbox:        [batch, num_rois, num_classes, (dy, dx, log(dh), log(dw))]\r\n        \"\"\"\r\n        # Reshape to merge batch and roi dimensions for simplicity.\r\n        target_class_ids = tf.reshape(target_class_ids, (-1,))\r\n        target_bbox = tf.reshape(target_bbox, (-1, 4))\r\n        pred_bbox = tf.reshape(pred_bbox, (-1, pred_bbox.shape.as_list()[2], 4))\r\n\r\n        # Only positive ROIs contribute to the loss. And only\r\n        # the right class_id of each ROI. Get their indices.\r\n        positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]\r\n        positive_roi_class_ids = tf.cast(tf.gather(target_class_ids, positive_roi_ix), tf.int64)\r\n        indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\r\n\r\n        # Gather the deltas (predicted and true) that contribute to loss\r\n        target_bbox = tf.gather(target_bbox, positive_roi_ix)\r\n        pred_bbox = tf.gather_nd(pred_bbox, indices)\r\n\r\n        # Smooth-L1 Loss\r\n        if tf.size(target_bbox) > 0:\r\n            loss = smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox, config=self.config)  \r\n        else:\r\n            loss = tf.constant(0.0)\r\n        # loss = tf.cond(tf.size(target_bbox) > 0, \r\n        #                lambda:smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox, config=self.config), \r\n        #                lambda:tf.constant(0.0))\r\n        loss = tf.reduce_mean(loss)\r\n        \r\n        return loss\r\n\r\n    def mrcnn_mask_loss(self, target_masks, target_class_ids, pred_masks):\r\n        \"\"\"Mask binary cross-entropy loss for the masks head.\r\n        Params:\r\n        -----------------------------------------------------------\r\n            target_masks:     [batch, num_rois, height, width].\r\n                            A float32 tensor of values 0 or 1. Uses zero padding to fill array.\r\n            target_class_ids: [batch, num_rois]. Integer class IDs. Zero padded.\r\n            pred_masks:       [batch, proposals, height, width, num_classes] float32 tensor\r\n                            with values from 0 to 1.\r\n        \"\"\"\r\n        # Reshape for simplicity. Merge first two dimensions into one.\r\n        target_class_ids = tf.reshape(target_class_ids, (-1,))\r\n        mask_shape = tf.shape(target_masks)\r\n        target_masks = tf.reshape(target_masks, (-1, mask_shape[2], mask_shape[3]))\r\n        pred_shape = tf.shape(pred_masks)\r\n        pred_masks = tf.reshape(pred_masks, (-1, pred_shape[2], pred_shape[3], pred_shape[4]))\r\n\r\n        if self.config.MASK_LOSS_TYPE == \"binary_ce\":\r\n            # NOTE for Compute binary cross entropy ---------------------\r\n            # Permute predicted masks to [N, num_classes, height, width]\r\n            pred_masks = tf.transpose(pred_masks, [0, 3, 1, 2])\r\n\r\n            # Only positive ROIs contribute to the loss. And only\r\n            # the class specific mask of each ROI.\r\n            positive_ix = tf.where(target_class_ids > 0)[:, 0]\r\n            positive_class_ids = tf.cast(tf.gather(target_class_ids, positive_ix), tf.int64)\r\n            indices = tf.stack([positive_ix, positive_class_ids], axis=1)\r\n\r\n            # Gather the masks (predicted and true) that contribute to loss\r\n            y_true = tf.gather(target_masks, positive_ix)\r\n            # Compute binary cross entropy. \r\n            # If no positive ROIs, then return 0.\r\n            y_pred = tf.gather_nd(pred_masks, indices)\r\n            if tf.size(y_true) > 0:\r\n                loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\r\n            else:\r\n                loss = tf.constant(0.0)\r\n            # loss = tf.cond(tf.size(y_true) > 0, \r\n            #             lambda:tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred), \r\n            #             lambda:tf.constant(0.0))\r\n            # ----------------------------------------------------------\r\n        elif self.config.MASK_LOSS_TYPE == \"focal_loss\":\r\n            # Focal Loss -----------------------------------------------\r\n            # Only positive ROIs contribute to the loss. And only\r\n            # the class specific mask of each ROI.\r\n            positive_ix = tf.where(target_class_ids > 0)[:, 0]\r\n            # Gather the masks (predicted and true) that contribute to loss\r\n            y_true = tf.gather(target_masks, positive_ix)\r\n            y_pred = tf.gather(pred_masks, positive_ix)\r\n            if tf.size(y_true) > 0:\r\n                loss = focal_loss(y_pred, tf.cast(tf.one_hot(tf.cast(y_true, dtype=tf.int32), self.config.NUM_CLASSES), \r\n                                    dtype=tf.float32))\r\n            else:\r\n                loss = tf.constant(0.0)\r\n            # loss = tf.cond(tf.size(y_true) > 0, \r\n            #             lambda:focal_loss(y_pred, tf.cast(tf.one_hot(tf.cast(y_true, dtype=tf.int32), self.config.NUM_CLASSES), \r\n            #                         dtype=tf.float32)), \r\n            #             lambda:tf.constant(0.0))\r\n        \r\n        loss = tf.reduce_mean(loss)\r\n\r\n        return loss\r\n```\r\n## 4. output\r\n```python\r\ncollection: 0\r\nTotal Loss: 9.114525\r\nRPN Loss:   class_loss=3.048911 \tbbox_loss=3.986173\r\nMRCNN Loss: class_loss=2.079441 \tbbox_loss=0.000000\tmask_loss=0.000000\r\nbatch num: 1\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n================ 1\r\n2019-06-25 11:26:40.941132: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_45786\r\n2019-06-25 11:26:40.941250: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_45787\r\n2019-06-25 11:26:40.941301: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_45842\r\n2019-06-25 11:26:40.941345: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_45843\r\n2019-06-25 11:26:40.941380: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_45929\r\n2019-06-25 11:26:40.941458: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_45930\r\n2019-06-25 11:26:40.941495: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_46015\r\n2019-06-25 11:26:40.941546: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_46016\r\n2019-06-25 11:26:40.941585: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_46015_rewritten\r\n2019-06-25 11:26:40.941677: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_46016_rewritten\r\n2019-06-25 11:26:40.941734: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_46015_grad_46134\r\n2019-06-25 11:26:40.941897: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_46016_grad_46202\r\n2019-06-25 11:26:40.941949: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_45929_rewritten\r\n2019-06-25 11:26:40.942101: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_45930_rewritten\r\n2019-06-25 11:26:40.942168: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_45929_grad_46269\r\n2019-06-25 11:26:40.942450: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_45930_grad_46373\r\n2019-06-25 11:26:40.942500: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_45842_grad_46441\r\n2019-06-25 11:26:40.942612: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_45843_grad_46462\r\n2019-06-25 11:26:40.942648: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_45786_grad_46480\r\n2019-06-25 11:26:40.942710: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_45787_grad_46491\r\ncollection: 0\r\nTotal Loss: 9.401854\r\nRPN Loss:   class_loss=0.469327 \tbbox_loss=3.619739\r\nMRCNN Loss: class_loss=2.206486 \tbbox_loss=2.402370\tmask_loss=0.703931\r\nbatch num: 2\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n================ 1\r\n2019-06-25 11:26:57.657805: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_57233\r\n2019-06-25 11:26:57.657913: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_57234\r\n2019-06-25 11:26:57.657976: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_57289\r\n2019-06-25 11:26:57.658019: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_57290\r\n2019-06-25 11:26:57.658054: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_57376\r\n2019-06-25 11:26:57.658138: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_57377\r\n2019-06-25 11:26:57.658174: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_57462\r\n2019-06-25 11:26:57.658223: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_57463\r\n2019-06-25 11:26:57.658256: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_57462_rewritten\r\n2019-06-25 11:26:57.658374: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_57463_rewritten\r\n2019-06-25 11:26:57.658432: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_57462_grad_57581\r\n2019-06-25 11:26:57.658612: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_57463_grad_57649\r\n2019-06-25 11:26:57.658664: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_57376_rewritten\r\n2019-06-25 11:26:57.658829: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_57377_rewritten\r\n2019-06-25 11:26:57.658902: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_57376_grad_57716\r\n2019-06-25 11:26:57.659146: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_57377_grad_57820\r\n2019-06-25 11:26:57.659192: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_57289_grad_57888\r\n2019-06-25 11:26:57.659292: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_57290_grad_57909\r\n2019-06-25 11:26:57.659326: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_57233_grad_57927\r\n2019-06-25 11:26:57.659388: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_57234_grad_57938\r\ncollection: 0\r\nTotal Loss: 4.695867\r\nRPN Loss:   class_loss=0.405443 \tbbox_loss=2.216862\r\nMRCNN Loss: class_loss=2.073562 \tbbox_loss=0.000000\tmask_loss=0.000000\r\nbatch num: 3\r\ncollection: 111\r\nTotal Loss: 5.385295\r\nRPN Loss:   class_loss=0.153593 \tbbox_loss=3.163285\r\nMRCNN Loss: class_loss=2.068417 \tbbox_loss=0.000000\tmask_loss=0.000000\r\nbatch num: 4\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n================ 1\r\n2019-06-25 11:27:15.130479: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_68709\r\n2019-06-25 11:27:15.130596: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_68710\r\n2019-06-25 11:27:15.130638: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_68765\r\n2019-06-25 11:27:15.130688: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_68766\r\n2019-06-25 11:27:15.130718: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_68852\r\n2019-06-25 11:27:15.130784: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_68853\r\n2019-06-25 11:27:15.130812: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_68938\r\n2019-06-25 11:27:15.130850: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_68939\r\n2019-06-25 11:27:15.130877: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_68938_rewritten\r\n2019-06-25 11:27:15.130956: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_68939_rewritten\r\n2019-06-25 11:27:15.131002: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_68938_grad_69057\r\n2019-06-25 11:27:15.131131: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_68939_grad_69125\r\n2019-06-25 11:27:15.131169: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_68852_rewritten\r\n2019-06-25 11:27:15.131263: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_68853_rewritten\r\n2019-06-25 11:27:15.131316: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_68852_grad_69192\r\n2019-06-25 11:27:15.131490: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_68853_grad_69296\r\n2019-06-25 11:27:15.131531: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_68765_grad_69364\r\n2019-06-25 11:27:15.131596: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_68766_grad_69385\r\n2019-06-25 11:27:15.131625: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_68709_grad_69403\r\n2019-06-25 11:27:15.131667: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_68710_grad_69414\r\ncollection: 124\r\nTotal Loss: 15.362164\r\nRPN Loss:   class_loss=0.089456 \tbbox_loss=4.208913\r\nMRCNN Loss: class_loss=2.297886 \tbbox_loss=8.127378\tmask_loss=0.638531\r\nbatch num: 5\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n================ 1\r\n2019-06-25 11:27:31.283104: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_80156\r\n2019-06-25 11:27:31.283216: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_80157\r\n2019-06-25 11:27:31.283254: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_80212\r\n2019-06-25 11:27:31.283290: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_80213\r\n2019-06-25 11:27:31.283319: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_80299\r\n2019-06-25 11:27:31.283385: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_80300\r\n2019-06-25 11:27:31.283414: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_80385\r\n2019-06-25 11:27:31.283452: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_80386\r\n2019-06-25 11:27:31.283495: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_80385_rewritten\r\n2019-06-25 11:27:31.283559: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_80386_rewritten\r\n2019-06-25 11:27:31.283601: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_80385_grad_80504\r\n2019-06-25 11:27:31.283726: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_80386_grad_80572\r\n2019-06-25 11:27:31.283765: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_80299_rewritten\r\n2019-06-25 11:27:31.283854: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_80300_rewritten\r\n2019-06-25 11:27:31.283903: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_80299_grad_80639\r\n2019-06-25 11:27:31.284066: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_80300_grad_80743\r\n2019-06-25 11:27:31.284104: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_80212_grad_80811\r\n2019-06-25 11:27:31.284167: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_80213_grad_80832\r\n2019-06-25 11:27:31.284194: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_80156_grad_80850\r\n2019-06-25 11:27:31.284235: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_80157_grad_80861\r\ncollection: 91\r\nTotal Loss: 9.459186\r\nRPN Loss:   class_loss=0.326941 \tbbox_loss=3.104641\r\nMRCNN Loss: class_loss=2.290176 \tbbox_loss=3.031886\tmask_loss=0.705541\r\nbatch num: 6\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n/home/ubuntu/anaconda3/envs/tf13/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n================ 1\r\n2019-06-25 11:27:48.236550: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_91603\r\n2019-06-25 11:27:48.236652: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_91604\r\n2019-06-25 11:27:48.236691: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_91659\r\n2019-06-25 11:27:48.236725: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_91660\r\n2019-06-25 11:27:48.236753: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_91746\r\n2019-06-25 11:27:48.236822: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_91747\r\n2019-06-25 11:27:48.236853: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_91832\r\n2019-06-25 11:27:48.236906: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_91833\r\n2019-06-25 11:27:48.236936: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_91832_rewritten\r\n2019-06-25 11:27:48.236999: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_91833_rewritten\r\n2019-06-25 11:27:48.237047: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_true_91832_grad_91951\r\n2019-06-25 11:27:48.237174: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_3_false_91833_grad_92019\r\n2019-06-25 11:27:48.237212: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_91746_rewritten\r\n2019-06-25 11:27:48.237304: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_91747_rewritten\r\n2019-06-25 11:27:48.237352: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_true_91746_grad_92086\r\n2019-06-25 11:27:48.237516: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_2_false_91747_grad_92190\r\n2019-06-25 11:27:48.237556: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_true_91659_grad_92258\r\n2019-06-25 11:27:48.237619: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_1_false_91660_grad_92279\r\n2019-06-25 11:27:48.237645: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_true_91603_grad_92297\r\n2019-06-25 11:27:48.237688: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: cond_false_91604_grad_92308\r\n```\r\nchanged maskrcnn from keras to tf.keras, using subclass. https://github.com/tsing-cv/tf.keras_Mask_rcnn", "leak has nothing to do with tf.cond, because i replace all tf.cond. But gpu using increasing, unless add @tf.function", "@tsing-cv Will it possible to provide the minimal code snippet to reproduce the reported issue here. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30019, "title": "Fix: API`init_from_checkpoint` Restore Op placement", "body": "", "comments": ["@ebrevdo ", "@candyzone Could you please check failed build errors? Thanks!"]}, {"number": 30018, "title": "Fix: slot and primary can be different shape", "body": "See issue #19457", "comments": ["@protoget ", "Can one of the admins verify this patch?", "@tensorflowbutler CI build failed, it seems other reason. How to retrigger CI build?", "@candyzone Could you please address Ubuntu Sanity errors? Thanks!", "@candyzone Gentle ping to address Ubuntu Sanity errors? Thanks!", "@allenlavoie "]}, {"number": 30017, "title": "Tensorflow restore model and retrain - valueerror : Duplicate node name in graph", "body": "I am trying to restore the trained model and retrain it with some additional operations.\r\n\r\nI have 2 python files, lets say\r\n\r\ntrain.py - To train and save the model\r\nretrain.py - Load the trained model, add new elements in graph and retrain\r\n\r\n**train.py**\r\n\r\n```\r\ndef train():\r\n    # 1 NN\r\n    Xinp1 = tf.placeholder(\"float\", [None, 2], name=\"Xinp1\")\r\n    Xhidden1 = tf.layers.dense(Xinp1, units=16 , \r\n                kernel_initializer=tf.initializers.he_uniform(), \r\n                activation=tf.nn.relu, name=\"X_hidden1\")\r\n    Xout = tf.layers.dense(X_hidden5, units=1, \r\n kernel_initializer=tf.initializers.he_uniform(),activation=tf.nn.sigmoid, name=\"X_out\")\r\n\r\n    Xout1 = tf.identity(Xout, name=\"Xout1\")\r\n\r\n    #2 NN\r\n    Xinp2 = tf.placeholder(\"float\", [None, 2], name=\"Xinp2\")\r\n    Xhidden2 = tf.layers.dense(Xinp2, units=16 , \r\n                kernel_initializer=tf.initializers.he_uniform(), \r\n                activation=tf.nn.relu, name=\"X_hidden2\")\r\n    Xout = tf.layers.dense(X_hidden2, units=1, \r\nkernel_initializer=tf.initializers.he_uniform(),activation=tf.nn.sigmoid, name=\"X_out\")\r\n\r\n    Xout2 = tf.identity(Xout, name=\"Xout2\")\r\n\r\n    Xout1_label = tf.placeholder(\"float\", [None,1], name=\"Xout1_label\")\r\n    Xout2_label = tf.placeholder(\"float\", [None,1],name=\"Xout2_label\")\r\n\r\n\r\n    learning_rate = 1e-2\r\n    # Define loss and optimizer\r\n    loss_op1 = tf.losses.absolute_difference(Xout1_label, Xout1)\r\n    loss_op2 = tf.losses.absolute_difference(Xout2_label, Xout2)\r\n\r\n\r\n\r\n    # debug gradients\r\n    trainables = tf.trainable_variables()\r\n    print (\"trainables\", trainables)\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)\r\n\r\n    train_op1 = optimizer.minimize(loss_op1)\r\n    train_op2 = optimizer.minimize(loss_op2)\r\n\r\n    with tf.Session() as sess:\r\n          sess.run(tf.global_variables_initializer())\r\n          saver = tf.train.Saver()\r\n          for _ in range(100):\r\n               _, c1, summary = sess.run([train_op1, loss_op1, merged_summary_op], feed_dict={\r\n            Xinp1: X1,\r\n            Xinp2: X2,\r\n            Xout1_label: X1label,\r\n            Xout2_label: X2label\r\n            })    \r\n               _, c2, summary = sess.run([train_op2, loss_op2, merged_summary_op], feed_dict={\r\n            Xinp1: X1,\r\n            Xinp2: X2,\r\n            Xout1_label: X1label,\r\n            Xout2_label: X2label\r\n            })        \r\n          saver.save(sess, 'Model/trained.ckpt')\r\n          sess.close()\r\n```\r\n\r\nAs an output, I got following files\r\n\r\n1. checkpoint\r\n2. trained.ckpt.data-00000-of-00001\r\n3. trained.ckpt.index\r\n4. trained.ckpt.meta\r\n\r\n**retrain.py**\r\n\r\n```\r\ndef retrain():\r\n     with tf.Session() as sess:\r\n           saver = tf.train.import_meta_graph('Model/trained.ckpt.meta')\r\n           saver.restore(sess, 'Model/trained.ckpt')\r\n           graph = tf.get_default_graph()\r\n           Xinp1 = graph.get_tensor_by_name('Xinp1:0')\r\n           Xout1 = graph.get_tensor_by_name('Xout1:0')\r\n           Xinp2 = graph.get_tensor_by_name('Xinp2:0')\r\n           Xout2 = graph.get_tensor_by_name('Xout2:0') \r\n\r\n           # I want to add some additional nodes\r\n           T1 = tf.placeholder(\"float\", [None, 1], name=\"T1\")\r\n           T2 = tf.placeholder(\"float\", [None, 1], name=\"T2\")\r\n           Add1 = tf.add(tf.multiply(Xout1, tf.subtract(T1, T2)), T2, name=\"Add1_out\")\r\n\r\n           T3 = tf.placeholder(\"float\", [None, 1], name=\"T3\")\r\n           Add2 = tf.multiply(tf.multiply(T3,tf.subtract(Add1, 300)),tf.multiply(radial_length,0.000001), name=\"Add2_out\")\r\n\r\n           Addlabel = tf.placeholder(\"float\", [None, 1], name=\"Addlabel\")\r\n\r\n           loss_op = tf.losses.mean_squared_error(Addlabel, Add2)\r\n\r\n           # debug gradients\r\n           trainables = tf.trainable_variables()\r\n           print (\"trainables\", trainables)\r\n           optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)\r\n           train_op = optimizer.minimize(loss_op)\r\n\r\n           sess.run(tf.global_variables_initializer())\r\n           #training starts\r\n           # Here I except weights of 1 NN and 2 NN are learned during the training\r\n           for _ in range(100):\r\n               _, c, summary = sess.run([train_op, loss_op, merged_summary_op], feed_dict={\r\n               Xinp1 : NewX1,\r\n               Xinp2 : NewX2,\r\n               T1 : T1inp,\r\n               T2 : T2inp,\r\n               T3 : T3inp,\r\n               Addlabel : Addtarget               \r\n                }) \r\n```\r\n\r\nI am expecting the retrain.py to adjust the weights associated with 1 NN and 2 NN during the training.\r\n\r\nBut instead while running the retrain.py, I am getting the following error\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1659, in _create_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Duplicate node name in graph: 'X_hidden1/kernel/Adam'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/itmsec/Documents/tipclearance/src/TTG_tensorflowv14.py\", line 493, in <module>\r\n    restore_and_retrain(BDD)\r\n  File \"/home/itmsec/Documents/tipclearance/src/TTG_tensorflowv14.py\", line 244, in restore_and_retrain\r\n    train_op = optimizer.minimize(loss_op)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\r\n    name=name)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 595, in apply_gradients\r\n    self._create_slots(var_list)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 135, in _create_slots\r\n    self._zeros_slot(v, \"m\", self._name)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1153, in _zeros_slot\r\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\r\n    colocate_with_primary=colocate_with_primary)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\r\n    dtype)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\r\n    validate_shape=validate_shape)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\r\n    aggregation=aggregation)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\r\n    aggregation=aggregation)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\r\n    aggregation=aggregation)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\r\n    expected_shape=expected_shape, import_scope=import_scope)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\r\n    constraint=constraint)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1509, in _init_from_args\r\n    name=name)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 79, in variable_op_v2\r\n    shared_name=shared_name)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 1425, in variable_v2\r\n    shared_name=shared_name, name=name)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1823, in __init__\r\n    control_input_ops)\r\n  File \"/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1662, in _create_c_op\r\n    raise ValueError(str(e))\r\nValueError: Duplicate node name in graph: 'X_hidden1/kernel/Adam'\r\n```", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow CPU/GPU version. Also, did you compile from source or install a binary?\r\n\r\nRequest you to provide full code snippet for reproducing the issue.", "OS: Ubuntu 18\r\nTensorflow CPU version\r\nI installed Tensorflow via pip \r\n\r\nThe above provided code snippet is complete, I have just ignored only the pandas dataframe which is passed in the function.", "i tried to execute train.py with TF 1.13.1 i am getting below error.\r\nValueError: Variable X_hidden1/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\r\nPlease, help us to reproduce the issue for faster resolution.Thanks!", "Are you able to get resolution for this issue? Thanks!", "Nope", "> i tried to execute train.py with TF 1.13.1 i am getting below error.\r\n> ValueError: Variable X_hidden1/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\r\n> Please, help us to reproduce the issue for faster resolution.Thanks!\r\n\r\nCan you please comment on this.Thanks!", "I noticed an error here\r\n```\r\nXout1 = tf.identity(Xout, name=\"Xout1\")\r\n```\r\n\r\n\r\nI have updated the above code", "Are you able to get resolution for this issue by updating the code? . Thanks!\r\n", "Nope. I thought this might help you to reproduce the error ```ValueError: Duplicate node name in graph: 'X_hidden1/kernel/Adam' ```", "This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "Moving it to stack overflow", "The reason is that AdamOptimizer  creates additional variables and operation in your graph. When you store your model, those operations are stored and loaded with the graph when you restore the model. \r\nIf you run \r\n\r\n> tf.Graph.get_operations(graph)\r\n\r\nyou can see the list of operations that are loaded with you model. You will see operations that have */Adam or train/Adam* init. When you try to find-tune or reuse you model, the new AdamOptimizer tries to create those operations again, hence it raises the \"Duplicate node name\" error.\r\nOne way to fix the issue is to give a name to your new AdampOptimzer. \r\n\r\n> opt = tf.train.AdamOptimizer(2e-4m name='MyNewAdam').minimize(Loss)\r\n\r\nHowever, We are not done yet. \r\nAs you want to reuse the weight, you cannot initialize variable. However, if you will get error of uninitialized parameters when you run your training which is raised due to new AdamOptimizer variables which have not been initialized yet. To get around it, you need to initialize those new variables by :\r\n\r\n    uninitialized_vars = []\r\n    for var in tf.all_variables():\r\n        try:\r\n            sess.run(var)\r\n        except tf.errors.FailedPreconditionError:\r\n            uninitialized_vars.append(var)\r\n    \r\n    tf.initialize_variables(uninitialized_vars)\r\n\r\n\r\n\r\n\r\nNote: Unused nodes will not be executed and hence they won't affect training time.", "> OS: Ubuntu 18\r\n> Tensorflow CPU version\r\n> I installed Tensorflow via pip\r\n> \r\n> The above provided code snippet is complete, I have just ignored only the pandas dataframe which is passed in the function.\r\n\r\nThanks", "> tf.initialize_variables(uninitialized_vars)\r\n\r\nHi I met the similar problem, however, I have initialized the new variables created by newAdam, but still get error of using uninitialized variables. Why is this?", "> > tf.initialize_variables(uninitialized_vars)\r\n> \r\n> Hi I met the similar problem, however, I have initialized the new variables created by newAdam, but still get error of using uninitialized variables. Why is this?\r\n\r\nare you using the same session ? Maybe you create new session after initialisation of parameters? \r\nDo you face the same issue when you use other optimisers such as vanilla SGD? ", "Thanks for your reply. Actually I have figured out this problem, I use tf 1.8 and tf.initialize_variables has been discarded. I use `sess.run(tf.variables_initializer(uninitialized_vars))` and it works well. I have not yet tried any other optimizers, but I believe your solution will work for them too.."]}, {"number": 30015, "title": "building error on win7 with VS2015: ADD_LIBRARY for library tf_contrib_tpu_ops without any source files ", "body": "System information\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win7 X64\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version:1.13.1\r\nPython version:3.6\r\nInstalled using virtualenv? pip? conda?:conda\r\nBazel version (if compiling from source):cmake\r\nGCC/Compiler version (if compiling from source):vs 2015\r\nCUDA/cuDNN version:no cuda\r\nGPU model and memory:no gpu\r\nDescribe the problem\r\nwhen I use cmake GUI config TF, it show me the folowing error message:\r\n\"You have called ADD_LIBRARY for library tf_contrib_tpu_ops without any source files. This typically indicates a problem with your CMakeLists.txt file\r\nCMake Error at tf_python.cmake:217 (message):\r\nPython module not found: tensorflow/contrib/tpu/ops\"\r\nI think the problem is all the source files were moved to \"tensorflow/core/tpu\", do you have idea how to change the path from \"tensorflow/contrib/tpu/ops\" to \"tensorflow/core/tpu\"? or how to block the tpu module in config file?\r\nmany thanks~\r\nProvide the exact sequence of commands / steps that you executed before running into the problem", "comments": ["Can you try building TensorFlow from source using Bazel since support for cmake is no longer there. You can follow the steps mentioned in [TensorFlow website](https://www.tensorflow.org/install/source_windows) for reference. Let us know you are stuck anywhere. Thanks!", "Hi Achandraa,\r\nThanks for you response, I have looked the instruction you mentioned, it tell how to build a whl file. If I want to generate a vs .sln and build a .lib file, what should I do?\r\nThanks!\r\n", "Hello Achandrra and Ymodak, \r\nAny suggestion on it?\r\nThanks~", "@cj741 Apologies for the delay in response. We no longer support cmake builds and recommend to use bazel to build tensorflow from source. Thanks!"]}, {"number": 30014, "title": "Update version numbers for TensorFlow 1.12.3", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 1 -> 1\nMinor: 12 -> 12\nPatch: 2 -> 3\n\nNo lingering old version strings \"1.12.2\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"1.12.2\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 30013, "title": "Make the APIs in name_utils more robust", "body": "This PR refactors `OpName()` and `DatasetDebugString` in name_utils to make them more robust and consistent.\r\n\r\ncc: @jsimsa ", "comments": ["@jsimsa Thanks for the quick review! The comments are addressed by this commit (https://github.com/tensorflow/tensorflow/pull/30013/commits/ca03909328503fdea8a3d20c255a371c2f93ab20). Could you please have a look at the changes?", "@jsimsa Thanks for your time! 'set_args()' is added in this commit(https://github.com/tensorflow/tensorflow/pull/30013/commits/01bffaa05e5249ee134a5b8fb76c3f54cd8cc17b). Could you please take a look when you have a chance?", "@rthadur An error happened while migrating the change for the internal test. Could you please help re-trigger the internal tests? Thanks!", "@jsimsa The internal checks failed. Could you please help paste the log details here?", "`third_party/tensorflow/core/kernels/data/padded_batch_dataset_op.cc:60:9: error: field 'input_' will be initialized after field 'op_version_' [-Werror,-Wreorder]`", "Thanks @jsimsa! The declaration order of member variables are changed to match the initialization order. Please have another look (https://github.com/tensorflow/tensorflow/pull/30013/commits/1517c2d4994fb8d82713860b3e5c29f323025c8b)!", "@jsimsa Sorry that the internal checks failed again. Could you please help check the logs?", "Internal failures seem unrelated. I will help getting the internal CL merged.", "> Internal failures seem unrelated. I will help getting the internal CL merged.\r\n\r\nOnce this gets merged, I will update this one (https://github.com/tensorflow/tensorflow/pull/29901)."]}, {"number": 30012, "title": "Update release notes for TensorFlow 1.12.3", "body": "This PR is intentionally incomplete. One of the Release Owners for 1.12.3\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 30011, "title": "Install 'future' when building Docker images", "body": "Python 2-based images have been failing to build, and I think it's\nbecause 'future' is missing. This PR resolves that, safe_loads yaml to\nquiet a warning about safety, and rewords a few things in\nCONTRIBUTING.md.", "comments": []}, {"number": 30010, "title": "Tensorflow2.0beta is not fit to pycharm", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (win10 professional):\r\n- Mobile device (no)\r\n- TensorFlow installed from (pip):\r\n- TensorFlow version:2.0.0beta1\r\n- Python version:3.7.3\r\n- Installed using virtualenv? pip? conda?:conda env\r\n- Bazel version (if compiling from source):no\r\n- GCC/Compiler version (if compiling from source):no\r\n- CUDA/cuDNN version: 10.0 and 7.6.0\r\n- GPU model and memory: GTX 1060 Max-Q 6GB\r\n\r\n\r\n\r\n**I run some template code with virtual environment created by conda , and successed. But when I used PyCharm , it failed with error saying \r\n`Traceback (most recent call last):\r\n  File \"E:\\Anaconda\\envs\\tf2.0b\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"E:\\Anaconda\\envs\\tf2.0b\\lib\\ctypes\\__init__.py\", line 356, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:/CODE/py/gpucheck/test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"E:\\Anaconda\\envs\\tf2.0b\\lib\\site-packages\\tensorflow\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"E:\\Anaconda\\envs\\tf2.0b\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"E:\\Anaconda\\envs\\tf2.0b\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"E:\\Anaconda\\envs\\tf2.0b\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive\r\n`\r\nI don`t know how to solve this problem . I have already changed the Python`s path , which was installed before the Anaconda. \r\n**\r\n\r\n\r\n", "comments": []}, {"number": 30009, "title": "TensorFlow 1.14 docker images lacking", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\n---\r\n\r\nThere doesn't seem to be any docker images published along side the resent tf 1.14 release. Is this intentional, or can we expect them in the near future?", "comments": ["You're right -- thanks for the report. Our Docker CI system got confused because of our coincident release of the 2.0 beta (whose containers were pushed instead). I've triggered the builds manually and the images should be available in a few hours.", "`1.14.0` images have been published and the `latest` tag has been updated too. Thanks for waiting!", "Thank you so much!", "Happy to help! I've also pushed an internal change that will prevent the CI from getting confused in the future. Thanks!"]}, {"number": 30008, "title": "Call CMSIS-NN optimized kernel for depthwise_conv", "body": "By usings TAGS=cmsis-nn, the optimized depthwise conv is called,\r\nunder the restriction that the kernel meets size requirements.\r\n\r\nChange-Id: I0a070b37ce7dcd06dd8c747de362b4fd42ed4e5a", "comments": ["The micro-specific code is beyond my expertise. I'll leave this to @petewarden  -- Feel free to reassign"]}, {"number": 30007, "title": "Tensorflow Lite Micro fails to build for embedded targets due to dependencing on gemmlowp", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 420473f1fb\r\n- GCC/Compiler version (if compiling from source): arm-none-eabi-g++ 7.3.1\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuilding Tensorflow Lite Micro fails when building for the bluepill target, due to an unmet dependency.\r\n\r\nThe problem seems to be caused by the fact that tensorflow/lite/kernels/internal/common.h includes tensorflow/lite/kernels/internal/optimized/cpu_check.h. \r\n\r\ntensorflow/lite/kernels/internal/common.h is in turn included by the kernels in Tensorflow Lite Micro.\r\n\r\nThis adds gemmlowp as a dependency, which causes Tensorflow Lite Micro to not build when building for eg Cortex-M3 in the bluepill case.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n$ make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=bluepill test\r\n\r\n**Any other info / logs**\r\n`\r\nIn file included from tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/lite/kernels/cpu_backend_context.h:21,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/cpu_check.h:18,\r\n                 from ./tensorflow/lite/kernels/internal/common.h:25,\r\n                 from tensorflow/lite/experimental/micro/kernels/depthwise_conv.cc:18:\r\ntensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/../internal/multi_thread_gemm.h: In member function 'void gemmlowp::BlockingCounter::Wait()':\r\ntensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp/public/../internal/multi_thread_gemm.h:203:14: error: 'std::this_thread' has not been declared\r\n         std::this_thread::sleep_for(std::chrono::milliseconds(1));\r\n`\r\n\r\nFull error log:\r\n[errorlog.txt](https://github.com/tensorflow/tensorflow/files/3310477/errorlog.txt)", "comments": ["just verified & ditto for `TARGET=arduino` (trying to compile for cortex m4 in arduino using the mock_speech generator)\r\n\r\n... ok verified simple comment-out fix works and now runs - time to get some microphones :)", "Pete's recent commit should have solved this problem. https://github.com/tensorflow/tensorflow/commit/97123eff9496776d31cac2131ad65f07e9614f95", "Thanks @petewarden! I'll try this out and add to our Arduino-ready library https://github.com/adafruit/Adafruit_TFLite_Micro_Speech - we got it [working really nicely on a Cortex M4](https://blog.adafruit.com/2019/06/24/tiny-machine-learning-on-the-edge-with-tensorflow-lite-running-on-samd51-arduino-tensorflow-tinyml-tensorflow/)\r\n\r\nHere's a video of it in action :)\r\n [![Tiny Machine Learning on the Edge with TensorFlow Lite Running on SAMD51](http://img.youtube.com/vi/cn9PEDX_qLk/0.jpg)](http://www.youtube.com/watch?v=cn9PEDX_qLk \"Tiny Machine Learning on the Edge with TensorFlow Lite Running on SAMD51\")", "> Pete's recent commit should have solved this problem. [97123ef](https://github.com/tensorflow/tensorflow/commit/97123eff9496776d31cac2131ad65f07e9614f95)\r\n\r\nThat seems to have fixed it, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30007\">No</a>\n"]}, {"number": 30006, "title": "FreeBSD build fixes for hwloc", "body": "With this patches TensorFlow 2 can be built on FreeBSD out-of-box.", "comments": ["I am more concerned about how `dict`s are merged. as long as they are correct, I am ok with this change.", "I just noted there seems to be a typo in\r\n\r\n`\"#undef HAVE_CUDA_RUNTIME_API_H\": \"#undef HAVE_CUDA_RUNTIME_API_H 1\",`\r\n\r\nRight hand side should probably have `#define`, not `#undef`."]}, {"number": 30005, "title": "TensorFlow/examples The gesture_classification Install Dependencies FAIL", "body": "As the picture shows\r\n<img width=\"1102\" alt=\"\u87a2\u5e55\u5feb\u7167 2019-06-20 \u4e0b\u53488 20 45\" src=\"https://user-images.githubusercontent.com/28727682/59848978-11d59480-9399-11e9-8dc0-3025be7e51c3.png\">", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "I run the TensorFlow Lite example from [HERE](https://github.com/tensorflow/examples).\r\nI choice the gesture_classification.\r\nWhen I finish to train my model by web  and download it.\r\nThen I use Colabs to open the [tensorflowjs_to_tflite_colab_notebook.ipynb](https://github.com/tensorflow/examples/blob/master/lite/examples/gesture_classification/ml/tensorflowjs_to_tflite_colab_notebook.ipynb).\r\nIn the Install Dependencies part, I saw Error msg like the image.\r\nIs that correct?", "Looks like this is  TensorflowJS issue. You can post this issue on [TensorFlowJS](https://github.com/tensorflow/tfjs/issues) repository for better and faster help. Let us know if you have any clarification. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30004, "title": "a writing error in tf.contrib.data.map_and_batch", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/data/map_and_batch\r\n\r\n## Description of issue (what needs changing):\r\n\r\nArgs document of this API:\r\n\r\n> num_parallel_calls: (Optional.) A tf.int32 scalar tf.Tensor, representing the number of elements to process in parallel. If not specified, batch_size * num_parallel_batches elements will be processed in **parallel**.\r\n\r\nthe last word should be `sequential` rather than `parallel` \r\n ", "comments": ["The word \u201cparallel\u201d is correct here. The point of `map_and_batch` is to parallelize the execution of the map function and the copy into the output batch tensor(s). "]}, {"number": 30003, "title": "FlexAudioSpectrogram ops is not supported by the tflite interpreter", "body": "When I run a model converted from speech command demo using lite Interpreter, the error is:\r\nTraceback (most recent call last):\r\n  File \"/home/yuan/anaconda3/envs/TFLite/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/yuan/tensorflow-master/tensorflow/examples/speech_commands/audio/audio_processor_lite.py\", line 41, in run\r\n    self._interpreter.allocate_tensors()\r\n  File \"/home/yuan/anaconda3/envs/TFLite/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py\", line 198, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/home/yuan/anaconda3/envs/TFLite/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.Node number 0 (FlexAudioSpectrogram) failed to prepare.\r\nBut the model provided by speech command android demo works  well. (https://github.com/tensorflow/examples/blob/master/lite/examples/speech_commands/android/README.md)", "comments": ["Please help us to know which TensorFlow version you are using. Thanks!", "> Please help us to know which TensorFlow version you are using. Thanks!\r\n\r\nOK. I used \"pip3 install tf-nightly\" to install the tensorflow, and the version is 1.14.1-dev20190615\r\nAnd the original frozen model of pb format was from the model trained with tensorflow-gpu 1.12.0.", "Hi Alan, could you take a look at the speech demo, or do you know who's familar with this?", "Try this\r\ntflite_convert\r\n--output_file=/output.tflite\r\n--graph_def_file /path/to/my_frozen_graph.pb\r\n--input_arrays decoded_sample_data,decoded_sample_data:1\r\n--output_arrays labels_softmax\r\n--allow_custom_ops", "@zhizunbao-y \r\n\r\nHi, could you please try 1) tf-nightly >= 2.3.0 and 2) flex op?\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(your_model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```", "@zhizunbao-y We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. please refer [link1](https://stackoverflow.com/questions/57658509/how-to-invoke-the-flex-delegate-for-tflite-interpreters) , [link2](https://gitanswer.com/tensorflow-flexaudiospectrogram-ops-is-not-supported-by-the-tflite-interpreter-cplusplus-458581345) Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30003\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30003\">No</a>\n"]}, {"number": 30002, "title": "[TF 2.0 API Docs] `tf.keras.callbacks.LearningRateScheduler`", "body": "TensorFlow version: 2.0 (beta1)\r\n\r\n#### Doc links:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py\r\n\r\n#### Description:\r\nThe definition should be expanded for clarity and better user experience. Instead of a one short sentence - \"Learning rate scheduler.\" - maybe try:\r\n```\r\nLearning rate scheduler which can be used to adjust the learning rate over time. Any function can be defined, such as a decay function that states which decay rate to use after a certain number of epochs or batches. Then this custom function can be passed as the `schedule` parameter in the `LearningRateSchuler` callback. \r\n```\r\nAlternatively, a description from the \"Distributed Training with Keras\" [tutorial](https://www.tensorflow.org/beta/tutorials/distribute/keras), linked in the API doc, can also be used:\r\n```\r\nLearning Rate Scheduler: Using this callback, you can schedule the learning rate to change after every epoch/batch.\r\n```\r\n#### Example:\r\nThe word \"Example\" is missing before the example.\r\n\r\n#### Raises/Returns:\r\nShould be added.\r\n\r\n\r\nFor improvement suggestions of other `tf.keras.callbacks` classes see #29958 ", "comments": ["https://github.com/tensorflow/tensorflow/commit/089f8e2c0edb6284e5c3a3ba1042f410ac41b6e6 @achandraa and @jvishnuvardhan - did a bit of work with the description and a few minor changes in the style of the `ReduceLROnPlateau` callback", "@8bitmp3 Are you raising a PR? Thanks!", "I am closing the issue as it was stale issue. Please feel free to reopen when you have time to update the information. Thanks!"]}, {"number": 30001, "title": "TensorFlow 1.3 build fails with OpenMPI", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.3.1\r\n- Python version: 3.5.2\r\n- Installed using virtualenv? pip? conda?: git\r\n- Bazel version (if compiling from source): 0.4.5\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 8.0/6\r\n- GPU model and memory: none (explained below) and 8GB\r\n\r\n**Describe the problem**\r\nBuilding TensorFlow 1.3 leads to an error when MPI support is enabled:\r\n\r\n```\r\nIn file included from ./tensorflow/contrib/mpi/mpi_utils.h:27:0,\r\n                 from tensorflow/contrib/mpi/mpi_utils.cc:18:\r\n./third_party/mpi/mpi.h:2673:41: fatal error: openmpi/ompi/mpi/cxx/mpicxx.h: No such file or directory\r\ncompilation terminated.\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```bash\r\ngit clone git@github.com:tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout v1.3.1\r\n./configure # enable HDFS, CUDA and MPI support, full output in the next section\r\nbazel build -s --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nThe full build output is [there](https://drive.google.com/file/d/19g1oVyPUf1AfRwHBrpMJx5T1o9ZHc7hK/view?usp=sharing).\r\n\r\nI am building TensorFlow in a VM for another system that has a CUDA-compatible GPU. That is why I have installed CUDA and enabled CUDA support, despite the VM not having access to my laptop's GPU (GTX 1050).\r\n\r\nThis is the output of `./configure`, including my choices (I enabled HDFS, CUDA and MPI support):\r\n```\r\n...........\r\nYou have bazel 0.4.5 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.5/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nUsing python library path: /usr/lib/python3/dist-packages\r\nDo you wish to build TensorFlow with MKL support? [y/N]\r\nNo MKL support will be enabled for TensorFlow\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\nDo you wish to use jemalloc as the malloc implementation? [Y/n]\r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] y\r\nHadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]\r\nNo XLA support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with VERBS support? [y/N]\r\nNo VERBS support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nDo you want to use clang as CUDA compiler? [y/N]\r\nnvcc will be used as CUDA compiler\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]:\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]:\r\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.2\r\nDo you wish to build TensorFlow with MPI support? [y/N] y\r\nMPI support will be enabled for TensorFlow\r\nPlease specify the MPI toolkit folder. [Default is /usr]: /usr/lib/openmpi\r\nConfiguration finished\r\n```\r\n\r\nI have installed `libopenmpi-dev`.", "comments": ["I have tried to fix the build, as described in [this question](https://stackoverflow.com/questions/56669899/building-tensorflow-import-mpi-headers-from-outside-of-the-bazel-root), without success. Setting `CC=mpicc` didn't help, as mentioned in the comments.", "The build succeeds with MVAPICH installed from source, keeping the default MPI toolkit path `/usr/local`. The problem exists only when OpenMPI is used.", "@a-gn Did you a get chance to look [#26610](https://github.com/tensorflow/tensorflow/issues/26610) issue. Thanks!", "@gadagashwini I saw this issue, but their problem seems different from mine: in my case, Bazel looks for headers in the wrong place and fails executing the `//tensorflow/contrib/mpi:mpi_utils` rule; in theirs, it fails during the `//tensorflow:tf_python_api_gen_v1` genrule with a problem I don't really understand.", "Do you get a chance to configure.py the OpenMPI path?", "@byronyi Yes, I gave `/usr/lib/openmpi`. I tried other paths, but the `configure` script expects this directory to contain `lib` and `include`, and shows an error if it doesn't.\r\n\r\n`/usr` is the default, but OpenMPI doesn't install in `/usr/include` and `/usr/lib` the files Bazel is looking for. It puts them in `/usr/lib/openmpi` instead.", "Ping @jbedorf", "Looks like the path/file detection during configure fails, similar to this issue: https://github.com/tensorflow/tensorflow/issues/11903\r\nThe fact that it tries to include the `mpicxx.h` file should mean you can prevent that by disabling those headers via: `CC_OPT_FLAGS=\"-DOMPI_SKIP_MPICXX=1` as extra build line argument (see the previous mentioned issue)", "@a-gn Did you check the @jbedorf comment. Thanks!", "@gadagashwini Hi, I haven't yet, but I switched to building and installing MVAPICH from source instead of OpenMPI since I needed a working build.\r\n\r\nI did try to set this variable like this: `OMPI_SKIP_MPICXX=1 bazel build [...]`, but I still had the same error about `mpicxx.h`. I don't know if setting it like @jbedorf suggested fixes that.\r\n\r\nFor now I can work with MVAPICH, I will try in the next days again with that option. Thanks :)", "@a-gn Can we close this issue now since you got workaround. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Sure, thanks for your help."]}, {"number": 30000, "title": "clock_gettime undefined , build on centos6.6, gcc 4.9 \uff08build static lib\uff09", "body": "centos 6.6\r\ngcc 4.9\r\nbuild  static lib of tensorflow\r\nuse:  ./tensorflow/contrib/makefile/build_all_linux.sh \r\n\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 29999, "title": "If variable has huge size, where this variable is located when serveral parameter servers.", "body": "I have tried to model data using two-layered(linear, w*x + b) neural network using custom tf.estimate.Estimator and distribution strategy(default? train_distribution=None), and then an input feature dimension is so huge(almost > 100K).\r\nIf I have [300, 128] layered with biased term, it could be as following:\r\n1st layer: w1 variable will be 100K> x 300(float32), b1 = [1]\r\n2nd layer: w2 variable will be 300 x 128(float32) b2 = [1]\r\n\r\nFinally, my question is that w1 is so big size, where is w1 variable located? Is the w1 variable spread equally with other parameter servers or located in one parameter server.\r\n\r\nThank you for reading even my poor english, in advance.\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there and can provide better and faster resolution to such issues.Thanks\r\n", "Thank you. :)"]}, {"number": 29998, "title": "Updated documentation to include several examples", "body": "Please feel free to suggest improvements!", "comments": ["@tanzhenyu Could you please review the changes?", "@lufol Can you please check Ubuntu Sanity errors? Thanks!", "Can some one please check the changes I have made?\r\n@gbaned @tanzhenyu", "@gbaned  Could you possibly assign a new reviewer as the last update is more than a week old?", "Apology for the late reply. 2.0 has been kept us very busy."]}]