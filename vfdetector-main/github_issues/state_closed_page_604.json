[{"number": 35547, "title": "\u201cCloud TPU\u201d console spam on every TensorFlow import", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux (like Debian)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `v1.12.1-21487-g2e8d5e5 2.1.0-dev20200102`\r\n- Python version: Python 3.7.5rc1\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nImporting TensorFlow prints an unnecessary and unhelpful warning:\r\n\r\n> WARNING:tensorflow:Falling back to tensorflow client, its recommended to install the cloud tpu client directly with pip install cloud-tpu-client .\r\n\r\n**Describe the expected behavior**\r\n\r\nImporting TensorFlow should not print any messages about Cloud TPUs.\r\nThis is a normal desktop installation that doesn\u2019t have anything to do\r\nwith TPUs, and doesn\u2019t need them.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```shell\r\npython -c 'import tensorflow' 2>&1 | diff -u /dev/null -\r\n```\r\n\r\n**Other info / logs**\r\n\r\nLikely introduced by 5364121e858b.\r\n", "comments": ["Thanks for your report! It should be fixed starting with the nightly build tomorrow morning (`2.1.0-dev20200104`).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35547\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35547\">No</a>\n", "Awesome; thanks! Thanks for fixing the grammar, too. :-)\r\n", "> Thanks for your report! It should be fixed starting with the nightly build tomorrow morning (`2.1.0-dev20200104`).\r\n\r\nwhat version of TensorFlow fixes this issue?\r\n\r\nmy versions:\r\n\r\n```\r\ntensorboard               2.4.0              pyhc547734_0  \r\ntensorboard-plugin-wit    1.6.0                      py_0  \r\ntensorflow                2.4.1                    pypi_0    pypi\r\ntensorflow-estimator      2.4.0                    pypi_0    pypi\r\n```", "Got the same info message on Tensorflow 2.4.1.", "The commit doesn't stop the message from being printed, it only changes the level from warning to debug. When we import tensorflow on a local machine it still prints the message."]}, {"number": 35546, "title": "Cherry-pick the release build scripts", "body": "We forgot to cherry-pick these on `r2.1`. Without this, all PRs on this branch will fail CI as the real scripts for CI testing don't exist where CI is expecting them to be.", "comments": []}, {"number": 35545, "title": "Signal module import", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nThe `signal` module is not found  when doing `from tensorflow.signal`.\r\nI have this error:\r\n```\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-1-89a7b2fbc883> in <module>\r\n----> 1 from tensorflow.signal import fft2d\r\n\r\nModuleNotFoundError: No module named 'tensorflow.signal'\r\n```\r\n\r\n**Describe the expected behavior**\r\nI would like `from tensorflow.signal` to work.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nfrom tensorflow.signal import fft2d, ifft2d\r\n```\r\n\r\n**Other info / logs**\r\nIn version 1.14 this was working.\r\nAlso I can still do the following:\r\n```python\r\nimport tensorflow as tf\r\nfft2d = tf.signal.fft2d\r\nifft2d = tf.signal.ifft2d\r\n```\r\n but it's obviously not very handy.\r\n\r\nI also had opened an [SO question](https://stackoverflow.com/questions/59116928/how-do-i-import-the-fft2d-in-tensorflow-2-0-0), but it didn't get a lot of attention.", "comments": ["I was able to replicate the issue for TF-2.0,nightly and 2.1rc2 versions. Please find the [gist](https://colab.sandbox.google.com/gist/oanush/033f20bb27aa23571af02a5339af6422/35545.ipynb) of colab.", "@zaccharieramzi \r\nImporting modules in signal can be done in a way given below.\r\n\r\n`from tensorflow.python.ops.signal.fft_ops import fft2d, ifft2d`\r\n\r\nFor more info please refer to the following [link](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/signal/signal.py) and also the following [gist](https://colab.sandbox.google.com/gist/gowthamkpr/c546437c5202514615276c3bd4e83edc/35545.ipynb).\r\n\r\nClosing this issue as it has been resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35545\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35545\">No</a>\n", "Sure, thanks!\r\n\r\nI am satisfied with this answer which works in all the versions of tensorflow, but do you know why I need to use this heavy statement rather than `tensorflow.signal`?"]}, {"number": 35544, "title": "check if boxes have logical coordinates (different than a line or a p\u2026", "body": "This is related to the first bug in this issue https://github.com/tensorflow/tensorflow/issues/35482 .This code fix obliges the user to only pass logical box coordinates. In fact the two diagonal points shouldn't have x1 = x2 or y1 = y2. In this case an invalidArgumentError will be displayed. The complexity of the added code is O(n) which is not influencial in comparaison to the complexity of the non_max_suppression operation : O(n**2).", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35544) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@MoussaMM thank you for your contrbution , i don't see a CLA signed , can you please check again?", "@rthadur thank you for your reply. I guess i signed with a wrong email. Could you check now please?", "@MoussaMM it still says the CLA is not signed , please check again.", "@rthadur I changed the mail privacy on github so I guess now it works. Can you please check it out again?\r\n", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35544) for more info**.\n\n<!-- cla_yes -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35544) for more info**.\n\n<!-- ok -->", "Sorry about my carelessness.", "@mihaimaruseac multiple tests contain duplicate x or y. What should I do?", "We should fix them: either expect the failure or change the coordinates. Let's do that in this PR too.", "@mihaimaruseac sorry for bothering but I am quite lost with the testing used by tensorflow. Could you explain me the difference between the tests localized in python folder and the tests localized in compiler/test? Another question. One of the required test to change does not exist in the created branch. What should I do?", "For the second question, please rebase against master.\r\n\r\nFor the first question, the compiler/test tests test various compilers to optimize models whereas the python tests are main TF tests.", "@mihaimaruseac  is there anyway to test if the build works on google cloud instead of my local computer? ", "The only way to test on Google infrastructure is after review. But usually we should not have many changes between internal Google and outside (except some tests which I'll take care of during final integration).\r\n\r\nCan you solve the conflicts and then ping me again for a new review?", "@mihaimaruseac so how to check the source code of windows failed tests?", "That was an internal failure, let's retrigger", "It is working! Thank you @mihaimaruseac . It was a pleasure to work with you", "It is now imported internally in Google. There, it gets integrated with internal code and then reviewed again. After that, if all tests pass it will get merged automatically.\r\n\r\nThank you for the PR.", "Hi @MoussaMM The PR has been automatically rolled back in 525e091431b6e6661f5ec6b61b83857791aff441 as it breaks a large number of tests.\r\n\r\nWe can try a different approach where we add a flag guarding the check for logical coordinates. Or, I will try to fix this internally, though it will take some time and probably won't be in time for the upcoming TF 2.2 release.", "Hi @mihaimaruseac . Sorry can you explain your approach more? \r\nDoes it mean we are not allowed to change tests and we have to change the behaviour of the algorithm to be coherent with the tests?", "Since this PR is a behavior change, we have two options\r\n\r\n1. Either someone internally at Google fixes the behavior everywhere and gets approval from all affected teams. Then we make the fix and we include a note about it in the release notes so that people know to update their scripts in case they will be broken by this.\r\n1. Or, we add a new parameter to `non_max_suppression_padded` which is `False` by default and only checks for logical coordinates if set to `True`. Will also require API review and addition to the release notes.\r\n\r\nBoth of these might take longer than the time before the next branch cut, however.", "If you want we can let the illogical boxes get accepted by the algorithm and just eleminate the wrong behaviour they introduce. In fact, even the tests containing illogical boxes didn't have illogical results so I guess it can be merged. \r\nNevertheless, I think the error check make more sense. \r\n(The illogical behaviour I m talking about happens when an illogical boxe get chosen, the algorihm keep rechoosing that box until it reaches the maximum number of result boxes)"]}, {"number": 35543, "title": "Can anyone build a optimized tensorflow-gpu-v2.0 based on cuda10.0 and cudnn7.6(centos7) for me? ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nUsers in China can not download third-party tools from GitHub. It's so frustrating. Can some kind person help me compile an optimized version of TensorFlow-GPU-v2.0. THKS!\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@Times125 \r\nJust to verify did you get chance to follow instructions from [TensorFlow website](https://www.tensorflow.org/install/source) .Please, let us know how it progress. Thanks!\r\n", "> @Times125\r\n> Just to verify did you get chance to follow instructions from [TensorFlow website](https://www.tensorflow.org/install/source) .Please, let us know how it progress. Thanks!\r\n\r\nI compiled the following tutorial. However,  it always times out and fails when I pulled the related files from the repository rules_docker(error:0 package loaded). I used the bazel compile command follows as ` bazel build --config=opt --config=cuda --config=v2 --config=mkl //tensorflow/tools/pip_package:build_pip_package` ", "Hi @Times125 , Could you please fill the above template which will help  expedite the issue ?  Please  also try with [tested configurations ](https://www.tensorflow.org/install/source_windows#gpu)? For installing tensorflow 2.0 with Bazel , Tested configuration for tensorflow_gpu-2.0.0  are below. \r\n\r\ntensorflow_gpu-2.0.0 | 3.5-3.7 | MSVC 2017 | Bazel 0.26.1 | 7.4 (cuDNN)| 10 (CUDA) . Please check you CUDA version and select Tensorflow_gpu version accordingly.\r\n\r\nThanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35543\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35543\">No</a>\n"]}, {"number": 35542, "title": "Tf 2.0 training performance issue", "body": "**System information**\r\n- Custom code for training ResNet50\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip install (precompiled binary, stable version)\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.0.130\r\n- GPU model and memory: RTX 2060 (8GB)\r\n- CPU: AMD Ryzen 3200\r\n\r\nI am seeing slow training in order of 41.4%  in TF2.0 because of ~50% CPU and GPU utilization. Most likely the issue seems to be in memory transfer between CPU and GPU.  Other tf performance issues are closed without any satisfactory answer hence I have written standalone code in TF and pytorch for comparison. Please let me know how I can improve performance of my tf training code given below from 224ms/step to 133ms/step. This difference is almost doubling days of training time for the large model that I am training. \r\n\r\n-------TF code Start ------------\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n#tf.compat.v1.disable_eager_execution()\r\n\r\nclass Lossfunc(tf.keras.losses.Loss):\r\n    def __init__(self,\r\n                 reduction=tf.keras.losses.Reduction.AUTO,\r\n                    name = \"Lossfunc\"):\r\n        super(Lossfunc, self).__init__(reduction=reduction,\r\n                                                           name=name)\r\n\r\n    def call(self, target, output):\r\n        #target = NoneCHW\r\n        loss = tf.keras.losses.MSE(target, output)\r\n        return loss\r\n\r\n#channel = 'channels_last'\r\n#IMG_SHAPE = tuple((256,256,3))\r\n#output_shape = tuple((8,8,2048))\r\nchannel = 'channels_first'\r\nIMG_SHAPE = tuple((3, 256,256))\r\noutput_shape = tuple((2048,8,8))\r\ntf.keras.backend.set_image_data_format(channel)\r\n\r\ndef data_gen():\r\n    input = np.random.normal(0, 0.1, IMG_SHAPE)\r\n    y = np.random.normal(0.5, 0.1, output_shape)\r\n    yield input, y\r\n\r\ndef ResNet():\r\n      backbone = tf.keras.applications.ResNet50(\r\n                                              input_shape=IMG_SHAPE,\r\n                                              include_top=False,\r\n                                              #weights='imagenet')\r\n                                              weights=None)\r\n\r\n      final_output = backbone.output\r\n      model = tf.keras.Model(inputs=backbone.input, outputs=final_output)\r\n      return model\r\n\r\ndef main():\r\n    # cudnn related setting ???\r\n    model = ResNet()\r\n    model.summary()\r\n\r\n    train_loader = tf.data.Dataset.from_generator(\r\n                        data_gen,\r\n                        output_types=(tf.float32, tf.float32),\r\n                        output_shapes=((IMG_SHAPE),\r\n                                       (output_shape)\r\n                        )\r\n                    )\r\n    train_loader = train_loader.repeat().batch(16).prefetch(tf.data.experimental.AUTOTUNE)\r\n    criterion = Lossfunc()\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n    model.compile(loss=criterion, optimizer=optimizer)\r\n    history = model.fit(train_loader,\r\n                                  initial_epoch = 0,\r\n                                  epochs=10,\r\n                                  shuffle=False,\r\n                                  steps_per_epoch=100,\r\n                                  use_multiprocessing=True,\r\n                                  workers=4)\r\n\r\nif __name__ == '__main__':\r\n        main()\r\n```\r\nOutput:\r\n```\r\n100/100 [==============================] - 31s 306ms/step - loss: 0.1300\r\nEpoch 2/10\r\n100/100 [==============================] - 23s 226ms/step - loss: 0.0171\r\nEpoch 3/10\r\n100/100 [==============================] - 22s 224ms/step - loss: 0.0138\r\nEpoch 4/10\r\n100/100 [==============================] - 23s 227ms/step - loss: 0.0123\r\nEpoch 5/10\r\n100/100 [==============================] - 23s 227ms/step - loss: 0.0121\r\n```\r\nCPU utilization: ~50% (None of the CPU thread is more than 60% utilized at anytime)\r\nGPU utilization: 56%\r\n\r\n---Pytorch code Start---\r\n```python\r\nimport torch\r\nimport torchvision.models as models\r\nimport torch.backends.cudnn as cudnn\r\nimport torch.nn as nn\r\nfrom torch.utils.data import Dataset\r\nimport numpy as np\r\nimport time\r\n\r\n# cudnn related setting\r\ncudnn.benchmark = True\r\ntorch.backends.cudnn.deterministic = False\r\ntorch.backends.cudnn.enabled = True\r\n\r\nclass Lossfunc(nn.Module):\r\n    def __init__(self):\r\n        super(Lossfunc, self).__init__()\r\n        self.criterion = nn.MSELoss(reduction='mean')\r\n    def forward(self, output, target):\r\n        loss = self.criterion(output, target)\r\n        return loss\r\n\r\nIMG_SHAPE = tuple((3, 256,256))\r\noutput_shape = tuple((2048,8,8))\r\n\r\nclass GenData(Dataset):\r\n    def __init__(self ):\r\n        self.db = None\r\n\r\n    def __getitem__(self, idx):\r\n        input = np.float32(np.random.normal(0, 0.1, IMG_SHAPE))\r\n        y = np.float32(np.random.normal(0.5, 0.1, output_shape))\r\n        return input, y\r\n\r\n    def __len__(self,):\r\n        return 1600\r\n\r\nclass ResNet(nn.Module):\r\n    def  __init__(self):\r\n        super(ResNet, self).__init__()\r\n        backbone = models.resnet50(pretrained=True)\r\n        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\r\n\r\n    def forward(self, input):\r\n        x = self.backbone(input)\r\n        return x\r\n\r\ndef main():\r\n    # cudnn related setting\r\n\r\n    model = ResNet()\r\n    model = model.cuda()\r\n    print(model)\r\n\r\n    train_dataset = GenData()\r\n    train_loader = torch.utils.data.DataLoader(\r\n                        train_dataset,\r\n                        batch_size=16,\r\n                        shuffle=False,\r\n                        num_workers=4,\r\n                        pin_memory=True\r\n                    )\r\n\r\n    criterion = Lossfunc()\r\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\r\n\r\n    model.train()\r\n    for epoch in range(10):\r\n        start = time.time()\r\n        for i, (input, y) in enumerate(train_loader):\r\n            input = input.cuda()\r\n            output = model(input)\r\n            y = y.cuda(non_blocking=True)\r\n            loss = criterion(output, y)\r\n            optimizer.zero_grad()\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n        i +=1\r\n        end = time.time() - start\r\n        print(\"{} Steps in {} sec @ {} msec/step\".format(i,end, (end/i)*1000  ))\r\n\r\n\r\nif __name__ == '__main__':\r\n        main()\r\n```\r\nOUtput:\r\n```\r\n100 iterations in 14.790956020355225 sec @ 147.90956020355225 msec/step\r\n100 iterations in 13.290162563323975 sec @ 132.90162563323975 msec/step\r\n100 iterations in 13.326005935668945 sec @ 133.26005935668945 msec/step\r\n100 iterations in 13.390087127685547 sec @ 133.90087127685547 msec/step\r\n```\r\nCPU Utilization: 60%\r\nGPU Utilization: 98%\r\n\r\nThe difference in GPU % utilization is same as % time difference.\r\n\r\n\r\n", "comments": ["@neeraj-j, Tried replicating the issue with Tf-gpu 2.0.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/af5ced7289e3617872c49bfdd80c5c91/untitled337.ipynb). Can you confirm the expected outcome. Thanks!", "@neeraj-j,\r\nCould you please update TensorFlow to v2.3 and check if you are still facing the same issue? Thanks!"]}, {"number": 35541, "title": "Add more documentation and a usage example for tf.math.sigmoid", "body": "This change is to add documentation and a usage example for a key logistic activation, `tf.math.sigmoid`, so machine learning enthusiasts will be able to better understand the use of this function.", "comments": ["Please make both changes; if you want to show the values approach 0 and 1\nmaybe add a line like\n\nabs(sigmoid(10) - 1) < 0.001\n\netc\n\nOn Thu, Jan 2, 2020 at 8:57 AM Qwerty71 <notifications@github.com> wrote:\n\n> *@Qwerty71* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/ops/math_ops.py\n> <https://github.com/tensorflow/tensorflow/pull/35541#discussion_r362547474>\n> :\n>\n> > @@ -3212,6 +3218,15 @@ def sigmoid(x, name=None):\n>\n>    Returns:\n>      A Tensor with the same type as `x`.\n> +\n> +  Usage Example:\n> +\n> +  >>> y = tf.math.sigmoid(10.0)\n>\n> Would you like me to make both changes you requested (change inputs, use\n> fewer digits of precision on outputs) or only one? I was trying to\n> demonstrate how the values approach 0 and 1.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/35541?email_source=notifications&email_token=AAABHRNF2YHLHEWSSXBBKD3Q3YMGXA5CNFSM4KCCGFEKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQQ3LEA#discussion_r362547474>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLS3YALCZ6B4XSPOCLQ3YMGXANCNFSM4KCCGFEA>\n> .\n>\n\n\n-- \n - Alex\n", "Ok, I fixed that issue. It turns out values of 1.0 and -1.0 actually work better (as -1.0 returns in decimal notation rather than exponential notation, which is better to represent probability). In addition, I fixed an error with the line length.", "I saw at https://www.tensorflow.org/community/contribute/docs_ref and in a pull request of my own that the doctest should be put above the \"arguments\" section. I suggest you do that \ud83d\ude0a", "#35429 does the same thing", "One more thing. Instead of\r\n\r\n```python\r\n>>> y = tf.sigmoid(...)\r\n>>> print(y)\r\n.value..\r\n```\r\n\r\ncan you instead use\r\n\r\n```python\r\n>>> tf.sigmoid(...)\r\n.value..\r\n```\r\n\r\nThis slightly makes the tests faster and reduces space in the documentation.", "@Qwerty71 Could you please check mihaimaruseac's comments and keep us posted. Thanks!", "Definitely. Sorry I've been a bit busy lately, I will try to fix both commits today.", "@Qwerty71 thank you, it is failing doctest can you please check here for [logs](https://source.cloud.google.com/results/invocations/782d1ba0-12ce-4535-b4b5-9343e03f5688/targets/%2F%2Ftensorflow%2Ftools%2Fdocs:tf_doctest/tests)\r\n\r\nPlease run the doctest locally as mentioned here in the [contributor guidelines](https://www.tensorflow.org/community/contribute/docs_ref).", "@Qwerty71 Can you please resolve conflicts? Thanks!", "There is an issue with `import/copybara`, simply saying \"An error happened while migrating the change\" - no associated log. I don't have any way to see what went wrong here.", "All other checks have passed.", "Can you please solve conflicts (rebase on master)?\r\n\r\nCode diverging from master is the most common reason why copybara fails to migrate.", "Sorry, I didn't see this until now. I'll rebase it once I can.", "It seems another PR for documenting the same function landed before this one.", "I see that. Some of my PR contains aspects that the other PR doesn't\ncontain, perhaps I could integrate them.\n\nOn Tue, Jan 28, 2020, 12:01 PM Mihai Maruseac <notifications@github.com>\nwrote:\n\n> It seems another PR for documenting the same function landed before this\n> one.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/35541?email_source=notifications&email_token=AH4TA2DSRR5S45SL4EKVG3LRABQE3A5CNFSM4KCCGFEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEKEDGOI#issuecomment-579351353>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AH4TA2FMANBH6VNYYUPZRMDRABQE3ANCNFSM4KCCGFEA>\n> .\n>\n", "@Qwerty71 thank you , do you plan to open a new PR or include it in this PR ?", "@Qwerty71 Any update on this PR, please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 35540, "title": "Deadlock on recursive tf.function-decorated function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.10\r\n- TensorFlow installed from (source or binary): binary, conda\r\n- TensorFlow version (use command below): unknown 2.0.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nRecursive calls with a `tf.function` decorated python function results in a deadlock. A minimal example is provided below.\r\n\r\nWhere it gets stuck: by recursively calling `_maybe_define_function`, which internally requires a lock (line 2118 in `tensorflow_core/python/eager.function.py`). This seems to deadlock when trying to create a graph function again invoking itself.\r\n\r\nAbout use-cases: yes, there are. But yes, in principle, there are \"workarounds\". But I assume this is not in general intended to produce a deadlock anyway, should it? If so, I would rather propose a loud failure.\r\n\r\n**Code to reproduce the issue**\r\n```\r\n@tf.function(autograph=False)\r\ndef func1(depth=0):\r\n    if depth > 1:\r\n        return depth\r\n    else:\r\n        return func1(depth + 1)\r\n\r\nfunc1(0)\r\n```", "comments": ["Issue is replicating with Tf2.0.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/f3c4de7f4c91001fbc81be8c459dcdb8/untitled336.ipynb). Thanks!", "While I am only particular familiar with the internals of TF, an `RLock` that allows re-entrance by the same thread may solves the problem.\r\n\r\nIf the lock is there to avoid _concurrency/parallelism_ to mess with the state of the object, this will work.\r\n\r\nIf the lock is in place to make sure the state just does one single retrace, this won't.\r\n\r\nTo unfamiliar with this part of TF to give better ideas.", "Thanks @mayou36 for the detailed description and repro. `tf.function` does not support recursion. Using a `RLock` would lead to stack overflows in the case where the arg is a symbolic `tensor`. I agree we should raise a better error message than deadlocking in this case.", "I agree, and I may seem to have hit a rather rare use-case since no one else complained so far.\r\n\r\nA possible workaround is to call the `tf.function`-wrapped function (in the recursive scenario) _only_ if it is not yet _inside it's wrapper, otherwise the pure python function is called. This would be a safe method as no deadlocks appear, however not fully using the capability of `tf.function` and somewhat defeating the purpose of recursion as it is just flattened out.\r\n\r\nWhich is not the golden way and I see that it may does not make sense to implement it, at least not as long as not more people are interested in this an error seems good.", "I can confirm this is the case for me, too.", "So two solutions:\r\n- roll out the function (call pure Python function if already inside)\r\n- raise an error if already tracing the function\r\n\r\nThe second is safer for sure, it somewhat limits the ability to build things; anyway, recursive should not be the way to go but rather `tf.while_loop`\r\n", "I had the same issue here. ", "I would propose to add an error then, `RuntimeError`?", "I am able to reproduce the issue with TF version 2.3-rc1,nightly versions(`2.4.0-dev20200709`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/1455602ef1318f190dda7d466a16162e/untitled106.ipynb).Thanks!", "Use case: metalearning using MAML (https://arxiv.org/abs/1703.03400).\r\n\r\nHere we need to take a gradient w.r.t. to the initialization of a gradient descent method. This can be implemented naturally in a few lines with a recursive function. \r\n\r\nUnfortunately, due to the limitation expressed in this thread, this works only in Eager mode. ", "Was able to reproduce your issue in Tensorflow 2.5 and Tf Nightly version, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/1b23e68f13a8ff47ef0c93361215b34d/35540.ipynb).", "Issue still persists in `TF 2.6.0` and in `TF-nightly 2.7.0-dev20210917`. Please take a look at the [gist here](https://colab.research.google.com/gist/sanatmpa1/8d27c3a46485745d29b21e950a8653d0/35540.ipynb)", "This issue should have been fixed in the latest TF nightly. \r\nThe example in the report should return `<tf.Tensor: shape=(), dtype=int32, numpy=2>`.\r\nNote using Tensors as stop condition of recursive tf.function is still not supported.\r\nFor example,\r\n```\r\n@tf.function\r\ndef func1(depth=0):\r\n    if depth > 1:\r\n        return depth\r\n    else:\r\n        return func1(depth + 1)\r\n\r\nfunc1(tf.constant(0))  # maximum recursion depth exceeded\r\n```\r\nBut instead of a dead lock, it will error out.", "Great, many thanks, it's really appreciated! That will help to prevent finding deadlocks.\r\n\r\n> Note using Tensors as stop condition of recursive tf.function is still not supported.\r\n\r\nSure, that is an inherent feature of the tracing, thanks again", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35540\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35540\">No</a>\n"]}, {"number": 35539, "title": "CUDA libraries in a self created docker container", "body": "** Base System information**\r\n- Linux Ubuntu 18.04\r\n- nvidia-docker: Docker version 19.03.5, build 633a0ea838\r\n- nvidia driver via: `sudo apt-get install nvidia-driver-418`\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory:\r\n```\r\n$ nvidia-smi \r\nThu Jan  2 12:08:27 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.64       Driver Version: 430.64       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GT 710      Off  | 00000000:AF:00.0 N/A |                  N/A |\r\n| 40%   46C    P0    N/A /  N/A |      0MiB /  2002MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce RTX 207...  Off  | 00000000:D8:00.0 Off |                  N/A |\r\n| 34%   39C    P0     1W / 215W |      0MiB /  7982MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0                    Not Supported                                       |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n\r\n** Docker container information**\r\n- Linux Ubuntu 18.04\r\n- TensorFlow installed from: pip3\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: nvidia-smi output (see above)\r\n- my Dockerfile:\r\n```\r\n#https://www.tensorflow.org/install/gpu\r\nFROM nvidia/cuda:10.0-base-ubuntu18.04\r\n\r\nENV PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/conda/bin:$PATH\r\nRUN apt-get update && apt-get upgrade -y && apt-get install -y \\\r\n        nodejs \\\r\n        npm \\\r\n        python3-pip \\\r\n        wget \\\r\n        libmysqlclient-dev \\\r\n        python-dev\r\n#RUN wget -nv https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && bash Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda && rm Miniconda3-latest-Lin$\r\nRUN mkdir /etc/skel/notebooks\r\nRUN npm install -g configurable-http-proxy && pip3 install \\\r\n        jupyterhub \\\r\n        jupyterhub-ldapauthenticator \\\r\n        jupyterlab \\\r\n        notebook \\\r\n        tensorflow-gpu\r\nRUN pip3 install \\\r\n        folium \\\r\n        keras \\\r\n        matplotlib \\\r\n        mysql \\\r\n        mysql-connector \\\r\n        pandas \\\r\n        pymysql \\\r\n        seaborn \\\r\n        sklearn\r\nVOLUME [\"/home\"]\r\nRUN useradd -ms /bin/bash user -p \"$(openssl passwd -1 test)\"\r\nCOPY ./jupyterhub_config.py /etc/jupyterhub/jupyterhub_config.py\r\nCOPY ./jupyterhub_cookie_secret /etc/jupyterhub/jupyterhub_cookie_secret\r\nCOPY ./jupyterhub.sqlite /etc/jupyterhub/jupyterhub.sqlite\r\n#CMD [\"/usr/local/bin/jupyterhub\", \"upgrade-db\", \"--db=sqlite:////etc/jupyterhub/jupyterhub.sqlite\"]\r\nEXPOSE 8000\r\nCMD [\"/usr/local/bin/jupyterhub\", \"-f\", \"/etc/jupyterhub/jupyterhub_config.py\", \"--debug\"]\r\n```\r\n\r\n\r\n**Describe the problem**\r\n\r\nI created a Docker container based on the Dockerfile (see above) for a multiuser jupyterhub (with notebook and lab). The basics works fine, I can log in and use the desired python packages and running my projects. However, the container lacks the GPU capabiltites.\r\n\r\n- container will be started by: `$ nvidia-docker run -d -p 8000:8000 --runtime=nvidia --restart unless-stopped --gpus all -v ~/myDocker/home:/home jupyterhub`\r\n- `nvidia-smi` works within the container\r\n- `device_lib.list_local_devices()` prints:\r\n```[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 9710542890831123693\r\n, name: \"/device:XLA_GPU:0\"\r\ndevice_type: \"XLA_GPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 12724683280898329209\r\nphysical_device_desc: \"device: XLA_GPU device\"\r\n, name: \"/device:XLA_GPU:1\"\r\ndevice_type: \"XLA_GPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 12608392157467121046\r\nphysical_device_desc: \"device: XLA_GPU device\"\r\n, name: \"/device:XLA_CPU:0\"\r\ndevice_type: \"XLA_CPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 16188673672643731433\r\nphysical_device_desc: \"device: XLA_CPU device\"\r\n]\r\n```\r\n\r\n- `from keras import backend as K\r\nK.tensorflow_backend._get_available_gpus()` prints an empty field\r\n- `tf.test.is_gpu_available()` says `False`\r\n\r\nI can see that tensorflow is looking for the following ones and cannot find them:\r\n- libcublas.so.10.0\r\n- libcufft.so.10.0\r\n- libcurand.so.10.0\r\n- libcusolver.so.10.0\r\n- libcusparse.so.10.0\r\n- libcudnn.so.7\r\n\r\nIt is strange, I never installed nvidia-smi within the container, I seems to be deployed by docker, but necessary parts are missing for tensorflow. However, if I install CUDA or/and nvidia-toolkits and other software parts in the container, tensorflow is reporting about incorpatible versions:\r\n\r\n```\r\n2020-01-01 20:50:11.429852: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-01-01 20:50:11.466847: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2020-01-01 20:50:11.468037: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\r\n2020-01-01 20:50:11.468085: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 9f9f93453aee\r\n2020-01-01 20:50:11.468093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 9f9f93453aee\r\n2020-01-01 20:50:11.468236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.33.1\r\n2020-01-01 20:50:11.468265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.64.0\r\n2020-01-01 20:50:11.468285: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 430.64.0 does not match DSO version 440.33.1 -- cannot find working devices in this configuration\r\n2020-01-01 20:50:11.489100: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz\r\n2020-01-01 20:50:11.493082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4c12f30 executing computations on platform Host. Devices:\r\n2020-01-01 20:50:11.493143: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n```\r\nI do not think that it is an tensorflow issue. It is moreover the question, how to create an own docker container with tensorflow-gpu with CUDA support. Is the docker base image the right one?", "comments": ["I use this Docker (from Nvidia as well), which takes care of pretty much everything:\r\nhttps://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/running.html\r\n\r\nOnly thing required is to install the Nvidia drivers before launching the Docker ...", "@xentity, Please refer [Tensorflow doc](https://www.tensorflow.org/install/docker#gpu_support) for GPU support Tensorflow. Thanks!", "@jnd77 thx for the hint, I'll have a look to this image as well.\r\n\r\n@gadagashwini of course, I did read this page several times.\r\n\r\nI made some progress:\r\n- I had to extend the env: `ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64`\r\n- since tensorflow is looking for different filenames, I had to link them: `ln -s /usr/local/cuda/lib64/libcufft.so.10 /usr/local/cuda/lib64/libcufft.so.10.0` as an example for all other libs mentioned in the error message above.\r\n\r\nAfter that I realized that plain python can run it, but not on JupyterHub. After a lot of trying I realized JupyterHub knows no LD_LIBRARY_PATH (var is empty or not set), but this is necessary for TensorFlow, isn't it?. Some research showed me that it does not apply all envs from the system for security reasons. To solve it, I had to change my JupyterHub config:\r\n\r\n```\r\n#  This whitelist is used to ensure that sensitive information in the JupyterHub\r\n#  process's environment (such as `CONFIGPROXY_AUTH_TOKEN`) is not passed to the\r\n#  single-user server's process.\r\nc.Spawner.env_keep = ['PATH', 'PYTHONPATH', 'CONDA_ROOT', 'CONDA_DEFAULT_ENV', 'VIRTUAL_ENV', 'LANG', 'LC_ALL', 'LD_LIBRARY_PATH']\r\n```\r\nThis yielded into `['/job:localhost/replica:0/task:0/device:GPU:0']` when requesting keras for all GPUs. Yikes!\r\n\r\nI tried to run some model fitting, but ran into this issue as well: https://github.com/tensorflow/tensorflow/issues/24828\r\nThe workaround is to place this snippet on top of the notebook:\r\n```\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n```\r\nThe fitting runs, approximately seven times fast with GPU. I'm just wondering that such fundamental points like the lib names (for TensorFlow) and the env var (for JupyterHub) are not generally solved.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35539\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35539\">No</a>\n"]}, {"number": 35538, "title": "TFLite model output different probabilities and thus different classes in Android compared to the original h5 model..", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab / Android Studio\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (or github SHA if from source):  1.14\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\nTFLite Model output probabilities on same input text:\r\n```\r\n[0.07323484, 0.021794094, 0.013985702, 0.013658127, 0.010268052]\r\n```\r\n\r\nH5 Model file output on same input text: \r\n```\r\n[0.03437233, 0.02771266, 0.01885756, 0.01123235, 0.01093488]\r\n```\r\nHowever, in both cases the first probabilities belong to the same classes. The predicted classes in both cases are not meaningless but also they are not same, which should be the case.\r\n", "comments": ["@rishabhsahrawat \r\n\r\nCan you please help us by providing the related code. It helps us in localizing the issue faster. Thanks!", "Hi @ravikyram , thanks for your response. Which code exactly do you need?. Because it will consist code for the whole android app and also the python code for executing H5 model file. Thanks.", "@rishabhsahrawat Are you sure that you are feeding the same input (which in your case might be word vectors) to TFLite Model as your H5 Model. I suspect that you are using different methods/dictionaries/word_embeddings to convert raw text to the form of input data in the two cases thats why your results are different although the input text is same. Providing related code will be very helpful.\r\nYou can provide : \r\n1. Thepre-processing methods for input text, dictionaries and java class used for inference from android. \r\n2. Equvalent code that you have written in python.", "@am15h yes, I am feeding the same input before pre-processing and after it I am receiving the exact output that I am receiving in Python. This pre-processed text is then fed to a dictionary consisting the words to Embedding layers vectors (since Embedding layer is not supported in TFLite). This mapping was in data type double but as TFlite model does not support Double so it was converted Float type, however I read that it does not affect the TFLite model's output. The vectors are then fed to the TFLite model which was saved without the embedding layer (first layer), this outputs probabilities for each class, ultimately giving classes.\r\n\r\nBelow are the codes:- \r\n1. Android\r\n`````\r\n        // for removing stopwords\r\n        val english_stopwords: List<String> = BufferedReader(InputStreamReader(context!!.assets.open(\"english.txt\"))).readLines() //consisting stopwords\r\n        tokens = ArrayList(tokens)\r\n        tokens.removeAll(ArrayList(english_stopwords))\r\n        // Getting POS Tags for Lemmatizer\r\n        val pos_tags = posTaggerModel!!.tag(tokens.toTypedArray())\r\n        // Lemmatization\r\n        val lemmas = lemmatizerModel!!.lemmatize(tokens.toTypedArray(), pos_tags)\r\n       // Stemming\r\n        var stemmings = ArrayList<String>()\r\n        for (inputString in lemmas.map { it.trim() }) {\r\n            stemmings.add(stemmerModel!!.stem(inputString).toString())\r\n        }\r\n\r\n// For inferencing from TFLite model\r\n    @Throws(IOException::class)\r\n    private fun loadModelFile(): MappedByteBuffer {\r\n        val MODEL_ASSETS_PATH = \"CNNmodel4.tflite\"\r\n        val assetFileDescriptor = assets.openFd(MODEL_ASSETS_PATH)\r\n        val fileInputStream = FileInputStream(assetFileDescriptor.fileDescriptor)\r\n        val fileChannel = fileInputStream.channel\r\n        val startoffset = assetFileDescriptor.startOffset\r\n        val declaredLength = assetFileDescriptor.declaredLength\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startoffset, declaredLength)\r\n    }\r\nval interpreter = Interpreter(loadModelFile())\r\n#INPUTS ARE PADDED TO MATCH THE EXACT SHAPE BEFORE FEEDING TO THE MODEL\r\ninterpreter.run(inputs, outputs) // Giving probabilities as outputs\r\n`````\r\n\r\n2. In Python\r\n`````\r\ndef preprocess_fn(document_in):\r\n  document_in = document_in.translate(str.maketrans(string.punctuation,' '*len(string.punctuation)))# removing punctuations with space\r\n  document_in = document_in.split() #tokenization\r\n  document_in = [doc_word.lower() for doc_word in document_in if doc_word not in stopwords.words('english')]\r\n  document_in = [lemmer.lemmatize(token) for token in document_in]# moving 3rd -> 1st P and past, future -> present\r\n  print (\"Lemm: \",document_in)\r\n  document_in = [snowstemmer.stem(wert) for wert in document_in]# stemming words to root\r\n  print (\"Stem: \",document_in)\r\n  document_in = ' '.join(document_in)\r\n  return document_in\r\n\r\nencoder.encode(preprocess_fn(input_text_description)) // ENCODED INPUT TEXT\r\n#INPUTS ARE PADDED TO MATCH THE EXACT SHAPE BEFORE FEEDING TO THE MODEL\r\nmodel.predict(tf.expand_dims(input, 0), steps = 1)# Model prediction probs\r\n`````\r\n\r\nPlease let me know if you require any other information @ravikyram  @ymodak . Thank you very much!", "Any updates on this issue? ", "Hi @rishabhsahrawat , I want to know more about your models. could you share \"CNNmodel4.tflite\"'s structure and the file \"english.txt\"?", "i get the same issues any help plz", "For now, I am not sure what the exact cause is because there was no response, but I want to say that upgrading to the latest TensorFlows (e.g. tf-nightly>=2.5 or tensorflow>=2.4) and check it again.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35538\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35538\">No</a>\n"]}, {"number": 35537, "title": "Confusion between layers.Activation('softmax'...) and activations.softmax(...)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0.1\r\n- GPU model and memory: QuadroK620M\r\n\r\nI am building a custom model, and trying to use mixed precision. Please take a look at the following two custom models\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport functools\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, activations\r\n\r\n\r\nclass SFM1(tf.keras.Model):\r\n    def __init__(self):\r\n        super(SFM1, self).__init__()\r\n        self.output_layer = layers.Activation('softmax', dtype='float32')\r\n    \r\n    def call(self, inputs):\r\n        return self.output_layer(inputs)\r\n\r\nclass SFM2(tf.keras.Model):\r\n    def __init__(self):\r\n        super(SFM2, self).__init__()\r\n        \r\n    \r\n    def call(self, inputs):\r\n        return activations.softmax(inputs, axis=1)\r\n    \r\nx = tf.random.uniform((2, 4, 64, 64, 64), dtype=tf.float32)\r\nsfm1 = SFM1()\r\ny1 = sfm1(x)\r\n\r\nsfm2 = SFM2()\r\ny2= sfm2(x)\r\n\r\ntf.math.equal(y1, y2)\r\n```\r\ny1 and y2 differ, because layers.Activation(...) assumes axis=-1 by default.\r\nThe issue is, that in mixed presion doc [here](https://www.tensorflow.org/guide/keras/mixed_precision#training_the_model_with_a_custom_training_loop)\r\nThe dtype of the output layer shall be specified as tf.float32, but activations.softmax(...) cannot do it. If I use layers.Activation(...), the axis cannot be specified as 1 ( I am using channel_first data, and I am afraid that cannot change source data). So what can I do?\r\nShall I have to work around by \r\n``` tf.dtypes.cast(activations.softmax(inputs, axis=1), dtype=tf.float32)```", "comments": ["@yourtheron  You can refer to the following [question](https://stackoverflow.com/questions/53503985/what-is-the-difference-between-keras-activations-softmax-and-keras-layers-softma) which should be able to answer your question.\r\n\r\nAlso please post questions like these on stackoverflow as this question is not related to bug/performance, build/install, feature request or docs related issue. Thanks!", "First note, you only need to do softmax in float32 at the end of the model. Unless the softmax is immediately followed by the loss, it is typically safe to do in float16. This means the softmax in `SFM1` and `SFM2` is fine to do in float16 unless you plan on having those layers be the last layers of the model. Therefore you do not have to pass `dtype='float32'` to softmax.\r\n\r\nNow to answer the question: What if you did want to pass `axis` to softmax and do it in float32? This is unlikely as most losses expect the softmax to be done on the final axis, but it can occur with custom losses. Casting the inputs to float32 with `tf.dtypes.cast` and using the `activations.softmax` function is a good solution. But your example is slightly incorrect: You want to cast the *inputs* to softmax, not the *outputs*:\r\n\r\n```\r\nactivations.softmax(tf.dtypes.cast(inputs, dtype=tf.float32), axis=1)\r\n```\r\n\r\nAlternatively, you can directly use a `tf.keras.layers.Softmax` layer, which does have an activation argument:\r\n```\r\nlayer = tf.keras.layers.Softmax(axis=1, dtype=tf.float32)\r\n```"]}, {"number": 35536, "title": "there are some high level vulnerability in Tensorflow 1.15.0, do we have plan to upgrade it?", "body": "curl: 7.65.3\r\nsqlite3: 3.28.0\r\n\r\n", "comments": ["Do you happen to have links to the appropriate CVEs?\r\n\r\n@mihaimaruseac ", "There is a plan to upgrade. Would be great if you can also provide the appropriate CVEs so we can see if they are relevant.", "These are the ones I identified:\r\n\r\n* `curl`:\r\n  * [CVE-2019-5482](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5482)\r\n  * [CVE-2019-5481](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5481)\r\n* `sqlite3`:\r\n  * [CVE-2019-19646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19646)\r\n  * [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645)\r\n  * [CVE-2019-16168](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-16168)\r\n\r\nWe will release 1.15.1 and 2.0.1 with curl and sqlite3 upgraded.", "1.15.2 and 2.0.1 have been released"]}, {"number": 35535, "title": "lite/micro: Incorrectly copy quantization information from serialized data", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): gcc/c++ 5.4.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nWhen micro allocator copies quantization information from serialized data in InitializeRuntimeTensor(), it copies 8 bytes for 'zero_point'. However, the size of 'zero_point' is 4 bytes, so the next member data('allocation_type') will be modified accidentally.\r\n\r\n**Describe the expected behavior**\r\nI think it should just copy 4 bytes for 'zero_point'.\r\n\r\n**Code to reproduce the issue**\r\nAny test case in tensorflow/lite/micro/examples/ can reproduce the issue.\r\n\r\n**Other info / logs**\r\nThis is the fragment of bug code\r\n```\r\n  // This magic handles issues with little-endianness.\r\n  for (unsigned int b = 0; b < sizeof(int64_t); ++b)\r\n    *(reinterpret_cast<char*>(&result->params.zero_point) + b) =\r\n        *(reinterpret_cast<const char*>(\r\n          src_quantization->zero_point()->Data()) +\r\n            b);\r\n    result->params.zero_point =\r\n      flatbuffers::EndianScalar(result->params.zero_point);\r\n```\r\nScreenshot below is a tensor before the code\r\n![image](https://user-images.githubusercontent.com/11289375/71656049-b5562780-2d74-11ea-84ee-48cbe5b424b0.png)\r\n\r\nScreenshot below is a tensor after the code\r\n![image](https://user-images.githubusercontent.com/11289375/71656203-652b9500-2d75-11ea-8e35-8ff7810da4d1.png)\r\n\r\nThe quantization information should not modify the allocation_type. I think `sizeof(int64_t)` should be changed into `sizeof(result->params.zero_point)`\r\n", "comments": ["Thanks for reporting this issue.  I have created a patch to fix this internally, and it should merge in shortly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35535\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35535\">No</a>\n", "Hello, @njeffrie :\r\nThank you for your patch. However, I don't think the patch can resolve the issue. I want to know why the patch is that change `sizeof(int64_t)` into `sizeof(sizeof(result->params.zero_point))`. I think it doesn't make sense because the return type of `sizeof()` is `size_t` and the type of `params.zeor_point` is `int32_t`. In some machines, `sizeof(size_t)` is 8, that will overwrite memory allocation type. Why are there two `sizeof()`.\r\n", "Oops, good catch!  Unintentionally added an additional sizeof there. Submitting patch to fix this.", "Thank you very much."]}, {"number": 35534, "title": "Include file when building tensorflow 2.0 from source missing.", "body": "When compiled, tensorflow2.0 outputs the libtensorflow_cc.so and libtensorflow_framework.so\r\nUsed: bazel build --config=opt  //tensorflow:libtensorflow_cc.so \r\nHowever there are no more genfiles where I was getting the include files to link to . In the tensorflow/cc/ops directory e.g. I am missing array_ops. There are many others missing. Before I could those from genfiles directory, now this folder is gone. Where can I get all the include files to compile my file with?\r\nThe alternative I think would be to use bazel build <my file>, however this takes too long to compile my file. I just want to use g++ to link with the above lib and the include files.\r\n------------------------\r\nOS: Linux Ubuntu 14.04 \r\nTensorflow 2.0 (master) installed from source\r\nNo Cuda\r\nC++ API\r\n\r\n", "comments": ["You can use `bazel build //tensorflow:install_headers` and it will collect all the headers needed for libtensorflow.so and libtensorflow_cc.so etc and put them in a dir, then you can `cp -R bazel-genfiles/tensorflow/include/* /usr/include/tensorflow/`", "Thank you, is there some place you looked into the directory to know the command install_headers was needed with bazel build? If so, could you tell me, so that I can also compile third party tools like protobuf, google, etc. if need be without having to ask. Thanks again", "oh, i added the install_headers target to tensorflow a long time ago cuz I needed exactly this, so i knew its there ;). Its not a standardized bazel thing so I made a custom rule in tensorflow. There is this: https://github.com/bazelbuild/bazel/issues/5849 But nothing standardized for all packages to use yet.", "Thank you, is there some place you looked into the directory to know the command install_headers was needed with bazel build? If so, could you tell me, so that I can also compile third party tools like protobuf, google, etc. if need be without having to ask. Thanks again", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35534\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35534\">No</a>\n"]}, {"number": 35533, "title": "Bug: Model.fit VS GradientTape in tf2.0: GradientTape can't work", "body": "### 1. Network define\r\n```\r\nimport pathlib\r\nfrom concurrent.futures import ProcessPoolExecutor\r\n\r\nimport gensim\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom absl import app\r\nfrom absl import flags\r\nfrom absl import logging\r\nfrom tensorflow import keras as tfk\r\nfrom tqdm import tqdm\r\n\r\nfrom src.preprocessing.sequence import create_dataset\r\nfrom src.preprocessing.text import JiebaTokenizer\r\n\r\n\r\nclass TextCNN(tfk.Model):\r\n\r\n    LABEL_IDX_DICT = {\"constellation\": 0, \"education\": 1, \"entertainment\": 2, \"fashion\": 3, \"finance\": 4, \"game\": 5,\r\n                      \"house\": 6, \"land\": 7, \"lottery\": 8, \"political\": 9, \"social\": 10, \"sports\": 11, \"stock\": 12,\r\n                      \"technology\": 13}\r\n    IDX_LABEL_DICT = {idx: label for label, idx in LABEL_IDX_DICT.items()}\r\n\r\n    def __init__(self, embeddings):\r\n        super(TextCNN, self).__init__()\r\n        self.embedding_layer = tfk.layers.Embedding(embeddings.shape[0], embeddings.shape[1], trainable=False,\r\n                                                    embeddings_initializer=tf.initializers.Constant(embeddings))\r\n        self.conv_layers = [tfk.layers.Conv1D(FLAGS.filters, FLAGS.kernel_size + idx * FLAGS.kernel_distance,\r\n                                              strides=FLAGS.conv_strides, padding=FLAGS.conv_padding)\r\n                            for idx in range(FLAGS.conv_pool_num)]\r\n        self.pool_layers = [tfk.layers.MaxPool1D(pool_size=FLAGS.pool_size, strides=FLAGS.pool_strides,\r\n                                                 padding=FLAGS.pool_padding)\r\n                            for idx in range(FLAGS.conv_pool_num)]\r\n        self.dense1_layer = tfk.layers.Dense(FLAGS.dense_units, activation=FLAGS.activation)\r\n        self.batchnorm_layer = tfk.layers.BatchNormalization()\r\n        self.dense2_layer = tfk.layers.Dense(len(self.LABEL_IDX_DICT), activation=tfk.activations.softmax)\r\n        self.dropout_layer = tfk.layers.Dropout(FLAGS.dropout_rate)\r\n\r\n    def call(self, inputs, training=None):\r\n        x = inputs\r\n        x_embed = self.embedding_layer(x)\r\n        assert FLAGS.conv_pool_num > 0, ValueError(\"conv_pool_num must > 0\")\r\n        encodings = [self.conv_layers[idx](x_embed) for idx in range(FLAGS.conv_pool_num)]\r\n        encodings_pool = [self.pool_layers[idx](encodings[idx]) for idx in range(FLAGS.conv_pool_num)]\r\n        encodings_concat = tf.concat(encodings_pool, axis=-1)\r\n        encodings_concat = self.batchnorm_layer(encodings_concat, training=training)\r\n        encodings_flatten = tfk.layers.Flatten()(encodings_concat)\r\n        encodings_flatten = self.dropout_layer(encodings_flatten, training=training)\r\n        hidden = self.dense1_layer(encodings_flatten)\r\n        y_pred = self.dense2_layer(hidden)\r\n        return y_pred\r\n```\r\n### 2. Train with model.fit\r\n```\r\nw2v = gensim.models.KeyedVectors.load_word2vec_format(FLAGS.embeddings_path)\r\nwords = list(w2v.vocab.keys())[:FLAGS.vocab_size]\r\ntokenizer = JiebaTokenizer(words)\r\ngpus = tf.config.experimental.list_physical_devices(\"GPU\")\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\nembeddings = np.zeros(shape=(FLAGS.vocab_size + 2, w2v.vector_size), dtype=np.float32)\r\nfor word, idx in tokenizer.word2idx_dict.items():\r\n    if word in w2v.vocab:\r\n        embeddings[idx] = w2v.word_vec(word)\r\nx, y = TextCNN.preprocess_dataset(tokenizer, FLAGS.trainset_path)\r\ntrainset = create_dataset([x, y])\r\ntrainset = trainset.batch(FLAGS.batch_size).shuffle(FLAGS.buffer_size)\r\nval_x, val_y = TextCNN.preprocess_dataset(tokenizer, FLAGS.valset_path)\r\nvalset = create_dataset([val_x, val_y])\r\nvalset = valset.batch(FLAGS.batch_size).shuffle(FLAGS.buffer_size)\r\nmodel = TextCNN(embeddings)\r\noptimizer = tf.optimizers.Adam(FLAGS.lr)\r\nmodel.compile(optimizer=optimizer, loss=tf.losses.sparse_categorical_crossentropy, metrics=[\"acc\"])\r\nmodel.fit(x=x, y=y, batch_size=FLAGS.batch_size, epochs=FLAGS.epochs, validation_data=(val_x, val_y))\r\n```\r\n### 3. Train with GradientTape\r\n```\r\nw2v = gensim.models.KeyedVectors.load_word2vec_format(FLAGS.embeddings_path)\r\nwords = list(w2v.vocab.keys())[:FLAGS.vocab_size]\r\ntokenizer = JiebaTokenizer(words)\r\ngpus = tf.config.experimental.list_physical_devices(\"GPU\")\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\nembeddings = np.zeros(shape=(FLAGS.vocab_size + 2, w2v.vector_size), dtype=np.float32)\r\nfor word, idx in tokenizer.word2idx_dict.items():\r\n    if word in w2v.vocab:\r\n        embeddings[idx] = w2v.word_vec(word)\r\nx, y = TextCNN.preprocess_dataset(tokenizer, FLAGS.trainset_path)\r\ntrainset = create_dataset([x, y])\r\ntrainset = trainset.batch(FLAGS.batch_size).shuffle(FLAGS.buffer_size)\r\nval_x, val_y = TextCNN.preprocess_dataset(tokenizer, FLAGS.valset_path)\r\nvalset = create_dataset([val_x, val_y])\r\nvalset = valset.batch(FLAGS.batch_size).shuffle(FLAGS.buffer_size)\r\nmodel = TextCNN(embeddings)\r\noptimizer = tf.optimizers.Adam(FLAGS.lr)\r\nloss_object = tf.losses.SparseCategoricalCrossentropy()\r\ntrain_acc = tf.metrics.SparseCategoricalAccuracy()\r\nval_acc = tf.metrics.SparseCategoricalAccuracy()\r\ntrain_loss = tf.metrics.Mean()\r\nval_loss = tf.metrics.Mean()\r\n\r\n@tf.function\r\ndef train_op(x, y):\r\n    with tf.GradientTape() as tape:\r\n        y_pred = model(x, training=True)\r\n        loss = loss_object(y, y_pred)\r\n        train_acc.update_state(y, y_pred)\r\n        train_loss.update_state(loss)\r\n        grads = tape.gradient(loss, model.trainable_variables)\r\n        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\r\n\r\n@tf.function\r\ndef val_op(x, y):\r\n    y_pred = model(x, training=False)\r\n    loss = loss_object(y, y_pred)\r\n    val_acc.update_state(y, y_pred)\r\n    val_loss.update_state(loss)\r\n\r\nfor epoch in range(FLAGS.epochs):\r\n    tf.print(\"Epoch {}/{}\".format(epoch + 1, FLAGS.epochs))\r\n    bar = tfk.utils.Progbar(target=len(x), unit_name=\"sample\")\r\n    train_acc.reset_states()\r\n    val_acc.reset_states()\r\n    train_loss.reset_states()\r\n    val_loss.reset_states()\r\n    for batch_x, batch_y in trainset:\r\n        train_op(batch_x, batch_y)\r\n        bar.add(len(batch_y))\r\n    for batch_x, batch_y in valset:\r\n        val_op(batch_x, batch_y)\r\n    template = \"loss: {:.4f}\\nacc: {:.4f}\\nval_loss: {:.4f}\\nval_acc: {:.4f}\"\r\n    message = template.format(train_loss.result().numpy(), train_acc.result().numpy(),\r\n                              val_loss.result().numpy(), val_acc.result().numpy())\r\n    tf.print(message)\r\n```\r\n### 4. model.fit result\r\n![image](https://user-images.githubusercontent.com/22722147/71655214-d452ba80-2d70-11ea-9ef8-294d90944ea1.png)\r\n### 5. GradientTape result\r\n![image](https://user-images.githubusercontent.com/22722147/71654550-3e696080-2d6d-11ea-896e-e72ade58974a.png)\r\n![image](https://user-images.githubusercontent.com/22722147/71654563-5214c700-2d6d-11ea-880b-10744b899d6f.png)\r\n![image](https://user-images.githubusercontent.com/22722147/71654570-5b059880-2d6d-11ea-896c-a132b383ee32.png)\r\n### 6. Question\r\nLike the result above, I use same parameter, but get very different result. Who can help me to figure out it. I have read some relevant tensorflow2.0 source code, but can't solve it.\r\n", "comments": ["When I remove BatchNormalization and Dropout layer\uff0cmodel.fit also work, but tapegradient is very bad in train set and validate set. I have try many times to figure out it, but result tell me it is possible a bug\uff1f", "When I use modify my code to this:\r\n```\r\nclass TextCNN(tfk.Model):\r\n    LABEL_IDX_DICT = {\"constellation\": 0, \"education\": 1, \"entertainment\": 2, \"fashion\": 3, \"finance\": 4, \"game\": 5,\r\n                      \"house\": 6, \"land\": 7, \"lottery\": 8, \"political\": 9, \"social\": 10, \"sports\": 11, \"stock\": 12,\r\n                      \"technology\": 13}\r\n    IDX_LABEL_DICT = {idx: label for label, idx in LABEL_IDX_DICT.items()}\r\n\r\n    def __init__(self, embeddings):\r\n        super(TextCNN, self).__init__()\r\n        self.embedding_layer = tfk.layers.Embedding(embeddings.shape[0], embeddings.shape[1], trainable=False,\r\n                                                    embeddings_initializer=tf.initializers.Constant(embeddings))\r\n        self.conv_layers = [tfk.layers.Conv1D(FLAGS.filters, FLAGS.kernel_size + idx * FLAGS.kernel_distance,\r\n                                              strides=FLAGS.conv_strides, padding=FLAGS.conv_padding)\r\n                            for idx in range(FLAGS.conv_pool_num)]\r\n        self.pool_layers = [tfk.layers.MaxPool1D(pool_size=FLAGS.pool_size, strides=FLAGS.pool_strides,\r\n                                                 padding=FLAGS.pool_padding)\r\n                            for idx in range(FLAGS.conv_pool_num)]\r\n        self.dense1_layer = tfk.layers.Dense(FLAGS.dense_units, activation=FLAGS.activation)\r\n        self.dense2_layer = tfk.layers.Dense(len(self.LABEL_IDX_DICT), activation=tfk.activations.softmax)\r\n\r\n\r\n    def call(self, inputs, training=None):\r\n        x = inputs\r\n        x_embed = self.embedding_layer(x)\r\n        assert FLAGS.conv_pool_num > 0, ValueError(\"conv_pool_num must > 0\")\r\n        encodings = [self.conv_layers[idx](x_embed) for idx in range(FLAGS.conv_pool_num)]\r\n        encodings_pool = [self.pool_layers[idx](encodings[idx]) for idx in range(FLAGS.conv_pool_num)]\r\n        encodings_concat = tf.concat(encodings_pool, axis=-1)\r\n        encodings_flatten = tfk.layers.Flatten()(encodings_concat)\r\n        hidden = self.dense1_layer(encodings_flatten)\r\n        y_pred = self.dense2_layer(hidden)\r\n        return y_pred\r\n\r\n        @tf.function\r\n        def train_op(x, y):\r\n            with tf.GradientTape() as tape:\r\n                y_pred = model(x, training=True)\r\n                tf.print(y_pred)\r\n                loss = loss_object(y, y_pred)\r\n                train_loss.update_state(loss)\r\n                train_acc.update_state(y, y_pred)\r\n                grads = tape.gradient(loss, model.trainable_variables)\r\n                optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\r\n\r\n        @tf.function\r\n        def val_op(x, y):\r\n            y_pred = model(x, training=False)\r\n            tf.print(y_pred)\r\n            loss = loss_object(y, y_pred)\r\n            val_loss.update_state(loss)\r\n            val_acc.update_state(y, y_pred)\r\n```\r\nfront the epoch 7, the result is usual:\r\n![image](https://user-images.githubusercontent.com/22722147/71709843-5c4dc880-2e34-11ea-9bd4-7fedf46db8e6.png)\r\nthe end of epoch 8:\r\n![image](https://user-images.githubusercontent.com/22722147/71709878-899a7680-2e34-11ea-86e0-2df5c9711acd.png)\r\nevery batch predictions is same, I think this is a bug\r\n", "I have find the reason, use relu activation will cause it.", "Same problem with [#35585 ](https://github.com/tensorflow/tensorflow/issues/35585)\uff0cmodel.fit val_acc & val_loss is much better than GradientTape", "Any update on this? The Keras fit method is not serving my purpose and tf.GradientTape not working means TFv2 is now completely useless for my research. I am not sure going back to TFv1 is a good idea. Kindly give an update on when to expect a fix.", "Please take a look at issue #38596, linked above. I believe this is the underlying issue for why the Keras `model.fit()` method computes the wrong epoch loss.", "@gadagashwini @NLP-ZY I could solve my issue by using tf.gradients instead of using GradientTape inside a function decorated with tf.function.", "@amalroy2016 Thanks, can you give some example? ", "@NLP-ZY What is `src` in \r\n`from src.preprocessing.sequence import create_dataset`. Can you check the solution I provided for your code in other issue [here](https://github.com/tensorflow/tensorflow/issues/35585#issuecomment-615413203). \r\n\r\nPlease change this line from \r\n`        self.dense2_layer = tfk.layers.Dense(len(self.LABEL_IDX_DICT), activation=tfk.activations.softmax)\r\n`\r\nto \r\n`        self.dense2_layer = tfk.layers.Dense(len(self.LABEL_IDX_DICT))`\r\n\r\nChange the following line from \r\n`loss_object = tf.losses.SparseCategoricalCrossentropy()` \r\nto\r\n`loss_object = tf.losses.SparseCategoricalCrossentropy(from_logits=True)`\r\n\r\nPlease check and verify the results after updating your code. If the issue was resolved for you, then please close it. Thanks", "@jvishnuvardhan Thanks, I have make a change, but it doesn't work.", "The train_op would be like \r\n```\r\n@tf.function\r\ndef train_op(x, y):\r\n    y_pred = model(x, training=True)\r\n    tf.print(y_pred) # In my case the shapes of the output required an extra tf.squeeze\r\n    loss = loss_object(y, y_pred)\r\n    train_loss.update_state(loss)\r\n    train_acc.update_state(y, y_pred)\r\n    grads = tf.gradients(loss, model.trainable_variables)\r\n    optimizer.apply_gradients(grads, model.trainable_variables)\r\n```", "@amalroy2016 Thanks, it doesn't work for my problem.", "I have find the reason, I forget reset_states for every epoch.", "@NLP-ZY  can you give an example of reset_states?\r\nI'm having the same issue and adding reset_states doesn't  work\r\n", "@joey0320  Yes, please see my test code in [gist](https://colab.research.google.com/gist/NLP-ZY/3762cb58f789d36511f812edabe129aa/untitled0.ipynb)"]}, {"number": 35532, "title": "Fail to invoke tflite_runtime.interpreter", "body": "I'm trying to run the tflite_runtime.interpreter\r\n\r\nHowever when I go to run the interpreter I get the following error:\r\n`RuntimeError: tensorflow/lite/kernels/mfcc.cc:131 params->dct_coefficient_count != mfcc_output.size() (40 != 0)Node number 1 (Mfcc) failed to invoke.`\r\n", "comments": ["\u5b9a\u5b9a\u5b9a", "\u6c42\u5e2e\u5fd9", "\u4e0d\u8981\u6c89\u554a\u554a\u554a\u554a\u554a", "duplicate #33857\r\nPlease provide following information relevant to your case:\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.", "I solve the problem,thks", "Thanks. If you can please post your solution on this thread that will be great for the community. "]}, {"number": 35531, "title": "How to remove future warnings in tensorflow 2.0?", "body": "Hello I am using tensorflow 2.0 and whenever I import tensorflow it gives me a future warning which is very long and annoying and does hides a big part of the output. I have tried many solutions from other issues but none of them work and I think almost all of them are for tf1.0. I have tried - \r\n\r\n```py\r\nimport logging\r\ntf.get_logger().setLevel(logging.ERROR)\r\n```\r\n```py\r\nimport sys\r\noriginal_stdout = sys.stdout\r\nsys.stdout = None\r\n```\r\n```py\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \r\nimport tensorflow as tf\r\n```\r\nAlso I have tried solutions from these issues - \r\nhttps://github.com/tensorflow/tensorflow/issues/8340\r\nhttps://github.com/tensorflow/tensorflow/issues/7652\r\nNone of them work.", "comments": ["@rajcivils ,\r\nPlease try the solutions provided in these links [1](https://github.com/tensorflow/tensorflow/issues/8340#issuecomment-332212742) & [2](https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information).Thanks!", "@oanush None of them work", "@rajcivils ,\r\nCan you share a standalone code to reproduce the error faced by you?Thanks!", "@oanush There is no error it is a warning", "Hello I got the solution we need to only do this - \r\n```py\r\nimport warnings\r\nwarnings.filterwarnings(\"ignore\")\r\nimport tensorflow as tf\r\n```\r\nActually none of the solutions worked for me except for this one.\r\nI just wrote those lines before importing tensorflow and viola it worked."]}, {"number": 35530, "title": "Switch from where to where_v2 in matrix_exponential", "body": "(because `where` is deprecated).\r\n\r\n`where` and `where_v2` have different broadcasting rules: the former\r\n\"broadcasts\" by treating a 1D condition as a mask on the *outer*\r\ndimension of x and y; the latter follows standard broadcasting rules,\r\nwhich cause a 1D condition to act as a mask on the *inner* dimension of\r\nx and y. E.g. with `where_v2`, if x and y are [n, d, d], then a\r\ncondition [n] will either fail to build (if n != d) or be treated as\r\n[1, 1, n] (if n == d).\r\n\r\nIn this case, we want the condition to act as a mask on the outer\r\ndimension, e.g. be treated as [n, 1, 1]. The way to make that happen\r\nwith `where_v2` is simply to expand the condition's dimensions to that\r\nshape manually.\r\n\r\nIn the case of matrix exponential, by expanding the shape of `l1_norm`\r\nto [n, 1, 1]:\r\n - the conditions in `_nest_where` become the right shape,\r\n - the `squarings` variables get expanded too (i.e. [n] -> [n, 1, 1]),\r\n   which means that...\r\n - ... when scaling the Pade approximants we no longer need to expand\r\n   the dimensions of 2^squarings, and ...\r\n - ... the condition in `b` (used for the squaring while loop) becomes\r\n   the right shape.\r\n\r\nWhich is what we need.", "comments": []}, {"number": 35529, "title": "model crashes in distributed strategy in tf2.1", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0-rc2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1 / 7.6\r\n- GPU model and memory: RTX titan 24GB\r\n\r\n\r\n**Describe the current behavior**\r\nwhen the model is to be trained on distributed setting, model crashes with the message of Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled. When it is set on single gpu everything works fine\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport random\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\r\n\r\nclass Model(keras.Model):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.emb = keras.layers.Embedding(51,100)\r\n        self.layer = keras.layers.Dense(51)\r\n\r\n    def call(self,x):\r\n        x = self.emb(x)\r\n        x = self.layer(x)\r\n        return x\r\n\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\ndata = [[i for i in range(random.randint(10,50))] for j in range(400)]\r\n\r\n\r\ndef iterator():\r\n    for i in range(len(data)):\r\n        yield data[i], data[i]\r\n\r\n\r\nwith strategy.scope():\r\n    model = Model()\r\n    optimizer = keras.optimizers.Adam()\r\n\r\ndataset = tf.data.Dataset.from_generator(iterator, output_types=(tf.int64, tf.int64))\r\nbatchfier = dataset.padded_batch(4, padded_shapes=([None], [None]))\r\nbatchfier = strategy.experimental_distribute_dataset(batchfier)\r\n\r\n\r\n@tf.function(input_signature=batchfier.element_spec)\r\ndef multi_gpu_step(x,y):\r\n    def example_update_step(x, y):\r\n        with tf.GradientTape() as tape:\r\n            y_ = model(x)\r\n            batch_loss = keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_, from_logits=True)\r\n            losses = batch_loss / strategy.num_replicas_in_sync\r\n        step_grad = tape.gradient(losses, model.trainable_variables)\r\n        optimizer.apply_gradients(zip(step_grad, model.trainable_variables))\r\n        return tf.reduce_mean(batch_loss,1)\r\n    example_loss = strategy.experimental_run_v2(\r\n        example_update_step, args=(x, y))\r\n    losses_sum = strategy.reduce(\r\n        tf.distribute.ReduceOp.SUM, example_loss, axis=0)\r\n    return losses_sum\r\n\r\n\r\nfor x,y in batchfier:\r\n    multi_gpu_step(x,y)\r\n```\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\n\r\n> 2020-01-02 13:56:10.710246: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n2020-01-02 13:56:10.711123: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\nTraceback (most recent call last):\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2240, in _convert_inputs_to_signature\r\n    value, dtype_hint=spec.dtype)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1314, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 317, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 258, in constant\r\n    allow_broadcast=True)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 266, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: Attempt to convert a value (PerReplica:{\r\n  0 /job:localhost/replica:0/task:0/device:GPU:0: <tf.Tensor: shape=(2, 48), dtype=int64, numpy=\r\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\r\n        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\r\n        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,  0,  0,  0,  0,  0],\r\n       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\r\n        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\r\n        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])>,\r\n  1 /job:localhost/replica:0/task:0/device:GPU:1: <tf.Tensor: shape=(2, 48), dtype=int64, numpy=\r\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\r\n        16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  0,  0,  0,  0,  0,  0,\r\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\r\n       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\r\n        16, 17, 18, 19, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>\r\n}) with an unsupported type (<class 'tensorflow.python.distribute.values.PerReplica'>) to a Tensor.\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"multi_test_variable.py\", line 56, in <module>\r\n    multi_gpu_step(x,y)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 632, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2362, in __call__\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2661, in _maybe_define_function\r\n    *args, **kwargs)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2185, in canonicalize_function_inputs\r\n    self._flat_input_signature)\r\n  File \"/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2246, in _convert_inputs_to_signature\r\n    format_error_message(inputs, input_signature))\r\nValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors:\r\n  inputs: (\r\n    PerReplica:{\r\n  0 /job:localhost/replica:0/task:0/device:GPU:0: tf.Tensor(\r\n[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\r\n  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  0  0  0  0  0]\r\n [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\r\n  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]], shape=(2, 48), dtype=int64),\r\n  1 /job:localhost/replica:0/task:0/device:GPU:1: tf.Tensor(\r\n[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\r\n  24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\r\n [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20  0  0  0\r\n   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]], shape=(2, 48), dtype=int64)\r\n},\r\n    PerReplica:{\r\n  0 /job:localhost/replica:0/task:0/device:GPU:0: tf.Tensor(\r\n[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\r\n  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  0  0  0  0  0]\r\n [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\r\n  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]], shape=(2, 48), dtype=int64),\r\n  1 /job:localhost/replica:0/task:0/device:GPU:1: tf.Tensor(\r\n[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\r\n  24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\r\n [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20  0  0  0\r\n   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]], shape=(2, 48), dtype=int64)\r\n})\r\n  input_signature: (\r\n    TensorSpec(shape=(None, None), dtype=tf.int64, name=None),\r\n    TensorSpec(shape=(None, None), dtype=tf.int64, name=None))\r\n", "comments": ["@bj1123 This is a duplicate of issue #29911 and has been fixed. Can you try using the latest nightly TensorFlow package? \r\nThe generator message is not related to the actual error. You should not see this message in the latest nightly TF package.", "Duplicate of #29911 ", "> @bj1123 This is a duplicate of issue #29911 and has been fixed. Can you try using the latest nightly TensorFlow package?\r\n> The generator message is not related to the actual error. You should not see this message in the latest nightly TF package.\r\n\r\nTF nightly version does not show the above error. Thanks\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35529\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35529\">No</a>\n"]}, {"number": 35528, "title": "Why Tf Warns 'Model's Complie Policy is not the same as the dtype policy's loss scale'", "body": "I built up a custom model, then tried to adopt mixed precision as instructed by [here](https://www.tensorflow.org/guide/keras/mixed_precision#training_the_model_with_a_custom_training_loop)\r\n\r\n```\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\ncurOpt = tf.keras.optimizers.Adam(learning_rate=1e-4)\r\ncurOpt = mixed_precision.LossScaleOptimizer(curOpt, loss_scale='dynamic')\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\n# query if it has been well set\r\nprint('Compute dtype: %s' % policy.compute_dtype)\r\nprint('Variable dtype: %s' % policy.variable_dtype)\r\nmodelInDim = (4, 64, 64, 64)\r\nclassNum = 2\r\nmbSize = 2\r\nTUNet = SimpleUNet(modelInDim, classNum)\r\nTUNet.build_model(input_shape=(mbSize,)+modelInDim)\r\nTUNet.summary()\r\n```\r\nNote that I set all Then as I call\r\n```\r\nTUNet.compile(loss=softDiceLoss, optimizer=curOpt)\r\n```\r\nThe following warning pops out\r\n```\r\nTUNet.compile(loss=softDiceLoss, optimizer=curOpt)\r\nWARNING:tensorflow:LossScale of LossScaleOptimizer passed to compile (DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)) is not the same as the dtype policy's loss scale (DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)). Because the dtype policy has a loss scale, you should pass an optimizer that is not wrapped with a LossScaleOptimizer,\r\n```\r\nWhat does it mean? The guide requires the optimizer to be wrapped in the way above. I am quite confused... \r\nFYI, the following is the model I built up.\r\n```\r\nclass C3BR(tf.keras.Model):\r\n    ''' 3D Convolution + Batch Normalisation + Relu '''\r\n    def __init__(self, filterNum, kSize, strSize, padMode):\r\n        super(C3BR, self).__init__()\r\n        self.conv = layers.Conv3D(filters=filterNum, kernel_size=kSize, strides=strSize, padding=padMode, data_format='channels_first')\r\n        self.BN = layers.BatchNormalization(axis=1)\r\n    \r\n    def call(self, inputs, ifTrain=False):\r\n        x = self.conv(inputs)\r\n        if ifTrain == True:\r\n            x = self.BN(x)\r\n        return activations.relu(x)\r\n\r\n    def build_model(self, input_shape):\r\n        ''' A work-around to define dimensions of signals through the NN'''\r\n        self.build(input_shape)\r\n        inputs = tf.keras.Input(shape=input_shape[1:])\r\n        _ = self.call(inputs) \r\n\r\n\r\nclass SimpleUNet(tf.keras.Model):\r\n    \"\"\"\r\n    Input:\r\n        inDim: (for initialisation) [modaility/channel, tensor dimensions]\r\n        classNum: background included\r\n        name: name for the net\r\n        inputs: 5D tf tensor of [mbSize, modaility/channel, tensor dimensions]. Inputs must be organised into channel first order\r\n        input_shape: a 1X5 tuple (mbSize, modaility/channel, tensor dimensions)\r\n        ifTrain: True for training, and False for validation and testing\r\n    Returns:\r\n        outputs: 5D tf tensor of [mbSize, classNum, tensor dimensions]\r\n    \"\"\"\r\n    def __init__(self, inDim, classNum):\r\n        super(SimpleUNet, self).__init__()\r\n        self.inDim = inDim\r\n        self.classNum = classNum\r\n        dimEnSt1End = np.array(inDim)[1:]-2-2\r\n        dimEnSt2Ed = dimEnSt1End/2-2-2\r\n        dimBridgeEnd = (dimEnSt2Ed/2-2-2)*2\r\n        dimDEStd1End = (dimBridgeEnd-2-2)*2\r\n        self.outDim = dimDEStd1End-2-2-2\r\n        temp = ((dimEnSt2Ed - dimBridgeEnd)/2).astype('int32')\r\n        crop3d1 = tuple(np.tile(temp, (2, 1)).T)\r\n        temp = ((dimEnSt1End - dimDEStd1End)/2).astype('int32')\r\n        crop3d2 = tuple(np.tile(temp, (2, 1)).T)\r\n\r\n        self.en_st1_cbr1 = C3BR(32, 3, 1, 'valid')\r\n        self.en_st1_cbr2 = C3BR(64, 3, 1, 'valid')\r\n        self.en_st2_mp = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', data_format='channels_first')\r\n        self.en_st2_cbr1 = C3BR(128, 3, 1, 'valid')\r\n        self.en_st2_cbr2 = C3BR(128, 3, 1, 'valid')\r\n        self.bridge_mp = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', data_format='channels_first')\r\n        self.bridge_cbr1 = C3BR(256, 3, 1, 'valid')\r\n        self.bridge_cbr2 = C3BR(256, 3, 1, 'valid')    \r\n        self.bridge_tconv1 = layers.Conv3DTranspose(512, 2, strides=2, padding='valid', data_format='channels_first')\r\n        self.de_3dcrop1 = layers.Cropping3D(crop3d1, data_format='channels_first')\r\n        self.de_st1_concat = layers.Concatenate(axis=1)\r\n        self.de_st1_cbr1 = C3BR(256, 3, 1, 'valid')\r\n        self.de_st1_cbr2 = C3BR(128, 3, 1, 'valid')    \r\n        self.de_st1_tconv1 = layers.Conv3DTranspose(128, 2, strides=2, padding='valid', data_format='channels_first')\r\n        self.de_3dcrop2 = layers.Cropping3D(crop3d2, data_format='channels_first')\r\n        self.de_st2_concat = layers.Concatenate(axis=1)\r\n        self.de_st2_cbr1 = C3BR(64, 3, 1, 'valid')\r\n        self.de_st2_cbr2 = C3BR(64, 3, 1, 'valid') \r\n        self.final_conv3D = layers.Conv3D(filters=self.classNum, kernel_size=3, strides=1, padding='valid', data_format='channels_first')                \r\n        self.output_layer = layers.Activation('softmax', dtype='float32')\r\n    \r\n    #@tf.function\r\n    # In fact, decorating it does not bring much benefit as it primarily contains large ops. that have been optimised by tf.\r\n    def call(self, inputs, ifTrain=False):\r\n        x0 = self.en_st1_cbr1(inputs, ifTrain)\r\n        xEnSt1End = self.en_st1_cbr2(x0, ifTrain)\r\n        x1 = self.en_st2_mp(xEnSt1End)\r\n        x2 = self.en_st2_cbr1(x1, ifTrain)\r\n        xEnSt2Ed = self.en_st2_cbr2(x2, ifTrain)\r\n        x3 = self.bridge_mp(xEnSt2Ed)  \r\n        x4 = self.bridge_cbr1(x3, ifTrain)\r\n        x5 = self.bridge_cbr2(x4, ifTrain)    \r\n        xBridgeEnd = self.bridge_tconv1(x5)\r\n        xCrop1 = self.de_3dcrop1(xEnSt2Ed)\r\n        x6 = self.de_st1_concat([xBridgeEnd, xCrop1])\r\n        x7 = self.de_st1_cbr1(x6, ifTrain)\r\n        x8 = self.de_st1_cbr2(x7, ifTrain)\r\n        xDeSt1End = self.de_st1_tconv1(x8)\r\n        xCrop2 = self.de_3dcrop2(xEnSt1End)\r\n        x9 = self.de_st2_concat([xDeSt1End, xCrop2])\r\n        x10 = self.de_st2_cbr1(x9, ifTrain)\r\n        x11 = self.de_st2_cbr2(x10, ifTrain)\r\n        x12 = self.final_conv3D(x11)\r\n        outputs = self.output_layer(x12)\r\n        \r\n        return outputs\r\n        \r\n    def build_model(self, input_shape):\r\n        ''' A work-around to permit one to see dimensions of signals through the NN. An imperative API does not support it\r\n            by its own right\r\n        '''\r\n        self.build(input_shape)\r\n        inputs = tf.keras.Input(shape=input_shape[1:])\r\n        _ = self.call(inputs)\r\n        \r\n    def compute_output_shape(self):\r\n        ''''Override this function if one expects to use the subclassed model in Kera's fit() method; Otherwise, it is optional.\r\n        '''\r\n        return tf.TensorShape(np.append(self.classNum, self.outDim))    \r\n\r\n```", "comments": ["@yourtheron \r\n\r\nWhich version of Tensorflow you are using?.Please provide details about what platform you are using (operating system, architecture). Looks like code is incomplete. Request you to provide simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.I tried reproducing the issue with TF 2.0.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/15d4f2270e8f1638b1b57decb277d08e/untitled528.ipynb).Thanks!", "@ravikyram \r\nOS: Windows 7\r\nTF: 2.0.0\r\nPython: 3.7.5\r\nIDE: Spyder\r\nGPU: QuadroK620M\r\nTo call TUNet, just use a dummy signal\r\n`x = tf.random.uniform((mbSize,)+modelInDim, dtype=tf.float32)`\r\nThe issue occurs when I call\r\n`TUNet.compile(loss=softDiceLoss, optimizer=curOpt)`\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\nimport numpy as np\r\nfrom tensorflow.keras import layers, activations\r\n\r\n@tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32), tf.TensorSpec(shape=None, dtype=tf.uint8)])\r\ndef softDiceLoss(yPred, yTrue):\r\n    '''\r\n    SoftDiceLoss calculates multi-class soft dice loss\r\n    loss = avg_batch(1-(sum(W_k*sum(yPred.*yTrue)))/(sum(W_ksum(yPred^2+yTrue^2))))\r\n    where W_k = 1/(number of voxels in class k)^2\r\n    Class number of segmented regions includes background\r\n    Input:\r\n        yPred/yTrue: prediced and desired outputs shaped as [mbSize, classNum, tensor dimensions]. Also, both must be float-point\r\n    Return:\r\n        loss: a scalar tensor\r\n    '''\r\n    epsilon = 1e-16 \r\n    yTrue =tf.dtypes.cast(yTrue, dtype=yPred.dtype)\r\n    # Dot product yPred and yTrue and sum them up for each datum and class\r\n    crossProd=tf.multiply(yPred, yTrue)\r\n    # As a symbolic tensor, dimensions and shapes etc. cannot be extracted from data, nor can it be used in subroutines.\r\n    crossProdSum=tf.math.reduce_sum(crossProd, axis=np.arange(2, 5)) #tf.rank(yTrue)))\r\n    # Calculate weight for each datum and class \r\n    weight = tf.math.reduce_sum(yTrue, axis=np.arange(2, 5))#tf.rank(yTrue)))\r\n    weight = tf.math.divide(1, tf.math.square(weight)+epsilon)\r\n    # Weighted sum over classes\r\n    numerator = 2*tf.math.reduce_sum(tf.multiply(crossProdSum, weight), axis=1)\r\n    # Saquared summation \r\n    yySum = tf.math.reduce_sum(tf.math.square(yPred) + tf.math.square(yTrue), axis=np.arange(2, 5))#tf.rank(yTrue)))\r\n    # Weighted sum over classes\r\n    denominator = tf.math.reduce_sum(tf.multiply(weight, yySum), axis=1)\r\n    # Get individual loss and average over minibatch\r\n    loss = tf.math.reduce_mean(1 - tf.math.divide(numerator, denominator+epsilon))\r\n    \r\n    return loss\r\n\r\n```\r\nI also have three pertinent questions. \r\n1) If I use mixed preicision. Suppose my original input is of float32, do I have to manually cast it into float16?\r\n2) The doc instructs setting the output layer to be float32. layers.Activation(...) does not support setting axis=1 (my data is channel first), and if I use activations.softmax(...), it does not support manually setting dtype=float32, as I mentioned in another [issue](https://github.com/tensorflow/tensorflow/issues/35537)\r\nAny solution or work-around? \r\n3. Is the way I set the input signature of softDiceLoss(...) correct? or shall I write it like\r\n`@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.float32), tf.TensorSpec(shape=[None], dtype=tf.uint8),))` The online doc is a bit confusing\r\nThanks.", "Further more, as per the doc [here](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer?version=stable#minimize) , beside using CurOpt.get_scaled_loss(...) and CurOpt.get_unscaled_gradients(...), for example\r\n```\r\ncurOpt = mixed_precision.LossScaleOptimizer(curOpt, loss_scale='dynamic')\r\nepoch = 1\r\nfor ep in range(epoch):\r\n    print('Start of epoch %d' % (ep,))\r\n    # Each step crosses one minibatch\r\n    for step, data in enumerate(dsTrain):    \r\n\t\twith tf.GradientTape() as tape:\r\n\t\t\tyPred = model(data[0], ifTrain=True)\r\n\t\t\tloss = lossFunc(yPred, data[1])\r\n\t\t\tscaledLoss = optimizer.get_scaled_loss(curLoss)\r\n\t\tscaledGradients = tape.gradient(scaledLoss, model.trainable_variables)\r\n\t\tgradients = optimizer.get_unscaled_gradients(scaledGradients)\r\n\t\toptimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n```\r\nCan the two code snippets below be performed instead without using tf.GradientTape()? Are they equivalent, with/without mixed precision? I want to know that because it seems the following two provide a unified API for cases of using mixed precision or not.\r\n```\r\n# Code Snippet 1\r\ncurOpt = mixed_precision.LossScaleOptimizer(curOpt, loss_scale='dynamic')\r\nepoch = 1\r\nfor ep in range(epoch):\r\n    print('Start of epoch %d' % (ep,))\r\n    # Each step crosses one minibatch\r\n    for step, data in enumerate(dsTrain):        \r\n        yPred = TUNet(data[0])\r\n        loss = softDiceLoss(yPred, data[1])\r\n        gradients = curOpt.get_gradients(loss, TUNet.trainable_variables)\r\n        curOpt.apply_gradients(zip(gradients, TUNet.trainable_variables))  \r\n\r\n\r\n# Code Snippet 2\r\ncurOpt = mixed_precision.LossScaleOptimizer(curOpt, loss_scale='dynamic')\r\nepoch = 1\r\nfor ep in range(epoch):\r\n    print('Start of epoch %d' % (ep,))\r\n    # Each step crosses one minibatch\r\n    for step, data in enumerate(dsTrain):        \r\n        yPred = TUNet(data[0])\r\n        loss = softDiceLoss(yPred, data[1])\r\n        CurOpt.minimize(loss, TUNet.trainable_variables)\r\n```\r\nSorry for so many basic questions, I am trying my best to climb the mountain of tf2.0 now. Thanks again, indeed!", "@gowthamkpr As per [NVIDIA's guide](https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html) probably I should not have called model.compile(...) method after wrapping my optimizer by mixed_precision.LossScaleOptimizer(optimizer), but directly start training, because I use a graph-based code not Keras. Do you think so?\r\n![\u6355\u83b7](https://user-images.githubusercontent.com/51472988/71806031-c97c7c00-3035-11ea-9337-4b0f86c39267.JPG)\r\nAnother point is that NVIDIA sugests about using tf.train.experimental.enable_mixed_precision_graph_rewrite() to wrap the optimizer in lieu of mixed_precision.LossScaleOptimizer(). What is the difference between the two? I am aware that my GPU is too old to use the first one, but tf' doc says using the second one may at least enable me to double my batch size.", "Sorry for the late response. I answered your questions below. Let me know if you have any more questions.\r\n\r\n> The following warning pops out\r\n> \r\n> ```\r\n> TUNet.compile(loss=softDiceLoss, optimizer=curOpt)\r\n> WARNING:tensorflow:LossScale of LossScaleOptimizer passed to compile (DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)) is not the same as the dtype policy's loss scale (DynamicLossScale(current_loss_scale=32768.0, num_good_steps=0, initial_loss_scale=32768.0, increment_period=2000, multiplier=2.0)). Because the dtype policy has a loss scale, you should pass an optimizer that is not wrapped with a LossScaleOptimizer,\r\n> ```\r\n> \r\n> What does it mean? The guide requires the optimizer to be wrapped in the way above. I am quite confused...\r\n\r\nThis warning is poorly worded, and you can safely ignore it. If you want to know the technical details, what is happening is as follows. You set the policy to `mixed_float16` and use a `LossScaleOptimizer`. The `LossScaleOptimizer` automatically creates a `DynamicLossScale` object since you passed the string `dynamic`. However, when you call `TUNet.compile`, it automatically tries to convert the optimizer to a `LossScaleOptimizer` with a different `DynamicLossScale` object, since the policy is `mixed_float16` which has `DynamicLossScale`. Since you already passed a `LossScaleOptimizer`, it gives a warning.\r\n\r\nI will try to see how I can rework this error message, as it's too confusing. If you call `Model.fit`, you can fix by not wrapping the optimizer with a `LossScaleOptimizer`. If you do not call fit, you do need to wrap with a `LossScaleOptimizer` but you (probably) do not need to call `compile`.\r\n\r\n> If I use mixed preicision. Suppose my original input is of float32, do I have to manually cast it into float16?\r\n\r\nTypically no. The following lines will cause every Keras layer to cast their inputs to float16, so you do not have to do any casting.\r\n```\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\n```\r\n> The doc instructs setting the output layer to be float32. layers.Activation(...) does not support setting axis=1 (my data is channel first), and if I use activations.softmax(...), it does not support manually setting dtype=float32, as I mentioned in another issue\r\n\r\nI responded to that issue directly.\r\n\r\n> Is the way I set the input signature of softDiceLoss(...) correct? or shall I write it like\r\n@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.float32), tf.TensorSpec(shape=[None], dtype=tf.uint8),)) The online doc is a bit confusing\r\nThanks.\r\n\r\nPassing `shape=None` means the shape can be anything, such as `[2]` or `[3, 4]`. Passing `shape=[None]` means the shape must only have at least one component, or in other words, in the form of `[???]` where `???` can be any number. This means `[2]` would be acceptable but not `[3, 4]`. Assuming you always pass tensors with one component in their shape, I think the two forms have no practical difference, although `shape=[None]` may have a performance benefit. I'm not an expert on this.\r\n\r\n> Can the two code snippets below be performed instead without using tf.GradientTape()? Are they equivalent, with/without mixed precision? I want to know that because it seems the following two provide a unified API for cases of using mixed precision or not.\r\n\r\nYes, all three of those examples are correct. `curOpt.get_gradients` and `curOpt.minimize` automatically apply loss scaling when called on a LossScaleOptimizer, so you do not have to do extra work. However, when you use a `tf.GradientTape`, you must call `get_scaled_loss and `get_unscaled_gradients` (as you correctly did in the first example), since the GradientTape does not know about loss scaling. In general, if you compute gradients through the LossScaleOptimizer, you don't have to manually scale the loss and unscale gradients. If you compute gradient tapes through a GradientTape, you do have to manually scale the loss and unscale gradients.\r\n\r\n> Another point is that NVIDIA sugests about using tf.train.experimental.enable_mixed_precision_graph_rewrite() to wrap the optimizer in lieu of mixed_precision.LossScaleOptimizer(). What is the difference between the two? I am aware that my GPU is too old to use the first one, but tf' doc says using the second one may at least enable me to double my batch size.\r\n\r\nThis is complicated, and I will definitely clarify this in a doc in the future. The `enable_mixed_precision_graph_rewrite` function recommends is **completely separate** from the `mixed_precision.set_policy` API. You can use one API or the other, but not both because they both do the same thing. I recommend not using `enable_mixed_precision_graph_rewrite`, and we will deprecate and remove it in the future (although it will be accessible under the `tf.compat.v1` namespace for a long time). Instead use `mixed_precision.set_policy`. \r\n\r\n`enable_mixed_precision_graph_rewrite` causes the graph to be rewritten under the hood by the TensorFlow C++ backend to use mixed precision. `mixed_precision.set_policy('mixed_float16')` causes Keras layers to use mixed precision through `tf.cast` ops. The one shared component between the APIs is the LossScaleOptimizer. `enable_mixed_precision_graph_rewrite`  returns a LossScaleOptimizer, and you have to use it just as you do in the `mixed_precision.set_policy` API.\r\n\r\nAs `enable_mixed_precision_graph_rewrite` rewrites the graph, it does not work in Eager mode as there is no graph. Additionally, as it operates on the C++ backend, querrying `tensor.dtype` will always return float32 since the float16 happens on the C++ layer. Finally, you cannot override a dtype of a layer to float32 easily with the graph rewrite. On the other hand, `enable_mixed_precision_graph_rewrite` will never result in a TypeError, works outside of Keras as well as inside, and can more effectively determine the optimal dtypes of ops since it can look at the whole graph at once. The Keras `mixed_precision.set_policy` is recommended over the `enable_mixed_precision_graph_rewrite`.", "@reedwm, thank you so much for your detailed explanation! Everything is clear to me now!"]}, {"number": 35527, "title": "Python Crashes When Trying to Reload Weights from a Subclassed Model", "body": "OS: Windows 7\r\nPython Version: 3.7.5\r\nIDE: Spyder 4.0.0\r\n\r\nI built a subclassed model, which can run custom training loops properly, and I saved weights by\r\n```\r\nep=0  \r\ncurTime = strftime(\"%H-%M-%S-%d-%m-%Y\", gmtime())\r\nfullPath =  os.path.join(e:, 'Weight_' + curTime + '_Ep' + str(ep).zfill(5))\r\nos.makedirs(fullPath)\r\nmodel.save_weights(os.path.join(fullPath, 'Weight'), save_format='tf')\r\n```\r\nThen I tried to load weights as per instructions of tf's in the last section of\r\n(https://www.tensorflow.org/guide/keras/save_and_serialize#saving_subclassed_models)\r\n\r\nby firstly rebuilding the model's architecture, compiling it, training one sample, then\r\n```\r\npath = r'...\\TUNet_Test\\Weight_03-01-46-02-01-2020_Ep00000'\r\nmodel.load_weights(path)\r\n```\r\nI tried several times, but at this moment Python crashes by reporting\r\n```\r\n  Event Name:\tAPPCRASH\r\n  Application Name:\tpythonw.exe\r\n  Application Version:\t3.7.5150.1013\r\n  Application Time Stamp:\t5dbb41e3\r\n  Error Module Name:\t_pywrap_tensorflow_internal.pyd\r\n```\r\nWhat is saved in the folder is as follows:\r\n![\u6355\u83b7](https://user-images.githubusercontent.com/51472988/71650720-fa7f4880-2ce5-11ea-9928-3451bf6c5b3f.JPG)\r\n\r\nDid I make any mistake or is it an internal issue of tensorflow?", "comments": ["@yourtheron ,\r\nCan you share the code used to replicate  issue from our end?Also mention the TF version being used.Thanks!", "```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport functools\r\n\r\nimport os\r\nfrom time import gmtime, strftime\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, activations\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass C3BR(tf.keras.Model):\r\n    ''' 3D Convolution + Batch Normalisation + Relu '''\r\n    def __init__(self, filterNum, kSize, strSize, padMode):\r\n        super(C3BR, self).__init__()\r\n        self.conv = layers.Conv3D(filters=filterNum, kernel_size=kSize, strides=strSize, padding=padMode, data_format='channels_first')\r\n        self.BN = layers.BatchNormalization(axis=1)\r\n    \r\n    def call(self, inputs, ifTrain=False):\r\n        x = self.conv(inputs)\r\n        if ifTrain == True:\r\n            x = self.BN(x)\r\n        return activations.relu(x)\r\n\r\n    def build_model(self, input_shape):\r\n        ''' A work-around to define dimensions of signals through the NN'''\r\n        self.build(input_shape)\r\n        inputs = tf.keras.Input(shape=input_shape[1:])\r\n        _ = self.call(inputs) \r\n\r\n\r\nclass SimpleUNet(tf.keras.Model):\r\n    \"\"\"\r\n    Serialise basic units so as to build up a double-layered encoder-decoder U-Net. There are many forms of U-Net. Sometimes \r\n    people replace Max Pooling with stride=2; and only 1 C3BR is contained in each encoder/decoder, and only 3DTransposeConv\r\n    is used in decoder. \r\n    NVIDIA Tensor Cores in GPU's require certain dimensions of tensors to be a multiple of 8, so it is a best practice to choose\r\n    units in dense layers, numbers of feature mapes in convolutional layers, as well as sizes of minibatches to comply with the\r\n    requirement.Regardless of what model ends in, make sure the output is float32\r\n    Input:\r\n        inDim: (for initialisation) [modaility/channel, tensor dimensions]\r\n        classNum: background included\r\n        name: name for the net\r\n        inputs: 5D tf tensor of [mbSize, modaility/channel, tensor dimensions]. Inputs must be organised into channel first order\r\n        input_shape: a 1X5 tuple (mbSize, modaility/channel, tensor dimensions)\r\n        ifTrain: True for training, and False for validation and testing\r\n    Returns:\r\n        outputs: 5D tf tensor of [mbSize, classNum, tensor dimensions]\r\n    \"\"\"\r\n    def __init__(self, inDim, classNum):\r\n        super(SimpleUNet, self).__init__()\r\n        self.inDim = inDim\r\n        self.classNum = classNum\r\n        dimEnSt1End = np.array(inDim)[1:]-2-2\r\n        dimEnSt2Ed = dimEnSt1End/2-2-2\r\n        dimBridgeEnd = (dimEnSt2Ed/2-2-2)*2\r\n        dimDEStd1End = (dimBridgeEnd-2-2)*2\r\n        self.outDim = dimDEStd1End-2-2-2\r\n        temp = ((dimEnSt2Ed - dimBridgeEnd)/2).astype('int32')\r\n        crop3d1 = tuple(np.tile(temp, (2, 1)).T)\r\n        temp = ((dimEnSt1End - dimDEStd1End)/2).astype('int32')\r\n        crop3d2 = tuple(np.tile(temp, (2, 1)).T)\r\n\r\n        self.en_st1_cbr1 = C3BR(32, 3, 1, 'valid')\r\n        self.en_st1_cbr2 = C3BR(64, 3, 1, 'valid')\r\n        self.en_st2_mp = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', data_format='channels_first')\r\n        self.en_st2_cbr1 = C3BR(128, 3, 1, 'valid')\r\n        self.en_st2_cbr2 = C3BR(128, 3, 1, 'valid')\r\n        self.bridge_mp = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', data_format='channels_first')\r\n        self.bridge_cbr1 = C3BR(256, 3, 1, 'valid')\r\n        self.bridge_cbr2 = C3BR(256, 3, 1, 'valid')    \r\n        self.bridge_tconv1 = layers.Conv3DTranspose(512, 2, strides=2, padding='valid', data_format='channels_first')\r\n        self.de_3dcrop1 = layers.Cropping3D(crop3d1, data_format='channels_first')\r\n        self.de_st1_concat = layers.Concatenate(axis=1)\r\n        self.de_st1_cbr1 = C3BR(256, 3, 1, 'valid')\r\n        self.de_st1_cbr2 = C3BR(128, 3, 1, 'valid')    \r\n        self.de_st1_tconv1 = layers.Conv3DTranspose(128, 2, strides=2, padding='valid', data_format='channels_first')\r\n        self.de_3dcrop2 = layers.Cropping3D(crop3d2, data_format='channels_first')\r\n        self.de_st2_concat = layers.Concatenate(axis=1)\r\n        self.de_st2_cbr1 = C3BR(64, 3, 1, 'valid')\r\n        self.de_st2_cbr2 = C3BR(64, 3, 1, 'valid') \r\n        self.final_conv3D = layers.Conv3D(filters=self.classNum, kernel_size=3, strides=1, padding='valid', data_format='channels_first')                \r\n    \r\n    # @tf.function\r\n    # In fact, decorating it does not bring much benefit as it primarily contains large ops. that have been optimised by tf.\r\n    def call(self, inputs, ifTrain=False):\r\n        x0 = self.en_st1_cbr1(inputs, ifTrain)\r\n        xEnSt1End = self.en_st1_cbr2(x0, ifTrain)\r\n        x1 = self.en_st2_mp(xEnSt1End)\r\n        x2 = self.en_st2_cbr1(x1, ifTrain)\r\n        xEnSt2Ed = self.en_st2_cbr2(x2, ifTrain)\r\n        x3 = self.bridge_mp(xEnSt2Ed)  \r\n        x4 = self.bridge_cbr1(x3, ifTrain)\r\n        x5 = self.bridge_cbr2(x4, ifTrain)    \r\n        xBridgeEnd = self.bridge_tconv1(x5)\r\n        xCrop1 = self.de_3dcrop1(xEnSt2Ed)\r\n        x6 = self.de_st1_concat([xBridgeEnd, xCrop1])\r\n        x7 = self.de_st1_cbr1(x6, ifTrain)\r\n        x8 = self.de_st1_cbr2(x7, ifTrain)\r\n        xDeSt1End = self.de_st1_tconv1(x8)\r\n        xCrop2 = self.de_3dcrop2(xEnSt1End)\r\n        x9 = self.de_st2_concat([xDeSt1End, xCrop2])\r\n        x10 = self.de_st2_cbr1(x9, ifTrain)\r\n        x11 = self.de_st2_cbr2(x10, ifTrain)\r\n        x12 = self.final_conv3D(x11)\r\n        outputs = tf.dtypes.cast(activations.softmax(x12, axis=1), dtype=tf.float32)\r\n        \r\n        return outputs\r\n        \r\n    def build_model(self, input_shape):\r\n        ''' A work-around to permit one to see dimensions of signals through the NN. An imperative API does not support it\r\n            by its own right\r\n        '''\r\n        self.build(input_shape)\r\n        inputs = tf.keras.Input(shape=input_shape[1:])\r\n        _ = self.call(inputs)\r\n        \r\n    def compute_output_shape(self):\r\n        ''''Override this function if one expects to use the subclassed model in Kera's fit() method; Otherwise, it is optional.\r\n        '''\r\n        return tf.TensorShape(np.append(self.classNum, self.outDim))    \r\n\r\n\r\n\r\n@tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32), tf.TensorSpec(shape=None, dtype=tf.uint8)])\r\ndef softDiceLoss(yPred, yTrue):\r\n    '''\r\n    SoftDiceLoss calculates multi-class soft dice loss\r\n    loss = avg_batch(1-(sum(W_k*sum(yPred.*yTrue)))/(sum(W_ksum(yPred^2+yTrue^2))))\r\n    where W_k = 1/(number of voxels in class k)^2\r\n    Class number of segmented regions includes background\r\n    Input:\r\n        yPred/yTrue: prediced and desired outputs shaped as [mbSize, classNum, tensor dimensions]. Also, both must be float-point\r\n    Return:\r\n        loss: a scalar tensor\r\n    '''\r\n    epsilon = 1e-16 \r\n    yTrue =tf.dtypes.cast(yTrue, dtype=yPred.dtype)\r\n    # Dot product yPred and yTrue and sum them up for each datum and class\r\n    crossProd=tf.multiply(yPred, yTrue)\r\n    # As a symbolic tensor, dimensions and shapes etc. cannot be extracted from data, nor can it be used in subroutines.\r\n    crossProdSum=tf.math.reduce_sum(crossProd, axis=np.arange(2, 5)) #tf.rank(yTrue)))\r\n    # Calculate weight for each datum and class \r\n    weight = tf.math.reduce_sum(yTrue, axis=np.arange(2, 5))#tf.rank(yTrue)))\r\n    weight = tf.math.divide(1, tf.math.square(weight)+epsilon)\r\n    # Weighted sum over classes\r\n    numerator = 2*tf.math.reduce_sum(tf.multiply(crossProdSum, weight), axis=1)\r\n    # Saquared summation \r\n    yySum = tf.math.reduce_sum(tf.math.square(yPred) + tf.math.square(yTrue), axis=np.arange(2, 5))#tf.rank(yTrue)))\r\n    # Weighted sum over classes\r\n    denominator = tf.math.reduce_sum(tf.multiply(weight, yySum), axis=1)\r\n    # Get individual loss and average over minibatch\r\n    loss = tf.math.reduce_mean(1 - tf.math.divide(numerator, denominator+epsilon))\r\n    \r\n    return loss\r\n\r\n@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.float32), tf.TensorSpec(shape=[None], dtype=tf.uint8),))\r\ndef calcAcc(yPred, yTrue):\r\n    '''\r\n    Calculate accuracy class by class. For each class, only an identical label on the voxel belonging to the corresponding class \r\n    (1 in yTrue[class] and 0 in ~yTrue[class]) is considered being correctly identified, that is,\r\n    Acc = (TP +TN) / (TP + FP + TN + FN), where \r\n    TP = sum(yPred.*YTrue); whilst TN = sum((1-yPred).*(1-yTrue))\r\n    Input:\r\n        yPred/yTrue: prediced and desired outputs shaped as [mbSize, classNum, tensor dimensions]. Also, both must be float-point\r\n    Return:\r\n        acc: a 1XclassNum tensor indicating the accuracy over each class (background included). For dichotmous segmentation, \r\n        the two resulting accuracies are equal\r\n    '''\r\n    yTrue = tf.dtypes.cast(yTrue, dtype=yPred.dtype)\r\n    yPredInt = tf.round(yPred)\r\n    acc = 2 * tf.math.reduce_sum(tf.math.multiply(yPredInt, yTrue), axis=np.arange(2, tf.rank(yTrue)))\r\n    acc -= tf.math.reduce_sum(yPredInt+yTrue, axis=np.arange(2, tf.rank(yTrue)))\r\n    acc = acc/tf.dtypes.cast(tf.math.reduce_prod(tf.shape(yTrue)[2:]), dtype=yPred.dtype)\r\n    acc += 1\r\n    \r\n    return tf.math.reduce_mean(acc, axis=0)\r\n\r\n## For debugging tf.functions\r\ntf.config.experimental_run_functions_eagerly(True)\r\n## Hyper-paras for data\r\n# number of segmented classes including background\r\nclassNum = 2\r\nmodalNum = 4\r\nimgPatchSize = [64, 64, 64]\r\nlabelPatchSize=[22, 22, 22]\r\n\r\n## Hyper-paras for model and training\r\nmodelInDim = (modalNum,) + tuple(imgPatchSize)\r\nepoch = 10\r\nmbSize = 1\r\nlr = 1e-4\r\nlossFunc = softDiceLoss\r\naccFunc = calcAcc\r\ncurOpt = tf.keras.optimizers.Adam(learning_rate=lr)\r\nsaveOpt =[True, 10, 'w', r'.\\TUNet_Test', ]\r\n\r\nTUNet = SimpleUNet(modelInDim, classNum)\r\nTUNet.build_model(input_shape=(mbSize,)+modelInDim)\r\nTUNet.summary()\r\n\r\n@tf.function\r\ndef trainOneSample(data, model, optimizer, lossFunc, accFunc):\r\n    ''' Evaluate model to produce generalised error/accuracy\r\n    Input:\r\n        data: one pair of serialised input and label from dataset\r\n        model: an NN model for the inference       \r\n        optimizer: an optimiser configuration used for the model\r\n        lossFunc/accFunc: names of loss and accuracy functions\r\n    Return:\r\n        totalLoss/total/Acc: two vectors of loss and accuracy of each test input \r\n    '''\r\n    with tf.GradientTape() as tape:\r\n        yPred = model(data[0], ifTrain=True)\r\n        # Calculate loss and accuracy\r\n        curLoss = lossFunc(yPred, data[1])\r\n        curAcc = accFunc(yPred, data[1])\r\n    gradients = tape.gradient(curLoss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n    return curLoss, curAcc\r\n\r\nfor ep in np.arange(epoch):\r\n\r\n\t# Each step crosses one minibatch\r\n\tfor stepTr, data in enumerate(dsTrain):\r\n\t\tcurLoss, curAcc = trainOneSample(data, TUNet, curPot, softDiceLoss, calcAcc)\r\n\r\n\tif saveOpt[0] == True and ep % saveOpt[1] == 0:\r\n\t\tcurTime = strftime(\"%H-%M-%S-%d-%m-%Y\", gmtime())\r\n\t\tif saveOpt[2] == 'M' or saveOpt[2] == 'm':\r\n\t\t\tprint('Save model at ' + curTime)\r\n\t\t\tif ep == 0:\r\n\t\t\t\t# Warm-up for saving model\r\n\t\t\t\tx = tf.random.uniform((mbSize, modalNum, 64, 64, 64), dtype=tf.float32)\r\n\t\t\t\t_ = TUNet(x, ifTrain=True)\r\n\t\t\t\tTUNet._set_inputs(x)    \r\n\t\t\tfullPath =  os.path.join(saveOpt[3], 'Model_' + curTime + '_Ep' + str(ep).zfill(5))\r\n\t\t\tos.makedirs(fullPath)\r\n\t\t\tmodel.save(fullPath, save_format='tf') \r\n\t\telse:\r\n\t\t\tprint('Save weights at ' + curTime)\r\n\t\t\t# Note the last string is name not folder\r\n\t\t\tfullPath =  os.path.join(saveOpt[3], 'Weight_' + curTime + '_Ep' + str(ep).zfill(5))\r\n\t\t\tos.makedirs(fullPath)\r\n\t\t\tmodel.save_weights(os.path.join(fullPath, 'Weight'), save_format='tf')\r\n\r\n```\r\nTF: 2.0.0\r\nGPU: QuadroK620M\r\ndsTrain is too big to be uploaded. \r\nWhat is contained in dsTrain is a series of pairs of tensors. Each pair includes two 5D tensors\r\n[None, 4, 64, 64, 64] in tf.float32, and [None, 2, 22, 22, 22] in tf.uint8\r\n\r\nBTW, I also found issues when trying to save model, (saveOpt[2] = 'M' ). After saving it in tf format, if I try to load the model\r\n![\u65e0\u6807\u9898](https://user-images.githubusercontent.com/51472988/71714273-27f9ee00-2ddb-11ea-8ccd-c5c4575f3fbb.png)\r\n\r\n` newModel= tf.keras.models.load_model(...path)`, tf prompted\r\n```\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (1 total):\r\n    * Tensor(\"input_1_5:0\", shape=(None, 4, 64, 64, 64), dtype=float32)\r\n  Keyword arguments: {'training': <tf.Tensor 'keras_learning_phase:0' shape=() dtype=bool>}\r\n\r\nExpected these arguments to match one of the following 2 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (3 total):\r\n    * TensorSpec(shape=(None, 4, 64, 64, 64), dtype=tf.float32, name='input_1')\r\n    * False\r\n    * False\r\n  Keyword arguments: {}\r\n\r\nOption 2:\r\n  Positional arguments (3 total):\r\n    * TensorSpec(shape=(None, 4, 64, 64, 64), dtype=tf.float32, name='input_1')\r\n    * False\r\n    * True\r\n  Keyword arguments: {}\r\n```\r\nThe last thing is that for subclassed models, such those in my case, do I have to do \r\n```\r\nx = tf.random.uniform((mbSize, modalNum, 64, 64, 64), dtype=tf.float32)\r\n_ = TUNet(x, ifTrain=True)\r\nTUNet._set_inputs(x)    \r\n```\r\neach time before saving it as a model in tf format? I found if I did not run _set_inputs(...), I was prompted that tf does not know information like the size etc., and the model seemed not to be instantiated, and I have to run it through some real signals. But the fact is, prior to saving, multiple training loops have elapsed. Any idea? Or in future version, can it be made simpler and easier?\r\n\r\nCould you also take a look, please? Many thanks.\r\nPlease note that my model SimpleUNet can run and be trained--working properly. And I can save and restore checkpoints correctly by using tf.train.Checkpoint(....) and tf.train.CheckpointManager(...)", "@yourtheron Can you please check the approach mentioned in this [response](https://github.com/tensorflow/tensorflow/issues/36362) or can you provide minimal example. It is difficult to check very long code. Thanks!", "@jvishnuvardhan My issue is the same as one in that post, so if the solution works for that one, it will work for mine", "@yourtheron The solution is working for the code in other post. Can you please check for your code. Please close the issue if it was resolved for you also. Thanks!", "I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!"]}, {"number": 35526, "title": "iOS Demo Pod install error", "body": "i can search \"Tensorflow\", but can not install example : https://github.com/tensorflow/examples/tree/master/lite/examples/gesture_classification/ios\r\n\r\nError info:\r\n![image](https://user-images.githubusercontent.com/3898789/71649968-f6871100-2d4d-11ea-9225-f2b90fb8991b.png)\r\n![image](https://user-images.githubusercontent.com/3898789/71649972-fab32e80-2d4d-11ea-9878-d6fbca7548b5.png)\r\n", "comments": ["As mentioned in [step 2](https://github.com/tensorflow/examples/tree/master/lite/examples/gesture_classification/ios#building-the-ios-demo-app) did you change your directory to `lite/examples/gesture_classification/ios`\r\nbefore running `pod install`", "not work\r\n<img width=\"702\" alt=\"\u5c4f\u5e55\u5feb\u7167 2020-01-03 \u4e0a\u534811 44 42\" src=\"https://user-images.githubusercontent.com/3898789/71706443-d758b400-2e1f-11ea-9f39-70464ccb2233.png\">\r\n", "Can you also try `pod install --repo-update --verbose`?\r\nAlso, what specific version of `pod` tool are you using?", "@WPDreamMelody \r\n\r\nAny update on this issue please.Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 35525, "title": "Correction in the course material", "body": "## Description of issue (what needs changing):\r\n\r\nDo we still need the `steps_per_epochs` parameter while fitting the model to training set?\r\nIn the tensorflow tutorial(which is very similar to the MNIST tutorial of Intro to Deep Learning course ), there is no such parameter...\r\n\r\n## URL(s) with the issue:\r\n\r\nUdacity Course Notebook : https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l03c01_classifying_images_of_clothing.ipynb#scrollTo=S5Uhzt6vVIB2\r\n\r\n-----------------------------------------------------------------\r\n![Screenshot from 2020-01-01 23-27-10](https://user-images.githubusercontent.com/29497701/71644446-78dfe880-2cee-11ea-9da7-5c033d8a0592.png)\r\n-----------------------------------------------------------------\r\n\r\nTensorflow Tutorial : \r\nhttps://www.tensorflow.org/tutorials/keras/classification/\r\n\r\n-----------------------------------------------------------------\r\n![Screenshot from 2020-01-01 23-26-50](https://user-images.githubusercontent.com/29497701/71644452-93b25d00-2cee-11ea-97af-70d0ece074d9.png)\r\n-----------------------------------------------------------------\r\n\r\n### Parameters defined\r\n\r\n`steps_per_epoch` parameter in `model.fit` should be removed??\r\n\r\n### Submit a pull request?\r\n\r\nI'll submit a PR right away if this issue is relevant...", "comments": ["While training over large datasets, It is not possible to load the entire dataset onto the memory at once, one approach used is to perform step wise training where we only show a fixed number of datapoints to the model at every epoch, here steps_per_epoch is used. Total points per epoch is equal to steps_per_epoch*batch_size.", "> Total points per epoch is equal to steps_per_epoch*batch_size.\r\n\r\nDear sir, If I understand correctly from the manual, \"`step_per_epoch = n_samples / batch_size`\" will not do augmentation, because it will simply iterate all the data once. If you want to augment the data, should you set `step_per_epoch = n*(n_samples / batch_size)` (where n = 2, 3, 4, ...)? \r\n\r\n", "@ManishAradwad As of now, we still need `steps_per_epoch` flag otherwise it will throw an error as follows\r\n`ValueError: When passing an infinitely repeating dataset, you must specify the steps_per_epoch argument.` May be in the later versions, it will be removed. Even in the course material you mentioned, `steps_per_epoch` flag is present  in the `model.fit` as shown below.\r\n\r\n`model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))`\r\n\r\nI am closing this issue. Please feel free to reopen the issue if there is any related issue. thanks!"]}, {"number": 35524, "title": "Suspected memory leak - when loading multiple models with tf.keras.models.load_model()", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNA\r\n- TensorFlow installed from (source or binary): binary wheel via PyPI\r\n- TensorFlow version (use command below):\r\n2.1.0-dev20191231 (v1.12.1-21412-g3a094e6 2.1.0-dev20191231)\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\nNA\r\n- GCC/Compiler version (if compiling from source):\r\nNA\r\n- CUDA/cuDNN version:\r\nCUDA 10.0 \r\n- GPU model and memory:\r\nV100 32 GB\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm suspecting a CPU memory leak when loading multiple models.\r\nWhen im running infinite loop that keeps loading the same model while using the same variable the memory (private bytes and working set) of the process keep increasing. At some points the working set seems to free some memory, but the trend is that the memory keeps on rising.\r\nI used a simple model (attached).\r\n\r\nThis trend happens even though I call gc.collect() on every iteration and tf.keras.backend.clear_session().\r\n\r\nthe issue also happens in TF 2.0 (v2.0.0-rc2-26-g64c3d38 2.0.0).\r\nfor a specific model:\r\n    running in TF 2.0 each iteration adds 16 MiB\r\n    running in TF 2.1 each iteration adds 2 MiB\r\n\r\n**Describe the expected behavior**\r\n\r\nThe memory shouldnt increase on each interation\r\n\r\n**Code to reproduce the issue**\r\n`\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport gc # garbage collector\r\nimport objgraph\r\nfrom memory_profiler import profile\r\n\r\ndef mem_stat():\r\n  objs = gc.get_objects()\r\n  print(\"total objects count\", len(objs))\r\n\r\n@profile\r\ndef profile_own_model():\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n        tf.keras.layers.Dense(128, activation='relu'),\r\n        tf.keras.layers.Dropout(0.2),\r\n        tf.keras.layers.Dense(10, activation='softmax')\r\n    ])\r\n    # model.save('my_model')\r\n    tf.keras.backend.clear_session()\r\n    del model\r\n    gc.collect()\r\n\r\n@profile\r\ndef profile_load_model(path):\r\n    model = tf.keras.models.load_model(model_path, compile=False)\r\n    tf.keras.backend.clear_session()\r\n    del model\r\n    gc.collect()\r\n\r\n\r\n\r\nmodel_path = f'/my_model.hd5'\r\nprint(\"load model in loops:\")\r\n\r\nc = 1\r\nwhile True:\r\n    print(\"----------- iter\", c)\r\n    profile_load_model(model_path)\r\n\r\n    print(\"mem stat after model creation:\")\r\n    mem_stat()\r\n    objgraph.show_growth(limit=30)\r\n    c += 1\r\n```\r\n`\r\n\r\n**Other info / logs**\r\n![memory tf 2 1](https://user-images.githubusercontent.com/27951762/71644038-d9f5c500-2cca-11ea-96e3-b8aedd2e4efb.png)\r\n\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n", "comments": ["@farotem, I tried reproducing the issue with Tf 2.1.but got different error message. Please find the [gist](https://colab.sandbox.google.com/gist/gadagashwini/71946c07f0ba1906fc249029847f4259/untitled335.ipynb) and confirm. Thanks!", "@gadagashwini hi I looked at the gist, \r\nit looks like the profiler can't work under Ipython environment, you can look at the memory with your own tools.\r\nto run the code just comment the memory_profiler part:\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport gc # garbage collector\r\nimport objgraph\r\n#from memory_profiler import profile\r\n\r\n```\r\n```\r\ndef mem_stat():\r\n    objs = gc.get_objects()\r\n    print(\"total objects count\", len(objs))\r\n\r\n#@profile\r\ndef profile_own_model():\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n        tf.keras.layers.Dense(128, activation='relu'),\r\n        tf.keras.layers.Dropout(0.2),\r\n        tf.keras.layers.Dense(10, activation='softmax')\r\n    ])\r\n    # model.save('my_model')\r\n    tf.keras.backend.clear_session()\r\n    del model\r\n    gc.collect()\r\n\r\n#@profile\r\ndef profile_load_model(path):\r\n    model = tf.keras.models.load_model(model_path, compile=False)\r\n    tf.keras.backend.clear_session()\r\n    del model\r\n    gc.collect()\r\n\r\nmodel_path = f'/my_model.hd5'\r\nprint(\"load model in loops:\")\r\n\r\nc = 1\r\nwhile True:\r\n    print(\"----------- iter\", c)\r\n    profile_load_model(model_path)\r\n\r\n    print(\"mem stat after model creation:\")\r\n    mem_stat()\r\n    objgraph.show_growth(limit=30)\r\n    c += 1\r\n\r\n````\r\n`\r\n", "Installing tf-nightly-gpu with \"pip install tf-nightly-gpu\" fixed the issue for me", "@farotem, I tried replicating the issue with commenting profile, looks like issue is related my_model file. Please find the [gist](https://colab.sandbox.google.com/gist/gadagashwini/4fcd1d5ae63b0f72dcc65076e10aad15/untitled338.ipynb?authuser=1). Can you try @retviews's suggestion and let us know how it progresses. Thanks!", "Hi I tried installing tf-nightly-gpu, version: 2.1.0.dev20200107\r\n**still** receives memory leaks in the CPU.\r\nnote 1:\r\nthe number of python objects doesn't seem to be the cause for the leak, after few iterations the number of python objects do not increase but the memory usage of the CPU is still increasing.\r\nnote 2: \r\nI tried loading the same model from json and **there are no memory leaks**.\r\nI think it means the memory leaks is somewhere in deserializing the model from folder.\r\n\r\nI looked at the gist, below is the fixed code: (changed the path of file)\r\n\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport gc # garbage collector\r\n\r\ndef build_and_save_own_model():\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n        tf.keras.layers.Dense(128, activation='relu'),\r\n        tf.keras.layers.Dropout(0.2),\r\n        tf.keras.layers.Dense(10, activation='softmax')\r\n    ])\r\n    model.save('my_model')\r\n    tf.keras.backend.clear_session()\r\n    del model\r\n    gc.collect()\r\n\r\ndef profile_load_model(path):\r\n    model = tf.keras.models.load_model(model_path, compile=False)\r\n    tf.keras.backend.clear_session()\r\n    del model\r\n    gc.collect()\r\n\r\nmodel_path = 'my_model'\r\nbuild_and_save_own_model()\r\nprint(\"load model in loops:\")\r\nc = 1\r\nwhile True:\r\n    print(\"----------- iter\", c)\r\n    profile_load_model(model_path)\r\n    c += 1\r\n```\r\n", "Issue is replicating on colab.\r\nPlease take a look at [gist](https://colab.research.google.com/drive/1TLk3pOxde4KERIBOEHE96hlfgNZOZA67?usp=sharing). Thanks!", "Is this still an issue with latest version of tensorflow (2.2)?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35524\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35524\">No</a>\n", "I'm having this same issue - any fix in the roadmap?", "I seem to be having this same issue on TF 2.3.", "tested on TF 2.3 same issue..", "This seems to be reduced with the latest tf-nightly, tested with [this colab notebook](https://colab.research.google.com/gist/idfah/dff83de8d2a6406c9b92221e6282a8d6/tf2_load_mem_leak.ipynb#scrollTo=5IhHO-wynZKC). \r\n\r\nSee also #40171 for more discussion.  ", "It is reduced but not fixed sadly its still an issue for our team\r\nI opened a new bug for nightly version (tf2. 4)\r\nhttps://github.com/tensorflow/tensorflow/issues/45453#issuecomment-740755898"]}, {"number": 35523, "title": "Tensorflow 2.0 (GPU) throws CancelledErrors while fitting models ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04 LTS**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**\r\n- TensorFlow installed from (source or binary): **source**\r\n- TensorFlow version (use command below): **r2.0**\r\n- Python version: **3.6.9**\r\n- Bazel version (if compiling from source): **0.26.0**\r\n- GCC/Compiler version (if compiling from source): **7.4.0**\r\n- CUDA/cuDNN version: **v10.1**\r\n- GPU model and memory: **GeForce RTX 2070 Super (8GB)**\r\n\r\n**Describe the current behavior**\r\nThe script throws a `CancelledError` when fitting the model (very 1st epoch)\r\n\r\n**Describe the expected behavior**\r\n`$ model.fit( ... )` is executed without throwing any errors.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nmodel = Sequential()\r\nmodel.add(Embedding(vocab_size, dimensions,weights=[embedding_matrix], input_length=pad2, trainable=True))\r\nmodel.add(GRU(128, return_sequences=True))\r\nmodel.add(MaxPooling1D())\r\nmodel.add(AveragePooling1D())\r\nmodel.add(GRU(128))\r\nmodel.add(Dense(len(set(outputs)), activation='sigmoid'))\r\ncheckpoint = ModelCheckpoint('model-%s-%s-%s-%s' %(setting, indicators, case, str(window_size)), verbose=1, monitor='val_acc', save_best_only=True, mode='auto')\r\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\nprint(model.summary())\r\n# The summary is as expected\r\ntrain, dev = padded_docs[:split], padded_docs[split:]\r\ny_train, y_dev = y[:split], y[split:]\r\nmodel.fit(train, y_train, epochs=epochs, verbose=1, callbacks=[checkpoint], batch_size=batch_size, validation_data=(dev, y_dev))\r\n# This is where the script fails\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-18-ba796bf236a0> in <module>\r\n     70         train, dev = padded_docs[:split], padded_docs[split:]\r\n     71         y_train, y_dev = y[:split], y[split:]\r\n---> 72         model.fit(train, y_train, epochs=epochs, verbose=1, callbacks=[checkpoint], batch_size=batch_size, validation_data=(dev, y_dev))\r\n     73         pred = model.predict(dev, batch_size=batch_size)\r\n     74         model.save('./cross-fold-models/model-%s-%s-%s-%s-%s' %(setting, indicators, case, str(window_size), str(number)))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    518         # Lifting succeeded, so variables are initialized and we can run the\r\n    519         # stateless function.\r\n--> 520         return self._stateless_fn(*args, **kwds)\r\n    521     else:\r\n    522       canon_args, canon_kwds = \\\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_45}}]]\r\n\t [[Reshape_14/_42]] [Op:__inference_distributed_function_18141]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```", "comments": ["I see that this error has been raised before: \r\n- [33721](https://github.com/tensorflow/tensorflow/issues/33721): Downgrading TF to 1.14 'solved' the issue. I cannot downgrade TF from 2.0\r\n- [33200](https://github.com/tensorflow/tensorflow/issues/33200): Fixing `gast` did **not** solve the issue.\r\n- [SO Question](https://stackoverflow.com/questions/58359153/cancellederror-derived-recvasync-is-cancelled): My CUDA version isn't an issue.\r\n\r\nSome more context:\r\n- To fix a previous issue about mismatched versions, I had to refer to [this](https://github.com/keras-team/keras/issues/12379#issuecomment-471339468) answer and append a `tensorflow` prefix to all my keras imports. \r\n", "I am having the same issue.", "@darthbhyrava \r\n\r\nLooks like code is incomplete. Request you to provide colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@darthbhyrava \r\nAny update on this issue please. Thanks!", "Not OP, but I am not longer receiving this issue\n\nOn Thu, Jan 16, 2020 at 9:58 PM ravikyram <notifications@github.com> wrote:\n\n> @darthbhyrava <https://github.com/darthbhyrava>\n> Any update on this issue please. Thanks!\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/35523?email_source=notifications&email_token=AHPAW4YETG5PSCBBOQQPSTDQ6EUE7A5CNFSM4KB3BUX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJGLVLY#issuecomment-575453871>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AHPAW43MMI7V6RJ4ULNJS7LQ6EUE7ANCNFSM4KB3BUXQ>\n> .\n>\n", "> @darthbhyrava\r\n> \r\n> Looks like code is incomplete. Request you to provide colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!\r\n\r\nThanks for the response, apologies for the delay in replying. \r\n\r\nI cannot provide supporting files or the entire code, they're proprietary in nature. However I can provide details for the parameters in the embedding layer, and the nature of the data set with simple examples:\r\n\r\n```\r\nfrom keras.preprocessing.text import Tokenizer\r\nfrom keras.preprocessing.sequence import pad_sequences\r\n\r\n# vocab_size\r\nt = Tokenizer(split=\" \",lower=True, filters='@')\r\nt.fit_on_texts(X)\r\nvocab_size = len(t.word_index) + 1\r\n\r\n# dimensions\r\ndimensions = 300\r\n\r\n# embedding_matrix\r\nembedding_matrix = np.zeros((vocab_size, dimensions))\r\n# zeros replaced with GloVe embeddings, shape remains same\r\n\r\n# pad2 and padded_docs\r\nencoded_docs = t.texts_to_sequences(X)\r\nmax_len = []\r\nfor each in encoded_docs:\r\n\tmax_len.append(len(each))\r\npad2 = max(max_len)\r\npadded_docs = pad_sequences(encoded_docs, maxlen=pad2, padding='post')\r\n\r\n# outputs\r\nNumber of labels for classification\r\n\r\n# y\r\nCorresponding labels for the input sequences\r\n```\r\nPlease let me know if additional info is needed.\r\n\r\nAlso, my workaround was to eventually downgrade tensorflow (to r1.15) and CUDA (to 10.0).\r\n", "@darthbhyrava As mentioned in the other [post](https://github.com/keras-team/keras/issues/12379#issuecomment-471339468), did you import modules from `tensorflow.keras.**any_sub_module`? If the issue was cleared by using tensorflow.keras.* then please close the issue. \r\n\r\nIf the issue is with keras module (if you are using `keras.**any_module`) , then please post it in the [`keras repository here](https://github.com/keras-team/keras/issues). If the issue persists even after importing modules from tensorflow.keras.**, then please use a public data to create a standalone code to reproduce the issue. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35523\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35523\">No</a>\n"]}, {"number": 35522, "title": "Add usage example for tf.math.polyval", "body": "Here is the proposed usage example for `tf.math.polyval`, a function for evaluating polynomial expressions given input and list of coefficients. My usage example consists of a basic numerical example, and a potential application in polynomial regression.", "comments": ["Thanks for the approval!", "Hi, I just checked the build details, and it looked like it has failed the following tests:\r\n\r\n2. do_pylint PYTHON2: Python 2 pylint\r\n  FAIL\r\n3. do_pylint PYTHON3: Python 3 pylint\r\n  FAIL\r\n\r\nThere seems to be a problem with pylint - how can this be fixed?", "It means pylint doesn't like your code. The error message should give you\ndetails about what is wrong.\n\nOn Thu, Jan 2, 2020 at 1:11 PM Qwerty71 <notifications@github.com> wrote:\n\n> Hi, I just checked the build details, and it looked like it has failed the\n> following tests:\n>\n>    1. do_pylint PYTHON2: Python 2 pylint\n>    FAIL\n>    2. do_pylint PYTHON3: Python 3 pylint\n>    FAIL\n>\n> There seems to be a problem with pylint - how can this be fixed?\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/35522?email_source=notifications&email_token=AAABHROABI4QTE3XBRKISPLQ3ZKBFA5CNFSM4KBZK5IKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEH7N4RQ#issuecomment-570351174>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLGOLJK5LRIVUPTPGTQ3ZKBFANCNFSM4KBZK5IA>\n> .\n>\n\n\n-- \n - Alex\n", "Ok, it should be fixed now.", "@Qwerty71 thank you, it is failing doctest can you please check here for [logs](https://source.cloud.google.com/results/invocations/e875da6c-c1cd-45e8-81bb-8bb92addb410/targets/%2F%2Ftensorflow%2Ftools%2Fdocs:tf_doctest/tests)\r\n\r\nPlease run the doctest locally as mentioned here in the [contributor guidelines](https://www.tensorflow.org/community/contribute/docs_ref)."]}, {"number": 35521, "title": "Rename segment_graph_ to segment_graph_def_", "body": "", "comments": []}, {"number": 35520, "title": "Operation 'EagerPyFunc' has no attr named '_XlaCompile'.", "body": "I'm using tensorflow-gpu 2.1.0-rc1 on python 3.6.8. And I tried to write a loss function using spearman correlation and binary crossentropy. The final loss is the average of 30 targets. The basic idea is, if the target has only one unique value, binary crosessentropy will be used (to avoid nan in spearman), otherwise, spearman will be used. Here is the code:\r\n```\r\nimport tensorflow as tf\r\nfrom scipy.stats import spearmanr\r\nfrom tensorflow.kears import backend as K\r\n\r\ndef custom_loss(y_true, y_pred):\r\n    rhos = tf.constant(0, dtype='float32')\r\n    for ind in range(30):\r\n        a = tf.slice(y_true, [0, ind], [-1, 1])\r\n        a = tf.reshape(a, [-1])\r\n        b = tf.slice(y_pred, [0, ind], [-1, 1])\r\n        b = tf.reshape(b, [-1])\r\n        rhos = tf.cond(tf.equal(tf.argmax(a), tf.argmin(a)),\r\n                lambda: tf.add(rhos, tf.metrics.binary_crossentropy(a, b)),\r\n                lambda: tf.subtract(rhos,\r\n                    tf.py_function(spearmanr, [a, b], Tout=tf.float32)))\r\n    return tf.divide(rhos, tf.constant(30, 'float32'))\r\n```\r\nIt gives the following error:\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in get_attr(self, name)\r\n   2325       with c_api_util.tf_buffer() as buf:\r\n-> 2326         c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)\r\n   2327         data = c_api.TF_GetBuffer(buf)\r\n\r\nInvalidArgumentError: Operation 'EagerPyFunc' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n39 frames\r\nValueError: Operation 'EagerPyFunc' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in __hash__(self)\r\n    703     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\r\n    704         (g is None or g._building_function)):  # pylint: disable=protected-access\r\n--> 705       raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\r\n    706                       \"Instead, use tensor.experimental_ref() as the key.\")\r\n    707     else:\r\n\r\nTypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n```\r\n\r\nEven if I decorate the function with \"@tf.function\". It still gives the same error.\r\n\r\nThanks for any suggestions in advance!\r\n", "comments": ["Figure it out.", "How did you figure this out? I'm having the exact same issues when trying to use tf.py_function in a custom loss function."]}, {"number": 35519, "title": "[ROCm] Unit-test updates for the ROCm platform.", "body": "This commit mostly either enables or disables unittests on the ROCM platform, details listed below\r\n* adding/removing no_rocm tag for tests in the //tensorflow/compiler/mlir dir\r\n* enabling / disabling subtests within //tensorflow/core/grappler/optimizers:constant_folding_test for the ROCm platform\r\n* disabling a subtest within //tensorflow/core/distributed_runtime:collective_param_resolver_distributed_test fir the ROCm platform\r\n* adding no_rocm tag to tests that are failing on the ROCm platform\r\n* minor bug fix to ensure that the //tensorflow/compiler/mlir/tensorflow:error_util_test passes on a consistent basis\r\n\r\n-----------------------\r\n\r\n/cc @whchung @chsigg ", "comments": ["@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned , I have rebased the PR to resolve the merge conflict.\r\nplease re-approve and merge.\r\n\r\nthanks", "I  can approve for tensorflow/tools/docs directory, but I don't have enough context to properly review this.", "rebased PR to remove merge conflicts", "@deven-amd Can you please check jpienaar's comments and keep us posted. Thanks!", "@gbaned, thought I already did respond to @jpienaar s comments ", "> @gbaned, thought I already did respond to @jpienaar s comments\r\n\r\n@deven-amd Sorry, it is waiting for comment from @rmlarsen. Thank you!", "@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned I have rebased the PR to resolve the merge conflicts", "@chsigg , please re-approve...needed to rebase the PR to resolve an incorrect auto-merge", "@gbaned @chsigg gentle ping", "@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned , I have re-based the PR to resolve the merge conflicts. ", "gentle ping", "@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned , rebased PR yet again to resolve merge conflicts.\r\n\r\nplease re-review and merge. thanks", "gentle ping", "Hi @deven-amd, This is a big CL, touching many directories, and needs a bunch of internal approvals. It's got most of them, I'll see if I can track down the last couple."]}, {"number": 35518, "title": "R1.11", "body": "debugging", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35518) for more info**.\n\n<!-- need_sender_cla -->"]}]