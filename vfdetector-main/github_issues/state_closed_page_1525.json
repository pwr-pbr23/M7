[{"number": 7176, "title": "Catch dnn_hidden_units to avoid obsture error message", "body": "Not providing `dnn_hidden_units` in for dnn linear combined model would cause the following error message that's not useful for users.\r\n\r\n```\r\nType'NoneType' object is not iterable\r\n```", "comments": ["Test failure due to timeout. Will be fixed in #7180", "@rmlarsen Done. Thanks!", "@tensorflow-jenkins test this please", "Seems like an irrelevant issue that Martin is fixing", "@tensorflow-jenkins test this please"]}, {"number": 7175, "title": "Go: Documentation of default values for attributes of generated ops can be confusing", "body": "In the Go documentation of op.MatMulTransposeA it says \r\n\"value: If true, \"a\" is transposed before multiplication. If not specified, defaults to b:false\" \r\nwhich should probably be \r\n\"value: If true, \"a\" is transposed before multiplication. If not specified, defaults to a:false\"\r\n\r\nI haven't figured out yet where the documentation for the generated Go source code comes from, maybe it is used to generate documentation in other formats as well. ", "comments": ["could you provide link please? Documentation for Python is automatically generated from the string in C file with implementation here -- https://github.com/tensorflow/tensorflow/blame/a0d784bdd31b27e013a7eac58a86ba62e86db299/tensorflow/core/ops/math_ops.cc#L1030", "I think I know what's happening.\r\n\r\nShort story: That \"b\" there (yes, confusingly) refers not to the name of the attribute but rather the name of the field in the `AttrValue` proto.\r\n\r\nLong story: The documentation for Go is generated by the `genop` code generator. The line you're referring to comes from [`genop.go:177`](https://github.com/tensorflow/tensorflow/blob/f8d75baaf4c92e76837de6bb64adccf8127a21d6/tensorflow/go/genop/internal/genop.go#L177), which in turn uses the compact string representation of the [`AttrValue` protocol buffer's `value` field](https://github.com/tensorflow/tensorflow/blob/cb17d1b0e2b581b5da1d9597b7929ba764749d38/tensorflow/core/framework/attr_value.proto#L34), which is a `oneof`. So the `b:` is referring to the fact that the boolean field is named `b`\r\n\r\nI'm going to mark this as contributions welcome for now and think about possible solutions a bit more."]}, {"number": 7174, "title": "MacOSX ImportError: dlopen(/usr/local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib", "body": "Installed tensorflow for python3.5 on Mac, try the testing code as follows: \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nhello = tf.constant(\"test\")\r\nsess = tf.Session()\r\nprint(sess.run(hello))\r\n```\r\n\r\nIt is working when run it from the terminal. But if I run it from eclipse, will get this exception:\r\n```\r\nwarning: Debugger speedups using cython not found. Run '\"/usr/local/bin/python3.5\" \"/Users/leitian/.p2/pool/plugins/org.python.pydev_5.5.0.201701191708/pysrc/setup_cython.py\" build_ext --inplace' to build.\r\npydev debugger: starting (pid: 978)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/usr/local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib\r\n  Referenced from: /usr/local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n  Reason: image not found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/leitian/.p2/pool/plugins/org.python.pydev_5.5.0.201701191708/pysrc/pydevd.py\", line 1537, in <module>\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/Users/leitian/.p2/pool/plugins/org.python.pydev_5.5.0.201701191708/pysrc/pydevd.py\", line 976, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/Users/leitian/.p2/pool/plugins/org.python.pydev_5.5.0.201701191708/pysrc/_pydev_imps/_pydev_execfile.py\", line 25, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/Users/leitian/code/python/eclipse-ws/TestTF/Hello.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/usr/local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib\r\n  Referenced from: /usr/local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so\r\n  Reason: image not found\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n```", "comments": ["it sounds like your eclipse is not propagating the ld_library_path/dyld_library_path/path env vars correctly, this sounds like a good q to ask on stackoverflow rather than a bug in tensorflow itself", "thanks @yaroslavvb , I put in stackoverflow, but nobody answered me yet:\r\nhttp://stackoverflow.com/questions/41949689/import-tensorflow-failed-in-eclipse\r\nJust have a try here."]}, {"number": 7173, "title": "a bug in inception models?", "body": "Hi,\r\n\r\nI tried to use inception-vx model to extract features, but it keeps giving me error saying tensor name xxx not found in checkpoint files. I'm wondering whether it's my incorrect usage or there's some inconsistency.\r\n\r\nThe model files(ckpt) are downloaded from: https://github.com/tensorflow/models/blob/master/slim/README.md#pre-trained-models\r\n\r\nMy code is:\r\n\r\nimport tensorflow as tf\r\nimport nets.inception_v4 as net_v4\r\n\r\nx = tf.placeholder(tf.float32, shape=[None, 299, 299,3])\r\ninv4 = net_v4.inception_v4(x)\r\nsaver = tf.train.Saver()\r\nsess = tf.Session()\r\n\r\nsaver.restore(sess, \"models/inception_v4.ckpt\")\r\n\r\n\r\nThe error output:\r\n\r\n...\r\nNotFoundError (see above for traceback): Tensor name \"InceptionV4/Mixed_6d/Branch_2/Conv2d_0e_1x7/biases\" not found in checkpoint files models/inception_v4.ckpt\r\n\t [[Node: save/RestoreV2_150 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_150/tensor_names, save/RestoreV2_150/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_31/_567 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1633_save/RestoreV2_31\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\n\r\n\r\n", "comments": ["```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nfrom nets.inception_v4 import inception_v4, inception_v4_arg_scope\r\nimport numpy as np\r\n\r\nheight = 299\r\nwidth = 299\r\nchannels = 3\r\n\r\n# Create graph\r\nX = tf.placeholder(tf.float32, shape=[None, height, width, channels])\r\nwith slim.arg_scope(inception_v4_arg_scope()):\r\n    logits, end_points = inception_v4(X, num_classes=1001,\r\n                                      is_training=False)\r\npredictions = end_points[\"Predictions\"]\r\nsaver = tf.train.Saver()\r\n\r\nX_test = np.ones((1,299,299,3))  # your images, shape [batch_size, 299, 299, 3]\r\n\r\n# Execute graph\r\nwith tf.Session() as sess:\r\n    saver.restore(sess, \"./inception_v4.ckpt\")\r\n    predictions_val = predictions.eval(feed_dict={X: X_test})\r\n```\r\n    ", "Thank you.:) It worked."]}, {"number": 7172, "title": "freeze graph fail by using the published checkpoint file: Attempting to use uninitialized value", "body": "I am using the latest Tensorflow code on Ubuntu 16.04\r\n\r\n1. I download **Inception-ResNet-v2** model from the link https://github.com/tensorflow/models/tree/master/slim    \r\nthe check point file is:\r\nhttp://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\r\n\r\n2. use the code below to get graph define, which output is **graph.pbtxt**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom nets import inception_resnet_v2\r\nimport numpy as np\r\n\r\nx = tf.placeholder(shape=[1,299,299,3], dtype=tf.float32)\r\ninception_resnet_v2 = inception_resnet_v2.inception_resnet_v2(x)\r\n\r\nsess = tf.Session()\r\ntf.train.write_graph(sess.graph_def, './', 'graph.pbtxt')\r\n```\r\n3, use the freeze graph tool to get **.pb** file. \r\n\r\n`bazel-bin/tensorflow/python/tools/freeze_graph\r\n --input_graph=/home/scopeserver/RaidDisk/DeepLearning/mwang/Model_backup2/slim/graph.pbtxt --input_checkpoint=/home/scopeserver/RaidDisk/DeepLearning/mwang/Model_backup2/slim/inception_resnet_v2_2016_08_30.ckpt  \r\n--output_graph=/tmp/frozen_graph.pb --output_node_names=InceptionResnetV2/Logits/Predictions`\r\n\r\ni get the error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 218, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 150, in main\r\n    FLAGS.variable_names_blacklist)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 138, in freeze_graph\r\n    variable_names_blacklist=variable_names_blacklist)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util_impl.py\", line 218, in convert_variables_to_constants\r\n    returned_variables = sess.run(variable_names)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: **Attempting to use uninitialized value InceptionResnetV2/Repeat_1/block17_16/Branch_1/Conv2d_0c_7x1/biases**\r\n\t [[Node: _send_InceptionResnetV2/Repeat_1/block17_16/Branch_1/Conv2d_0c_7x1/biases_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=4447330825950993621, tensor_name=\"InceptionResnetV2/Repeat_1/block17_16/Branch_1/Conv2d_0c_7x1/biases:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionResnetV2/Repeat_1/block17_16/Branch_1/Conv2d_0c_7x1/biases)]]\r\n\r\n\r\n```", "comments": ["I try to freeze another model: **inception v2**, and get similar error as well. Please notice you need change num_classes=1000, to num_classes=1001 in .py file.\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 218, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 150, in main\r\n    FLAGS.variable_names_blacklist)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 138, in freeze_graph\r\n    variable_names_blacklist=variable_names_blacklist)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util_impl.py\", line 218, in convert_variables_to_constants\r\n    returned_variables = sess.run(variable_names)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: **Attempting to use uninitialized value InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/biases**\r\n\t [[Node: _send_InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/biases_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=8458274957196541200, tensor_name=\"InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/biases:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/biases)]]\r\n", "so the question is how to freeze the published .ckpt model files successfully ", "You are not using correct model for that checkpoint, as you mention in referenced issue, pre-trained checkpoint files are useless by themselves, you need to use the code that created the model that generated it.", "I think this is a documentation issue, can you say where you found the place that mentions the checkpoint (http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz). That same document should also describe how to load it", "I'm also curious about how to use/load the checkpoint model. I tried using the nets.inception_v4 or nets.inception_res_v2 codes but it didn't work for me. #7173 \r\n\r\nThanks.", "@sguada -- do you know how are people coming across these checkpoints/where the docs should go?", "I download the checkpoint file from the page: https://github.com/tensorflow/models/tree/master/slim\r\n\r\nYou can see a table here: https://github.com/tensorflow/models/tree/master/slim#pre-trained-models\r\n\r\nIt has all checkpoint files for inception v1-v4... I just use the published check point files.\r\n", "@yaroslavvb I also got the checkpoint files from the webpage @civilman628 mentioned.", "I see....it may be a problem with the checkpoints then, that page lists @nathansilberman @sguada  as maintainers", "i figure out how to use them. the code below is to export .pbtxt file for inception_resnet_v2.\r\n\r\nUse this .pbtxt and the published .ckpt to  freeze graph, if you want to get .pb file.\r\n\r\nif you want to load other models or get other .pbtxt files, just change the key word **inception_resnet_v2** to other model name, such as **inception_v2**, **inception_v3**\r\n\r\nthe first node of .pb file is **Placeholder**, which is the input 4D tensor of image, such as [1,299,299,3]\r\n\r\nyou can use .ckpt for prediction as below. The endpoint is \"Prediction\", But I use .pb in general, which is smaller.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nfrom nets.inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\r\nimport numpy as np\r\n\r\nheight = 299\r\nwidth = 299\r\nchannels = 3\r\n\r\n# Create graph\r\nX = tf.placeholder(tf.float32, shape=[None, height, width, channels])\r\nwith slim.arg_scope(inception_resnet_v2_arg_scope()):\r\n    logits, end_points = inception_resnet_v2(X, num_classes=1001,is_training=False)\r\npredictions = end_points[\"Predictions\"]\r\nsaver = tf.train.Saver()\r\n\r\nX_test = np.ones((1,299,299,3))  # a fake image, you can use your own image\r\n\r\n# Execute graph\r\nwith tf.Session() as sess:\r\n    saver.restore(sess, \"./inception_resnet_v2.ckpt\")\r\n    predictions_val = predictions.eval(feed_dict={X: X_test})\r\n    tf.train.write_graph(sess.graph_def, './', 'resnetv2.pbtxt')\r\n```", "the cmd to free graph for the model, pay attention to ouput node name, you can get it from .pbtxt file.\r\n\r\nbazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/scopeserver/RaidDisk/DeepLearning/resnetv2.pbtxt --input_checkpoint=/home/scopeserver/RaidDisk/DeepLearning/slim/inception_resnet_v2.ckpt --output_graph=./inception_resetv2.pb --output_node_names=**InceptionResnetV2/Logits/Predictions**\r\n", "No sure why this is assigned to me, seems solved. Feel free to re-open if there is still an issue.", "I am getting this issue when I try to freeze the graph from a checkpoint file for a model that I created myself. I was not seeing this error in 0.12.x", "I have the same issue on how to use my fine-tuned checkpoint files to predict the image. I will try freeze graph now. the document is very poor on this topic.", "Hi @civilman628 could you explain in detail as to how to get the output_node_names from the .pbtxt file?\r\n", "@abhiML  you need read the paper to see which node is for prediction. .pbtxt contains all node names.", "@civilman628 \r\nI have used the slim/inception_v3 model. \r\nfinetuned it and got the graph.pbtxt , .cpkt files. \r\nI am trying to freeze the finetuned result( graph.pbtxt, .cpkt) but I am getting the same error. How did you get past the error to generate a frozen.pb ?   \r\n\r\n", "my errors:\r\n1)\r\nTraceback (most recent call last):\r\n  File \"freeze_graph.py\", line 255, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"freeze_graph.py\", line 187, in main\r\n    FLAGS.variable_names_blacklist)\r\n  File \"freeze_graph.py\", line 179, in freeze_graph\r\n    variable_names_blacklist)\r\n  File \"freeze_graph.py\", line 116, in freeze_graph_with_def_protos\r\n    variable_names_blacklist=variable_names_blacklist)\r\nTypeError: convert_variables_to_constants() got an unexpected keyword argument 'variable_names_blackl          ist'\r\n\r\n2)\r\nTraceback (most recent call last):\r\n  File \"freeze_graph.py\", line 255, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"freeze_graph.py\", line 187, in main\r\n    FLAGS.variable_names_blacklist)\r\n  File \"freeze_graph.py\", line 179, in freeze_graph\r\n    variable_names_blacklist)\r\n  File \"freeze_graph.py\", line 115, in freeze_graph_with_def_protos\r\n    output_node_names.split(\",\"))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_util_impl.py\", line 226, in co                    nvert_variables_to_constants\r\n    returned_variables = sess.run(variable_names)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value accuracy                    /total\r\n         [[Node: accuracy/total/_1558 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/                    replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor                    _name=\"edge_1172_accuracy/total\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](accuracy/total)]]\r\n", "To add my 2 cents:\r\n\r\nIf the final goal is to use a pre-trained model to predict or extract features for new images, there is no need to generate intermediate .pbtxt file and consecutively freeze it. If you already know the layer names, below is the example of how to use ResNet50 model to extract features (inspired a bit from @civilman628 's answer and documentation on [resnet_v1.py](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py)):\r\n\r\n```python\r\nfrom tensorflow.contrib.slim.nets import resnet_v1\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\n\r\n# Create graph\r\ninputs = tf.placeholder(tf.float32, shape=[batch_size, height, width, channels])\r\nwith slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n        net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)\r\n\r\nsaver = tf.train.Saver()    \r\n\r\nwith tf.Session() as sess:\r\n        saver.restore(sess, '.resnet_v1_50.ckpt')\r\n        representation_tensor = sess.graph.get_tensor_by_name('resnet_v1_50/pool5:0') # if you don't know names like these, consider referring to corresponding model file or generate .pbtxt file as mentioned in  @civilman628 's answer above\r\n        img = ...  #load image here with size [1, 224,224, 3]\r\n        features = sess.run(representation_tensor, {'Placeholder:0': x})\r\n```\r\n\r\n\r\n", "did you have a look at #6953 ?", "@civilman628 \r\nfollowed your solution, it's ok! many thanks"]}, {"number": 7171, "title": "DBpedia datasets not available. 404.", "body": "Trying to run the code in /learn/text_classification returns a 404 when trying to download the DBpedia dataset.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification.py\r\n\r\nThe constant \"DBPEDIA_URL\" in .../learn/python/learn/datasets/text_datasets.py seems to be wrong as it returns a 404 in Chrome as well.\r\n\r\nThis is the URL in text_datasets.py:\r\nhttps://googledrive.com/host/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M/dbpedia_csv.tar.gz\r\n\r\nWhich returns a 404.\r\n\r\n", "comments": ["Looks fixed at head: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py#L30."]}, {"number": 7170, "title": "tf.pow(x,y) doesn't work for non-integer values of y", "body": "**Operating System:** Debian 4.8.15-2\r\n**Installed version of CUDA:** 8.0\r\n**Installed version of cuDNN:** 5.1.5\r\n**The output of `ls -l /path/to/cuda/lib/libcud*`:**\r\n> myuser@mymachine:/mypath$ ls -l /usr/local/cuda-8.0/lib64/libcud*\r\n> -rw-r--r-- 1 root root 558720 sept. 15 01:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\n> lrwxrwxrwx 1 root root     16 sept. 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\n> lrwxrwxrwx 1 root root     19 sept. 15 01:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n> -rw-r--r-- 1 root root 415432 sept. 15 01:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n> -rw-r--r-- 1 root root 775162 sept. 15 01:02 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\n\r\n**A link to the pip package you installed:** Lost in history. I don't think this is the problem, so I'm going to skip it.\r\n\r\n**The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:**\r\n> myuser@mymachine:/mypath$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n> 0.12.1\r\n\r\n**Minimal reproducible example:** (using python3)\r\n```\r\nimport tensorflow as tf\r\nsession = tf.InteractiveSession()\r\ntf.pow(2,1.5).eval()\r\n```\r\n\r\n**Logs or other output that would be helpful:**\r\n> Traceback (most recent call last):\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 490, in apply_op\r\n>     preferred_dtype=default_dtype)\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n>     return constant(v, dtype=dtype, name=name)\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 165, in constant\r\n>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 367, in make_tensor_proto\r\n>     _AssertCompatible(values, dtype)\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 302, in _AssertCompatible\r\n>     (dtype.name, repr(mismatch), type(mismatch).__name__))\r\n> TypeError: Expected int32, got 1.5 of type 'float' instead.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 507, in pow\r\n>     return gen_math_ops._pow(x, y, name=name)\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1705, in _pow\r\n>     result = _op_def_lib.apply_op(\"Pow\", x=x, y=y, name=name)\r\n>   File \"/mypath/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 499, in apply_op\r\n>     repr(values), type(values).__name__))\r\n> TypeError: Expected int32 passed to parameter 'y' of op 'Pow', got 1.5 of type 'float' instead.\r\n", "comments": ["`tf.pow()` requires that both its arguments have the same type, so to use a `tf.float32` Tensor as the exponent (`y`), you must pass a `tf.float32` Tensor for `x`. e.g.\r\n\r\n```python\r\n>>> sess = tf.InteractiveSession()\r\n>>> sess.run(tf.pow(2.0, 1.5))\r\n2.8284271\r\n```", "So this works\r\n`sess.run(tf.pow(2., 2))`\r\n\r\nbut this doesn't\r\n`sess.run(tf.pow(2, 2.))`\r\n\r\n`apply_op_def` has logic to promote Python objects to shared type T but it doesn't always work. Perhaps type promotion should be done in a deeper layer in runtime, so that it also applies to Tensor values", "@mrry can this be included into `pow` documentation?", "Certainly! I'd welcome a pull request."]}, {"number": 7169, "title": "Java: Update README to run the configure script", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["There isn't enough detail here to go by. Please include as much detail as you can to reproduce the problem. Filling in all the fields above of the bug template would help, as would any logs of the steps you took and the full output of the error.", "I followed the step of TensorFlow for Java. I installed all the requirement and clone the whole tensorflow repository from git.  I was caught the error when I was trying to use this commend: \r\nbazel build -c opt \\\r\n  //tensorflow/java:tensorflow \\\r\n  //tensorflow/java:libtensorflow_jni\r\nunder the tensorflow folder.\r\nThe detailed errors:\r\nERROR: /Users/neil/tensorflow/tensorflow/core/BUILD:1226:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /Users/neil/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: /Users/neil/tensorflow/tensorflow/core/BUILD:1226:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /Users/neil/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: /Users/neil/tensorflow/tensorflow/core/BUILD:1226:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /Users/neil/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted.\r\nINFO: Elapsed time: 0.178s\r\nNeils-MacBook-Pro:tensorflow neil$ bazel build -c opt \\\r\n>   //tensorflow/java:tensorflow \\\r\n>   //tensorflow/java:libtensorflow_jni\r\nERROR: /Users/neil/tensorflow/tensorflow/core/BUILD:1226:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /Users/neil/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: /Users/neil/tensorflow/tensorflow/core/BUILD:1226:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /Users/neil/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: /Users/neil/tensorflow/tensorflow/core/BUILD:1226:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /Users/neil/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.\r\nERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted.", "Ah, I see. The problem is that the [`configure`](https://github.com/tensorflow/tensorflow/blob/master/configure) script needs to be run first (as per the \"[install from sources](https://www.tensorflow.org/get_started/os_setup#configure_the_installation)\" instructions on www.tensorflow.org) I will update the java README to reflect that.\r\n\r\nPlease run that and let us know if that solves your problem."]}, {"number": 7168, "title": "Revert \"Added absolute path expansion of parent directory check in saver.py, \u2026\"", "body": "Reverts tensorflow/tensorflow#6601\r\n\r\nBreaks saving to all non-local filesystem paths.", "comments": ["Also adding a test (internally) so it doesn't happen again.", "Jenkins, test this please."]}, {"number": 7167, "title": "Branch 146128391", "body": "Push internal changes.", "comments": []}, {"number": 7166, "title": "How should Python packages depending on TensorFlow structure their requirements?", "body": "Many packages build on TensorFlow. For example, our work in Edward uses `tensorflow>=1.0.0a0` as an install requirement. \r\n\r\nHowever, this conflicts with `tensorflow-gpu`, which can no longer be installed because of the requirement specifically on `tensorflow`. What do you suggest is the best way to handle this?\r\n\r\nOne option suggested by @gokceneraslan (https://github.com/blei-lab/edward/pull/428#issuecomment-276394115) is to hack in the dependency according to whether the user has a GPU. Another option, which PrettyTensor and Keras employ, is to not even require TensorFlow. (Both options sound not good.)\r\n\r\nAlso see https://github.com/blei-lab/edward/pull/428. also looping in GPflow devs (@jameshensman, @alexggmatthews) in case they have the same problem. (Note I'm raising this as an issue instead of asking on a mailing list, in case this is something that should be changed on TensorFlow's end and not our end.)", "comments": ["I'm pretty sure the fundamental issue here is that pypi doesn't support uploading wheels with and without GPU support (see [PEP 425](https://www.python.org/dev/peps/pep-0425) for a list of supported tags). Hence the separate \"tensorflow-gpu\" distribution on pypi.\r\n\r\nBoth of your suggested work-arounds (hacks in setup.py or simply removing problematic dependencies altogether) are commonly done by Python packages for scientific computing.", "Do you have some examples? This would be great references in deciding from the work-arounds. (I'm leaning towards removing the dependence.)", "@dustinvtran Here's a discussion about this for patsy: https://github.com/pydata/patsy/issues/5", "@shoyer interesting example, I wonder if that explains why `pip install --upgrade $TF_BINARY_URL` replaces MKL numpy on our machines with OpenBLAS numpy (there's `REQUIRED_PACKAGES = [ 'numpy >= 1.11.0',` inside of TF's setup.py\r\n", "@yaroslavvb yes, that's likely the case. Pip install only recently got the option `--upgrade-strategy=only-if-needed` which is probably what you want to use here. Eventually this will become the default behavior (https://github.com/pypa/pip/issues/3871).", "@dustinvtran See [here](https://github.com/ska-sa/montblanc/blob/rime-tf/setup.py) for an example which detects a CUDA installation and then selects either tensorflow/tensorflow-gpu depending on CUDA availability.", "@sjperkins Detecting if nviidia gpu is available will not work when installing in Dockerfile to a Docker image, and in general if you install it somewhere where you don't intend to run it.\r\n\r\nI was checking if it could be done with setup.py extras:\r\nhttps://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-extras-optional-features-with-their-own-dependencies\r\n\r\nbut I don't think it's possible.\r\n\r\nIMO most straightforward would be to drop tensorflow from the install_requires list, and just try to import tf it in setup.py, catch the ImportError, and raise some pip exception saying that you need either tensorflow or tensorflow-gpu installed.", "> Detecting if nviidia gpu is available will not work when installing in Dockerfile to a Docker image, and in general if you install it somewhere where you don't intend to run it.\r\n\r\n@t0mk One still needs to install CUDA in the docker container. The example I provided will still compile CUDA code if GPUs aren't available, but it won't be able to target specific architectures and will default to sm_30.", "Currently I am using [extras_require](http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-extras-optional-features-with-their-own-dependencies) in setup.py\r\n```\r\nsetup(\r\n    name=\"my_package\",\r\n    ...,  # other stuff\r\n    install_requires=<list of dependencies EXCLUDING tensorflow>,\r\n    extras_require={\r\n        \"tf\": [\"tensorflow>=1.0.0\"],\r\n        \"tf_gpu\": [\"tensorflow-gpu>=1.0.0\"],\r\n    }\r\n)\r\n```\r\nThe problem here is that if user does not specify which version of package he/she wants, i.e. like this `my_package[tf_gpu]`, tensorflow won't be required. But I think at least it is better then not specifying tensorflow at all.", "For Edward I decided to remove the explicit dependence on TensorFlow and make it part of `extras_require`. Not ideal, but I think it's the best present solution. Feel free to close this issue\u2014it would be nice though to have this type of recommended advice in the docs."]}, {"number": 7165, "title": "Make curl forward/backward compatible", "body": "I'm working on fixing https://github.com/bazelbuild/bazel/issues/1262, which will change the way Bazel organizes the execution root.  The curl library needs to use ../curl as an include prefix in new versions of Bazel and external/curl in old versions.\r\n\r\nThis patch should be forward/backward compatible.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@jart is this good to go?", "My name is Justine Tunney and I approve this pull request.", "@tensorflow-jenkins test this please", "I'm having trouble getting these tests to pass, even without my changes.  Is there anything in particular I need to set up to get, say, Linux CPU Tests working?  I've got a vanilla TF setup without my changes and I'm getting (for example, with `bazel test //tensorflow/contrib/factorization/examples:mnist`):\r\n\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\n-----------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/kchodorow/.cache/bazel/_bazel_kchodorow/d39e1471d317a89f747169f52aae8653/execroot/clean_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/factorization/examples/mnist.runfiles/org_tensorflow/tensorflow/contrib/factorization/examples/mnist.py\", line 36, in <module>\r\n    import tensorflow as tf\r\n  File \"/home/kchodorow/.cache/bazel/_bazel_kchodorow/d39e1471d317a89f747169f52aae8653/execroot/clean_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/factorization/examples/mnist.runfiles/org_tensorflow/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/kchodorow/.cache/bazel/_bazel_kchodorow/d39e1471d317a89f747169f52aae8653/execroot/clean_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/factorization/examples/mnist.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 124, in <module>\r\n    from tensorflow.python.platform import test\r\n  File \"/home/kchodorow/.cache/bazel/_bazel_kchodorow/d39e1471d317a89f747169f52aae8653/execroot/clean_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/factorization/examples/mnist.runfiles/org_tensorflow/tensorflow/python/platform/test.py\", line 83, in <module>\r\n    import mock                # pylint: disable=g-import-not-at-top,unused-import\r\nImportError: No module named mock\r\n```", "@kchodorow: I notice that this import is conditional on the version: \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/test.py#L82\r\n\r\nCould this check be wrong? ", "Ah, I didn't have mock installed!  `sudo pip install mock` made it pass.  Unfortunately, now it passes for me locally both with and without my change (gah!).  Is there a way to see the Bazel tests logs Jenkins generates (so I can see what, specifically, made these things fail)?", "@kchodorow Click on \"Console Output\" link for the tests here:\r\n\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-multijob/3566/\r\n\r\nFor the full log, click on the \"Full Log\" link at the top of the individual console output pages. They are very verbose, but searching for \"Failure\" usually does the trick.", "Mr. Jenkins test this please", "Okay, rebased my change on top of @jhseu's fix, so now it only updates the curl library.  Could you try triggering the Jenkins build again (hopefully for the last time)?", "Jenkins, test this please", "Horay!!!!", "Friendly ping: could someone merge this in when you get a chance?"]}, {"number": 7164, "title": "contrib.batch_norm fails on float16 input", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI have found a bunch of old issues dated from the initial implementation of float16, but nothing relevant.\r\n\r\n### Environment info\r\nOperating System: FC21\r\n\r\nInstalled version of CUDA and cuDNN: CUDA8, CuDNN 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n/cuda8_cudnn5_1/lib64/libcudadevrt.a\r\n/cuda8_cudnn5_1/lib64/libcudart.so -> libcudart.so.8.0\r\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0.44\r\n/cuda8_cudnn5_1/lib64/libcudart_static.a\r\n/cuda8_cudnn5_1/lib64/libcudnn.so -> libcudnn.so.5\r\n/cuda8_cudnn5_1/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n/cuda8_cudnn5_1/lib64/libcudnn.so.5.1.5\r\n/cuda8_cudnn5_1/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: today nightly build\r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-0.12.1-cp34-cp34m-linux_x86_64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\n>tf.__version__\r\n'0.12.head'\r\n>tf.__git_version__\r\n'0.12.1-2263-g4cc0d1e-dirty'\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```\r\np16 = tf.placeholder(tf.float16, (4, 16, 16, 3))\r\nbn16 = tf.contrib.layers.batch_norm(p16)\r\n```\r\n\r\nIt fails with float32 to float16 conversion error deep inside BN op. Traceback is below.\r\n\r\n### What other attempted solutions have you tried?\r\nFor now working with float32. I tried to track where exactly it fails, but I couldn't. It looks like computed mean value is float32 by default although the variable itself should be `inputs.dtype.base_dtype` and `tf.nn.moments` returns `float16` with corresponding input.\r\n\r\n### Logs or other output that would be helpful\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-e659548f8d6c> in <module>()\r\n----> 1 bn16 = tf.contrib.layers.batch_norm(p16)\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    175       current_args = current_scope[key_func].copy()\r\n    176       current_args.update(kwargs)\r\n--> 177     return func(*args, **current_args)\r\n    178   _add_op(func)\r\n    179   setattr(func_with_args, '_key_op', _key_op(func))\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\r\n    516           _scope=sc,\r\n    517           _reuse=reuse)\r\n--> 518       outputs = layer.apply(inputs, training=is_training)\r\n    519\r\n    520       # Add variables to collections.\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\r\n    301       Output tensor(s).\r\n    302     \"\"\"\r\n--> 303     return self.__call__(inputs, **kwargs)\r\n    304\r\n    305\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\r\n    271             self.build(input_shapes)\r\n    272           self._built = True\r\n--> 273         outputs = self.call(inputs, **kwargs)\r\n    274\r\n    275         # Apply activity regularization.\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\r\n    191       if not self.updates:\r\n    192         mean_update = moving_averages.assign_moving_average(\r\n--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)\r\n    194         variance_update = moving_averages.assign_moving_average(\r\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\r\n     70         update_delta = _zero_debias(variable, value, decay)\r\n     71       else:\r\n---> 72         update_delta = (variable - value) * decay\r\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\r\n     74\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\r\n    704     def _run_op(a, *args):\r\n    705       # pylint: disable=protected-access\r\n--> 706       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\r\n    707     # Propagate __doc__ to wrapper\r\n    708     try:\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n    885     with ops.name_scope(None, op_name, [x, y]) as name:\r\n    886       if not isinstance(y, sparse_tensor.SparseTensor):\r\n--> 887         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\r\n    888       return func(x, y, name=name)\r\n    889\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n    649       name=name,\r\n    650       preferred_dtype=preferred_dtype,\r\n--> 651       as_ref=False)\r\n    652\r\n    653\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\r\n    714\r\n    715         if ret is None:\r\n--> 716           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    717\r\n    718         if ret is NotImplemented:\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    587     raise ValueError(\r\n    588         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\r\n--> 589         % (dtype.name, t.dtype.name, str(t)))\r\n    590   return t\r\n    591\r\n\r\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm/Reshape_1:0\", shape=(3,), dtype=float16)'\r\n```", "comments": ["Can confirm with CPU version too.", "Well, I found a workaround for that one. I just modified `BatchNormalization` layer `get_variable()` calls to use dtype from passed initializers. Ugly, but worked. Btw, it is a regression from 0.12.0. I found a machine with that version that doesn't have this bug on python side.\r\n\r\nUPD: removed unrelated problem and resubmitted as another issue.", "close this one as it is resubmitted as another issue.", "I resumbitted another thing that I detailed in the second message and then edited out. When I fixed this issue with BN (by manually editing my TF installation as I explained above in an unelegant way) I discovered another problem that firstly I thought also related to float16 and BN, but in C code. It turned out it wasn't linked to BN, so I resumbitted it in #7226.\r\n\r\nPlease reopen this one as it is still stands.", "This indeed still stands, but it appears it's being addressed in https://github.com/tensorflow/tensorflow/issues/8535."]}, {"number": 7163, "title": "[WIP] Add standlone Poplar plugin scaffolding", "body": "Summary:\r\n1) Add poplar and popnn third_party library support\r\n2) Add a poplar XLA device, plugin python wrapper, and appropriate test\r\n3) Adjust XLA unit tests to allow for a plugin, and add IPU as a plugin type", "comments": ["I asked David to send this PR so we could see how we could get an XLA device added as a purely external library via tf.load_library.  These are the changes he had to make to get something to load, but we should figure out what changes to TF need to be made to allow this support.\r\n\r\nI'm going to be OOO most of this week, so if someone wants to jump in, great!  I'll return this when I am back", "Some notes:\r\n\r\nfor the external library (third_party/ipus/...), I have used 2 environment variables to enable the module.  This differs from Cuda / OpenCL which have stuff in the ./configure script.   I avoided copying Cuda / OpenCL because the ./configure script seems messy, and I imagine that it will be cleaned up at some point.\r\n\r\nTo build our device (it is just a stub copy of the xla cpu device at the moment), you could set the 2 environment variables (TF_POPLAR_BASE and TF_POPNN_BASE) to any empty directory, comment out the two included headers in the xla_ipu_device.cc file.  then ./configure, including XLA, and build something like:\r\n\r\nbazel test --config=opt //tensorflow/compiler/poplar:device_test\r\n\r\nthis should demonstrate the device .so being built, and the .so and .py files working together to load the device into tensorflow, and the test checking that the XLA_IPU device has been registered.\r\n\r\nYou could also try:\r\n\r\nbazel test --config=opt //tensorflow/compiler/tests:xla_device_test\r\n\r\nyou should see that the CPU device passes, while the IPU device doesn't pass (because it doesn't register any of the ops that are required at the moment).\r\n\r\n\r\nFinally - I've checked that without the TF_POPLAR_BASE and TF_POPNN_BASE env vars set, the system builds with XLA and the unit tests run successfully.    i.e. I would like this merge request to be actually merged after any discussion is done.\r\n\r\n\r\n\r\n", "@vrv would you like to assign some possible reviewers for this?", "Hi,\r\n\r\nFurther to this, I've been working on added a 'platform' and a 'compiler' to the driver.  I have discovered the file tensorflow/tf_exported_symbols.lds requires something adding to it to ensure that XLA can be accessed by a plugin.  I've added *xla*, which works, but generates some warnings on link.\r\n\r\nConsequently I have managed to add a platform, compiler and executable (stubs) for my hardware.  I could add these to the pull request if you like.\r\n\r\nI have had to add a constant to the stream_executor library that holds my hardware platform ID.  Would it be a good idea to assume that nobody will ever need to load plugins for more than one type of exotic hardware, and just have a single 'kThirdPartyPluginPlatformId' for third party hardware?\r\n\r\n", "sorry - that was some bad Git management.  sigh :(  - tried to merge one commit onto the top of the pile and sucked in every merge and old bit of work on the branch.\r\n\r\nI think I will try this whole thing again with another pull request. \r\n", "No worries David, and thanks for purusing this. \r\n\r\n1) From a brief look at this code, it appears there isn't much that needs to actually be added to TensorFlow core code (most of the poplar-specific code could live in its own repository, using bazel or not) -- this is great, and I'm glad you went through the effort of helping to identify where it works and where it doesn't.\r\n\r\n2) There are some exceptions like you mention (such as the id registration) and several changes to extend stream executor.  @hawkinsp do you have an idea of what could be changed to core TF so that this custom device could be completely separate from the core repo?  @henline too, since stream executor will eventually be a separate project in llvm, and it would be good to understand what needs to be easily extendable without commits to core code.", "I have replaced this one with https://github.com/tensorflow/tensorflow/pull/7191\r\n"]}, {"number": 7162, "title": "Can't quantize nodes of an RNN (\"The node has inputs from different frames.\")", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI found a few similar, but not equivalent, problems with frozen/quantized graphs:\r\n\r\nCannot import graph_def for 8-bit Quantized cnn model #5470\r\n\r\ntf.import_graph_def: graph_def is invalid at node #4044\r\n\r\nUnable to import frozen graph with batchnorm #3628 \r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.10\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n```\r\n-rw-r--r-- 1 root root   558720 Sep 14 20:02 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Sep 14 20:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Sep 14 20:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   415432 Sep 14 20:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Sep 14 20:02 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Jan 27 22:01 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: https://pypi.python.org/pypi/tensorflow-gpu\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\r\n\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.1\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nI reduced this to a simple RNN model available here on branch tf_issue_7162: https://github.com/reuben/tf-export-test/tree/tf_issue_7162\r\n\r\nYou don't have to train it again, the repository includes a checkpoint with trained weights. If you run the commands starting from the freeze_graph in the [README](https://github.com/reuben/tf-export-test/blob/master/README.md) there, you get this error when importing the quantized graph:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"import.py\", line 14, in <module>\r\n    imports = tf.import_graph_def(pb, name=\"\")\r\n  File \"/home/reuben/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 339, in import_graph_def\r\n    % (input_name,)))\r\nValueError: graph_def is invalid at node u'RNN/cond/Greater/y': More inputs specified ('RNN/cond/Switch:0') than the op expects..\r\n```", "comments": ["This error happens whether or not you freeze the graph first.", "I can still reproduce this with TensorFlow 1.0.", "I reduced the test case to a much simpler graph:\r\n\r\n```python\r\nlstm_cell = tf.contrib.rnn.BasicLSTMCell(64)\r\n\r\noutputs, _ = tf.nn.dynamic_rnn(lstm_cell,\r\n    dtype=tf.float32,\r\n    inputs=tf.constant([[[1.,1.,1.]], [[1.,1.,0.]]]),\r\n    sequence_length=tf.constant([3,2]))\r\n\r\npred = tf.add(outputs, tf.constant(0.), name=\"y\")\r\n```\r\n\r\nI reused the repository for a different (but related) issue, #7949. So the code for this is now on branch tf_issue_7162 there: https://github.com/reuben/tf-export-test/tree/tf_issue_7162", "Over in issue #7949 @petewarden suggested that I use the new transform_graph tool instead of quantize_graph.py, and that worked for weights quantization. On the other hand, when using that tool to quantize the graph, I run into a different problem:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"import.py\", line 19, in <module>\r\n    result = sess.run(y)\r\n  File \"/home/reuben/.virtualenvs/deepspeech/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/home/reuben/.virtualenvs/deepspeech/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/reuben/.virtualenvs/deepspeech/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/reuben/.virtualenvs/deepspeech/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'rnn/while/basic_lstm_cell/basic_lstm_cell/MatMul_eightbit/rnn/while/basic_lstm_cell/basic_lstm_cell/MatMul/Enter/reshape' has inputs from different frames. The input 'rnn/while/basic_lstm_cell/basic_lstm_cell/MatMul/Enter' is in frame 'rnn/while/rnn/while/'. The input 'rnn/while/basic_lstm_cell/basic_lstm_cell/MatMul_eightbit/rnn/while/basic_lstm_cell/basic_lstm_cell/concat/reshape_dims' is in frame ''.\r\n```\r\n\r\nThis, coincidentally, is the same problem I was running into originally over in issue #7949.\r\n\r\nUpdated code for reproducing this is in https://github.com/reuben/tf-export-test/tree/tf_issue_7162", "hi\r\n\r\nI am getting this error when doing optimization\r\n\r\nValueError: graph_def is invalid at node 'word_embeddings/Variable/Assign': Input tensor 'word_embeddings/Variable:0' Cannot convert a tensor of type float32 to an input of type float32_ref\r\n\r\ninput_graph_def = tf.GraphDef()\r\n    checkpoint = tf.train.get_checkpoint_state(model_dir)\r\n    input_checkpoint = checkpoint.model_checkpoint_path\r\n\r\n    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\r\n    output_graph = absolute_model_folder + \"/frozen_model.pb\"\r\n\r\n    with tf.gfile.FastGFile(output_graph, 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n        _ = tf.import_graph_def(graph_def, name='')\r\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n        graph_def,\r\n        [''],\r\n        [''],\r\n        tf.float32.as_datatype_enum)\r\n any help is greatly appreciated", "Can you share the graph file you're using and the command line you're running? You can either share it as an attachment here, or email it to petewarden@google.com. That will help me debug what's going wrong.", "@petewarden Did you see the minimal example @reuben set up[[1](https://github.com/reuben/tf-export-test/tree/tf_issue_7162)].", "Any progress? I meet the same issues as [reubne mentioned](https://github.com/tensorflow/tensorflow/issues/7162#issuecomment-283412259).", "@reuben @petewarden I fixed it by adding control input to the constant node #9792 ", "Looks like this fixes the problem on our network as well. I just tested applying the documented transforms for \"8 bits calculations\", and the resulting file does indeed work.\r\n\r\nMore precisely, `add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'` produced a network where our \"output_node\" is removed.\r\n\r\nBut `add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\")  fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'` produces a network where we can do inference.", "@wodesuck Experimenting with your fix, I spotted that even models without a RNN layer (actually we do use `tf.nn.bidirectional_dynamic_rnn()`) do not report the same inference time. From the benchmark I could run locally, I identified, on our mozilla/DeepSpeech model nuking the bidirectionnal dynamic layers:\r\n - model 8-bitized with transform tool without any change shows inference time ~ 0.8secs\r\n - model 8-bitized with fixed transform tools shows inference time ~1.1secs", "@lissyx Maybe the control inputs slow down the model. Actually, only for those nodes within a while loop (e.g. nodes in dynamic_rnn), it is necessary to add control inputs when quantizing them.\r\n\r\nPersonally, I add it iff the node name contain \"/rnn/while/\". This is a simple method but work for my model \ud83d\ude25, I think you can try it too. And I expect someone prove a more precise way to identify nodes in while loop \ud83d\ude04 .", "Thanks @wodesuck ! When you say that you add it if and only if the name contains `/rnn/while/`, I'm unsure about something: are you referring to transformation applied by `transform_graph` ? If so, it means you changed the code from your PR to limit the scope to control loops ?", "@lissyx That's right.\r\n\r\nHere is the code, it is not suit for general use (maybe someone have a node name \"while\" or a while loop name without \"while\"), so I don't add it in the PR. Besides, there's more works could do to optimize a specific model (run some benchmark & try to optimize the bottleneck), I had customized a lot in my `transform_graph`.\r\n```c++\r\n          // Add some common constants we need for reshaping inputs.\r\n          NodeDef reshape_dims;\r\n          reshape_dims.set_op(\"Const\");\r\n          reshape_dims.set_name(unique_input_name + \"/reshape_dims\");\r\n          if (float_node.name().find(\"/while/\") != string::npos) {\r\n            AddNodeInput(\"^\" + input_name, &reshape_dims);\r\n          }\r\n          SetNodeAttr(\"dtype\", DT_INT32, &reshape_dims);\r\n          Tensor reshape_dims_tensor(DT_INT32, {1});\r\n          reshape_dims_tensor.flat<int32>()(0) = -1;\r\n          SetNodeTensorAttr<int32>(\"value\", reshape_dims_tensor, &reshape_dims);\r\n          new_nodes->push_back(reshape_dims);\r\n\r\n          NodeDef reduction_dims;\r\n          reduction_dims.set_op(\"Const\");\r\n          reduction_dims.set_name(unique_input_name + \"/reduction_dims\");\r\n          if (float_node.name().find(\"/while/\") != string::npos) {\r\n            AddNodeInput(\"^\" + input_name, &reduction_dims);\r\n          }\r\n          SetNodeAttr(\"dtype\", DT_INT32, &reduction_dims);\r\n          Tensor reduction_dims_tensor(DT_INT32, {1});\r\n          reduction_dims_tensor.flat<int32>()(0) = 0;\r\n          SetNodeTensorAttr<int32>(\"value\", reduction_dims_tensor,\r\n                                   &reduction_dims);\r\n          new_nodes->push_back(reduction_dims);\r\n```", "Thanks for the confirmation @wodesuck ", "Any chance that this problem gets solved?", "I think this problem is not fully solved. quantize_graph.py still generate model with this issue. there is no explanation on this issue. why a const node need a control input dependency on another node?", "@yuanhua8 First, `quantize_graph.py` seems no longer maintained, you could use `transform_graph` instead. Second, all nodes within a tf control loop need a property called \"frame\" to run properly, while quantization adding const nodes without \"frame\" will break it. So, it is necessary to add control input to make sure nodes having a correct \"frame\".", "@wodesuck, thanks daniel for your answer. I like the python code since more easy to modify it(for example I want to convert something in side meta_graph), but it looks a known bug not fixed in python code.... \r\nthanks for your information.", "also find that in bug in the quantize_graph.py which call remove_training_nodes. suppose a const name has a control dependency on an identity node which depend on switch node. after  idenity is remvoed. const should just have control dependency on switch node, not use switch node as input", "@yuanhua8 yes they remove all the nodes that no do impact the inference of the output node specified.\r\n\r\nBut as you said, it might be a problem since many of us use the identity trick to name a node in the network.", "Hi,\r\n\r\nI'm also getting similar errors ,trying to run inference after quantize_nodes transform operation in GTT.\r\nStarted with the code from NMT tutorial https://github.com/tensorflow/nmt\r\nFreezed the graph into PB , used the GTT tool to transform the graph and load it back for the inference part. \r\n\r\nError message : \r\n'dynamic_seq2seq/encoder/bidirectional_rnn/..../basic_lstm_cell/basic_lstm_cell/concat/reshape_dims' is in frame ''.\r\n\r\ntried this solution , did'nt work. https://github.com/tensorflow/tensorflow/commit/17ce98437f34ab5439b3e46adb2eb5b692c48abd\r\n\r\nany idea how to fix this issue? \r\nthanks", "I believe this is related to #3628, since it seems like there are certain graphs we have trouble freezing due to their structure. I haven't had a chance to dig in deeper, but it seems worth keeping open since there seem to be multiple problems in this area. I'm also cc-ing Suharsh, since he's been looking at issues around freeze_graph.", "(reopening, since I hit the wrong button and just meant to comment!)", "For any one who still got the problem:\r\n\r\nTensorFlow fixed this issue in their source code from r1.5, but that comes with a new problem with graph binary version if you use older TensorFlow version to inference the model, so you have to keep using TensorFlow r1.5 or above to inference the quantized model.", "I have similar errors when quantize_nodes for [Tensor2Tensor Transformer](https://github.com/tensorflow/tensor2tensor) model.\r\nIt's no problem after freeze_graph, it's also no problem with quantize_weights. But when I qutize_nodes, it will:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'transformer/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/add_1/eightbit' has inputs from different frames. The input 'transformer/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/add_1_eightbit/transformer/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/add_1/Enter/quantize' is in frame 'transformer/while/while_context'. The input 'transformer/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/mul_1/eightbit/requantize' is in frame ''.\r\n```\r\nI have tried TF1.4 and TF1.7, and the error is the same.\r\nCan anyone help me?\r\n", "@wodesuck @petewarden \r\nCan you help me?", "@efeiefei i have the same issue with transformer model. Do you fix it now?", "Nagging Assignees @petewarden, @suharshs, @raghuraman-k: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is not work for me\r\n```\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float, shape=\"-1,480000\")\r\n  remove_nodes(op=CheckNumerics)\r\n fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  quantize_nodes\r\n  strip_unused_nodes\r\n  sort_by_execution_order\r\n  '\r\n```\r\n\r\nBut this work fine \r\n\r\n```\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float, shape=\"-1,480000\")\r\n  remove_nodes(op=CheckNumerics)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  quantize_nodes\r\n  strip_unused_nodes\r\n  sort_by_execution_order\r\n  '\r\n```\r\n", "Closing this for now as there is a working solution. ", "> @efeiefei i have the same issue with transformer model. Do you fix it now?\r\n\r\nI also met this issue. Did you fix it? and would you plz share? Many thx!"]}, {"number": 7161, "title": "Fix wrong description for tf.nn.max_pool_with_argmax", "body": "The description for indices is wrong. The real format is (y * width + x) * channels + c, batch index is ignored which can be seen [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/maxpooling_op_gpu.cu.cc#L78).\r\n\r\nFixed pull request from https://github.com/tensorflow/tensorflow/pull/7090", "comments": ["Can one of the admins verify this patch?", "I'm not sure your change is correct. I think the batch index is used at the top level to shard the computation across threads here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/maxpooling_op_gpu.cu.cc#L212\r\n\r\nThe line you pointed to calculates the index within such a chunk, I think.\r\n\r\n@bsteiner, care to comment?", "The cuda loop iterates over batch * channels * pooled_height * pooled_width indices. The batch dimension is recovered in the 'n' variable computed by dividing the cuda loop index by pooled_width * pooled_height * channels. So I believe the description is correct.", "@rmlarsen @benoitsteiner \r\n\r\n'n' variable is not used to compute the index because the data pointer is local for each example.\r\n```\r\nconst dtype* bottom_data_n = bottom_data + n * channels * height * width;\r\n...\r\nint idx = c * height * width + h * width + w;\r\n...\r\nmask[index] = maxidx;\r\n```\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/maxpooling_op_gpu.cu.cc#L75\r\n\r\nTest example which shows this is below. Note that index for pooled value 2 is 3 and not 7.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nimg_shape = (2,2,2,1)\r\nimg = tf.placeholder(tf.float32, img_shape)\r\nksize = [1,2,2,1]\r\nstride = [1,2,2,1]\r\npool, argmax = tf.nn.max_pool_with_argmax(img, ksize, stride, padding='SAME', name='pool')\r\n\r\nimg_np = np.zeros(img_shape)\r\nimg_np[0,0,0] = 1\r\nimg_np[1,1,1] = 2\r\n\r\nwith tf.Session() as sess:\r\n  ops = [argmax]\r\n  feed = {img:img_np}\r\n  out = sess.run(ops, feed_dict=feed)\r\n  print(img_np)\r\n  print(out)\r\n```\r\n```\r\n [[[[ 1.]                                                                                                                                                                                                           \r\n    [ 0.]]                                                                                                                                                                                                                                                                                                                                                                                                            \r\n   [[ 0.]                                                                                                                                                                                                           \r\n    [ 0.]]]                                                                                                                                                                                                         \r\n                                                                                                                                                                                                                    \r\n                                                                                                                                                                                                                    \r\n  [[[ 0.]                                                                                                                                                                                                           \r\n    [ 0.]]                                                                                                                                                                                                                                                                                                                                                                                                      \r\n   [[ 0.]                                                                                                                                                                                                           \r\n    [ 2.]]]]    \r\n                                                                                                                                                                                                    \r\n [array([[[[0]]], [[[3]]]])]    \r\n```", "Why is this pull request still not being merged? I see the old wrong doc with batch dimension on tensorflow official website as of today."]}, {"number": 7160, "title": "Decrease accuracy after upgrade from v0.11 to v0.12", "body": "Hi! I've recently updated from v0.11 to v.012 using pip with CUDA 8.0, cuDNN 5.1in a TitanX under Ubuntu 16.04 LTS.\r\n\r\nDuring the training of a small CNN triplet network with triplet margin loss I noticed that the performance in terms of accuracy went down by a factor of ~40%.  Getting around 9% and 14% FPR95 with v0.11 and v0.12 respectively, both at epoch 30th. Notice with v0.12 the accuracy gets stuck in early epoch 10th.\r\n\r\nThe optimizer that I'm using is Momentum with a LR of 1e-4 without decay policy.\r\nI've also added the regularization term with a weight decay of 1e-4.\r\n\r\nDid you introduce any change with last versions in the optimization API that could make this difference?\r\n\r\nPD: I left here the link to the code.\r\nhttps://github.com/vbalnt/tfeat/tree/master/tensorflow\r\nNotice that we are trying to reproduce from the original LuaTorch version.", "comments": ["Hi,\r\nI have some continuous integration tests set up for some of my projects, where I run the code on small training sets and didn't notice any change in performance when I was switching from 0.11 to 0.12. The integration tests are running on CPU though. Maybe could you check for the first epochs if you get the same results in 0.11 vs 0.12 via CPU? This would tell us that there is something going on with the GPU stuff maybe. Also, do you maybe have any random gens that are not seeded?", "@edgarriba Ouch, those ones are hard to troubleshoot, can you try with latest nightly from https://github.com/tensorflow/tensorflow ?", "Hi guys, sorry for this late reply. @rasbt you were right I finally found that opencv resizes routine has a random component. So, after setting all the random seeds the results in different versions are almost the same.\r\n\r\n@yaroslavvb Besides, and not sure if it's the correct place to ask, but as I mentioned above we have been struggling to replicate some results from a paper we have using triplets networks. The original code is in LuaTorch, and during the conversion of the loss function to TF we are not getting the same performance in terms of accuracy.\r\n\r\nIf someone want to check here is the code\r\nhttps://github.com/vbalnt/tfeat/blob/master/tensorflow/train/tfeat/loss.py#L13", "@edgarriba there's no magic bullet for matching performance of two frameworks unfortunately. Last time I tried to match Torch's l-BFGS in TensorFlow, I ended up saving results after each operation in both Torch and in TensorFlow, and comparing them numerically one-by-one until I found the difference. See [SaveTensor1D](https://github.com/yaroslavvb/lbfgs/blob/master/mnist_sgd.lua#L91) and acompanying [notebook]( https://github.com/yaroslavvb/lbfgs/blob/master/Porting%20Torch%20l-BFGS%20to%20immediate.ipynb)", "I'll close it for now since this doesn't seem like a bug in TensorFlow", "@yaroslavvb sure I'll try. Thanks!"]}, {"number": 7159, "title": "Tensorflow restore doesn't work on AWS", "body": "I am running a script that perfectly works on ubuntu 14.04, docker over ubuntu 14.04, docker over MAC OS - but doesn't work on ubuntu 16 on AWS.\r\nthe script is:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n\r\ndef load_model_to_session(session, model_dir, meta_file, ckpt_file):\r\n    model_dir_exp = os.path.expanduser(model_dir)\r\n    saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\r\n    saver.restore(session, os.path.join(model_dir_exp, ckpt_file))\r\n\r\nsession = tf.Session()\r\nprint ('loading models')\r\nmodel_dir = '/data/model'\r\nmeta_file, ckpt_file = 'a.meta', 'a.ckpt'\r\nprint ('ckpt file ' + ckpt_file)\r\nload_model_to_session(session, model_dir, meta_file, ckpt_file)\r\nprint ('finish loading the model')\r\nsession.close()\r\n\r\n`````\r\n\r\nthe errors i get:\r\n\r\n> W tensorflow/core/framework/op_kernel.cc:975] Data loss: Unable to open table file /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n> W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n> W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n> W tensorflow/core/framework/op_kernel.cc:975] Data loss: Unable to open table file /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n> W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n> W tensorflow/core/framework/op_kernel.cc:975] Data loss: Unable to open table file /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n> Traceback (most recent call last):\r\n>   File \"/tmp/runner.py\", line 35, in <module>\r\n>     load_model_to_session(session, model_dir, meta_file, ckpt_file)\r\n>   File \"/tmp/runner.py\", line 7, in load_model_to_session\r\n>     saver.restore(session, os.path.join(model_dir_exp, ckpt_file))\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1388, in restore\r\n>     {self.saver_def.filename_tensor_name: save_path})\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n>     run_metadata_ptr)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n>     feed_dict_string, options, run_metadata)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n>     target_list, options, run_metadata)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.DataLossError: Unable to open table file /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n>          [[Node: save/restore_slice_318 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice_318/tensor_name, save/restore_slice_318/shape_and_slice)]]\r\n> \r\n> Caused by op u'save/restore_slice_318', defined at:\r\n>   File \"/tmp/runner.py\", line 35, in <module>\r\n>     load_model_to_session(session, model_dir, meta_file, ckpt_file)\r\n>   File \"/tmp/runner.py\", line 6, in load_model_to_session\r\n>     saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1526, in import_meta_graph\r\n>     **kwargs)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.py\", line 502, in import_scoped_meta_graph\r\n>     producer_op_list=producer_op_list)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 285, in import_graph_def\r\n>     op_def=op_def)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n>     original_op=self._default_original_op, op_def=op_def)\r\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n>     self._traceback = _extract_stack()\r\n> \r\n> DataLossError (see above for traceback): Unable to open table file /data/model/a.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n>          [[Node: save/restore_slice_318 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice_318/tensor_name, save/restore_slice_318/shape_and_slice)]]\r\n> \r\n\r\nin order to reproduce this, you can use the pre-trained open source model here:\r\nhttps://drive.google.com/file/d/0B5MzpY9kBtDVSTgxX25ZQzNTMGc/view\r\n\r\nI'm using tensorflow (python) 0.12.1 .\r\n\r\nI suspect that it has something to do with the virtualization (AWS).\r\n\r\nBTW, the code works on the pretrained model http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz", "comments": ["related (unanswered yet) stackoverflow question - http://stackoverflow.com/questions/41958096/cannot-load-checkpoint-file", "seems like a currepted file", "I have the similar issue on AWS\r\n\r\n### simple code to create/save a model\r\nimport tensorflow as tf\r\nimport sys\r\nimport numpy as np\r\n\r\n\r\nw1 =  tf.Variable(tf.random_normal((2,2)), name=\"w1\")\r\nw2 =  tf.Variable(tf.random_normal((2,2)), name=\"w2\")\r\nb1 =  tf.Variable(tf.random_uniform([2],0,100, dtype = tf.int32, seed = 10), name=\"b1\")\r\nb2 =  tf.Variable(tf.random_uniform([2],0,100, dtype = tf.int32, seed = 1), name=\"b2\")\r\n\r\nsaver = tf.train.Saver()\r\nsess = tf.Session()\r\nsess.run(tf.initialize_all_variables())\r\n\r\nprint sess.run(w1)\r\nprint sess.run(w2)\r\nprint sess.run(b1)\r\nprint sess.run(b2)\r\n\r\nsaver.save(sess, 'modW1W2')\r\nsess.close()\r\n\r\n### a simple script to restore\r\nimport tensorflow as tf\r\nimport sys\r\nimport numpy as np\r\n\r\nw1 =  tf.Variable(tf.zeros((2,2)), name=\"w1\")\r\nw2 =  tf.Variable(tf.zeros((2,2)), name=\"w2\")\r\nb1 =  tf.Variable(tf.zeros(2), name=\"b1\")\r\nb2 =  tf.Variable(tf.zeros(2), name=\"b2\")\r\n\r\nmodel_saver = tf.train.Saver()\r\nwith tf.Session() as session:\r\n    model_saver.restore(session, 'modW1W2.meta')\r\n    print(\"Model restored.\") \r\n    print('Initialized')\r\n\r\n\r\n=======================================\r\n\r\n### The error I am getting\r\n\r\nDataLossErrorTraceback (most recent call last)\r\n<ipython-input-1-e2eb1ef816ae> in <module>()\r\n     12 model_saver = tf.train.Saver()\r\n     13 with tf.Session() as session:\r\n---> 14     model_saver.restore(session, 'modW1W2.meta')\r\n     15     print(\"Model restored.\")\r\n     16     print('Initialized')\r\n\r\n/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)\r\n   1343 \r\n   1344     sess.run(self.saver_def.restore_op_name,\r\n-> 1345              {self.saver_def.filename_tensor_name: save_path})\r\n   1346 \r\n   1347   @staticmethod\r\n\r\n/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    715     try:\r\n    716       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 717                          run_metadata_ptr)\r\n    718       if run_metadata:\r\n    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    913     if final_fetches or final_targets:\r\n    914       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 915                              feed_dict_string, options, run_metadata)\r\n    916     else:\r\n    917       results = []\r\n\r\n/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n    963     if handle is None:\r\n    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n--> 965                            target_list, options, run_metadata)\r\n    966     else:\r\n    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n    983         except KeyError:\r\n    984           pass\r\n--> 985       raise type(e)(node_def, op, message)\r\n    986 \r\n    987   def _extend_graph(self):\r\n\r\nDataLossError: Unable to open table file modW1W2.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n\t [[Node: save/restore_slice = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice/tensor_name, save/restore_slice/shape_and_slice)]]\r\n\t [[Node: save/restore_slice_2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_21_save/restore_slice_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op u'save/restore_slice', defined at:\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/ubuntu/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-e2eb1ef816ae>\", line 12, in <module>\r\n    model_saver = tf.train.Saver()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 986, in __init__\r\n    self.build()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1015, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 620, in build\r\n    restore_sequentially, reshape)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 357, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 270, in restore_op\r\n    preferred_shard=preferred_shard))\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 204, in _restore_slice\r\n    preferred_shard, name=name)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\r\n    preferred_shard=preferred_shard, name=name)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nDataLossError (see above for traceback): Unable to open table file modW1W2.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\r\n\t [[Node: save/restore_slice = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/restore_slice/tensor_name, save/restore_slice/shape_and_slice)]]\r\n\t [[Node: save/restore_slice_2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_21_save/restore_slice_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n", "Are you using version 12.1 by chance? That version provided new format for saving checkpoints, but didn't provide a way to read them. The solution is to save in old format:\r\n\r\n`saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)`\r\n\r\nsee: http://stackoverflow.com/questions/41048819/how-to-restore-a-model-by-filename-in-tensorflow-r12", "Hello Yaroslav,\n\n\nI just check the version, it says\n\n\nprint tf.__version__\n\n0.11.0rc2\n\n\nI am using the tensorflow in iPython notebook setup.\n\n\n\nBy the way, I found this example\n\nhttp://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python\nI believe you answered that question at some point.\n\n\n\nThese lines run ok\n\n\nw1 = tf.Variable(tf.truncated_normal(shape=[10]), name='w1')\nw2 = tf.Variable(tf.truncated_normal(shape=[20]), name='w2')\ntf.add_to_collection('vars', w1)\ntf.add_to_collection('vars', w2)\nsaver = tf.train.Saver()\nsess = tf.Session()\n#sess.run(tf.global_variables_initializer()) <--- I had to comment this out\nsess.run(tf.initialize_all_variables())\nsaver.save(sess, 'my-model')\n\n\nBut my simple, as primitive as I could get on it, would give me trouble. I am still learning the TF and I am not sure I am doing something obviously wrong.\n\n\nThank you,\n\n\u0421\u043f\u0430\u0441\u0438\u0431\u043e\n\n\n\nHakim\n\n\n\n________________________________\nFrom: Yaroslav Bulatov <notifications@github.com>\nSent: Thursday, February 9, 2017 5:14 AM\nTo: tensorflow/tensorflow\nCc: hakimka; Comment\nSubject: Re: [tensorflow/tensorflow] Tensorflow restore doesn't work on AWS (#7159)\n\n\nAre you using version 12.1 by chance? That version provided new format for saving checkpoints, but didn't provide a way to read them. The solution is to save in old format:\n\nsaver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n\nsee: http://stackoverflow.com/questions/41048819/how-to-restore-a-model-by-filename-in-tensorflow-r12\n\n[https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon@2.png?v=73d79a89bded]<http://stackoverflow.com/questions/41048819/how-to-restore-a-model-by-filename-in-tensorflow-r12>\n\nHow to restore a model by filename in Tensorflow r12 ...<http://stackoverflow.com/questions/41048819/how-to-restore-a-model-by-filename-in-tensorflow-r12>\nstackoverflow.com\nThe R12 has changed the checkpoint format. You should save the model in the old format. import tensorflow as tf from tensorflow.core.protobuf import saver_pb2 ...\n\n\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/7159#issuecomment-278549223>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADeHZ-91e90GRrrn2Q1DhRvT7JyW6aYrks5raqC2gaJpZM4LyZEX>.\n", "Hello @hakimka \r\n\r\nI had a very similar problem while trying to restore a trained DNN, which was trained in an AWS instance. I found that the tensorflow version that was installed in the AMI I was launching, was 0.12.1, while the version I have installed in my local computer, where I was trying to restore the trained DNN was 1.5.0.\r\n\r\nI update the tensorflow to 1.5.0 in the AWS instance AMI, re-trained, saved again, and then I was able to restore the trained DNN successfully. Check that the NN you are trying to restore was saved in the same version as your computer. It worked for me."]}, {"number": 7158, "title": "Documentation for Inference from saved model", "body": "As explained at https://www.tensorflow.org/tutorials/mnist/pros/#build_a_multilayer_convolutional_network I created a CNN for MNIST image recognition. I don't want to test it in the same script so I trained the model, saved the checkpoint files and graph structure and then using freeze_graph.py script(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py)  I froze it into single .pb file. Now using this .pb file I want to check the accuracy of the model but there is no clear documentation as to how to do it. There is one example written in examples/label_images directory but that too is in C++ and for inception network. I have already parsed the .pb file and made a tf.Graph object.  ", "comments": ["@ashokvishnoi1994 You will have to export your trained model with Tensorflow Serving Server for inference. Here is the documentation on Inference/serving. \r\nhttps://tensorflow.github.io/serving/serving_basic\r\nand \r\nhttps://tensorflow.github.io/serving/serving_advanced\r\n", "You should be able to run the frozen graph. Pete should know all hte details about how to run a frozen graph. :)", "@ashokvishnoi1994 Some documentation does help. But if you want to get some quick information, you can try something like this: \r\n```python\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n    input, predictions = tf.import_graph_def(g, return_elements=\r\n                                                     ['Input:0', \r\n                                                      'Predictions/Reshape_1:0'])\r\n    p_val = predictions.eval(feed_dict={input: image})\r\n```\r\nwhere you need to know the name of input node and output node when you freeze the graph.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 7157, "title": "AttributeError: 'module' object has no attribute 'constant'", "body": "I've just installed tensorflow (without the gpu) on my mac, through my virtual environment. I initially had tensorflow downloaded in my ~/ directory, but then found that I could not import it at all in python3.4. I found that I fixed this by making a copy of the tensorflow directory in my working directory fixed that. But now the problem is that once I import tensorflow with $ import tensorflow as tf, I get the message: \r\n\r\n`>>> a = tf.constant('Hello')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'constant'`", "comments": ["Maybe there is a script named Tensorflow left on your system which is getting referenced instead of the Tensorflow package...so check it and rename it", "Indeed, try a clean install and make sure you have activated the proper virtualenv, and there are no other installs of tensorflow or directories anywhere else.  \r\n\r\nThis is a question more suited for StackOverflow, so please consider posting it there and tagging 'tensorflow'", "I installed tensorflow from Source had the same problem. I noticed that while executing the command \"sudo pip install /tmp/tensorflow_pkg/tensorflow-1.5.0-py2-none-any.whl\", I was executing it by copying and pasting it directly which was wrong because the term \"tensorflow-1.5.0-py2-none-any.whl\" need to be replaced with the right name of the .whl file. First time running it gave some error but when I ran it again, it worked like a charm. You can find it in location /tmp/tensorflow_pkg. Just putting it here hoping it would save someone else's load of time."]}, {"number": 7156, "title": "Spatial Cross Entropy Loss - Feature Request", "body": "For Fully Convolutional Networks, the logits are reshaped into 2D tensors `[batch_size, n_classes]`. Can't there be a spatial loss function similar to [SpatialClassNLLCriterion](https://github.com/torch/cunn/blob/master/lib/THCUNN/SpatialClassNLLCriterion.cu') built by Torch?", "comments": ["Your link to torch is broken.", "Try [this](https://github.com/torch/cunn/blob/master/lib/THCUNN/SpatialClassNLLCriterion.cu) link?", "Ah, it's just a link to code, not documentation.  Could you give a self contained mathematical description?", "Closing for now, but I'm happy to reopen if there is a mathematical description that seems like something useful.  I'm not going to reverse engineer the meaning from code.", "I figured that [`tf.nn.softmax_cross_entropy_with_logits`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) computes the cross entropy map even for spatial inputs and spatial targets. This issue can be considered closed. Thanks!", "tf.nn.sparse_softmax_cross_entropy_with_logits is the equivalent function here -- the \"sparse_\" means that the distribution is hard, i.e. (0, 1, 0, ..., 0) not (0.5, 0.25, 0.25, 0, ... 0), which is what SpatialClassNLLCriterion is also assumes"]}, {"number": 7155, "title": "Branch 146066214", "body": "Merging internal changes", "comments": ["Closing this PR. Will do a new push once build issues are fixed."]}, {"number": 7154, "title": "Update inception_v3.py", "body": "the operation array_ops.concat has been changed, which the parameters should be concat_dim followed by values. fixed this problem which could lead a bug in fine-tune and training", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "I believe the original code is correct- check out the note for `tf.concat` for the [v1.0.0rc0](https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0-rc0) release. The changes you're making are actually changing them _back_ to the old function signature.", "@ymswhu, @samjabrahams is correct."]}, {"number": 7153, "title": "Branch 146039928", "body": "Merging internal changes.", "comments": ["Discarding it in favor of PR 7155"]}, {"number": 7152, "title": "Library not loaded: @rpath/AdobeCreativeSDKCore.framework/AdobeCreativeSDKCore", "body": "I just completed migrating my project from swift 2 to swift 3. I had installed AdobeCreativeSDKCore and AdobeCreativeSDKImages as pod file. The code builds but I get a \"**_Thread 1: signal SIGABRT_**\" error in the \"**_0_abory_with_payload_**\" file and \"**_10_dyld_start_**\" \r\n\r\n```\r\ndyld`__abort_with_payload:\r\n    0x1063966f8 <+0>:  movl   $0x2000209, %eax          ; imm = 0x2000209 \r\n    0x1063966fd <+5>:  movq   %rcx, %r10\r\n    0x106396700 <+8>:  syscall \r\n->  0x106396702 <+10>: jae    0x10639670c               ; <+20>\r\n    0x106396704 <+12>: movq   %rax, %rdi\r\n    0x106396707 <+15>: jmp    0x106396014               ; cerror_nocancel\r\n    0x10639670c <+20>: retq   \r\n    0x10639670d <+21>: nop    \r\n    0x10639670e <+22>: nop    \r\n    0x10639670f <+23>: nop    \r\n```\r\n\r\n```\r\ndyld`_dyld_start:\r\n    0x10636e000 <+0>:   popq   %rdi\r\n    0x10636e001 <+1>:   pushq  $0x0\r\n    0x10636e003 <+3>:   movq   %rsp, %rbp\r\n    0x10636e006 <+6>:   andq   $-0x10, %rsp\r\n    0x10636e00a <+10>:  subq   $0x10, %rsp\r\n    0x10636e00e <+14>:  movl   0x8(%rbp), %esi\r\n    0x10636e011 <+17>:  leaq   0x10(%rbp), %rdx\r\n    0x10636e015 <+21>:  movq   0x3ef04(%rip), %r8        ; _dyld_start_static\r\n    0x10636e01c <+28>:  leaq   -0x23(%rip), %rcx         ; <+0>\r\n    0x10636e023 <+35>:  subq   %r8, %rcx\r\n    0x10636e026 <+38>:  leaq   -0x102d(%rip), %r8\r\n    0x10636e02d <+45>:  leaq   -0x8(%rbp), %r9\r\n    0x10636e031 <+49>:  callq  0x10636e073               ; dyldbootstrap::start(macho_header const*, int, char const**, long, macho_header const*, unsigned long*)\r\n->  0x10636e036 <+54>:  movq   -0x8(%rbp), %rdi\r\n    0x10636e03a <+58>:  cmpq   $0x0, %rdi\r\n    0x10636e03e <+62>:  jne    0x10636e050               ; <+80>\r\n    0x10636e040 <+64>:  movq   %rbp, %rsp\r\n    0x10636e043 <+67>:  addq   $0x8, %rsp\r\n    0x10636e047 <+71>:  movq   $0x0, %rbp\r\n    0x10636e04e <+78>:  jmpq   *%rax\r\n    0x10636e050 <+80>:  addq   $0x10, %rsp\r\n    0x10636e054 <+84>:  pushq  %rdi\r\n    0x10636e055 <+85>:  movq   0x8(%rbp), %rdi\r\n    0x10636e059 <+89>:  leaq   0x10(%rbp), %rsi\r\n    0x10636e05d <+93>:  leaq   0x8(%rsi,%rdi,8), %rdx\r\n    0x10636e062 <+98>:  movq   %rdx, %rcx\r\n    0x10636e065 <+101>: movq   (%rcx), %r8\r\n    0x10636e068 <+104>: addq   $0x8, %rcx\r\n    0x10636e06c <+108>: testq  %r8, %r8\r\n    0x10636e06f <+111>: jne    0x10636e065               ; <+101>\r\n    0x10636e071 <+113>: jmpq   *%rax\r\n```\r\n\r\nOn the console I get\r\n```\r\ndyld: Library not loaded: @rpath/AdobeCreativeSDKCore.framework/AdobeCreativeSDKCore\r\n  Referenced from: /Users/kelvinnjeri/Library/Developer/CoreSimulator/Devices/67DEC3A4-74B9-4203-97DA-004B8B4A254E/data/Containers/Bundle/Application/2A3FB423-BA0D-4DBD-9B51-748428D91D36/CloudiT.app/CloudiT\r\n  Reason: image not found\r\n(lldb) \r\n```\r\nI've been checking the podfile, I seem to have the framework in the \"Pods\" droplist but not in the products drop list \r\n\r\n![screen shot 2017-01-30 at 4 23 24 pm](https://cloud.githubusercontent.com/assets/20662833/22442415/493d67ca-e709-11e6-81ef-de57964aa741.png)\r\n\r\n![screen shot 2017-01-30 at 4 25 32 pm](https://cloud.githubusercontent.com/assets/20662833/22442284/cdca07ce-e708-11e6-895d-4cedfea7da17.png)\r\n\r\nIm also not able to add it to the build phases cause Xcode is not giving me that option \r\n\r\n![screen shot 2017-01-30 at 4 28 21 pm](https://cloud.githubusercontent.com/assets/20662833/22442380/259b7f0a-e709-11e6-8d4a-fe54256d465c.png)\r\n\r\nI'm sure it's a simple fix, probably somewhere in the settings but I'm don't know where. I am still new to iOS development. Any response is greatly appreciated ", "comments": ["i have the same issue but could not find solution\r\ni added manually these two framwork", "I have the exact same issue, trying for the whole day ...\r\nHere you can Find some ideas: http://stackoverflow.com/a/30656819\r\nBut doesn't really work on my side\r\n", "Automatically closing due to lack of recent activity. We hope that you were able to resolve it on your own. However, since this is a support issue rather than a bug or feature request, you will probably get more information by posting it on StackOverflow."]}, {"number": 7151, "title": "Improve cudnn.h search during build (#6850)", "body": "Update _find_cuda_define() and _cudnn_version() to use\r\n_find_cudnn_header_dir() to locate the cudnn.h header. The latter\r\nalready knows how to look in multiple locations for the header.\r\n\r\nThis works on POWER Ubuntu when cuDNN is installed via tarball or\r\ndeb package and CUDNN_INSTALL_PATH is set to /usr/local/cuda-8.0.\r\n\r\nIn those cases, cudnn.h is ultimately found at:\r\n\r\n$ sudo tar -C /usr/local -xzvf cudnn-8.0-linux-ppc64le-v5.1.tgz\r\n\r\n/usr/local/cuda-8.0/targets/ppc64le-linux/include/cudnn.h\r\n\r\n-or-\r\n\r\n$ sudo dpkg -i libcudnn5*deb\r\n\r\n/usr/include/cudnn.h (is soft link to /etc/alternatives/libcudnn\r\nis soft link to /usr/include/powerpc64le-linux-gnu/cudnn_v5.h)", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 7150, "title": "Quantization:quantize_graph produces corrupted graph", "body": "Hi,\r\nsorry to bother again. In order to save some space I would like to quantize my graph, but everytime I run quantize_graph, it becomes unusable in android app later on. I would like to generally ask, how is this facility meant to be used. What I have done:\r\n\r\n\r\n1. retrained graph (works fine)\r\n2. optimized it using optimize_for_inference (works fine)\r\n3. bazel-bin/tensorflow/tools/quantization/quantize_graph \\\r\n--input=/tmp/optimized.pb \\\r\n--output=/tmp/eightbit.pb \\\r\n--output_node_names=\"final_result_a,final_result_b\" \\\r\n--mode=eightbit\r\n\r\nThen it threws on android following (excerpt):\r\n\r\n`I/native: tensorflow_inference_jni.cc:85 Creating new session variables for 635cce3c13fa1ff4\r\nI/native: tensorflow_inference_jni.cc:113 Loading Tensorflow.\r\nI/native: tensorflow_inference_jni.cc:120 Session created.\r\nI/native: tensorflow_inference_jni.cc:126 Acquired AssetManager.\r\nI/native: tensorflow_inference_jni.cc:128 Reading file to proto: file:///android_asset/eightbit.pb\r\nI/native: jni_utils.cc:111 Opening asset eightbit.pb from disk with zero-copy.\r\nI/native: tensorflow_inference_jni.cc:132 GraphDef loaded from file:///android_asset/eightbit.pb with 1345 nodes.\r\nI/native: stat_summarizer.cc:38 StatSummarizer found 1345 nodes\r\nI/native: tensorflow_inference_jni.cc:139 Creating TensorFlow graph from GraphDef.\r\nI/native: tensorflow_inference_jni.cc:151 Initialization done in 234.141ms\r\n`\r\nWhich I suppose is correct\r\n\r\nBut then:\r\n\r\n`\r\nI/native: tensorflow_inference_jni.cc:228 End computing. Ran in 2665ms (2665ms avg over 1 runs)\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0xb95eb000 in tid 31217 (inference)\r\nApplication terminated.\r\n`\r\nWould you please once again help? Thanks\r\n\r\n", "comments": ["@bazinac There should be more info associated with the segfault; can you please provide the adjacent log lines?\r\n\r\nIt might also be helpful to add some print statements following the call to runInference() until you can narrow down the exact line this crash is happening on.\r\n\r\nAs a random guess, are you positive that you're reading out the right data types from final_result_a and final_result_b?", "Thanks for answer. I put before and after log around. runInference, all I got is:\r\n```\r\n\r\n`D/INFERNECE: before\r\nI/native: tensorflow_inference_jni.cc:228 End computing. Ran in 2822ms (2822ms avg over 1 runs)\r\nD/INFERNECE: after\r\nD/INFERNECE: before\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0xb9583000 in tid 9986 (inference)\r\nApplication terminated.`\r\n\r\n```\r\n\r\n\r\n\r\nRegarding right data types reading - I suppose that quantization script should not change those, therefore when it works with just optimized_for_inference graph correctly and I just run quantization on it it shoud work in same manner, right?", "Right, so continue to place log statements until you don't see one getting hit. Then when that happens start bisecting the area between the last printout and the first missing printout until you've narrowed down the exact line.\r\n\r\nThere should also be more information associated with the segfault, could you please provide it?\r\n", "Yeah but issue is that it is happening at .runInference call, on the second time when its called. I placed those log statements like this:\r\n\r\n```\r\n    Log.d(\"INFERNECE\",\"before\");\r\n    inferenceInterface.runInference(outputNames);\r\n    Log.d(\"INFERNECE\",\"after\");\r\n```\r\n\r\nand unfortunatelly there is not any further info regarding segfault, just\r\n\r\n```\r\n01-30 23:34:35.479 9490-9700/bazinac.aplikacenahouby I/CameraDeviceState: Legacy camera service transitioning to state CAPTURING\r\n01-30 23:34:35.519 9490-9641/bazinac.aplikacenahouby D/tensorflow: CameraActivity: Initializing buffer 0 at size 228096\r\n01-30 23:34:35.529 9490-9641/bazinac.aplikacenahouby D/tensorflow: CameraActivity: Initializing buffer 1 at size 114047\r\n01-30 23:34:35.529 9490-9641/bazinac.aplikacenahouby D/tensorflow: CameraActivity: Initializing buffer 2 at size 114047\r\n01-30 23:34:35.599 9490-9640/bazinac.aplikacenahouby D/INFERNECE: beforerunInference\r\n01-30 23:34:38.359 9490-9640/bazinac.aplikacenahouby I/native: tensorflow_inference_jni.cc:228 End computing. Ran in 2765ms (2765ms avg over 1 runs)\r\n01-30 23:34:38.359 9490-9640/bazinac.aplikacenahouby D/INFERNECE: afterrunInference\r\n01-30 23:34:38.389 9490-9640/bazinac.aplikacenahouby D/INFERNECE: beforerunInference\r\n01-30 23:34:40.779 9490-9640/bazinac.aplikacenahouby A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x97028000 in tid 9640 (inference)\r\n```", "I see, you are calling runInference() twice? You should only need to call it once, even if you're reading from two output nodes. Though it shouldn't crash if you do.\r\n\r\nThere's nothing at all beyond the SIGSEGV line? That is surprising -- are you sure you're not filtering it out somehow?", "Or do you mean it crashes on the second time through? What I am trying to figure out is if you are doing something like:\r\n```\r\nfillNode* methods\r\nrunInference(finalResultA, finalResultB)\r\nreadNode* methods\r\n...\r\nfillNode* methods\r\nrunInference(finalResultA, finalResultB)\r\nreadNode* methods\r\n```\r\nor\r\n```\r\nfillNode*\r\nrunInference(finalResultA)\r\nrunInference(finalResultB)\r\nreadNode*\r\n```\r\n\r\nbecause if possibly you are reading calling runInference twice, once for each output node, and then trying to read from an output buffer that was cleared by the second runInference call, that will cause problems.", "Yeah I run it twice, because I am using two separate instances of Classifier, one for each output layer, which is probably not the best design). However it worked with non quantized version of graph.\r\n\r\nIt is actually more like:\r\n\r\n```\r\nfillNode*\r\nrunInference(finalResultA)\r\nreadNode*\r\n\r\nfillNode*\r\nrunInference(finalResultB)\r\nreadNode*`\r\n```\r\n\r\nWhen displaying really all output (not just related to my app), i see:\r\n```\r\n\r\n01-30 23:52:38.879 378-378/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n01-30 23:52:38.879 378-378/? A/DEBUG: Build fingerprint: 'samsung/j5nltexx/j5nlte:6.0.1/MMB29M/J500FNXXU1BPI1:user/release-keys'\r\n01-30 23:52:38.879 378-378/? A/DEBUG: Revision: '5'\r\n01-30 23:52:38.879 378-378/? A/DEBUG: ABI: 'arm'\r\n01-30 23:52:38.879 378-378/? A/DEBUG: pid: 25257, tid: 25857, name: inference  >>> bazinac.aplikacenahouby <<<\r\n01-30 23:52:38.879 378-378/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xb95d5000\r\n01-30 23:52:38.879 396-25924/? W/QCamera2HWI: processAutoFlashValue: AutoFlash not enabled, no ops here\r\n01-30 23:52:38.899 378-378/? A/DEBUG:     r0 b9511da0  r1 00000000  r2 b95d5000  r3 fff3cd98\r\n01-30 23:52:38.899 378-378/? A/DEBUG:     r4 00000000  r5 00000001  r6 00000001  r7 00000040\r\n01-30 23:52:38.899 378-378/? A/DEBUG:     r8 96d86020  r9 96e492e0  sl 00000001  fp 9ece219c\r\n01-30 23:52:38.899 378-378/? A/DEBUG:     ip 96d86080  sp 9ece2078  lr 00000000  pc 9e5e4dcc  cpsr a00f0030\r\n01-30 23:52:38.909 396-25924/? W/QCamera2HWI: processAutoFlashValue: AutoFlash not enabled, no ops here\r\n01-30 23:52:38.909 378-378/? A/DEBUG: backtrace:\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #00 pc 005c0dcc  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #01 pc 005cb85f  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #02 pc 005e26cf  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #03 pc 005e5dc9  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #04 pc 00606aed  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #05 pc 0064f367  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.909 378-378/? A/DEBUG:     #06 pc 0064f5df  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #07 pc 006439b3  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #08 pc 0064b2db  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #09 pc 0064b3cd  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #10 pc 0064b659  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #11 pc 0064c615  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #12 pc 006484e3  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #13 pc 00646507  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #14 pc 000991c7  /data/app/bazinac.aplikacenahouby-1/lib/arm/libtensorflow_demo.so (Java_org_tensorflow_contrib_android_TensorFlowInferenceInterface_runInference+1854)\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #15 pc 006418d5  /data/app/bazinac.aplikacenahouby-1/oat/arm/base.odex (offset 0x425000) (int org.tensorflow.contrib.android.TensorFlowInferenceInterface.runInference(java.lang.String[])+96)\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #16 pc 007de4cf  /data/app/bazinac.aplikacenahouby-1/oat/arm/base.odex (offset 0x425000) (java.util.List org.tensorflow.demo.TensorFlowImageClassifier.recognizeImage(android.graphics.Bitmap)+1650)\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #17 pc 006491ef  /data/app/bazinac.aplikacenahouby-1/oat/arm/base.odex (offset 0x425000) (void org.tensorflow.demo.ClassifierActivity$1.run()+434)\r\n01-30 23:52:38.919 378-378/? A/DEBUG:     #18 pc 037e3377  /system/framework/arm/boot.oat (offset 0x2fc3000)\r\n```\r\n```\r\n01-30 23:52:39.709 378-378/? A/DEBUG: Tombstone written to: /data/tombstones/tombstone_04\r\n01-30 23:52:39.709 378-378/? E/DEBUG: AM write failed: Broken pipe\r\n                                      \r\n                                      [ 01-30 23:52:39.709   378:  378 E/         ]\r\n                                      ro.product_ship = true\r\n                                      \r\n                                      [ 01-30 23:52:39.709   378:  378 E/         ]\r\n                                      ro.debug_level = 0x4f4c\r\n                                      \r\n                                      [ 01-30 23:52:39.709   378:  378 E/         ]\r\n                                      sys.mobilecare.preload = false\r\n01-30 23:52:39.709 3323-3323/? E/audit: type=1701 msg=audit(1485816759.709:290): auid=4294967295 uid=10162 gid=10162 ses=4294967295 subj=u:r:untrusted_app:s0:c512,c768 pid=25857 comm=\"inference\" reason=\"memory violation\" sig=11\r\n```\r\nThank you for your time Andrew, I really appreciate your help here.", "To be clear, you have instantiated two unique TensorFlowInferenceInterface objects in your app, and you use one for each layer you're interested in? If you make the calls in the opposite order, does it still crash? \r\n\r\nTo workaround your issue, if the input data remains the same in computing finaleResultA/B, you can and should get both output layers from a single runInference call on a single TensorFlowInferenceInterface instance. This will save you multiple seconds of duplicate computation anyway.\r\n\r\nIt's possible you've run into a bug in TF, but without doublechecking that all the identifiers are correct, you're not using any of the same buffers etc, it's hard to diagnose if the problem is in TF or your app. Sometimes things can seem to work in one situation, when really there is still a problem and the other codepaths just aren't as picky about the data access. If you have a minimal reproducible example you'd be willing to share I can take a look, but otherwise I'd suggest just using a single TensorFlowInferenceInterface.\r\n", "I have tried it with another phone, and here, error is the same, but log is more verbose. It might be that such a stupid design as I have produced somehow corrupts memory management in android. Please Andrew, do not waste your time here, tommorow I will rewrite my code properly to use just one Classifier (and doing fillnode just once), maybe it will help. I will post how did it went.\r\n\r\n```\r\n[D/INFERNECE: beforerunInference\r\nE/BufferQueueProducer: [SurfaceTexture-1-23802-1] dequeueBuffer: min undequeued buffer count (2) exceeded (dequeued=9 undequeued=1)\r\nI/native: tensorflow_inference_jni.cc:228 End computing. Ran in 2037ms (2037ms avg over 1 runs)\r\nD/INFERNECE: afterrunInference\r\nD/INFERNECE: beforerunInference\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x93ec0000 in tid 24104 (inference)\r\nE/BufferQueueCore: [SurfaceTexture-1-23802-1] Slot 0 is in mFreeBuffers but is not FREE (3)\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x8 in tid 23815 (Binder_2)\r\nI/libc: Another thread contacted debuggerd first; not contacting debugger.]\r\n```", "I have changed my code according to your advice and now I utilize single runInterference call on single TensorFlowInferenceInterface). However, Fatal signal 11 (SIGSEGV) still persists, when using quantized graph.\r\n\r\n**What I have tried now:**\r\nWhen I use just optimized graph, I can use both output layers of my graph just fine (final_result_A, final_result_B). When I quantize graph to eightbit, I can use just one layer (final_result_A), when I try to use both or JUST final_result_B, I get this SIGSEGV... This therefore leads me to belief, that issue is in some operation done in quantize_graph script. \r\n\r\nAre there any restrictions with usage of this script (unsupported nodes) or something like this?", "@bazinac Ok, that does seem to narrow it down to TF a bit more. I think it'd help to know more about your graph topology. What are unique nodes on the path to final_result_B that don't connect to final_result_A? What are the types/dimensions? Can you run quantize_graph with just final_result_B and then query it at runtime?\r\n\r\n@petewarden Do you know of any issues involving quantization with multiple outputs?", "I think it is just sqrt, mean, truediv and pow. Actually Andrew, maybe it would be easier if I provide my graph to you? If you promise me that you wont put it to piratebay, then I would be fine with it as I kind of trust and respect you :).\r\n\r\nOne thing here is that I have read in some old post that in order to use quantized ops, I should add \t\"//tensorflow/contrib/quantization:cc_ops\",\"/tensorflow/contrib/quantization/kernels:quantized_ops\", to my build. I will try this...", "Sure, you can email a link to andrewharp at google. Might be helpful to have both the quantized and unquantized graphs, thanks.", "Is the second output layer's name actually final_result_b? I'm not seeing it or final_result_a, only final_result.", "Sorry you're hitting so many problems @bazinac! As a side note, we're moving over active development from the Python scripts you mention to the Graph Transform Tool:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/#quantize_weights\r\n\r\nIt might be worth trying that approach just to see if there's any difference.\r\n\r\nI'll sync with Andrew and get the model files from him, in case there's anything there that helps me understand what's going wrong.", "Ok, figured out the layer names :)\r\n\r\nI've been able to reproduce this by requantizing your graph from the original optimized and then running benchmark_model on it. As you say it only crashes when reading the results from the second output node in the quantized version. We'll take a look to see what might be going on.", "Hi guys, thanks for looking into it. I fiddled with graph_transforms as proposed by Pete, however I am unable to succesfully run even strip_unused_nodes(type=float, shape=\"1,299,299,3\"). It quickly fills whole available memory of my PC (which is 8GB) and then crashes with \"terminate called after throwing an instance of 'std::bad_alloc'\", which probably means it has ran out of memory.\r\n\r\nI am eagerly anticipating any updates from you :).", "Urk! Can you copy and paste the command line you ran that hit that problem?", "```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=output.pb \\\r\n--out_graph=stripped.pb \\\r\n--inputs='Mul:0' \\\r\n--outputs=\"final_result_musoth,final_result\" \\\r\n--transforms='\\\r\nstrip_unused_nodes(type=float, shape=\"1,299,299,3\") \\\r\nremove_nodes(op=Identity, op=CheckNumerics) \\\r\nfold_constants(ignore_errors=true) \\\r\nfold_batch_norms \\\r\nfold_old_batch_norms\\\r\n'\r\n```", "Hi Andrew, is there any chance that you will find where the issue lies, or should I rather start looking into some other techniques (eg. prunning or something like this.) Thank you for your help...", "I have tracked down the issue with the transform graph command line. It's in the argument parsing code, and I have a fix pending, but in the meantime you can remove the new lines and it should work:\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=output.pb --out_graph=stripped.pb --inputs='Mul:0' --outputs=\"final_result_musoth,final_result\" --transforms='strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms'\r\n```", "Thank you very much Pete! will check when I will be back home...", "Yeap it works, this way (using transformations strip_unused_nodes, remove_nodes, all those folds, then round_weights and eightbit) my graph does not crashes anymore when used in android, like it did when I have used python scripts.\r\n\r\nHowever, final_result layer works the same in just stripped version as in eightbit, but the second one (final_result_musoth - originally referenced as final_result_b) produces completely wrong results when graph is converted to eightbit... There has to be some operation that somehow twists it. When just stripped, it works fine. Hope @andrewharp will find something. Thank you for your support guys, you are doing great job here.", "Hi guys, sorry for being such a pestilent guy, but is there any development it this? Or, could you please point me to some other possibilites how to shrink graph size (eg. some prunning), I desperately need to make it more compact for mobile deployment... Thanks", "Are you only trying to shrink the file size, rather than reduce latency? If so, try using \"quantize_weights\" rather than \"quantize_nodes\" in your call to the graph transform tool. That will store the parameters as eight bit, but use float calculations inside the graph (expanding the weights to floats the first time the graph is run). That might help your accuracy problems.", "Actually that is what I did. First I stripped graph, then rounded weights (round_weights(num_steps=256)')\r\nand then quantized weights using:\r\n\r\n`bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/tmp/rounded.pb --out_graph=/tmp/eightbit.pb --inputs='Mul:0' --outputs=\"final_result_musoth,final_result\" --transforms='quantize_weights'`\r\n\r\nHowever, after this step, it is not accuracy problem that I am hitting there - it is so that final_result_musoth layer produces super bad output when quantized (It is all the time casting almost 1 in favor of one category). I am unable to found what is causing this... With no quantization, both layers work just fine, but graph is too big. Any tips? Thanks", "UPDATE: @petewarden I think this has something to do with quantize_weights.cc script, specially with this part:\r\n```\r\n // min_value == max_value is a tricky case. It can occur for general\r\n        // tensors, and of course for scalars. The quantized ops cannot deal\r\n        // with this case, so we set max_value to something else.\r\n        // It's a tricky question what is the numerically best solution to\r\n        // deal with this degeneracy.\r\n        // TODO(petewarden): Better use a tolerance than a hard comparison?\r\n        if (min == max) {\r\n          if (std::abs(min) < 0.000001f) {\r\n            max = min + 1.0f;\r\n          } else if (min > 0) {\r\n            max = 2.0f * min;\r\n          } else {\r\n            max = min / 2.0f;\r\n          }\r\n        }\r\n```\r\n\r\nThere is some comparison (<0.000001f) and in output of my  layer which basically works totally wrong after quantization I see interference results like this:\r\n0.9999943\r\n0.9999887\r\n0.9999981\r\n0.99999905\r\n...\r\nSo they basically range with difference of that threshold. Prior to quantization, those worked correctly and have shown something between 0 and 1 based on input. Does this indicate something or is it just coincidence?  Thanks", "I noticed that [quantize_weights.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/quantize_weights.cc#L85) has:\r\n `max = min / 2.0f;` \r\n\r\nwhile [round_weights.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/round_weights.cc#L88) has:\r\n `min = 2.0f * max;`\r\n\r\nCould this be related?", "@andrewharp: is this question to me or to pete? I coud barely answer I understand the this script code jsut poorly, please treat me as BFU :D", "@bazinac Primarily for @petewarden, but you might try changing them both to match each other (for both versions) and see if anything improves.", "@andrewharp Ok will do, thanks for your support - unfortunatelly, it did not helped. Output still in range of 0.999992-0.9999995 where it was in 0.01 - 0.99 prior to quantiation.", "I have a similar issue, I think. If I quantize an inception v3 graph on Ubuntu (Intel x86_64) and test on the same platform then I get reasonable results. If I try to use the quantized graph on Linux (ARMv7) then the results are quite bad. Is there something specific to a platform that is done in quantization process? I apologize I have not investigated the quantization code/build settings in greater detail.", "@anuragrs For me it does not work after quantization even on Ubuntu. I even tried to quantize inception V3 graph prior to retraining, and it does not work... It works only when I retrain only on unquantized network (then it works on both platforms). ", "Update here, I have found out that quantization does not just corrupts my second output layer, but messes with first one as well. It seems that after quantization, classifing tends to favor just one category no matter what you feed it. Therefore I think something is definititelly wrong with quantize_weights transform (as user @Bruczzz in issue #7523 is hitting exactly same problem). Now when he is having the same problem, then I am pretty sure there is some bug in that transformation, please @andrewharp  and @petewarden help us :).\r\n\r\nI have retrained clean inception V3 graph on few categories and this is pattern of classifing, you can see that after quantization is really obsessed with T category.:\r\n\r\n`**Sample image 1 (R)**\r\n_unquantized results:_\r\nR (score = 0.40234)\r\nP (score = 0.19375)\r\nB (score = 0.19081)\r\nC (score = 0.06899)\r\nF (score = 0.06185)\r\n\r\n_quantized results:_\r\nT (score = 0.97295)\r\nL (score = 0.00936)\r\nH (score = 0.00766)\r\nG (score = 0.00272)\r\nS (score = 0.00128)\r\n\r\n**Sample image 2 (is H)**\r\n_unquantized results:_\r\nH (score = 0.99536)\r\nD (score = 0.00163)\r\nE (score = 0.00086)\r\nC (score = 0.00051)\r\nU (score = 0.00024)\r\n\r\n_quantized results:_\r\nT (score = 0.76606)\r\nH (score = 0.10995)\r\nS (score = 0.09073)\r\nD (score = 0.01019)\r\nF (score = 0.00469)\r\n\r\n**Sample image 3 ( is A)**\r\n_unquantized results:_\r\nA (score = 0.91210)\r\nX (score = 0.07343)\r\nW (score = 0.00629)\r\nG (score = 0.00273)\r\nS (score = 0.00208)\r\n\r\n_quantized results:_\r\nT (score = 0.69732)\r\nG (score = 0.07490)\r\nF (score = 0.04135)\r\nD (score = 0.03919)\r\nH (score = 0.02643)` ", "@bazinac Can you try quantization with both quantize_weights *and* quantize_nodes? I'm still investigation but adding quantize_nodes to the mix seems to yields much better results. The [eight-bit-calculations](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/#eight-bit-calculations) instructions are up-to-date.", "@amdrehertz I have tried adding quantize nodes, running transformation as described in eight-bit-calculations (just omitting stripunused in order to be able to run inference on PC). But when quantize nodes is added, it then fails when I try to run inference using eightbit graph, maybe this can show something... I get:\r\n\r\n```\r\n  File \"/home/poborak/PycharmProjects/TF/anh_evaluator.py\", line 23, in create_graph\r\n    _ = tf.import_graph_def(graph_def, name='')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 383, in import_graph_def\r\n    ops.set_shapes_for_outputs(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1667, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 652, in _call_cpp_shape_fn_impl\r\n    v = tensor_util.constant_value(op.inputs[idx])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py\", line 684, in constant_value\r\n    ret = _ConstantValue(tensor)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py\", line 584, in _ConstantValue\r\n    input_shape = tensor.op.inputs[0].get_shape()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1437, in __getitem__\r\n    return self._op._inputs[i]\r\nIndexError: list index out of range\r\n```\r\n", "Thanks! That's a different problem we are currently working on. Please add \"sort_by_execution_order\" at the end of your list of transformations. (importer.py requires some order in the graph, which transform_graph doesn't guarantee)", "Ha, now it seems to work much better. Behavior described above (quantized graph producing output leaning always toward single category) is gone. However great bit of accuracy is lost.\r\n\r\nThank you @andrehentz for the support. Appreciate it.\r\n\r\n \r\n\r\n", "@bazinac, is there something about the accuracy of the quantized graph that you think should be investigated?", "@andrehentz, currently I do not think so. There is definitelly quite significant accuracy diff, but I have not had time to check it more precisely and find some sort of pattern in it (as I am dealing with other issues in development). I will close this now as the original bug is solved and let you know in the future if I found something. Thank you for your help and kind attitude!  ", "Hello, \r\nSame case here (retrained inception v3 model).\r\nI followed everything but still have the same issue like @bazinac had (output leaning always toward single category) when running on android (using the demo example).\r\nBoth quantize_graph and eight-bit-calculations(with both quantize_weights and quantize_nodes) have the same issue.\r\nBefore quantize - i see speeds at 800ms-1.5sec on each prediction on a s7 edge exynos but great results.\r\nAfter quantize/eightbit i see 350ms-800ms speeds but predictions are always the same class.\r\n", "Hi left13, could you post the full command you are using to quantize using the 'eight-bit-calculations'?", "@andrehentz \r\nUsing a retrained inception v3 model with 100 classes\r\n\r\n`bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=retrained_graph.pb \\\r\n--out_graph=transformed_graph.pb \\\r\n--inputs='Mul' \\\r\n--outputs='final_result' \\\r\n--transforms='\r\n add_default_attributes\r\n strip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\n remove_nodes(op=Identity, op=CheckNumerics)\r\n fold_old_batch_norms\r\n quantize_weights\r\n quantize_nodes\r\n strip_unused_nodes\r\n sort_by_execution_order'`", "Would you be able to try the following?\r\n--transforms='add_default_attributes strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'\r\n\r\n(The only difference being \"fold_constants(ignore_errors=true)\")\r\n", "@andrehentz Nothing changed, same as before.", "@left13 Is there a way you can share retrained_graph.pb and maybe a couple of test images?", "@andrehentz sure, where to send the link?", "@left13 this behavior has affected my project only until I compiled latest TF from source back then in the end of February. Just mentioning this for case that you are using older TF. Good luck!", "@bazinac thanks for your suggestion, i'm already on latest TF.", "@left13  You can email the link to me. The address is in my profile. Thanks!\r\n", "Hi,\r\nI am using the latest tensorflow version (1.2.0 at this time) and I have been trying to quantize my model in order to use it in an Android application.\r\n\r\nThe steps I have followed are:\r\n  - freeze_graph.py\r\n  - bazel-bin/tensorflow/python/tools/optimize_for_inference\r\n  - bazel-bin/tensorflow/tools/quantization/quantize_graph (eightbit)\r\n\r\nI have used the prebuilt libraries (nightly Android build artifacts) and also have built the libraries myself.\r\n\r\nI can load my model and run it, but the output I get is completely outside of the expected ranges (I expect +/-1e-3 and the values are around +/-1e6 with a very small variance).\r\n\r\nI am using a VGG-based model.\r\n\r\nI would really appreciate a little guidance. Thank you in advance.\r\n\r\n", "@cpgil Could you try using bazel-bin/tensorflow/tools/graph_transforms/transform_graph instead of quantize_graph?", "@cpgil I was probably solving same issue as you some time ago. Solution for me was using transform_graph as andre proposes (like this)\r\n\r\n`bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=/tmp/output.pb \\\r\n--out_graph=/tmp/manip.pb \\\r\n--inputs='Mul:0' \\\r\n--outputs='final_result_musoth,final_result' \\\r\n--transforms='\r\n add_default_attributes\r\n strip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\n remove_nodes(op=Identity, op=CheckNumerics)\r\n fold_old_batch_norms\r\n quantize_weights\r\n quantize_nodes\r\n sort_by_execution_order'`", "@andrehentz, @bazinac I used `bazel-bin/tensorflow/tools/graph_transforms/transform_graph` as proposed but this didn't help since the output continued to be much greater than expected. \r\n\r\nI then played a little with the transformations until I used my already optimized model (optmize_for_inference) and only `--transforms='quantize_weights'`and this worked. All other combinations corrupted my graph and gave errors when loading the model even in python.\r\n\r\nI have to say I didn't think of following this path before since in most tutorials is recommended to use the \"recipe\" that I used, for this reason I though the error was somewhere else (e.g. my .so files). It would be very helpful if this approach was also included (or it has more coverage) on the documentations/tutorials. It is still unclear to me why this way works and the other one doesn't.\r\n\r\nThank you very much!\r\n"]}, {"number": 7149, "title": "[Java][Feature] Generating operation methods used to build a graph", "body": "As suggested in https://www.tensorflow.org/versions/r0.11/how_tos/language_bindings, the list of operation methods for building a graph should be generated dynamically from the list exposed by the core, using preferably protobuf. \r\n\r\nIs anyone already working on that feature? If not, I'm tempted to try it. I was thinking of generating a builder hierarchy that allows to optionally set an argument after adding an operation. For example\r\n```java\r\nGraphBuider\r\n    .matMul(a, b)\r\n        .withTransposeB(true)\r\n    .softmax(logits)\r\n    ...\r\n```\r\nand the GraphBuilder classes would be generated at build time by Bazel and would make use of the already existing OperationBuilder. Since I'm new to Tensorflow, please tell me if that doesn't make any sense to you\r\n\r\nThanks\r\n\r\n(p.s. as suggested by @drpngx, I've started this discussion as a seperate issue to avoid continuing the #5 saga)", "comments": ["Thanks @karllessard! @asimshankar should know if that's in the plans or if it would be a welcome contribution.", "Having generated code for ops in Java is indeed a next step for the Java API, but we haven't gotten around to it, or figuring out what an appropriate API would be.\r\n\r\nWe'd be happy to hear any suggestions/proposals you may have. As for the suggestion above, I don't think we want to put all operations as methods in a single `GraphBuilder` class for a few reasons such as (a) Per-op attribute handling seems a bit tricky, (b) What about custom operations defined by other external libraries (e.g. as per the [Adding a new op HOWTO](https://www.tensorflow.org/how_tos/adding_an_op/)).\r\n\r\nWe can take inspiration from the generated C++ API (see the [label_image example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc#L102) and the Go API, but it does require more thought.", "I agree that exposing operations in their own particular object would create a richer API than declaring everything into a single builder class, I'll also get my mind into it.\r\n\r\nNow, without insisting, I'll clarify how my suggestion would have handled point a), maybe some of those ideas can morph into something else:\r\n\r\n1. The generated builder class implements each operations by returning a specialized builder that inherits this same class (e.g. GraphBuilder.matMul() returns a MatMulGraphBuilder that inherits GraphBuilder).\r\n\r\n2. The specialized builder exposes all other operations directly from its superclass (for going on with graph building) + methods for setting optional attributes of the current operation, prefixed by \"with\" (e.g. withTransposeA() and withTransposeB()).\r\n\r\n3. The specialized builder is responsible of building the current operation, using internally an OperationBuilder.\r\n\r\n4. Invoking another operation on a specialized builder will therefore end the construction of the current operation and return another specialized builder for building the new operation.", "Anyone curious to see how a static API for building a graph may look like, I've pushed a little POC to my [repo](https://github.com/karllessard/tensorflow/tree/java-static-api/tensorflow/java) (this [commit](https://github.com/karllessard/tensorflow/commit/d2a5518a5830ec9d0b81912b95e3e33b64bd5ec5))  that minimally fulfill the requirements of the [LabelImage](https://github.com/karllessard/tensorflow/blob/java-static-api/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage2.java) example.\r\n\r\nThis POC focuses on the following point:\r\n\r\n1. Group operations into related topics, like the C++ client does, by generating a static API per /tensorflow/core/ops/* library (e.g. [ImageOps](https://github.com/karllessard/tensorflow/blob/java-static-api/tensorflow/java/src/main/java/org/tensorflow/ops/image/ImageOps.java), [ArrayOps](https://github.com/karllessard/tensorflow/blob/java-static-api/tensorflow/java/src/main/java/org/tensorflow/ops/array/ArrayOps.java), ...)\r\n\r\n2. Allow optional parametrization using operation-specific methods encapsulated in their own classes (e.g. the [DecodeJpeg](https://github.com/karllessard/tensorflow/blob/java-static-api/tensorflow/java/src/main/java/org/tensorflow/ops/image/DecodeJpeg.java) interface)\r\n\r\n3. Keep the simplicity and elegance of the solution from the previous version of LabelImage while allowing more flexibility to support all cases (e.g. multi-output operations, etc). The following lists supported technics to connect nodes together.\r\n  \r\na) Functionally\r\n```java\r\nop1(s, op2(s, const(s, x)), const(s, y));\r\n``` \r\nb) By node references\r\n```java\r\nConst c1 = const(s, x);\r\nConst c2 = const(s, y);\r\nop1(s, op2(s, c1), c2);\r\n```\r\nc) By node lookups\r\n```java\r\nop2(s, \"op2\", const(s, x));\r\nop1(s, s.node(\"op2\"), const(s, y));\r\n```\r\n\r\nTechnics b) and c) allows us to access output value other than the default (0) one for multi-output operations. For example:\r\n```java\r\nop1(s, s.node(\"op2\").output(1), const(s, y));\r\n```\r\n\r\nAny comments are more than welcomed", "@karllessard and I (with guidance from @asimshankar) have consolidated ideas on this thread into [a proposal for the API](https://docs.google.com/document/d/1kJ1lak4OIz0b7N6am3PSRe6i1enZgRHjbj8U-8PJ68w/edit?usp=sharing). We'd love to hear your feedback, so please continue to add comments on this issue.\r\n\r\nWe'd also like to help move things forward via code contributions, and Karl and I plan to start some related PRs. Please let us know if you're interested/working on something related, so we can jointly work to bring Java bindings for Tensorflow operators.", "Marking 'contributions welcome' since this is an issue actively being worked on.", "@karllessard @kbsriram I saw so many ops with plenty of many properties and methods, such as array_ops, control_flow_ops, nn_ops and so on,  in c++ api. Does that mean we will implement them all in Java api?", "Yes, they will all be automatically implemented in Java. All operations found in the C++ core are to be wrapped by classes generated at compile-time (TensorFlow-speaking) that will expose their inputs, attributes and outputs with named variables and methods.", "What is the current status of this issue? Is someone working on it and is it supposed to be resolved soon or is it a goal which lies far in the future?", "It is still ongoing and actively being committed but it takes some time, there is a lot of code and iterations involved. Pull request #14094 is related to this story and is currently being reviewed by @asimshankar .", "Closing as this is resolved\r\n\r\n\r\n\r\n"]}, {"number": 7148, "title": "Fix a typo", "body": "", "comments": ["Can one of the admins verify this patch?", "@mhue thanks for the fix."]}, {"number": 7147, "title": "Branch 145994731", "body": "Push internal changes.", "comments": ["@tensorflow-jenkins test this please\r\n", "@tensorflow-jenkins test this please"]}]