[{"number": 19418, "title": "R1.8", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 19417, "title": "Assertion error while using triplet_semihard_loss function", "body": "Though my label dimensions are of the form (?,1) and embeddings dimensions (?, 128)\r\nthe loss function throwing out assertion error.\r\n\r\n[  lshape = array_ops.shape(labels)](https://github.com/tensorflow/tensorflow/blob/4bd6243e45f7e4c9757e32e499495ac1ec28f95f/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py#L178)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Yes, i wrote a custom code.\r\nBasically im trying to use `tf.contrib.losses.metric_learning.triplet_semihard_loss` function to calculate loss.\r\nit takes input as labels, embeddings so when i tried to use it with Y(?,1) and Z3(?,128).\r\nit is throwing assertion error though those are valid inputs and the exact point where im getting assertion error is [here](https://github.com/tensorflow/tensorflow/blob/4bd6243e45f7e4c9757e32e499495ac1ec28f95f/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py#L178)\r\n\r\n\r\nremaining fields are irrelevant so consider them as N/A", "I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n", "Problem still exists \r\n\r\n    178   lshape = array_ops.shape(labels)\r\n--> 179   assert lshape.shape == 1\r\n    180   labels = array_ops.reshape(labels, [lshape[0], 1])\r\n    181 \r\n\r\nAssertionError: "]}, {"number": 19416, "title": "ImportError : no module named 'pywrap_tensorflow_internal'", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nwindows 7 ultimate 64 bit.\r\n- **TensorFlow installed from (source or binary)**:\r\nconda\r\n- **TensorFlow version (use command below)**:\r\n1.8.0\r\n- **Python version**: \r\n3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n1 . conda create -n tensorflow pip python=3.5\r\n2 . activate tensorflow\r\n3 . pip install --ignore-installed --upgrade tensorflow\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n\r\nLog from tf_env_collect.sh\r\n\r\nCollecting system information...\r\ncat: /proc/1/cgroup: No such file or directory\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/SRIDHA~1/AppData/Local/Temp/check_tf.py\", line 1, in <module>\r\n    import tensorflow as tf;\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\SridharKannan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nWrote environment to tf_env.txt. You can review the contents of that file.\r\nand use it to populate the fields in the github issue template.\r\n\r\ncat tf_env.txt\r\n\r\n\r\n### Describe the problem\r\n I tried to install tensorflow in my laptop.The installation went smoothly , but I'm getting error while importing tensorflow . \r\n\r\n### Source code / logs\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 938, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 938, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\SridharKannan\\Miniconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["This looks like a duplicate of #17386. "]}, {"number": 19415, "title": "Expose stream executor namespace in cmake shared object.", "body": "", "comments": ["Testing here:\r\nhttp://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/29/", "Another try here\r\nhttp://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/30/", "Yet another try:\r\nhttp://ci.tensorflow.org/job/tf-pr-win-cmake-gpu/31/", "I think we now got around the symbol limit issue, however now I am seeing this:\r\nhttp://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/34/console\r\n```\r\nC:\\tf_jenkins\\workspace\\tf-pr-win-cmake-gpu\\cmake_build\\Release\\contrib_image_sirds_ops_gen_python.exe : fatal error LNK1169: one or more multiply defined symbols found [C:\\tf_jenkins\\workspace\\tf-pr-win-cmake-gpu\\cmake_build\\contrib_image_sirds_ops_gen_python.vcxproj]\r\n```", "We now have a successful build!\r\nhttp://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/38/"]}, {"number": 19414, "title": "Feature Request: Add support in TFAndroid to toggle camera for DetectorActivity in TF Detect", "body": "Add Toggle camera button widget in TF Detect App for detecting objects using front camera of the phone.\r\nThanks!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 36 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@aselle I have swapped the camera to front view but the bboxes are inverted. I do not know where to change the drawing orientation so that the bboxes for the front camera are correct. Could you help me with it? Thanks!", "@achowdhery , could you take a look at this feature req?", "The AndroidManifest.xml is where we configure Portrait or Landscape mode.", "@achowdhery I was looking for object detection using front camera. I switched to front camera but the detected bounding boxes are incorrect? I think they are inverted with respect to the camera orientation. Could you suggest me where to edit the code to correct this problem? Thanks! The stack overflow question is here https://stackoverflow.com/q/51268196/9394171", "@DeepakSridhar You may need to look at lines 160-163 of TFLiteObjectDetectionAPIModel.java to ensure that the image input (pixelValue) is passed in the correctly - we configured this for portrait mode right now. It could be that switching i and j will work.\r\n\r\n160    for (int i = 0; i < inputSize; ++i) {\r\n161     for (int j = 0; j < inputSize; ++j) {\r\n162     int pixelValue = intValues[i * inputSize + j];\r\n\r\nLet us know once you test this.", "@achowdhery I got it working by a hack by subtracting the bounding boxes from the model input size.\r\n I am not using TFLite. I will convert my model to TFLite and test it and will let you know. Just curious, how fast is TFLite models compared to pb models for object detection on android?", "We are getting 15fps on Pixel 2 with SSD as referenced in blog post:\r\nhttps://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193", "Hi @achowdhery \r\nI also using front camera, I detected bounding boxes correct.\r\nNow I have added the tracking module by tensorflow/examples/android demo.\r\nHowever, when i tracking object, The target box is always moving in the opposite direction to the left and right. \r\nCan you give me some advice\uff1fThanks.", "@jackweiwang: Possible option: Tracking code is not aware of front camera. You may consider checking code carefully", "@DeepakSridhar My boxes are moving in the opposite direction to the left and right. Can you tell me exactly what you did to solve this problem? Thanks.", "@minhnbwork97 You have to flip the boxes before it is being drawn. If your model input size is 300, then subtract the output from 300 in the RectF location variable in processImage() in DetectorActivity.java file.", "@DeepakSridhar Thank you. That's a pretty good idea but it doesn't seem to work well for me. There were 2 or more boxes appearing on my screen, each appeared when I moved my object out of the old box. Did it work well for you? If it did can you tell me more details about how you modified the RectF location variable?  Btw this is my code: \r\n![image](https://user-images.githubusercontent.com/38205529/47833325-bd12e880-ddcc-11e8-894d-2c716fb62d00.png)\r\n", "I figured out how to solve this problem. I put this under camera.setDisplayOrientation(90); in LegacyCameraConnectionFragment.java \r\n![image](https://user-images.githubusercontent.com/38205529/47947503-266f3480-df50-11e8-96d3-1f4941674379.png)\r\n", "I converted the rgbFrameBitmpp like this:\r\npublic Bitmap convertBmp(Bitmap bmp) {\r\n    int w = bmp.getWidth();\r\n    int h = bmp.getHeight();\r\n    Matrix matrix = new Matrix();\r\n    matrix.postScale(-1, 1); // \u955c\u50cf\u6c34\u5e73\u7ffb\u8f6c\r\n    Bitmap convertBmp = Bitmap.createBitmap(bmp, 0, 0, w, h, matrix, true);\r\n    return convertBmp;\r\n  }\r\nrgbFrameBitmap = convertBmp(rgbFrameBitmap); \r\nand then I got correct box.\r\n however,  when target moves, the box is still there, and new box which is correct shows, too. I am wondering why  it happens @@", "@minhnbwork97  \r\nhi, I still can't solve the problem you had solved.\r\nI use landscape orientation, could you take a look on my problem please?\r\nThis problem has taken me a couple of days.\r\nI also  recorded my problem in a video, and I put the link on the issue.\r\nhttps://github.com/tensorflow/tensorflow/issues/23919", "@jktruimp1  Don't change location like you did here, just delete these 2 lines and it will work correctly. You only need to flip the front camera. \r\n![image](https://user-images.githubusercontent.com/38205529/48932984-10daa280-ef31-11e8-9ae6-2847664427c8.png)\r\n", "@minhnbwork97  could you show me that where I have to change my code?\r\nif I delete these code I will get opposite derection in detecting.", "@jktruimp1 you only need to put this code under camera.setDisplayOrientation(90); in LegacyCameraConnectionFragment.java \r\n![image](https://user-images.githubusercontent.com/38205529/48991266-cfcad400-f164-11e8-9f98-16b417dfa135.png)\r\n", "@minhnbwork97  I use landscape and front camera, and I didn't use this code\r\n//  camera.setDisplayOrientation(90);\r\nI have tried your way, but I get black scene, and the tracking box is still in opposite direction", "your way didn't work for me QQ", "I see\r\n", "Did you change any line of code in TF example before adding my flip camera code?", "@minhnbwork97 \r\nin LegacyCameraConnectionFragment.java\r\nI change\r\ncamera.addCallbackBuffer(new byte[ImageUtils.getYUVByteSize( s.width,s.height)]);\r\ntextureView.setAspectRatio(s.width,s.height);\r\nand \r\n\r\nstatic {\r\n    ORIENTATIONS.append(Surface.ROTATION_0, 0);\r\n    ORIENTATIONS.append(Surface.ROTATION_90, 90);\r\n    ORIENTATIONS.append(Surface.ROTATION_180, 180);\r\n    ORIENTATIONS.append(Surface.ROTATION_270, 270);\r\n  }", "Well try undoing these change and add my code. The point is, TF example only work for back camera, positioning and tracking object might be programmed to work only for back camera too. So I think the easiest way to solve this problem is to flip front camera to make it look like we're using back camera, in my case it worked perfectly. These pictures might help you get it, they show the difference between before and after I add my flip camera code\r\n![1](https://user-images.githubusercontent.com/38205529/48992370-f3444d80-f169-11e8-8129-43483ffdd160.png)\r\n![2](https://user-images.githubusercontent.com/38205529/48992371-f3444d80-f169-11e8-86c9-46da3dc1b99b.png)\r\n\r\n", "still not working, my screen is black, and the detection's direction is wrong now...(maybe it's because I use landscape?)\r\nthey are counterclockwise 90 degree now.\r\nI will try more way to solve it , thank you very much :)\r\n", "Btw I can't watch your video. Do you have any other direct link? I'm kinda curious.", "@minhnbwork97 \r\nVideo\u2019s link\r\nhttps://drive.google.com/file/d/1LQ9Pr9ETl4Jd3W9qNRunhWKLP06PnNAM/view?usp=drivesdk\r\n\r\n\r\nminhnbwork97 <notifications@github.com>\u65bc 2018\u5e7411\u670826\u65e5 \u9031\u4e00\uff0c\u4e0b\u534812:16\u5beb\u9053\uff1a\r\n\r\n> Btw I can't watch your video. Do you have any other direct link? I'm kinda\r\n> curious.\r\n>\r\n> \u2014\r\n> You are receiving this because you are subscribed to this thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/19414#issuecomment-441514127>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/AJuUMNmunUTjHbvK7I7dsPFuDzkU_e9Vks5uy2sqgaJpZM4UF7en>\r\n> .\r\n>\r\n", "Hello, I have same problem, can anyone to help me?", "Wishing there were a more elegant solution, but for a hack of the source, you can flip the bounding box from left to right by adding \r\n```\r\nlocation.set((TF_OD_API_INPUT_SIZE - location.left), location.top, (TF_OD_API_INPUT_SIZE - location.right), location.bottom);\r\n```\r\njust above [this](https://github.com/tensorflow/examples/blob/f55194adcfafa5cddd57f8c05d42b8a428e9d24b/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/DetectorActivity.java#L204)"]}, {"number": 19413, "title": "StreamingFilesDataset fixes", "body": "This PR fixes an issue with StreamingFilesDataset, where the remote call always returns a string. Now the remote call will output a dataset with types based on the output types of the source dataset.\r\n\r\nAdditionally, 2a6c599 introduced some functionality so that StreamingFilesDataset always emits the 0th element of the remote call (not sure why). I just did a small fix to get that working again if multiple output types are specified.", "comments": ["@saeta "]}, {"number": 19412, "title": "[Batch Normal] Would you have plan to sync batch normalization?", "body": "For semantic segmentation, it is very import to syncbn. would you tell us how to do it?", "comments": ["Duplicate of #18222", "If we can use it like tf.layers?"]}, {"number": 19411, "title": "Fix typo", "body": "fix typo", "comments": []}, {"number": 19410, "title": "Add stream executor as a cmake dependency.", "body": "This is to avoid build failures for gpu kernels that look like:\r\nCreating library T:/src/github/tensorflow/cmake_build/Release/_gru_ops.lib and object T:/src/github/tensorflow/cmake_build/Release/_gru_ops.exp\r\n    12>blas_gemm.obj : error LNK2019: unresolved external symbol \"public: class stream_executor::Stream & __cdecl stream_executor::Stream::ThenBlasGemm(enum stream_executor::blas::Transpose,enum stream_executor::blas::Transpose,unsigned __int64,unsigned __int64,unsigned __int64,float,class stream_executor::DeviceMemory<float> const &,int,class stream_executor::DeviceMemory<float> const &,int,float,class stream_executor::DeviceMemory<float> *,int)\" (?ThenBlasGemm@Stream@stream_executor@@QEAAAEAV12@W4Transpose@blas@2@0_K11MAEBV?$DeviceMemory@M@2@H2HMPEAV52@H@Z) referenced in function \"public: void __cdecl tensorflow::functor::TensorCuBlasGemm<float>::operator()(class tensorflow::OpKernelContext *,bool,bool,unsigned __int64,unsigned __int64,unsigned __int64,float,float const *,int,float const *,int,float,float *,int)\" (??R?$TensorCuBlasGemm@M@functor@tensorflow@@QEAAXPEAVOpKernelContext@2@_N1_K22MPEBMH3HMPEAMH@Z) [T:\\src\\github\\tensorflow\\cmake_build\\_gru_ops.vcxproj]", "comments": ["Also testing with this build:\r\nhttp://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/26/", "Another try at http://ci.tensorflow.org/view/TF%20pull%20requests/job/tf-pr-win-cmake-gpu/28", "This did not work. reverting."]}, {"number": 19409, "title": "Branch 197218170", "body": "Merging internal changes", "comments": []}, {"number": 19408, "title": "Add missing dependencies to test_lite_main", "body": "", "comments": ["contrib failure looks liike a flake."]}, {"number": 19407, "title": "Using estimators created by `tf.keras.estimator.model_to_estimator` in `tf.estimator.train_and_evaluate` causes a memory leak of sorts", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see provided gist\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian Jessie\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: ('v1.8.0-0-g93bc2e2072', '1.8.0')\r\n- **Python version**: 2.7.9\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: Run provided gist\r\n\r\n\r\n### Describe the problem\r\nWhen using keras models with `train_and_evaluate`, you need to convert them into estimators first. The best way to do this is `tf.keras.estimator.model_to_estimator`. However, when `train_and_evaluate` is called with those estimators, the default graphs that are created end up referenced in `_GRAPH_LEARNING_PHASES` and never deallocated (so sort of a memory leak). This is due to a call to `keras.backend.set_learning_phase` that's done as part of the created `model_fn`, which uses the default graph as a key into `_GRAPH_LEARNING_PHASES`. Since that graph changes every so often in `train_and_evaluate`, that key changes so there's a new key inserted without the old ones being removed.\r\n\r\nOr at leas, I'm 80% certain that's what's going on. You can see in the provided code a very simple Keras model turned into an estimator and then run with a hook that prints out memory usage and the size of `_GRAPH_LEARNING_PHASES`. It increases over time!\r\n\r\nWhile the leak is small in the provided example, it has caused me great strife in real usage.\r\n### Source code / logs\r\n\r\nThe source code and a sample run are provided in [this gist](https://gist.github.com/zmjjmz/392ead713f19db025390f6d8de17bde2). It should be easy to run the python script yourself however you'll need to have `numpy` and `psutil` installed.", "comments": ["I found that adding : \r\n\r\n```python\r\nclass MemoryLogHook(tf.train.SessionRunHook):\r\n    def begin(self):\r\n        K._GRAPH_LEARNING_PHASES = {}\r\n        K._GRAPH_UID_DICTS = {}\r\n```\r\n\r\nfixes the issue. (will stabilize around 1.35e+9) We probably need to clear those before calling the model_fn. [Here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/keras.py#L339)\r\n\r\n```python\r\n  def model_fn(features, labels, mode):\r\n    \"\"\"model_fn for keras Estimator.\"\"\"\r\n\r\n    # Clear graphs before doing anything.\r\n    # Cannot call K.clear_session because the graph is read_only.\r\n    K._GRAPH_LEARNING_PHASES = {}\r\n    K._GRAPH_UID_DICTS = {}\r\n```\r\n", "Hey thanks! This workaround works for me, although I imagine it's probably not the best solution :)", "Also I think that this workaround will not work with `mode_to_estimator` cause in that case the model_fn it is not explicitly built.", "ping @fchollet ", "Just a quick update: as of 1.9 at least, it seems like this is still happening with `model_to_estimator`. Here's a graph of memory usage on an EC2 instance during a `train_and_evaluate` run using a Keras model that was turned into an Estimator.\r\n\r\n![keras_memleak_tf19](https://user-images.githubusercontent.com/1694612/44674768-87343b00-a9fc-11e8-9f49-a3776b59793b.png)\r\n\r\nIs there any progress on this?", "Any updates on this?", "@zmjjmz We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/19407\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/19407\">No</a>\n"]}, {"number": 19406, "title": "runtime error in monitored_session.py", "body": "The complete code I am running is very short: its in a github project RL-Implementation-IMPALA where I uncommented the with GPU in the learner. The code runs fine if you do not use the GPU.  I have installed tensorflow-gpu 1.4 under ubuntu16.04.   I can run  nvidia-settings  and it shows the GPU gtx1060 \r\n\r\n\r\n```\r\nFile \"/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 368, in MonitoredTrainingSession\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save/StringJoin': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:explorer/replica:0/task:0/device:CPU:0, /job:learner/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n\t [[Node: save/StringJoin = StringJoin[N=2, separator=\"\", _device=\"/device:GPU:0\"](save/Const, save/StringJoin/inputs_1)]]\r\n\r\n```", "comments": ["closing do to misunderstanding of usage . "]}, {"number": 19405, "title": "1.6.1 release preparation", "body": "", "comments": []}, {"number": 19404, "title": "Make distributed_test use tf-nightly by default.", "body": "", "comments": []}, {"number": 19403, "title": "INTEL MKL: Enhance MkL Pooling ops with primitive reuse", "body": "Enable MKL Pooling ops with primitive reuse, to improve\r\n  (1) model training and\r\n  (2) inference of small batch size\r\nby minimizing primitive creation time.\r\n\r\n************ Notes *******************\r\nPlease review and merge this PR first\r\n https://github.com/tensorflow/tensorflow/pull/19399\r\n", "comments": ["Close temporarily - pending conv_bwd PR", "mkl_conv_ops.cc has been reverted to avoid any review confusion. \r\nThe new version of mkl_conv_ops.cc is contained in PR #19399. \r\n\r\nThanks", "Pending on https://github.com/tensorflow/tensorflow/pull/19754\r\n", "Reopen since PR #19399 has been merged", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Yes, i have already singed CLA, and should be ok to contribute.", "Yes, i have already singed CLA, and should be ok to contribute.", "Hi, \r\nI am the PR submitter and confirm that I am OK with all the changes made by yiqianglee.\r\nThanks,\r\nGZ", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Hi Rasmus, \r\nThank you for all review suggestions which I have taken with code change,\r\nexcept one (common class for fwd/bwd primitive reuse classes) which needs more thoughts - maybe done with a separate PR. \r\nThanks,\r\nGZ", "Hi @gzmkl, thanks for the update. I agree that refactoring the class structure can wait. Let me take a look.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Code refactoring in mkl_util.h SetOp() method causes unit test failures in ops/nn_grad_test.py.\r\nThis refactoring code has been backed out. ", "For the couple of conflicts in mkl_util.h, please take the \"master\" code.\r\nI do not have \"write access\" to the repo, so I cannot address conflict myself (\"Mark as Resolved\" button is grayed out). \r\n\r\nThanks!", "@gzmkl resolved.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "Rasmus, many thanks to you for your help in address the merge conflict.   - GZ"]}, {"number": 19402, "title": "INTEL MKL: Enhance MkL BatchNorm ops with primitive reuse", "body": "Enable MKL BatchNorm ops with primitive reuse, to improve\r\n  (1) model training and\r\n  (2) inference of small batch size\r\nby minimizing primitive creation time.\r\n\r\n************ Notes *******************\r\nPlease review and merge this PR first\r\n https://github.com/tensorflow/tensorflow/pull/19399\r\n", "comments": ["Close temporarily - pending conv_bwd PR", "mkl_conv_ops.cc has been reverted to avoid any review confusion. \r\nThe new version of mkl_conv_ops.cc is contained in PR #19399. \r\n\r\nThanks", "Pending on https://github.com/tensorflow/tensorflow/pull/19754", "Reopen since PR #19399 has been merged", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Yes, i have already singed CLA, and should be ok to contribute.", "Hi, \r\nI am the PR submitter and confirm that I am OK with all the changes made by yiqianglee.\r\nThanks,\r\nGZ", "@gzmkl I think many of my comments for PR 19403 would apply to this as well, please modify accordingly.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "Plan to apply  PR 19403 comments on this PR too.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Latest code change based on PR 19403 code review suggestions.\r\nSummary:\r\n   (1) Change signature of Execute (...) so that input parameters are declared as \"const\" while output parameter as \"non-const\". \r\n   (2) In many places, remove unnecessary static_cast and const_cast to simplify the code.\r\n   (3) Back-out code in SetOp() method (mkl_util.h) - using \"emplace\" causes unit test failures of ops/nn_grad_test.py. \r\n   (4) Minor changes in some comment statements to make descriptions more accurate. \r\nBTW, related code review suggestions from PR 19399 & 19400 have also been reflected in this PR. ", "@gzmkl Thanks for the update. Let's try to get PR 19403 merged first before we push the remaining PRs. Running tests for it again now.\r\n\r\n", "@gzmkl resolved conflict", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "Hi Rasmus,\r\n\r\nPlease choose \"master\" version to address the following conflict in mkl_util.h\r\n\r\n  <<<<<<< primreuse_batch_norm\r\n#include <vector>\r\n=======\r\n>>>>>>> master\r\n\r\nLine of \"#include <vector>\" seems to be duplicated. ", "Please take the branch code with the following conflict\r\n<<<<<<< primreuse_batch_norm\r\n#include \"tensorflow/core/platform/cpu_info.h\"                          // Keep this line\r\n=======\r\n>>>>>>> master\r\n\r\nThanks!"]}, {"number": 19401, "title": "Adding back abi and stacktrace dependencies to stacktrace_handler", "body": "Corresponding headers are referenced in:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/stacktrace_handler.cc", "comments": []}, {"number": 19400, "title": "INTEL MKL: Enhance Mkl Relu Op with primitive reuse", "body": "Enable MKL primitive reuse for Relu Op via caching, to improve\r\n  (1) model training and\r\n  (2) inference of small batch size\r\nby minimizing primitive creation time.\r\n\r\n************ Notes *******************\r\n   Please review and merge this PR first \r\n          https://github.com/tensorflow/tensorflow/pull/19399\r\n    ", "comments": ["Close temporarily - pending conv_bwd PR ", "mkl_conv_ops.cc has been reverted to avoid any review confusion. \r\nThe new version of mkl_conv_ops.cc is contained in PR #19399. \r\n\r\nThanks", "@rmlarsen there are a few of these CLs, I am assigning them to you. You could try to enlist @tatianashp if she's up for it.", "Pending on https://github.com/tensorflow/tensorflow/pull/19754\r\n", "Reopen since PR #19399 has been merged", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Yes, i have already singed CLA, and should be ok to contribute.", "Hi,\r\nI am the PR submitter and confirm that I am OK with all the changes made by yiqianglee.\r\nThanks,\r\nGZ", "@gzmkl I think many of my comments for PR 19403 would apply to this as well, please modify accordingly.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "Plan to apply  PR 19403 comments on this PR too.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@gzmkl resolved conflict.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "I think the Mac error is unrelated to this CL.\r\n\r\n```\r\nERROR: /Volumes/BuildData/tmpfs/bazel_output/_bazel_kbuilder/d1b2600cd78e76a92812a06683f5de10/external/com_google_googletest/BUILD.bazel:45:1: Couldn't build file external/com_google_googletest/_objs/gtest/external/com_google_googletest/googletest/src/gtest-death-test.o: C++ compilation of rule '@com_google_googletest//:gtest' failed: Unexpected IO error.: Running '/Volumes/BuildData/tmpfs/bazel_output/_bazel_kbuilder/d1b2600cd78e76a92812a06683f5de10/execroot/org_tensorflow/_bin/xcode-locator 8.3.3' failed with code 1.\r\nThis most likely indicates that xcode version 8.3.3 is not available on the host machine.\r\nProcess exited with status 1\r\nstdout: error: Unable to extract CFBundleShortVersionString from URL: file:///Volumes/BuildData/tmpfs/bazel_output/_bazel_kbuilder/d1b2600cd78e76a92812a06683f5de10/external/grpc/tools/dockerfile/distribtest/node_ubuntu1604_x64/\r\n```", "@gzmkl can you ping this PR when you are done applying the changes suggested in PR 19403, please?", "Hi Rasmus, I am done with code change with this PR. Thanks!\r\n\r\nFrom: Rasmus Munk Larsen [mailto:notifications@github.com]\r\nSent: Tuesday, July 31, 2018 5:21 PM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Zhuang, Guozhong <guozhong.zhuang@intel.com>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] INTEL MKL: Enhance Mkl Relu Op with primitive reuse (#19400)\r\n\r\n\r\n@gzmkl<https://github.com/gzmkl> can you ping this PR when you are done applying the changes suggested in PR 19403, please?\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/pull/19400#issuecomment-409408371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Ab3J2y4p2rtzWj9xpELB3flY7T-p-c88ks5uMPRXgaJpZM4UFTyj>.\r\n", "Sorry, this PR is for relu, and I have not done the code change per suggestions from PR 403.\r\n\r\nThe thing is that there are quite a few recent changes with MKL relu op and we are doubt-check if\r\nThis PR (developed long time ago) overwrite any of them.\r\n\r\nThanks!\r\n\r\nFrom: Rasmus Munk Larsen [mailto:notifications@github.com]\r\nSent: Tuesday, July 31, 2018 5:21 PM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Zhuang, Guozhong <guozhong.zhuang@intel.com>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] INTEL MKL: Enhance Mkl Relu Op with primitive reuse (#19400)\r\n\r\n\r\n@gzmkl<https://github.com/gzmkl> can you ping this PR when you are done applying the changes suggested in PR 19403, please?\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/pull/19400#issuecomment-409408371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Ab3J2y4p2rtzWj9xpELB3flY7T-p-c88ks5uMPRXgaJpZM4UFTyj>.\r\n", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "I have done code change per code review suggestions from other PR (19403). \r\n\r\nPlease ignore changes in mkl_util.h after PR 19403/19402 have been approved.  \r\n\r\nThanks!", "Hi,\r\n\r\nI have done code change with PR (taking review comments of previous related PRs such as #19403; rebase mkl_util.h to avoid merge conflicts etc). Please let me know if I need to take future actions.\r\n\r\nThanks!", "Could you pull rebase and push again to resolve the conflicts? Thanks.", "@yiqianglee do you approve the commit for the CLA?", "Hi, \r\nRamesh of our team will take care of merge conflicts, as he has seen many of such on multiple PRs but did not have time to fix this PR.\r\n\r\nThanks,\r\nGZ", "hi @drpngx ,  I am OK with all the changes made by @gzmkl . Thanks!", "I am ok with my commits being contributed to this project. ", "I am OK with the change (to address merge conflicts) by Ramesh.\r\n\r\n", "Hi, \r\nRamesh has helped to address the merge conflict. \r\nSomehow the \"cla\" tag still says \"no\". Please help to address the cla problem.\r\n\r\nWe would like to merge this PR asap, because we need to submit Relu3D before the end of the Friday, to give a two-week window for getting into Tensorflow 1.11.\r\n\r\nThank you!", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "@rmlarsen if you have time, then the authors would like to have this reviewed in the next couple of days or so to make the `1.11` release cutoff.", "I am OK with the change by Ramesh and GZ.", "@gzmkl Thanks. Sorry about the review delay.", "Rasmus,\r\nThank you very much for the diligent work of review all primitive reuse PRs. \r\nThere were too much code change (almost rewriting MKL-DNN integration code). \r\nWe truly appreciate your hard work with valuable code refinement suggestions. Great collaboration!\r\n-GZ", "Hi, \r\nI saw this PR approved but was not merged. There was a time-time during \"Internal CI Build\".\r\nPlease let me know what I can help. Thanks!  -GZ"]}, {"number": 19399, "title": "INTEL-MKL:  Enhance Mkl conv2d backward (filter and input) ops with primitive reuse", "body": "1. Enable MKL primitive reuse for backward conv2d (filter & input) to improve performance of\r\n   (1) model training and\r\n  (2) inference of small batch size\r\n\r\n", "comments": ["Hi Rasmus, please let me know when you start to review this.\r\nI have budgeted my time to take actions on your suggestions for code change.\r\nBest,\r\nGZ", "For conv2d forward related refactoring work, I will create a new PR. \r\nOnce the new PR is reviewed and merged, I will reopen this one. ", "Reopen since PR #19754 has been approved", "cc: @yifeif "]}, {"number": 19398, "title": "Implemented cosine distance metric", "body": "Losses in `tf.contrib.losses.metric_learning` rely only on euclidean distance.\r\nI implemented the cosine distance that can be used to calculate the losses for:\r\n\r\n- `lifted_struct_loss`\r\n- `cluster_loss`\r\n- `triplet_semihard_loss`\r\n\r\nI added an extra argument `metric` with default value `euclidean`, in order to make the API backward compatible.", "comments": ["Hi @case540 - I was wondering if the PR can be merged.\r\nThanks", "@kokoro-team \r\nI am not sure how to fix the checks that were not successful\r\n\r\n", "This seems like the relevant logs\r\n\r\nTest output for //bazel_pip/tensorflow/contrib/losses:metric_loss_ops_test:\r\n  File \"/home/kbuilder/.cache/bazel/_bazel_kbuilder/f2d52ca1f092ccbe254cc98c3dc90790/execroot/org_tensorflow/bazel-out/k8-opt/bin/bazel_pip/tensorflow/contrib/losses/metric_loss_ops_test.runfiles/org_tensorflow/bazel_pip/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops_test.py\", line 215\r\n    pairwise_dist_fn=metric_loss_ops.pairwise_distances_cosine))\r\n                                                               ^\r\nSyntaxError: invalid syntax\r\n", "@case540 - it should be fixed now.", "@case540 - Once again, I hope it's fixed now.", "Thanks for working through the errors. This seems now like most recent issues...\r\n\r\n\r\nERROR:  testPairwiseCosine (__main__.PairwiseCosineTest)\r\n\r\nTraceback (most recent call last):\r\n  File \"/b/s/w/ir/run/bazel-out/k8-opt/bin/tensorflow/contrib/losses/metric_loss_ops_test.runfiles/org_tensorflow/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops_test.py\", line 68, in testPairwiseCosine\r\n    sklearn_result = 1 - metric.pairwise.cosine_similarity(embedding)\r\nNameError: name 'metric' is not defined\r\n\r\nERROR:  testTripletSemiHardCosine (__main__.TripletSemiHardLossCosineTest)\r\n\r\nTraceback (most recent call last):\r\n  File \"/b/s/w/ir/run/bazel-out/k8-opt/bin/tensorflow/contrib/losses/metric_loss_ops_test.runfiles/org_tensorflow/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops_test.py\", line 176, in testTripletSemiHardCosine\r\n    pdist_matrix = 1 - metric.pairwise.cosine_similarity(embedding)\r\nNameError: name 'metric' is not defined", "@case540 - Little by little I'll make this work and merged :)", "@case540 - ready to test again", "@case540 \r\nI need your help with this.\r\nThe error is\r\n```bash\r\nAttributeError: module 'tensorflow.contrib.losses.python.metric_learning' has no attribute 'pairwise_distance_cosine'\r\n```\r\nBut `pairwise_distance_cosine` is defined in `tensorflow.contrib.losses.python.metric_learning` (it's the module where I added it)\r\nI don't understand why `MacOS Contrib` doesn't fail and `Ubuntu contrib` does.\r\n\r\nThanks", "Guessing you have to modify tensorflow/contrib/losses/python/metric_learning/__init__.py to add the API to _allowed_symbols? Not really familiar with the code too much", "Also, you will need to fix these pylint errorrs....\r\n\r\n\r\nFAIL: Found 4 non-whitelited pylint errors:\r\ntensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py:86: [C0301(line-too-long), ] Line too long (112/80)\r\ntensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py:97: [C0326(bad-whitespace), ] Exactly one space required around assignment\r\ntensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py:186: [C0301(line-too-long), ] Line too long (94/80)\r\ntensorflow/contrib/losses/python/metric_learning/metric_loss_ops_test.py:179: [C0330(bad-continuation), ] Wrong hanging indentation (add 4 spaces).\r\n\r\nAnd sorry for taking so long to respond", "Thanks, I'll work on it\r\n", "@case540 \r\nI fixed the `_allowed_symbols`, but I am not sure that was the problem.\r\nCan you run the checks? If what I did doesn't solve it, maybe someone else can pitch in?\r\n\r\nThanks", "Sorry for the delay. There are still test failures. Rerunning tests, but please take a look at failures if they still exist.", "It has been 20 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 49 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 19397, "title": "[Bug] tf.shape does not return correct value when using tf.cond and tf.reshape", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.8.0-0-g93bc2e2072', '1.8.0')\r\n- **Python version**: 2.7.15\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: GeForce GTX 1060 6GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nWhen  all of below conditions is true, tf.shape return NOT correct value.\r\n* use `tf.reshape` in and out of `tf.cond` and \r\n* `tf.reshape` inside of `tf.cond` has unknown shape (-1)\r\n* `tf.reshape` inside of `tf.cond` reduces or increases rank of tensor\r\n\r\n\r\n\r\nI have checked that same code doesn't cause error  in TensorFlow 1.7. But TensorFlow 1.8 cause this error.\r\n\r\nI guess this phenomena caused by a failure of branch prediction or error of graph-optimization.\r\n\r\n### Source code / logs\r\n\r\n#### Source code\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef init(height):\r\n    orig = tf.zeros(shape=[height])\r\n    reshaped = tf.reshape(orig, shape=[-1])\r\n\r\n    # tf.shape(reshaped) must return [1, 2]. But this actually return [2, 2]. It's WRONG!!\r\n    reshaped = tf.Print(reshaped, [tf.shape(reshaped)], message=\"tf.shape(reshaped) before tf.cond: \")\r\n\r\n    def true_fn(t):\r\n        t = tf.Print(t, [], message=\"pass in true_fn\")\r\n        return tf.reshape(t, (2, 1))\r\n\r\n    def false_fn(t):\r\n        t = tf.Print(t, [], message=\"pass in false_fn\")\r\n        return tf.reshape(t, (-1, 1))\r\n\r\n    reshaped = tf.cond(\r\n        tf.equal(tf.shape(reshaped)[0], 2), lambda: true_fn(reshaped), lambda: false_fn(reshaped), strict=True)\r\n\r\n    reshaped = tf.Print(reshaped, [tf.shape(reshaped)], message=\"tf.shape(reshaped) after tf.cond: \")\r\n\r\n    return reshaped\r\n\r\n\r\ndef main():\r\n\r\n    height = tf.placeholder(dtype=tf.int32, shape=())\r\n    reshaped = init(height)\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(reshaped, feed_dict={height: 1})\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n#### Log\r\n```\r\n2018-05-19 04:54:10.722065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero\r\n2018-05-19 04:54:10.722448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\r\nname: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7845\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 5.94GiB freeMemory: 4.86GiB\r\n2018-05-19 04:54:10.722467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-05-19 04:54:10.911223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-05-19 04:54:10.911263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0\r\n2018-05-19 04:54:10.911271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N\r\n2018-05-19 04:54:10.911466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4623 MB memory) -> physical GPU (device: 0\r\n, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\ntf.shape(reshaped) before tf.cond: [2]\r\npass in true_fn\r\nTraceback (most recent call last):\r\n  File \"./main.py\", line 40, in <module>\r\n    main()\r\n  File \"./main.py\", line 36, in main\r\n    sess.run(reshaped, feed_dict={height: 1})\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 1 values, but the requested shape has 2\r\n         [[Node: cond/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/Print/_19, cond/Reshape/shape)]]\r\n         [[Node: Shape_2/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_26_Shape_2\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op u'cond/Reshape', defined at:\r\n  File \"./main.py\", line 40, in <module>\r\n    main()\r\n  File \"./main.py\", line 33, in main\r\n    reshaped = init(height)\r\n  File \"./main.py\", line 23, in init\r\n    tf.equal(tf.shape(reshaped)[0], 2), lambda: true_fn(reshaped), lambda: false_fn(reshaped), strict=True)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2063, in cond\r\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1913, in BuildCondBranch\r\n    original_result = fn()\r\n  File \"./main.py\", line 23, in <lambda>\r\n    tf.equal(tf.shape(reshaped)[0], 2), lambda: true_fn(reshaped), lambda: false_fn(reshaped), strict=True)\r\n  File \"./main.py\", line 16, in true_fn\r\n    return tf.reshape(t, (2, 1))\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6113, in reshape\r\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1 values, but the requested shape has 2\r\n         [[Node: cond/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/Print/_19, cond/Reshape/shape)]]\r\n         [[Node: Shape_2/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_26_Shape_2\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\n", "comments": ["Thanks for reporting this bug. I can reproduce. Maybe turn off graph rewriting to see if it's the cause.\r\n      rewriter_config = rewriter_config_pb2.RewriterConfig(\r\n          disable_model_pruning=True,\r\n          constant_folding=rewriter_config_pb2.RewriterConfig.OFF,\r\n          arithmetic_optimization=rewriter_config_pb2.RewriterConfig.OFF,\r\n          dependency_optimization=rewriter_config_pb2.RewriterConfig.OFF,\r\n          function_optimization=rewriter_config_pb2.RewriterConfig.OFF,\r\n          layout_optimizer=rewriter_config_pb2.RewriterConfig.OFF,\r\n          loop_optimization=rewriter_config_pb2.RewriterConfig.OFF,\r\n          memory_optimization=rewriter_config_pb2.RewriterConfig.NO_MEM_OPT)\r\n      config = tf.ConfigProto(\r\n          allow_soft_placement=True,\r\n          graph_options=tf.GraphOptions(rewrite_options=rewriter_config)\r\n      )\r\n      sess = tf.Session(config=config)", "Thank you very much. I got the appropriate result. Also, i got the correct result with the following code.\r\n```python\r\nrewriter_config = rewriter_config_pb2.RewriterConfig(                      \r\n        constant_folding=rewriter_config_pb2.RewriterConfig.OFF,           \r\n        )                                                                  \r\nconfig = tf.ConfigProto(                                                   \r\n        graph_options=tf.GraphOptions(rewrite_options=rewriter_config)     \r\n        ) \r\nsess = tf.Session(config=config)                                                           \r\n```\r\n\r\nDoes adding the option slow down the program ? Will this behavior be fixed in tensorflow 1.9 (or 1.10) ?", "We will work on fixing this issue. Thank you very much for reporting it.", "OK. I will use this workaround for a while. ", "This bug will be fixed in the next release.\r\n\r\n", "Nagging Assignee @bignamehyp: It has been 121 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "what release this issue has been fixed in?", " 1.11.0rc1 is still buggy!", "> This bug will be fixed in the next release.\r\n\r\n@bignamehyp, Could you please tell the commit which has introduced the fix?"]}, {"number": 19396, "title": "Add test case for empty tensor with clip ops", "body": "This fix is based on #19337 and #19338. The issue was that previously an empty tensor for `tf.clip_by_value` on GPU triggers a crash. The issue should have been fixed by #19338 and\r\nthe recent master. It makes sense to adds the test case for this issue.\r\n\r\nThis fix adds the test case.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 19394, "title": "Fix the TFLite iOS demo apps.", "body": "This partially reverted 2bf2308872a6dfa8d6d0809acf0098f666e00fe8.\r\nThe demo apps in `lite/examples` depends on CocoaPod, not the Github\r\nhead code.", "comments": []}, {"number": 19393, "title": "Build Tensorflow-master with sycl support - error computecpp", "body": "\r\n- Ubuntu 18.04\r\n- TensorFlow installed from source 1.80\r\n- Python version 2.7\r\n- Bazel version 0.13.0\r\n- GCC/Compiler 7.3\r\n- OpenCL 1.2 AMD-APP \r\n- AMD Vega FE\r\n- bazel build --config=sycl --verbose_failures --test_timeout 1600 //tensorflow/tools/pip_package:build_pip_package\r\n\r\nI am trying to compile Tensorflow for my amd GPU, when i set it to --config=sycl it fails with the error :\r\n\r\n`\r\nINFO: Found 1 target...\r\nERROR: /home/frankie/Downloads/TENSORFLOW_BUILDs/tensorflow/tensorflow/contrib/tensor_forest/hybrid/BUILD:72:1: C++ compilation of rule '//tensorflow/contrib/tensor_forest/hybrid:utils' failed (Exit 1): computecpp failed: error executing command\r\n  (cd /home/frankie/.cache/bazel/_bazel_frankie/d74dd7347ab17909423a2342e3b420ce/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    COMPUTECPP_TOOLKIT_PATH=/usr/local/computecpp \\\r\n    HOST_CXX_COMPILER=/usr/bin/g++ \\\r\n    HOST_C_COMPILER=/usr/bin/gcc \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_COMPUTECPP=1 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=1 \\\r\n  external/local_config_sycl/crosstool/computecpp -fPIE -fno-omit-frame-pointer -Wall -msse3 -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/k8-opt/bin/tensorflow/contrib/tensor_forest/hybrid/_objs/utils/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/contrib/tensor_forest/hybrid/_objs/utils/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.pic.o' -fPIC -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/k8-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/k8-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/genfiles/external/local_config_sycl -iquote external/protobuf_archive -iquote bazel-out/k8-opt/genfiles/external/protobuf_archive -isystem external/eigen_archive -isystem bazel-out/k8-opt/genfiles/external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/local_config_sycl/sycl -isystem bazel-out/k8-opt/genfiles/external/local_config_sycl/sycl -isystem bazel-out/k8-opt/bin/external/local_config_sycl/sycl -isystem external/local_config_sycl/sycl/include -isystem bazel-out/k8-opt/genfiles/external/local_config_sycl/sycl/include -isystem bazel-out/k8-opt/bin/external/local_config_sycl/sycl/include -isystem external/protobuf_archive/src -isystem bazel-out/k8-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/k8-opt/bin/external/protobuf_archive/src -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc -o bazel-out/k8-opt/bin/tensorflow/contrib/tensor_forest/hybrid/_objs/utils/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.pic.o)\r\nIn file included from tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc:15:\r\nIn file included from ./tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.h:20:\r\nIn file included from ./tensorflow/core/framework/tensor.h:19:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:163:19: error: no matching member function for call to 'get_access'\r\n    auto ptr =buf.get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::host_buffer>().get_pointer();\r\n              ~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nexternal/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:593:3: note: candidate template ignored: invalid explicitly-specified argument for template parameter 'accessMode'\r\n  get_access() {\r\n  ^\r\nexternal/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:611:53: note: candidate function template not viable: requires single argument 'cgh', but no arguments were provided\r\n  accessor<T, dimensions, accessMode, accessTarget> get_access(\r\n                                                    ^\r\nexternal/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:633:53: note: candidate function template not viable: requires 3 arguments, but 0 were provided\r\n  accessor<T, dimensions, accessMode, accessTarget> get_access(\r\n                                                    ^\r\nexternal/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:653:53: note: candidate function template not viable: requires at least 2 arguments, but 0 were provided\r\n  accessor<T, dimensions, accessMode, accessTarget> get_access(\r\n                                                    ^\r\nexternal/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:670:68: note: candidate function template not viable: requires 2 arguments, but 0 were provided\r\n  accessor<T, dimensions, accessMode, access::target::host_buffer> get_access(\r\n                                                                   ^\r\nexternal/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:684:68: note: candidate function template not viable: requires at least argument 'range', but no arguments were provided\r\n  accessor<T, dimensions, accessMode, access::target::host_buffer> get_access(\r\n                                                                   ^\r\nIn file included from tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc:15:\r\nIn file included from ./tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.h:20:\r\nIn file included from ./tensorflow/core/framework/tensor.h:19:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:61: error: no member named 'map_allocator' in namespace 'cl::sycl'\r\n      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));\r\n                                                  ~~~~~~~~~~^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:75: error: unexpected type name 'uint8_t': expected expression\r\n      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));\r\n                                                                          ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:86: warning: expression result unused [-Wunused-value]\r\n      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));\r\n                                                                                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:31: error: expected unqualified-id\r\n        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);\r\n                              ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:107: error: nested name specifier 'cl::sycl::access::target::' for declaration does not refer into a class, class templat\r\ne or class template partial specialization\r\n        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);\r\n                                                                                ~~~~~~~~~~~~~~~~~~~~~~~~~~^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:120: error: expected ';' at end of declaration\r\n        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);\r\n                                                                                                                       ^\r\n                                                                                                                       ;\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:62: error: no member named 'map_allocator' in namespace 'cl::sycl'\r\n      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));\r\n                                                   ~~~~~~~~~~^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:76: error: unexpected type name 'uint8_t': expected expression\r\n      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));\r\n                                                                           ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:87: warning: expression result unused [-Wunused-value]\r\n      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));\r\n                                                                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:32: error: expected unqualified-id\r\n        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);\r\n                               ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:117: error: nested name specifier 'cl::sycl::access::target::' for declaration does not refer into a class, class templat\r\ne or class template partial specialization\r\n        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);\r\n                                                                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:130: error: expected ';' at end of declaration\r\n        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);\r\n                                                                                                                                 ^\r\n                                                                                                                                 ;\r\n2 warnings and 11 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 8.290s, Critical Path: 7.83s\r\nINFO: 2 processes, local.\r\nFAILED: Build did NOT complete successfully\r\n`\r\n\r\nIt compile well without sycl.\r\n\r\nI have installed computecpp downloading the files from the official website (ComputeCpp-CE-0.8.0-Ubuntu.16.04-64bit.tar.gz) and coping them to /usr/local/computecpp, adding the variable with \r\n\r\n`export COMPUTECPP_PACKAGE_ROOT_DIR=/usr/local/computecpp/`\r\n\r\nam i missing something ?\r\nthanks !", "comments": ["i got tensorflow compile using the right sources.\r\n\r\n i used this branch :\r\n\r\n> https://github.com/lukeiwanski/tensorflow/tree/dev/amd_gpu\r\n\r\nchecking it with \r\n\r\n> git checkout dev/amd_gpu\r\n\r\nand Bazel 0.11.1\r\n\r\n> https://github.com/bazelbuild/bazel/releases/download/0.11.1/bazel_0.11.1-linux-x86_64.deb\r\n\r\n\r\n", "Same error with ComputeCpp-CE-0.9.1.", "@inferrna the official TensorFlow repository doesn't have the recent changes needed by SYCL yet.\r\nPlease use the eigen_sycl branch of https://github.com/codeplaysoftware/tensorflow for now. It only supports TF 1.6 for now but we are working towards merging 1.9.\r\nYou will also need to use bazel 0.11.1.", "Hi i'm unable to compile with bazel 0.11.1/0.18.0 and computecpp 0.61/0.8/1.0.1 and using both  https://github.com/codeplaysoftware/tensorflow on the eigen_sycl branch and https://github.com/lukeiwanski/tensorflow/ on branch dev/amd_gpu. \r\n\r\n```\r\nERROR: /home/mlnode/tensorflowd1/tensorflow/python/eager/BUILD:190:1: C++ compilation of rule '//tensorflow/python/ea ger:python_eager_op_gen' failed (Exit 1)\r\nIn file included from tensorflow/python/eager/python_eager_op_gen.cc:27:\r\nIn file included from ./tensorflow/core/framework/types.h:23:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:163:19: error: no matching member functi on for call to 'get_access'\r\n    auto ptr =buf.get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::host_buffer>().get_poin ter();\r\n\r\n```\r\n\r\nI couldn't find any combination of repo/version that made the build happen.\r\n\r\nUsing UBUNTU 18.04 (Fresh Install + AmdGpuPro 18.30 (--opencl=legacy,pal --headless)", "Hello @gianks,\r\nI'm guessing you don't see this exact same error with the eigen_sycl branch as the TensorDeviceSycl.h file shouldn't look like that anymore.\r\nRegarding my previous comment, TF 1.9 has now been merged :) As a rule you should always use the latest version of ComputeCpp and of the eigen_sycl branch from the [official Codeplay repository](https://github.com/codeplaysoftware/tensorflow). We used bazel 0.16.0, it seems bazel 0.17 and above don't work yet even with the most recent version of TF.\r\nLastly, we don't support Ubuntu 18.04 nor AmdGpuPro 18.30 but it could always work! If you have any issue please create a ticket in the Codeplay repository.", "Hi @Rbiessy, thanks for the reply.\r\nI'm confused, when you say you don't support 18.30, does it mean it is too new or you don't support AmdGpu?\r\nI have installed in the last hour a new fresh 16.04 but the build is not succeding too so i don't understand which driver version is ok.", "Sorry, I meant it is too new. I am using amdgpu-pro 17.50 which you can get with\r\n`wget --referer http://support.amd.com/ https://www2.ati.com/drivers/linux/ubuntu/amdgpu-pro-17.50-511655.tar.xz`\r\nThe driver won't affect your compile error though so feel free to create an issue for that. Make sure that your remove your cache folder, sometimes even a `bazel clean --expunge` is not enough.\r\nIt's good that you are trying Ubuntu 16.04. I know the build instructions aren't very clear yet, we are still working on updating the ones on the website!", "Ok, here i am again...\r\nTensorDeviceSycl.h:163:19: error: no matching member function for call to 'get_access'\r\n\r\nBuild fails here, last ComputeCpp 1.0.1.\r\nAs far as i have understood this is caused by a mismatch in the SYCL interface which got updated recently... but i don't know how to proceed more.\r\n\r\nI have restarted from a new clone, no possibilities bazel cache was messed up!\r\nMeanwhile i have a 2nd machine i have started from scratch with ubuntu 16.04 and AmdGpu 17.50 you provided. Going to start the build in minutes, hopefully this will work.\r\n\r\nAnyway this is the main error that occurs and prevents the installation on Ubuntu 18.04 too.", "Hi, now it builds using the driver you said on a fresh install but i cannot use all the cards, just the first, even if clinfo and comptecpp_info report all of them. Please see this link, i asked the question on stackoverflow:\r\nhttps://stackoverflow.com/questions/52864399/multiple-amd-gpus-with-tensorflow-and-opencl-on-ubuntu-16-04\r\nAny ideas how to address this issue?", "Moved my answer here: https://github.com/codeplaysoftware/tensorflow/issues/16"]}, {"number": 19392, "title": "update embedding combiner default from mean to sqrtn", "body": "according to the warning this should be the default since 2016/11/01", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I agreed to it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Cant find a good person to review this. Do we just follow the comment and change the default behavior?", "Despite what the warning states, we are sticking the current default (as not to change behavior on people) unless it can be shown very clearer using combiner=sqrtn is superior. \r\n\r\nBut thanks for looking into cleaning up code!", "Could the warning be removed ?", "That sounds good to me. Maybe just replace with a comment with TODO: investigate changing default to sqrt", "I made a new commit with the TODO.\r\nThis is closed, and therefore I think it will not be pulled in. \r\n\r\nRe-open a new PR or not important ?"]}, {"number": 19389, "title": "when i compile tf", "body": "\r\n1.  the info list :\r\ndega@degawong:~/Downloads/degawong/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nWARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/absl_py/WORKSPACE:1: Workspace name in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/absl_py/WORKSPACE (@io_abseil_py) does not match the name given in the repository's definition (@absl_py); this will cause a build error in future versions\r\nWARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/WORKSPACE:1: Workspace name in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions\r\nWARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/seq2seq/BUILD:89:1: undeclared inclusion(s) in rule '//tensorflow/contrib/seq2seq:beam_search_ops_op_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/contrib/seq2seq/ops/beam_search_ops.cc':\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/stddef.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/stdarg.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/stdint.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include-fixed/limits.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include-fixed/syslimits.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/mmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/emmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/xmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/mm_malloc.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/6/include/pmmintrin.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2.301s, Critical Path: 1.90s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:17.10\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:latest\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:latest\r\n- **GCC/Compiler version (if compiling from source)**:6\r\n- **CUDA/cuDNN version**:9.0/7.0.5\r\n- **GPU model and memory**:1050 ti\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nwhen i install tensorflow , there seems always something wrong......\r\n\r\n### Source code / logs\r\n\r\n", "comments": ["```\r\nERROR: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/seq2seq/BUILD:89:1: undeclared inclusion(s) in rule '//tensorflow/contrib/seq2seq:beam_search_ops_op_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/contrib/seq2seq/ops/beam_search_ops.cc':\r\n'/usr/lib/gcc/x86_64-linux-gnu/6/include/stddef.h'\r\n```\r\nThis looks like a bazel issue.\r\nCould you include the output of `bazel version`? ", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 19388, "title": "Pandas input fn accepts DataFrame for Y", "body": "This pull request is to implement the feature request from #19182 ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "This has been sitting out here for a while. Any ETA on when it's going to be looked at? Anything else I can do?", "Thanks for the review @xiejw. Good feedback. Will get a pull request together soon to address the issues.", "@xiejw Have updated the pull request to address the issues we discussed. Take a look at your convenience and let me know how it looks. Thanks!", "@xiejw is there a way to get more info about the failing tests? I'm seeing that they exit with error code 1. What direction should I go to debug why it's failing on the Ubuntu Python 2 and Python 3 but working on my Ubuntu machine.", "Based on the test log [1], if I understand the failure correctly, as six is used, you need to import six at the head of the file. You might or might not need to adjust the bazel BUILD file also. Can you try that? I can trigger the test for you at any time. \r\n\r\n[1] https://source.cloud.google.com/results/invocations/4b6f38a2-e310-42c8-a250-48f7c3de8568/targets/%2F%2Ftensorflow%2Fpython%2Festimator:pandas_io_test/log", "@xiejw Thanks, that makes complete sense. I'm now confused though as to why the test does not produce an error on my local. I did a bazel clean before trying it again and it still passes even though six is not imported. This is the command I'm using:\r\n\r\n```bazel test --config=opt //tensorflow/python/estimator:pandas_io_test```\r\n\r\nI've also used\r\n\r\n```bazel run --config=opt //tensorflow/python/estimator:pandas_io_test ```\r\n\r\nIt says 17 passing.\r\n\r\nShould I be running the tests in a different way for local development?", "I think given the tests need to be run against different python versions and platforms. The best way to try it is to submit your commit and I will kick another test run for you. ", "Ok submitted the commit. Kick off the tests when ready.", "I think the final error is easy to fix. \r\n\r\ntensorflow/python/estimator/inputs/pandas_io.py:114: [C0301(line-too-long), ] Line too long (85/80)", "@yifeif  Yifei, is there a link or page describing how to run lint in open source. It is annoying for contributors to keep committing and trying here (just for a trivial lint error)", "For future references, you can run https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_sanity.sh locally for the sanity check.", "Thanks @yifeif. I ran that locally and got some failures that don't look like they are related to my changes. Is my environment not setup correctly? \r\n\r\n```bash\r\n4. do_buildifier: buildifier check\r\n  FAIL\r\n5. do_bazel_nobuild: bazel nobuild\r\n  FAIL\r\n6. do_pip_package_licenses_check: pip: license check for external dependencies\r\n  FAIL\r\n7. do_lib_package_licenses_check: C library: license check for external dependencies\r\n  FAIL\r\n8. do_java_package_licenses_check: Java Native Library: license check for external dependencies\r\n  FAIL\r\n9. do_pip_smoke_test: Pip Smoke Test: Checking py_test dependencies exist in pip package\r\n  FAIL\r\n10. do_check_load_py_test: Check load py_test: Check that BUILD files with py_test target properly load py_test\r\n  FAIL\r\n```\r\n", "From the last CI log only the bazel nobuild failed. The others that failed on my local did not fail in that environment. https://source.cloud.google.com/results/invocations/d280d3b0-083d-4607-8666-d619f87234b2/targets/%2F%2Ftensorflow%2Ftools%2Fci_build:gen_ci_sanity_out/log"]}, {"number": 19387, "title": "why ...the tfmobile has stopped ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 19386, "title": "CMake: fix include error when building with PYTHON_BINDINGS off", "body": "If tensorflow_BUILD_PYTHON_BINDINGS is disabled in cmake. The following error occurs during compilation:\r\ntensorflow/tensorflow/c/python_api.cc:19:64: fatal error: tensorflow/python/framework/cpp_shape_inference.pb.h: No such file or directory\r\n\r\nThis PR fixes this issue in cmake", "comments": []}]