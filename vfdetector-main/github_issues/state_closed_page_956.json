[{"number": 24751, "title": "Instantiating Separate Session for Each GPU", "body": "\r\nI'm trying to speed up Tensorflow inference by using multiple GPUs and instantiating a separate Session for each GPU.\r\n\r\nI am using Tensorflow 1.7 and 2 Quadro GV100's for this. The GV100's are device 0 and device 1, respectively.\r\n\r\nMy C++ code looks something like the following:\r\n\r\nauto options0 = SessionOptions();\r\noptions0.config.mutable_gpu_options()->set_visible_device_list(\"0\");\r\nNewSession(options0, &m_session0);\r\n\r\nauto options1 = SessionOptions();\r\noptions1.config.mutable_gpu_options()->set_visible_device_list(\"1\");\r\nNewSession(options1, &m_session1);\r\nHowever, when I execute this code, I get the following error message:\r\n\r\nname: Quadro GV100 major: 7 minor: 0 memoryClockRate(GHz): 1.627 pciBusID: 0000:18:00.0 totalMemory: 31.87GiB freeMemory: 31.33GiB 2019-01-07 17:56:09.453901: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1423] Adding visible gpu devices: 0 2019-01-07 17:56:10.196800: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-01-07 17:56:10.202994: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:917] 0 2019-01-07 17:56:10.206965: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 0: N 2019-01-07 17:56:10.211407: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30421 MB memory) -> physical GPU (device: 0, name: Quadro GV100, pci bus id: 0000:18:00.0, compute capability: 7.0) 17:56:11.099: Choosing GPU: 1 2019-01-07 17:56:11.280313: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1344] Found device 0 with properties: name: Quadro GV100 major: 7 minor: 0 memoryClockRate(GHz): 1.627 pciBusID: 0000:3b:00.0 totalMemory: 31.87GiB freeMemory: 31.33GiB 2019-01-07 17:56:11.291274: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1423] Adding visible gpu devices: 1 2019-01-07 17:56:12.076807: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-01-07 17:56:12.082561: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:917] 1 2019-01-07 17:56:12.088587: I C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 1: N 2019-01-07 17:56:12.095142: F C:\\tensorflow_1_7\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_id_manager.cc:45] Check failed: cuda_gpu_id.value() == result.first->second (1 vs. 0)Mapping the same TfGpuId to a different CUDA GPU id. TfGpuId: 0 Existing mapped CUDA GPU id: 0 CUDA GPU id being tried to map to: 1\r\n\r\nMy question is, what is the proper way to assign/dedicate a GPU to each Tensorflow session?\r\n\r\nThank you very much for your help in advance!", "comments": ["Additionally, I tried \r\n\r\nauto options = SessionOptions();\r\noptions.config.mutable_gpu_options()->set_visible_device_list(\"0, 1\");\r\nNewSession(options, &m_session0);\r\nNewSession(options, &m_session1);\r\n\r\nand then loading the same graph twice each time onto a diff Session\r\nGraphDef graph_def;\r\nReadBinaryProto(Env::Default(), graphPath, &graph_def);\r\nm_session0->Create(graph_def);\r\ngraph::SetDefaultDevice(\"/device:GPU:0\", &graph_def);\r\n\r\nGraphDef graph_def1;\r\nReadBinaryProto(Env::Default(), graphPath, &graph_def1);\r\nm_session1->Create(graph_def1);\r\ngraph::SetDefaultDevice(\"/device:GPU:1\", &graph_def1);\r\n\r\nThis got past the error.  I am calling m_session0.Run() and m_session1.Run() on separate threads.  This however, did not speed up the inference speed as opposed to using just one Session object and one GPU.  Am I missing something? ", "Hello @GothamCityPro , TensorFlow tends to allocate GPU resources to each session and thread in the order they are created.\r\nHi @azaks2 , can you advice how the user can allocate GPUs to sessions to threads, if possible. Thanks.", "@msymp Are you still blocked on this?  If yes, can you please provide a full reproducer (i.e. something I can run myself to reproduce the problem)?", "Closing for lack of activity.  If this is still blocking you please reopen with a reproducer.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24751\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24751\">No</a>\n"]}, {"number": 24750, "title": "add cocl submodule", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 24749, "title": "r1.13-rc0 cherry-pick request: Fix bug in FuseTransposeMklOpTranspose", "body": "Intel MKL bug fix cherry-pick. TensorFlow --config=mkl builds can have dangling pointer failures if not fixed.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@wenxizhu I'm trying to cherry-pick this bug fix into release 1.13. Could you please post here that you are okay with your commits being contributed to the project (so I can set cla to yes)?\r\n", "@penpornk It's OK. Thank you!", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "@wenxizhu Thank you for your fast reply!"]}, {"number": 24748, "title": ".numpy() was missing in code example in README.md: tf.add(1, 2) should be tf.add(1, 2).numpy()", "body": "", "comments": []}, {"number": 24747, "title": "Add cuDNN deterministic env variable (only for convolution)", "body": "This change is a component of the recipe for making TensorFlow training reproducible on GPUs.\r\n\r\nSetting the environment variable TF_CUDNN_DETERMINISTIC=1 (or true) will ensure that both forward and backwards convolution algorithms are both fixed and deterministic. It overrides autotune and selects deterministic back-prop algorithms.\r\n\r\nThis pull request has two previous abandoned versions:\r\n* [pr/24301](https://github.com/tensorflow/tensorflow/pull/24301) was issued incorrectly based on r1.12.\r\n* [pr/24355](https://github.com/tensorflow/tensorflow/pull/24355) was temporarily closed and could not be re-opened after a force-push to the branch.\r\n\r\nThis pull request is different from 24355 in the following ways:\r\n\r\n1. It caches the environment variable using a more favorable, pre-existing pattern.\r\n2. It uses tensor op math, if it's available.\r\n3. It factors the logic that decides if tensor op math is available into a separate inline function.\r\n4. If TF_CUDNN_DETERMINISTIC is set, the code that accumulates the list of algorithm options is skipped.\r\n\r\nAttention @azaks2 @timshen91 ", "comments": ["@timshen91 is a better reviewer for this, since he reviewed pr/24355.", "Hi Tim (@timshen91), when I run `clang-format` on this file, I see formatting differences between the human and the program. Should all files be totally clean with `clang-format`? I think they're compliant with the coding guidelines, but the program made different choices. If so, should I issue another pull-request after this one to fix those formatting issues (so that other people don't have to pick through them)? What's the best practice on this?", "You're seeing this because clang-format is not a stable format, and Google runs bleeding-edge clang, as compared to whatever version you happen to have installed on your system.\r\n\r\nWe've recently set things up so that when we import a PR, we run our bleeding-edge clang-format over the whole thing.  So I believe @yifeif was planning to disable the clang-format check externally; it shouldn't be necessary anymore.", "(So I'd say for this PR, don't worry about it.)", "I've made some changes. This is ready for review again.", "I'm assuming these four build failures are unrelated to my pull request. Please let me know if I caused this and/or if there is anything I need to to to run those checks again.", "> I'm assuming these four build failures are unrelated to my pull request. Please let me know if I caused this and/or if there is anything I need to to to run those checks again.\r\n\r\nI'm helping to get this PR merged. I'll keep you posted if anything is required from your end. ", "See follow-on pull request [25269](https://github.com/tensorflow/tensorflow/pull/25269) that addresses non-determinism in max pooling.", "How it's related to `TF_CUDNN_USE_AUTOTUNE` ?\r\nFrom [here](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9911-determinism-in-deep-learning.pdf) \r\n`TF_CUDNN_DETERMINISTIC` used to disable auto-tuning and select deterministic cuDNN convolution algorithms.", "@mrgloom, `TF_CUDNN_USE_AUTOTUNE=false` disables TF cuDNN auto-tuning, which is enabled by default. TF cuDNN auto-tuning tries different forward and backward algorithms for each layer to find the highest-performing one.\r\n\r\n`TF_CUDNN_DETERMINISTIC=true` selects deterministic algorithms, where they are available, and ensures that the same algorithms are always used, even when there are only deterministic options available. This is what is meant by disabling auto-tuning: there is no automatic algorithm selection.\r\n\r\nWhen `TF_CUDNN_DETERMINISTIC=true` is used `TF_CUDNN_USE_AUTOTUNE=false` should not be used. The latter is not only unnecessary but will actually thwart the effect of the former."]}, {"number": 24746, "title": "Fix warning in keras base_layer_utils.py", "body": "While debugging 24741 I noticed the following warning:\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:125: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n```\r\n\r\nThis fix update the base_layer_utils.py to remove the warning.\r\nNote dtype is passed in the subsequent calls already so there is no need to\r\ncall with dtype in __init__ in this case.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @fchollet for the review. The PR has been rebased and updated to fix the merge conflict.", "@fchollet  Could you please approve this if it looks good. Once it is approved, then I can proceed further."]}, {"number": 24745, "title": "NcclAllReduce Registered Multiple TImes", "body": "This is likely a problem between the chair and keyboard, but bear with me. I try to simply:\r\n\r\n`from tensorflow.contrib import nccl`\r\n\r\nThis causes code to run that registers an operation called NcclAllReduce multiple times because of various imports:\r\n\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/gradescan/.local/lib/python2.7/site-packages/tensorflow/contrib/nccl/__init__.py\", line 30, in <module>\r\n    from tensorflow.contrib.nccl.python.ops.nccl_ops import all_max\r\n  File \"/home/gradescan/.local/lib/python2.7/site-packages/tensorflow/contrib/nccl/python/ops/nccl_ops.py\", line 52, in <module>\r\n    @ops.RegisterGradient('NcclAllReduce')\r\n  File \"/home/gradescan/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2494, in __call__\r\n    _gradient_registry.register(f, self._op_type)\r\n  File \"/home/gradescan/.local/lib/python2.7/site-packages/tensorflow/python/framework/registry.py\", line 61, in register\r\n    (self._name, name, function_name, filename, line_number))\r\nKeyError: \"Registering two gradient with name 'NcclAllReduce'! (Previous registration was in <module> /home/gradescan/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py:72)\"\r\n```\r\n\r\nSeems like one should be able to register multiple functions with the tensoflow RegsiterGradient to the same operation. Any help pointing me to documentation I can review, or general thoughts on how to resolve this issue would be appreciated.", "comments": ["Please provide following information. Thanks!\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24744, "title": "why is there different latency for post-training quantization and quantization-aware trained models? ", "body": "**System information**\r\n- TensorFlow version: TFlite \r\n- Doc Link:https://www.tensorflow.org/lite/performance/model_optimization\r\n\r\nin the model optimization documentation page:\r\nhttps://www.tensorflow.org/lite/performance/model_optimization\r\nTable 1 gives a latency of 145ms for post-training quantization and 80.2 for quantization-aware training. \r\n\r\nit is unclear to me why there should be a difference in latency as both methods results in models that use 8-bit operation. The documentation implies that the benefit of using quantization aware training is to increase model accuracy when using int8, but from the table it seems that latency is also improved. why is that?\r\n\r\n", "comments": ["The reason is well explained in another doc, the [post_training_quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) page. In short, models quantized by post-training quantization compute using floating point kernels; models quantized by quantization aware training use fixed-point kernels.", "Thanks for the reply!\r\n\r\nHowever, I still find it confusing as the move from floating kerenl to fixed point kernels is done via graph_freezing as explained in the [quantization-aware training](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantize/README.md) doc.\r\n\r\nIs there no way to freeze the eval graph created by post training quantization to get the full speed up offered by using fixed point kernels? After all these graphs are conceptually the same. It would seem to be a shame to force a user to go through the train process if she only wishes to gain the latency speed-up.\r\n\r\nA slightly unrelated issue that I cannot find any documentation on - does the TFlite quantization use channel-wise quantization as explained in [1] or layer-wise quantization?\r\n\r\n[1] [Quantizing deep convolutional networks for efficient inference: A whitepaper](https://arxiv.org/abs/1806.08342)\r\n", "Hello @grobman , we would like to thank @freedomtan for addressing your post-training quantization vs. quantization-aware training query in TFLite.\r\nPlease kindly submit a follow up issue for your query:\r\nA slightly unrelated issue that I cannot find any documentation on - does the TFlite quantization use channel-wise quantization as explained in [1] or layer-wise quantization? https://arxiv.org/abs/1806.08342\r\nThanks. This issue is closed."]}, {"number": 24743, "title": "load model's checkpoint", "body": "hi \r\nhow can i restore checkpoints to use this in pyhton?", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 24742, "title": "Inconsistent behavior of tf.function when using autograph", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac OS X 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION=\"1.13.0-dev20181226\" (this is the TF 2.0-preview)\r\nGIT_VERSION=\"b'v1.12.0-5133-gc343196842'\"\r\n- Python version:\r\n3.6.6\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\n`tf.function` converts almost identical functions into completely different graphs. It seems like a bug, but perhaps it's just a bit too complicated for me. If it's working as expected, then I think the documentation really needs to be expanded, with detailed examples and clear guidelines.\r\n\r\n**Describe the expected behavior**\r\nAll the following functions should return almost identical graphs.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef foo1(x):\r\n    for i in range(10):\r\n        x = x + 1\r\n    return x\r\n\r\n@tf.function\r\ndef foo2(x):\r\n    for i in range(tf.constant(10)):\r\n        x = x + tf.constant(1)\r\n    return x\r\n\r\n@tf.function\r\ndef foo3():\r\n    x = 0\r\n    for i in range(10):\r\n        x = x + 1\r\n    return x\r\n\r\n@tf.function\r\ndef foo4():\r\n    x = tf.constant(0)\r\n    for i in range(tf.constant(10)):\r\n        x = x + tf.constant(1)\r\n    return x\r\n\r\ndef _print_sub_ops(op, indent=0):\r\n    \"\"\"Recursively print an op's inputs\"\"\"\r\n    print(\"  \"*indent, op.name)\r\n    for ts in op.inputs:\r\n        _print_sub_ops(ts.op, indent + 1)\r\n\r\ndef print_graph(func, *args):\r\n    print(func.__name__)\r\n    ops = func.get_concrete_function(*args).graph.get_operations()\r\n    _print_sub_ops(ops[-1])   # or just print(ops) if you prefer\r\n    print()\r\n\r\nprint_graph(foo1, tf.constant(0))\r\nprint_graph(foo2, tf.constant(0))\r\nprint_graph(foo3)\r\nprint_graph(foo4)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nBelow is the output of this program. Notice that:\r\n* foo1 is horrible, autograph did not generate a `tf.while_loop`. Imagine a loop with 10000 iterations, it would just blow up.\r\n* foo2 is pretty good, but it's odd that I have to wrap every integer into a tf.constant.\r\n* foo3 is perfect, it even reduced the whole graph to a single constant, congrats.\r\n* foo4 is virtually identical to foo2, which is pretty good, but why didn't it get the same magic as foo3?\r\n\r\n```\r\nfoo1\r\n Identity\r\n   add_9\r\n     add_8\r\n       add_7\r\n         add_6\r\n           add_5\r\n             add_4\r\n               add_3\r\n                 add_2\r\n                   add_1\r\n                     add\r\n                       x\r\n                       add/y\r\n                     add_1/y\r\n                   add_2/y\r\n                 add_3/y\r\n               add_4/y\r\n             add_5/y\r\n           add_6/y\r\n         add_7/y\r\n       add_8/y\r\n     add_9/y\r\n\r\nfoo2\r\n Identity\r\n   while/Identity_2\r\n     while\r\n       while/loop_counter\r\n       Const_1\r\n       x\r\n       maximum_iterations\r\n       range\r\n         range/start\r\n         Maximum\r\n           Const\r\n           Maximum/y\r\n         range/delta\r\n\r\nfoo3\r\n Identity\r\n   Const\r\n\r\nfoo4\r\n Identity\r\n   while/Identity_2\r\n     while\r\n       while/loop_counter\r\n       Const_2\r\n       Const\r\n       maximum_iterations\r\n       range\r\n         range/start\r\n         Maximum\r\n           Const_1\r\n           Maximum/y\r\n         range/delta\r\n```", "comments": ["@alextp @alexbw @brilee @jmd101 @aaandrewww\r\n\r\nThis is a very good issue that you raised.\r\n\r\nBefore I elaborate, let me add a use case to your suite. It is less awkward than `range(tf.constant(x))` and also gives you more certainty about its behavior:\r\n\r\n```\r\n@tf.function\r\ndef foo4(x):\r\n    for i in tf.range(10):\r\n        x = x + 1\r\n    return x\r\n```\r\n\r\nAt the core of this confusing behavior is the need to support the use case of building a multi-layer neural network:\r\n\r\n```\r\nfor i in range(num_layers):\r\n  do_something_that_cannot_be_done_in_a_tf_while()\r\n```\r\n\r\nI agree that this automatic behavior can lead to surprising behavior, as you pointed out. For example writing a training loop `for i in range(num_steps)` will most likely not have the desired result.\r\n\r\nA robust solution is unobvious to me, so I'm opening the thread for discussion on a few alternatives, off the top of my head:\r\n\r\n1. Add a check for non-staged loops in which, if the number of steps is too large, or the resulting graph increases too much, output a warning to the user, in the form ('The loop x is not running in TensorFlow, is this what you intend?').\r\n\r\n2. Output a warning if the loop is unstaged, but could be (e.g. it doesn't create any resources).\r\n\r\n3. More aggressively run the loop in TF, perhaps by attempting to always run in TF and fall back to unrolling only if we detect that e.g. a resource was created.\r\n\r\nThoughts?", "@jmd1011\r\n\r\nCopying the correct ID", "I think that in general, unless we can infer the user's intent with high probability, trying to guess is often worse than just providing a way for the user to pick one or the other. The documentation does mention the range() vs. tf.range() thing, but we could maybe make that more prominent. The range/tf.range toggle seems to me like the easiest way for the user to indicate intent.", "Hi, thanks for the interesting feedback. So if I understand correctly, `for i in range(...)` will not be converted into a `tf.while()` block, but `for i in tf.range(...)` will (and so will `for i in range(tensor)`)? \r\nAhh, makes more sense now.\r\n\r\n@brilee, could you please point me to the part of the documentation that mentions this? I looked at the 2.0-preview documentation for `tf.autograph.to_code()` and `to_graph()`, as well as `tf.function()`, but I see no mention of this.\r\nI agree with your point about guessing vs giving the user the choice.  I think that if the `range`/`tf.range` choice is presented more prominently in the documentation, it should be understandable.  However, if `tf.range` is the most common option (is it?), or if `range` is the most dangerous one, then perhaps it should be the reverse: `range` would be converted to a `tf.while` block, while `tf.python_range` (or something) would be treated like a regular python loop. Just dropping the idea here, not sure it's any good.\r\n", "I'm looking at https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/autograph.ipynb and realizing that the latest version doesn't mention this range/tf.range thing. I'll add a note to that colab.", "Indeed, the bug originated from the fact that `range` was not expected to represent \"don't convert\" and is the dangerous one. One possible fix is to output a clear error when range is called with a tensor argument.\r\n\r\nHowever, this still doesn't solve the problem of `for i in range(1000): train()`. Always converting range and error out when that's not possible because e.g. variables (case in which we'd require something like `python_range`) would in turn be guaranteed to be safe.", "I just discussed with @alextp about this. The problem is that the default behavior (`range` vs `tf.range`, python args vs tensor args, etc.) is quite surprising to new users (as I experienced last week when giving a TF2 course). Indeed, pretty much everyone expected `foo(5)` to behave like `foo(tf.constant(5))` when using `autograph=True`.  Similarly, everyone expected `range` to be included in the graph when `autograph=True`. How can we make the default behavior less surprising?\r\n\r\nPerhaps one solution could be to treat python values as if they were wrapped in `tf.constant(...)`, by default, for example:\r\n\r\n```python\r\n@tf.function\r\ndef foo(x):\r\n    for i in tf.range(10):\r\n        x = x + 1\r\n    return x\r\n\r\nfoo(5)  # okay, equivalent to `foo(tf.constant(5))`\r\nfoo(tf.constant(5)) # okay, equivalent\r\n```\r\n\r\nIf you set `convert_args_to_tensors=False` when calling `tf.function` (the option name is to be defined, of course), then python arguments get treated like today:\r\n\r\n```python\r\n@tf.function(convert_args_to_tensors=False)\r\ndef foo(x):\r\n    for i in tf.range(10):\r\n        x = x + 1\r\n    return x\r\n\r\nfoo(5)  # okay, but NOT equivalent to `foo(tf.constant(5))`\r\nfoo(tf.constant(5))  # okay\r\n```\r\n\r\nAlternatively, python values could simply be rejected by default, with a helpful error message:\r\n\r\n```python\r\n@tf.function\r\ndef foo(x):\r\n    for i in tf.range(10):\r\n        x = x + 1\r\n    return x\r\n\r\nfoo(5)  # ERROR: \"All arguments must be tensors. If you need python args, please set `support_python_args=True`.\"\r\nfoo(tf.constant(5)) # okay\r\n```\r\n\r\nSo if a user wants to support python arguments to their function, they must set `support_python_args=True` when calling `tf.function` (again, this option name is to be defined):\r\n\r\n```python\r\n@tf.function(support_python_args=True)\r\ndef foo(x):\r\n    for i in tf.range(10):\r\n        x = x + 1\r\n    return x\r\n\r\nfoo(tf.constant(5))  # okay\r\nfoo(5) # okay, since `support_python_args=True`, but NOT equivalent to `foo(tf.constant(5))`\r\n```\r\n\r\nYet another solution could be to reject python args by default, but let users pass a special `PythonArgumentSpec` to indicate that a specific argument is expected to be a python arg:\r\n\r\n```python\r\n@tf.function(input_signature=[tf.PythonArgumentSpec(name=\"x\")])\r\ndef foo(x):\r\n    for i in tf.range(10):\r\n        x = x + 1\r\n    return x\r\n\r\nfoo(tf.constant(5))  # ERROR: the argument is not expected to be a tensor\r\nfoo(5) # okay\r\n```\r\n\r\nRegarding `range` vs `tf.range`, perhaps `range` should default to the same behavior as `tf.range`:\r\n\r\n```python\r\n@tf.function\r\ndef foo(x):\r\n    for i in range(10):  # equivalent to tf.range(10), by default there's no difference\r\n        x = x + 1\r\n    return x\r\n```\r\n\r\nBut if you want `range` to behave like a regular python `range` (i.e., not be included in the graph), then set `static_range=True` (again, arg name to be defined):\r\n\r\n```python\r\n@tf.function(static_range=True)\r\ndef foo(x):\r\n    for i in range(10):  # NOT equivalent to tf.range(10)\r\n        x = x + 1\r\n    return x\r\n```\r\n\r\nAlternatively, perhaps we should always let `range` be equivalent to `tf.range`, but then we could add a `tf.static_range` for whenever you need to run a static loop (i.e., not added to the graph)?\r\n\r\nThese are just ideas, they can certainly be improved a lot. Again, the end goal is to make the default behavior unsurprising to new users (i.e., `range` is added to the graph when using `autograph=True`, and `foo(5)` behaves like `foo(tf.constant(5))`), while making it possible to easily opt-in for python values as arguments and static range behavior.\r\n\r\nWdyt?", "Thank you Aur\u00e9lien for your input. The insights you gathered are most valuable. Please continue to send us any new data points you might gather.\r\n\r\nIt would seem that new users tend to have different expectations compared to \"veteran\" developers who wrote lots of TF graph code.\r\n\r\nOne thing that becomes obvious is that mechanisms which reliably avoid ambiguity would be useful regardless of what the defaults would be.\r\nAn extreme version of such a mechanism would be an \"all-graph\" mode, in the lines of what you suggested: `@tf.function(autograph=STRICT)` where everything ran in graph, and doing anything outside the graph required special overrides.\r\n\r\nAs a side note, we recently pushed a change where a construct like `range(tf.constant(n))` would be unsupported and raise an error. Although, that still leaves us with unexpected behavior in the case when the argument to the function was a Python value, or when users wrote `range(n)` out of sheer convenience, fully expecting the loop to be in-graph. The hope was that this would drive the habit of using either `range` to always statically unroll, or `tf.range` to always run in graph.\r\n\r\n", "Hi @mdanatg ,\r\nIt's great that `range(tf.constant(n))` is now rejected! :)\r\nWould `autograph=STRICT` be the default? If so, I guess it would mean that by default `range()` would act like `tf.range()` (great!).  Would it also mean that `foo(5)` would be rejected, or better, behave like `foo(constant(5))`? I would vote for that!\r\nPeople who want the current behavior could specify something like `autograph=MIXED`, right?", "Actually, thinking about this some more, I should probably mention that the most surprising behavior (to me and to the participants in my course) was, by far, the fact that `foo(n)` traces the function once for each distinct value of `n` (when `n` is a python value). It is not clear to me how often this behavior will be needed. I didn't run into any actual use case yet. So I would argue that the default should be to just reject python arguments, or at least convert them to tensors automatically (using `tf.constant()`).\r\nOn the other hand, it is true that the use case of building a model (e.g., using the subclassing API) composed of multiple similar layers or submodels is quite common, and it does require using a static loop (i.e., `range()`), rather than a dynamic loop (i.e., `tf.range()`).\r\n", "We'd have to think very carefully about adding modes like `STRICT` and `MIXED`. We want to avoid adding complexity to the interface unless absolutely necessary, so it might take a bit to decide whether we move from idea to implementation. The biggest unanswered question, as you point out, is what to do with things like hyperparameters (e.g. `train=True/False`, `num_layers`, etc.). Perhaps those would have to be marked explicitly.\r\n\r\nThe idea of autoboxing literals is interesting. What I wonder is, what should be the behavior of a constant created inside the function (e.g. `n = 3`). Should that be autoboxed, consistent with the function argument? That might not be feasible to do for `@tf.function` alone.\r\n\r\n@alextp I think the possibility of autoboxing is a question for the interface of `@tf.function`, so it should be discussed in that context.", "In terms of literals, there's a variety of ways that the graph can change with different python literals - num_layers, mode=TRAINING, unroll_steps, etc.\r\n\r\nFor the autoboxing question... probably the least surprising way to go about things is to copy NumPy's autoboxing semantics. But I don't know that NumPy is a shining star for unsurprising behavior - I discovered just now that `[1, 2, 3] * np.array([1, 2, 3]) == array([1, 4, 9])`. \r\n\r\n", "@ageron The decision to retrace on python scalars was to allow people to write code like\r\n\r\n```\r\n@tf.function\r\ndef apply_resnet(n_layers, image): ...\r\n```\r\n\r\nWe take this conservative retracing approach because (1) the set of things you're allowed to do with a python scalar is strictly bigger than the set of things you're allowed to do with a tf scalar (see here for example using it to set the number of layers of a resnet), and (2) for uniformity between argument passing and closure capturing, i.e. there is no way to special-case when a tf.function uses a python scalar variable defined outside the function and make that pretend to be a tf scalar.\r\n\r\nI am curious though because I tried to make it sure that retracing is mostly invisible, and will only have negative performance effects. So what kind of behavior did your students witness that was confusing to them?\r\n\r\n(we have a plan to diminish the frequency of retraces wrt shapes which I think can be extended to scalars, but it does have a side effect of no longer letting us use a python dictionary to do trace lookup, so I want to defer adding it to see if someone else comes up with a better way)", "Thanks @alextp , I understand your constraints a bit better, in particular the need for uniformity between argument passing and closure capturing.\r\nRegarding the participants (and myself), the surprise came from examining the graphs generated by various functions, and the number of times the functions were traced. Indeed, the outputs were the ones we expected, it's just a matter of performance, and possibly running out of RAM. But there can be a x100 performance difference or more, so it's not a small detail.  It's like `deque` vs `list`: sometimes knowing how something is implemented is critical.\r\nMoreover, it may not be trivial to debug. I fear that many users will write `range()` instead of `tf.range()`, or they will call `foo(5)` instead of `foo(tf.constant(5))`. I'm just trying to think of ways to reduce that risk (other than having super clear warnings in the documentation and good code examples). Perhaps there's no way around it, but I think it's worth exploring.\r\n", "Thanks you all for the useful discussion. This contributed to formulating a set of semantics consistent across autograph, which are summarized here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/intro.md\r\n\r\nA few concerns remain around expectations for first-time users, but I'm hopeful those can be addressed by documentation and tutorials.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=24742\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=24742\">No</a>\n"]}, {"number": 24741, "title": "When passing tf.data.Dataset instance to model.fit method which is instantiated by tf.keras.Sequential, tf.keras.Model, subclassing tf.keras.Model, passing metrics argument to 'accuracy' in model.compile method provokes TypeError ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.2\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6.6\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nWhen passing `tf.data.Dataset` instance to `model.fit` method which is instantiated by `tf.keras.Sequential`, `tf.keras.Model`, subclassing `tf.keras.Model`, passing `metrics` argument to `'accuracy'` in `model.compile` method provokes `TypeError`. But passing `np.array` to `model.fit` method doesn't provoke `TypeError`.\r\n\r\n**Code to reproduce the issue**\r\n**`tf.data.Dataset`** provkes `TypeError`. (because I think `tf.keras.metrics.sparse_categorical_accuracy`\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nkeras = tf.keras\r\n\r\n# tf.data.Dataset instance\r\ntr_data = np.random.random((1000, 32)).astype(np.float32)\r\ntr_label = np.random.randint(low=0, high=10, size = 1000).astype(np.int32)\r\ntr_dataset = tf.data.Dataset.from_tensor_slices((tr_data, tr_label))\r\ntr_dataset = tr_dataset.batch(batch_size=32)\r\ntr_dataset = tr_dataset.repeat()\r\n\r\nval_data = np.random.random((100, 32)).astype(np.float32)\r\nval_label = np.random.randint(low=0, high=10, size = 100).astype(np.int32)\r\nval_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))\r\nval_dataset = val_dataset.batch(batch_size=100).repeat()\r\n\r\n# Training\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Dense(units=64, activation='relu'))\r\nmodel.add(keras.layers.Dense(units=64, activation='relu'))\r\nmodel.add(keras.layers.Dense(units=10, activation='softmax'))\r\nmodel.compile(optimizer=tf.train.GradientDescentOptimizer(.01), \r\n              loss=keras.losses.sparse_categorical_crossentropy,\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,\r\n          validation_data = val_dataset, validation_steps = 1)\r\n```\r\noutput\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    509                 as_ref=input_arg.is_ref,\r\n--> 510                 preferred_dtype=default_dtype)\r\n    511           except TypeError as err:\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1145     if ret is None:\r\n-> 1146       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1147 \r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    982         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n--> 983         (dtype.name, t.dtype.name, str(t)))\r\n    984   return t\r\n\r\nValueError: Tensor conversion requested dtype int32 for Tensor with dtype int64: 'Tensor(\"metrics/acc/ArgMax:0\", shape=(?,), dtype=int64)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-ef35f2c07d04> in <module>\r\n      9 \r\n     10 model.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,\r\n---> 11           validation_data = val_dataset, validation_steps = 1)\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n   1534         steps_name='steps_per_epoch',\r\n   1535         steps=steps_per_epoch,\r\n-> 1536         validation_split=validation_split)\r\n   1537 \r\n   1538     # Prepare validation data.\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\r\n    990         x, y, sample_weight = next_element\r\n    991     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\r\n--> 992                                                      class_weight, batch_size)\r\n    993     return x, y, sample_weights\r\n    994 \r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_weights(self, x, y, sample_weight, class_weight, batch_size)\r\n   1078                      metrics=self.metrics,\r\n   1079                      loss_weights=self.loss_weights,\r\n-> 1080                      target_tensors=target_tensors)\r\n   1081 \r\n   1082     # In graph mode, if we had just set inputs and targets as symbolic tensors\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py in _method_wrapper(self, *args, **kwargs)\r\n    472     self._setattr_tracking = False  # pylint: disable=protected-access\r\n    473     try:\r\n--> 474       method(self, *args, **kwargs)\r\n    475     finally:\r\n    476       self._setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    646         targets=self.targets,\r\n    647         skip_target_indices=skip_target_indices,\r\n--> 648         sample_weights=self.sample_weights)\r\n    649 \r\n    650     # Prepare gradient updates and state updates.\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _handle_metrics(self, outputs, skip_target_indices, targets, sample_weights, masks)\r\n    311         metric_results.extend(\r\n    312             self._handle_per_output_metrics(self._per_output_metrics[i], target,\r\n--> 313                                             output, output_mask))\r\n    314         metric_results.extend(\r\n    315             self._handle_per_output_metrics(\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)\r\n    268               metric_fn)\r\n    269           metric_result = weighted_metric_fn(\r\n--> 270               y_true, y_pred, weights=weights, mask=mask)\r\n    271 \r\n    272         if not context.executing_eagerly():\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in weighted(y_true, y_pred, weights, mask)\r\n    596     \"\"\"\r\n    597     # score_array has ndim >= 2\r\n--> 598     score_array = fn(y_true, y_pred)\r\n    599     if mask is not None:\r\n    600       mask = math_ops.cast(mask, y_pred.dtype)\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py in sparse_categorical_accuracy(y_true, y_pred)\r\n    660     y_pred = math_ops.cast(y_pred, K.floatx())\r\n    661 \r\n--> 662   return math_ops.cast(math_ops.equal(y_true, y_pred), K.floatx())\r\n    663 \r\n    664 \r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py in equal(x, y, name)\r\n   2732   if _ctx is None or not _ctx._eager_context.is_eager:\r\n   2733     _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 2734         \"Equal\", x=x, y=y, name=name)\r\n   2735     _result = _op.outputs[:]\r\n   2736     _inputs_flat = _op.inputs\r\n\r\n/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    544                   \"%s type %s of argument '%s'.\" %\r\n    545                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\r\n--> 546                    inferred_from[input_arg.type_attr]))\r\n    547 \r\n    548           types = [values.dtype]\r\n\r\nTypeError: Input 'y' of 'Equal' Op has type int64 that does not match type int32 of argument 'x'.\r\n```\r\n\r\n**`np.array`** doesn't provoke `TypeError`\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nkeras = tf.keras\r\n\r\n# np.array \r\ntr_data = np.random.random((1000, 32)).astype(np.float32)\r\ntr_label = np.random.randint(low=0, high=10, size = 1000).astype(np.int32)\r\n# tr_dataset = tf.data.Dataset.from_tensor_slices((tr_data, tr_label))\r\n# tr_dataset = tr_dataset.batch(batch_size=32)\r\n# tr_dataset = tr_dataset.repeat()\r\n\r\nval_data = np.random.random((100, 32)).astype(np.float32)\r\nval_label = np.random.randint(low=0, high=10, size = 100).astype(np.int32)\r\n# val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))\r\n# val_dataset = val_dataset.batch(batch_size=100).repeat()\r\n\r\n# Training\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Dense(units=64, activation='relu'))\r\nmodel.add(keras.layers.Dense(units=64, activation='relu'))\r\nmodel.add(keras.layers.Dense(units=10, activation='softmax'))\r\nmodel.compile(optimizer=tf.train.GradientDescentOptimizer(.01), \r\n              loss=keras.losses.sparse_categorical_crossentropy,\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x=tr_data, y=tr_label, epochs=5, batch_size=32, validation_data=(val_data, val_label))\r\n# model.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,\r\n#           validation_data = val_dataset, validation_steps = 1)\r\n```\r\noutput\r\n```python\r\nTrain on 1000 samples, validate on 100 samples\r\nEpoch 1/5\r\n1000/1000 [==============================] - 0s 171us/step - loss: 2.3126 - acc: 0.1160 - val_loss: 2.3027 - val_acc: 0.1000\r\nEpoch 2/5\r\n1000/1000 [==============================] - 0s 43us/step - loss: 2.3078 - acc: 0.1200 - val_loss: 2.2976 - val_acc: 0.0900\r\nEpoch 3/5\r\n1000/1000 [==============================] - 0s 45us/step - loss: 2.3049 - acc: 0.1240 - val_loss: 2.2953 - val_acc: 0.0800\r\nEpoch 4/5\r\n1000/1000 [==============================] - 0s 42us/step - loss: 2.3030 - acc: 0.1190 - val_loss: 2.2926 - val_acc: 0.0900\r\nEpoch 5/5\r\n1000/1000 [==============================] - 0s 46us/step - loss: 2.3009 - acc: 0.1200 - val_loss: 2.2925 - val_acc: 0.1000\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@aisolab I tried with tf-nightly and it works fine. I think the issue may have been fixed. Can you try with tf-nightly and see if the issue persist?\r\n```\r\nroot@ubuntu:/v# python3 -c 'import tensorflow as tf; print(tf.VERSION)'\r\n1.13.0-dev20190104\r\nroot@ubuntu:/v# python3 24741.py\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:439: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1761: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\r\n2019-01-07 21:19:22.135609: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-01-07 21:19:22.158710: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\r\n2019-01-07 21:19:22.159015: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x3efce10 executing computations on platform Host. Devices:\r\n2019-01-07 21:19:22.159035: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): <undefined>, <undefined>\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:125: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nEpoch 1/5\r\n31/31 [==============================] - 0s 6ms/step - loss: 2.3249 - acc: 0.0958 - val_loss: 2.3252 - val_acc: 0.0600\r\nEpoch 2/5\r\n31/31 [==============================] - 0s 866us/step - loss: 2.3218 - acc: 0.1002 - val_loss: 2.3213 - val_acc: 0.0600\r\nEpoch 3/5\r\n31/31 [==============================] - 0s 867us/step - loss: 2.3174 - acc: 0.0971 - val_loss: 2.3191 - val_acc: 0.0600\r\nEpoch 4/5\r\n31/31 [==============================] - 0s 864us/step - loss: 2.3134 - acc: 0.0950 - val_loss: 2.3173 - val_acc: 0.0400\r\nEpoch 5/5\r\n31/31 [==============================] - 0s 834us/step - loss: 2.3105 - acc: 0.0961 - val_loss: 2.3166 - val_acc: 0.0500\r\nroot@ubuntu:/v# \r\n```", "@yongtang Thanks. I confirmed that it works fine at tf-nightly version", "Closing this issue since its resolved. Thanks everybody :)", "Thankyou,,,It is working for me."]}, {"number": 24740, "title": "TF Android Example first time compile and run FileNotFoundException bug fix", "body": "java.lang.RuntimeException: java.io.FileNotFoundException: mobilenet_v1_1.0_224_quant.tflite\r\nthis error reported after application compile and run first time using Studio, this fix solves the exist problem.\r\n\r\nThis solution for issue #[24263](https://github.com/tensorflow/tensorflow/issues/24263) fix.", "comments": ["@shashishekhar\r\n\r\nWelcome for review and thanks....."]}, {"number": 24739, "title": " AttributeError: module 'tensorflow.python.pywrap_tensorflow' has no attribute 'IsSequenceForData'", "body": "I have followed the TensorFlow tutorial, \"first_steps_with_tensor_flow.ipynb\"  When I ran the code below local , I got  the error messages behind the code below:\r\n\r\nfrom __future__ import print_function\r\n\r\nimport math\r\n\r\nfrom IPython import display\r\nfrom matplotlib import cm\r\nfrom matplotlib import gridspec\r\nfrom matplotlib import pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom sklearn import metrics\r\nimport tensorflow as tf\r\nfrom tensorflow.python.data import Dataset\r\n\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-15-f9edf7e7a602> in <module>\r\n----> 1 from tensorflow.python.data import Dataset\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/__init__.py in <module>\r\n     23 \r\n     24 # pylint: disable=unused-import\r\n---> 25 from tensorflow.python.data import experimental\r\n     26 from tensorflow.python.data.ops.dataset_ops import Dataset\r\n     27 from tensorflow.python.data.ops.iterator_ops import Iterator\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/experimental/__init__.py in <module>\r\n     66 # pylint: disable=unused-import\r\n     67 \r\n---> 68 from tensorflow.python.data.experimental.ops.batching import dense_to_sparse_batch\r\n     69 from tensorflow.python.data.experimental.ops.batching import map_and_batch\r\n     70 from tensorflow.python.data.experimental.ops.batching import unbatch\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/batching.py in <module>\r\n     20 import numpy as np\r\n     21 \r\n---> 22 from tensorflow.python.data.experimental.ops import get_single_element\r\n     23 from tensorflow.python.data.experimental.ops import grouping\r\n     24 from tensorflow.python.data.ops import dataset_ops\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/get_single_element.py in <module>\r\n     18 from __future__ import print_function\r\n     19 \r\n---> 20 from tensorflow.python.data.ops import dataset_ops\r\n     21 from tensorflow.python.data.util import nest\r\n     22 from tensorflow.python.data.util import sparse\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py in <module>\r\n     26 \r\n     27 from tensorflow.python.compat import compat\r\n---> 28 from tensorflow.python.data.ops import iterator_ops\r\n     29 from tensorflow.python.data.util import nest\r\n     30 from tensorflow.python.data.util import random_seed\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py in <module>\r\n     22 \r\n     23 from tensorflow.python.compat import compat\r\n---> 24 from tensorflow.python.data.ops import optional_ops\r\n     25 from tensorflow.python.data.util import nest\r\n     26 from tensorflow.python.data.util import sparse\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/ops/optional_ops.py in <module>\r\n     20 import abc\r\n     21 \r\n---> 22 from tensorflow.python.data.util import structure\r\n     23 from tensorflow.python.framework import dtypes\r\n     24 from tensorflow.python.framework import ops\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/util/structure.py in <module>\r\n     20 import abc\r\n     21 \r\n---> 22 from tensorflow.python.data.util import nest\r\n     23 from tensorflow.python.framework import dtypes\r\n     24 from tensorflow.python.framework import ops\r\n\r\n~/zhang/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py in <module>\r\n     98 \r\n     99 # See the swig file (../../util/util.i) for documentation.\r\n--> 100 is_sequence = _pywrap_tensorflow.IsSequenceForData\r\n    101 \r\n    102 # See the swig file (../../util/util.i) for documentation.\r\n\r\nAttributeError: module 'tensorflow.python.pywrap_tensorflow' has no attribute 'IsSequenceForData'", "comments": ["@zyq11223, as it is not clear to find the root-cause of the issue, could you fill the following build/installation [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md).  Please report the installation process followed and commands used. ", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 24738, "title": "float16 matmul is way slower than float32 matmul on CPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.5.2\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nfloat16 matmul is way slower than float32 matmul on CPU\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport time\r\nfrom datetime import timedelta\r\n\r\n\r\na = tf.random.normal(shape=[1, 768, 768], dtype=tf.float16)\r\nb = tf.random.normal(shape=[1, 768, 768], dtype=tf.float16)\r\n\r\nc = tf.random.normal(shape=[1, 768, 768], dtype=tf.float32)\r\nd = tf.random.normal(shape=[1, 768, 768], dtype=tf.float32)\r\n\r\ne = tf.matmul(a, b)\r\nf = tf.matmul(c, d)\r\n\r\nconfig = tf.ConfigProto(\r\n    intra_op_parallelism_threads=24,\r\n    inter_op_parallelism_threads=24,\r\n    allow_soft_placement=True,\r\n    device_count={\"GPU\": 0},\r\n)\r\n\r\nwith tf.Session(config=config) as sess:\r\n    for i in range(100):\r\n        if i % 2:\r\n            print(\"16bit -- \", end=\"\")\r\n            op = e\r\n        else:\r\n            print(\"32bit -- \", end=\"\")\r\n            op = f\r\n        start = time.monotonic()\r\n        sess.run(op)\r\n        end = time.monotonic()\r\n        print(i, timedelta(seconds=end - start))\r\n```       \r\noutput         \r\n```\r\n2019-01-07 16:06:19.698878: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow bi\r\nnary was not compiled to use: AVX512F\r\n32bit -- 0 0:00:00.017297\r\n16bit -- 1 0:00:00.275746\r\n32bit -- 2 0:00:00.002908\r\n16bit -- 3 0:00:00.261320\r\n32bit -- 4 0:00:00.003028\r\n16bit -- 5 0:00:00.253561\r\n32bit -- 6 0:00:00.002849\r\n16bit -- 7 0:00:00.256515\r\n32bit -- 8 0:00:00.006011\r\n16bit -- 9 0:00:00.255613\r\n32bit -- 10 0:00:00.003996\r\n16bit -- 11 0:00:00.242231\r\n32bit -- 12 0:00:00.003338\r\n```", "comments": ["It is simple, because Intel Architecture does not support FP16.\r\nSee also:\r\nhttps://stackoverflow.com/questions/49995594/half-precision-floating-point-arithmetic-on-intel-chips\r\nhttps://stackoverflow.com/questions/15340781/python-numpy-data-types-performance", "@dchatterjee172,\r\nAbove comment has almost answered your question but you can also take a look at [Mixed_Precision](https://www.tensorflow.org/guide/mixed_precision) which helps us to switch between **`Float32`** and **`Float16`**, for **`Faster Training`**. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 24737, "title": "TF Android Example compile warning fixes", "body": "1. The minSdk and targetSdk version should not be declared in the android manifest file. You can move the version from the manifest to the defaultConfig in the build.gradle file.\r\nReference : https://developer.android.com/guide/topics/manifest/manifest-intro#uses-sdk\r\n2. Configuration 'compile' is obsolete and has been replaced with 'implementation' and 'api'.\r\nReference : http://d.android.com/r/tools/update-dependency-configurations.html", "comments": ["@shashishekhar \r\n\r\nWelcome for review and thanks....."]}, {"number": 24736, "title": "Fix crossentropy loss by assuming last dimension as classes", "body": "Fixes #24397 ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "While I would like to see this issue resolved, I'm not going through the process of signing a document for a fix that consists of a single character edit :) . I'm sure a contributor can review this and make the edit themselves."]}, {"number": 24735, "title": "Error while building from source with Bazel: in target '//external:cc_toolchain': no such package '@local_config_cc//'", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13\r\n- Python version: 3.6.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.20.0\r\n\r\n\r\n**Describe the problem**\r\nI followed the instructions to build TF from source with bazel. But this error occurs:\r\n\r\n> C:\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nc:\\tensorflow/.bazelrc\r\nStarting local Bazel server and connecting to it...\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nINFO: Invocation ID: 1a8498c3-1a43-45b0-abe9-317aa5b27e0b\r\nERROR: in target '//external:cc_toolchain': no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 51\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 347, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 257, in _find_missing_vc_tools\r\n                find_msvc_tool(repository_ctx, vc_path, tool)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 230, in find_msvc_tool\r\n                repository_ctx.path((vc_path + \"\\\\Tools\\\\MSVC\")).readdir()\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)\r\nINFO: Elapsed time: 4,086s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (2 packages loaded)\r\n    Fetching @local_config_cc; fetching\r\n\r\n(I did the default configuration)\r\n\r\nThe weird thing is that it seems to look for a file in MSVC 2017, while I have MSVC 2015 Update 3 installed (I also tried with MSVC 2017, same error).\r\n\r\nNote that I had tried building with Cuda 9.0 before and had a similar error ( issue #24549 ).\r\n\r\nIs there anything I can do ?\r\n\r\nThanks.\r\n\r\n", "comments": ["Hello @Maxtoq , please try building with bazel 0.15.0 with TensorFlow version 1.12.0 , and let us know. Thanks.", "Hi,\r\nI tried this and I have the same issue:\r\n\r\n> C:\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: 'BAZEL_VC' is not set, start looking for the latest Visual C++ installed.\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Looking for VS%VERSION%COMNTOOLS environment variables, eg. VS140COMNTOOLS\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Looking for Visual C++ through registry\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Visual C++ build tools found at C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\VC\r\nERROR: in target '//external:cc_toolchain': no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 51\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 336, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 253, in _find_missing_vc_tools\r\n                find_msvc_tool(repository_ctx, vc_path, tool)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 226, in find_msvc_tool\r\n                repository_ctx.path((vc_path + \"\\\\Tools\\\\MSVC\")).readdir()\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)\r\nINFO: Elapsed time: 0,651s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\nI'm starting to think my installation of Visual Studio Code could be part of the issue.\r\nThe folder \"Tools\" is missing in \"C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/\".\r\n\r\nDo you have any clue ?\r\n\r\nThanks", "@Maxtoq , you may be correct, it has been noticed that MSVC 2015 update 3 is more reliable with r1.12.0 , and since you are building r1.13.0 from source, please investigate this. Thanks.", "But last try was actually with r1.12.0 and MSVC 2015 Update 3 (and bazel 0.15.0).\r\nThe weird thing is that it still tries to look for a file in the folder \"../Miscrosoft Visual Studio/2017/\".\r\nI'm gonna try to uninstall VS Code and reinstall MSVC 2015 to see if there's a change.\r\n\r\nIf you have any other idea, I'll take it.\r\n\r\nThanks.", "Hi @mrry , can you advise what this user may be facing with respect to the MSVC 2017? Thanks.", "I uninstalled Visual Studio 2017, the error is now different:\r\n\r\n> C:\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\n.....................\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: 'BAZEL_VC' is not set, start looking for the latest Visual C++ installed.\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Looking for VS%VERSION%COMNTOOLS environment variables, eg. VS140COMNTOOLS\r\nDEBUG: C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5:\r\nAuto-Configuration Warning: Looking for Visual C++ through registry\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1447\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1303, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 217, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 153, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\")\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 223, in find_msvc_tool\r\n                _is_vs_2017(vc_path)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 183, in _is_vs_2017\r\n                vc_path.find(\"2017\")\r\ntype 'NoneType' has no method find(string)\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1447\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1303, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 217, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/tensorflow/third_party/gpus/cuda_configure.bzl\", line 153, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\")\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 223, in find_msvc_tool\r\n                _is_vs_2017(vc_path)\r\n        File \"C:/users/maxim/_bazel_maxim/xv6zejqw/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 183, in _is_vs_2017\r\n                vc_path.find(\"2017\")\r\ntype 'NoneType' has no method find(string)\r\nINFO: Elapsed time: 7,332s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n\r\nIt seems bazel doesn't find the MSVC 2015 files.\r\nCan I do something ?", "Hi @Maxtoq , I believe you may have narrowed it down. Can you please submit the issue with the Bazel GitHub community, since it is a bazel / MSVC 2015 issue along with your specific environment. Their link is: https://github.com/bazelbuild/bazel/issues\r\nMeanwhile we will close the issue here. Thanks.", "I'll do that.\r\nThanks", "I solved the problem. The problem was I had badly set the environment variable BAZEL_VS (or BAZEL_VC). I followed the examples given here: https://docs.bazel.build/versions/0.21.0/install-compile-source.html#bootstrap-windows-bootstrap."]}, {"number": 24734, "title": "Check failed: GetOpGradFactory()->insert({op, func}).second Duplicated gradient for ReadVariableOp Aborted (core dumped)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):pip install \r\n- TensorFlow version (use command below):1.12\r\n- Python version:3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nTF version = 1.12\r\ntfnightly = 1.13.0.dev20190104\r\npython 3.5\r\nModel ssd_mobilenet_v1_coco_2018_01_28\r\n\r\n```\r\nimport tensorflow as tf\r\nimport sys\r\ndef convert(frozen):\r\n\tgraph_def_file = frozen+\"/frozen_inference_graph.pb\"\r\n\tinput_arrays = [\"image_tensor\"]\r\n\toutput_arrays = [\"detection_boxes\",\"detection_scores\",\"detection_classes\",\"num_detections\"]\r\n\tconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(graph_def_file,input_arrays,output_arrays)#,input_shapes={\"image_tensor\":[None,300,300,3]})\r\n\ttflite_model = converter.convert()\r\n\topen(frozen+\"/model.tflite\", \"wb\").write(tflite_model)\r\n\r\nif __name__=='__main__':\r\n\tfrozen_path = sys.argv[1]\r\n\tconvert(frozen_path)\r\n```\r\nError\r\n\r\n> 2019-01-07 09:01:08.263004: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> 2019-01-07 09:01:08.268020: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300030000 Hz\r\n> 2019-01-07 09:01:08.268185: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x56b0400 executing computations on platform Host. Devices:\r\n> 2019-01-07 09:01:08.268255: I tensorflow/compiler/xla/service/service.cc:168] StreamExecutor device (0): , \r\n> 2019-01-07 09:01:09.412404: I tensorflow/core/grappler/devices.cc:53] Number of eligible GPUs (core count >= 8): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n> 2019-01-07 09:01:09.412562: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n> 2019-01-07 09:01:11.571194: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:584] Optimization results for grappler item: graph_to_optimize\r\n> 2019-01-07 09:01:11.571245: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] model_pruner: Graph size after: 5957 nodes (-3), 10020 edges (-3), time = 68.272ms.\r\n> 2019-01-07 09:01:11.571253: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] function_optimizer: Graph size after: 5957 nodes (0), 10020 edges (0), time = 13.564ms.\r\n> 2019-01-07 09:01:11.571259: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] constant folding: Graph size after: 5958 nodes (1), 10022 edges (2), time = 539.625ms.\r\n> 2019-01-07 09:01:11.571265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] shape_optimizer: Graph size after: 5958 nodes (0), 10022 edges (0), time = 31.515ms.\r\n> 2019-01-07 09:01:11.571271: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] arithmetic_optimizer: Graph size after: 4306 nodes (-1652), 8412 edges (-1610), time = 243.152ms.\r\n> 2019-01-07 09:01:11.571280: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] loop_optimizer: Graph size after: 4289 nodes (-17), 8380 edges (-32), time = 43.908ms.\r\n> 2019-01-07 09:01:11.571289: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] dependency_optimizer: Graph size after: 4272 nodes (-17), 8358 edges (-22), time = 103.724ms.\r\n> 2019-01-07 09:01:11.571299: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] layout: Graph size after: 4272 nodes (0), 8358 edges (0), time = 15.684ms.\r\n> 2019-01-07 09:01:11.571309: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] memory_optimizer: Graph size after: 4272 nodes (0), 8358 edges (0), time = 263.292ms.\r\n> 2019-01-07 09:01:11.571319: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] model_pruner: Graph size after: 4258 nodes (-14), 8332 edges (-26), time = 43.246ms.\r\n> 2019-01-07 09:01:11.571329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] function_optimizer: Graph size after: 4258 nodes (0), 8332 edges (0), time = 11.187ms.\r\n> 2019-01-07 09:01:11.571338: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] constant folding: Graph size after: 4258 nodes (0), 8332 edges (0), time = 305.64ms.\r\n> 2019-01-07 09:01:11.571348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] shape_optimizer: Graph size after: 4258 nodes (0), 8332 edges (0), time = 22.274ms.\r\n> 2019-01-07 09:01:11.571358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] arithmetic_optimizer: Graph size after: 4256 nodes (-2), 8328 edges (-4), time = 192.768ms.\r\n> 2019-01-07 09:01:11.571367: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:586] dependency_optimizer: Graph size after: 4256 nodes (0), 8328 edges (0), time = 100.01ms.\r\n> Traceback (most recent call last):\r\n> File \"export_graph.py\", line 15, in \r\n> convert(frozen_path)\r\n> File \"export_graph.py\", line 10, in convert\r\n> tflite_model = converter.convert()\r\n> File \"/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/lite/python/lite.py\", line 499, in convert\r\n> **converter_kwargs)\r\n> File \"/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/lite/python/convert.py\", line 445, in toco_convert_impl\r\n> input_data.SerializeToString())\r\n> File \"/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/lite/python/convert.py\", line 208, in toco_convert_protos\r\n> \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n> tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n> 2019-01-07 09:01:12.809603: F tensorflow/core/framework/function.cc:1640] Check failed: GetOpGradFactory()->insert({op, func}).second Duplicated gradient for ReadVariableOp\r\n> Aborted (core dumped)\r\n> ", "comments": ["This should be fixed in the latest tf-nightly.", "Yeah, this should be fixed with 9f3acf3d89a4ef5f9313a6e2cb2d81e03177e8ef, apologies for the trouble."]}, {"number": 24733, "title": "Fix several DeprecationWarning: invlid escape sequence", "body": "Updated #24688", "comments": ["@alextp could you please the failing checks ?", "It looks like a real failure on assert raises with predicate match. Please fix.", "@Dayananda-V  please check above comments .", "@alextp \r\n\r\nthanks for review comments, noticed problem is fixed and updated commit. "]}, {"number": 24731, "title": "cannot locate \"pip_test/whl/*.whl\" while executing parameterized_docker_build.sh", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:1.12\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nI modify `ci_build/Dockerfile.gpu`, change the ENV part\r\n```\r\n# Configure the build for our CUDA configuration.\r\nENV TF_NEED_CUDA 1\r\nENV TF_NEED_TENSORRT 1\r\nENV TF_CUDA_COMPUTE_CAPABILITIES=6.1,7.0\r\nENV TF_CUDA_VERSION=9.0\r\nENV TF_CUDNN_VERSION=7\r\nENV NO_TEST_ON_INSTALL=1\r\nENV TF_GPU_COUNT=1\r\n```\r\n\r\nthen I execute `parameterized_docker_build.sh` as below\r\n```\r\nTF_DOCKER_BUILD_TYPE=gpu TF_DOCKER_BUILD_IS_DEVEL=no TF_DOCKER_BUILD_DEVEL_BRANCH=r1.12 ./parameterized_docker_build.sh\r\n```\r\nafter pip test finished, I got the following error\r\n```\r\nParameterized build ends with SUCCESS at: Fri Jan  4 11:35:46 UTC 2019 (Elapsed time: 1271 s)\r\n~/tf_builder/tensorflow/tensorflow/tools/docker\r\nls: cannot access 'pip_test/whl/*.whl': No such file or directory\r\nERROR: Cannot locate the locally-built pip whl file\r\n```\r\n\r\n**Any other info / logs**\r\nI found in `parameterized_docker_build.sh`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/38c91321421694432117b077294df43aa31d1193/tensorflow/tools/docker/parameterized_docker_build.sh#L250-L265\r\n\r\nbefore the `ci_parameterized_build.sh ` execute , the script enterd the folder `${SCRIPT_DIR}/../../../`, and left the folder immediately after build finish.\r\n\r\nthen the script will check whether the whl is existed by `ls pip_test/whl/*.whl | head -1`\r\n\r\nI think the whl existence check should also be executed inside `push pop` section, not outside.Am I right?\r\n\r\nMy source code is in directory `~/tf_builder/tensorflow/`\r\nSo the building script is in `~/tf_builder/tensorflow/tensorflow/tools/docker`\r\nAfter building finish, I can find whl in `~/tf_builder/tensorflow/pip_test/whl/`\r\n", "comments": ["This problem can be solved by executing script under `${SCRIPT_DIR}`\r\n```\r\ncd ~/tf_builder/tensorflow/\r\nTF_DOCKER_BUILD_TYPE=gpu TF_DOCKER_BUILD_IS_DEVEL=no TF_DOCKER_BUILD_DEVEL_BRANCH=r1.12 tensorflow/tools/docker/parameterized_docker_build.sh\r\n```\r\nI executed the script in `~/tf_builder/tensorflow/tensorflow/tools/docker` before.\r\nBut I think the script should also changed in section\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/38c91321421694432117b077294df43aa31d1193/tensorflow/tools/docker/parameterized_docker_build.sh#L250-L265"]}, {"number": 24730, "title": "Depthwise Conv Tensor Allocation Failure", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\n`java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/contrib/lite/kernels/depthwise_conv.cc:92 NumDimensions(input) != 4 (0 != 4)Node number 0 (DEPTHWISE_CONV_2D) failed to prepare.`\r\n\r\nI construct the model with:\r\n```\r\ninterpreter = Interpreter(loadModelFile(\"model.tflite\"), object: Interpreter.Options() {\r\n                override fun setAllowFp16PrecisionForFp32(allow: Boolean): Interpreter.Options {\r\n                    return super.setAllowFp16PrecisionForFp32(true)\r\n                }\r\n\r\n                override fun setUseNNAPI(useNNAPI: Boolean): Interpreter.Options {\r\n                    return super.setUseNNAPI(true)\r\n                }\r\n\r\n            })\r\n```\r\n\r\nand invoke it with:\r\n\r\n```            \r\nimgData = ByteBuffer.allocateDirect(4 * 100 * 100).apply { order(nativeOrder()) }.asFloatBuffer()\r\n            labelProbArray = IntArray(1)\r\ninterpreter.run(imgData, labelProbArray as Any)\r\n```\r\n\r\n**Describe the expected behavior**\r\nExpected behavior is that the byte buffer would be converted to tensors of float32 under the hood as per the placeholder op. \r\n\r\n**Other info / logs**\r\n[model.dot.pdf](https://github.com/tensorflow/tensorflow/files/2730812/model.dot.pdf)\r\n\r\n", "comments": ["Hello @twalk4821 , Thanks for the detailed model schematics PDF.\r\nHello @aselle & @andrehentz , can you please check the user's code fragment in _interpreter_ function, and if the TFLite setUseNNAPI usage is correct. Please advise. Thanks.", "Are you resizing the input tensor in java in any way? It looks like the op is expecting a 4D tensor, but is getting an empty tensor (0D) instead???", "Also, when you converted your .tflite model, what shape did you specify for the input tensor?", "I just want to say thank you guys for your responses, I hope this isn't a waste of time for you.\r\n\r\n> Also, when you converted your .tflite model, what shape did you specify for the input tensor?\r\n\r\nI thought of that as well, was hopeful that would have been the problem. This is the command I used:\r\n\r\n`tflite_convert --output_file=/export/model.tflite --saved_model_dir=/export/1546746950 --input_shapes=1,100,100,1 --input_arrays=Placeholder\r\n`\r\n\r\n> Are you resizing the input tensor in java in any way? It looks like the op is expecting a 4D tensor, but is getting an empty tensor (0D) instead???\r\n\r\nAs far as transforming the input, all I am doing is passing in a ByteBuffer, of size 4x100x100x1x1, since 4 bytes needed per float, and then the input matrix has dimensions 100x100x1 with batch size 1.\r\n\r\nAlso, here is the first line of my model_fun, where input is initially transformed and accepted into the network: \r\n\r\n```\r\ndef model_fun(features, labels, mode):\r\n  input_layer = tf.cast(tf.reshape(features[\"x\"], [-1, 100, 100, 1]), dtype=tf.float32)\r\n// model_fun cont.\r\n```", "Oh, I forgot I also used this serving input receiver function when saving the model:\r\n\r\n```\r\ndef serving_input_receiver_fn():\r\n  features = { 'x': tf.placeholder(shape=[1, 100, 100, 1], dtype=tf.float32) }\r\n  return tf.estimator.export.ServingInputReceiver(features, features)\r\n```\r\n\r\nWas trying to keep this part as fool proof as possible, but, well, I guess it wasn't fool proof enough.", "@twalk4821 , hope this discussion has been useful to your TFlite query. We close this issue. Thanks.", "No it wasn't, but thanks anyway.", "Please reopen the issue, I have similar doubt.", " @twalk4821 Hi, twalk4821. \r\nSorry for my bad English.  When I convert the mobilenetv2+deeplabv3+ model to  a tflite file and then deploy it to Andriod, I encountered the same error:\r\nInternal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/depthwise_conv.cc:108 params->depth_multiplier * SizeOfDimension(input, 3) != SizeOfDimension(filter, 3) (0 != 32)Node number 16 (DEPTHWISE_CONV_2D) failed to prepare.\r\nCan you give me some suggestions? Thanks."]}, {"number": 24729, "title": "Speech recognition with pretrained model", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n\r\n\r\nTrain the acoustic model with 30 words in the speech command database.\r\n\r\nThe pretrained model file \"conv_actions_labels.txt\" only contains 10 words, however, the speech command database (http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz) contains 30 words. If I follow the train process in the tutorial (https://www.tensorflow.org/tutorials/sequences/audio_recognition) , the trained model can only handle 10 words, right?\r\n\r\nHow can I train the model to recognize other words in the speech command database? (which include words like forward, tree, etc...)\r\n\r\nThanks.", "comments": []}, {"number": 24728, "title": "backpropagation of gradients into labels in tensorflow tf.nn.ctc_loss()", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- Python version: 2.7\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI am working with tensorflow ctc loss function `tf.nn.ctc_loss(labels,inputs,__)`\r\n\r\nHere `inputs` argument is the output from some RNN1 and `labels` argument is true target that we want to achieve.\r\nIn my case `labels` is also generated from some other RNN2.\r\n\r\nBut after training, only RNN1 weights are updated by tensorflow backpropagation and RNN2 weights are not changing at all. I think tensorflow does not support backpropagation of **gradients** into `labels` for **ctc_loss** as done in `tf.nn.softmax_cross_entropy_with_logits_v2()`.\r\n\r\nWhat is the possible workaround for it?\r\n\r\n**Will this change the current api? How?**\r\n\r\nNew parameter can be added to existing api `tf.nn.ctc_loss()` to enable or disable gradients backpropagation along `labels`.\r\n\r\n**Who will benefit with this feature?**\r\nA wast community of DL developers working with ctc_loss as labels can be generated dynamically from another neural network.", "comments": ["Hi,\r\nBy default CTC wasn't meant to backpropgrate through labels because they are the ground truth inputs. The reason why it worked with softmax cross entropy was because the loss got differentiated in the graph itself with respect to the labels. This isn't the case with ctc_loss as the labels don't have a gradient.", "> Hi,\r\n> By default CTC wasn't meant to backpropgrate through labels because they are the ground truth inputs. The reason why it worked with softmax cross entropy was because the loss got differentiated in the graph itself with respect to the labels. This isn't the case with ctc_loss as the labels don't have a gradient.\r\n\r\nWhy softmax cross entropy loss was differentiated w.r.t ground truth labels?\r\nIf anyway differentiation was performed in cross entropy loss, similar thing can be achieved in ctc_loss.\r\nI do not see any problem in that.", "It might be possible. Someone will need to write the custom gradient implementation for it", "Hello @abhiramsingh0 , @vidursatija has addressed the original query for this issue. This issue shall be closed. But feel free to raise a PR for gradient implementation for ctc_loss, if necessary. Thanks."]}, {"number": 24727, "title": "Run tflite model on self-developed embedded system", "body": "Hi experts,\r\nI have self-developed an embedded system. I want to run tflite model on this system for detection or classification. But I can't how to do it. Could you please give me advises and instruction of solving this problem? \r\n\r\nThanks.", "comments": []}, {"number": 24726, "title": "PolymorphicFunction.get_concrete_function() creates a different concrete function for each python scalar value", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac OS X 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION=\"1.13.0-dev20181226\" (this is the TF 2.0-preview)\r\nGIT_VERSION=\"b'v1.12.0-5133-gc343196842'\"\r\n- Python version:\r\n3.6.6\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\n`tf.function` returns a `PolymorphicFunction`.  When called, this function creates a concrete function to call for the specific types and shapes of the arguments, by calling `PolymorphicFunction.get_concrete_function()`, and subsequently, it reuses the same concrete function when it encounters the same types and shapes again.\r\n\r\nUnfortunately, when passed python scalars or arrays of scalars, it seems to create a new function for each different value, instead of each different type (see code example below). Similarly, it creates a new function for [1.0, 2.0], and [3.0, 4.0].\r\n\r\nI understand that there may be a good technical reason for this, but even if there is, I fear that users will pass Python scalar values or arrays (instead of tensors or NumPy arrays) to @tf.functions and they won't understand why their system blows up (slowed down by all the traces and new concrete functions piling up in RAM all the time).\r\n\r\n**Describe the expected behavior**\r\nI expect `PolymorphicFunction.get_concrete_function()` to return the same concrete function whether I pass it 1, or 2, or tf.constant(3) or tf.constant(4) as an argument.  I expect a different concrete function to be returned when I pass it [1.0], but this second concrete function should be the same as for the arguments [2.0], or tf.constant([3.0]), or tf.constant([4.0]) or np.array([5.0]), or or np.array([6.0])\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n@tf.function\r\ndef square(x):\r\n    print(\"Calling\")\r\n    tf.get_logger().warning(\"Tracing\")\r\n    return tf.square(x)\r\n\r\nprint(\"Square of int32 scalars\")\r\nfor i in range(3):\r\n    square(tf.constant(i))\r\nprint(\"OKAY\")\r\n    \r\nprint()\r\nprint(\"Square of float32 scalars\")\r\nfor i in range(3):\r\n    square(tf.constant(i, dtype=tf.float32))\r\nprint(\"OKAY\")\r\n\r\nprint()\r\nprint(\"Square of float32 arrays of shape [2]\")\r\nfor i in range(3):\r\n    square(tf.constant([i, i], dtype=tf.float32))\r\nprint(\"OKAY\")\r\n\r\nprint()\r\nprint(\"Square of float32 NumPy arrays of shape [2]\")\r\nfor i in range(3):\r\n    square(tf.constant(np.array([i, i]), dtype=tf.float32))\r\nprint(\"OKAY\")\r\n\r\nprint()\r\nprint(\"Square of python integers 1, 2, 3\")\r\nfor i in range(3):\r\n    square(i)\r\nprint(\"ERROR! Why is there one trace per call?\")\r\n\r\nprint()\r\nprint(\"Square of python integers 1, 2, 3 (AGAIN)\")\r\nfor i in range(3):\r\n    square(i)\r\nprint(\"ERROR! No traces anymore, which means that one Function was cached for each specific integer 1, 2, 3.\")\r\n\r\nprint()\r\nprint(\"Square of python integers arrays of shape [2]\")\r\nfor i in range(3):\r\n    square([i, i])\r\nprint(\"ERROR! Why is there one trace per call?\")\r\n```\r\n\r\n**Other info / logs**\r\nHere is the output of this program:\r\n\r\n```\r\nSquare of int32 scalars\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of float32 scalars\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of float32 arrays of shape [2]\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of float32 NumPy arrays of shape [2]\r\nCalling\r\nCalling\r\nCalling\r\nOKAY\r\n\r\nSquare of python integers 1, 2, 3\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nERROR! Why is there one trace per call?\r\n\r\nSquare of python integers 1, 2, 3 (AGAIN)\r\nCalling\r\nCalling\r\nCalling\r\nERROR! No traces anymore, which means that one Function was cached for each specific integer 1, 2, 3.\r\n\r\nSquare of python integers arrays of shape [2]\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nWARNING:tensorflow:Tracing\r\nCalling\r\nERROR! Why is there one trace per call?\r\n```\r\n\r\n", "comments": ["Hello @martinwicke , @ageron has elucidated the polymorphic property of tf.function usage, and pointing to scalar and array arguments throwing warnings. If this intended, can this be noted? Thanks.", "Thanks @msymp. My code produces the warnings to show when the function is being traced. My point is that `square(1)`, `square(2)` and `square(3)` produce and cache three different concrete functions. This seems wasteful and counterintuitive. If I wrap the integers in `tf.constant()`, it has the expected behavior (just one concrete function is generated).", "@alextp I believe this is intentional (for optimization purposes) but I agree it needs to be very clear in the docs. ", "Thanks @martinwicke , I was afraid it might be intentional.  This behavior is really surprising to me, and even now that I know it, I am concerned that I might unintentionally fall into this trap again. Perhaps it should be opt-in, somehow. Can you please give an example of where it might be useful?", "Indeed it is intentional. It's a compromise to support the case where the python scalar is something like \"num_layers\" which dramatically affects the structure of the generated graph :-/", "Hi @alextp , oh I see, thanks for the example use case.  This probably deserves a very clear warning in the documentation, wdyt?", "Good point about a warning in the documentation. Do you feel like writing\none, or do you want me to take a stab at it?\n\nOn Mon, Jan 14, 2019 at 4:46 PM Aur\u00e9lien Geron <notifications@github.com>\nwrote:\n\n> Hi @alextp <https://github.com/alextp> , oh I see, thanks for the example\n> use case. This probably deserves a very clear warning in the documentation,\n> wdyt?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24726#issuecomment-454220980>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxR3--SVROMYHGSh-kRqYfdZUYKLIks5vDSTJgaJpZM4ZyVze>\n> .\n>\n\n\n-- \n - Alex\n", "Hi @alextp, I won't have time in the next couple of days, but I can do this at the end of the week.", "Sounds good to me. We're not cutting a release branch between now and then.\n\nOn Mon, Jan 14, 2019 at 5:21 PM Aur\u00e9lien Geron <notifications@github.com>\nwrote:\n\n> Hi @alextp <https://github.com/alextp>, I won't have time in the next\n> couple of days, but I can do this at the end of the week.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24726#issuecomment-454227611>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxVVkwtqT7y8V3VxuoMkVOk9TpseAks5vDSz9gaJpZM4ZyVze>\n> .\n>\n\n\n-- \n - Alex\n", "Regarding the \"warning in the documentation\" discussed here:\r\n- https://www.tensorflow.org/api_docs/python/tf/contrib/eager/function doesn't have the warning that was going to be added in 1.13 (which is why I'm commenting on this specific bug);\r\n- https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/function mentions the problem, but this paragraph (3rd) can't be called a warning. Bold text, color would help. A note that A MISTAKE HERE WILL EAT YOUR COMPUTER would be more explicit than \"a new graph will be generated for each distinct value\". Also, the section on Retracing is written to suggest TF may eventually become smart about not retracing too much. It should be noted in very clear terms that it is not yet smart at all about it. \r\n- https://www.tensorflow.org/alpha/guide/autograph doesn't have a mention of this (and has a nice \"Use Python control flow\" section, but lacks a \"BUT DON'T USE PYTHON VALUES\" section;\r\n- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md doesn't mention this either, and yes I can see it contains a different kind of table, but it is linked to by the tf.function tutorial as \"Capabilities and Limitations\" of tf.function and AutoGraph, and one could assume it is a fair summary of gotchas -- it isn't;\r\n- The RFC https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md mentions the idea of a warning when too many traces are created, but I don't think the warning exists yet.\r\n\r\nAlso, more fundamentally, could this be changed to something of a tad saner compromise in TF2?\r\n\r\nCurrently, if you merely forget to wrap in a tensor a Python value, anywhere in your code, hell ensues and you are given no clue whatsoever. Not even: \"We've allocated 16GB because we keep compiling your code over and over.. maybe check how function f() is called ... beware Python values ...\", or better: some soft threshold on how many times you recompile the same function: \"warning... f{} has been recompiled 1001 times ... maybe check for code calling it with non-Tensor argument values...\". (Turns out the RFC also thought such a warning would make sense.)\r\n\r\nIt also makes writing code a pain, when the whole point of tf.function is to make it more Pythonic -- but it does pretty much the exact opposite because Python values should be reserved to very specific (and in practice, with complex code, quite rare) cases.\r\n\r\nWhat about requiring a positive marker on values which should be considered constant with respect to graph instantiation? That is, require wrapping *those* Python values, and treat others like tensors?\r\n\r\ntf.YesIDoWantYouToSpendThreeSecondsRecompilingThisCallAndAllocatingTonsOfRAMDoingSo(3), or maybe tf.GraphConstant(3) or whatever?", "A warning after N retraces of the function (10? 100?) sounds good to me. Want to send a pull request?\r\n\r\nForcing wrapping of other python values doesn't.\r\n\r\nI'd still like to find out a better way to inspect code and find out if it'll do something funny with tensor-convertible python values, but I haven't had the time to do this yet.", "To be clear, I mean forcing wrapping of Python values with tf.GraphConstant() that are intended to be compile-time constants, and *removing* the need for wrapping as tensor every single Python value that changes a bit. I don't have data, but in my code it's 5% true constants, 95% variables.\r\n\r\nAnother problem with the need to wrap nearly-all Python values as tensors is that this applies only at function call boundaries.\r\n\r\nSo if your code works, and you say \"I'd like to refactor the body of this loop using another tf.function\", all of a sudden you better make sure you're indeed using tf.range() not range(), that you don't use integer variables to keep track of stuff, etc... and that's a fair bit of work in a language without type annotations. It's a barrier to code reorg.\r\n\r\nAdditionally, it's quite backwards: the possibility of optimization shouldn't be at the risk of turning your computer into a pile of molten metal. Hopefully that ship hasn't sailed. I mean, C eventually adopted \"restrict\" as an explicit keyword, after three decades of \"we'll just make silent and subtle assumptions about memory aliasing and break shit \u2013 developers will just get it right, after all we have a footnote about this\".\r\n\r\nI'll submit a PR for a runtime warning in the tracing code and will include a reference to this issue.\r\n\r\n> I'd still like to find out a better way to inspect code and find out if it'll do something funny with tensor-convertible python values, but I haven't had the time to do this yet.\r\n\r\nWhat do you mean? Do you suggest deriving, through code analysis, that a Python value is clearly not a constant (e.g. return value of range(variable) ...) and therefore do not create a new graph whenever it changes? Generally speaking, through static analysis one could estimate a range / set of possible values for a given variable, and only create new graphs for new values of variables deemed to be nearly-constant, i.e. you can prove that the set of possible values is small. But that immediately introduces the need for a way to override the static analyzer if it gets it wrong. And in this line of work, the static analysis is necessarily conservative. Hence the need for a tf.GraphConstant annotation...\r\n\r\nIt's also counter-intuitive on this level: the history of compilers is full of constant analysis, and it's not particularly hard, not the other way around.\r\n\r\nIn any case, this could be done dynamically: instead of a runtime warning, blacklist a function from further retracing if it gets retraced too many times (and maybe still print a warning)? I'll create a second PR for that too, if I can find a sane way to do it.", "I have given a few TensorFlow 2.0 courses, and I can confirm that this behavior surprised every single student (@ericrannaud , the \"pile of molten metal\" made me laugh).\r\n\r\nI was also in favor of dynamic-by-default, but I think the ship has sailed, and a warning sounds like the best option, ideally pointing to the problematic argument(s), and perhaps even a pointer to the line of code where tf.function is called. Thanks for your contribution @ericrannaud. Big warnings in the docs would also be very helpful."]}, {"number": 24725, "title": "tensorflow cannot launch operator: NormalizeWithDimensions", "body": "2019-01-06 03:31:37.602215: E tensorflow/stream_executor/cuda/cuda_dnn.cc:4063] failed to run cudnnLRNCrossChannelForward\r\nTraceback (most recent call last):\r\n  File \"main_segnet.py\", line 124, in <module>\r\n    main()\r\n  File \"main_segnet.py\", line 119, in main\r\n    segnet_solver.train()\r\n  File \"/home/jingwei/RA_XJTLU__10_12_2018_to_2_28_2019/KTF/scripts/Segmentation_Nets/Seg_net/solver_segnet.py\", line 188, in train\r\n    _, loss, cur_lr = sess.run([self.train_op, self.net.Loss, self.lr_node], feed_dict=feed_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: NormalizeWithDimensions launch failed\r\n\t [[Node: norm1 = LRN[T=DT_FLOAT, alpha=0.0001, beta=0.75, bias=1, depth_radius=5, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_3/_87)]]\r\n\r\nCaused by op u'norm1', defined at:\r\n  File \"main_segnet.py\", line 124, in <module>\r\n    main()\r\n  File \"main_segnet.py\", line 91, in main\r\n    is_bw_loss=False)\r\n  File \"/home/jingwei/RA_XJTLU__10_12_2018_to_2_28_2019/KTF/scripts/Segmentation_Nets/Seg_net/model_segnet.py\", line 56, in __init__\r\n    phase_train=self.phase_train)\r\n  File \"/home/jingwei/RA_XJTLU__10_12_2018_to_2_28_2019/KTF/scripts/Segmentation_Nets/Seg_net/layers_segnet.py\", line 207, in inference\r\n    norm1 = tf.nn.lrn(images, depth_radius=5, bias=1.0, alpha=0.0001, beta=0.75, name='norm1')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4380, in lrn\r\n    beta=beta, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInternalError (see above for traceback): NormalizeWithDimensions launch failed\r\n\t [[Node: norm1 = LRN[T=DT_FLOAT, alpha=0.0001, beta=0.75, bias=1, depth_radius=5, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_x_0_3/_87)]]\r\n\r\n\r\nThis bug happens in GTX2080ti only. Tensorflow works fine in GTX1080ti.\r\nI try to upgrade the version of tensorflow from 1.5.0 to 1.9.0 but it does not help.\r\nMy operating system is Ubuntu 18.04.", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Issues happen when run a operator in tensorflow on GTX2080ti.\r\nI get this issues done through just assigning the operator on CPU.", "@Adopteruf  What is the cuda version you are using? @samikama Do you think it can be related possibly to cuda version mismatch?Thanks!", "What is the cuda and cudnn version? For 2080 it needs to be 10 and compatible cudnn. TF1.9 might be  too old for these.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24723, "title": "Fix incorrectly returned error type during RaggedTensor iteration", "body": "This fix tries to address the issue raised in #24679 where RaggedTensor iteration does not stop correctly (eager mode):\r\n```\r\nimport tensorflow as tf\r\nr = tf.ragged.constant([[1., 2.], [3., 4., 5.], [6.]])\r\nfor elem in r:\r\n    print(elem)\r\n```\r\n\r\nThe reason was that `__getitem__()` should have thrown IndexError (translated to StopIteration in next/__next__()) in order for python to correctly process iteration.\r\n\r\nThis fix fixes the issue.\r\n\r\nThis fix fixes #24679.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @penpornk for the help. The PR has been updated with test fixed. Please take a look.\r\n\r\nThere are still failing tests remaining but it looks like they are unrelated."]}, {"number": 24722, "title": "Error building master branch from source", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master branch\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 18 and 19\r\n- GCC/Compiler version (if compiling from source): 5.4\r\n- CUDA/cuDNN version: 9.0/7.2 and 10.0/7.4\r\n- GPU model and memory: GT 755M\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nThe problem occurred for both gpu and cpu build. I was able to replicate the error on two different machines with set up listed above (i.e. one with cuda 9.0 and cuDNN 7.2 and another with cuda 10.0 and cuDNN 7.4). On both machines, I was able to build tensorflow 1.12 without any issue.\r\n\r\nThe exact error message is follows:\r\n\r\n```bash\r\nERROR: missing input file '@pasta//:LICENSE'\r\nERROR: /home/shiki/tensorflow/tensorflow/tools/pip_package/BUILD:235:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@pasta//:LICENSE'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/shiki/tensorflow/tensorflow/tools/pip_package/BUILD:235:1 1 input file(s) do not exist\r\n```\r\n\r\nIt seems that the issue is related to dependency with respect to `pasta` which unfortunately I am not familiar with. ", "comments": ["remove this line works for me,  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/BUILD#L172", "@YellowOldOdd cool you save my time", "this should be fixed by 48d0e4d813b914fc480c51de5c48903b9bcc4cc7.\r\nI created a similar patch, git pull, and found that it was fixed.", "@YellowOldOdd @freedomtan thanks for the help. ", "closing this issue now since it has been fixed"]}, {"number": 24721, "title": "Problems with building tensorflow", "body": "Hello,\r\n\r\nI'm having problems building tensorflow from source using bazel. I am currently using the guide here: (https://medium.com/@amsokol.com/update-2-how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-61c26553f7e8)\r\n\r\nI have verified that everything is installed correctly, and keep on running into problems when it comes time to build. I have tried multiple versions of bazel, making sure to clean between builds.\r\n\r\n**System information**\r\nOS =  windows 7\r\nCPU = i7-4790k\r\nGPU = RTX2070, GTX970\r\n\r\nI have decided to stick with bazel 0.19.0 as this is the only version that actually progresses. Others seems to get hung up in one place or another.\r\n\r\nbazel info release results in: \r\nWARNING: The following rc files are no longer being read, please transfer their\r\ncontents or import their path into one of the standard rc files:\r\nc:\\users\\scorpion\\development\\tensorflow-build\\tensorflow/.bazelrc\r\nc:\\users\\scorpion\\development\\tensorflow-build\\tensorflow/tools/bazel.rc\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nrelease 0.19.0\r\n\r\n--Though I have been able to find individuals reporting similar issues, I have not been able to find a solution to the problem.\r\n\r\nWhen it comes time to build, here is the result:\r\n\r\n(tensorflow-v1.12) C:\\Users\\SCORPION\\Development\\tensorflow-build\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their\r\ncontents or import their path into one of the standard rc files:\r\nc:\\users\\scorpion\\development\\tensorflow-build\\tensorflow/.bazelrc\r\nc:\\users\\scorpion\\development\\tensorflow-build\\tensorflow/tools/bazel.rc\r\nStarting local Bazel server and connecting to it...\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\n    currently loading: tensorflow/tools/pip_package\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (2 packages loaded, 0 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (5 packages loaded, 0 targets configured)\r\nERROR: While resolving toolchains for target //tensorflow/tools/pip_package:simple_console_for_windows: invalid registered toolchain '@local_config_sh//:local_sh_toolchain': no such package '@local_config_sh//': type 'path' has no method replace(string, string)\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: invalid registered toolchain '@local_config_sh//:local_sh_toolchain': no such package '@local_config_sh//': type 'path' has no method replace(string, string)\r\nINFO: Elapsed time: 12.142s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (10 packages loaded, 29 targets configured)\r\nFAILED: Build did NOT complete successfully (10 packages loaded, 29 targets configured)\r\n\r\n\r\nAny help would be greatly appreciated\r\n\r\nEdit:\r\nAfter playing around with everything, changing bazel to 0.20.0, and reconfiguring, I am now receiving this error:\r\n\r\nC:\\tensorflow>bazel build --config=opt --cpu=x64_windows --compiler=msvc-cl --incompatible_remove_native_http_archive=false --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\nWARNING: The following rc files are no longer being read, please transfer their\r\ncontents or import their path into one of the standard rc files:\r\nc:\\tensorflow/.bazelrc\r\nc:\\tensorflow/tools/bazel.rc\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeata\r\nble flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nINFO: Invocation ID: 3fb463b2-516b-4fc8-a22f-f30ba60ff8f3\r\nLoading:\r\nLoading: 0 packages loaded\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages l\r\noaded, 0 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (2 packages l\r\noaded, 0 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (55 packages\r\nloaded, 62 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (119 packages\r\n loaded, 2958 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (190 packages\r\n loaded, 3607 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (224 packages\r\n loaded, 4739 targets configured)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (232 packages\r\n loaded, 4776 targets configured)\r\nERROR: C:/tensorflow/third_party/eigen3/BUILD:34:1: no such package '@eigen_arch\r\nive//': Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 69, in _apply_patch\r\n                _wrap_bash_cmd(ctx, [\"patch\", \"-p1\", \"-d\", ctx.pa...)])\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 28, in _wrap_bash_cmd\r\n                fail(\"BAZEL_SH environment variable i...\")\r\nBAZEL_SH environment variable is not set and referenced by '//third_party/eigen3\r\n:eigen3'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fai\r\nled; build aborted: no such package '@eigen_archive//': Traceback (most recent c\r\nall last):\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 69, in _apply_patch\r\n                _wrap_bash_cmd(ctx, [\"patch\", \"-p1\", \"-d\", ctx.pa...)])\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 28, in _wrap_bash_cmd\r\n                fail(\"BAZEL_SH environment variable i...\")\r\nBAZEL_SH environment variable is not set\r\nINFO: Elapsed time: 8.092s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (233 packages loaded, 4776 targets c\r\nonfigured)\r\nFAILED: Build did NOT complete successfully (233 packages loaded, 4776 targets c\r\nonfigured)\r\n\r\nAll of the bazel environment variables are definitely set though...\r\n\r\nEdit 2:\r\nOK! So I finally got it to build correctly (I think). It seems like I got every error that this thing could throw at me, but it was the weekend and I had time to actually work through the logs and errors.\r\n\r\nOne of the errors it kept snagging on was swig not being present in the /_bazel_scorpion/ folder even though swig was set in environment variables. I decided to copy the swig files over that I had to that folder and that seemed to fix that problem.\r\n\r\nAdding the patches, mentioned in the post at the beginning of this comment, helped bypass issues with bazel.rc\r\n\r\nI also had to change a const value in a header file to progress past another problem (I apologize, but I have totally forgotten the error thrown and the specific header file. If I find the issue again I will reference it here).\r\n\r\nAnother was it kept throwing this 'x64_windows' error. Fixed with the '--cpu=x64_windows --compiler=msvc-cl' build option.\r\n\r\nAnother issue was it kept having problems downloading resources, or at least that's what I was able to gather from the errors it was throwing. Using pip install h5py fixed this issue, and pip install enum34 fixed some other issue I can't remember right now.\r\n\r\nI don't remember exactly what this other error was, but I fixed that by having to uninstall .NET 4.7, installing .NET 4, installing whatever package I was trying to install, and then upgrading to .NET 4.7 again. I think it was an SDK referenced somewhere.\r\n\r\nAnyways, I was finally able to get it to work by entering:\r\nbazel build --cpu=x64_windows --compiler=msvc-cl --incompatible_remove_native_http_archive=false --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\nI initially tried to build from source because it kept on hanging on 'adding available GPU device' for 3-4min when I installed tensorflow-gpu using pip. (On a side note, I had to specifically enter '5.2,7.5' in 'python ./configure' to get this issue to stop happening. This seems like... a really big issue for a lot of people though. Will these issues be fixed in the future?\r\nBest of luck to everyone trying to do this and running into problems. I hope this helps some of you!", "comments": ["@scorpionsting6x3 Thanks for sharing your steps. We can expect smoother builds for cuda 10 starting from TensorFlow 2.0"]}, {"number": 24720, "title": "ExtractImagePatches request", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 \r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 1.12\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, MAXIMUM, MAX_POOL_2D, MUL, PAD. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.\r\n\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@TheSadRhino,\r\n**`Tensorflow`** has undergone many Upgrades and Advances in past 2 years. Can you please confirm if the API, [tf.image.extract_patches](https://www.tensorflow.org/api_docs/python/tf/image/extract_patches) resolves your issue? Thanks!", "Probably we could maintain this, update the label, and close the fresh duplicate at https://github.com/tensorflow/tensorflow/issues/50344", "@bhack  How can one give custom define tf.image.extract_patches op for converting model to a tflite model?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Replied on the other issue. Closing this duplicate one."]}]