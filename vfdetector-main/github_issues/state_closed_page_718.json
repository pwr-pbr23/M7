[{"number": 32036, "title": "custom layers", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 32035, "title": "TF-TRT not producing any Tensor Engine Nodes", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.  Converting custom saved model.  The model is able to run.  However, \"trt.TrtGraphConverter\" does not appear to work.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04, Docker 19.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Installed from docker (tensorflow/tensorflow:nightly-gpu-py3)\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: T4\r\n\r\n**Describe the current behavior**\r\n\r\nThis might be a documentation issue, but I'm confused as how to properly use TF-TRT with the nightly build.  Do I need to also use docker image `nvcr.io/nvidia/tensorrt:19.07-py3` or does image `tensorflow/tensorflow:nightly-gpu-py3` contain the necessary TensorRT binaries?  \r\n\r\nWhen I used the image 'tensorflow/tensorflow:latest-gpu-py3', I received errors of an unknown TensorRT version (0,0,0).  I no longer see this error with the nightly version.\r\n\r\nI have verified nvidia-docker is installed and working.  Am I missing a step, or is there an issue with TensorRT in the docker image?\r\n\r\nMy conversion code is:\r\n\r\n```\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nconverter = trt.TrtGraphConverter(\r\n\t\tinput_saved_model_dir = str(saved_model_dir),\r\n\t\tmax_batch_size = batch_size,\r\n\t\tprecision_mode = precision )\r\n\tconverter.convert()\r\n\tconverter.save(output_saved_model_dir = str(output_saved_model_dir))\r\n```\r\n\r\nAm I linking to the correct trt import?  Thanks in advance.\r\n", "comments": ["I repulled the nightly version, and was able to get some output from TensorRT.  The night version also linked up to TensorRT 5.1.5 correctly.\r\n\r\nThe image that worked was:\r\n`tensorflow/tensorflow   nightly-gpu-py3     30d5e94bc707`\r\n\r\nSo, to answer my own question, the image `nvcr.io/nvidia/tensorrt:19.07-py3` is not needed when running the night image.\r\n\r\nThanks again!\r\n\r\n"]}, {"number": 32034, "title": "Customize Keras Tensorboard callback", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): install by pip in anaconda environment\r\n- TensorFlow version (use command below):  tensorflow-gpu==2.0.0-rc0; Tensorboard 1.14\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version:  cudatoolkit( 10.0.130); cudnn( 7.6.0)     \r\n- GPU model and memory: GeForce GTX 1080 - 8117MiB \r\n\r\n\r\n**Describe the current behavior**\r\nIn Tensorflow 1.13.1, I create my tensorboard callback to add image while training by customizing the `keras.callbacks.TensorBoard.`\r\n\r\n**Ex**: from this :https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L1114-L1122\r\nI add the code:\r\n```\r\n                if hasattr(layer, 'output'):\r\n                    if isinstance(layer.output, list):\r\n                        for i, output in enumerate(layer.output):\r\n                            tf.summary.histogram('{}_out_{}'.format(layer.name, i),\r\n                                                 output)\r\n                    else:\r\n                        tf.summary.histogram('{}_out'.format(layer.name),\r\n                                             layer.output)\r\n\r\n                # My code\r\n                input1 = self.model.get_layer('input1').input\r\n                tf.summary.image('input1', input1 , max_outputs=MAX_OUT)\r\n                # End my code\r\n\r\n        self.merged = tf.summary.merge_all()\r\n```\r\nThen I can see the image while training.\r\n\r\n**But now in** https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py#L1491. \r\nI can't find `if self.histogram_freq and self.merged is None:`  or \r\n`self.merged = tf.summary.merge_all()` in the `def set_model(self, model):`\r\n\r\n**Describe the expected behavior**\r\nWhere I can add the \r\n```\r\ninput1 = self.model.get_layer('input1').input\r\ntf.summary.image('input1', input1 , max_outputs=MAX_OUT)\r\n```\r\nto see the image while training ?\r\n\r\n", "comments": ["@shaolinkhoa Modifying the Callbacks in this way is not supported, but you can add tf.summaries inside of Layers and Models in the nightly preview of 2.0 like this:\r\n\r\n```\r\nclass MyLayer(keras.layers.Layer):\r\n  ...\r\n  def call(self, inputs):\r\n    tf.summary.image(inputs)\r\n    return 2*inputs\r\n\r\nmodel = Model(...)\r\ntb = keras.callbacks.TensorBoard(log_dir, update_freq=1)\r\nmodel.fit(x, y, callbacks=[tb])\r\n```\r\n\r\nThat should be able to support your use case\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32034\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32034\">No</a>\n", "@omalleyt12 Thank you for replying.\r\nSo it really inconveniences in tf.keras and tf2 now. \r\nIt means I have to modify all the `def call(self, inputs):` of my layer in the model, even the existed core layers ( Dense, Conv2D,...), to add the ` tf.summary.image(inputs)` instead of modifying only my custom keras tensorboard callback as I did in tf 1.13.1. \r\nAnd it only works on TF2-nightly preview ? not the TF2-rc ?", "> @shaolinkhoa Modifying the Callbacks in this way is not supported, but you can add tf.summaries inside of Layers and Models in the nightly preview of 2.0 like this:\r\n> \r\n> ```\r\n> class MyLayer(keras.layers.Layer):\r\n>   ...\r\n>   def call(self, inputs):\r\n>     tf.summary.image(inputs)\r\n>     return 2*inputs\r\n> \r\n> model = Model(...)\r\n> tb = keras.callbacks.TensorBoard(log_dir, update_freq=1)\r\n> model.fit(x, y, callbacks=[tb])\r\n> ```\r\n> \r\n> That should be able to support your use case\r\n\r\n@omalleyt12 Is this working anymore? I summary an image in this way but cannot find it in Tensorboard."]}, {"number": 32033, "title": "TFLite conversion change model weights", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution : Windows Server 2016\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.14\r\n- Python version:3.5\r\n\r\n**Describe the current behavior**\r\nI convert .pb file to .tflite file .Then I found the model weights changed in .tflite file.\r\nMy CNN model just some separable convolution layers.In fact, I just replaced the ordinary convolution layer of VGG16 with the separable convolution layer. \r\nAll the pointwise convolution  weights change in .tflite file ,while all the depthwise convolution weights remain the same in two files.\r\nAs you can see below as an example.\r\n\r\n### **pointwise convolution weights in .pb:**\r\n![1566965436(1)](https://user-images.githubusercontent.com/4417111/63825376-2cc21780-c98d-11e9-8802-27b67e615c19.png)\r\n\r\n### **pointwise convolution weights in .tflite**\r\n![1566965467(1)](https://user-images.githubusercontent.com/4417111/63825409-46fbf580-c98d-11e9-9efa-993f1833237c.png)\r\n\r\n**Code to reproduce the issue**\r\n### **I used this code below to freeze model weights and saved as .pb file.**\r\n![1566965770(1)](https://user-images.githubusercontent.com/4417111/63825655-2ed8a600-c98e-11e9-8e01-62420e930fac.png)\r\n\r\n### **I used this code below to convert .pb file to .tflite file.**\r\n![1566965842(1)](https://user-images.githubusercontent.com/4417111/63825687-49128400-c98e-11e9-8853-c7b376b11c92.png)\r\n\r\n### **I used this code below to print weights in .pb file and .tflite file.**\r\n![1566965966(1)](https://user-images.githubusercontent.com/4417111/63825722-69dad980-c98e-11e9-8847-fae9f5e50884.png)\r\n\r\n\r\nI don't konw why this problem occur.\r\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/31359", "We do optimizations like folding batchnorm constants into the conv filter when converting tf models to tflite. It's expected to change the values of the tensor. Please compare whether the two models generate different output. If not it's a real bug. Feel free to reopen if you find that's the case. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32033\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32033\">No</a>\n"]}, {"number": 32032, "title": "Is there a way to use keras flow_from_directory with distributed training (mirrored strategy)?", "body": "I cannot find any documentation or example code on how to do dynamic file loading with distribute strategies in tensorflow 2.0 when doing distributed training. \r\n\r\nI see many examples using keras flow_from_directory which seems to be very nice because it relies on generator and does scaling etc on the fly so doesn't require loading hundreds of thousands of images at once. But the distribute strategy examples (mirrored strategy etc) all show pre-loading the entire dataset and then using dataset.from_tensor_slices() and loading that to strategy.experimental_distribute_dataset(). This is not feasable with large data that exceeds the memory. I've tried to combine the above dynamic loading method from keras with distributed batching but it looks like there is no trivial way to convert some flow_from_directory output to be compatible with what strategy.experimental_distribute_dataset() expects so these two features are probably not compatible with one another.\r\n\r\nIs there some other way to do this with distributed training?\r\n\r\nI could probably hand-code dynamic file loading during training but it would be pretty slow and basic compared to what generators and flow offer. I would be very surprised if TF2 didn't include this functionality for distributed training yet.\r\n\r\nHowever, in lack of examples or documentation, assuming this is not yet implemented, I am posting it as feature request. Hopefully I'm wrong and there is a way to do it. Then I would recommend to add that to the distribute strategies documentation as example code.\r\n", "comments": ["\r\nWhile I'd still be very glad if the very convenient and concise flow_from_directory() with generators could work with TF2 distribute strategies (because in the rest of my project I use TF2 tf.compat.v2 for distributed training), I've been looking for alternatives:\r\n\r\nAn alternative way of dynamically load and preprocess large datasets is described here:\r\nIn lack of full examples, I tried to follow the tutorial here:\r\nhttps://www.tensorflow.org/tutorials/load_data/images\r\nhttps://www.tensorflow.org/guide/performance/datasets\r\n\r\nThe output being the same Dataset format what strategy.experimental_distribute_dataset() method takes as input, it should work. However, the tutorial and documentations are all written for tf.compat.v1 (which is deprecated I think) not tf.compat.v2.\r\n\r\nThere are commands that don't work any more in tf.compat.v2 (eg. there is no output_shape and output_type attribute for Dataset v2). \r\n\r\nWhile I can make it run with a few small changes, is it safe to run that code in tf.compat.v2 in TF2?\r\nOr is there some updated examples somewhere?\r\n\r\n", "I think tf.data should serve your needs. I am not sure about the version problem. @jsimsa probably could comment.", "To load data dynamically using tf.data, you can use [tf.data.Dataset.from_generator](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#from_generator). This should work seamlessly with single worker distribution strategies. For multi-worker distribution strategies, you will need to use [experimental_dataset_from_function](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/distribute/Strategy#experimental_distribute_datasets_from_function) as automatically sharding the generator dataset across workers is not supported.", "Thank you for the answers! I needed solution for multi-GPU distribution strategy but I'm not sure if the multi-GPUs offered by Gcloud or Azure, that I've been using, are multi-worker systems or not, I think they are just multiple GPUs and multiple CPUs on a single VM.\r\nSince then I've rewritten my code in tf.keras functional API and then got this working very nicely with the alternative method of \r\ntrain_dataset = tf.data.Dataset.from_tensor_slices(((train_images, dummydata),train_images)).shuffle(TRAIN_BUF).repeat().batch(BATCH_SIZE)\r\nand then this directly goes to fit(). This works nicely with distribute strategy. ", "Note that \"worker\" means machine. Multiple GPUs on a single machine are a single worker distribution strategy (e.g. MirroredStrategy). In any case, great to hear that you were able to use tf.data (and in an idiomatic way too) to solve your problem!", "@kristofgiber Can you please close the issue if this issue was resolved already? Thanks!", "Any chance you can provide a little more detail around your solution\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices(((train_images, dummydata),train_images)).shuffle(TRAIN_BUF).repeat().batch(BATCH_SIZE)\r\n\r\ne.g. How have you set up/loaded train_images?\r\n\r\nThanks", "@kristofgiber, could you please provide details of your solution. How you set up train_images? I'm using\r\ntf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_dataframe() \r\nfor CPU and single GPU training but when transferring to multi-GPU training with tf.distribute.MirroredStrategy(), I could not find any documentation on how to distribute dataset among GPUs with flow_from_dataframe(). Any help would be appreciated, Thanks!"]}, {"number": 32031, "title": "when I quantized mobilenetv3 got an error", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\ngot error log:\r\n2019-08-28 02:01:30.680587: F tensorflow/lite/toco/graph_transformations/quantize.cc:491] Unimplemented: this graph contains an operator of type Div for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\ntflite_convert  --graph_def_file ./mobilenetstpu/v3small.pb   --inference_type QUANTIZED_UINT8  --input_arrays truediv --input_shapes 1,224,224,3  --output_arrays softmax_tensor  --std_dev_values 1  --mean_values 0  --default_ranges_min 0 --default_ranges_max 6 --output_file mobilenetv3.tflite \r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Suharsh could you PTAL?\r\n", "thx"]}, {"number": 32030, "title": "include comment for kInferencesPerCycle for a Teensy4.0", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32030) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32030) for more info**.\n\n<!-- ok -->", "cc @dansitu ", "@matpalm Could you please check reviewer comments and keep us posted. Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 32029, "title": "tensorflow.keras.Model.compute_output_shape gives wrong results", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nlinux Ubuntu 18.04\r\n\r\n- TensorFlow installed from (source or binary):\r\nconda\r\n- TensorFlow version (use command below):\r\ntried with 1.12.0 and 1.14.0\r\n- Python version:\r\n3.6\r\n\r\n**Describe the current behavior**\r\n\r\nusing a keras model (stored in a variable mm) in tensorflow.keras I would like to calculate the output_shape for a given input. This works correctly only the first time I call `mm.compute_output_shape()`, the subsequent results for calling the same function with different shapes are inconsistent.\r\n\r\nUsing standard keras methods I get different and consistent results. \r\nAn example for the problem is implemented in the tf_bug.py script that you find in the zip\r\nif you call it without parameters it loads a fully convolutional model \r\nfrom a json file (provided in the zip) and does \r\n\r\n```\r\nimport json\r\nimport tensorflow.keras as keras\r\nwith open(\"model_tf_bug.json\", \"r\") as fi:  \r\n    kk=json.load(fi)  \r\n    mm=keras.models.model_from_json(json.dumps(kk)) \r\n\r\nfor n in range(999, 1020):  \r\n     ss=[(1,n,1,1)]\r\n     print(ss,mm.compute_output_shape(input_shape=ss)) \r\n```\r\nthe result displaying the input and corresponding output shape on each line is\r\n```\r\n[(1, 999, 1, 1)] (1, 481, 1, 1)\r\n[(1, 1000, 1, 1)] (1, 481, 1, 1)\r\n[(1, 1001, 1, 1)] (1, 482, 1, 1)\r\n[(1, 1002, 1, 1)] (1, 482, 1, 1)\r\n[(1, 1003, 1, 1)] (1, 483, 1, 1)\r\n[(1, 1004, 1, 1)] (1, 483, 1, 1)\r\n[(1, 1005, 1, 1)] (1, 484, 1, 1)\r\n[(1, 1006, 1, 1)] (1, 484, 1, 1)\r\n[(1, 1007, 1, 1)] (1, 482, 1, 1)\r\n[(1, 1008, 1, 1)] (1, 485, 1, 1)\r\n...\r\n```\r\nI kept only the relevant lines. You see that after the first lines that are correct \r\nstarting with input shape 1007 the output shape decreases and starts to produce erratic behavior, while for the fully convolutional model it should increase monotonously with the input size.\r\n\r\n**Describe the expected behavior**\r\n\r\nRunning the same script with argument keras uses the vanilla keras version 2.2.4\r\nand in this case the output shape increases  as expected\r\n```\r\n[(1, 999, 1, 1)] (1, 481, 1, 1)\r\n[(1, 1000, 1, 1)] (1, 481, 1, 1)\r\n[(1, 1001, 1, 1)] (1, 482, 1, 1)\r\n[(1, 1002, 1, 1)] (1, 482, 1, 1)\r\n[(1, 1003, 1, 1)] (1, 483, 1, 1)\r\n[(1, 1004, 1, 1)] (1, 483, 1, 1)\r\n[(1, 1005, 1, 1)] (1, 484, 1, 1)\r\n[(1, 1006, 1, 1)] (1, 484, 1, 1)\r\n[(1, 1007, 1, 1)] (1, 485, 1, 1)\r\n[(1, 1008, 1, 1)] (1, 485, 1, 1)\r\n...\r\n```\r\n\r\nNote that I can get a correct result with tf.keras as well if I clear the model._output_shape_cache before I compute the output_shape.\r\nRunning the script with argument clear uses a modified loop as follows\r\n```\r\nfor n in range(999, 1020):  \r\n     ss=[(1,n,1,1)]\r\n     if len(sys.argv) > 1 and sys.argv[1] == \"clear\":\r\n         mm._output_shape_cache.clear()\r\n     print(ss,mm.compute_output_shape(input_shape=ss)) \r\n```\r\nThe results are correct as expected. \r\n\r\nLooking into the function `mm.compute_output_shape`\r\n I found that compared to keras you changed the cache_key generation\r\n\r\nwhere keras does\r\n```   \r\ncache_key = ', '.join([str(x) for x in input_shapes])\r\n```\r\ntf.keras does\r\n```\r\n    cache_key = generic_utils.object_list_uid(input_shape)\r\n```\r\nIt appears that the cache_key in tf.keras confuses different input shapes as the same and returns wrong results from the cache.\r\n\r\n**Code to reproduce the issue**\r\n\r\nYou find the script, model and output files in the zip\r\n\r\n[tf_compute_output_shape_bug.zip](https://github.com/tensorflow/tensorflow/files/3548512/tf_compute_output_shape_bug.zip)\r\n", "comments": ["Was able to reproduce the issue. Please find the attachment of github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/b4519fb3fb254cd7daaecc7095070456/untitled127.ipynb). Thanks!", "@gowthamkpr Did you find the solution for this?\r\nI have similar problem: https://github.com/tensorflow/tensorflow/issues/33785", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32029\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32029\">No</a>\n"]}, {"number": 32028, "title": "Can't import tensorflow.config.slim in TensorFlow 1.15 nightly build ", "body": "## System Information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux  Ubuntu 18.04 LTS \r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.12.1-7396-g12481e7e74 1.15.0-dev20190730\r\n- **Python version**: Python 3.6.8\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: Don't need it in this case, but cuda_10.1.243_418.87.00\r\n- **GPU model and memory**: Don't need it in this case, but GeForce GTX 960 with 2 GB/\r\n- **Exact command to reproduce**: `python -c \"import tensorflow.contrib.slim\"`\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nI am trying to quantize a model for use on Coral USB Accelerator.  According to https://coral.withgoogle.com/docs/edgetpu/models-intro/, \"you must use the TensorFlow 1.15 \"nightly\" build and set both the input and output type to uint8\".  The model I am working with uses tensorflow.contrib.slim.  If I try to import tensorflow.contrib.slim with 1.15 installed, I get the following traceback:\r\n\r\n### Source code / logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_core/contrib/__init__.py\", line 39, in <module>\r\n    from tensorflow.contrib import compiler\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_core/contrib/compiler/__init__.py\", line 21, in <module>\r\n    from tensorflow.contrib.compiler import jit\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_core/contrib/compiler/__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.compiler import xla\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_core/contrib/compiler/xla.py\", line 22, in <module>\r\n    from tensorflow.python.estimator import model_fn as model_fn_lib\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_core/python/estimator/model_fn.py\", line 26, in <module>\r\n    from tensorflow_estimator.python.estimator import model_fn\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/jbrownkramer/Desktop/YOLOV3 on Coral USB/yoloOnCoralEnv/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features'\r\n```\r\n\r\n", "comments": ["I was able to successfully import slim module using TF Nightly build version '1.15.0-dev20190821' using Google Colab.\r\n```python\r\nimport tensorflow.contrib.slim as slim\r\n#prints\r\nW0828 00:43:23.448170 140025563473792 lazy_loader.py:50] \r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n```\r\nPerhaps you can try using TF in virtual environment .", "@jbrownkramer ,\r\nCan you please try In using `TF Nightly build version '1.15.0-dev20190821'  ` as instructed by @ymodak .Worked for me aswell. Thanks!", "Thanks, it worked!  Full (embarrassing) disclosure: I had not upgraded pip recently, so the nightly build versions available to me did not initially include 1.15.0-dev20190821.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32028\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32028\">No</a>\n"]}, {"number": 32027, "title": "Update version numbers for TensorFlow 1.15.0-rc0", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 1 -> 1\nMinor: 14 -> 15\nPatch: 0 -> 0\n\nWARNING: Below are potentially instances of lingering old version string \n\"1.14.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/java/maven/libtensorflow_jni/pom.xml:9:1.14.0\ntensorflow/java/maven/proto/pom.xml:9:1.14.0\ntensorflow/java/maven/libtensorflow_jni_gpu/pom.xml:9:1.14.0\ntensorflow/java/maven/libtensorflow/pom.xml:9:1.14.0\ntensorflow/java/maven/pom.xml:9:1.14.0\ntensorflow/java/maven/tensorflow-hadoop/pom.xml:8:1.14.0\ntensorflow/java/maven/tensorflow/pom.xml:9:1.14.0\ntensorflow/java/maven/spark-tensorflow-connector/pom.xml:9:1.14.0\ntensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java:177:1.14.0\ntensorflow/python/tpu/profiler/capture_tpu_profile.py:146:1.14.0\ntensorflow/python/tpu/profiler/capture_tpu_profile.py:147:1.14.0\ntensorflow/tools/pip_package/setup.py:65:1.14.0\ntensorflow/tools/pip_package/setup.py:66:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:37:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:39:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:40:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:43:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:45:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:46:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:48:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:50:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:53:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:56:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:62:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:63:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:64:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:67:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:69:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:71:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:73:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:77:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:78:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:79:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:80:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:81:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:83:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:86:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:89:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:92:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:94:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:96:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:100:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:102:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:103:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:104:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:106:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:110:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:112:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:115:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:116:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:118:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:120:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:123:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:124:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:127:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:129:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:131:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:133:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:136:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:140:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:142:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:143:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:144:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:145:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:146:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:151:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:152:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:153:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:154:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:157:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:158:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:159:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:161:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:163:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:164:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:165:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:166:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:167:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:168:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:169:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:170:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:171:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:172:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:173:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:174:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:175:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:176:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:177:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:178:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:179:1.14.0\ntensorflow/lite/g3doc/guide/python.md:38:1.14.0\ntensorflow/lite/g3doc/guide/python.md:44:1.14.0\ntensorflow/lite/g3doc/guide/python.md:45:1.14.0\ntensorflow/lite/g3doc/guide/python.md:46:1.14.0\ntensorflow/lite/g3doc/guide/python.md:47:1.14.0\ntensorflow/lite/g3doc/guide/python.md:48:1.14.0\ntensorflow/lite/g3doc/guide/python.md:49:1.14.0\ntensorflow/lite/g3doc/guide/python.md:54:1.14.0\ntensorflow/lite/g3doc/guide/python.md:55:1.14.0\ntensorflow/lite/g3doc/guide/python.md:58:1.14.0\ntensorflow/lite/g3doc/guide/python.md:59:1.14.0\ntensorflow/lite/g3doc/guide/python.md:60:1.14.0\ntensorflow/lite/g3doc/guide/python.md:61:1.14.0\ntensorflow/lite/g3doc/guide/python.md:62:1.14.0\ntensorflow/lite/g3doc/guide/python.md:63:1.14.0\ntensorflow/lite/experimental/objc/TensorFlowLiteObjC.podspec:3:1.14.0\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:22:1.14.0\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:23:1.14.0\ntensorflow/lite/experimental/swift/TensorFlowLiteSwift.podspec:3:1.14.0\ntensorflow/lite/experimental/ios/TensorFlowLiteC.podspec:3:1.14.0\ntensorflow/lite/experimental/micro/examples/micro_speech/train_speech_model.ipyn\nb:126:1.14.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"1.14.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/java/maven/libtensorflow_jni/pom.xml:9:1.14.0\ntensorflow/java/maven/proto/pom.xml:9:1.14.0\ntensorflow/java/maven/libtensorflow_jni_gpu/pom.xml:9:1.14.0\ntensorflow/java/maven/libtensorflow/pom.xml:9:1.14.0\ntensorflow/java/maven/pom.xml:9:1.14.0\ntensorflow/java/maven/tensorflow-hadoop/pom.xml:8:1.14.0\ntensorflow/java/maven/tensorflow/pom.xml:9:1.14.0\ntensorflow/java/maven/spark-tensorflow-connector/pom.xml:9:1.14.0\ntensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java:177:1.14.0\ntensorflow/python/tpu/profiler/capture_tpu_profile.py:146:1.14.0\ntensorflow/python/tpu/profiler/capture_tpu_profile.py:147:1.14.0\ntensorflow/tools/pip_package/setup.py:65:1.14.0\ntensorflow/tools/pip_package/setup.py:66:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:37:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:39:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:40:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:43:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:45:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:46:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:48:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:50:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:53:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:56:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:62:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:63:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:64:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:67:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:69:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:71:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:73:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:77:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:78:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:79:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:80:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:81:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:83:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:86:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:89:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:92:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:94:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:96:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:100:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:102:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:103:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:104:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:106:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:110:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:112:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:115:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:116:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:118:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:120:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:123:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:124:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:127:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:129:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:131:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:133:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:136:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:140:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:142:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:143:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:144:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:145:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:146:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:151:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:152:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:153:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:154:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:157:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:158:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:159:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:161:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:163:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:164:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:165:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:166:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:167:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:168:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:169:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:170:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:171:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:172:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:173:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:174:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:175:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:176:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:177:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:178:1.14.0\ntensorflow/lite/toco/tflite/op_version.cc:179:1.14.0\ntensorflow/lite/g3doc/guide/python.md:38:1.14.0\ntensorflow/lite/g3doc/guide/python.md:44:1.14.0\ntensorflow/lite/g3doc/guide/python.md:45:1.14.0\ntensorflow/lite/g3doc/guide/python.md:46:1.14.0\ntensorflow/lite/g3doc/guide/python.md:47:1.14.0\ntensorflow/lite/g3doc/guide/python.md:48:1.14.0\ntensorflow/lite/g3doc/guide/python.md:49:1.14.0\ntensorflow/lite/g3doc/guide/python.md:54:1.14.0\ntensorflow/lite/g3doc/guide/python.md:55:1.14.0\ntensorflow/lite/g3doc/guide/python.md:58:1.14.0\ntensorflow/lite/g3doc/guide/python.md:59:1.14.0\ntensorflow/lite/g3doc/guide/python.md:60:1.14.0\ntensorflow/lite/g3doc/guide/python.md:61:1.14.0\ntensorflow/lite/g3doc/guide/python.md:62:1.14.0\ntensorflow/lite/g3doc/guide/python.md:63:1.14.0\ntensorflow/lite/experimental/objc/TensorFlowLiteObjC.podspec:3:1.14.0\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:22:1.14.0\ntensorflow/lite/experimental/objc/tests/TFLInterpreterTests.m:23:1.14.0\ntensorflow/lite/experimental/swift/TensorFlowLiteSwift.podspec:3:1.14.0\ntensorflow/lite/experimental/ios/TensorFlowLiteC.podspec:3:1.14.0\ntensorflow/lite/experimental/micro/examples/micro_speech/train_speech_model.ipyn\nb:126:1.14.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"r1.14\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/g3doc/performance/post_training_quant.ipynb:109:r1.14\n```", "comments": []}, {"number": 32026, "title": "Tensorflow r2.0 will not build successfully on skylake machines", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): not installed (attempting to build from source)\r\n- TensorFlow version: attempting to build from branch r2.0\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: Anaconda conda virtual environment \r\n- Bazel version (if compiling from source): 0.26.0\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: CUDA 10, cuDNN 7.6.2\r\n- GPU model and memory: NVidia RTX 2080 Ti (MSI Sea Hawk X, 11 GB)\r\n\r\n**Describe the problem**\r\nbazel build is unsuccessful yielding error in tensorflow/lite/experimental/ruy/kernel_avx512.cc\r\nPlease see [Issue 31187](https://github.com/tensorflow/tensorflow/issues/31187) for background leading to the same bug being resolved on the master branch.  I don't know how they fixed it on master.  The fix needs to be ported from master to r2.0 branch.\r\n\r\nPlease also note that you can bypass using AVX-512 and get a successful build by changing:\r\n~/tensorflow/tensorflow/lite/experimental/ruy/platform.h\r\nComment out:\r\n// TODO(b/138433137) Select AVX-512 at runtime rather than via compile options.\r\n// #if defined(__AVX512F__) && defined(__AVX512DQ__) && defined(__AVX512CD__) && \\\r\n    defined(__AVX512BW__) && defined(__AVX512VL__)\r\n// #define RUY_DONOTUSEDIRECTLY_AVX512 1\r\n// #else\r\n#define RUY_DONOTUSEDIRECTLY_AVX512 0\r\n// #endif\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout r2.0\r\n./configure\r\nAccept defaults initially\r\nWhen asked for CUDA support, type \"y\"\r\nWhen asked for TensorRT support, type \"y\"\r\nWhen asked for compute capabilities, type 7.0,7.5\r\nAccept defaults thereafter\r\nbazel build --explain=verbose_explanations.txt --verbose_explanations --verbose_failures --subcommands=pretty_print --config=opt --config=cuda --config=v2 --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nThis error does not occur on machines that do not have Skylake support for AVX-512 (I know because I can build it fine on my laptop and other users report this bug is particular to Skylake).\r\n\r\nI have attached a dump of the terminal output of the bazel build command (cleaned-capture.txt) and verbose_explanations.txt:\r\n\r\n[cleaned-capture.txt](https://github.com/tensorflow/tensorflow/files/3548002/cleaned-capture.txt)\r\n[verbose_explanations.txt](https://github.com/tensorflow/tensorflow/files/3548006/verbose_explanations.txt)\r\n\r\nFull error message:\r\nERROR: /home/daniel/tensorflow/tensorflow/lite/experimental/ruy/BUILD:271:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:kernel' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/daniel/.cache/bazel/_bazel_daniel/79db702fc9f94af7d11e11c5d64854d0/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/extras/CUPTI/lib64 \\\r\n    PATH=/home/daniel/anaconda3/envs/tfgpu/bin:/home/daniel/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/lite/experimental/ruy/_objs/kernel/kernel_avx512.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/lite/experimental/ruy/_objs/kernel/kernel_avx512.pic.o' -iquote . -iquote bazel-out/host/bin -iquote external/gemmlowp -iquote bazel-out/host/bin/external/gemmlowp '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -c tensorflow/lite/experimental/ruy/kernel_avx512.cc -o bazel-out/host/bin/tensorflow/lite/experimental/ruy/_objs/kernel/kernel_avx512.pic.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nIn file included from tensorflow/lite/experimental/ruy/kernel_avx512.cc:18:0:\r\n./tensorflow/lite/experimental/ruy/kernel.h:613:9: warning: multi-line comment [-Wcomment]\r\n #endif  // (RUY_PLATFORM(NEON_64) || RUY_PLATFORM(NEON_32) || \\\r\n         ^\r\nIn file included from external/gemmlowp/fixedpoint/fixedpoint.h:895:0,\r\n                 from ./tensorflow/lite/experimental/ruy/kernel.h:22,\r\n                 from tensorflow/lite/experimental/ruy/kernel_avx512.cc:18:\r\nexternal/gemmlowp/fixedpoint/./fixedpoint_sse.h:43:39: warning: ignoring attributes on template argument \u2018__m128i {aka __vector(2) long long int}\u2019 [-Wignored-attributes]\r\n struct FixedPointRawTypeTraits<__m128i> {\r\n                                       ^\r\nIn file included from tensorflow/lite/experimental/ruy/kernel_avx512.cc:18:0:\r\n./tensorflow/lite/experimental/ruy/kernel.h: In function \u2018void ruy::MakeKernelParamsFloat(const ruy::PackedMatrix<float>&, const ruy::PackedMatrix<float>&, const ruy::BasicSpec<float, float>&, int, int, int, int, ruy::Matrix<float>*, ruy::KernelParamsFloat<LhsCols, RhsCols>*)\u2019:\r\n./tensorflow/lite/experimental/ruy/kernel.h:456:53: warning: typedef \u2018using Params = struct ruy::KernelParamsFloat<LhsCols, RhsCols>\u2019 locally defined but not used [-Wunused-local-typedefs]\r\n   using Params = KernelParamsFloat<LhsCols, RhsCols>;\r\n                                                     ^\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc: In function \u2018void ruy::Kernel8bitAvx512(const ruy::KernelParams8bit<16, 16>&)\u2019:\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:111:34: error: \u2018_mm512_loadu_epi8\u2019 was not declared in this scope\r\n         const __m512i lhs_data = _mm512_loadu_epi8(lhs_ptr);\r\n                                  ^~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:111:34: note: suggested alternative: \u2018_mm512_add_epi8\u2019\r\n         const __m512i lhs_data = _mm512_loadu_epi8(lhs_ptr);\r\n                                  ^~~~~~~~~~~~~~~~~\r\n                                  _mm512_add_epi8\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:161:32: error: \u2018_mm512_loadu_epi32\u2019 was not declared in this scope\r\n                                _mm512_loadu_epi32(&params.lhs_sums[row]));\r\n                                ^~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:161:32: note: suggested alternative: \u2018_mm512_load_epi32\u2019\r\n                                _mm512_loadu_epi32(&params.lhs_sums[row]));\r\n                                ^~~~~~~~~~~~~~~~~~\r\n                                _mm512_load_epi32\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:170:32: error: \u2018_mm512_loadu_epi32\u2019 was not declared in this scope\r\n                                _mm512_loadu_epi32(&params.rhs_sums[col]));\r\n                                ^~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:170:32: note: suggested alternative: \u2018_mm512_load_epi32\u2019\r\n                                _mm512_loadu_epi32(&params.rhs_sums[col]));\r\n                                ^~~~~~~~~~~~~~~~~~\r\n                                _mm512_load_epi32\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:277:13: error: \u2018_mm_storeu_epi8\u2019 was not declared in this scope\r\n             _mm_storeu_epi8(tmp_ptr, _mm512_cvtepi32_epi8(accum_data_v[j]));\r\n             ^~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:277:13: note: suggested alternative: \u2018_mm_store_epi64\u2019\r\n             _mm_storeu_epi8(tmp_ptr, _mm512_cvtepi32_epi8(accum_data_v[j]));\r\n             ^~~~~~~~~~~~~~~\r\n             _mm_store_epi64\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:293:13: error: \u2018_mm_storeu_epi8\u2019 was not declared in this scope\r\n             _mm_storeu_epi8(tmp_ptr, _mm512_cvtepi32_epi8(accum_data_v[j]));\r\n             ^~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:293:13: note: suggested alternative: \u2018_mm_store_epi64\u2019\r\n             _mm_storeu_epi8(tmp_ptr, _mm512_cvtepi32_epi8(accum_data_v[j]));\r\n             ^~~~~~~~~~~~~~~\r\n             _mm_store_epi64\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:309:13: error: \u2018_mm256_storeu_epi16\u2019 was not declared in this scope\r\n             _mm256_storeu_epi16(tmp_ptr,\r\n             ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:309:13: note: suggested alternative: \u2018_mm256_store_epi64\u2019\r\n             _mm256_storeu_epi16(tmp_ptr,\r\n             ^~~~~~~~~~~~~~~~~~~\r\n             _mm256_store_epi64\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:326:13: error: \u2018_mm512_storeu_epi32\u2019 was not declared in this scope\r\n             _mm512_storeu_epi32(tmp_ptr, accum_data_v[j]);\r\n             ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/experimental/ruy/kernel_avx512.cc:326:13: note: suggested alternative: \u2018_mm512_store_epi32\u2019\r\n             _mm512_storeu_epi32(tmp_ptr, accum_data_v[j]);\r\n             ^~~~~~~~~~~~~~~~~~~\r\n             _mm512_store_epi32\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 35.925s, Critical Path: 10.04s\r\nINFO: 282 processes: 282 local.\r\nFAILED: Build did NOT complete successfully", "comments": ["This should now be fixed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32026\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32026\">No</a>\n"]}, {"number": 32025, "title": "I need more accuracy", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n 1.13 and 2.0\r\n- Are you willing to contribute it (Yes/No): \r\nYes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nTensorflow has been used to compute images but I want to use Tensorflow to compute Biological Models. However, the biological model requires big division and this causes numerical instability. I want to have tensorflow that supports more numerically stablility.  \r\n**Will this change the current api? How?**\r\nI don't know\r\n**Who will benefit with this feature?**\r\nA biologist who wants to use tensorflow as a means to compute gene expression models with high degree of accuracy.\r\n**Any Other info.**\r\nThis is based on my recent work in \r\nhttps://www.biorxiv.org/content/10.1101/655639v1", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32025\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32025\">No</a>\n", "I think this is a performance issue (Higher precision support needed). Please help because I do not know how to solve this problem."]}, {"number": 32024, "title": "TPU nightly", "body": "I'm training a custom resnet on a single TPU device using tf.keras, and saving the model using ModelCheckpoint callback on the VM. The time takes to save the model during training is very much. The model is about 200mb and it takes ~1 hour to save it to the VM", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "I created VM and TPU v3-8 using ctpu up command, with TF version 1.15.0-dev20190730 on Debian 9.\r\n\r\n```\r\ndef create_model()\r\n.\r\n.\r\n.\r\n.\r\n.\r\ncompile.model(Adam, custom_loss)\r\nreturn model\r\n\r\n\r\nwith tpu_strategy.scope():\r\n    model=create_model()\r\n    ######## Tensorboard ############\r\n    logdir='gs://dataset_us/logs/'+name\r\n    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, write_graph=True)\r\n    ######## Model Save #############\r\n    filepath = './models'+name+'.hdf5'\r\n    checkpoint = keras.callbacks.ModelCheckpoint((filepath), monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True)\r\n    #################################\r\n    clbk=[tensorboard_callback, checkpoint]\r\n    ###############fit#############\r\n    model.fit(get_training_dataset(), validation_data=get_validation_dataset(), steps_per_epoch=steps_per_epoch ,validation_steps=val_steps, epochs=EPOCHS, verbose=1, initial_epoch=0, callbacks=clbk)\r\n    ```\r\n\r\neverytime during training there is a best weight, the saving precedure in the host VM takes about 1 hour. ", "Can you try by keeping the model function inside the scope definition and rest outside of it? SO, like this-\r\n\r\n````\r\nwith tpu_strategy.scope():\r\n    model=create_model()\r\n\r\n####### Tensorboard ############\r\nlogdir='gs://dataset_us/logs/'+name\r\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, write_graph=True)\r\n######## Model Save #############\r\nfilepath = './models'+name+'.hdf5'\r\ncheckpoint = keras.callbacks.ModelCheckpoint((filepath), monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True)\r\n#################################\r\nclbk=[tensorboard_callback, checkpoint]\r\n###############fit#############\r\nmodel.fit(get_training_dataset(), validation_data=get_validation_dataset(), steps_per_epoch=steps_per_epoch ,validation_steps=val_steps, epochs=EPOCHS, verbose=1, initial_epoch=0, callbacks=clbk)\r\n\r\n````\r\n", "I've tried it. The same outcome", "@nsantavas Can you share a simple and standalone code to reproduce the issue? Thanks!", "@jvishnuvardhan \r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow import keras\r\nimport random \r\n\r\n\r\ntpu='tfn'\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu)\r\ntf.config.experimental_connect_to_host(resolver.master())\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\ntpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n\r\n\r\nEPOCHS=250\r\nname='sep_Adam'\r\nBATCH_SIZE=32\r\n\r\n\r\nbucket = 'gs://dataset_us/dataset/TF3/*'\r\ntfr = tf.io.gfile.glob(bucket)\r\nrandom.shuffle(tfr)\r\ntrain = tfr[:int((len(tfr)*0.8))]\r\nvalid = tfr[int((len(tfr)*0.8)):]\r\ntraining_filenames = train\r\nvalidation_filenames = valid\r\nsteps_per_epoch = int(len(train)*2000/(BATCH_SIZE))\r\nval_steps = int(len(valid)*2000/(BATCH_SIZE))\r\n\r\n\r\nAUTO = tf.data.experimental.AUTOTUNE\r\n\r\ndef read_tfrecord(example):\r\n    features = {\r\n        'image': tf.io.FixedLenFeature([], tf.string),\r\n        'labels': tf.io.FixedLenFeature([], tf.string)\r\n    }\r\n    sample=tf.io.parse_single_example(example, features)\r\n    image = tf.image.decode_jpeg(sample['image'], channels=3)\r\n    image = tf.reshape(image, tf.stack([540, 540, 3]))\r\n    image = augmentation(image)\r\n    labels = tf.io.decode_raw(sample['labels'], tf.float64)\r\n    labels = tf.reshape(labels, tf.stack([2,2,45]))\r\n    labels = tf.dtypes.cast(labels, tf.float32)\r\n    return image, labels\r\n\r\ndef load_dataset(filenames):\r\n    ignore_order = tf.data.Options()\r\n    ignore_order.experimental_deterministic = False\r\n\r\n    files = tf.data.Dataset.list_files(filenames)\r\n    dataset = files.with_options(ignore_order)\r\n    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=32, num_parallel_calls=AUTO)\r\n    dataset = dataset.map(map_func=read_tfrecord, num_parallel_calls=AUTO)\r\n    return dataset\r\n\r\ndef augmentation(img):\r\n    image = tf.dtypes.cast(img, tf.float32)/255.0\r\n    image = tf.image.random_brightness(image, max_delta=25/255)\r\n    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\r\n    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\r\n    image = tf.image.per_image_standardization(image)\r\n    return image\r\n\r\ndef get_batched_dataset(filenames):\r\n    dataset = load_dataset(filenames)\r\n    dataset = dataset.shuffle(2000)\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n    dataset = dataset.prefetch(AUTO)\r\n    return dataset\r\n\r\ndef get_training_dataset():\r\n    return get_batched_dataset(training_filenames)\r\n\r\ndef get_validation_dataset():\r\n    return get_batched_dataset(validation_filenames)\r\n\r\n\r\ndef sep(input, kernel, filt, stride, dilation):\r\n    x = layers.SeparableConv2D(filters=filt, kernel_size=kernel, strides=stride, dilation_rate=dilation, depthwise_regularizer=keras.regularizers.l2(0.01), pointwise_regularizer=keras.regularizers.l2(0.01))(input)\r\n    return x\r\n\r\ndef resblock(input, filters):\r\n    x = sep(input, 1, filters, 1 ,2)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = layers.LeakyReLU(alpha=0.2)(x)  \r\n    x = sep(x, 3, filters, 1 ,2)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = layers.LeakyReLU(alpha=0.2)(x)  \r\n    x = sep(x, 1, filters, 1 ,2)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    short = sep(input, 3, filters, 1 ,2)\r\n    x = layers.Add()([x, short])\r\n    x = layers.LeakyReLU(alpha=0.2)(x)   \r\n    return x\r\n\r\ndef sep_down(input, filters):\r\n    x = sep(input, 3, filters, 2 ,1)\r\n    x = layers.BatchNormalization(axis=-1, fused=True)(x)\r\n    x = layers.LeakyReLU(alpha=0.2)(x)  \r\n    return x\r\n    \r\n\r\ndef create_model():\r\n    Input = layers.Input(shape=(540, 540, 3))\r\n    x = resblock(Input, 128)\r\n    x = resblock(x, 128)\r\n    x = resblock(x, 128)\r\n    ####################\r\n    x = sep_down(x, 256)\r\n    ####################\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 128)\r\n    x = resblock(x, 256)\r\n    #####################\r\n    x = sep_down(x, 512)\r\n    #####################\r\n    x = resblock(x, 128)\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 128)\r\n    x = resblock(x, 256)\r\n    #####################\r\n    x = sep_down(x, 512)\r\n    #####################\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 512)\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 512)\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 512)\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 512)\r\n    x = resblock(x, 1024)\r\n    x = resblock(x, 512)\r\n    x = resblock(x, 256)\r\n    x = resblock(x, 128)\r\n    x = resblock(x, 45)\r\n    Conf = keras.layers.Lambda(conf)(x)\r\n    Theta = keras.layers.Lambda(theta)(x)\r\n    Depth = keras.layers.Lambda(depth)(x)\r\n    Radius = keras.layers.Lambda(radius)(x)\r\n    obj=[Conf, Theta, Depth, Radius]\r\n    tens=keras.layers.Lambda(conca)(obj)\r\n    model = tf.keras.Model(inputs=Input, outputs=tens)\r\n    model.compile(optimizer=keras.optimizers.Adam(), loss=custom_loss)\r\n    return model\r\n\r\n\r\n\r\ndef conf(x):\r\n    conf = x[:,0,0,:]\r\n    conf = keras.activations.relu(conf)\r\n    return conf\r\n\r\ndef theta(x):\r\n    ##### Theta belongs [0,2p]  ######\r\n    ##### x-axis belongs [0,1] as proportion of image resolution #######\r\n    thet = x[:,0,1,:]\r\n    thet = keras.activations.tanh(thet)\r\n    return thet\r\n\r\ndef radius(x):\r\n    ##### Radius belongs [0,2...] ######\r\n    ##### y-axis belongs [0,1] as proportion of image resolution #######\r\n    rad = x[:,1,1,:]\r\n    rad = keras.activations.tanh(rad)\r\n    return rad\r\n\r\ndef depth(x):\r\n    ##### Depth belongs [0,infinite] ######\r\n    dep = x[:,1,0,:]\r\n    return dep\r\n\r\n    \r\ndef conca(obj):\r\n    conf = obj[0]\r\n    theta = obj[1]\r\n    depth = obj[2]\r\n    radius = obj[3]\r\n    conf = keras.backend.expand_dims(conf, 1)\r\n    theta = keras.backend.expand_dims(theta, 1)\r\n    depth = keras.backend.expand_dims(depth, 1)\r\n    radius = keras.backend.expand_dims(radius, 1)\r\n    temp1 = keras.layers.concatenate([conf,theta], 1)\r\n    temp2 = keras.layers.concatenate([depth,radius], 1)\r\n    temp1 = keras.backend.expand_dims(temp1, 1)\r\n    temp2 = keras.backend.expand_dims(temp2, 1)\r\n    tens = keras.layers.concatenate([temp1,temp2], 1)\r\n    return tens\r\n\r\ndef custom_loss(y_true,y_pred):\r\n    conf=y_pred[:,0,0,:]\r\n    #################\r\n    theta_true=y_true[:,0,1,:]\r\n    theta_pred=y_pred[:,0,1,:]\r\n    theta_body1=tf.math.sqrt(tf.losses.mean_squared_error(theta_true[:,1:4],theta_pred[:,1:4]))\r\n    theta_body2=tf.math.sqrt(tf.losses.mean_squared_error(theta_true[:,42:],theta_pred[:,42:]))\r\n    theta_body=(theta_body1+theta_body2)\r\n    theta_fing=tf.math.sqrt(tf.losses.mean_squared_error(theta_true[4:42], theta_pred[4:42]))*10\r\n    #################\r\n    radius_true=y_true[:,1,1,:]\r\n    radius_pred=y_pred[:,1,1,:]\r\n    #####\r\n    radius_body1=tf.math.sqrt(tf.losses.mean_squared_error(radius_true[:,1:4], radius_pred[:,1:4]))\r\n    radius_body2=tf.math.sqrt(tf.losses.mean_squared_error(radius_true[:,42:], radius_pred[:,42:]))\r\n    radius_body=(radius_body1+radius_body2)\r\n    #####\r\n    radius_fing=tf.math.sqrt(tf.losses.mean_squared_error(radius_true[4:42], radius_pred[4:42]))*10\r\n    #################\r\n    x_error=tf.math.sqrt((tf.losses.mean_squared_error(theta_true[:,0],theta_pred[:,0])))*10\r\n    y_error=tf.math.sqrt(tf.losses.mean_squared_error(radius_true[:,0], radius_pred[:,0]))*10\r\n    #################\r\n    sum_error = theta_body+theta_fing+radius_fing+radius_body+x_error+y_error\r\n    return sum_error\r\n\r\n\r\n\r\n ######## Tensorboard ############\r\nlogdir='gs://dataset_us/logs/'+name\r\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, write_graph=True)\r\n######## Model Save #############\r\nfilepath = './models/'+name+'.hdf5'\r\ncheckpoint = keras.callbacks.ModelCheckpoint((filepath), save_freq=(steps_per_epoch*10), verbose=1, save_weights_only=False)\r\n\r\n#################################\r\nclbk=[tensorboard_callback, checkpoint] \r\n###############fit#############\r\n\r\nwith tpu_strategy.scope():\r\n    model=create_model()\r\n\r\n\r\nmodel.fit(get_training_dataset(), validation_data=get_validation_dataset(), steps_per_epoch=steps_per_epoch ,validation_steps=val_steps, epochs=EPOCHS, verbose=1, initial_epoch=00, callbacks=clbk)\r\n\r\n\r\n```", "Quick check: Is your GCS regional storage and in the same Cloud zone as your VMs?", "@rxsang yes", "@nsantavas I am also training a different model on Colab TPU and I have noticed few things maybe you can confirm these with your model.\r\n1. Can you remove the validation part from `.fit()`, only feed the training data and check the speed of saving the file? \r\nIn my experiment, feeding validation data to `fit` has a huge impact on the speed of training than saving the model. Since you are performing both, then I am sure validation data is the culprit plus saving model.\r\n2. If you remove also the saving part and just train the model then it will make the training even more faster on TPU.", "Any resolution on this as i am also going through same issue", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 32023, "title": "tf.keras.layers.Concatenate layer has unexpected behavior since 1.13", "body": "`tf.keras.layers.Concatenate` used to operate in a very straightforward way with the Keras functional API for building DenseNet-esque feedforward networks.\r\n\r\nThe code below works in TF 1.13 but fails in 1.14, 2.0.0a0 and beyond.\r\n \r\nI also tested replacing the `Concatenate` layer with its functional alternative, `concatenate`, and produced the same error.\r\n```python\r\nfrom tensorflow.keras.layers import Dense, Input, Concatenate\r\nfrom tensorflow.keras.models import Model\r\n\r\ninputs = Input(shape=(10,))\r\n\r\nall_layers = []\r\n\r\nx1 = Dense(512)(inputs)\r\nall_layers.append(x1)\r\n\r\n# all layers: [x1]\r\nx2 = Dense(256, activation='relu')(x1)\r\nall_layers.append(x2)\r\n\r\n# all layers: [x1, x2]\r\nconc = Concatenate()(all_layers)\r\nx3 = Dense(128, activation='relu')(conc)\r\nall_layers.append(x3)\r\n\r\n# all layers: [x1, x2, x3]\r\nconc = Concatenate()(all_layers)\r\nprediction = Dense(1)(conc)\r\nmodel = Model(inputs=inputs, outputs=prediction)\r\n```\r\nThe error output is \r\n```\r\nValueError: Graph disconnected: cannot obtain value for tensor Tensor(\"dense_2/Identity:0\", shape=(None, 128), dtype=float32) at layer \"concatenate\". The following previous layers were accessed without issue: ['input_1', 'dense', 'dense_1']\r\n```\r\nVisualization of model\r\n![](https://i.imgur.com/17UNrSk.png)\r\n", "comments": ["I was able to reproduce this issue in tensorflow [1.13.2](https://colab.sandbox.google.com/gist/gowthamkpr/c68210d825eda78bc557bfff218c9db8/untitled111.ipynb), [1.14.0,](https://colab.sandbox.google.com/gist/gowthamkpr/08d42792fd855982f20bbfa9bf4f3b04/untitled112.ipynb#scrollTo=AEWA95USJilO) [1.15](https://colab.sandbox.google.com/gist/gowthamkpr/759847000ce53118d30ab366eee6211d/untitled113.ipynb) and [2.0-rc0](https://colab.research.google.com/gist/gowthamkpr/bb2abb3d6b2e7b546133b54c4dc52667/untitled114.ipynb)", "Interestingly, if doing it in the following way, then it works.\r\n```python\r\nfrom tensorflow.keras.layers import Dense, Input, Concatenate\r\nfrom tensorflow.keras.models import Model\r\n\r\ninputs = Input(shape=(10,))\r\n\r\nall_layers = []\r\n\r\nx1 = Dense(512)(inputs)\r\nall_layers.append(x1)\r\n\r\n# all layers: [x1]\r\nx2 = Dense(256, activation='relu')(x1)\r\nall_layers.append(x2)\r\n\r\n# all layers: [x1, x2]\r\nconc = Concatenate()(list(all_layers))\r\nx3 = Dense(128, activation='relu')(conc)\r\nall_layers.append(x3)\r\n\r\n# all layers: [x1, x2, x3]\r\nconc = Concatenate()(list(all_layers))\r\nprediction = Dense(1)(conc)\r\nmodel = Model(inputs=inputs, outputs=prediction)\r\n```", "Is someone working on this?", "@noahtren I think this was resolved in `tf-nightly`. I was not able to reproduce the issue with `tf-nightly`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/747b7ec0bc45a54dfcb227dd47b7b6dd/untitled114.ipynb). Thanks.\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "Yep, it looks like this was fixed! Thanks @jvishnuvardhan ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32023\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32023\">No</a>\n"]}, {"number": 32022, "title": "Manylinux 2014 Dockerfiles for ppc64le", "body": "Based on the work TensorFlow did to support manylinux 2010, these docker files\r\nwill be used to build docker images to build tensorflow for ppc64le that is\r\ncompliant with manylinux 2014.\r\n\r\nppc64le can never be manylinux 2010 compliant as little endian support for POWER\r\nwas not added until after 2010.\r\n\r\nDocker files provided for CPU and GPU builds.\r\n\r\nCleaned up two ppc64le specific install scripts.", "comments": ["The non ppc64le changes were made in this PR: https://github.com/tensorflow/tensorflow/pull/32021\r\nThis PR contains the ppc64le only changes.", "Ok, this is awesome! One reason I haven't started this work yet myself is that I think we really need to get rid of all the duplication across scripts here and pull out some common abstractions.\r\nThe dockerfiles in the end should be basically just a couple of lines\r\n1. a FROM line\r\n2. a couple of COPY lines\r\n3. a call to a script (or perhaps 2 scripts? :)\r\n\r\nSorry to put that on you, but I'm somewhat concerned we'll quickly have those diverge if we don't start doing it right now :(", "@r4nt, Thanks for the comment. I will start looking into how we can remove the duplication in the docker files."]}, {"number": 32021, "title": "Changes to support ci_build/install scripts with Ubuntu 18.04 docker \u2026", "body": "\u2026containers\r\n\r\nSwitched from clang-format-3.8 to clang-format-3.9, as it is available on\r\nUbuntu 18.04, in addition to being available on Ubuntu 14.04 and Ubuntu 16.04.\r\n\r\npython-setuptools in Ubuntu 18.04 no longer includes easy_install. For Ubuntu\r\n18.04 only, installing pip using the https://bootstrap.pypa.io/get-pip.py\r\npython program. Ubuntu 16.04 and 14.04 behavior unchanged.\r\n\r\nForce installing lazy-object-proxy version 1.4.1, because non x86_64 systems\r\nthat need to compile from source encounter an error with version 1.4.2:\r\n`AttributeError: module 'setuptools.build_meta' has no attribute '__legacy__'`\r\nThis error is because we install setuptools with apt, and then replace\r\nsetuptools with a newer version using pip. This error is resolved in the latest\r\nversion of setuptools.", "comments": ["This is for a forthcoming PR for manylinux support for ppc64le. nivida only provides CUDA 10.0 containers with Ubuntu 18.04 for ppc64le.\r\n\r\nTested docker build on x86 with the following files:\r\nDockerfile.cpu  (Ubuntu 16.04)\r\nDockerfile.custom_op_gpu (Ubuntu 14.04)", "Looks good from my side, thanks for prepping this for 18!", "I made the changed requested. I tested docker build on x86 with the following files:\r\nDockerfile.rbe.ubuntu16.04-manylinux2010 (Ubuntu 16.04)\r\nDockerfile.custom_op_gpu (Ubuntu 14.04)\r\n\r\nTested bazel build using a container created from the first image."]}, {"number": 32020, "title": "Jvishnuvardhan patch 3", "body": "", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32020) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 32019, "title": "hi  i want to freeze east text a  pretrained model    the ckpt.meta data file  exist in the model folder but i get this error can any one help me please !!!!                                              ", "body": "re_fusion/Conv_7/Sigmoid,model_0/feature_fusion/concat_3\r\nTraceback (most recent call last):\r\n  File \"freez2.py\", line 66, in <module>\r\n    freeze_graph(args.model_dir, args.output_node_names)\r\n  File \"freez2.py\", line 41, in freeze_graph\r\n    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices\r\n=clear_devices)\r\n  File \"C:\\Users\\DeLl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\sav\r\ner.py\", line 1435, in import_meta_graph\r\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\r\n  File \"C:\\Users\\DeLl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\sav\r\ner.py\", line 1447, in _import_meta_graph_with_return_elements\r\n    meta_graph_def = meta_graph.read_meta_graph_file(meta_graph_or_file)\r\n  File \"C:\\Users\\DeLl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\me\r\nta_graph.py\", line 633, in read_meta_graph_file\r\n    raise IOError(\"File %s does not exist.\" % filename)\r\nOSError: File /tmp/east_icdar2015_resnet_v1_50_rbox/model.ckpt-49491.meta does n\r\not exist.\r\n\r\n(base) C:\\Users\\DeLl\\Documents\\east>", "comments": ["@amal268 ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "hi @oanush  thank you \r\ni'am using \r\n-windows 7 \r\n-python 3.6 under anaconda \r\n-tensorflow 1;13.1\r\nmy problem is solved but i'am facing new one \r\nmy goal is to freeze this pretrained model \" https://github.com/argman/EAST \"\r\nthis model is trained on GPU and i'am using it with CPU \r\ndetection work normaly but i can't freeze it \r\ncan u help please ? \r\n\r\n\"\r\n\"\r\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed\r\n. This is most likely due to a mismatch between the current graph and the graph\r\nfrom the checkpoint. Please ensure that you have not altered the graph expected\r\nbased on the checkpoint. Original error:\r\n\r\nCannot assign a device for operation model_0/split: node model_0/split (defined\r\nat freez.py:16) was explicitly assigned to /device:GPU:0 but available devices a\r\nre [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specif\r\nication refers to a valid device. The requested device appears to be a GPU, but\r\nCUDA is not enabled.\r\n         [[node model_0/split (defined at freez.py:16) ]]\r\n", "The below error says you have explicit device allocations made to GPU in the imported model which are not available in your instance.\r\nYou may try removing these device allocations. You can use ```tf.train.import_meta_graph``` with ```clear_devices``` option.\r\n```python\r\nCannot assign a device for operation model_0/split: node model_0/split (defined\r\nat freez.py:16) was explicitly assigned to /device:GPU:0 but available devices a\r\nre [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specif\r\nication refers to a valid device. The requested device appears to be a GPU, but\r\nCUDA is not enabled.\r\n```", "thank u very much @ymodak it works for me now ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32019\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32019\">No</a>\n", "> c\u1ea3m \u01a1n b\u1ea1n r\u1ea5t nhi\u1ec1u @ymodak n\u00f3 l\u00e0m vi\u1ec7c cho t\u00f4i b\u00e2y gi\u1edd\r\n\r\nCan you guide me to freeze with the EAST model. Thank you"]}, {"number": 32018, "title": "[TF 2.0] Unsupported op node error messages in latest tf-nightly (8-27-19)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly-gpu-2.0-preview==2.0.0.dev20190827\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7.6.2\r\n- GPU model and memory: Titan Xp 12 gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen running a model that previously yielded no errors, I'm getting errors of the form \r\n```\r\n2019-08-27 11:35:15.004095: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/enter/_15' id:223 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_eff\r\nects/get_phiC/add_collisions/while/enter/_15}} = Enter[T=DT_INT32, frame_name=\"policy/fn_...ions/while\", is_constant=false, parallel_iterations=10, _device=\"/job:localhost/replica:0\r\n/task:0/device:GPU:0\"](policy/apply_gauss_force/ExpandDims/dim)}}\r\n2019-08-27 11:35:15.004669: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/enter/_9' id:224 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_effe\r\ncts/get_phiC/add_collisions/while/enter/_9}} = Enter[T=DT_INT32, frame_name=\"policy/fn_...ions/while\", is_constant=false, parallel_iterations=10, _device=\"/job:localhost/replica:0/t\r\nask:0/device:GPU:0\"](policy/postprocess_policy_inputs/Sum/reduction_indices)}}\r\n2019-08-27 11:35:15.005043: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/enter/_4' id:227 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_effe\r\ncts/get_phiC/add_collisions/while/enter/_4}} = Enter[T=DT_INT32, frame_name=\"policy/fn_...ions/while\", is_constant=false, parallel_iterations=10, _device=\"/job:localhost/replica:0/t\r\nask:0/device:GPU:0\"](policy/postprocess_policy_inputs/get_collision/strided_slice_3/stack_1/0)}}\r\n2019-08-27 11:35:15.005378: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/enter/_2' id:228 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_effe\r\ncts/get_phiC/add_collisions/while/enter/_2}} = Enter[T=DT_INT32, frame_name=\"policy/fn_...ions/while\", is_constant=false, parallel_iterations=10, _device=\"/job:localhost/replica:0/t\r\nask:0/device:GPU:0\"](policy/postprocess_policy_inputs/get_collision/strided_slice_3/stack_1/0)}}\r\n2019-08-27 11:35:15.005796: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/enter/_11' id:242 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_eff\r\nects/get_phiC/add_collisions/while/enter/_11}} = Enter[T=DT_BOOL, frame_name=\"policy/fn_...ions/while\", is_constant=false, parallel_iterations=10, _device=\"/job:localhost/replica:0/\r\ntask:0/device:GPU:0\"](policy/postprocess_policy_inputs/Tile_7)}}\r\n2019-08-27 11:35:15.006245: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/merge/_29' id:255 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_eff\r\nects/get_phiC/add_collisions/while/merge/_29}} = Merge[N=2, T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](policy/fn__call__/build_one_time_effects_or_recurrenc\r\ne/get_effects/get_phiC/add_collisions/while/enter/_15, policy/fn__call__/build_one_time_effects_or_recurrence/get_effects/get_phiC/add_collisions/while/next_iteration/_74)}}\r\n2019-08-27 11:35:15.006623: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/merge/_23' id:256 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_eff\r\nects/get_phiC/add_collisions/while/merge/_23}} = Merge[N=2, T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](policy/fn__call__/build_one_time_effects_or_recurrenc\r\ne/get_effects/get_phiC/add_collisions/while/enter/_9, policy/fn__call__/build_one_time_effects_or_recurrence/get_effects/get_phiC/add_collisions/while/next_iteration/_68)}}\r\n2019-08-27 11:35:15.007007: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/merge/_18' id:259 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_eff\r\nects/get_phiC/add_collisions/while/merge/_18}} = Merge[N=2, T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](policy/fn__call__/build_one_time_effects_or_recurrenc\r\ne/get_effects/get_phiC/add_collisions/while/enter/_4, policy/fn__call__/build_one_time_effects_or_recurrence/get_effects/get_phiC/add_collisions/while/next_iteration/_63)}}\r\n2019-08-27 11:35:15.007369: E tensorflow/compiler/jit/compilability_check_util.cc:346] unsupported op node : {name:'policy/fn__call__/build_one_time_effects_or_recurrence/get_effect\r\ns/get_phiC/add_collisions/while/merge/_16' id:260 op device:{/job:localhost/replica:0/task:0/device:GPU:0} def:{{{node policy/fn__call__/build_one_time_effects_or_recurrence/get_eff\r\nects/get_phiC/add_collisions/while/merge/_16}} = Merge[N=2, T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](policy/fn__call__/build_one_time_effects_or_recurrenc\r\ne/get_effects/get_phiC/add_collisions/while/enter/_2, policy/fn__call__/build_one_time_effects_or_recurrence/get_effects/get_phiC/add_collisions/while/next_iteration/_61)}}\r\n```\r\nwhen using autograph with the tf.function decorator.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nI'm just curious how we are supposed to interpret these logs; so far it's non blocking, but I'm wondering if this is indicating autograph is failing to convert parts of my model.\r\n", "comments": ["@mjlbach, In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "I countered the same issue. Here is my code that can be used to reproduce it.\r\nIt works fine in tensorflow 2.0 without GPU, but emits errors with  tf-nightly-gpu-2.0-preview 2.0.0.dev20190827\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ny = tf.cast(np.random.randn(1, 100, 100), tf.float32)\r\nz = tf.cast(np.random.randn(1, 100), tf.float32)\r\n\r\nlayer = tf.keras.layers.GRU(100)\r\n\r\n@tf.function\r\ndef fun(layer, x):\r\n    return layer(x)\r\n\r\nwith tf.GradientTape() as tape:\r\n    loss = tf.norm(fun(layer, y) - z)\r\n```", "I think the example above is sufficient, I'll retest on nightly with https://github.com/tensorflow/addons/pull/459 ", "cc @alextp Hi, Alexandre, can you take a look at this or redirect to someone else who can? Thanks.", "cc @asimshankar", "I can't reproduce it on 20190830's nightly, so I think this is a bug that was fixed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32018\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32018\">No</a>\n"]}, {"number": 32017, "title": "Training stalls after saving checkpoint 0", "body": "Hello. \r\n\r\nI'm trying to run the LibriSpeech problem using tensor2tensor on Google Colab's GPU runtime, but the training stalls after saving checkpoint 0 and opening dynamic library libcublas.so.10.0. There is no error message, it just stops there forever. \r\nI'm posting it here because the stalling point happens on Tensorflow's packages.\r\n\r\nPython's version : 3.6.8\r\nTensorflow's version : 1.14.0\r\ntensor2tensor's version : 1.14.0\r\nCUDA's version : 10.1\r\nOS : Ubuntu 18.04\r\n\r\nThis is the code\r\n```\r\nfrom tensor2tensor import models\r\nfrom tensor2tensor.utils import registry\r\n\r\n!t2t-trainer \\\r\n    --tmp_dir='/content/gdrive/My Drive/TCC/T2T LibriSpeech/tmp/' \\\r\n    --problem='librispeech_clean_small' \\\r\n    --model='transformer' \\\r\n    --train_steps=10 \\\r\n    --hparams_set='transformer_librispeech' \\\r\n    --data_dir='/content/gdrive/My Drive/TCC/T2T LibriSpeech/data/' \\\r\n    --output_dir='/content/gdrive/My Drive/TCC/T2T LibriSpeech/output/' \\\r\n    --worker-gpu=0\r\n```\r\n\r\nAnd here's the output : \r\n\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0827 17:43:33.747592 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nW0827 17:43:35.111425 139969908836224 lazy_loader.py:50] \r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nW0827 17:43:36.899833 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n\r\nW0827 17:43:36.900365 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n\r\nW0827 17:43:36.911696 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\r\n\r\nW0827 17:43:36.911862 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n\r\nW0827 17:43:36.928164 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/research/neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\r\n\r\nW0827 17:43:36.975095 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nW0827 17:43:36.993708 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\r\n\r\nW0827 17:43:37.006869 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\r\n\r\nW0827 17:43:37.007008 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\r\n\r\nW0827 17:43:38.449517 139969908836224 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n\r\nW0827 17:43:38.449705 139969908836224 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n\r\nW0827 17:43:38.449807 139969908836224 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nI0827 17:43:38.450179 139969908836224 t2t_trainer.py:155] Found unparsed command-line arguments. Checking if any start with --hp_ and interpreting those as hparams settings.\r\nW0827 17:43:38.450768 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py:165: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\r\n\r\nW0827 17:43:38.450837 139969908836224 t2t_trainer.py:165] Found unknown flag: --worker-gpu=0\r\nW0827 17:43:38.451183 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/hparams_lib.py:49: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\r\n\r\nW0827 17:43:38.451832 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:839: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\r\n\r\nW0827 17:43:38.452693 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:123: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\r\n\r\nW0827 17:43:38.452859 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:129: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\r\n\r\nW0827 17:43:38.453019 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:242: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nWhen switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\r\nI0827 17:43:38.453181 139969908836224 trainer_lib.py:265] Configuring DataParallelism to replicate the model.\r\nI0827 17:43:38.453252 139969908836224 devices.py:76] schedule=continuous_train_and_eval\r\nI0827 17:43:38.453314 139969908836224 devices.py:77] worker_gpu=1\r\nI0827 17:43:38.453381 139969908836224 devices.py:78] sync=False\r\nW0827 17:43:38.453437 139969908836224 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\r\nI0827 17:43:38.453504 139969908836224 devices.py:170] datashard_devices: ['gpu:0']\r\nI0827 17:43:38.453559 139969908836224 devices.py:171] caching_devices: None\r\nI0827 17:43:38.454001 139969908836224 devices.py:172] ps_devices: ['gpu:0']\r\nI0827 17:43:38.454567 139969908836224 estimator.py:209] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4cda9f8438>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1.0\r\n}\r\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 0.95\r\n}\r\nallow_soft_placement: true\r\ngraph_options {\r\n  optimizer_options {\r\n    global_jit_level: OFF\r\n  }\r\n}\r\nisolate_session_state: true\r\n, '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/gdrive/My Drive/TCC/T2T LibriSpeech/output/', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f4cda9f84a8>}\r\nW0827 17:43:38.454751 139969908836224 model_fn.py:630] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f4cda9e7ae8>) includes params argument, but params are not passed to Estimator.\r\nW0827 17:43:38.454877 139969908836224 trainer_lib.py:783] ValidationMonitor only works with --schedule=train_and_evaluate\r\nW0827 17:43:38.455530 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py:328: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\r\n\r\nW0827 17:43:38.458196 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py:344: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nI0827 17:43:38.487565 139969908836224 estimator_training.py:186] Not using Distribute Coordinator.\r\nI0827 17:43:38.487942 139969908836224 training.py:612] Running training and evaluation locally (non-distributed).\r\nI0827 17:43:38.488237 139969908836224 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\r\nW0827 17:43:38.493283 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nI0827 17:43:38.502703 139969908836224 problem.py:644] Reading data files from /content/gdrive/My Drive/TCC/T2T LibriSpeech/data/librispeech_clean_small-train*\r\nI0827 17:43:38.543926 139969908836224 problem.py:670] partition: 0 num_data_files: 100\r\nW0827 17:43:38.545797 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nW0827 17:43:38.581830 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_audio.py:92: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0827 17:43:38.823341 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_audio.py:115: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0827 17:43:38.987241 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse eager execution and: \r\n`tf.data.TFRecordDataset(path)`\r\nW0827 17:43:40.327878 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:395: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.data.get_output_shapes(dataset)`.\r\nW0827 17:43:40.328149 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:398: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nW0827 17:43:40.328256 139969908836224 data_reader.py:399] Shapes are not fully defined. Assuming batch_size means tokens.\r\nW0827 17:43:40.374079 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/grouping.py:193: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0827 17:43:40.414666 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nI0827 17:43:40.470206 139969908836224 estimator.py:1145] Calling model_fn.\r\nI0827 17:43:40.481091 139969908836224 t2t_model.py:2248] Setting T2TModel mode to 'train'\r\nW0827 17:43:40.552857 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:244: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\r\n\r\nI0827 17:43:41.160171 139969908836224 api.py:255] Using variable initializer: uniform_unit_scaling\r\nI0827 17:43:41.531091 139969908836224 t2t_model.py:2248] Transforming feature 'inputs' with speech_recognition_modality.bottom\r\nW0827 17:43:41.532868 139969908836224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py:439: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.keras.layers.Conv2D` instead.\r\nI0827 17:43:41.922302 139969908836224 t2t_model.py:2248] Transforming feature 'targets' with symbol_modality_256_384.targets_bottom\r\nI0827 17:43:42.037450 139969908836224 t2t_model.py:2248] Building model body\r\nW0827 17:43:42.094394 139969908836224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\nW0827 17:43:42.130389 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\r\n\r\nW0827 17:43:42.473380 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_attention.py:1249: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\r\n\r\nI0827 17:43:49.011597 139969908836224 t2t_model.py:2248] Transforming body output with symbol_modality_256_384.top\r\nW0827 17:43:49.118912 139969908836224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/learning_rate.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nI0827 17:43:49.120072 139969908836224 learning_rate.py:29] Base learning rate: 2.000000\r\nI0827 17:43:49.131614 139969908836224 optimize.py:338] Trainable Variables Total size: 70343552\r\nI0827 17:43:49.131888 139969908836224 optimize.py:338] Non-trainable variables Total size: 5\r\nI0827 17:43:49.132170 139969908836224 optimize.py:193] Using optimizer adam\r\nI0827 17:43:59.596418 139969908836224 estimator.py:1147] Done calling model_fn.\r\nI0827 17:43:59.597772 139969908836224 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nI0827 17:44:03.685569 139969908836224 monitored_session.py:240] Graph was finalized.\r\n2019-08-27 17:44:03.685968: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-27 17:44:03.708726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-08-27 17:44:03.898700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-08-27 17:44:03.899340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x207fb80 executing computations on platform CUDA. Devices:\r\n2019-08-27 17:44:03.899389: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\r\n2019-08-27 17:44:03.901408: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2019-08-27 17:44:03.901570: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x207ea00 executing computations on platform Host. Devices:\r\n2019-08-27 17:44:03.901594: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-08-27 17:44:03.901797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-08-27 17:44:03.902276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:00:04.0\r\n2019-08-27 17:44:03.902614: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-27 17:44:03.907500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-08-27 17:44:03.908556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-08-27 17:44:03.911851: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-08-27 17:44:03.916549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-08-27 17:44:03.917606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-08-27 17:44:03.925044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-08-27 17:44:03.925147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-08-27 17:44:03.925681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-08-27 17:44:03.926137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-08-27 17:44:03.926182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-27 17:44:03.927269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-08-27 17:44:03.927290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-08-27 17:44:03.927300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-08-27 17:44:03.927408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-08-27 17:44:03.927907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-08-27 17:44:03.928376: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2019-08-27 17:44:03.928411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14325 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\n2019-08-27 17:44:07.049904: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\nI0827 17:44:09.037412 139969908836224 session_manager.py:500] Running local_init_op.\r\nI0827 17:44:09.280463 139969908836224 session_manager.py:502] Done running local_init_op.\r\nI0827 17:44:18.882892 139969908836224 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/gdrive/My Drive/TCC/T2T LibriSpeech/output/model.ckpt.\r\n2019-08-27 17:44:39.361151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n```", "comments": ["Same problem. When setting TF_CPP_MIN_VLOG_LEVEL=2, it printing this:\r\n```\r\n[...]\r\nsession_manager.py:500] Running local_init_op.\r\nsession_manager.py:502] Done running local_init_op.\r\nbasic_session_run_hooks.py:606] Saving checkpoints for 0 into ~/trainoutput/librispeech/model.ckpt.\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 20480 ms.\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 40960 ms.\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 60000 ms.\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 60000 ms.\r\n```", "@Victor-Almeida, Will it possible to provide Google colab link to expedite the trouble-shooting process. Thanks!\r\n", "I encounter the same problem when executing tensor2tensor on my local machine. \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: Python 2.7.12\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: CUDA 10.1 / CUDNN 7.5\r\n- GPU model and memory: Nvidia 1080Ti 11GB\r\n\r\n**Describe the current behavior**\r\n```\r\n[...]\r\nsession_manager.py:500] Running local_init_op.\r\nsession_manager.py:502] Done running local_init_op.\r\nbasic_session_run_hooks.py:606] Saving checkpoints for 0 into ~/trainoutput/librispeech/model.ckpt.\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 20480 ms.\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 40960 ms.\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 60000 ms.\r\ntensorflow/core/framework/model.cc:440] Starting optimization of tunable parameters\r\ntensorflow/core/framework/model.cc:482] Number of tunable parameters: 0\r\ntensorflow/core/kernels/data/model_dataset_op.cc:172] Waiting for 60000 ms.\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\nInstall tensor2tensor (Release v1.14.0)\r\n\r\n```\r\nexport TF_CPP_MIN_VLOG_LEVEL=2\r\nt2t-trainer --problem=librispeech --model=transformer --data_dir=~/datasets/t2t/librispeech/ --output_dir=~/trainoutput/librispeech/ --hparams_set=transformer_librispeech --worker_gpu=1\r\n```\r\n", "[Here](https://github.com/tensorflow/tensorflow/files/3551652/Training_Speech_Recognition_Model_with_tensor2tensor.zip) it is.\r\n", "I'm experiencing the same issue.  If I `export TF_CPP_MIN_VLOG_LEVEL=2` before running `t2t-trainer` I get the following error, just prior to the stall.  It might be unique to my custom librispeech-like `--problem` -- but curious if others are seeing that too?  Perhaps related, I've been fighting with a similar message when attempting to load an older t2t _saved model_ into a current TFServing.\r\n```\r\n2019-08-30 17:54:05.447740: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 3917 allocator_name: \"cpu\" }\r\n2019-08-30 17:54:05.447758: I tensorflow/core/common_runtime/executor.cc:2240] [/job:localhost/replica:0/task:0/device:CPU:0] Executor start aborting: Unimplemented: Generic conv implementation only supports NHWC tensor format for now.\r\n\t [[{{node Conv2D}}]]\r\n```", "@Victor-Almeida @tenghaha Do you specifically need those versions of cuDNN and CUDA? If not the official tested configuration for tf1.14_gpu looks like cuDNN=7.4, CUDA=10.0, see [this](https://www.tensorflow.org/install/source#tested_build_configurations). And you might have an easier time debugging it in comparison to something that works in CPU mode as well as in comparison to a trivially simple t2t problem and model.", "I'm seeing the same issues running from the official 1.14.0-gpu docker image.  As well as the nightly-gpu.  The training works fine with the simple models (eg --problem=image_mnist --model=shake_shake).\r\n\r\nSeems to be some issue with the interaction between the T2T Librispeech problem and the new tensorflow versions.", "@jsimsa, could you triage? I'm guessing I was assigned due to the \"checkpoint\" keyword, but it looks like checkpointing completes and this is either input pipeline optimization related or GPU related.", "Can you collect a stacktrace at the time your program hangs a share a link to it?", "Can you clarify what you're looking for?  Since the process does not halt, there is no stacktrace.  A representative end-of-logging is shown in @cantwbr post (github.com/tensorflow/tensorflow/issues/32017#issuecomment-525726395).\r\n\r\nWith `TF_CPP_MIN_VLOG_LEVEL=2` enabled the logging is extremely verbose and probably not practical to post here.", "Here is a snip of the last ~100 lines from a run of the basic problem, run via:\r\n`t2t-trainer --problem=librispeech_clean_small --model=transformer --output_dir=/models/JUNK --data_dir=/data/ --save_checkpoints_secs=1800 --schedule=train --hparams_set=transformer_tiny`\r\n```\r\n2019-09-05 19:38:13.932318: W tensorflow/core/common_runtime/executor.cc:2428]     Input 147: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932329: W tensorflow/core/common_runtime/executor.cc:2428]     Input 148: Tensor<type: int32 shape: [], bytes: 4>\r\n2019-09-05 19:38:13.932341: W tensorflow/core/common_runtime/executor.cc:2428]     Input 149: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932349: W tensorflow/core/common_runtime/executor.cc:2428]     Input 150: Tensor<type: int32 shape: [1], bytes: 4>\r\n2019-09-05 19:38:13.932357: W tensorflow/core/common_runtime/executor.cc:2428]     Input 151: Tensor<type: int32 shape: [1], bytes: 4>\r\n2019-09-05 19:38:13.932366: W tensorflow/core/common_runtime/executor.cc:2428]     Input 152: Tensor<type: int32 shape: [1], bytes: 4>\r\n2019-09-05 19:38:13.932373: W tensorflow/core/common_runtime/executor.cc:2428]     Input 153: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932382: W tensorflow/core/common_runtime/executor.cc:2428]     Input 154: Tensor<type: float shape: [], bytes: 4>\r\n2019-09-05 19:38:13.932390: W tensorflow/core/common_runtime/executor.cc:2428]     Input 155: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932396: W tensorflow/core/common_runtime/executor.cc:2428]     Input 156: Tensor<type: int32 shape: [], bytes: 4>\r\n2019-09-05 19:38:13.932401: W tensorflow/core/common_runtime/executor.cc:2428]     Input 157: Tensor<type: int32 shape: [], bytes: 4>\r\n2019-09-05 19:38:13.932406: W tensorflow/core/common_runtime/executor.cc:2428]     Input 158: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932412: W tensorflow/core/common_runtime/executor.cc:2428]     Input 159: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932417: W tensorflow/core/common_runtime/executor.cc:2428]     Input 160: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932425: W tensorflow/core/common_runtime/executor.cc:2428]     Input 161: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932435: W tensorflow/core/common_runtime/executor.cc:2428]     Input 162: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932443: W tensorflow/core/common_runtime/executor.cc:2428]     Input 163: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932448: W tensorflow/core/common_runtime/executor.cc:2428]     Input 164: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932456: W tensorflow/core/common_runtime/executor.cc:2428]     Input 165: Tensor<type: float shape: [250,80,3], bytes: 240000>\r\n2019-09-05 19:38:13.932461: W tensorflow/core/common_runtime/executor.cc:2428]     Input 166: Tensor<type: int32 shape: [], bytes: 4>\r\n2019-09-05 19:38:13.932466: W tensorflow/core/common_runtime/executor.cc:2428]     Input 167: Tensor<type: int64 shape: [1], bytes: 8>\r\n2019-09-05 19:38:13.932470: W tensorflow/core/common_runtime/executor.cc:2428]     Input 168: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932475: W tensorflow/core/common_runtime/executor.cc:2428]     Input 169: Tensor<type: int64 shape: [201], bytes: 1608>\r\n2019-09-05 19:38:13.932480: W tensorflow/core/common_runtime/executor.cc:2428]     Input 170: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932486: W tensorflow/core/common_runtime/executor.cc:2436]     Total bytes 729120\r\n2019-09-05 19:38:13.932497: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 25835 allocator_name: \"cpu\" }\r\n2019-09-05 19:38:13.932512: I tensorflow/core/common_runtime/executor.cc:1868] Synchronous kernel done: 102 step -8435589056233180824 {{node Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer/_4, Conv2D/filter) device: /job:localhost/replica:0/task:0/device:CPU:0\r\n2019-09-05 19:38:13.932520: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 1501 allocator_name: \"gpu_host_bfc\" }\r\n2019-09-05 19:38:13.932527: I tensorflow/core/common_runtime/bfc_allocator.cc:526] DeallocateRaw gpu_host_bfc 487360\r\n2019-09-05 19:38:13.932536: I tensorflow/core/common_runtime/executor.cc:2249] [/job:localhost/replica:0/task:0/device:CPU:0] Executor start aborting: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n2019-09-05 19:38:13.932547: W tensorflow/core/common_runtime/executor.cc:2007] 0x7f0368013e90 Compute status: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n\t [[Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer/_10]]\r\n2019-09-05 19:38:13.932557: I tensorflow/core/common_runtime/executor.cc:1777] Async kernel done: 110 step -8435589056233180824 {{node Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer/_10}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=-2425652197422393730, tensor_name=\"edge_154_Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]() device: /job:localhost/replica:0/task:0/device:CPU:0\r\n2019-09-05 19:38:13.932567: W tensorflow/core/common_runtime/executor.cc:2007] 0x7f0368013e90 Compute status: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n\t [[mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_14]]\r\n2019-09-05 19:38:13.932576: I tensorflow/core/common_runtime/executor.cc:1777] Async kernel done: 117 step -8435589056233180824 {{node mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_14}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=-2425652197422393730, tensor_name=\"edge_168_mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]() device: /job:localhost/replica:0/task:0/device:CPU:0\r\n2019-09-05 19:38:13.932586: W tensorflow/core/common_runtime/executor.cc:2007] 0x7f03680133b0 Compute status: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n\t [[mul_2/_12]]\r\n2019-09-05 19:38:13.932592: W tensorflow/core/common_runtime/executor.cc:2442] Dumping state\r\n2019-09-05 19:38:13.932597: W tensorflow/core/common_runtime/executor.cc:2444] \r\n2019-09-05 19:38:13.932602: W tensorflow/core/common_runtime/executor.cc:2448]   Iteration:\r\n2019-09-05 19:38:13.932611: W tensorflow/core/common_runtime/executor.cc:2366]     Pending Node: {name:'Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer' id:10 op device:{} def:{{{node Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer}} = DataFormatVecPermute[T=DT_INT32, _kernel=\"host\", dst_format=\"NHWC\", src_format=\"NCHW\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Shape_3/_8)}}\r\n2019-09-05 19:38:13.932618: W tensorflow/core/common_runtime/executor.cc:2371]       Input 0: Tensor<type: float shape: [0]>\r\n2019-09-05 19:38:13.932628: W tensorflow/core/common_runtime/executor.cc:2366]     Pending Node: {name:'Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer/_9' id:11 op device:{} def:{{{node Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer/_9}} = _HostSend[T=DT_INT32, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=-2425652197422393730, tensor_name=\"edge_154_Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Shape_3-0-0-DataFormatVecPermuteNCHWToNHWC-LayoutOptimizer)}}\r\n2019-09-05 19:38:13.932635: W tensorflow/core/common_runtime/executor.cc:2371]       Input 0: Tensor<type: float shape: [0]>\r\n2019-09-05 19:38:13.932642: W tensorflow/core/common_runtime/executor.cc:2366]     Pending Node: {name:'mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer' id:13 op device:{} def:{{{node mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_2/_12, mul_2-0-0-PermConstNCHWToNHWC-LayoutOptimizer)}}\r\n2019-09-05 19:38:13.932648: W tensorflow/core/common_runtime/executor.cc:2371]       Input 0: Tensor<type: float shape: [0]>\r\n2019-09-05 19:38:13.932653: W tensorflow/core/common_runtime/executor.cc:2371]       Input 1: Tensor<type: int32 shape: [4]>\r\n2019-09-05 19:38:13.932661: W tensorflow/core/common_runtime/executor.cc:2366]     Pending Node: {name:'mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_13' id:14 op device:{} def:{{{node mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_13}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=-2425652197422393730, tensor_name=\"edge_168_mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](mul_2-0-0-TransposeNCHWToNHWC-LayoutOptimizer)}}\r\n2019-09-05 19:38:13.932668: W tensorflow/core/common_runtime/executor.cc:2371]       Input 0: Tensor<type: float shape: [0]>\r\n2019-09-05 19:38:13.932676: W tensorflow/core/common_runtime/executor.cc:2385]     Active Node: {name:'Shape_3/_8' id:9 op device:{} def:{{{node Shape_3/_8}} = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=-3160500913623757191, tensor_name=\"edge_151_Shape_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()}}\r\n2019-09-05 19:38:13.932685: W tensorflow/core/common_runtime/executor.cc:2385]     Active Node: {name:'mul_2/_12' id:12 op device:{} def:{{{node mul_2/_12}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=-3160500913623757191, tensor_name=\"edge_166_mul_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()}}\r\n2019-09-05 19:38:13.932692: W tensorflow/core/common_runtime/executor.cc:2428]     Input 0: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932697: W tensorflow/core/common_runtime/executor.cc:2428]     Input 1: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932702: W tensorflow/core/common_runtime/executor.cc:2428]     Input 2: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932708: W tensorflow/core/common_runtime/executor.cc:2428]     Input 3: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932715: W tensorflow/core/common_runtime/executor.cc:2428]     Input 4: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932721: W tensorflow/core/common_runtime/executor.cc:2428]     Input 5: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932726: W tensorflow/core/common_runtime/executor.cc:2428]     Input 6: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932731: W tensorflow/core/common_runtime/executor.cc:2428]     Input 7: Tensor<type: int32 shape: [4], bytes: 16>\r\n2019-09-05 19:38:13.932735: W tensorflow/core/common_runtime/executor.cc:2428]     Input 8: Tensor<type: float shape: [0], bytes: 0>\r\n2019-09-05 19:38:13.932741: W tensorflow/core/common_runtime/executor.cc:2436]     Total bytes 16\r\n2019-09-05 19:38:13.932748: I tensorflow/core/common_runtime/executor.cc:1777] Async kernel done: 12 step -8435589056233180824 {{node mul_2/_12}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=-3160500913623757191, tensor_name=\"edge_166_mul_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]() device: /job:localhost/replica:0/task:0/device:GPU:0\r\n2019-09-05 19:38:13.932755: I tensorflow/core/common_runtime/executor.cc:2249] [/job:localhost/replica:0/task:0/device:GPU:0] Executor start aborting: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n\t [[mul_2/_12]]\r\n2019-09-05 19:38:13.932766: W tensorflow/core/common_runtime/executor.cc:2007] 0x7f03680133b0 Compute status: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n\t [[Shape_3/_8]]\r\n2019-09-05 19:38:13.932775: I tensorflow/core/common_runtime/executor.cc:1777] Async kernel done: 9 step -8435589056233180824 {{node Shape_3/_8}} = _HostRecv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=-3160500913623757191, tensor_name=\"edge_151_Shape_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]() device: /job:localhost/replica:0/task:0/device:GPU:0\r\n2019-09-05 19:38:13.932795: I tensorflow/core/common_runtime/process_function_library_runtime.cc:927] Component function execution failed: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n2019-09-05 19:38:13.932797: I tensorflow/core/common_runtime/process_function_library_runtime.cc:927] Component function execution failed: Unimplemented: The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n\t [[{{node Conv2D}}]]\r\n\t [[mul_2/_12]]\r\n2019-09-05 19:38:13.932842: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4294 allocator_name: \"cpu\" }\r\n2019-09-05 19:38:13.932864: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 4295 allocator_name: \"cpu\" }\r\n2019-09-05 19:38:16.281181: I tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb\r\n2019-09-05 19:38:16.281277: I tensorflow/core/framework/model.cc:943] Number of tunable parameters: 0\r\n2019-09-05 19:38:16.281328: I tensorflow/core/kernels/data/model_dataset_op.cc:192] Waiting for 10240 ms.\r\n2019-09-05 19:38:26.521615: I tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb\r\n2019-09-05 19:38:26.521725: I tensorflow/core/framework/model.cc:943] Number of tunable parameters: 0\r\n2019-09-05 19:38:26.521775: I tensorflow/core/kernels/data/model_dataset_op.cc:192] Waiting for 20480 ms.\r\n2019-09-05 19:38:47.002024: I tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb\r\n2019-09-05 19:38:47.002125: I tensorflow/core/framework/model.cc:943] Number of tunable parameters: 0\r\n2019-09-05 19:38:47.002175: I tensorflow/core/kernels/data/model_dataset_op.cc:192] Waiting for 40960 ms.\r\n2019-09-05 19:39:27.962480: I tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb\r\n2019-09-05 19:39:27.962617: I tensorflow/core/framework/model.cc:943] Number of tunable parameters: 0\r\n2019-09-05 19:39:27.962692: I tensorflow/core/kernels/data/model_dataset_op.cc:192] Waiting for 60000 ms.```", "It does not halt, but it does stalls and it would be good to understand what is each thread of the program doing (e.g. if this is a deadlock). The log itself does not provide enough information to form a hypothesis about what could be going on and the first thing I would do to debug further is to use gdb to connect to running process to see what is each thread doing. As far as I know, this will not be possible running the program in a colab though.\r\n\r\n@ymodak could you please loop in someone from the trainer2trainer project as I am not familiar with that project.", "I've attached a gdb to the 'stalled' process, would you want to see a `bt` ?", "Also, FWIW, the lead of the Tensor2Tensor team referred this to Tensorflow support in: https://github.com/tensorflow/tensor2tensor/issues/1643", "Could you run `thread apply all bt` and post the result in pastebin and share a link to it here? Thanks.", "https://pastebin.com/w3ZevdSs\r\nThe full trace was 1.6MB in size, but most of the higher number threads were identical.  I've tried to edit out the mostly redundant traces.", "Thank you Michael. At least some of the threads seem to be waiting in tf.data. @rachellim could you please try to reproduce and investigate this issue? Thank you.", "Thank you! \r\n@rachellim please let me know if you have any trouble reproducing the issue (on gpu).  \r\n\r\nMy setup is via Nvidia Docker Hub\r\n - tensorflow/tensorflow:1.14.0-gpu\r\nor\r\n - tensorflow/tensorflow:nightly-gpu\r\nand\r\n - pip2 install tensorflow-hub && pip2 install tensor2tensor\r\n - apt-get update && apt-get install sox\r\n\r\n```t2t-trainer --problem=librispeech_clean_small --model=transformer --output_dir=/models/JUNK --data_dir=/data/ --save_checkpoints_secs=1800 --schedule=train --hparams_set=transformer_librispeech```\r\n\r\nNote: you'll need to include the ` --generate_data` flag the first time you run to dl and prep the dataset.", "Did a little more testing to try to narrow down in which version of tensorflow this issue crops up...\r\nTesting with T2T 1.13.4:\r\nTF 1.13.2  works\r\nTF 1.14.0+ hangs ", "I'm having trouble reproducing this with the following setup:\r\ntensorflow-gpu: 1.14.0\r\ntensor2tensor: 1.14.0\r\n\r\n$ t2t-trainer --problem=librispeech_clean_small --model=transformer --output_dir=/tmp/t2t_output --data_dir=/tmp/t2t_data/ --save_checkpoints_secs=1800 --schedule=train --hparams_set=transformer_librispeech\r\n\r\n(It runs multiple steps without hanging)\r\n\r\n\r\nAre you encountering this issue with non-gpu tensorflow as well, or just `tensorflow-gpu`? ", "Hmm, just setup a non-gpu container and it _is_ running w/o issue there.  \r\nOf course for production training we need to utilize the GPUs...", "Yup -- just trying to further narrow down the possible sources of this issue. Let me dig into this a little further. Thanks!", "Thanks!\r\n\r\nIn case it is helpful, the host NVIDIA GPU driver I currently have loaded is: 430.34 (I see the current version is 430.50).\r\n\r\nUPDATE: installed 430.50 gpu driver and got same stall behavior", "Could you guys check if you can resume training from checkpoint? I am\ngetting the checkpoint not valid error with this same setup on normal\nruntime.\n\nEm sex, 13 de set de 2019 19:14, Michael Schonwetter <\nnotifications@github.com> escreveu:\n\n> Thanks!\n>\n> In case it is helpful, the host NVIDIA GPU driver I currently have loaded\n> is: 430.34 (I see the current version is 430.50).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32017?email_source=notifications&email_token=AJ6VEEHJVI5AWQZ5M2QHVKLQJQGD5A5CNFSM4IQHWXEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6WJZ6A#issuecomment-531406072>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AJ6VEEBDXBCVINGXZU2FAYTQJQGD5ANCNFSM4IQHWXEA>\n> .\n>\n", "@Victor-Almeida, just tested per your request, with the _non_-gpu version I was able to save a checkpoint, and resume from that checkpoint w/o error. (TF1.14.0, T2T1.14.0)", "In case it helps, I ran with `TF_CPP_MIN_VLOG_LEVEL=2` enabled, and here is the very end of the log (where it hangs):\r\nhttps://pastebin.com/xvxzyXkS", "@rachellim When you are getting a working test:\r\n - Are you testing with the tensorflow/tensorflow:1.14.0-gpu docker image?  \r\n - What NVidia GPU are you using?\r\n\r\nDo you have any other suggestions for how I could help isolate the cause of the hang?", "I managed to get a repro, now trying to get to the bottom of it! (I'm using a GTX 1080 with driver version 430.34)", "Just adding some more findings here.\r\nEnvironments:\r\n- tensorflow: 1.14.0\r\n- tensor2tensor: tried 1.11, 1.13, 1.14, results were the same.\r\n\r\nWhen I use the default hparams set (transformer_librispeech), the training will hang.\r\nI explored the problem specific hparams (defined in tensor2tensor/data_generators/speech_recognition.py) and tried the below changes which can avoid the hang:\r\n- set `audio_add_delta_deltas` from True to `False`\r\nOR\r\n- set `audio_preproc_in_bottom` from False to `True` (this moves the feature generation process from the preprocessing stage to the bottom of the transformer encoder)\r\n\r\nIt looks like the hang is due to some audio feature generation operations in preprocessing stage.  When I removed them from preprocessing, the hang is gone.  Hope this helps in pinpointing the cause.\r\n\r\nIn summary, either of the below can make the training started:\r\n- Use tensorflow-gpu 1.13.2.\r\nOR\r\n- Use tensorflow-gpu 1.14.0, with the above mentioned changes in hparams.\r\n", "Thanks for flagging it and the repro instructions. I found the issue in `parallel_interleave_dataset_op.cc`. Fix: https://github.com/tensorflow/tensorflow/commit/6274f037d4acc9d04cd4aafbda7547a3d89e5674 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32017\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32017\">No</a>\n", "The cause of the hanging here is that `parallel_interleave_dataset_op.cc` doesn't handle iterator creation errors correctly when the `sloppy=True` param is set. This fix above makes it handle the error more gracefully (i.e. it raises an error instead of hanging), but the actual dataset iterator creation error here is:\r\n\r\n```\r\n  (0) Unimplemented:  The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n         [[{{node Conv2D}}]]\r\n  (1) Unimplemented:  The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\r\n         [[{{node Conv2D}}]]\r\n         [[Shape_3/_8]]\r\n```\r\n\r\nin the `preprocessing` function in the t2t code.", "@rachellim Thank you very much for isolating the cause of the hang!\r\n\r\n~Can you clarify if the Unimplemented Conv2D errors are still present after applying fix 6274f03?~\r\n\r\nSpecifically does this (Unimplemented issue) still need to get fixed in the T2T code?\r\n\r\nUPDATE:  By setting `sloppy=False` I can replicate the halt on Conv2D errors.  Do you suggest a new issue to resolve why the same T2T code works fine in TF 1.13.2 but crashes in TF 1.14.0?"]}, {"number": 32016, "title": "Fix broken Jupyter links", "body": "The Jupyter notebooks were moved to the tf models directory recently, and their\nabsence is causing the Docker images for 2.0.0rc0 to fail to build.", "comments": []}, {"number": 32015, "title": "\"File already exists in database: google/protobuf/descriptor.proto\" after TensorFlow import", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.14\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): gcc 5.4.0\r\n- CUDA/cuDNN version: 10.1, 7.5.1\r\n- GPU model and memory: N/A\r\n\r\n**Describe the problem**\r\n\r\nI built TensorFlow 1.14.0 from source. I have a patch to ensure that we build against protobuf 3.6.1 since that is the version that is used across the rest of my firm:\r\n```\r\ndiff --git a/tensorflow/workspace.bzl b/tensorflow/workspace.bzl\r\nindex 55d7eb9371..9a3693818e 100755\r\n--- a/tensorflow/workspace.bzl\r\n+++ b/tensorflow/workspace.bzl\r\n@@ -373,16 +373,17 @@ def tf_workspace(path_prefix = \"\", tf_repo_name = \"\"):\r\n \r\n     # 5902e759108d14ee8e6b0b07653dac2f4e70ac73 is based on 3.7.1 with a fix for BUILD file.\r\n     PROTOBUF_URLS = [\r\n-        \"http://mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/5902e759108d14ee8e6b0b07653dac2f4e70ac73.tar.gz\",\r\n-        \"https://github.com/protocolbuffers/protobuf/archive/5902e759108d14ee8e6b0b07653dac2f4e70ac73.tar.gz\",\r\n+        \"http://mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/48cb18e5c419ddd23d9badcfe4e9df7bde1979b2.tar.gz\",\r\n+        \"https://github.com/protocolbuffers/protobuf/archive/48cb18e5c419ddd23d9badcfe4e9df7bde1979b2.tar.gz\",\r\n     ]\r\n-    PROTOBUF_SHA256 = \"1c020fafc84acd235ec81c6aac22d73f23e85a700871466052ff231d69c1b17a\"\r\n-    PROTOBUF_STRIP_PREFIX = \"protobuf-5902e759108d14ee8e6b0b07653dac2f4e70ac73\"\r\n+    PROTOBUF_SHA256 = \"f5a35e17fb07f3b13517264cd17a089636fcbb2912f9df7bef7414058969a8d2\"\r\n+    PROTOBUF_STRIP_PREFIX = \"protobuf-48cb18e5c419ddd23d9badcfe4e9df7bde1979b2\"\r\n \r\n     tf_http_archive(\r\n         name = \"protobuf_archive\",\r\n         sha256 = PROTOBUF_SHA256,\r\n         strip_prefix = PROTOBUF_STRIP_PREFIX,\r\n+        patch_file = clean_dep(\"//third_party/protobuf:expose-protoc-path.patch\"),\r\n         system_build_file = clean_dep(\"//third_party/systemlibs:protobuf.BUILD\"),\r\n         system_link_files = {\r\n             \"//third_party/systemlibs:protobuf.bzl\": \"protobuf.bzl\",\r\ndiff --git a/third_party/protobuf/expose-protoc-path.patch b/third_party/protobuf/expose-protoc-path.patch\r\nnew file mode 100644\r\nindex 0000000000..8f3f0caff7\r\n--- /dev/null\r\n+++ b/third_party/protobuf/expose-protoc-path.patch\r\n@@ -0,0 +1,24 @@\r\n+diff --git a/protobuf.bzl b/protobuf.bzl\r\n+index 78f19c62..325a952d 100644\r\n+--- a/protobuf.bzl\r\n++++ b/protobuf.bzl\r\n+@@ -109,7 +109,7 @@ def _proto_gen_impl(ctx):\r\n+         inputs=inputs,\r\n+         outputs=ctx.outputs.outs,\r\n+         arguments=args + import_flags + [s.path for s in srcs],\r\n+         mnemonic=\"ProtoCompile\",\r\n+         use_default_shell_env=True,\r\n+     )\r\n+@@ -266,8 +266,8 @@ def internal_gen_well_known_protos_java(srcs):\r\n+   Args:\r\n+     srcs: the well known protos\r\n+   \"\"\"\r\n+-  root = Label(\"%s//protobuf_java\" % (REPOSITORY_NAME)).workspace_root\r\n+-  pkg = PACKAGE_NAME + \"/\" if PACKAGE_NAME else \"\"\r\n++  root = Label(\"%s//protobuf_java\" % (native.repository_name())).workspace_root\r\n++  pkg = PACKAGE_NAME + \"/\" if native.package_name() else \"\"\r\n+   if root == \"\":\r\n+     include = \" -I%ssrc \" % pkg\r\n+   else:\r\n```\r\n\r\nWe have another library that is dynamically linked against libprotobuf.so. When you load the other library and then TensorFlow, everything works as expected:\r\n```python\r\nPython 3.6.8 (default, Aug  9 2019, 04:47:37) \r\n[GCC 4.7.2] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import celfs\r\n>>> import tensorflow as tf\r\n2019-08-27 16:12:09.162189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0827 16:12:11.169919 140361581864704 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\n>>> \r\n```\r\n\r\nHowever, if I load TensorFlow and then the other library, I get the following error:\r\n```python\r\nPython 3.6.8 (default, Aug  9 2019, 04:47:37) \r\n[GCC 4.7.2] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2019-08-27 16:07:30.536598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0827 16:07:32.523208 139698008938240 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\n>>> import celfs\r\n[libprotobuf ERROR external/protobuf_archive/src/google/protobuf/descriptor_database.cc:58] File already exists in database: google/protobuf/descriptor.proto\r\n[libprotobuf FATAL external/protobuf_archive/src/google/protobuf/descriptor.cc:1358] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\nterminate called after throwing an instance of 'google::protobuf::FatalException'\r\n  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\nAborted\r\n```\r\n\r\nShould I be linking protobuf dynamically for TensorFlow as well?", "comments": ["I'm afraid we don't provide support on GitHub for these kinds of patches. Generally speaking, dynamically linking libraries like this can lead to unexpected results (like this).\r\n\r\nSince this issue tracker is only for official support, please ask about this elsewhere (Stack Overflow, for example, is much better to help out other users with similar issues). ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32015\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32015\">No</a>\n", "Totally understandable. Thanks anyway, Austin!", "Hi:\r\nDid you fix this bug? I have a similar bug too but I can't fix it with any solution I found..", "> Hi:\r\n> Did you fix this bug? I have a similar bug too but I can't fix it with any solution I found..\r\n\r\nHi\uff0cI got the same bug, Have you fixed it ?", "Same here any solution?", "This looks very similar to https://github.com/google/or-tools/issues/1830 - `python can only load one Protobuf native shared library`. I had the same issue when trying to import both a python tf-based library and a swig-based binary which uses TF as well. I had to make a cut-down version of the python library that does NOT import TF at all - luckily I only need it for some simple data containers / filesystem abstraction (so far, at least :crossed_fingers:)", "It's should be a link error(repeated link), I have fixed the same error in https://github.com/deepmind/reverb/pull/24/commits/f4f9308dea9c4f62bf6f48713b0267e30412a557"]}, {"number": 32014, "title": "TF 1.14 : assgin Variable in loss function can't update value ? ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from : binary\r\n- TensorFlow version :  tensorflow-gpu 1.14.0\r\n- Python version: python 3.7.1\r\n- CUDA/cuDNN version: CUDA 10.1 cuDNN 7.5\r\n- GPU model and memory: GTX 2060 6G\r\n\r\n**Question**\r\n\r\nI customize the loss function in tf. keras and use a variable to output part of the loss to metric. What puzzles me is that in normal custom metrics, direct assgin variables give the correct output, but in loss functions, I have to call the assgin operator to get the normal output.\r\n\r\n**Describe the current behavior**\r\nnow code :\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\nimport tensorflow.keras.layers as kl\r\nimport tensorflow.keras.metrics as km\r\nfrom tensorflow.keras.datasets import fashion_mnist\r\n\r\ntfcfg = tf.ConfigProto()\r\ntfcfg.gpu_options.allow_growth = True\r\nsess = tf.Session(config=tfcfg)\r\nk.backend.set_session(sess)\r\n\r\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\nx_train = x_train.reshape((-1, 28, 28, 1))\r\nx_test = x_test.reshape((-1, 28, 28, 1))\r\ny_train = k.utils.to_categorical(y_train, 10)\r\ny_test = k.utils.to_categorical(y_test, 10)\r\n\r\n\r\nmodel = k.Sequential([\r\n    kl.Conv2D(32, 3, 1, input_shape=[28, 28, 1]),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.Conv2D(64, 3, 1),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.Conv2D(128, 3, 1),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.LeakyReLU(),\r\n    kl.Flatten(),\r\n    kl.Dense(512),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.Dense(10)\r\n])\r\n\r\n\r\nclass Metric_HIGH_COST(km.Metric):\r\n    def __init__(self, name=None, dtype=None, **kwargs):\r\n        super().__init__(name=name, dtype=dtype, **kwargs)\r\n        self.ce = self.add_weight('ce', initializer=tf.zeros_initializer)\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        self.ce.assign(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)))\r\n\r\n    def result(self):\r\n        return self.ce\r\n\r\n\r\nclass Metric_LOW_COST(km.Metric):\r\n    def __init__(self, cross_entropy: tf.Variable, name='CE', dtype=None):\r\n        \"\"\" yolo landmark error metric\r\n\r\n        Parameters\r\n        ----------\r\n        MeanMetricWrapper : [type]\r\n\r\n        landmark_error : ResourceVariable\r\n            a variable from yoloalign loss\r\n        name : str, optional\r\n            by default 'LE'\r\n        dtype : [type], optional\r\n            by default None\r\n        \"\"\"\r\n        super().__init__(name=name)\r\n        self.ce = cross_entropy\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        self.ce\r\n\r\n    def result(self):\r\n        return self.ce.read_value()\r\n\r\n\r\nclass Myloss(k.losses.Loss):\r\n    def __init__(self, name=None):\r\n        super().__init__(name=name)\r\n        self.ce = tf.get_variable('ce', (), tf.float32, tf.zeros_initializer)  # type:tf.RefVariable\r\n\r\n    def call(self, y_true, y_pred):\r\n        ce_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\r\n\r\n        # ! method 1 got zero output :\r\n        self.ce.assign(ce_loss)\r\n        return ce_loss\r\n\r\n        # ! method 2 get correct output :\r\n        # return ce_loss + 0 * self.ce.assign(ce_loss)\r\n\r\n\r\nmyloss = Myloss()\r\nhigh_cost_metric = Metric_HIGH_COST('high_cost_ce')\r\nlow_cost_metric = Metric_LOW_COST(myloss.ce, 'low_cost_ce')\r\n\r\nsess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\r\n\r\nmodel.compile(k.optimizers.Adam(), [myloss], [high_cost_metric, low_cost_metric])\r\n\r\nmodel.fit(x_train, y_train, 100, 10)\r\n\r\n```\r\n\r\n**output `low_cost_ce`  always `0`**: \r\n\r\n```sh\r\n11700/60000 [====>.........................] - ETA: 24s - loss: 175.2779 - high_cost_ce: 67.9055 - low_cost_ce: 0.0000e+00\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nnew code:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\nimport tensorflow.keras.layers as kl\r\nimport tensorflow.keras.metrics as km\r\nfrom tensorflow.keras.datasets import fashion_mnist\r\n\r\ntfcfg = tf.ConfigProto()\r\ntfcfg.gpu_options.allow_growth = True\r\nsess = tf.Session(config=tfcfg)\r\nk.backend.set_session(sess)\r\n\r\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\nx_train = x_train.reshape((-1, 28, 28, 1))\r\nx_test = x_test.reshape((-1, 28, 28, 1))\r\ny_train = k.utils.to_categorical(y_train, 10)\r\ny_test = k.utils.to_categorical(y_test, 10)\r\n\r\n\r\nmodel = k.Sequential([\r\n    kl.Conv2D(32, 3, 1, input_shape=[28, 28, 1]),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.Conv2D(64, 3, 1),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.Conv2D(128, 3, 1),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.LeakyReLU(),\r\n    kl.Flatten(),\r\n    kl.Dense(512),\r\n    kl.BatchNormalization(),\r\n    kl.LeakyReLU(),\r\n    kl.Dense(10)\r\n])\r\n\r\n\r\nclass Metric_HIGH_COST(km.Metric):\r\n    def __init__(self, name=None, dtype=None, **kwargs):\r\n        super().__init__(name=name, dtype=dtype, **kwargs)\r\n        self.ce = self.add_weight('ce', initializer=tf.zeros_initializer)\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        self.ce.assign(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)))\r\n\r\n    def result(self):\r\n        return self.ce\r\n\r\n\r\nclass Metric_LOW_COST(km.Metric):\r\n    def __init__(self, cross_entropy: tf.Variable, name='CE', dtype=None):\r\n        \"\"\" yolo landmark error metric\r\n\r\n        Parameters\r\n        ----------\r\n        MeanMetricWrapper : [type]\r\n\r\n        landmark_error : ResourceVariable\r\n            a variable from yoloalign loss\r\n        name : str, optional\r\n            by default 'LE'\r\n        dtype : [type], optional\r\n            by default None\r\n        \"\"\"\r\n        super().__init__(name=name)\r\n        self.ce = cross_entropy\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        self.ce\r\n\r\n    def result(self):\r\n        return self.ce.read_value()\r\n\r\n\r\nclass Myloss(k.losses.Loss):\r\n    def __init__(self, name=None):\r\n        super().__init__(name=name)\r\n        self.ce = tf.get_variable('ce', (), tf.float32, tf.zeros_initializer)  # type:tf.RefVariable\r\n\r\n    def call(self, y_true, y_pred):\r\n        ce_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\r\n\r\n        # ! method 1 got zero output :\r\n        # self.ce.assign(ce_loss)\r\n        # return ce_loss\r\n\r\n        # ! method 2 get correct output :\r\n        return ce_loss + 0 * self.ce.assign(ce_loss)\r\n\r\n\r\nmyloss = Myloss()\r\nhigh_cost_metric = Metric_HIGH_COST('high_cost_ce')\r\nlow_cost_metric = Metric_LOW_COST(myloss.ce, 'low_cost_ce')\r\n\r\nsess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\r\n\r\nmodel.compile(k.optimizers.Adam(), [myloss], [high_cost_metric, low_cost_metric])\r\n\r\nmodel.fit(x_train, y_train, 100, 10)\r\n```\r\n\r\n```sh\r\n11500/60000 [====>.........................] - ETA: 24s - loss: 172.6385 - high_cost_ce: 85.5574 - low_cost_ce: 171.8945     \r\n```\r\n\r\n#### Why do you have to call the assgin operator in the loss function to update variables?Is this a bug? \r\n\r\n\r\n", "comments": ["@zhen8838, Will it be possible to provide the code without importing tensorflow.python. Applicable to all imports.   When i tried replicating the issue i received the following error\r\n`AttributeError: module 'tensorflow' has no attribute 'python'`\r\nThanks!", "> @zhen8838, Will it be possible to provide the code without importing tensorflow.python. Applicable to all imports. When i tried replicating the issue i received the following error\r\n> `AttributeError: module 'tensorflow' has no attribute 'python'`\r\n> Thanks!\r\n\r\nSorry , I have update the code. now you can run above code in tf1.14", "I don't know why. In my computer can use `import tensorflow.python as tf`, but in some people's computers got error `AttributeError: module 'tensorflow' has no attribute 'python'`. I'm very sorry that this problem has wasted your time.", "@zhen8838, Thanks for updating the code. \r\n```\r\nimport tensorflow.python.keras as k\r\nimport tensorflow.python.keras.layers as kl\r\nfrom tensorflow.python.keras.utils import losses_utils\r\nimport tensorflow.python.keras.metrics as km\r\nfrom tensorflow.python.keras.datasets import fashion_mnist\r\n```\r\nCould you please change these imports also. \r\nThanks!", "@gadagashwini The code has been updated. Please let me know if you have any questions.", "@zhen8838, Thanks for your update. I could replicate the reported issue. Please take a look at colab gist of [current behavior](https://colab.research.google.com/drive/1BaY8cvaNbX02jWeVyVZY22ITxld_Js4c)  and [expected behavior](https://colab.research.google.com/drive/12MdBxthmu7Urnd8UUuYheXvYXYNnh_EF). \r\nThanks!", "@zhen8838 I think parts of the code need to be updated. Can you please check this [guide](https://www.tensorflow.org/guide/keras/train_and_evaluate) and update custom metric and custom loss.\r\n\r\nPlease feel free to close the issue if this was already resolved for you. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32014\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32014\">No</a>\n"]}, {"number": 32013, "title": "CustomOp segfaults using work sharder on MacOS with TF1.13.1", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): from pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nWhen running a simple custom-op on CPU adapted from the tutorial with multiple threads using work sharder it can find only 1 thread and segfaults.\r\n\r\n**Describe the expected behavior**\r\nShould find 12 threads and runs.\r\n\r\n**Code to reproduce the issue**\r\nminimal.cc\r\n```c++\r\n #include <stdio.h>\r\n#include <cfloat>\r\n\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include \"tensorflow/core/framework/tensor_shape.h\"\r\n\r\n#include \"./work_sharder.h\"\r\n\r\nusing namespace tensorflow;\r\ntypedef Eigen::ThreadPoolDevice CPUDevice;\r\n\r\nREGISTER_OP(\"Minimal\")\r\n    .Input(\"input: float\")\r\n    .Output(\"shared_arr: float\")\r\n;\r\n\r\nclass MinimalOp : public OpKernel {\r\n public:\r\n  explicit MinimalOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n\r\n    const Tensor& input= context->input(0);\r\n    auto input_flat = input.flat<float>();\r\n    const int N = input_flat.size();\r\n\r\n    // Create an output tensor of the right shape\r\n    Tensor* shared_arr = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, input.shape(),\r\n                                                     &shared_arr));\r\n    // This tensor is going to be shared among threads\r\n    auto shared_arr_flat = shared_arr->flat<float>();\r\n\r\n    // Shard function on ranges\r\n    auto shard = [&input_flat, &shared_arr_flat]\r\n                  (int64 start, int64 limit) {\r\n        for (int i = 0; start < limit; i++) {\r\n            if ((input_flat(i))<0.){\r\n                shared_arr_flat(i) = 0.;\r\n            }}};\r\n\r\n    std::cout<<\"Shard definition was okay\\n\";\r\n    const DeviceBase::CpuWorkerThreads& worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\r\n    std::cout<<\"Number of workers = \"<<worker_threads.num_threads<<\"\\n\";\r\n    const int64 shard_cost = N;\r\n    Shard(worker_threads.num_threads, worker_threads.workers,\r\n            N, shard_cost, shard);\r\n\r\n  }};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"Minimal\").Device(DEVICE_CPU), MinimalOp);\r\n```\r\ncompiling commands:\r\n```\r\nTF_CFLAGS=( $(python3 -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\r\nTF_LFLAGS=( $(python3 -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\r\ng++ -std=c++11 -shared -undefined dynamic_lookup minimal.cc -o minimal.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2\r\n```\r\nPython script:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n\r\nminimal_module = tf.load_op_library(\"./minimal.so\")\r\ntf_minimal = minimal_module.minimal\r\n\r\ninput_tensor = tf.constant(np.random.normal(size=(100, 100)).astype(\"float32\"))\r\nreturned_tensor = tf_minimal(input_tensor)\r\nsess = tf.Session()\r\nsess.run(returned_tensor)\r\n```\r\n**Other info / logs**\r\nhttps://stackoverflow.com/questions/57427277/tensorflow-customop-multiprocessing-not-working-for-cpu\r\nMaybe related issue: \r\nhttps://github.com/tensorflow/tensorflow/issues/13308\r\ngcc is clang: \r\ng++ --version\r\n```\r\nConfigured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.1 (clang-1001.0.46.3)\r\nTarget: x86_64-apple-darwin18.2.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```\r\n", "comments": ["I am trying to use gcc4.9 as indicated in this other issue #13308 but encounters another problem (but it might be due to my brittle install of gcc4.9).", "Any update on this ?", "Up !", "Up !", "Up !", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32013\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32013\">No</a>\n"]}, {"number": 32012, "title": "Typos in Ftrl get_config", "body": "_serializer_hyperparameter -> _serialize_hyperparameter\r\n\r\nin two places", "comments": ["Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac", "Where is \"master\" for 1.14? Is this it: https://github.com/tensorflow/tensorflow/tree/r1.15", "There is only one `master` branch, all commits should go there.\r\n\r\nThe `rX.Y` (e.g. `r1.14`) branches are release branches, we use them to do the X.Y main TensorFlow release (eg Tensorflow 1.14). After that release, we only do patch releases if there are security vulnerabilities. That is, X.Y.1 (e.g., 1.14.1) are released extremely rarely.\r\n\r\nBecause of this process, we cannot accept pull requests on release branches, except if the branch is the currently active one (i.e., a final release is incoming, see `r1.15` and `r2.0` for TensorFlow 1.15 and TensorFlow 2.0 releases) AND the PR is a cherry-pick of a fix already on `master`. \r\n\r\nAll other contributions to release branches are gated by the need of making a security patch release.", "Ok, thanks for the info."]}, {"number": 32011, "title": "Enabled third party Mellanox TensorFlow CI", "body": "See added README section for details about additional on demand TensorFlow CI by Mellanox.", "comments": ["bot:mlx:test", "Mellanox CI PASSed.\n", "<details><summary>Mellanox CI status: <b>PASS</b#  > (click for details)</summary>\n\n**Note:** the artefacts will be deleted after 03-Sep-2019\n\nArtefact file | Status\n-- | --\n[build_nccl.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/09456cda43cc9d82da0fb4d696078f1833a82b37/build_nccl.log) | :heavy_check_mark: PASS\n[build_tf.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/23532c57d35af5f95e5a62a5b3694ea32147e6f3/build_tf.log) | :heavy_check_mark: PASS\n[build_tf_launcher.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/0358033d24edabaf3305d2b8e65eb3f8f6b75e03/build_tf_launcher.log) | :heavy_check_mark: PASS\n[ml-tf-test-launcher.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/a81881768230924f1ae37962c49a28a9e6b7cee3/ml-tf-test-launcher.log) | :heavy_check_mark: PASS\n[run_nccl_test.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/127b297a690c68dd90c507b3367c383c1dccf2a8/run_nccl_test.log) | :heavy_check_mark: PASS\n[run_tf_cnn_benchmarks.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/5d076e308e5c69ba793e340044539cc4fc093917/run_tf_cnn_benchmarks.log) | :heavy_check_mark: PASS\n[run_tf_models_imagenet_launcher.log](https://gist.githubusercontent.com/mellanox-github/9a47e5566840e998e966ef859771a80a/raw/27d0bad53c73dd33dfa12fd62436e0e0502bf34b/run_tf_models_imagenet_launcher.log) | :heavy_check_mark: PASS\n"]}, {"number": 32010, "title": "NotImplementedError in Distributed tensorflow with parameter_server", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0rc\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:  cuda 10.0/ cudnn 7.6\r\n- GPU model and memory: Tesla, 24gb per gpg\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nHi, i am using this script resnet_cifar_main.py in https://github.com/tensorflow/models/tree/master/official/vision/image_classification to test parameter distributed strategy. I have added some codes to configure cluster in this file as follows\r\n```\r\nimport os\r\n import json\r\n tf.compat.v1.disable_eager_execution() # if not, it will raise error\r\nos.environ[\"TF_CONFIG\"] = json.dumps({\r\n      'cluster': {\r\n        'ps' : [\"100.102.32.179:8080\"],\r\n        'worker':  [\"100.102.33.40:8080\"]\r\n                  },\r\n         'task': # {'type':'ps', 'index':0} # for the ps sever\r\n            {'type': 'worker', 'index': 0}\r\n          })\r\n```\r\nfor the ps server, i have done the similar things. \r\ni use the following command to run .\r\n`python resnet_cifar_main.py --data_dir cifar-10-batches-bin/ --distribution_strategy parameter_server`.\r\nIt works when i set only one gpu avaiable. that is,\r\n```\r\nexport CUDA_VISIBLE_DEVICES=0\r\n```\r\nHowever, when i set all gpu avaiable, it fails with the following error log.\r\n```\r\n/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n2019-08-27 21:20:21.718509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-08-27 21:20:21.771457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:04:00.0\r\n2019-08-27 21:20:21.772876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:05:00.0\r\n2019-08-27 21:20:21.774307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:08:00.0\r\n2019-08-27 21:20:21.775831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:09:00.0\r\n2019-08-27 21:20:21.777206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:84:00.0\r\n2019-08-27 21:20:21.778613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:85:00.0\r\n2019-08-27 21:20:21.780023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:88:00.0\r\n2019-08-27 21:20:21.781431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:89:00.0\r\n2019-08-27 21:20:21.781638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-27 21:20:21.783058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-08-27 21:20:21.784468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-08-27 21:20:21.784759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-08-27 21:20:21.786481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-08-27 21:20:21.787803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-08-27 21:20:21.791692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-08-27 21:20:21.813851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\n2019-08-27 21:20:21.814258: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-27 21:20:21.823038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399910000 Hz\r\n2019-08-27 21:20:21.824902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b04056a20 executing computations on platform Host. Devices:\r\n2019-08-27 21:20:21.824934: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-08-27 21:20:23.267705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b03884990 executing computations on platform CUDA. Devices:\r\n2019-08-27 21:20:23.267737: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267744: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267749: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267755: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267760: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (4): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267766: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (5): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267771: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (6): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.267776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (7): Tesla M40 24GB, Compute Capability 5.2\r\n2019-08-27 21:20:23.277272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:04:00.0\r\n2019-08-27 21:20:23.278704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:05:00.0\r\n2019-08-27 21:20:23.280111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:08:00.0\r\n2019-08-27 21:20:23.281511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:09:00.0\r\n2019-08-27 21:20:23.282918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:84:00.0\r\n2019-08-27 21:20:23.284400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:85:00.0\r\n2019-08-27 21:20:23.285821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:88:00.0\r\n2019-08-27 21:20:23.287255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: \r\nname: Tesla M40 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.112\r\npciBusID: 0000:89:00.0\r\n2019-08-27 21:20:23.287327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-27 21:20:23.287349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-08-27 21:20:23.287374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-08-27 21:20:23.287398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-08-27 21:20:23.287416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-08-27 21:20:23.287434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-08-27 21:20:23.287452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-08-27 21:20:23.309337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\n2019-08-27 21:20:23.309395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-08-27 21:20:23.321783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-08-27 21:20:23.321864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 5 6 7 \r\n2019-08-27 21:20:23.321876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N N N N \r\n2019-08-27 21:20:23.321885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N N N N \r\n2019-08-27 21:20:23.321900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N N N N \r\n2019-08-27 21:20:23.321908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N N N N \r\n2019-08-27 21:20:23.321916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N Y Y Y \r\n2019-08-27 21:20:23.321930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 5:   N N N N Y N Y Y \r\n2019-08-27 21:20:23.321944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 6:   N N N N Y Y N Y \r\n2019-08-27 21:20:23.321959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 7:   N N N N Y Y Y N \r\n2019-08-27 21:20:23.337402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13843 MB memory) -> physical GPU (device: 0, name: Tesla M40 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.339205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 16016 MB memory) -> physical GPU (device: 1, name: Tesla M40 24GB, pci bus id: 0000:05:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.340928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 16166 MB memory) -> physical GPU (device: 2, name: Tesla M40 24GB, pci bus id: 0000:08:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.342575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15535 MB memory) -> physical GPU (device: 3, name: Tesla M40 24GB, pci bus id: 0000:09:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.344296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 13420 MB memory) -> physical GPU (device: 4, name: Tesla M40 24GB, pci bus id: 0000:84:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.345968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 16228 MB memory) -> physical GPU (device: 5, name: Tesla M40 24GB, pci bus id: 0000:85:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.347619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 15985 MB memory) -> physical GPU (device: 6, name: Tesla M40 24GB, pci bus id: 0000:88:00.0, compute capability: 5.2)\r\n2019-08-27 21:20:23.349287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 16314 MB memory) -> physical GPU (device: 7, name: Tesla M40 24GB, pci bus id: 0000:89:00.0, compute capability: 5.2)\r\nI0827 21:20:23.353662 139753917540160 parameter_server_strategy.py:250] Multi-worker ParameterServerStrategy with cluster_spec = {'ps': ['100.102.32.179:8080'], 'worker': ['100.102.33.40:8080']}, task_type = 'worker', task_id = 0, num_ps_replicas = 1, is_chief = True, device_map = ReplicaDeviceMap(['/job:worker/replica:0/task:0/device:GPU:0', '/job:worker/replica:0/task:0/device:GPU:1', '/job:worker/replica:0/task:0/device:GPU:2', '/job:worker/replica:0/task:0/device:GPU:3', '/job:worker/replica:0/task:0/device:GPU:4', '/job:worker/replica:0/task:0/device:GPU:5', '/job:worker/replica:0/task:0/device:GPU:6', '/job:worker/replica:0/task:0/device:GPU:7']), variable_device = <bound method _ReplicaDeviceChooser.device_function of <tensorflow.python.training.device_setter._ReplicaDeviceChooser object at 0x7f1a966e84e0>>\r\nContrib missing: Skip remove monkey patch tf.contrib.distribute.*\r\nW0827 21:20:23.734989 139753917540160 deprecation.py:323] From /data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nDeprecated in favor of operator or tf.math.divide.\r\nW0827 21:20:23.736282 139753917540160 deprecation.py:323] From /data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py:332: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nW0827 21:20:23.800738 139753917540160 deprecation.py:506] From /data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"resnet_cifar_main_dist_ps_remote_0.py\", line 260, in <module>\r\n    absl_app.run(main)\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"resnet_cifar_main_dist_ps_remote_0.py\", line 254, in main\r\n    return run(flags.FLAGS)\r\n  File \"resnet_cifar_main_dist_ps_remote_0.py\", line 173, in run\r\n    model = resnet_cifar_model.resnet56(classes=cifar_preprocessing.NUM_CLASSES)\r\n  File \"/data1/wayneweixu/models/official/vision/image_classification/resnet_cifar_model.py\", line 227, in resnet\r\n    name='conv1')(x)\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 777, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2099, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 165, in build\r\n    dtype=self.dtype)\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2269, in __setattr__\r\n    if val.trainable:\r\n  File \"/data1/wayneweixu/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 476, in trainable\r\n    raise NotImplementedError\r\nNotImplementedError\r\n```\r\nhow can i fix this error? thanks a lot.\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Parameter Server strategy is post 2.0. please look at the below link to find whats supported in 2.0 and Distribution Strategy.\r\nhttps://www.tensorflow.org/beta/guide/distribute_strategy#whats_supported_now", "> Parameter Server strategy is post 2.0. please look at the below link to find whats supported in 2.0 and Distribution Strategy.\r\n> https://www.tensorflow.org/beta/guide/distribute_strategy#whats_supported_now\r\n\r\nI see that \r\n> In TF 2.0 beta release, we support training with Keras using MirroredStrategy, CentralStorageStrategy and MultiWorkerMirroredStrategy. Both CentralStorageStrategy and MultiWorkerMirroredStrategy are currently experimental APIs and are subject to change. Support for other strategies will be coming soon. The API and how to use will be exactly the same as above.\r\n\r\nHowever, i am using tf 2.0 rc. I am not sure that whether parameter server strategy is supported in tf2.0 rc. But i can run in ps strategy  when i let only one gpu avaiable. Could you explain why for one gpu it works, but failed with multiple gpus.", "Hello, \r\nsorry if the earlier message was not clear, but Parameter Server support will be added in post 2.0.0 releases, so 2.0rc0 does not have it yet. That could be the reason why multi gpu is not working. \r\n", "> Hello,\r\n> sorry if the earlier message was not clear, but Parameter Server support will be added in post 2.0.0 releases, so 2.0rc0 does not have it yet. That could be the reason why multi gpu is not working.\r\n\r\nThanks for you help :-).\r\nI can close this issue now."]}, {"number": 32009, "title": "[C++] The SessionOptions doesn't control the usage of CPU ?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, only use C++ API\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.14\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): GCC 5.5\r\n- CUDA/cuDNN version: only CPU\r\n- GPU model and memory: only CPU\r\n\r\n**Describe the current behavior**\r\nI created a session option with inter=1 and intra=1. Then I used this option to create a session and load a model.\r\nWhen I run the model, the program used almost all the CPUs in my server(the CPU usage is more than 5000%).\r\nAnd No matter what value I set to \"inter\" and \"intra\", the CPU usage is more than 5000%.\r\n\r\n**Describe the expected behavior**\r\nWhen I set inter=1 and intra=1, I expect the usage of CPU is limited to <= 100%.\r\n\r\n**Code to reproduce the issue**\r\n\r\n    std::unique_ptr<tensorflow::Session> sess_;\r\n    tensorflow::SessionOptions sess_options_;\r\n    sess_options_.config.set_use_per_session_threads(false);\r\n    sess_options_.config.set_intra_op_parallelism_threads(1);\r\n    sess_options_.config.set_inter_op_parallelism_threads(1);\r\n    sess_.reset(tensorflow::NewSession(sess_options_));\r\n    tensorflow::GraphDef graph_def;\r\n    auto default_env = tensorflow::Env::Default();\r\n    tensorflow::ReadBinaryProto(default_env, model_path, &graph_def);\r\n    sess_->Create(graph_def);\r\n    run_model();\r\n\r\n**Other info / logs**\r\nWhen I use the python API of TensorFlow 1.14 do the same thing, it seems like the CPU usage can be controlled by the inter and intra parameter.\r\n\r\nWhy did this happen? What's the right way to control the computing resources used by tensorflow?\r\n", "comments": ["I found some other problems in my environment, and I will reopen this when I have confirmed the problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32009\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32009\">No</a>\n", "> I found some other problems in my environment, and I will reopen this when I have confirmed the problem.\r\n\r\nHi JiayiFu, have you solved the issue? If it is solved, could you please let me know what changes did you make? Thanks.", "> > I found some other problems in my environment, and I will reopen this when I have confirmed the problem.\r\n> \r\n> Hi JiayiFu, have you solved the issue? If it is solved, could you please let me know what changes did you make? Thanks.\r\n\r\n@Binbin16 I saw your email and write a reply to you. "]}, {"number": 32008, "title": "[lite] [micro] Refactor allocator interfaces & pass info about intermediate allocs", "body": "Refactors allocator interfaces to allow for future memory allocators to be swapped in.\r\n\r\nSummary of changes:\r\n* Move code that should be useful to all allocators out of `SimpleTensorAllocator` to `allocator_utils` (new).\r\n* Move `TfLiteTensor` struct initialisation logic out of `SimpleTensorAllocator` to `MicroAllocator` (useful for all allocators).\r\n* Change tensor lifetime computation (create before op / destroy after op) to be a bit more straightforward and add explanatory constants.\r\n* Change `MicroInterpreter` to inform `MicroAllocator` when an op has start & finished executing.\r\n* Allocate and deallocate tensor data based on the above (currently calls `SimpleTensorAllocator` which is a no-op in most cases)\r\n* Add `MicroAllocator` tests.\r\n* Simplify `SimpleTensorAllocator` to do just memory buffer management. Allocators now also receive a `TfLiteContext` if they need to move tensors around to make space.\r\n* Refactor `SimpleTensorAllocator` tests to match it's current functionality. ", "comments": ["There's a coming allocator change that supersedes this, so I'm closing the PR."]}, {"number": 32007, "title": ".a library file is not working on android platform while using tf lite with c++ api.", "body": "I am trying to make an android project using tensorflow lite, I want to use lite api in c++ level, however the examples in the repository are all using java api.\r\n\r\nAs the guidance tf lite can be applied in both java level and c++ level, but the .a library is not working. \r\n\r\nI built the libtensorflow-lite.a following the https://tensorflow.google.cn/lite/guide/build_arm64, but it seems this .a file is not working on android platform. Anyone can give me some advices about how to build a available .so library file for me to use c++ api in a android project?\r\n\r\nThanks a lot!\r\n", "comments": ["@devin730 ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\n\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here or Error being faced.Thanks!\r\n\r\n", "> \r\n> \r\n> @devin730 ,\r\n> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\n> \r\n> In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here or Error being faced.Thanks!\r\n\r\nThanks for your reply, I am making android app with Android Studio on windows 10 system. The target is an Arm64 developing board(however I think it does not matter because built failed not runing failed on board). The TesorFlow version I used is the latest code in github, and I built the libtensorflow-lite.a following the https://tensorflow.google.cn/lite/guide/build_arm64. The library file .a is obtained successfully, my code is exactly done as the tensorflow/tensorflow/lite/examples/minimal.cc and tensorflow/tensorflow/lite/examples/label_image.cc shows.\r\n\r\n However, when I build my project, I meet errors that functions in tensorflow lite all lack some system standard library. As shown below:\r\n\r\n```\r\nBuild command failed.\r\n\r\nError while executing process F:\\Sdk\\Sdk\\cmake\\3.6.4111459\\bin\\cmake.exe with arguments {--build F:\\AIgroup\\app\\.externalNativeBuild\\cmake\\debug\\arm64-v8a --target AgeGenderEstimation}\r\n[1/2] Building CXX object CMakeFiles/AgeGenderEstimation.dir/AgeGenderEstimation/age_gender_estimation.cpp.o\r\nclang++.exe: warning: -Z-reserved-lib-stdc++: 'linker' input unused [-Wunused-command-line-argument]\r\n\r\n[2/2] Linking CXX shared library F:\\AIgroup\\app\\build\\intermediates\\cmake\\debug\\obj\\arm64-v8a\\libAgeGenderEstimation.so\r\nFAILED: cmd.exe /C \"cd . && F:\\Sdk\\Sdk\\ndk-bundle\\toolchains\\llvm\\prebuilt\\windows-x86_64\\bin\\clang++.exe  --target=aarch64-none-linux-android21 --gcc-toolchain=F:/Sdk/Sdk/ndk-bundle/toolchains/llvm/prebuilt/windows-x86_64 --sysroot=F:/Sdk/Sdk/ndk-bundle/toolchains/llvm/prebuilt/windows-x86_64/sysroot -fPIC -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -Wa,--noexecstack -Wformat -Werror=format-security -stdlib=libc++ -std=c++11 -fexceptions -frtti -lstdc++ -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--warn-shared-textrel -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments -Wl,-z,noexecstack -Wl,-z,relro -Wl,-z,now -shared -Wl,-soname,libAgeGenderEstimation.so -o F:\\AIgroup\\app\\build\\intermediates\\cmake\\debug\\obj\\arm64-v8a\\libAgeGenderEstimation.so CMakeFiles/AgeGenderEstimation.dir/AgeGenderEstimation/age_gender_estimation.cpp.o  F:/AIgroup/libfacedetection_tengine/app/src/main/cpp/../../../../app/src/main/jniLibs/arm64-v8a/libtensorflow-lite.a F:/AIgroup/libfacedetection_tengine/app/src/main/cpp/../../../../app/src/main/jniLibs/arm64-v8a/libopencv_java4.so F:/AIgroup/libfacedetection_tengine/app/build/intermediates/cmake/debug/obj/arm64-v8a/liblogger.so -llog -latomic -lm && cd .\"\r\nF:/AIgroup/libfacedetection_tengine/app/src/main/cpp/../../../../app/src/main/jniLibs/arm64-v8a/libtensorflow-lite.a(activations.o): In function `void tflite::ops::builtin::activations::(anonymous namespace)::PopulateLookupTable<unsigned char>(tflite::ops::builtin::activations::OpData*, TfLiteTensor const*, TfLiteTensor*, std::function<float (float)> const&) [clone .isra.60]':\r\n\r\nactivations.cc:(.text.unlikely+0x88): undefined reference to `std::__throw_bad_function_call()'\r\n\r\nF:/AIgroup/libfacedetection_tengine/app/src/main/cpp/../../../../app/src/main/jniLibs/arm64-v8a/libtensorflow-lite.a(activations.o): In function `void tflite::ops::builtin::activations::(anonymous namespace)::PopulateLookupTable<signed char>(tflite::ops::builtin::activations::OpData*, TfLiteTensor const*, TfLiteTensor*, std::function<float (float)> const&) [clone .isra.61]':\r\n\r\nactivations.cc:(.text.unlikely+0x19c): undefined reference to `std::__throw_bad_function_call()'\r\n\r\nF:/AIgroup/libfacedetection_tengine/app/src/main/cpp/../../../../app/src/main/jniLibs/arm64-v8a/libtensorflow-lite.a(activations.o): In function `_GLOBAL__sub_I_activations.cc':\r\n\r\nactivations.cc:(.text.startup+0x18): undefined reference to `std::ios_base::Init::Init()'\r\n\r\nactivations.cc:(.text.startup+0x1c): undefined reference to `std::ios_base::Init::~Init()'\r\n\r\nactivations.cc:(.text.startup+0x2c): undefined reference to ``std::ios_base::Init::~Init()` \r\n```", "Hi, this problem is solved,\r\n\r\nmy college used android NDK to compile a .so library file with provided source files in tf-lite reposity.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32007\">No</a>\n"]}]