[{"number": 30636, "title": "[Mirrored Strategy] You dataset iterator ran out of data; interrupting training. ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):Pip tensorflow-gpu 2.0 beta1\r\n- TensorFlow version (use command below):2.0 beta1\r\n- Python version:3.7\r\n- GPU model and memory:Titan RTX x 2 (2 x 24GB) / P100 x 2 (2 x 16GB)\r\n\r\nError in keras.Model.fit.\r\nWhen using the mirroredstrategy with tensorflow dataset in both training and validation.\r\nSingle GPU card works fine, whether using the mirroredstertegy or not. (When using the mirroredstertegy, set the devices = /gpu:0). This problem only occurs when using multiple gpu cards.\r\n\r\nThe error displayed:\r\n[training_arrays.py 325] Your dataset iterator ran out of data; interrupting training. Make sure that your iterator can geretate at least \"validation_steps * epochs\" batches.\r\n\r\nCurrently the only worked solutation for me is manully set the \"validation_steps\" in keras.Model.fit.\r\n\r\nTensorflow dataset repeat or/and take, will not work. By setting the validation batch size to 2 (1 for each GPU) also does not work\r\n\r\nSimliar issues in here [https://github.com/tensorflow/tensorflow/issues/25254](https://github.com/tensorflow/tensorflow/issues/25254), but closed", "comments": ["As mentioned in #25254 . The offical example code does not worked either.", "Keras should be able to figure out validation_steps.  (cc @omalleyt12 )\r\n\r\nCould you please share the code so that we have more complete details of this case while we are looking at it?  Thanks.", "> \r\n> \r\n> Keras should be able to figure out validation_steps. (cc @omalleyt12 )\r\n> \r\n> Could you please share the code so that we have more complete details of this case while we are looking at it? Thanks.\r\n\r\nWhen I do not pass the validations_steps:\r\n\r\nWithout Mirroed Strategy : **Work**\r\nWith Mirroed Strategy, Single Card : **Work**\r\nWith Mirroed Strategy, Multiple Cards with device = /gpu:0 : **work**\r\nWith Mirroed Strategy, Multiple Cards with device = /gpu:1 : **work**\r\nWith Mirroed Strategy, Multiple Cards : **Error**", "I think this maybe the keras does not consider when the numbers of val data is odd.", "same here here", "I have get the same problem", "Same issue", "@edwardyehuang Can you please test it against latest tf 2.0 nightly build. Thanks!\r\n```\r\npip install tf-nightly-2.0-preview\r\n```", "@edwardyehuang Is this still an issue? Can you check with `TF2.0` and/or `tf-nightly` and let us know whether the issue persists with latest TF version. Thanks!", "@edwardyehuang Is this still an issue? If not, please close the issue. Thank!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30636\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30636\">No</a>\n", "Is this really fixed? With tf 2.0.0 + keras.fit + tf.dataset for validation data + multi-gpu, i'm having the same issue. ", "FIxed confirmed in 2.0 stable version", "what's the fix ? want to use it in 1.14", "I found it cannot estimate the data from tfrecord.\r\nUsually, the keras fit will show the message: Train for xxx steps, validate for xxxx step\r\nIf I did not set the \"validation_step\" in model.fit and use the tfrecord, it will only show : Train for xxx steps", "However, it still can complete the validation, but will print some ugly warning message. The program will not stop", "try:\r\n  %tensorflow_version 1.x # enable TF 1.x in Colab\r\nexcept Exception:\r\n  pass\r\n\r\nprint(tf.__version__)\r\n\r\n#just try to not to use TF 2.x ", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30636\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30636\">No</a>\n"]}, {"number": 30635, "title": "Java version upgrade from 1.13.1 to 1.14.0 got error", "body": "<em>Java version upgrade from 1.13.1 to 1.14.0 got error</em>\r\n\r\n**System information**\r\n- Ubuntu 18.04.2 LTS (GNU/Linux 4.18.0-1013-azure x86_64):\r\n- TensorFlow 1.14.0:\r\n- Java 1.8:\r\n\r\nLog with 1.13.1(Worked):\r\n ``` .   ____          _            __ _ _\r\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\r\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\r\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\r\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\r\n =========|_|==============|___/=/_/_/_/\r\n :: Spring Boot ::        (v2.1.3.RELEASE)\r\n\r\n2019-07-12 07:15:28.366  INFO 21194 --- [           main] com.springWeb.App                        : Starting App v0.0.1-SNAPSHOT on RaTceUbt2019 with PID 21194 (/home/RaTce2019/od/springWeb-0.0.1-SNAPSHOT.jar started by RaTce2019 in /home/RaTce2019/od)\r\n2019-07-12 07:15:28.375  INFO 21194 --- [           main] com.springWeb.App                        : No active profile set, falling back to default profiles: default\r\n2019-07-12 07:15:31.058  INFO 21194 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8765 (http)\r\n2019-07-12 07:15:31.143  INFO 21194 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]\r\n2019-07-12 07:15:31.143  INFO 21194 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.16]\r\n2019-07-12 07:15:31.171  INFO 21194 --- [           main] o.a.catalina.core.AprLifecycleListener   : The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib]\r\n2019-07-12 07:15:31.362  INFO 21194 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext\r\n2019-07-12 07:15:31.362  INFO 21194 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2885 ms\r\n2019-07-12 07:15:31.940  INFO 21194 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\r\n2019-07-12 07:15:32.424  INFO 21194 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8765 (http) with context path ''\r\n2019-07-12 07:15:32.432  INFO 21194 --- [           main] com.springWeb.App                        : Started App in 4.883 seconds (JVM running for 5.79)\r\n2019-07-12 07:15:36.232  INFO 21194 --- [nio-8765-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'\r\n2019-07-12 07:15:36.233  INFO 21194 --- [nio-8765-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'\r\n2019-07-12 07:15:36.249  INFO 21194 --- [nio-8765-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 16 ms\r\n2019-07-12 07:15:38.465576: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: models/pepsi/ssd/saved_model\r\n2019-07-12 07:15:38.574596: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n2019-07-12 07:15:38.614832: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n2019-07-12 07:15:38.621862: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2019-07-12 07:15:38.623574: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7fe1c435d720 executing computations on platform Host. Devices:\r\n2019-07-12 07:15:38.623614: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-07-12 07:15:38.716123: I tensorflow/cc/saved_model/loader.cc:182] Restoring SavedModel bundle.\r\n2019-07-12 07:15:38.716231: I tensorflow/cc/saved_model/loader.cc:192] The specified SavedModel has no variables; no checkpoints were restored. File does not exist: models/pepsi/ssd/saved_model/variables/variables.index\r\n2019-07-12 07:15:38.716265: I tensorflow/cc/saved_model/loader.cc:285] SavedModel load for tags { serve }; Status: success. Took 250701 microseconds.\r\n```\r\n\r\nLog with 1.14.0(Failed):\r\n```\r\n  .   ____          _            __ _ _\r\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\r\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\r\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\r\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\r\n =========|_|==============|___/=/_/_/_/\r\n :: Spring Boot ::        (v2.1.3.RELEASE)\r\n\r\n2019-07-12 06:59:43.499  INFO 19308 --- [           main] com.springWeb.App                        : Starting App v0.0.1-SNAPSHOT on RaTceUbt2019 with PID 19308 (/home/RaTce2019/od/springWeb-0.0.1-SNAPSHOT.jar started by RaTce2019 in /home/RaTce2019/od)\r\n2019-07-12 06:59:43.507  INFO 19308 --- [           main] com.springWeb.App                        : No active profile set, falling back to default profiles: default\r\n2019-07-12 06:59:46.150  INFO 19308 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8765 (http)\r\n2019-07-12 06:59:46.236  INFO 19308 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]\r\n2019-07-12 06:59:46.237  INFO 19308 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.16]\r\n2019-07-12 06:59:46.279  INFO 19308 --- [           main] o.a.catalina.core.AprLifecycleListener   : The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib]\r\n2019-07-12 06:59:46.447  INFO 19308 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext\r\n2019-07-12 06:59:46.447  INFO 19308 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2844 ms\r\n2019-07-12 06:59:47.007  INFO 19308 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\r\n2019-07-12 06:59:47.481  INFO 19308 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8765 (http) with context path ''\r\n2019-07-12 06:59:47.490  INFO 19308 --- [           main] com.springWeb.App                        : Started App in 4.798 seconds (JVM running for 5.729)\r\n2019-07-12 07:00:05.710  INFO 19308 --- [nio-8765-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'\r\n2019-07-12 07:00:05.710  INFO 19308 --- [nio-8765-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'\r\n2019-07-12 07:00:05.723  INFO 19308 --- [nio-8765-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 13 ms\r\n2019-07-12 07:00:08.082 ERROR 19308 --- [nio-8765-exec-1] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: /tmp/tensorflow_native_libraries-1562914806051-0/libtensorflow_jni.so: libtensorflow_framework.so.1: cannot open shared object file: No such file or directory] with root cause\r\n\r\njava.lang.UnsatisfiedLinkError: /tmp/tensorflow_native_libraries-1562914806051-0/libtensorflow_jni.so: libtensorflow_framework.so.1: cannot open shared object file: No such file or directory\r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method) ~[na:1.8.0_212]\r\n\tat java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941) ~[na:1.8.0_212]\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824) ~[na:1.8.0_212]\r\n\tat java.lang.Runtime.load0(Runtime.java:809) ~[na:1.8.0_212]\r\n\tat java.lang.System.load(System.java:1086) ~[na:1.8.0_212]\r\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:101) ~[libtensorflow-1.14.0.jar!/:na]\r\n\tat org.tensorflow.TensorFlow.init(TensorFlow.java:66) ~[libtensorflow-1.14.0.jar!/:na]\r\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:70) ~[libtensorflow-1.14.0.jar!/:na]\r\n\tat org.tensorflow.SavedModelBundle.<clinit>(SavedModelBundle.java:170) ~[libtensorflow-1.14.0.jar!/:na]\r\n\tat com.springWeb.controller.Controller.detectImage(Controller.java:73) ~[classes!/:0.0.1-SNAPSHOT]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_212]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_212]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_212]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_212]\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:660) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:200) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:834) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_212]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_212]\r\n\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat java.lang.Thread.run(Thread.java:748) [na:1.8.0_212]\r\n\r\n2019-07-12 07:00:26.038 ERROR 19308 --- [nio-8765-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.NoClassDefFoundError: Could not initialize class org.tensorflow.SavedModelBundle] with root cause\r\n\r\njava.lang.NoClassDefFoundError: Could not initialize class org.tensorflow.SavedModelBundle\r\n\tat com.springWeb.controller.Controller.detectImage(Controller.java:73) ~[classes!/:0.0.1-SNAPSHOT]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_212]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_212]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_212]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_212]\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:660) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) ~[spring-webmvc-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.5.RELEASE.jar!/:5.1.5.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:200) ~[tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:834) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_212]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_212]\r\n\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.16.jar!/:9.0.16]\r\n\tat java.lang.Thread.run(Thread.java:748) [na:1.8.0_212]\r\n```\r\nThis is my pom.xml:\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n\txsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n\t<modelVersion>4.0.0</modelVersion>\r\n\r\n\t<groupId>springWeb</groupId>\r\n\t<artifactId>springWeb</artifactId>\r\n\t<version>0.0.1-SNAPSHOT</version>\r\n\t<packaging>jar</packaging>\r\n\r\n\t<name>springWeb</name>\r\n\t<url>http://maven.apache.org</url>\r\n\r\n\t<properties>\r\n\t\t<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n\t\t<java.version>1.8</java.version>\r\n\t\t<maven.compiler.source>1.8</maven.compiler.source>\r\n\t\t<maven.compiler.target>1.8</maven.compiler.target>\r\n\t</properties>\r\n\r\n\t<parent>\r\n\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t<artifactId>spring-boot-starter-parent</artifactId>\r\n\t\t<version>2.1.3.RELEASE</version>\r\n\t</parent>\r\n\r\n\t<dependencies>\r\n\t\t<dependency>\r\n\t\t\t<groupId>junit</groupId>\r\n\t\t\t<artifactId>junit</artifactId>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t\t<artifactId>spring-boot-starter-web</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.tensorflow</groupId>\r\n\t\t\t<artifactId>tensorflow</artifactId>\r\n\t\t\t<version>1.14.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.tensorflow</groupId>\r\n\t\t\t<artifactId>proto</artifactId>\r\n\t\t\t<version>1.14.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.json</groupId>\r\n\t\t\t<artifactId>json</artifactId>\r\n\t\t\t<version>20180813</version>\r\n\t\t</dependency>\r\n\t</dependencies>\r\n\r\n\t<build>\r\n\t\t<plugins>\r\n\t\t\t<plugin>\r\n\t\t\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t\t\t<artifactId>spring-boot-maven-plugin</artifactId>\r\n\t\t\t</plugin>\r\n\t\t</plugins>\r\n\t</build>\r\n</project>\r\n\r\n`And what I did was changed version from 1.13.1 to 1.14.0.`\r\n\r\nAnd I tried official Java start up got the same error:\r\n**System information**\r\n- macOS High Sierra Version 10.13.6 (17G6030):\r\n- TensorFlow 1.14.0:\r\n- Java 1.8:\r\n\r\npom.xml:\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n\txsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n\t<modelVersion>4.0.0</modelVersion>\r\n\r\n\t<groupId>tftest</groupId>\r\n\t<artifactId>tftest</artifactId>\r\n\t<version>0.0.1-SNAPSHOT</version>\r\n\t<packaging>jar</packaging>\r\n\r\n\t<name>tftest</name>\r\n\t<url>http://maven.apache.org</url>\r\n\r\n\t<properties>\r\n\t\t<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n\t</properties>\r\n\r\n\t<dependencies>\r\n\t\t<dependency>\r\n\t\t\t<groupId>junit</groupId>\r\n\t\t\t<artifactId>junit</artifactId>\r\n\t\t\t<version>3.8.1</version>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.tensorflow</groupId>\r\n\t\t\t<artifactId>tensorflow</artifactId>\r\n\t\t\t<version>1.14.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.tensorflow</groupId>\r\n\t\t\t<artifactId>libtensorflow</artifactId>\r\n\t\t\t<version>1.14.0</version>\r\n\t\t</dependency>\r\n\t</dependencies>\r\n</project>\r\n\r\n\r\nApp.java:\r\n```package tftest.tftest;\r\n\r\nimport org.tensorflow.Graph;\r\nimport org.tensorflow.Session;\r\nimport org.tensorflow.Tensor;\r\nimport org.tensorflow.TensorFlow;\r\n\r\npublic class App {\r\n\tpublic static void main(String[] args) throws Exception {\r\n\t\ttry (Graph g = new Graph()) {\r\n\t\t\tfinal String value = \"Hello from \" + TensorFlow.version();\r\n\t\t\t// Construct the computation graph with a single operation, a constant\r\n\t\t\t// named \"MyConst\" with a value \"value\".\r\n\t\t\ttry (Tensor t = Tensor.create(value.getBytes(\"UTF-8\"))) {\r\n\t\t\t\t// The Java API doesn't yet include convenience functions for adding operations.\r\n\t\t\t\tg.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\r\n\t\t\t}\r\n\t\t\t// Execute the \"MyConst\" operation in a Session.\r\n\t\t\ttry (Session s = new Session(g);\r\n\t\t\t\t\t// Generally, there may be multiple output tensors,\r\n\t\t\t\t\t// all of them must be closed to prevent resource leaks.\r\n\t\t\t\t\tTensor output = s.runner().fetch(\"MyConst\").run().get(0)) {\r\n\t\t\t\tSystem.out.println(new String(output.bytesValue(), \"UTF-8\"));\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\nLog:\r\n```\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: /private/var/folders/0c/nz0823ps085b_1zcq6l8ry441kqw10/T/tensorflow_native_libraries-1562915587706-0/libtensorflow_jni.dylib: dlopen(/private/var/folders/0c/nz0823ps085b_1zcq6l8ry441kqw10/T/tensorflow_native_libraries-1562915587706-0/libtensorflow_jni.dylib, 1): Library not loaded: @rpath/libtensorflow_framework.1.dylib\r\n  Referenced from: /private/var/folders/0c/nz0823ps085b_1zcq6l8ry441kqw10/T/tensorflow_native_libraries-1562915587706-0/libtensorflow_jni.dylib\r\n  Reason: image not found\r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method)\r\n\tat java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1938)\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1821)\r\n\tat java.lang.Runtime.load0(Runtime.java:809)\r\n\tat java.lang.System.load(System.java:1086)\r\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:101)\r\n\tat org.tensorflow.TensorFlow.init(TensorFlow.java:66)\r\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:70)\r\n\tat org.tensorflow.Graph.<clinit>(Graph.java:479)\r\n\tat tftest.tftest.App.main(App.java:10)\r\n```", "comments": ["Just to verify after upgrading to TF 1.14.0 are you able to import Tensorflow in Java successfully.Thanks!", "Yes, import is success, but it seems libtensorflow.so was not found in tmp directory.\r\nI got this ```Library not loaded: @rpath/libtensorflow_framework.1.dylib``` when I try to run ```TensorFlow.version()```. Worked for 1.13.1 but not 1.14.0.\r\nThanks!", "I can confirm that 1.14.0 does not load its library. I have tested it on Linux (Ubuntu 19.04) and OSX (current) on Java 1.8. I have put the [code example](https://www.tensorflow.org/install/lang_java) into https://github.com/davidmweber/tf-java-error so that it can easily be replicated.\r\n\r\nHere is the stack trace (with org.tensorflow.NativeLibrary.DEBUG=1)\r\n\r\norg.tensorflow.NativeLibrary: tryLoadLibraryFailed: no tensorflow_jni in java.library.path\r\norg.tensorflow.NativeLibrary: jniResourceName: org/tensorflow/native/linux-x86_64/libtensorflow_jni.so\r\norg.tensorflow.NativeLibrary: frameworkResourceName: org/tensorflow/native/linux-x86_64/libtensorflow_framework.so\r\norg.tensorflow.NativeLibrary: extracting native library to: /tmp/tensorflow_native_libraries-1563269252070-0/libtensorflow_framework.so\r\norg.tensorflow.NativeLibrary: copied 34748520 bytes to /tmp/tensorflow_native_libraries-1563269252070-0/libtensorflow_framework.so\r\norg.tensorflow.NativeLibrary: extracting native library to: /tmp/tensorflow_native_libraries-1563269252070-0/libtensorflow_jni.so\r\norg.tensorflow.NativeLibrary: copied 150449736 bytes to /tmp/tensorflow_native_libraries-1563269252070-0/libtensorflow_jni.so\r\n[WARNING] \r\njava.lang.UnsatisfiedLinkError: /tmp/tensorflow_native_libraries-1563269252070-0/libtensorflow_jni.so: libtensorflow_framework.so.1: cannot open shared object file: No such file or directory\r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method)\r\n\tat java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941)\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824)\r\n\tat java.lang.Runtime.load0(Runtime.java:809)\r\n\tat java.lang.System.load(System.java:1086)\r\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:101)\r\n\tat org.tensorflow.TensorFlow.init(TensorFlow.java:66)\r\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:70)\r\n\tat org.tensorflow.Graph.<clinit>(Graph.java:479)\r\n\tat HelloTensorFlow.main(HelloTensorFlow.java:8)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:282)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n", "same issue.\r\nmacOS 10.14.4\r\njava version : 1.8.0_152\r\npom:\r\n```\r\n        <dependency>\r\n            <groupId>org.tensorflow</groupId>\r\n            <artifactId>libtensorflow</artifactId>\r\n            <version>1.14.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.tensorflow</groupId>\r\n            <artifactId>proto</artifactId>\r\n            <version>1.14.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.tensorflow</groupId>\r\n            <artifactId>libtensorflow_jni</artifactId>\r\n            <version>1.14.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.tensorflow</groupId>\r\n            <artifactId>tensorflow</artifactId>\r\n            <version>1.14.0</version>\r\n        </dependency>\r\n```\r\n\r\nexception : \r\n```\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: /private/var/folders/3v/v52y0yq94kl2khm53q4848_m0000gn/T/tensorflow_native_libraries-1563783638694-0/libtensorflow_jni.dylib: dlopen(/private/var/folders/3v/v52y0yq94kl2khm53q4848_m0000gn/T/tensorflow_native_libraries-1563783638694-0/libtensorflow_jni.dylib, 1): Library not loaded: @rpath/libtensorflow_framework.1.dylib\r\n  Referenced from: /private/var/folders/3v/v52y0yq94kl2khm53q4848_m0000gn/T/tensorflow_native_libraries-1563783638694-0/libtensorflow_jni.dylib\r\n  Reason: image not found\r\n```", "I experienced this on both Mac OS X and Linux.\r\n\r\nTracing through the `org.tensorflow.NativeLibrary`class, it seems that what is happening is that the code is extracting the dependent framework lib _without_ the version (i.e. `libtensorflow_framework.dylib`) to a temp directory for loading, but the dependency (\"@rpath\") in the JNI lib is for the framework lib _with_ the version (i.e. `libtensorflow_framework.1.dylib`).\r\n\r\nThe same thing happens on Linux with .so files.\r\n\r\nThe `NativeLibrary` class needs to make sure it is extracting the flavor of the framework lib that the JNI lib is actually depending on.\r\n\r\nI worked around this on Mac OS X by writing code to extract all the flavors and load the libs before `NativeLibrary` kicks in, but after seeing this defect in both platforms I think I will just revert to 1.13.1.", "Can confirm this is an issue with 1.14.0 on OS X", "Also have this problem in OSX, but not in Windows.\r\n\r\n@silvanheller @klarson2 Here is a quick workaround:\r\n\r\n1. Create a package `org.tensorflow` in the top level of your source directory (e.g. src/org/tensorflow)\r\n\r\n2. Copy in the NativeLibrary.java file from here: https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java\r\n\r\n3. Change:\r\n\r\n```\r\nfinal String frameworkLibName =\r\n                getVersionedLibraryName(System.mapLibraryName(\"tensorflow_framework\"));\r\n```\r\n\r\nto\r\n\r\n```\r\nString frameworkLibName =\r\n                getVersionedLibraryName(System.mapLibraryName(\"tensorflow_framework\"));\r\nif (frameworkLibName.equals(\"libtensorflow_framework.dylib\")) frameworkLibName = \"libtensorflow_framework.1.dylib\";\r\n```\r\n\r\n@davidmweber I guess if it is the same error on linux you can also add\r\n\r\n```\r\nif (frameworkLibName.equals(\"libtensorflow_framework.so\")) frameworkLibName = \"libtensorflow_framework.so.1\";\r\n```\r\n\r\nAt least for me, this version overrides the one in the jar. Everything seems to work fine.", "Same for me in macOS `10.14.x`, it works in `1.13.1` but have the error when I move to `1.14.0`:\r\n\r\n```bash\r\nAn exception or error caused a run to abort: /private/var/folders/4p/vy_4h7z563d7gnq98nsg0gc80000gn/T/tensorflow_native_libraries-1566919860658-0/libtensorflow_jni.dylib: dlopen(/private/var/folders/4p/vy_4h7z563d7gnq98nsg0gc80000gn/T/tensorflow_native_libraries-1566919860658-0/libtensorflow_jni.dylib, 1): Library not loaded: @rpath/libtensorflow_framework.1.dylib\r\n  Referenced from: /private/var/folders/4p/vy_4h7z563d7gnq98nsg0gc80000gn/T/tensorflow_native_libraries-1566919860658-0/libtensorflow_jni.dylib\r\n  Reason: image not found \r\njava.lang.UnsatisfiedLinkError: /private/var/folders/4p/vy_4h7z563d7gnq98nsg0gc80000gn/T/tensorflow_native_libraries-1566919860658-0/libtensorflow_jni.dylib: dlopen(/private/var/folders/4p/vy_4h7z563d7gnq98nsg0gc80000gn/T/tensorflow_native_libraries-1566919860658-0/libtensorflow_jni.dylib, 1): Library not loaded: @rpath/libtensorflow_framework.1.dylib\r\n  Referenced from: /private/var/folders/4p/vy_4h7z563d7gnq98nsg0gc80000gn/T/tensorflow_native_libraries-1566919860658-0/libtensorflow_jni.dylib\r\n  Reason: image not found\r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method)\r\n\tat java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941)\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824)\r\n\tat java.lang.Runtime.load0(Runtime.java:809)\r\n\tat java.lang.System.load(System.java:1086)\r\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:101)\r\n\tat org.tensorflow.TensorFlow.init(TensorFlow.java:66)\r\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:70)\r\n```", "I'm experiencing the same issue with Ubuntu 16.04, Oracle JDK 1.8.0_201.\r\nWorks well with 1.13.1", "If you use Scala with Gradle, in addition to provided workaround you'll also need to modify your `build.gradle`.\r\n```\r\nsourceSets.main.scala.srcDir \"src/main/java\"\r\nsourceSets.main.java.srcDirs = []\r\n\r\nsourceSets.test.scala.srcDir \"src/test/java\"\r\nsourceSets.test.java.srcDirs = []\r\n```", "Any chance of getting this pushed to maven?", "The upcoming release of TF 1.15.0 will contain the fixes for this problem.", "Thanks @sjamesr, unfortunately, there is no ETA or any life cycle regarding on how long it takes to have TensorFlow on Maven after its official release. Also, the pre-releases were never got to Maven for testing like it's done for Python.\r\n \r\nI myself am still waiting for TF 2.0 to have something on Maven so we can migrate our codes.\r\n\r\nThanks again, hope we can get `1.15` and `2.0` soon on Maven.", "Thanks @geometrikal - works on linux (mint 19) w/ the mentioned quick workaround.", "Switching to 1.15.0 didn't help a lot. Having the same issue and the same error message (... Reason: image not found... ) on macOS 10.14.5.\r\nThe suggested workaround still works though. ", "@mickaeltardy Are you sure? The reason I am asking is to be sure the cache is cleared and you are using only the `1.15.0` and nothing from the previous installation.\r\nI haven't tested myself since we need to figure out where to find some `.so` files we need in `cntorib` but I saw some projects moved to `1.15.0` so I assumed it was fixed.", "> @mickaeltardy Are you sure? The reason I am asking is to be sure the cache is cleared and you are using only the `1.15.0` and nothing from the previous installation.\r\n> I haven't tested myself since we need to figure out where to find some `.so` files we need in `cntorib` but I saw some projects moved to `1.15.0` so I assumed it was fixed.\r\n\r\nThank you for pointing out for me. Properly cleaning dependencies made it work as a charm. Downvoting my previous comment.", "I ran into the same bug and can confirm it didn't reproduce with TensorFlow version 1.15.0", "I have the same issue with TensorFlow 1.15.0 on Debian buster. The workaround mentioned above did not resolve the problem.", "@lucaro The workaround was for the time there was no new release. Have you tested with `1.15.0`? ", "Yes, I tried it with 1.15.0 with and without the workaround but it doesn't work either way.", "I was asking because for me it works inside Intellij but when I make a Fat JAR it gives me: \r\n```\r\njava.lang.UnsatisfiedLinkError: /tmp/tensorflow_native_libraries-1575293215388-0/libtensorflow_jni.so: libtensorflow_framework.so.1: cannot open shared object file: No such file or directory\r\n```\r\nI was sure it was just me since everyone upgraded to 1.15.0 without reporting this issue.", "OK, this issue still remains on Ubuntu (16.04 at least). The problem is that it's only copy `libtensorflow_jni.so` file in the `/tmp` directory and doesn't copy `libtensorflow_framework.so.1` even though I can see it in my compiled JAR that these two files exist under `linux-x86_64` in native.\r\n\r\nThis is what's inside my compiled JAR (sbt assembly with TF 1.15.0)\r\n\r\n```\r\n        0  2020-01-02 12:15   org/tensorflow/native/\r\n        0  2020-01-02 12:15   org/tensorflow/native/darwin-x86_64/\r\n        0  2020-01-02 12:15   org/tensorflow/native/linux-x86_64/\r\n        0  2020-01-02 12:15   org/tensorflow/native/windows-x86_64/\r\n    11419  2019-10-22 17:09   org/tensorflow/native/darwin-x86_64/LICENSE\r\n   422253  2019-10-22 17:09   org/tensorflow/native/darwin-x86_64/THIRD_PARTY_TF_JNI_LICENSES\r\n 28642820  2019-10-22 17:09   org/tensorflow/native/darwin-x86_64/libtensorflow_framework.1.dylib\r\n284042344  2019-10-22 17:09   org/tensorflow/native/darwin-x86_64/libtensorflow_jni.dylib\r\n    11419  2019-10-22 17:09   org/tensorflow/native/linux-x86_64/LICENSE\r\n   422253  2019-10-22 17:09   org/tensorflow/native/linux-x86_64/THIRD_PARTY_TF_JNI_LICENSES\r\n 35226832  2019-10-22 17:09   org/tensorflow/native/linux-x86_64/libtensorflow_framework.so.1\r\n154073736  2019-10-22 17:09   org/tensorflow/native/linux-x86_64/libtensorflow_jni.so\r\n    11419  2019-10-22 17:09   org/tensorflow/native/windows-x86_64/LICENSE\r\n 78973440  2019-10-22 17:09   org/tensorflow/native/windows-x86_64/tensorflow_jni.dll\r\n```\r\n\r\nFor some reason on Ubuntu 16.04 it only copies `libtensorflow_jni.so` and not `libtensorflow_framework.so.1` as well.", "@maziyarpanahi Is that with the workaround or with plain 1.15?", "@geometrikal With the plain 1.15.0.\r\n\r\nHowever, if I copy the `NativeLibrary.java` file from 1.14, apply the workaround, it works in 1.15.0 on Ubuntu 16.04.\r\n\r\nThat is why I think this issue still exists at least on some OSes or when you compile a fat JAR.", "Same issue with 1.15.0 on Ubuntu 16.04 and macOS 10.15.3\r\nThis only happens when using a fat Jar. Works fine with gradle,\r\n\r\nThe problem is in https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/java/src/main/java/org/tensorflow/NativeLibrary.java#L176 when getting the version. The implementation version is read from `META-INF/MANIFEST.MF` in the fatJar which may not be provided ( my case) or does not match the tensorflow major version (1 in this case), so it returns null and causes the missing `libtensorflow_framework.1.dylib` or `libtensorflow_framework.so.1`. \r\n\r\nI think it needs a more reliable way to get the version.\r\n\r\nOne workaround is to provide the implementation-version in manifest like the following in gradle\r\n```\r\n Jar {\r\n    manifest {\r\n        attributes 'Implementation-Version': '1.xx'\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n", "I just successfully tested this workaround on Debian buster.", "@larryrxu  \r\nIs this still an issue.", "well actually i meet this issue in tensorflow1.13.1 when I run the java app with self-compiled tensorflow with bazel, the document says the java only need libtensorflow.jar and libtensorflow_jni.so but actually libtensorflow_framework.so is also needed when i run my project. I had to build a directory with both so file and insert them into the official maven tensorflow-jni dependency JAR.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue still exists even in the 1.15 release which we still had to manually add the workaround mentioned earlier (which thank you @geometrikal) and the last post is from a week ago so how is this a stalled issue?", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30635\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30635\">No</a>\n", "I am experiencing same issue with TF 1.15 maven artifacts.", "If using ivy, make sure your lib does not have older versions of libtensorflow or tensorflow. Removing the older versions and using 1.15.0 resolved the problem for our java project. The ivy.xml lines we use are\r\n````\r\n        <!--tensorflow has native libraries, but handled fine with this dependeny - see https://www.tensorflow.org/install/lang_java -->\r\n        <!--if having trouble loading the DLL, you might have to downgrade locally to version 1.5.0-->\r\n        <!--make sure to delete newer versions of libtensorflow* and tensorflow* from lib/-->\r\n        <dependency org=\"org.tensorflow\" name=\"tensorflow\" rev=\"1.15.0\" />\r\n        \r\n        <!--to use GPU if you have an Nvida GPU installed, comment line above and use lines below with appropriate version of tensor flow. \r\n        You have to separately install Cuda toolkit  for this to work - see https://developer.nvidia.com/cuda-toolkit -->\r\n        <dependency org=\"org.tensorflow\" name=\"libtensorflow_jni_gpu\" rev=\"1.15.0\" />\r\n\r\n````"]}, {"number": 30634, "title": "[Documentation][TF 1.14] Missing documentation for `batch_dims` in `tf.gather`", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/gather\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn TF 1.14, `tf.batch_gather` is marked as deprecated, and the keyword `batch_dims` has been added to `tf.gather` to handle the batch version. Though, the documentation of `tf.gather` has only been updated with the **type** of `batch_dims`, but not **how to use** it neither **what it does**.\r\n\r\nThe old [`tf.batch_gather`](https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/batch_gather) function was documented in TF 1.13. Though, `tf.gather` is a bit more complex than the old `tf.batch_gather`, so maybe the [documentation of the underlying `_batch_gather`](https://github.com/tensorflow/tensorflow/blob/2aca283764bbbd54a5556319eb7cc0ed323c81f1/tensorflow/python/ops/array_ops.py#L3514) function could be used.\r\n\r\nThese two existing documentations could be used to complete the existing documentation of `tf.gather`.\r\n\r\n### Correct links\r\n\r\nYes.\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n\r\n### Usage example\r\n\r\nNot for using `batch_dims`.\r\n\r\n### Submit a pull request?\r\n\r\nNo.\r\n", "comments": ["I would like to make a contribution for this request.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "https://www.tensorflow.org/api_docs/python/tf/gather?version=nightly\r\n\r\n`tf.gather` docs have been greatly expanded. I think this is covered."]}, {"number": 30633, "title": "tf.sysconfig.get_link_flags() issue", "body": "Env:\r\ntensorflow 1.14.0\r\nmacos\r\n\r\ntf.sysconfig.get_link_flags() returns\r\n```\r\n['-L/Users/kimmyzhang/anaconda2/lib/python2.7/site-packages/tensorflow',\r\n '-l:libtensorflow_framework.1.dylib']\r\n```\r\n\r\n\"-l:libtensorflow_framework.1.dylib\" will cause a custom op compilation failure:\r\n```\r\nld: library not found for -l:libtensorflow_framework.1.dylib\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```\r\n\r\nIt should be -ltensorflow_framework.", "comments": ["Think the ld should be `-ltensorflow_framework.1`. Created a PR #30656 for the fix.", "The issue has been fixed through PR #30656", "-ltensorflow_framework is OK."]}, {"number": 30632, "title": "How do I create a custom OP using TF1.14?", "body": "I am a TensorFlow beginner. The environment I use is ubuntu18.04, python3.7, TensorFlow-GPU1.14, CUDA10.0.\r\n\r\nI want to build a custom OP (using GPU), I saw from the official website tutorial that you need to include #include \"tensorflow/core/util/cuda_kernel_helper.h\" in the source code.\r\nBut when I was \"make\", I got an error: \"cuda_kernel_helper.h\" was not found.\r\n\r\nIn addition, I used the python environment built by anaconda. I found gpu_kernel_helper.h in the folder in the environment. I guess this is a replacement file for cuda_kernel_helper.h. When I replace the file name in my source code, another one appears. Error: \"third_party/gpus/cuda/include/cuda_fp16.h\" file not found.\r\nAfter that, I only found the \"eigen3\" folder in the \u201cthird_party\u201d folder and did not find the \"gpus\" folder.\r\nI installed TensorFlow-gpu using pip. Is there a problem with my installation method?\r\n\r\nI hope to get help to solve this problem. thank you all.", "comments": ["Why are you importing a .h header file in python ? do you know the difference from python API and the C++ backend ? \r\nThe docs:\r\nhttps://www.tensorflow.org/api_docs\r\n", "> Why are you importing a .h header file in python ? do you know the difference from python API and the C++ backend ?\r\n> The docs:\r\n> https://www.tensorflow.org/api_docs\r\n\r\n@Uiuran Thank you very much for your answer.\r\nSorry, I don't know much about this knowledge.\r\nI am trying to learn TensorFlow through the project given below. When I executed the \"make\" command in the \"hdrnet\" folder, I had the problems I raised. So I am very confused.\r\nDo I need to install a C++ library into my system?\r\nProject: https://github.com/mgharbi/hdrnet\r\nI look forward to your reply again, thank you.", "@TCBocean \r\n\r\nJust to verify did you get chance to follow instructions from [TensorFlow](https://www.tensorflow.org/guide/extend/op) website .Please, let us know. Thanks!", "> @TCBocean\r\n> \r\n> Just to verify did you get chance to follow instructions from [TensorFlow](https://www.tensorflow.org/guide/extend/op) website .Please, let us know. Thanks!\r\n\r\n@ravikyram \r\nHello, in this example, the code for \"kernel_example.cu.cc\" has a header file` #include tensorflow / core / util / cuda_kernel_helper.h`. But when I compiled \".so\" with g++, I was prompted not to find this file. Then I will go to the official github example:\r\nHttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/adding_an_op/cuda_op_kernel.cu.cc\r\nFound it renamed gpu_kernel_helper.h.\r\nThen, I also encountered a problem at compile time, the official compiler command is:\r\n```\r\nNvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc \\\r\n\u00a0\u00a0${TF_CFLAGS[@]} -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC\r\n\r\ng++ -std=c++11 -shared -o cuda_op_kernel.so cuda_op_kernel.cc \\\r\n\u00a0\u00a0Cuda_op_kernel.cu.o ${TF_CFLAGS[@]} -fPIC -lcudart ${TF_LFLAGS[@]}\r\n```\r\nBut when `GOOGLE_CUDA=1` is compiled, the compiler prompts that \"third_party/gpus/cuda/include/cuda_fp16.h\" in \"gpu_kernel_helper.h\" is not found.\r\nI found only the \"eigen3\" folder in the \"Anaconda3\\envs\\CV_env\\Lib\\site-packages\\tensorflow\\include\\third_party\" folder in my python version of TensorFlow, but I didn't see any other files. folder. I installed the 1.14 version of TensorFlow-gpu using pip. Do I still need to install the C++ version to complete the compilation? Or is there any other way to solve this problem?\r\nLooking forward to your answer, thank you", "https://github.com/tensorflow/custom-op for the latest documentation on creating custom ops.\r\n@yifeif may be able to answer if there is anything missing there.", "@yifeif  @ravikyram   \r\nI think I am lucky.\r\nI changed my environment:\r\nUbuntu16.04\r\ngcc4.8\r\nCUDA9.0\r\ncudnn7.1.4\r\nTensorFlow-gpu1.12\r\nI used the code framework in \"https://github.com/tensorflow/custom-op\" to replace the custom OP code in the HDRnet project and successfully compiled the dynamic library.\r\nThank you for your active help."]}, {"number": 30631, "title": "[LITE] Add the missed header for osx platform in micro_speech example for makefile.", "body": "When we use the target specific \"audio_provider.cc\"[1], we should also add\r\nits header dependency[2] in makefile.\r\n\r\n[1]\r\ntensorflow/lite/experimental/micro/examples/micro_speech/osx/audio_provider.cc\r\n[2]\r\ntensorflow/lite/experimental/micro/examples/micro_speech/simple_features/simple_model_settings.h", "comments": ["@petewarden \r\nCould you please review this pr?", "@JerryShih Could you please check failed build errors? Thanks!", "> @JerryShih Could you please check failed build errors? Thanks!\r\n\r\n@gbaned \r\nI have no idea for the failed windows build. I don't think these errors are related to my patch.\r\nAnd I also check the same tests in other pr. They hit the same error too(e.g. https://source.cloud.google.com/results/invocations/bbcc967b-10dd-4e98-93f4-7bc7f5126ddb/targets).\r\n\r\nHere are the logs:\r\nexternal/local_config_mlir/lib/TableGen/Constraint.cpp(66): error C2061: syntax error: identifier 'StringRef'\r\nexternal/local_config_mlir/lib/TableGen/Constraint.cpp(68): error C2511: 'mlir::tblgen::AppliedConstraint::AppliedConstraint(mlir::tblgen::Constraint &&)': overloaded member function not found in 'mlir::tblgen::AppliedConstraint'\r\n", "@petewarden \r\nI rebase to current master. Maybe the failed tests could pass.\r\n\r\nI have no idea for the failed windows build. I don't think these errors are related to my patch.\r\nAnd I also check the same tests in other pr. They hit the same error too(e.g. https://source.cloud.google.com/results/invocations/bbcc967b-10dd-4e98-93f4-7bc7f5126ddb/targets).", "Can one of the admins verify this patch?", "gentle ping @petewarden for review ? Thanks!", "@JerryShih  Can you please resolve conflicts? Thanks!", "@gbaned\r\n> @JerryShih Can you please resolve conflicts? Thanks!\r\n\r\nI just rebase to the current master."]}, {"number": 30630, "title": "keras/saving_utils: call losses.deserialize instead of losses.get in `compile_args_from_training_config`", "body": "When loading a keras model saved in `h5` format, there is a problem with custom losses.\r\n\r\nReproduction: https://gist.github.com/suyash/d45f664f0a9d62fd4ab052b4040e6a16\r\n\r\nEssentially, from the stack trace, the `keras.losses.get` function does not accept a `custom_objects` parameter, which makes loading a custom loss break.\r\n\r\nThis changes `compile_args_from_training_config` to call `losses.deserialize` instead of `losses.get`, similar to `optimizers.deserialize` a couple of lines above", "comments": ["Can one of the admins verify this patch?", "Thank you for the fix, there is another PR that fixes the same issue  https://github.com/tensorflow/tensorflow/pull/33229 so i am going to close this one. "]}, {"number": 30629, "title": "unable to build pip package from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13.2 commit\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n\r\n**Describe the problem**\r\n```\r\n File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 63, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 28, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 36, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 39, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/home/p.patel/.cache/bazel/_bazel_root/1bd8cf0b6a86ac78985c768eb3530621/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 133, in <module>\r\n    \"* `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\\n  \")\r\nAttributeError: attribute '__doc__' of 'type' objects is not writable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Just to verify did you get chance to follow instructions from [TensorFlow](https://www.tensorflow.org/install/source) website .Please, let us know. Thanks!", "Yes ", "@mihaimaruseac who did the release for 1.13.2\r\nDid we see this issue in the release branch?\r\n\r\nAlso, did you make any changes to the source?", "I didn't change the source and didn't see the issue during the release. I saw it many months ago on master but then I upgraded bazel and it worked.\r\n\r\nAlso, the release landed after the issue was opened. I'd try a rebuild now? Can you also try a newer version of Bazel? I used 0.21.0 for the release and everything worked", "@patelprateek \r\n\r\nCan you please confirm if the issue still persists.Thanks!", "Also have this issue too", "Just to confirm, @chuanqi129 did you do a fresh checkout of the branch, are using bazel 0.21.0, ran `./configure` before starting the compile?\r\n\r\nWhat python and compiler are you using? What operating system?", "hi, @mihaimaruseac \r\nI followed the instruction on Tensorflow \r\nhttps://www.tensorflow.org/install/source_windows\r\nI had a hard time when doing this command\r\n\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n(I also found others said: change to -c opt, but not working either)\r\nmost of the error said \r\nFAILED: Build did NOT complete successfully(326 packages loaded, 7927 targets c\r\nonfigured)  <== Something like this\r\n\r\nmy OS : windows server 2012 r2\r\nBazel version: 0.28.1, also tried so many other versions 0.21.0, 0.24.1 etc\r\ntensorflow version: 1.13.1\r\npython version: 3.6.8\r\n\r\n> using bazel 0.21.0, ran ./configure before starting the compile?\r\n\r\nDoes this mean every time I change Bazel version need to start all over again?\r\n\r\nthanks a lot!\r\n\r\n=====update.. after more attempt=====\r\nbazel-out/x64_windows-opt/bin/external/com_google_protobuf/src: warning: directo\r\nry does not exist.\r\nbazel-out/x64_windows-opt/bin/external/com_google_protobuf/src: warning: directo\r\nry does not exist.\r\nERROR: C:/users/administrator/desktop/tensorflow/tensorflow-master/tensorflow/co\r\nre/BUILD:2301:1: output 'tensorflow/core/protobuf/conv_autotuning.pb.h' was not\r\ncreated\r\nERROR: C:/users/administrator/desktop/tensorflow/tensorflow-master/tensorflow/co\r\nre/BUILD:2301:1: output 'tensorflow/core/protobuf/conv_autotuning.pb.cc' was not\r\n created\r\nERROR: C:/users/administrator/desktop/tensorflow/tensorflow-master/tensorflow/co\r\nre/BUILD:2301:1: not all outputs were created or valid\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 181.594s, Critical Path: 25.73s\r\nINFO: 509 processes: 509 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n\r\nthis time hold a little bit longer, but still failed", "@mihaimaruseac hi, I creat a new issue in case you don't understand what I'm talking about\r\n[LINK](https://github.com/tensorflow/tensorflow/issues/31944#issue-484800011)", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue as original asker didn't reply at all and there is a duplicate.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30629\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30629\">No</a>\n"]}, {"number": 30628, "title": "Fix linker error", "body": "MacOS nonpip jobs are failing with a linker error. This should fix it", "comments": []}, {"number": 30627, "title": "Fix visibility of a few targets", "body": "ubuntu/cpu_py_3{56}_ful/pip build jobs pass all tests but some are not build due to deps being invisible", "comments": []}, {"number": 30626, "title": "Remove `set -ex` on `ci_sanity.sh`", "body": "It causes the build to fail on stuff like `((a++))` as that evaluates to `1` which `set -ex` considers to be an error", "comments": ["I'm a little on the fence on this one but I guess we are not merging this back to master.", "I added it myself (#30583) to debug but it's no longer needed"]}, {"number": 30625, "title": "[Intel MKL] Upgrading to MKLDNN v0.20.1", "body": "", "comments": ["@nhasabni Seems like there's a merge conflict. Could you please help resolve it? Thank you!", "@penpornk I've merged master into my branch without any conflicts. Pls take a look."]}, {"number": 30624, "title": "Refactor FixedLengthRecordDataset and add tests", "body": "This PR refactors `FixedLengthRecordDataset` and add the tests.\r\n\r\ncc: @jsimsa ", "comments": []}, {"number": 30623, "title": "compile_nsync.sh does not exist", "body": "compile_nsync.sh does not exist\r\nyet again I give it up\r\nFUCK GOOGLE\r\nFUCK TENSORFLOW", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the [Github](https://github.com/tensorflow/tensorflow/issues/new/choose) new issue template.\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 30622, "title": "errorrr", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory:2344\r\n\r\n\r\n\r\n**Describe the problem**\r\nimport tensorflow as tf\r\nTraceback (most recent call last):\r\nFile \"C:\\Users\\heyx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"C:\\Users\\heyx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in \r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"C:\\Users\\heyx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nFile \"C:\\Users\\heyx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"C:\\Users\\heyx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\nreturn _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 30621, "title": "RPI3 - g++-4.8 does'nt exist on debian buster (june 2019)", "body": "no way I am gonna fill this\r\nguys, update your doc please ;-)", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30620, "title": "Feature: Add safe division in reciprocal operation", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.14 / 2.0 alpha\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nHello, \r\nI wanted to add a feature to the `tf.math.reciprocal` operation to optionally perform \"safe\" reciprocal. If the input is zero, it returns zero instead of NaN. I found this feature useful when implementing one of the recent [PR](https://github.com/tensorflow/tensorflow/pull/30152/files#diff-614af081276f42dbb98e5d731d7a1a86R158). This is similar to the [`tf.math.div_no_nan`](https://github.com/tensorflow/tensorflow/pull/21621) operation/PR. \r\n\r\nShould this feature request be approved, I can either add an optional argument to the current `tf.math.reciprocal()` operation which indicates whether to perform safe division. The default for this would be False, thus retaining the current interface. OR I can create a new tf.math operation called `tf.math.reciprocal_no_nan()` similar to the safe division op. Would love inputs on this!\r\n\r\n**Will this change the current api? How?**\r\nDepending on the two options laid out above, the first option would change the current API slightly, while the second option adds a new operation. \r\n\r\n**Who will benefit with this feature?**\r\nAny researcher designing algorithms involving reciprocals as well as engineers/developers who would otherwise write wrapper functions to perform safe reciprocals. \r\n\r\n**Any Other info.**\r\n", "comments": ["tf.math.reciprocal_no_nan is probably the best name for this", "Thank you, @alextp I'll raise a PR for this soon! Would it be possible to assign this issue to me? ", "@alextp  I am planning to implement a full-fledged operation (in C++, will be part of `gen_math_ops`) and add a wrapper on Python api similar to the other core math ops. This would have better performance and could perhaps be easily extended to other (non-python) APIs like tfjs in the future.\r\n\r\nThe other option is to try and implement it with existing TF ops in just the python api, and so only affecting the Python API.  While easier, it seems more restrictive. \r\n\r\nShould I continue with the first option or switch to the second one? Just wanted to check before I start.", "To implement a full-fledged C++ operation you probably want to change eigen to get this to vectorize well (I think? Let's ask @rmlarsen).\r\n\r\nIf you don't you won't gain much over implementing this with existing ops, which is what I mildly prefer.", "@kmh4321 This issue can be closed now!?", "@kshitij12345 sure, I  haven't taken a look at this in a while so you can close it for now. ", "Closing this issue since the associated PR has been merged and the [feature](https://www.tensorflow.org/api_docs/python/tf/math/reciprocal_no_nan) has been implemented. Thanks!"]}, {"number": 30619, "title": "TF-TRT example does not convert a graph with INT8 precision", "body": "System information\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cudnn version: 10.0/7.4.1\r\n- GPU model and memory: Titan XP\r\n\r\nI simply followed an example in the following directory to generate a resnet (resnet_v1_50) model quantized with INT8\r\n\r\n- tensorflow/tensorrt/tftrt/examples/image-classification/image_classification.py\r\n\r\nI cannot find any particular error messages in the log. Here is the summary of the graphs.\r\n\r\n- num_nodes(native_tf): 741\r\n- num_nodes(tftrt_total): 474\r\n- num_nodes(trt_only): 0\r\n- graph_size(MB)(calib): 97.8\r\n- graph_size(MB)(native_tf): 97.8\r\n- graph_size(MB)(trt): 97.8\r\n- time(s)(saving_frozen_graph): 0.5\r\n- time(s)(trt_calibration): 7.9\r\n- time(s)(trt_conversion): 1.6\r\n\r\nThe number of nodes in tftrt_total is reduced from native_tf, but cannot see any node of trt_only.\r\nI expected TRTEngineOp in the graph but I cannot see it when I read the cached INT8 graph. Most of data types are DL_FLOAT, not  DL_INT8. \r\n\r\nBased on this observation, I guess the cached graph is not a graph quantized with INT8. \r\nAny clue why it does not generate a quantized graph? I repeated this for different models such as vgg_16 and inception_v3, but I did not have a luck.\r\n\r\n", "comments": ["I managed to run it successfully by using nvidia docker container in the following link.\r\n- https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow\r\n\r\nPreviously I used TensorFlow Docker container. \r\n\r\nI checked the difference between them in terms of their execution behaviors.\r\n\r\n- The program, tensorflow/contrib/tensorrt/segment/segment.cc:461] is called in the nvidia docker container,  but it is not called in the tensorflow  docker container. \r\n- The nvidia docker container uses tensorflow 1.13.1, the tensorflow docker containers uses 1.14\r\n\r\n\r\n\r\nAnybody knows why it is so? \r\n", "Glad to know that issue is resolved, are you happy to close this issue. Thanks!"]}, {"number": 30618, "title": "[ROCm] Adding ROCm support for the stateful_random ops", "body": "This PR adds ROCm support for the stateful_random ops\r\n\r\nThe changes in this PR are mostly trivial, please review and merge.\r\n\r\n--------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30617, "title": "Save and Load keras model in multi-gpu environment changing the input and output tensor names", "body": "API Used:\r\nKerras==2.2.4\r\nTensorflow=1.13.1\r\n\r\nProblem Statement:\r\nAfter I load my saved keras model for retraining, it changes the input and output tensor names.\r\n\r\nCode to replicate:\r\n```\r\nfrom keras.applications import MobileNet\r\nfrom keras.layers import Input\r\nfrom keras.utils import multi_gpu_model\r\nfrom keras.models import model_from_json, load_model\r\n\r\ninput_tensor = Input(shape=(224, 224, 3), name=\"input\")\r\npre_trained_model = MobileNet(input_shape=(224,224,3),\r\n                                       alpha=1,\r\n                                       depth_multiplier=1,\r\n                                       dropout=1e-3,\r\n                                       include_top=True,\r\n                                       weights='imagenet',\r\n                                       input_tensor=input_tensor,\r\n                                       classes=1000)\r\nlast_layer = pre_trained_model.layers[-1].output\r\noutput_tensor = Dense(10, activation='softmax', name='output')(last_layer)\r\nmodel = Model(inputs=input_tensor, outputs=output_tensor)\r\nmodel = multi_gpu_model(model, gpus=4)\r\nmodel.compile(\r\n            optimizer='adam',\r\n            loss='binary_crossentropy',\r\n            metrics='accuracy',\r\n        )\r\n\r\n---- Training ----\r\n\r\narchitecture_file=\"model_arch.json\"\r\nweight_file=\"model_weights.h5\"\r\nmodel.save_weights(weight_file)\r\nwith open(architecture_file, 'w') as f:\r\n     f.write(model.to_json())\r\n\r\n```\r\nAfter the first training, when I froze the model and loaded into the testing environment, I could feed to ```input``` node and get output from ```output```\r\n\r\n\r\nThen reload and train again\r\n```\r\n with open(architecture_file, 'r') as f:\r\n      model = model_from_json(f.read())\r\n      model.load_weights(weight_file, by_name=True)\r\n\r\nmodel.compile(\r\n            optimizer='adam',\r\n            loss='binary_crossentropy',\r\n            metrics='accuracy',\r\n        )\r\n\r\n---- training ----\r\narchitecture_file=\"model_arch.json\"\r\nweight_file=\"model_weights.h5\"\r\nmodel.save_weights(weight_file)\r\nwith open(architecture_file, 'w') as f:\r\n     f.write(model.to_json())\r\n````\r\n\r\nAfter the second training from the saved model, when I froze the model and loaded into the testing environment,\r\nI could feed to input to ```input``` node the input node has changed to ```input_1``` ", "comments": ["I have tried same thing using ```model.save()```, the same result, the input tensor name has changed.\r\nCode to reproduce\r\n```\r\nfrom keras.applications import MobileNet\r\nfrom keras.layers import Input\r\nfrom keras.utils import multi_gpu_model\r\nfrom keras.models import model_from_json, load_model\r\n\r\ninput_tensor = Input(shape=(224, 224, 3), name=\"input\")\r\npre_trained_model = MobileNet(input_shape=(224,224,3),\r\n                                       alpha=1,\r\n                                       depth_multiplier=1,\r\n                                       dropout=1e-3,\r\n                                       include_top=True,\r\n                                       weights='imagenet',\r\n                                       input_tensor=None,\r\n                                       classes=1000)\r\nlast_layer = pre_trained_model.layers[-1].output\r\noutput_tensor = Dense(10, activation='softmax', name='output')(last_layer)\r\nmodel = Model(inputs=input_tensor, outputs=output_tensor)\r\nmodel = multi_gpu_model(model, gpus=4)\r\nmodel.compile(\r\n            optimizer='adam',\r\n            loss='binary_crossentropy',\r\n            metrics='accuracy',\r\n        )\r\n\r\n---- Training ----\r\n\r\nmodel_file=\"entire_model.h5\"\r\nmodel.save(model_file)\r\n```\r\nabove code \r\n1. Input node name by default is ```input_1```\r\n2. output node name is ```output```\r\n\r\nthen load the previous model and starts the training from where it stopped\r\n\r\n```\r\nmodel = load_model(model_file)\r\n---- training ----\r\nmodel_file=\"entire_model.h5\"\r\nmodel.save(model_file)\r\n```\r\n\r\nabove code \r\n1. Right now input has two nodes named ```input_1``` and ```input_1_1```\r\n2. output node name is ```output```\r\n\r\nbut after I load that model for prediction, I could not pass the image to ```input_1``` rather i have to use \r\n```input_1_1``` instead.\r\n\r\nThis really a problem, If I have to retrain the model it will every time adds a new input node.\r\n\r\nThe tensorboard also shows the same ```input_1_1``` as the input not the ```input_1```", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30617\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30617\">No</a>\n"]}, {"number": 30616, "title": "[Documentation] In TF 1.13.1, tf.keras.experimental.export does not exist despite being documented", "body": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/experimental/export\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOk, so let's say for some arbitrary reason out of your control (*cough* sagemaker *cough*) you are pegged to TensorFlow <= 1.13.1. The cool new `tf.keras.experimental.export` feature looks a _lot_ easier than building all that stuff yourself, so you go to try and use it.\r\n\r\nUnfortunately, you get hit with the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"documented_example.py\", line 10, in <module>\r\n    saved_to_path = tf.keras.experimental.export(\r\nAttributeError: 'module' object has no attribute 'export'\r\n```\r\n\r\n### Correct links\r\n\r\nIt is not -- the part that is `Defined in tensorflow/python/keras/saving/saved_model.py.` links to `https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/saving/saved_model.py` which gets a 404!\r\n\r\n### Parameters defined\r\n\r\nProbably.\r\n\r\n### Returns defined\r\n\r\nVery possible\r\n\r\n### Raises listed and defined\r\n\r\nYep.\r\n\r\n### Usage example\r\n\r\nYes! In fact, it doesn't work.\r\n\r\nFor posterity here's that usage example copy-pasted into a Github gist: https://gist.github.com/zmjjmz/fcc73dad9f49d34f9c047c108fdd0e3f\r\n\r\n### Submit a pull request?\r\n\r\nNope.", "comments": ["I think the issue is that the newer version (r1.14) has [this module](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/saving/saved_model.py#L47) but when the release was cut for 1.14, some changes were backported to r1.13 API documentation? ", "I was thinking that, but the difference between the documentation for 1.13's [`tf.keras.experimental.export`](https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/experimental/export) and 1.14's [`tf.keras.experimental.export_saved_model`](https://www.tensorflow.org/api_docs/python/tf/keras/experimental/export_saved_model) is pretty significant.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 30615, "title": "[ROCm] Fixes unit-test failures on the ROCm platform", "body": "This PR contains a two commits\r\n* the first commit updates a couple of python files in the TF list source to fix a couple of unit test failures we were running into on the ROCm fork. The reason for the failure was that the code was expecting \"bytes\" but was getting passed \"string\" instead. The failure does not seem ROCm specific (rather it seems to be Python3 specific), so don't know why it is not showing up on other platforms.\r\n* the second commit disables XLA support specific unit test on the ROCm platform (since support for the same has not yet been enabled in the TF repo)\r\n\r\nPlease review. thanks\r\n\r\n---------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n\r\n---------------------------------------------------\r\n\r\nupdate : amended the PR to add \"no_rocm\" tag to some tests in the `tensorflow/python/keras/distribute` directory. These tests timeout when run on a single GPU on the ROCm platform.", "comments": ["@deven-amd Can you please check Ubuntu Sanity errors? Thanks!", "> @deven-amd Can you please check Ubuntu Sanity errors? Thanks!\r\n\r\n@gbaned done. please re-approve to run CI again. thanks", "@chsigg gentle ping...please re-approve. thanks"]}, {"number": 30614, "title": "[ROCm] Adding ROCm support for the einsum op", "body": "This PR adds ROCm support for the einsum op\r\n\r\nThe changes in this PR are trivial, please review and merge. thanks.\r\n\r\n--------------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": ["I do not seem to have access to the failure log for `Linux GPU`....is there a way I can get a peek at them to figure out whether the failure is related to a change in this PR?\r\n\r\nthanks"]}, {"number": 30613, "title": "[ROCm] Re-enabling ROCm support for the average pooling op", "body": "ROCm support for the average pooling op was disabled in this commit (https://github.com/tensorflow/tensorflow/commit/151ebd0bc676e0b5f3b3fb574ff180f8fdda37f3) , because it was leading to a compiler error in the `--config=rocm` build. \r\n\r\nThat issue has now been fixed and hence filign this PR to re-enable ROCm support for the average pooling op.\r\n\r\nplease review and merge. thanks.\r\n\r\n-------------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30612, "title": "Failed to load the native TensorFlow runtime.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):pip install tensorflow\r\n\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:no gpu \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nimport tensorflow as tf\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\python.exe\" \"G:/Data Camp/keras3.6/test.py\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"G:/Data Camp/keras3.6/test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\keras3.6\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nProcess finished with exit code 1\r\n", "comments": ["@game-sys ,\r\nCan you please confirm if you have installed Visual Studio? If not, can you please install it from this [link](https://visualstudio.microsoft.com/vs/older-downloads/) and check if the issue still persists.\r\nThanks.", "installed Visual studio firstly was working on PyCharm but error not resolved\r\n\r\n\r\n  Message=Traceback (most recent call last):\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\test\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\test\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n  Source=C:\\Users\\Mohsin Ali\\source\\repos\\PythonApplication1\\PythonApplication1\\PythonApplication1.py\r\n  StackTrace:\r\n  File \"C:\\Users\\Mohsin Ali\\source\\repos\\PythonApplication1\\PythonApplication1\\PythonApplication1.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n\r\n >  File \"C:\\Users\\Mohsin Ali\\source\\repos\\PythonApplication1\\PythonApplication1\\PythonApplication1.py\", line 2, in <module>\r\n >    import tensorflow as tf\r\nLoaded 'tensorflow.python.pywrap_tensorflow'\r\nLoaded 'tensorflow.python'\r\nLoaded 'tensorflow'\r\nLoaded '__main__'\r\nThe program 'python.exe' has exited with code -1 (0xffffffff).", "anyone can suggest something as problem is not resolved till now ", "@game-sys Can you confirm your CPU supports AVX2 instructions? Thanks!", "No my CPU is xeon w3565 and I think it does not support AVX2 ", "@game-sys Please take a look at the [Tensorflow](https://www.tensorflow.org/install/source_windows#configuration_options) website. Thanks!", "got this using bazel\r\n\r\nc:\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nc:\\tensorflow/tools/bazel.rc\r\nWARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/Mohsin Ali/Anaconda3/python.exe --action_env PYTHON_LIB_PATH=C:/Users/Mohsin Ali/Anaconda3/lib/site-packages --python_path=C:/Users/Mohsin Ali/Anaconda3/python.exe --define with_xla_support=true --define with_gdr_support=true --define with_verbs_support=true --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_NEED_CUDA=0 --action_env TF_DOWNLOAD_CLANG=0 --define grpc_no_ares=true --strip=always --config monolithic --copt=-w --host_copt=-w --verbose_failures\r\nERROR: Config value monolithic is not defined in any .rc file\r\n", "@game-sys Please provide the exact command if possible to produce the output included in your test case. Thanks!\r\n", "C:\\WINDOWS\\system32>cd c:\\\r\n\r\nc:\\>cd tensorflow\r\n\r\nc:\\tensorflow>git checkout r1.9\r\nAlready on 'r1.9'\r\nYour branch is up to date with 'origin/r1.9'.\r\n\r\nc:\\tensorflow>python ./configure.py\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nc:\\tensorflow/tools/bazel.rc\r\nWARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.27.2 installed.\r\nPlease specify the location of python. [Default is C:\\Python27\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Python27\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Python27\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: .Y\r\nInvalid selection: .Y\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: Y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: Y\r\nGDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: Y\r\nVERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: N\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n\r\nc:\\tensorflow>\r\n\r\n\r\nwhat to do next?\r\n\r\n", "And also tell is above configuration is correct to run tensorflow", "@game-sys Please take a look at the instructions mentioned in the [Tensorflow website](https://www.tensorflow.org/install/source_windows) to build Tensorflow from source on Windows system.Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30611, "title": "[ROCm] Misc updates for the ROCm platform", "body": "This PR contains the following updates (to sync contents from the ROCm TF fork)\r\n * *Cuda* -> *Gpu* renamings\r\n * clang-format changes\r\n\r\nplease review and merge. thanks\r\n\r\n--------------------------------------------------------------------\r\n\r\n@tatianashp @whchung @chsigg \r\n\r\n---------------------------------------------------------------------\r\n\r\nupdate:\r\n\r\nadded two commits to the PR that a couple of minor changes\r\n", "comments": []}, {"number": 30610, "title": "[r1.13.1] ImportError for  tf.keras.applications.imagenet_utils.preprocess_input", "body": "**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS (Mojave) 10.14.4\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6.7\r\n\r\n- CUDA/cuDNN version: No GPU\r\n- GPU model and memory: No GPU\r\n\r\n**Describe the current behavior**\r\nNone of the following imports work are working on the current version:\r\n```{python}\r\nfrom tensorflow.keras.applications import imagenet_utils\r\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\r\n\r\nfrom tensorflow.keras.applications import preprocess_input\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe aforementioned imports should work. I reviewed the source code for branch r1.13 examining file `tensorflow/python/keras/applications/__init__.py`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2aca283764bbbd54a5556319eb7cc0ed323c81f1/tensorflow/python/keras/applications/__init__.py#L74-L86\r\n\r\n`preprocess_input` appears to be missing. \r\n\r\n**Code to reproduce the issue**\r\nProvided above.\r\n", "comments": ["@swghosh The above mentioned imports are available in master branch.Please have a look at this [link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/__init__.py#L53-L72). let us know if that solves the problem. Thanks!", "Sure thing, the imports appear to be working as on the master branch. Thanks for clarifying @gadagashwini"]}, {"number": 30609, "title": "(more) spurious deprecation warnings", "body": "Similar to #27897\r\n\r\n**System information**\r\n- OS Platform and Distribution\r\n Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic\r\n- TensorFlow installed from:\r\npip install tensorflow==2.0.0-beta1\r\n- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1\r\n- Python version: 3.6.8\r\n\r\n(This is happening in colab.sandbox.google.com)\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using new APIs that replaced old APIs, you deprecation warnings as if you were still using the old API.\r\n\r\n**Describe the expected behavior**\r\n\r\nIf I use the new APIs, I should not get deprecation warnings.\r\n\r\n**Code to reproduce the issue**\r\n\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport functools\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\n\r\nTRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\r\n\r\ntrain_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\r\nLABEL_COLUMN = 'survived'\r\nLABELS = [0, 1]\r\n\r\ndef get_dataset(file_path):\r\n  dataset = tf.data.experimental.make_csv_dataset(\r\n      file_path,\r\n      batch_size=12, # Artificially small to make examples easier to show.\r\n      label_name=LABEL_COLUMN,\r\n      na_value=\"?\",\r\n      num_epochs=1,\r\n      ignore_errors=True)\r\n  return dataset\r\n\r\nraw_train_data = get_dataset(train_file_path)\r\n\r\n\"\"\"\r\n-------OUTPUT------------\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0711 17:34:31.453707 140627566475136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/readers.py:498: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\n------END OUTPUT-------\r\n\"\"\"\r\n\r\nCATEGORIES = {\r\n    'sex': ['male', 'female'],\r\n    'class' : ['First', 'Second', 'Third'],\r\n    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\r\n    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\r\n    'alone' : ['y', 'n']\r\n}\r\n\r\ncategorical_columns = []\r\nfor feature, vocab in CATEGORIES.items():\r\n  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\r\n        key=feature, vocabulary_list=vocab)\r\n  categorical_columns.append(tf.feature_column.indicator_column(cat_col))\r\n\r\nMEANS = {\r\n    'age' : 29.631308,\r\n    'n_siblings_spouses' : 0.545455,\r\n    'parch' : 0.379585,\r\n    'fare' : 34.385399\r\n}\r\n\r\ndef process_continuous_data(mean, data):\r\n  # Normalize data\r\n  data = tf.cast(data, tf.float32) * 1/(2*mean)\r\n  return tf.reshape(data, [-1, 1])\r\n\r\nnumerical_columns = []\r\n\r\nfor feature in MEANS.keys():\r\n  num_col = tf.feature_column.numeric_column(feature, normalizer_fn=functools.partial(process_continuous_data, MEANS[feature]))\r\n  numerical_columns.append(num_col)\r\n\r\npreprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)\r\n\r\n\r\ndef get_model(hidden_units=[100, 100]):\r\n\r\n  model = tf.keras.Sequential([preprocessing_layer])\r\n  for units in hidden_units:\r\n    model.add(tf.keras.layers.Dense(units, activation='relu'))\r\n \r\n  return model\r\n\r\n\r\ntrain_data = raw_train_data.shuffle(500)\r\n\r\nmodel = get_model()\r\nmodel.compile(\r\n    loss='binary_crossentropy',\r\n    optimizer='adam',\r\n    metrics=['accuracy'])\r\n\r\nmodel.fit(train_data, epochs=20)\r\n\r\n\"\"\"\r\n-------OUTPUT------\r\n\r\nEpoch 1/20\r\nW0711 17:34:32.313002 140627566475136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0711 17:34:32.347570 140627566475136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4215: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\r\nW0711 17:34:32.350716 140627566475136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\r\n\"\"\"\r\n```\r\n", "comments": ["I have discovered that if I build the model Sequentially, the warnings at the end go away.\r\n\r\n```\r\nmodel = tf.keras.Sequential([\r\n  preprocessing_layer,\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dense(1, activation='sigmoid'),\r\n])\r\n\r\nmodel.compile(\r\n    loss='binary_crossentropy',\r\n    optimizer='adam',\r\n    metrics=['accuracy'])\r\n\r\nmodel.fit(train_data, epochs=20)\r\n```", "I am getting the same error as @adammichaelwood. Is there some new Feature Columns API on the way, or are these actually spurious as indicated? I have not seen any official TF 2.0 responses yes, only a workaround. \r\n ", "@rohan100jain Rohan, can you take a look how FeatureColumn APIs can be updated so that they don't print out deprecation warnings?", "https://github.com/tensorflow/tensorflow/commit/f70c46f8cd2a91b390455827cda65b5b5fe92ef0 should fix the spurious warnings. Closing bug now. Please re-open / open a new one if you still see warnings.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30609\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30609\">No</a>\n"]}, {"number": 30608, "title": "Patch fix issues", "body": "Fixes some issues from previous PRs to the branch that have been uncovered on the last attempt", "comments": []}, {"number": 30607, "title": "Little fix in docstring for DynamicRnnEstimator", "body": "The constructor has the `optimizer` argument that is referred to as 'optimizer_type' later in parameters description.", "comments": []}]