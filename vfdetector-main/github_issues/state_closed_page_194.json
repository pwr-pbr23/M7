[{"number": 48904, "title": "Update version numbers for TensorFlow 2.5.0-rc3", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 5 -> 5\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.5.0-rc2\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"2.5.0rc2\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 48903, "title": "tf.data.experimental.snapshot segfault when using repeat and prefetch", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): 2.4.0\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nUsing the following simple script, we can see a segmentation fault:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ndataset = tf.data.Dataset.from_tensor_slices(np.random.rand(16, 1024))\r\ndataset = dataset.apply(\r\n    tf.data.experimental.snapshot('snapshot'))\r\ndataset = dataset.shuffle(buffer_size=16)\r\ndataset = dataset.batch(16)\r\ndataset = dataset.repeat()\r\ndataset = dataset.prefetch(1)\r\ndef run(dataset):\r\n    iterator = iter(dataset)\r\n    for _ in range(30):\r\n        next(iterator)\r\nfor _ in range(10):\r\n    run(dataset) \r\n```\r\nIf we run it with Tensorflow 2.4.0 (or Tensorflow 2.4.1), the output is:\r\n```\r\n...\r\n2021-05-04 11:04:17.989897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-05-04 11:04:17.990504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2596985000 Hz\r\nSegmentation fault (core dumped)\r\n```\r\nIf either of `snapshot` or `repeat` or `prefetch` is removed, this would not occur.\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is that there would not be a segmentation fault\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - yes\r\nBriefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ndataset = tf.data.Dataset.from_tensor_slices(np.random.rand(16, 1024))\r\ndataset = dataset.apply(\r\n    tf.data.experimental.snapshot('snapshot'))\r\ndataset = dataset.shuffle(buffer_size=16)\r\ndataset = dataset.batch(16)\r\ndataset = dataset.repeat()\r\ndataset = dataset.prefetch(1)\r\ndef run(dataset):\r\n    iterator = iter(dataset)\r\n    for _ in range(30):\r\n        next(iterator)\r\nfor _ in range(10):\r\n    run(dataset) \r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nAnalyzing the core dump, this is the truncated stack trace:\r\n```\r\n#0  0x00007fa2236c08af in tensorflow::data::experimental::SnapshotDatasetV2Op::Dataset::Iterator::Reader::~Reader() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#1  0x00007fa2236c0971 in tensorflow::data::experimental::SnapshotDatasetV2Op::Dataset::Iterator::Reader::~Reader() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fa2236c04aa in tensorflow::data::experimental::SnapshotDatasetV2Op::Dataset::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fa2222eefee in tensorflow::data::MapDatasetOp::Dataset::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fa222335867 in tensorflow::data::ShuffleDatasetOpBase::ShuffleDatasetBase::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fa2222c13a9 in tensorflow::data::BatchDatasetOp::Dataset::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fa22232b529 in tensorflow::data::RepeatDatasetOp::Dataset::ForeverIterator::~ForeverIterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fa223e7e385 in tensorflow::data::PrefetchDatasetOp::Dataset::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fa223771615 in tensorflow::data::experimental::(anonymous namespace)::MaxIntraOpParallelismDatasetOp::Dataset::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fa2222fb665 in tensorflow::data::ModelDatasetOp::Dataset::Iterator::~Iterator() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00007fa223e441ab in std::_Sp_counted_ptr_inplace<tensorflow::data::IteratorResource::State, std::allocator<tensorflow::data::IteratorResource::State>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007fa21d44b1f6 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007fa223e4dc62 in tensorflow::data::IteratorResource::~IteratorResource() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#13 0x00007fa223e4dd51 in tensorflow::data::IteratorResource::~IteratorResource() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#14 0x00007fa2199ac086 in tensorflow::ResourceMgr::ResourceAndName::~ResourceAndName() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#15 0x00007fa2199ae73f in tensorflow::ResourceMgr::DoDelete(std::string const&, unsigned long long, std::string const&, std::string const&) ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#16 0x00007fa2199aeb89 in tensorflow::ResourceMgr::Delete(tensorflow::ResourceHandle const&) ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#17 0x00007fa223e4f684 in tensorflow::data::DeleteIteratorOp::DoCompute(tensorflow::OpKernelContext*) ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#18 0x00007fa223e444b1 in tensorflow::data::HybridAsyncOpKernel::Compute(tensorflow::OpKernelContext*) ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#19 0x00007fa22396409b in tensorflow::KernelAndDeviceOp::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<absl::lts_2020_02_25::variant<tensorflow::Tensor, tensorflow::TensorShape>, std::allocator<absl::lts_2020_02_25::variant<tensorflow::Tensor, tensorflow::TensorShape> > >*, tensorflow::CancellationManager*, absl::lts_2020_02_25::optional<tensorflow::EagerRemoteFunctionParams> const&) ()\r\n   from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#20 0x00007fa22391f359 in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_2020_02_25::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, absl::lts_2020_02_25::optional<tensorflow::EagerRemoteFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tensorflow::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tensorflow::CancellationManager*, absl::lts_2020_02_25:\r\n:Span<tensorflow::TensorHandle*>) () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#21 0x00007fa2239202c0 in tensorflow::ExecuteNode::Run() () from /home/ashahab/dev/tensorflow-build_trunk/tmp/tf-venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#22 0x00007fa22395d14f in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) ()\r\n```", "comments": ["@ashahab \r\nI was able to reproduce the issue in  TF v2.4.1, TF2.5rc1 and TF-nightly(2.6.0) with no errors Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/ee62c3dfdc40f543b17a6cc2f6431e8d/-48903.ipynb) here and let us know if it helps. Thanks!\r\n\r\n", "@UsharaniPagadala I think this is a race condition. I don't know about the execution environment of the notebook and whether it allows true multi-threading.\r\nHere are the steps I followed on a 12-core Azure nv12 box:\r\n```bash\r\n$pip install tensorflow==2.4.1\r\n$python segfault.py\r\n...\r\n2021-05-05 04:57:51.915818: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-05-05 04:57:51.915930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-05-05 04:57:51.915948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]\r\n2021-05-05 04:57:51.966764: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-05-05 04:57:51.967255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2596985000 Hz\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nLet me know if you follow the above steps you don't see the segfault.\r\n", "@jvishnuvardhan \r\nI was able to run the code in tf2.4, tf2.5rc1 and tf-nightly .Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/ee62c3dfdc40f543b17a6cc2f6431e8d/-48903.ipynb) here.Thanks", "Thanks for the link. I can also reproduce the issue.", "@yangustc07  Were you able to see the segmentation fault?", "Yes, I can see the segmentation fault and I'm working on a fix. Inputs are welcome if you have more information.", "@yangustc07 Thanks for reproducing the issue.\r\nYes I have more inputs.\r\nThis is caused only when we combine these five: snapshot, shuffle, batch, repeat, and prefetch. I have been unsuccessful in removing any of these to narrow the problem.\r\n\r\nI added some logging where snapshot Reader was getting an input reference: `input_->Ref()` and where it was returning the reference: `input_->UnRef()`. \r\nAll threads except one will first execute `input_->Ref()` and then execute `input_->UnRef()` (I logged the thread ids). However, the last thread invokes `input_->UnRef()` without doing the prior `input_->Ref()`. It's trying to invoke `input_->UnRef()` on a null(0) `input_`.\r\n\r\n\r\n\r\n", "Tried to debug more. The reason one thread does not call `input_->Ref()` is `SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize` returns a cancelled error somewhere. In that case, the destructor shouldn't call `input_->UnRef()`, and there shouldn't be any calls to `Reader::GetNextInternal()`.", "Yang, your earlier solution of commenting out ref and unref does not seem\nsafe to me, and may result in memory leaks.\n\nOn Wed, May 5, 2021 at 6:28 PM Yang Chen ***@***.***> wrote:\n\n> Tried to debug more. The reason one thread does not call input_->Ref() is\n> SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize returns a\n> cancelled error somewhere. In that case, the destructor shouldn't call\n> input_->UnRef(), and there shouldn't be any calls to\n> Reader::GetNextInternal().\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833158741>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAFISPOVBXPH7F5DAKPRRRDTMHWENANCNFSM44DJOMUA>\n> .\n>\n", "Yes, thanks for the note. I have updated the comment earlier. I have a better fix now.", "Yeah I think the fix can handle the cancellation.\n\nOn Wed, May 5, 2021 at 7:59 PM Yang Chen ***@***.***> wrote:\n\n> Yes, I have updated the comment earlier. I have a better fix now.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/48903#issuecomment-833188464>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAFISPKJQLJYY7EPEZCHVJDTMIA2LANCNFSM44DJOMUA>\n> .\n>\n", "@yangustc07 do you have a fix?", "Yes, I just submitted https://github.com/tensorflow/tensorflow/commit/858a5698a7b4ee95befa2e9c3d7aaa0a8170ec54. I'm trying to see why it changed my commit message to \"internal change.\" The original description was:\r\n\r\n```\r\n[tf.data] Fix snapshot segfault when using repeat and prefetch.\r\n\r\nFixes: https://github.com/tensorflow/tensorflow/issues/48903.\r\n\r\n`input_->MakeIterator` refs the dataset in\r\nhttps://github.com/tensorflow/tensorflow/blob/a9cf3a0e4b419630f0183b0cc4e48e0641a62721/tensorflow/core/framework/dataset.cc#L679. So\r\nwe don't need to call `input_->Ref()`. Otherwise, if\r\n`SnapshotDatasetV2Op::Dataset::Iterator::Reader::Initialize` returns an error,\r\n`input_->Ref()` isn't called, but the destructor still calls `input_->Unref()`.\r\n\r\nIf `InitializeIterator` returns an error, the iterator_ needs to be reset to\r\nnullptr. Otherwise, if GetNextInternal is called a second time,\r\n`iterator_->GetNext` may dereference a null `input_impl_`.\r\n\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48903\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48903\">No</a>\n"]}, {"number": 48900, "title": "[Cherry-Pick:2.5]Fix fetching of handle data in ResourceGather's gradient", "body": "Adds some related tests for correct shape inference\n\nFixes #48430.\n\nPiperOrigin-RevId: 371793122\nChange-Id: I61d8ff30eb46290188b32201d402a1fc173358e1", "comments": []}, {"number": 48899, "title": "[Cherry-Pick:2.5]disable irrelevant logging info for external users", "body": "PiperOrigin-RevId: 369689465\nChange-Id: Icfb10d47d88aecc9fcc4291628c0bed2e2b4f93e", "comments": []}, {"number": 48898, "title": "I am still having this issue...", "body": "@HaraBeron This is a know bug with `accuracy`. In earlier TF versions `accuracy` was correctly inferred from the `loss` function. In this case, `accuracy` need to be inferred as `sparse_categorical_accuracy` but in the current version it is not working as expected.\r\n\r\nEverything works as expected If you replace `accuracy` with `sparse_categorical_accuracy` in `model.compile` as shown below.\r\n\r\n```\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['sparse_categorical_accuracy'])\r\n```\r\n\r\n\r\n\r\n_Originally posted by @jvishnuvardhan in https://github.com/tensorflow/tensorflow/issues/42890#issuecomment-685998646_\r\n\r\n\r\n\r\n\r\nCan someone please help me about the above? I already trained a few models with TF=2.3.0, then when I tried loading the model to print some ROC curves, I got zero-accuracy across everything. I tried to compile with 'sparse_categorical_accuracy' as referenced above after I load_model, but it did not work.. Do I have to re-train all my models because of this bug?\r\n\r\nPlease help", "comments": ["Is this a dup of https://github.com/tensorflow/tensorflow/issues/41361?", "> Is this a dup of #41361?\r\n\r\nNo, I don't think so.  It's the same issue as #42890 and was marked as closed. I tried the recommended bug fix of using 'sparse_categorical_accuracy' when I compile after load_model, but it did not work\r\n\r\nThanks for the fast response :) ", "@rawansuww Can you please share a standalone code to reproduce the issue? Also mention what TF versions you are using for training (TF2.3 as you mentioned) and for loading (what TF version?). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48898\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48898\">No</a>\n"]}, {"number": 48897, "title": "Issue Bug Template - Fix rendering", "body": "", "comments": ["/cc @nikitamaia the bot internally changed some new lines as you can see in the commit https://github.com/tensorflow/tensorflow/commit/4d14ef79741dd2185f775df5e61b83272b9c7d50", "/cc @mihaimaruseac  @MarkDaoust ", "@mihaimaruseac Copybara doesn't like this :robot:  ", "Will manually import sometimes"]}, {"number": 48896, "title": "Issue", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48896\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48896\">No</a>\n"]}, {"number": 48895, "title": "Couldnot visualize convnet's internals, TypeError: Cannot convert a symbolic Keras input/output to a numpy array. Same for keras-vis and Kaggle kernel", "body": "Firstly I was checking [this notebook][1] from Kaggle, and for some reason I couldn't reproduce the **Visualizing Filter Patterns of Convolution layers** section of this notebook.\r\n\r\nI am getting this error:\r\n\r\n```\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\nTypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nRecursionError                            Traceback (most recent call last)\r\n\r\nRecursionError: maximum recursion depth exceeded\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n/usr/lib/python3.7/inspect.py in getfullargspec(func)\r\n   1130         # else. So to be fully backwards compatible, we catch all\r\n   1131         # possible exceptions here, and reraise a TypeError.\r\n-> 1132         raise TypeError('unsupported callable') from ex\r\n   1133\r\n   1134     args = []\r\n\r\nTypeError: unsupported callable\r\n```\r\n\r\n\r\n\r\nSecondly, I tried to use the [Keras blog tutorial][2],\r\n\r\nI get this error,\r\n\r\n```\r\n      4\r\n----> 5 loss, img = visualize_filter(0)\r\n      6 keras.preprocessing.image.save_img(\"0.png\", img)\r\n\r\n6 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _override_gradient_function(self, gradient_function_map)\r\n   4957\r\n   4958     # This is an internal API and we don't need nested context for this.\r\n-> 4959     assert not self._gradient_function_map\r\n   4960     self._gradient_function_map = gradient_function_map\r\n   4961     yield\r\n\r\nAssertionError:\r\n```\r\n\r\nThirdly, I found this amazing [Keras library][3], but with this too, I was unable to get anything.\r\n\r\nThis was giving same error as the first option.\r\n\r\n```\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\nTypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nRecursionError                            Traceback (most recent call last)\r\n\r\nRecursionError: maximum recursion depth exceeded while calling a Python object\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n/usr/lib/python3.7/inspect.py in getfullargspec(func)\r\n   1130         # else. So to be fully backwards compatible, we catch all\r\n   1131         # possible exceptions here, and reraise a TypeError.\r\n-> 1132         raise TypeError('unsupported callable') from ex\r\n   1133\r\n   1134     args = []\r\n\r\nTypeError: unsupported callable\r\n```\r\n\r\nI have seen this issue crop up suddenly here, but not sure if this has any way around or not.\r\n\r\n\r\nHere is the code for reproducing the errors:\r\n\r\n\r\n```python3\r\nimport matplotlib.pyplot as plt\r\nfrom datetime import datetime\r\nimport pandas as pd\r\nimport numpy as np\r\nimport glob\r\nimport time\r\nimport cv2\r\nimport os\r\n\r\n#https://drive.google.com/file/d/12q7fPPb9Lb-cL2LJxn2d_dQGHto27PYT/view?usp=sharing\r\n! wget \"https://github.com/Jimut123/simply_junk/raw/main/models/classification_model_blood.h5\"\r\n\r\nimport tensorflow as tf\r\nfrom keras.regularizers import l2\r\nfrom tensorflow.keras import datasets, layers, models\r\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, Flatten, \\\r\n                                    GlobalMaxPool2D, Dropout, SpatialDropout2D, add, concatenate\r\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\r\nfrom tensorflow.keras.optimizers import SGD, Adam\r\nfrom tensorflow.keras.models import Model\r\n\r\n# m1_1, m1_2, l1_1, l1_2, m2_1, m2_2, l2_1, l2_2, m3_1, m3_2, m3_1, m3_2, l3_1, l3_2, m4_1,\r\n\r\nH, W, C = 360, 360, 3\r\nN_LABELS = 8\r\nD = 1\r\ndef Classification(H,W,C):\r\n    \r\n    input_layer = tf.keras.Input(shape=(H, W, C))\r\n\r\n    m1_1 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=\"m1_1\", padding='same')(input_layer))\r\n    m1_2 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=\"m1_2\", padding='same')(m1_1))\r\n    m1_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=\"m1_3\", padding='same')(m1_2)))\r\n\r\n    l1_1 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=\"l1_1\", padding='same')(m1_3))\r\n    l1_2 = BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=\"l1_2\", padding='same')(l1_1))\r\n    l1_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(32, 3, activation='relu', strides=(1, 1), name=\"l1_3\", padding='same')(l1_2)))\r\n\r\n    m2_1 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=\"m2_1\", padding='same')(l1_3))\r\n    m2_2 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=\"m2_2\", padding='same')(m2_1))\r\n    m2_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=\"m2_3\", padding='same')(m2_2)))\r\n\r\n    l2_1 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=\"l2_1\", padding='same')(m2_3))\r\n    l2_2 = BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=\"l2_2\", padding='same')(l2_1))\r\n    l2_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(64, 3, activation='relu', strides=(1, 1), name=\"l2_3\", padding='same')(l2_2)))\r\n\r\n\r\n    m3_1 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=\"m3_1\", padding='same')(l2_1))\r\n    m3_2 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=\"m3_2\", padding='same')(m3_1))\r\n    m3_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=\"m3_3\", padding='same')(m3_2)))\r\n\r\n    l3_1 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=\"l3_1\", padding='same')(m3_3))\r\n    l3_2 = BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=\"l3_2\", padding='same')(l3_1))\r\n    l3_3 = MaxPool2D((2, 2))(BatchNormalization(axis=-1)(Conv2D(128, 3, activation='relu', strides=(1, 1), name=\"l3_3\", padding='same')(l3_2)))\r\n\r\n    m4_1 = BatchNormalization(axis=-1)(Conv2D(256, 3, activation='relu', strides=(2, 2), name=\"m4_1\")(l3_3))\r\n    m4_2 = BatchNormalization(axis=-1)(Conv2D(256, 3, activation='relu', strides=(2, 2), name=\"m4_2\")(m4_1))\r\n    # m4_3 = BatchNormalization(axis=-1)(Conv2D(512, 3, activation='relu', strides=(2, 2), name=\"m4_3\")(m4_2))\r\n    # m4_4 = BatchNormalization(axis=-1)(Conv2D(512, 3, activation='relu', strides=(2, 2), name=\"m4_4\")(m4_3))\r\n\r\n\r\n    #x = SpatialDropout2D(0.5, name=\"dropout_3\")(m4_4)\r\n    x = Flatten(name=\"flatten\")(m4_2)\r\n    x = Dense(512, activation='relu', name=\"dense_512\")(x)\r\n    x = Dense(N_LABELS, activation='softmax', name=\"output_layer\")(x)\r\n\r\n    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\r\n    return model\r\n\r\n\r\nmodel = Classification(H,W,C)\r\n\r\nopt = Adam(learning_rate=1e-5)\r\n\r\nmodel.compile(optimizer=opt,\r\n              loss='categorical_crossentropy',\r\n              metrics= ['accuracy'])\r\n\r\nmodel.summary()\r\n\r\n\r\nfrom tensorflow import keras\r\nmodel = keras.models.load_model('classification_model_blood.h5')\r\n\r\n# https://www.kaggle.com/anktplwl91/visualizing-what-your-convnet-learns\r\n\r\n# The purpose of this function is to just convert a numpy array to a standard image format, so that it can be displayed and viewed comfortably\r\ndef deprocess_image(x):\r\n    \r\n    x -= x.mean()\r\n    x /= (x.std() + 1e-5)\r\n    x *= 0.1\r\n    x += 0.5\r\n    x = np.clip(x, 0, 1)\r\n    x *= 255\r\n    x = np.clip(x, 0, 255).astype('uint8')\r\n\r\n    return x\r\n\r\n# This function is used to create a loss function that maximizes the value of a given filter in a convolution layer, and then we use SGD to adjust the values of the\r\n# input image so as to maximize this activation value. We pass the layer name and the filter index to the function as arguments. 'loss' is the mean for that particular\r\n# filter, 'grads' is the gradient calculated for this loss with respect to input image. Finally, SGD is run for 80 iterations which continuously maximizes the response\r\n# to input image by adding the gradient. Finally, it uses 'deprocess_image' to convert this array to a representable image format.\r\n\r\ndef generate_pattern(layer_name, filter_index, size=150):\r\n    \r\n    layer_output = model.get_layer(layer_name).output\r\n    loss = K.mean(layer_output[:, :, :, filter_index])\r\n    grads = K.gradients(loss, model.input)[0]\r\n    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\r\n    iterate = K.function([model.input], [loss, grads])\r\n    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\r\n    step = 1.\r\n    for i in range(80):\r\n        loss_value, grads_value = iterate([input_img_data])\r\n        input_img_data += grads_value * step\r\n        \r\n    img = input_img_data[0]\r\n    return deprocess_image(img)\r\n\r\n\r\n\r\n#======================================== Part 1\r\n\r\nimport os\r\nimport numpy as np # linear algebra\r\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\nimport cv2\r\nimport matplotlib.pyplot as plt\r\nimport keras.backend as K\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.preprocessing import image\r\nfrom keras.models import Model\r\nfrom keras.layers import Input, Dense, Dropout\r\nfrom keras.applications.inception_v3 import InceptionV3\r\nfrom keras.applications.inception_v3 import preprocess_input, decode_predictions\r\n\r\n%matplotlib inline\r\n\r\nfrom tensorflow.python.framework.ops import disable_eager_execution\r\ndisable_eager_execution()\r\n\r\n# Below are the patterns to which the filters from first convolution layer get activated. As we can see these are very basic cross-sectional patterns formed by\r\n# horizontal and vertical lines, which is what the these filters look in the input image and get activated if they find one.\r\nfig = plt.figure(figsize=(2, 2))\r\nfor img in range(4):\r\n    ax = fig.add_subplot(2, 2, img+1)\r\n    ax = plt.imshow(generate_pattern('l3_2', img))\r\n    plt.xticks([])\r\n    plt.yticks([])\r\n    fig.subplots_adjust(wspace=0.05, hspace=0.05)\r\n\r\n\r\n\r\n\r\n\r\n\r\n#========================== Part - 2\r\n\r\n# 'm1_1', 'm1_2', 'l1_1', 'l1_2', 'm2_1', 'm2_2', 'l2_1', 'l2_2', 'm3_1', 'm3_2', 'm3_1', 'm3_2', 'l3_1', 'l3_2', 'm4_1', 'm4_2'\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n# The dimensions of our input image\r\nimg_width = 360\r\nimg_height = 360\r\n# Our target layer: we will visualize the filters from this layer.\r\n# See `model.summary()` for list of layer names, if you want to change this.\r\nlayer_name = \"m2_2\"\r\n\r\n\r\n# Set up a model that returns the activation values for our target layer\r\nlayer = model.get_layer(name=layer_name)\r\nfeature_extractor = keras.Model(inputs=model.inputs, outputs=layer.output)\r\n\r\ndef compute_loss(input_image, filter_index):\r\n    activation = feature_extractor(input_image)\r\n    # We avoid border artifacts by only involving non-border pixels in the loss.\r\n    filter_activation = activation[:, 2:-2, 2:-2, filter_index]\r\n    return tf.reduce_mean(filter_activation)\r\n\r\n\r\n@tf.function\r\ndef gradient_ascent_step(img, filter_index, learning_rate):\r\n    with tf.GradientTape() as tape:\r\n        tape.watch(img)\r\n        loss = compute_loss(img, filter_index)\r\n    # Compute gradients.\r\n    grads = tape.gradient(loss, img)\r\n    # Normalize gradients.\r\n    grads = tf.math.l2_normalize(grads)\r\n    img += learning_rate * grads\r\n    return loss, img\r\n\r\n\r\ndef initialize_image():\r\n    # We start from a gray image with some random noise\r\n    img = tf.random.uniform((1, img_width, img_height, 3))\r\n    # ResNet50V2 expects inputs in the range [-1, +1].\r\n    # Here we scale our random inputs to [-0.125, +0.125]\r\n    return (img - 0.5) * 0.25\r\n\r\n\r\ndef visualize_filter(filter_index):\r\n    # We run gradient ascent for 20 steps\r\n    iterations = 30\r\n    learning_rate = 10.0\r\n    img = initialize_image()\r\n    for iteration in range(iterations):\r\n        loss, img = gradient_ascent_step(img, filter_index, learning_rate)\r\n\r\n    # Decode the resulting input image\r\n    img = deprocess_image(img[0].numpy())\r\n    return loss, img\r\n\r\n\r\ndef deprocess_image(img):\r\n    # Normalize array: center on 0., ensure variance is 0.15\r\n    img -= img.mean()\r\n    img /= img.std() + 1e-5\r\n    img *= 0.15\r\n\r\n    # Center crop\r\n    img = img[25:-25, 25:-25, :]\r\n\r\n    # Clip to [0, 1]\r\n    img += 0.5\r\n    img = np.clip(img, 0, 1)\r\n\r\n    # Convert to RGB array\r\n    img *= 255\r\n    img = np.clip(img, 0, 255).astype(\"uint8\")\r\n    return img\r\n\r\n\r\nfrom IPython.display import Image, display\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n\r\nloss, img = visualize_filter(0)\r\nkeras.preprocessing.image.save_img(\"0.png\", img)\r\n\r\n\r\n#======================================== Part 3\r\n\r\n! pip install keras-vis\r\n\r\nfrom keras.applications import VGG16\r\n\r\nfrom vis.losses import ActivationMaximization\r\nfrom vis.regularizers import TotalVariation, LPNorm\r\nfrom vis.input_modifiers import Jitter\r\nfrom vis.optimizer import Optimizer\r\nfrom vis.callbacks import GifGenerator\r\n\r\nimport tensorflow.compat.v2.feature_column as fc\r\n\r\n# Build the VGG16 network with ImageNet weights\r\n#model = VGG16(weights='imagenet', include_top=True)\r\nprint('Model loaded.')\r\n\r\n# The name of the layer we want to visualize\r\n# (see model definition in vggnet.py)\r\nlayer_name = 'm2_2'\r\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\r\noutput_class = [1]\r\n\r\nlosses = [\r\n    (ActivationMaximization(layer_dict[layer_name], output_class), 2),\r\n    (LPNorm(model.input), 10),\r\n    (TotalVariation(model.input), 10)\r\n]\r\nopt = Optimizer(model.input, losses)\r\nopt.minimize(max_iter=500, verbose=True, input_modifiers=[Jitter()], callbacks=[GifGenerator('opt_progress')])\r\n\r\n```\r\n\r\nHere is the [Colab][4] version. Not sure if this is a bug or not, but mostly it is difficult to perform this operation using our own custom Tensorflow functional models. Any work around would help!\r\n\r\n  [1]: https://www.kaggle.com/anktplwl91/visualizing-what-your-convnet-learns\r\n  [2]: https://keras.io/examples/vision/visualizing_what_convnets_learn/\r\n  [3]: https://github.com/raghakot/keras-vis\r\n  [4]: https://colab.research.google.com/drive/13MS7dk4ZA1OgJJVuriCfKR17dAjVIFKj?usp=sharing\r\n", "comments": ["For the first example you could try to add\r\n\r\n```\r\nexperimental_run_tf_function=False\r\n```\r\nin \r\n```\r\nmodel.compile(optimizer=opt,\r\n              loss='categorical_crossentropy',\r\n              metrics= ['accuracy'])\r\n```", "@bhack, unfortunately, it doesn't change anything. You could confirm [here](https://colab.research.google.com/drive/13MS7dk4ZA1OgJJVuriCfKR17dAjVIFKj?usp=sharing).\r\n\r\nEdit: Running again helped. Thanks!\r\n\r\nClosing issue.."]}, {"number": 48894, "title": "[tf.data] graduate rejection_resample API from experimental to tf.data.Dataset", "body": "This PR graduates the `tf.data.experimental.rejection_resample` API into `tf.data.Dataset.rejection_resample` by making the following changes:\r\n\r\n- [x] Adds the deprecation decorator for the experimental API.\r\n- [x] Add the `rejection_resample()` method to `DatasetV2` class.\r\n- [x] Updates example in documentation with new API.\r\n- [x] Regenerate golden API's.\r\n- [x] Moved and updated the `rejection_resample_test` target from experimental/kernel_tests to kernel_tests\r\n- [x] Updated the RELEASE.md file\r\n\r\nTEST LOG\r\n```\r\nINFO: Build completed successfully, 8120 total actions\r\n//tensorflow/python/data/kernel_tests:rejection_resample_test            PASSED in 5.1s\r\n  Stats over 10 runs: max = 5.1s, min = 2.6s, avg = 3.6s, dev = 0.9s\r\n```", "comments": ["```python\r\nIn [81]: import numpy as np\r\n    ...: import tensorflow as tf\r\n    ...:\r\n    ...: init_dist = [0.6 , 0.4]\r\n    ...: target_dist = [0.5, 0.5]\r\n    ...: num_classes = len(init_dist)\r\n    ...: num_samples = 10000\r\n    ...: data_np = np.random.choice(num_classes, num_samples, p=init_dist)\r\n    ...: dataset = tf.data.Dataset.from_tensor_slices(data_np)\r\n    ...: vals = defaultdict(int)\r\n    ...: for i in dataset:\r\n    ...:   vals[i.numpy()]+=1\r\n    ...: print(\"Initial distribution: {}\".format(vals))\r\nInitial distribution: defaultdict(<class 'int'>, {1: 4040, 0: 5960})\r\n\r\nIn [82]: resampler = tf.data.experimental.rejection_resample(\r\n    ...:             class_func=lambda x: x,\r\n    ...:             target_dist=target_dist,\r\n    ...:             initial_dist=init_dist)\r\n    ...:\r\n    ...: dataset = dataset.apply(resampler)\r\n    ...:\r\n    ...: from collections import defaultdict\r\n    ...: vals = defaultdict(int)\r\n    ...: for i in dataset:\r\n    ...:   vals[i[-1].numpy()]+=1\r\n    ...: print(\"Resampled distribution: {}\".format(vals))\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nProportion of examples rejected by sampler is high: [0.6][0.6 0.4][0 1]\r\nResampled distribution: defaultdict(<class 'int'>, {1: 8080, 0: 5960})\r\n```\r\n\r\ncc: @jsimsa I was playing around with the API and observed some weird behavior. In the above example, it seems like elements are being added to the `dataset` instead of being removed. \r\n", "The dataset produced by `rejection_resampling` internally uses `sample_from_datasets` to sample from a) the original dataset and b) a filtered instance of the original dataset ([code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/resampling.py#L101-L104)). \r\n\r\nIn other words, it is not unexpected that the number of output elements is greater that the cardinality of original input dataset but it is unexpected that the distribution does not match the target distribution. This is related to an issue we have recently [fixed](https://github.com/tensorflow/tensorflow/commit/5ca1f9fba95241a3e479260cfccb5042731a5ffb#diff-b2f19d0f33e0f29478a23473d4c4d8cccf294f5cb02d6f6b37e7a4ff83525c79) for `sample_from_datasets`, where the transformation would stop respecting the sampling distribution as some of the input datasets to sample from become empty. I will send a follow up CL which will update `rejection_resampling` implementation to use the new `sample_from_dataset` argument, which will fix the issue where the distribution of resampled dataset will fail to match the target distribution (in the case where a most or all elements of the resampled dataset are consumed).\r\n\r\n@yangustc07 FYI\r\n\r\nWith my fix patched, the following program (which I adopted from your example):\r\n\r\n```\r\nimport collections\r\nimport tensorflow as tf\r\n\r\ninit_dist = [0.5, 0.5]\r\ntarget_dist = [0.6, 0.4]\r\ndataset = tf.data.Dataset.range(100000)\r\nx = collections.defaultdict(int)\r\nfor i in dataset:\r\n  x[i.numpy() % 2] += 1\r\nprint(\"Initial distribution: {}\".format(x))\r\n\r\nresampler = tf.data.experimental.rejection_resample(\r\n    class_func=lambda x: x % 2,\r\n    target_dist=target_dist,\r\n    initial_dist=init_dist)\r\ndataset = dataset.apply(resampler)\r\n\r\ny = collections.defaultdict(int)\r\nfor i in dataset:\r\n  cls, _ = i\r\n  y[cls.numpy()] += 1\r\nprint(\"Resampled distribution: {}\".format(y))\r\n```\r\n\r\nProduces the following output:\r\n\r\n```\r\nInitial distribution: defaultdict(<class 'int'>, {0: 50000, 1: 50000})\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nProportion of examples rejected by sampler is high: [0.5][0.5 0.5][1 0]\r\nResampled distribution: defaultdict(<class 'int'>, {0: 75089, 1: 50000})\r\n```", "PR https://github.com/tensorflow/tensorflow/pull/49009 has been raised as a pre-requisite for the current one.", "@kvignesh1420  Can you please resolve conflicts? Thanks!", "@gbaned the file changes in this PR conflict with the ones in pre-requisite PR's. I will resolve all the conflicts in this PR once the prereqs are merged. Hope it's fine.", "@kvignesh1420 Can you please resolve conflicts? Thanks!", "@aaudiber could you please take a look? thanks"]}, {"number": 48893, "title": "Fix an issue when fusing BatchNorm in backprop", "body": "Previous PR https://github.com/tensorflow/tensorflow/pull/48063 might hit CUDNN_STATUS_NOT_SUPPORTED error if the Add node has both inputs to be the BatchNorm nodes, in which case we will mistakenly mark both BatchNormGrad as valid for fusion. Though it is not possible that both BatchNormGrad in the backward pass will be fused, there is chance that the forward pass and backward pass select different branch to fuse, causing the unexpected reserve space sizes.\r\n\r\nThis PR fixes this issue by checking if the BatchNormGrad's directly connected forward BatchNorm matches the to-be-fused forward BatchNorm. In addition, the unit tests are updated to test the double BN inputs of add op.\r\n\r\ncc. @nluehr ", "comments": []}, {"number": 48891, "title": "[Cherry-pick:r2.5]Add -lrt to tf_cc_test linkopts on Linux platforms", "body": "", "comments": []}, {"number": 48890, "title": "Build with CUDA support fails with GCC >= 10.3", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu Linux 21.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.5.0-rc2\r\n- Python version: 3.9\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3\r\n- CUDA/cuDNN version: 11.2 / 8.2\r\n\r\n**Describe the problem**\r\n\r\nBuilding tensorflow with CUDA support with GCC 10.3 fails with the following error:\r\n```\r\n/usr/include/c++/10/chrono:428:27: internal compiler error: Segmentation fault\r\n  428 |  _S_gcd(intmax_t __m, intmax_t __n) noexcept\r\n      |                           ^~~~~~\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-10/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n\r\nApparently, this is a regression starting with GCC 10.3 (default compiler on Ubuntu 21.04) when using gcc in conjunction with nvcc. Here is the upstream bug report: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=100102\r\n\r\nInstalling and using gcc-9 as NVCC host compiler in `configure` still works.", "comments": ["https://github.com/NVIDIA/nccl/issues/494\r\n", "@pwuertz \r\nWould you want to down grade to cuda 11.0 and tensorflow stable tested version 2.4.1 and let us know if you face any issues.", "> Would you want to down grade to cuda 11.0 and tensorflow stable tested version 2.4.1 and let us know if you face any issues.\r\n\r\nNot really, sorry, since I'm building everything at a non-isolated system level and require python 3.9 and CUDA 11.2 for other reasons. And as said before, building the configuration above with GCC-9 as NVCC host compiler works fine. I just wanted to make anyone who is looking for this aware and give a pointer to the upstream bug report at GCC.\r\n\r\nThe problem seems to be pretty much identified at this point, so I suppose we'll have to see and wait for an upstream fix...", "@pwuertz In the meantime can you build in our docker devel container `tensorflow/tensorflow:devel` or does it not fit your use case?", "@bhack I'm fine with my GCC-9 based build, thanks.", "I know this isn't strictly how bugs should be fixed, however, if you're desperate and under a deadline like me, comment out that block of code\r\n\r\n```\r\n        /*\r\n        static constexpr intmax_t\r\n        _S_gcd(intmax_t __m, intmax_t __n) noexcept\r\n        {\r\n          // Duration only allows positive periods so we don't need to\r\n          // support negative values here (unlike __static_gcd and std::gcd).\r\n          return (__m == 0) ? __n : (__n == 0) ? __m : _S_gcd(__n, __m % __n);\r\n        }\r\n        */\r\n```\r\nThe segmentation error disappears", "@pwuertz,  this is purely a GCC issue right?  Or are you suggesting that there is some workaround possible in the TF source code?", "@sanjoy Yes, probably a pure GCC issue. No suggestions on how to handle this on the Tensorflow end other than monitoring what's happening upstream. A warning emitted by the Tensorflow build for known-bad compiler versions would be nice, but I don't know how much work this is.\r\nCould be worthwhile though since there is no telling when we'll get a fix in GCC and at which point that patch is applied in linux-distribution-of-your-choice (if at all).", "@pwuertz  How do you change the NVCC host compiler to gcc-9? I installed gcc-9 but the nvcc still uses 10 I think. Thanks.", "> @pwuertz How do you change the NVCC host compiler to gcc-9? I installed gcc-9 but the nvcc still uses 10 I think. Thanks.\r\n\r\nWhen you `./configure` your Tensorflow build one of the questions asked will be \"Please specify which gcc should be used by nvcc as the host compiler\" or similar. You then just enter `/usr/bin/gcc-9` and you should be good to go.", "The GCC project has committed a patch:\r\n\r\nhttps://gcc.gnu.org/git/gitweb.cgi?p=gcc.git;h=5357ab75dedef403b0eebf9277d61d1cbeb5898f\r\n(in response to the problem report https://gcc.gnu.org/bugzilla/show_bug.cgi?id=100102)", "This should be fixed for newer versions of GCC, as per the above bug report. \"Fixed for GCC 10.4, 11.2 and 12.\"", "@pwuertz Could you please try to install from [source](https://www.tensorflow.org/install/source#tested_build_configurations) using latest version of TF 2.6.0 and let us know if it helps? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48890\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48890\">No</a>\n", "> @pwuertz Could you please try to install from [source](https://www.tensorflow.org/install/source#tested_build_configurations) using latest version of TF 2.6.0 and let us know if it helps? Thank you!\r\n\r\nGot a successful build with the following environment:\r\n- Tensorflow 2.7.0\r\n- CUDA 11.3\r\n- GCC 10.3.0 as NVCC host compiler (GCC 11 not supported by CUDA 11.3)\r\n- Ubuntu 21.10\r\n"]}, {"number": 48889, "title": "Which version of gast for TF 2.4?  (Autograph warning)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Centos7\r\n- TensorFlow installed from (source or binary):  Conda install\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: Conda\r\n\r\n**Describe the problem**\r\n\r\nWhen training a model, receive \"WARNING: Autograph could not transform...\" ... \"Cause: module 'gast' has no attribute 'Index'\"\r\n\r\nI have gast 0.4.0 installed.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nmodel.fit() with custom loss.\r\n\r\nSorry, can't paste long stuff in due to being on offline system.\r\n\r\nMy real question, do I need to back off to an older gats version?\r\n\r\n", "comments": ["Check https://github.com/tensorflow/tensorflow/issues/44146", "@Mastiff37   please use gast 0.3.3 for Tensorflow version 2.4. If you prefer to work with gast 0.4 use latest Tensorflow/Nightly version. Thanks!", "When I attempt to install gast 0.3.3 with conda, it wants to downgrade tensorflow-gpu to 2.2.  Is this expected?", "We don't directly support conda install here.", "Ok thanks.  This would seem to indicate that TF 2.4 is somehow telling conda it needs a newer version of gast (than 0.3.3).  My understanding is limited, but don't the TF developers provide the dependencies to conda somehow?", "If you need Conda it is supported by third-party. \r\nYou could try to ask or open a ticket at:\r\nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\r\nhttps://github.com/AnacondaRecipes/tensorflow_recipes\r\n", "@Mastiff37  Please go ahead and close the issue if you don't have any further questions. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48889\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48889\">No</a>\n", "> When I attempt to install gast 0.3.3 with conda, it wants to downgrade tensorflow-gpu to 2.2. Is this expected?\r\n\r\n@Mastiff37 I ran `pip install gast==0.3.3` inside the Conda environment. It complained about dependencies but downgraded anyway. It seems to solve the issue.", "> > When I attempt to install gast 0.3.3 with conda, it wants to downgrade tensorflow-gpu to 2.2. Is this expected?\r\n> \r\n> @Mastiff37 I ran `pip install gast==0.3.3` inside the Conda environment. It complained about dependencies but downgraded anyway. It seems to solve the issue.\r\n\r\nYes.  I'm learning that sometimes conda is just too restrictive.  pip does what it's asked.  My MO now is to use conda until I can't, then just start pipping."]}, {"number": 48887, "title": "[cherry-pick r2.5] Fix the backward RNN layer with ragged inputs.", "body": "When RaggedTensors are used in Bidirectional (or backward) RNN/LSTM/GRU layers, the current implementation silently returns incorrect values, which is a grave issue without any obvious indication. Therefore, I propose to cherry-pick it for TF 2.5 before it is released.", "comments": ["@mihaimaruseac Do you think it would it be possible to get this into the 2.5 release?", "We'll discuss this soon with the release owner."]}, {"number": 48886, "title": "Traceback (most recent call last):", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution ( Windows 10 Home ):\r\n- TensorFlow installed from (source ):\r\n- TensorFlow version: don't know \r\n- Python version: 3.9.4\r\n- Installed using virtualenv? pip? conda?: pip \r\n- GPU model and memory: AMD Redeon R4 integrated graphics card 4 gb memory \r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in _main\r\n    status = self.run(options, args)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 204, in wrapper\r\n    return func(self, options, args)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 318, in run\r\n    requirement_set = resolver.resolve(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 127, in resolve       \r\n    result = self._result = resolver.resolve(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 473, in resolve\r\n    state = resolution.resolve(requirements, max_rounds=max_rounds)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 341, in resolve\r\n    name, crit = self._merge_into_criterion(r, parent=None)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _merge_into_criterion     \r\n    if not criterion.candidates:\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 139, in __bool__\r\n    return bool(self._sequence)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in __bool__\r\n    return any(self)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 129, in <genexpr>\r\n    return (c for c in iterator if id(c) not in self._incompatible_ids)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 33, in _iter_built\r\n    candidate = func()\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 200, in _make_candidate_from_link\r\n    self._link_candidate_cache[link] = LinkCandidate(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 306, in __init__    \r\n    super().__init__(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 151, in __init__    \r\n    self.dist = self._prepare()\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 234, in _prepare    \r\n    dist = self._prepare_distribution()\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 317, in _prepare_distribution\r\n    return self._factory.preparer.prepare_linked_requirement(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\r\n    return self._prepare_linked_requirement(req, parallel_builds)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\r\n    local_file = unpack_url(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\r\n    file = get_http_url(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\r\n    from_path, content_type = download(link, temp_dir.path)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 157, in __call__\r\n    for chunk in chunks:\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 152, in iter\r\n    for x in it:\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 62, in response_chunks\r\n    for chunk in response.raw.stream(\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\r\n    data = self.read(amt=amt, decode_content=decode_content)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\r\n    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\contextlib.py\", line 135, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\r\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\r\npip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\r\nWARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\r\nWARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages) \r\n\r\n\r\n**Provide the exact sequence of commands/steps that you executed before running into the problem**\r\n`pip install tenserflow`\r\n\r\n\r\n**Any other info/logs**\r\nInclude any logos or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@its-shubham2323 \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nBased on the error please refer to: #48034,#43986,#38235, [link](https://stackoverflow.com/questions/43298872/how-to-solve-readtimeouterror-httpsconnectionpoolhost-pypi-python-org-port) and let us know.", "> pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\r\n\r\nLooks you are having weak internet connection which fails to download the pip package.\r\nPlease try with a stable connection.", "> > pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n> \n> Looks you are having weak internet connection which fails to download the pip package.\n> Please try with a stable connection.\n\nOkkk", "@its-shubham2323 \r\nplease move this to closed status if resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48886\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48886\">No</a>\n"]}, {"number": 48885, "title": "Docker Hosted automl predict ignores score_threshold param", "body": "I have deployed the .pb file exported out of GCP as per below instructions \r\n \r\nhttps://cloud.google.com/vision/automl/object-detection/docs/containers-gcs-tutorial\r\n \r\nI am able to get the response but I am getting all predictions with all scores. I tried to limit the responses with below payload and score_threshold. But its still not filtering the response with low scores and seems to be ignoring score_threshold [](url)\r\n \r\nI followed documentation at here\r\nhttps://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#google.cloud.automl.v1.PredictRequest\r\n \r\n \r\nPlace where Docker is hosted: http://localhost:8080/v1/models/default:predict\r\n \r\nPayload:\r\n{\r\n    \"instances\": [\r\n        {\r\n            \"image_bytes\": {\r\n                \"b64\": \"<base64 image>\u201d\r\n          },\r\n            \"key\": \"your-chosen-image-key123\"\r\n        }\r\n    ],\r\n                \"params\": {\r\n                \"score_threshold\": 0.7\r\n            }\r\n}\r\n ", "comments": ["I think that you need to use the feedback button in that docs page footer. It is not in the TensorFlow perimeter.", "> I think that you need to use the feedback button in that docs page footer. It is not in the TensorFlow perimeter.\r\n\r\nThe parameter is being accepted but not working. \r\nIf you try something like below payload you get an error as parameter is not identified .. Ultimately whether you host it in Docker or in GCP it should be calling the predict api \r\n\r\nhttps://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#google.cloud.automl.v1.PredictRequest\r\n\r\n{\r\n\"instances\": [\r\n{\r\n\"image_bytes\": {\r\n\"b64\": \"\u201d\r\n},\r\n\"key\": \"your-chosen-image-key123\"\r\n},\r\n\"params\": {\r\n\"score_threshold\": 0.7\r\n}\r\n]\r\n}", "@ayandebbarman Looks like this is more related to `automl`. Can you please post it in `automl` repo  https://github.com/google/automl/issues so that experts in that repository will resolve your issue faster. Thanks!", "Done https://github.com/google/automl/issues/985", "Closing as created new one in automl https://github.com/google/automl/issues/985", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48885\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48885\">No</a>\n"]}, {"number": 48883, "title": "[mlir-hlo] Added BufferReuse Optimization. ", "body": "In this PR, we want to introduce a new optimization on reusing already allocated buffers to save memory consumption. The optimization consists of two steps. First, for each buffer, we find a list of buffers that are potential reuses. A possible reuse has the following properties: \r\n- the types are compatible\r\n- no interference in the `UserangeAnalysis` (#48847)\r\n- the dominance is still given\r\n\r\nThe second step is a fixpoint iteration over the potential reuses. This step is divided into two substeps: \r\n- try to assign possible reuses for each buffer\r\n- update the potential reuses based on the assignments from step 1.\r\nAfter the distribution of all possible reusable buffers is done, they are actually replaced.\r\n```\r\nFor example:                        Result:\r\nfunc @simpleReuse(%arg0: i1) {      func @simpleReuse(%arg0: i1) {\r\n  %0 = alloc()                        %0 = alloc()\r\n  %1 = alloc()\r\n  cond_br %arg0, ^bb1, ^bb2           cond_br %arg0, ^bb1, ^bb2\r\n ^bb1:                               ^bb1:\r\n  use(%0)                             use(%0)\r\n  br ^bb3                             br ^bb3\r\n ^bb2:                               ^bb2:\r\n  use(%1)                             use(%0)\r\n  br ^bb3                             br ^bb3\r\n ^bb3:                               ^bb3:\r\n  return                              return\r\n}                                   }\r\n```\r\nIn this simple example `%1` can be replaced with `%0`, because all requirements mentioned above are fulfilled.\r\n\r\nThis PR is a follow up to #48847, in which we introduced the `UserangeAnalysis`.", "comments": ["@dfki-albo  Can you please check @sanjoy's comments and keep us posted ? Thanks!", "@dfki-albo Can you please resolve conflicts? Thanks!"]}, {"number": 48882, "title": "Tensorflow is not detecting  GPU but Pytorch is", "body": "Hi,\r\n\r\nI am on Manjaro _5.4.114-1-MANJARO_ kernel. Pytorch is detecting the GPU and using it while training the model but TensorFlow\r\n is not detecting it.\r\n\r\n![image](https://user-images.githubusercontent.com/28386721/116854848-f8990280-ac15-11eb-829c-364d85a3ac5e.png)\r\n", "comments": ["@tbhaxor ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\n\r\nThanks!", "I solved this already by using community packages with python3.9"]}, {"number": 48879, "title": "How to modify weights in TFLite model and check effect on activation layer output, set_tensor helps only on input layers and not intermediate tensors.", "body": "How to modify weights in TFLite model and check effect on activation layer output for experimentation purpose, set_tensor helps reapply things only on input layers and not intermediate tensors.\r\nI am ok doing in offline by extracting output of previous layer and convolving it with the extracted weights and biases of layer in consideration. \r\nPlease share if there is a command for that. Else how can I exactly replicate the convolution and activation process of that particular Resnet50 layer outside the model using python etc.\r\nUsing standard Resnet50- keras model, quantised by TFLite converter.\r\n\r\nTargetting conv2_block1_2 for experimentation; able to extract output of previous conv block which is input to this (conv2_block1_1) along with weights (ReadVariableOp) and bias of conv2_block1_2 from the TFLite model.\r\n\r\nTensorflow 2.0", "comments": ["@manp-git ,\r\n\r\nIn order to reproduce the issue reported here, could you please provide  the complete code and the dataset  or colab link you are using. Thanks!", "To modify the weight of the specific graph nodes, you need to edit the flatbuffer library based on the TFLite schema directly.\r\n\r\nThe TensorFlow Lite model file is based on the flatbuffer file format.", "> To modify the weight of the specific graph nodes, you need to edit the flatbuffer library based on the TFLite schema directly.\r\n> \r\n> The TensorFlow Lite model file is based on the flatbuffer file format.\r\n\r\nThanks @abattery. \r\nSo I found the following links related to what you mentioned:-\r\nhttps://www.tensorflow.org/lite/convert/metadata\r\nhttps://www.tensorflow.org/lite/api_docs/cc/class/tflite/flat-buffer-model#classtflite_1_1_flat_buffer_model_1a658e48aadda1eafb55fc7deb0434da14\r\nhttps://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/metadata/metadata_schema.fbs\r\nhttps://tensorflow.google.cn/lite/api_docs/cc/class/tflite/flat-buffer-model?hl=it\r\nhttps://analyticsindiamag.com/my-first-cnn-project-emotion-detection-using-convolutional-neural-network-with-tpu/\r\n\r\nIs there a template available which I can use to access the flatbuffer file, see the contents inside it, identify the weights tensor (array), replace with new weights and then execute the model to check effect of changed weights on the relu output of that particular node?\r\n\r\nDoes it have anything to do with JSON as i searched?\r\n\r\n", "@manp-git You can follow https://google.github.io/flatbuffers/flatbuffers_guide_tutorial.html\r\nThere is a section about mutating Flatbuffers. Our schema is https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs", "@thaink , thanks,\r\n\r\nAs per what I understand from the above links is that:\r\n\r\nI nee to install flatbuffers from Anaconda by doing:\r\nconda install -c conda-forge flatbuffers\r\nThen run the flatc command on the schema and model:\r\nflatc -t schema.fbs -- model.tflite\r\n\r\nThen can call the table elements in schema using monster command\r\nThen can edit using mutate (python support not available/ other languages to try)\r\n\r\nAnd then may be recompile to generate the new model.\r\n\r\nBut I can not find where the weights (64x3x3x64) will be in the schema.fbs,\r\nIs there a template to get this done?\r\nOr some simpler way?\r\n\r\nVery new to Computer science, never heard of these files and formats.\r\n\r\nZip file of the resnet-50 tflite model attached; Has those layers only that I pulled out for observability.\r\n[tflite_model_int8_w_conv_6.zip](https://github.com/tensorflow/tensorflow/files/6433155/tflite_model_int8_w_conv_6.zip)\r\n\r\nTargetting conv2_block1_2 for experimentation; successfully able to extract output of previous conv block which is input to this (conv2_block1_1) along with weights (ReadVariableOp) and bias of conv2_block1_2 from the TFLite model.\r\n\r\n\r\n\r\n", "Hi @thaink @abattery \r\nThis what I have done to replicate the resnet tflite model functionality outside the model, this would help me get more flexibility over my intended project:-\r\n\r\nFollowing tensors extracted from TFLite Resnet50 model for experimentation on convolution.\r\nin1.shape = (1,56,56,64)    (output from previous relu)\r\nweight_kernel.shape = (64,3,3,64)       (weight of conv_relu under consideration)\r\n\r\n\r\nin1 -> [1, height, width, channels] -> (1,56,56,64)\r\nweight_kernel -> [height, width, in_channels, out_channels] -> (3,3,64,64)\r\n\r\nApply:-\r\nimage_conv = tensorflow.nn.conv2d(in1, weight_kernel, strides=(1,1), padding='SAME', dilations=None)\r\n\r\nNow this gives me shape of output of conv, same as input shape -> (1,56,56,64)\r\n\r\n\r\n\r\nOver this I have added the biases that were extracted from the resnet model , Conv_2D_bias.shape (64,) - as shown in python and in TFlite image below.\r\n\r\nthis is done by simply doing image_conv + Conv_2D_bias\r\n\r\nthe output dimension remains the same - (1,56,56,64)\r\n\r\n\r\nNow I need to apply Relu activation from my side and compare with the existing relu output\r\n\r\nThe output from conv+bias is not visible from tflite model so cant compare.\r\n\r\nRelu output is also different; and is mentioned as Fused activation function rather than just activation\r\n\r\nMy ques is how can I replicate this computation outside the model, as a second option.  The TFLite model of Resnet as in image was attached in .zip file in previous comment along with description, for reference.\r\n\r\n![image](https://user-images.githubusercontent.com/82860513/117398438-01dae580-af1c-11eb-8020-fb9ac0cf94f3.png)\r\n", "@tilakrayal the #48933 was for me to resolve the conv issue, which I had posted as a query, then found a workaround myself.", "@manp-git I think the C++ example is prettty clear:\r\n````\r\nauto monster = GetMutableMonster(buffer_pointer);  // non-const\r\nmonster->mutate_hp(10);                      // Set the table `hp` field.\r\nmonster->mutable_pos()->mutate_z(4);         // Set struct field.\r\nmonster->mutable_inventory()->Mutate(0, 1);  // Set vector element.\r\n````\r\nHere, replace buffer_pointer by the content of the tflite after reading it to memory.\r\nAnd replace mutate_* and mutable_* function by what you are planning to do.", "> Hi @thaink @abattery \n> This what I have done to replicate the resnet tflite model functionality outside the model, this would help me get more flexibility over my intended project:-\n> \n> Following tensors extracted from TFLite Resnet50 model for experimentation on convolution.\n> in1.shape = (1,56,56,64)    (output from previous relu)\n> weight_kernel.shape = (64,3,3,64)       (weight of conv_relu under consideration)\n> \n> \n> in1 -> [1, height, width, channels] -> (1,56,56,64)\n> weight_kernel -> [height, width, in_channels, out_channels] -> (3,3,64,64)\n> \n> Apply:-\n> image_conv = tensorflow.nn.conv2d(in1, weight_kernel, strides=(1,1), padding='SAME', dilations=None)\n> \n> Now this gives me shape of output of conv, same as input shape -> (1,56,56,64)\n> \n> \n> \n> Over this I have added the biases that were extracted from the resnet model , Conv_2D_bias.shape (64,) - as shown in python and in TFlite image below.\n> \n> this is done by simply doing image_conv + Conv_2D_bias\n> \n> the output dimension remains the same - (1,56,56,64)\n> \n> \n> Now I need to apply Relu activation from my side and compare with the existing relu output\n> \n> The output from conv+bias is not visible from tflite model so cant compare.\n> \n> Relu output is also different; and is mentioned as Fused activation function rather than just activation\n> \n> My ques is how can I replicate this computation outside the model, as a second option.  The TFLite model of Resnet as in image was attached in .zip file in previous comment along with description, for reference.\n> \n> ![image](https://user-images.githubusercontent.com/82860513/117398438-01dae580-af1c-11eb-8020-fb9ac0cf94f3.png)\n> \n\nThanks @thaink, I will relook into the flatbuffer topic, but this is something that will take time for me to do the setup for.\n\nIf you could let me know on this Relu query in python code I have quoted, this suits my experimentation topic better and I have already spend a few days progressing in it.\n\nAfter applying the convolution and adding bias, how do I bring in the fused Relu correctly into picture so as to get the correct output as already in the model (given by the Identity_1). I find this method giving me good flexibility and better setup.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48879\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48879\">No</a>\n", "Hi i generated the json file using some other schema.fbs link, found in one of the github links, as the one shared was giving error. I have not gone beyond that as I checked that it is rounding off q factor to 6 decimal places, also not so well versed with it. I recreated my own fucntion to do my job for now. Will get back if I try the flat compiler method. Thanks.", "> Hi i generated the json file using some other schema.fbs link, found in one of the github links, as the one shared was giving error. I have not gone beyond that as I checked that it is rounding off q factor to 6 decimal places, also not so well versed with it. I recreated my own fucntion to do my job for now. Will get back if I try the flat compiler method. Thanks.\r\n\r\nHi @manp-git did you try the flatbuffers idea yet? Could you share your results with me please?", "> > Hi i generated the json file using some other schema.fbs link, found in one of the github links, as the one shared was giving error. I have not gone beyond that as I checked that it is rounding off q factor to 6 decimal places, also not so well versed with it. I recreated my own fucntion to do my job for now. Will get back if I try the flat compiler method. Thanks.\n> \n> Hi @manp-git did you try the flatbuffers idea yet? Could you share your results with me please?\n\nHi @dronefreak , As I am not a part of this project now, so I couldn't try further on the flatbuffers and the issue is marked closed. Thanks for dropping by."]}, {"number": 48878, "title": "[Custom Layer]ValueError: tf.function-decorated function tried to create variables on non-first call", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Colab**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**\r\n- TensorFlow installed from (source or binary): **Colab**\r\n- TensorFlow version (use command below): **Colab**\r\n- Python version: **Colab**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **Colab**\r\n- GPU model and memory: **Colab**\r\n\r\n\r\n## **Describe the current behaviour**\r\nI am trying to implement a custom transformer encoder layer **which I truly believe is the custom layer that is causing the above error**. Apart from the above layer, I have developed 3 more simple custom layers which I didn't mention here to maintain neatness.\r\n\r\n### Transformer layer\r\n\r\n    class transformer(layers.Layer):\r\n      \r\n      def __init__(self, num_heads, transformer_layers, patch_size):\r\n        super(transformer, self).__init__()\r\n        self.num_heads = num_heads\r\n        self.transformer_layers = transformer_layers\r\n        self.patch_size = patch_size\r\n      \r\n      def call(self, encoded_patches):\r\n        for _ in range(self.transformer_layers):\r\n            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\r\n            attention_output = layers.MultiHeadAttention(\r\n                num_heads = self.num_heads, key_dim = projection_dim, dropout = 0.1 \r\n            )(x1,x1)\r\n            x2 = attention_output + encoded_patches\r\n            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\r\n            x3 = mlp(x3, transformer_units, 0.2)\r\n            encoded_patches = x3 + x2\r\n    \r\n        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\r\n        resize_img = layers.Reshape([image_size // self.patch_size, image_size // self.patch_size, 64])(representation)\r\n        \r\n        return resize_img \r\n\r\n### Model \r\n\r\n    def PVT():\r\n    \r\n      # Inputs\r\n      input = layers.Input(shape=input_shape)\r\n      augment = data_augmentation(input)\r\n    \r\n      # Stage 1\r\n      patches_1 = Patch_1(patch_size_1)(augment)\r\n      patches_1 = PatchEncoder(num_patches=(image_size // patch_size_1) ** 2, projection_dim=projection_dim)(patches_1)\r\n      input_2 = transformer(num_heads, transformer_layers, patch_size_1)(patches_1) #Output 1\r\n    \r\n      # Stage 2\r\n      patches_2 = Patch_2(patch_size_2)(input_2)\r\n      patches_2 = PatchEncoder(num_patches=(image_size // patch_size_2) ** 2, projection_dim=projection_dim)(patches_2)\r\n      input_3 = transformer(num_heads, transformer_layers, patch_size_2)(patches_2) #Output 2\r\n    \r\n      # Stage 3\r\n      patches_3 = Patch_3(patch_size_3)(input_3)\r\n      patches_3 = PatchEncoder(num_patches=(image_size // patch_size_3) ** 2, projection_dim=projection_dim)(patches_3)\r\n      input_4 = transformer(num_heads, transformer_layers, patch_size_3)(patches_3) #Output 3\r\n    \r\n      # Stage 4\r\n      patches_4 = Patch_4(patch_size_4)(input_4)\r\n      patches_4 = PatchEncoder(num_patches=(image_size // patch_size_4) ** 2, projection_dim=projection_dim)(patches_4)\r\n      input_5 = transformer(num_heads, transformer_layers, patch_size_4)(patches_4) #Output 4\r\n    \r\n      representation = layers.Flatten()(input_5)\r\n      representation = layers.Dropout(0.5)(representation)\r\n      # Classify outputs.\r\n      logits = layers.Dense(num_classes)(representation)\r\n      # Create the Keras model.  \r\n      model = keras.Model(inputs=input, outputs=logits)\r\n    \r\n      return model\r\n\r\n### Compiler and optimizer\r\n\r\n    def run_experiment(model):\r\n    \r\n        optimizer = tfa.optimizers.AdamW(\r\n            learning_rate=learning_rate, weight_decay=weight_decay, beta_1=0.9, beta_2=0.999\r\n        )\r\n    \r\n        model.compile(\r\n            optimizer=optimizer,\r\n            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n            metrics=[\r\n                keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\r\n                keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\r\n            ],\r\n        )\r\n    \r\n    \r\n        history = model.fit(\r\n            x=xtrain,\r\n            y=ytrain,\r\n            batch_size=batch_size,\r\n            epochs=5,\r\n            validation_split=0.1\r\n        )\r\n    \r\n        model.save('model-5.h5')\r\n    \r\n        return history\r\n    \r\n    pvt = PVT()\r\n    history = run_experiment(pvt)\r\n\r\n### Note\r\nI have checked several sources about this but still, I am confused about understanding this error. Before you direct me to other sources, I assure you that I have already checked them all. So I sincerely request you to please provide a clean solution here. By the way, this code is my attempt to reproduce the [Pyramid vision transformers](https://arxiv.org/abs/2102.12122).\r\n\r\n### Model summary(FYI)\r\n\r\n    Model: \"model_2\"\r\n    _________________________________________________________________\r\n    Layer (type)                 Output Shape              Param #   \r\n    =================================================================\r\n    input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \r\n    _________________________________________________________________\r\n    data_augmentation (Sequentia (None, 72, 72, 3)         7         \r\n    _________________________________________________________________\r\n    patch_1_2 (Patch_1)          (None, None, 48)          0         \r\n    _________________________________________________________________\r\n    patch_encoder_8 (PatchEncode (None, 324, 64)           23872     \r\n    _________________________________________________________________\r\n    transformer_8 (transformer)  (None, 18, 18, 64)        0         \r\n    _________________________________________________________________\r\n    patch_2_2 (Patch_2)          (None, None, 4096)        0         \r\n    _________________________________________________________________\r\n    patch_encoder_9 (PatchEncode (None, 81, 64)            267392    \r\n    _________________________________________________________________\r\n    transformer_9 (transformer)  (None, 9, 9, 64)          0         \r\n    _________________________________________________________________\r\n    patch_3_2 (Patch_3)          (None, None, 16384)       0         \r\n    _________________________________________________________________\r\n    patch_encoder_10 (PatchEncod (None, 16, 64)            1049664   \r\n    _________________________________________________________________\r\n    transformer_10 (transformer) (None, 4, 4, 64)          0         \r\n    _________________________________________________________________\r\n    patch_4_2 (Patch_4)          (None, None, 65536)       0         \r\n    _________________________________________________________________\r\n    patch_encoder_11 (PatchEncod (None, 4, 64)             4194624   \r\n    _________________________________________________________________\r\n    transformer_11 (transformer) (None, 2, 2, 64)          0         \r\n    =================================================================\r\n    Total params: 5,535,559\r\n    Trainable params: 5,535,552\r\n    Non-trainable params: 7\r\n\r\n## **Describe the expected behavior**\r\nTo train without any bugs.\r\n\r\n## **Standalone code to reproduce the issue**\r\n[Colab Code](https://colab.research.google.com/drive/1o2SWFH74WnmR9Vkz352Zh9R9_fw5lnE5?usp=sharing)\r\n\r\n## **Other info/logs** \r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-15-b64accfa4347> in <module>()\r\n     27     return history\r\n     28 \r\n---> 29 pvt = PVT()\r\n     30 history = run_experiment(pvt)\r\n\r\n13 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nValueError: in user code:\r\n\r\n    <ipython-input-14-e002dca74606>:12 call  *\r\n        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1008 __call__  **\r\n        self._maybe_build(inputs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\r\n        self.build(input_shapes)  # pylint:disable=not-callable\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py:1206 build\r\n        experimental_autocast=False)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:639 add_weight\r\n        caching_device=caching_device)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:810 _add_variable_with_custom_getter\r\n        **kwargs_for_getter)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:142 make_variable\r\n        shape=variable_shape if variable_shape else None)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:260 __call__\r\n        return cls._variable_v1_call(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\r\n        shape=shape)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:731 invalid_creator_scope\r\n        \"tf.function-decorated function tried to create \"\r\n\r\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```\r\n", "comments": ["@AdityaNikhil \r\nWhile i replicate the colab shared i face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a26bd4bec65360b7b9e5e593d1c0534a/untitled598.ipynb)\r\n\r\nCould you please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/27120#issuecomment-768443779) and let us know if it helps. [similar issue #34983, [link](https://www.tensorflow.org/api_docs/python/tf/config/run_functions_eagerly)]", "Hi @Saduf2019,\r\nIt was just the cell where the variable declared was below that function. \r\nAlso, **run_eagerly** is creating a new set of problems. I don't know why. I have already gone through those links which you have posted. \r\nAnyway, can you try running my colab code again? ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@AdityaNikhil \r\nPlease share a colab gist with the issue faced.", "@Saduf2019 \r\nIf you really care about this issue, you wouldn't be here twice asking for the colab gist which is already mentioned in the issue. \r\n", "@AdityaNikhil \r\nAs mentioned in your previous comment that you face a new problem with eagerly and we do not face the same issue as shared in our gist, we request you to share a colab gist with the issue.", "@Saduf2019 \nIf it works fine, maybe there's something wrong when I am running on eagerly. I request you to send me your working gist with eagerly turned on.", "Can you check https://github.com/tensorflow/tensorflow/issues/48851#issuecomment-830858393", "@AdityaNikhil \r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48878\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48878\">No</a>\n"]}, {"number": 48877, "title": "Android implementation orientation question", "body": "Hi, I am trying to switch orientation of sample android classification app, and having trouble making screen as full-screen.\r\n\r\nI modified menifest xml's orientation from portrait to landscape, but still main cameraview of the app takes just part of the screen, which is not full-screen.\r\nBesides, when I changed orientation from portrait to landscape, logcat returns the warnings which are,\r\n```\r\nUnable to acquire a buffer item, very likely client tried to acquire more than maxImages buffers\r\n```\r\n\r\nIs there any guide or things to change to make the app's default orientation as landscape view?\r\n\r\nThanks.\r\n\r\n++ \r\nI found that there exists auto-orient code in CameraConnectionFragment.java, but it does fit to the optimal size with the comparison function, rather than the full screen size.", "comments": ["@mhyeonsoo \r\nCould you please fill the template\r\n In order to expedite the trouble-shooting process, please provide a code snippet /colab gist to reproduce the issue reported here. Thanks!\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "thanks for the response.\r\nSadly I cannot provide the code due to the policy that i am joining in.\r\nI will keep figuring out with searching issue cases.\r\nI appreciate you."]}, {"number": 48876, "title": "download error for cars196 dataset when using tfds.load", "body": "It seems \"cars196\" dataset is not available:\r\n\r\n(train_ds, val_ds, test_ds), metadata = tfds.load(\r\n    'cars196',\r\n    split=['train[:80%]', 'train[80%:]', 'test'],\r\n    with_info=True\r\n)\r\n\r\n**DownloadError**: Failed to get url https://image-net.org/internal/car196/cars_test.tgz. HTTP code: 404.", "comments": ["@imanvk \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nIf it just about the dataset, you can find them here : [link](https://www.tensorflow.org/datasets/catalog/cars196) ,[link1](https://ai.stanford.edu/~jkrause/cars/car_dataset.html)", "duplicate https://github.com/tensorflow/tensorflow/issues/48818\r\nThe host website (stanford.edu) has ceased hosting the dataset which is parsed by `tfds.load` thus you see the error.\r\nYou may track the above issue to know the progress. Closing since we already have a tracker for this. \r\nYour best bet here will be to download the [tar](http://imagenet.stanford.edu/internal/car196/car_ims.tgz) of images and locally load the dataset.\r\nThanks!"]}, {"number": 48875, "title": "Understanding distributed strategy loss for tpu training", "body": "I had some questions about distribute strategy custom training. https://www.tensorflow.org/tutorials/distribute/custom_training.\r\n\r\n\"If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the tf.nn.scale_regularization_loss function.\"\r\nWhy are regularization loss treated different compared to other type of losses?\r\n\r\n\"Using tf.reduce_mean is not recommended. Doing so divides the loss by actual per replica batch size which may vary step to step.\"\r\nHow does the batch size vary step to step per replica? Also, I am not exactly sure why we would not tf.reduce mean if the batch size changes step instead of diving by the global batch size\r\n", "comments": ["@rohanmuplara ,\r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nThanks", "closed\r\n"]}, {"number": 48874, "title": "'File' value has no field or method 'append' in in _prune_relocatable_code rule @nccl_archive//:device_pruned:", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mint 20.1, Ubuntu 20.04 base\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: origin/r2.5\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: Regular version installed via pip, but that's not the one with the issue\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 9.3\r\n- CUDA/cuDNN version: CUDA 11.3, cuDNN 8\r\n- GPU model and memory: GeForce GT 750M, Driver Version: 418.113\r\n- Clang 12\r\n- NCCL 2.9.6 installled with the local installer off nvidia site\r\n\r\nConfigure options were CUDA only, CUDA and cuDNN autodetected, python 3.8, GPU capability 3.0, using clang without experimental download, default flags, no android. Running the following line I copied off an online guide:\r\n\r\n`bazel build --config=opt --config=cuda --local_resources 2048,.5,1.0 //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nI got:\r\n```\r\nWARNING: The following configs were expanded more than once: [cuda_clang, cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'local_resources' is deprecated: --local_resources is deprecated. Please use --local_ram_resources and --local_cpu_resources instead.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=190\r\nINFO: Reading rc options for 'build' from /home/davidoso/Downloads/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/davidoso/Downloads/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /home/davidoso/Downloads/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3.8/dist-packages --python_path=/usr/bin/python3 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.3 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.0 --action_env LD_LIBRARY_PATH=:/usr/local/cuda-11.3/lib64 --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/local/bin/clang --config=cuda_clang\r\nINFO: Found applicable config definition build:short_logs in file /home/davidoso/Downloads/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/davidoso/Downloads/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:cuda_clang in file /home/davidoso/Downloads/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang\r\nINFO: Found applicable config definition build:cuda in file /home/davidoso/Downloads/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:cuda_clang in file /home/davidoso/Downloads/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang\r\nINFO: Found applicable config definition build:cuda in file /home/davidoso/Downloads/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:opt in file /home/davidoso/Downloads/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare\r\nINFO: Found applicable config definition build:cuda in file /home/davidoso/Downloads/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:linux in file /home/davidoso/Downloads/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/davidoso/Downloads/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Build options --@local_config_cuda//:cuda_compiler, --action_env, and --repo_env have changed, discarding analysis cache.\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /home/davidoso/Downloads/tensorflow/WORKSPACE:23:14: in <toplevel>\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace0.bzl:105:34: in workspace\r\n  /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nERROR: /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/nccl_archive/BUILD.bazel:54:17: in _prune_relocatable_code rule @nccl_archive//:device_pruned: \r\nTraceback (most recent call last):\r\n\tFile \"/home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/local_config_nccl/build_defs.bzl\", line 207, column 15, in _prune_relocatable_code_impl\r\n\t\toutput.append(outputs)\r\nError: 'File' value has no field or method 'append'\r\nINFO: Repository pybind11 instantiated at:\r\n  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1068:20: in _tf_repositories\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>\r\nINFO: Repository mkl_dnn_v1 instantiated at:\r\n  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:180:20: in _tf_repositories\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>\r\nINFO: Repository cython instantiated at:\r\n  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:856:20: in _tf_repositories\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>\r\nINFO: Repository jsoncpp_git instantiated at:\r\n  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:693:20: in _tf_repositories\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>\r\nINFO: Repository cudnn_frontend_archive instantiated at:\r\n  /home/davidoso/Downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:1118:21: in workspace\r\n  /home/davidoso/Downloads/tensorflow/tensorflow/workspace2.bzl:157:20: in _tf_repositories\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:112:21: in tf_http_archive\r\nRepository rule _tf_http_archive defined at:\r\n  /home/davidoso/Downloads/tensorflow/third_party/repo.bzl:65:35: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis of target '@nccl_archive//:device_pruned' failed\r\nINFO: Elapsed time: 679.978s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (363 packages loaded, 16248 targets configured)\r\n\r\n```\r\n\r\nI specifically notice the one error on the nccl part, copied below to highlight it\r\n\r\n```\r\nERROR: /home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/nccl_archive/BUILD.bazel:54:17: in _prune_relocatable_code rule @nccl_archive//:device_pruned: \r\nTraceback (most recent call last):\r\n\tFile \"/home/davidoso/.cache/bazel/_bazel_davidoso/3a3497116f85579b213da4e18ca6049d/external/local_config_nccl/build_defs.bzl\", line 207, column 15, in _prune_relocatable_code_impl\r\n\t\toutput.append(outputs)\r\nError: 'File' value has no field or method 'append'\r\n```", "comments": ["@Davidy22  Could you please try using CUDA 11.2 instead of 11.3 on a new virtual environment and let us know if you facing the issues still. Thanks!", "Duplicate issue: #48652", "Followed the solution that was taken in the attached report, replaced\r\n\r\n`output.append(outputs)`\r\n\r\nwith\r\n\r\n`outputs.append(output)`\r\n\r\nIn the offending file and it worked, might make a pull request some time if i got the time to find where this gets generated", "@Davidy22  Please go ahead and close the issue since the issue was resolved for you. Please feel free to submit a PR to fix the  issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48874\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48874\">No</a>\n", "This is fixed in c8e4f2a but it's stopping the compilation of the tarball for 2.5.0.", "This is not fixed in 2.5.1.", "I could have sworn I saw a pull request for this. The fix was just one line too. I can reopen and open a pull request.", "This is available in latest versions https://github.com/tensorflow/tensorflow/blob/master/third_party/nccl/build_defs.bzl.tpl#L207 , closing this issue . Thank you ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48874\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48874\">No</a>\n"]}, {"number": 48873, "title": "Could not initialize EfficientNet with mixed precision policy", "body": "\r\n\r\n### System information\r\n\r\n-   **Have I written custom code**: yes\r\n-   **OS Platform and Distribution**: Manjaro 21.0.3 Ornara\r\n-   **TensorFlow installed from**: binary\r\n-   **TensorFlow version**: 2.5.0-rc\r\n-   **Python version**: 3.9\r\n-   **CUDA/cuDNN version**: 11.3\r\n-   **GPU model and memory**: RTX 3060 (6GB) [laptop]\r\n-   **Exact command to reproduce**: \r\n```python\r\n# this does not work\r\nimport tensorflow as tf\r\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\r\nmodel = tf.keras.applications.EfficientNetB0()\r\n\r\n# this works\r\nimport tensorflow as tf\r\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\r\nmodel = tf.keras.applications.MobileNetV2()\r\n```\r\n\r\n### Describe the problem\r\n\r\nCould not initialize EfficientNet model using the command and environment mentioned above. This problem could not be reproduced on google colab with TF version 2.4.1 (it works on colab). Initialization of different model (MobileNetV2) works fine on my laptop (environment above).\r\n\r\n\r\n### Source code / logs\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n   1244             r_op = getattr(y, \"__r%s__\" % op_name)\r\n-> 1245             out = r_op(x)\r\n   1246             if out is NotImplemented:\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in r_binary_op_wrapper(y, x)\r\n   1265       #   r_binary_op_wrapper use different force_same_dtype values.\r\n-> 1266       y, x = maybe_promote_tensors(y, x)\r\n   1267       return func(x, y, name=name)\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in maybe_promote_tensors(force_same_dtype, *tensors)\r\n   1201       promoted_tensors.append(\r\n-> 1202           ops.convert_to_tensor(tensor, dtype, name=\"x\"))\r\n   1203     return promoted_tensors\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)\r\n    162           return func(*args, **kwargs)\r\n--> 163       return func(*args, **kwargs)\r\n    164 \r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1532     if dtype is not None and not dtype.is_compatible_with(value.dtype):\r\n-> 1533       raise ValueError(\r\n   1534           \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n\r\nValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: <tf.Tensor 'normalization/Cast:0' shape=(None, 224, 224, 3) dtype=float32>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-1-11aa21a3e81b> in <module>\r\n      1 import tensorflow as tf\r\n      2 tf.keras.mixed_precision.set_global_policy('mixed_float16')\r\n----> 3 model = tf.keras.applications.EfficientNetB0()\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/applications/efficientnet.py in EfficientNetB0(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\r\n    533                    classifier_activation='softmax',\r\n    534                    **kwargs):\r\n--> 535   return EfficientNet(\r\n    536       1.0,\r\n    537       1.0,\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/applications/efficientnet.py in EfficientNet(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\r\n    319   x = img_input\r\n    320   x = layers.Rescaling(1. / 255.)(x)\r\n--> 321   x = layers.Normalization(axis=bn_axis)(x)\r\n    322 \r\n    323   x = layers.ZeroPadding2D(\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    967     # >> model = tf.keras.Model(inputs, outputs)\r\n    968     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\r\n--> 969       return self._functional_construction_call(inputs, args, kwargs,\r\n    970                                                 input_list)\r\n    971 \r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)\r\n   1105         layer=self, inputs=inputs, build_graph=True, training=training_value):\r\n   1106       # Check input assumptions set after layer building, e.g. input shape.\r\n-> 1107       outputs = self._keras_tensor_symbolic_call(\r\n   1108           inputs, input_masks, args, kwargs)\r\n   1109 \r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)\r\n    838       return nest.map_structure(keras_tensor.KerasTensor, output_signature)\r\n    839     else:\r\n--> 840       return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n    841 \r\n    842   def _infer_output_signature(self, inputs, args, kwargs, input_masks):\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)\r\n    878           self._maybe_build(inputs)\r\n    879           inputs = self._maybe_cast_inputs(inputs)\r\n--> 880           outputs = call_fn(inputs, *args, **kwargs)\r\n    881 \r\n    882         self._handle_activity_regularization(inputs, outputs)\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/keras/layers/preprocessing/normalization.py in call(self, inputs)\r\n    240     mean = array_ops.reshape(self.mean, self._broadcast_shape)\r\n    241     variance = array_ops.reshape(self.variance, self._broadcast_shape)\r\n--> 242     return ((inputs - mean) /\r\n    243             math_ops.maximum(math_ops.sqrt(variance), backend.epsilon()))\r\n    244 \r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n   1248             return out\r\n   1249           except (TypeError, ValueError):\r\n-> 1250             raise e\r\n   1251         else:\r\n   1252           raise\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n   1232         #   r_binary_op_wrapper use different force_same_dtype values.\r\n   1233         x, y = maybe_promote_tensors(x, y, force_same_dtype=False)\r\n-> 1234         return func(x, y, name=name)\r\n   1235       except (TypeError, ValueError) as e:\r\n   1236         # Even if dispatching the op failed, the RHS may be a tensor aware\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    204     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    205     try:\r\n--> 206       return target(*args, **kwargs)\r\n    207     except (TypeError, ValueError):\r\n    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py in subtract(x, y, name)\r\n    546 @dispatch.add_dispatch_support\r\n    547 def subtract(x, y, name=None):\r\n--> 548   return gen_math_ops.sub(x, y, name)\r\n    549 \r\n    550 \r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py in sub(x, y, name)\r\n  10559       pass  # Add nodes to the TensorFlow graph.\r\n  10560   # Add nodes to the TensorFlow graph.\r\n> 10561   _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n  10562         \"Sub\", x=x, y=y, name=name)\r\n  10563   _result = _outputs[:]\r\n\r\n~/venv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\r\n    553                   inferred_from[k] = \"Default in OpDef\"\r\n    554 \r\n--> 555             raise TypeError(\r\n    556                 \"%s type %s of argument '%s'.\" %\r\n    557                 (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\r\n\r\nTypeError: Input 'y' of 'Sub' Op has type float16 that does not match type float32 of argument 'x'.\r\n```\r\n", "comments": ["@PetrDvoracek \r\nI ran the code in tf 2.5rc1 and tf-nightly,did not face any errors.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/c87b68e164fc8b5fbe1a7fde1c2a3f93/untitled31.ipynb) here \r\n\r\nand also\r\nCould you please have a look on the similar issues [#39982](https://github.com/tensorflow/tensorflow/issues/39982),[#34406](https://github.com/tensorflow/tensorflow/issues/34406) it may help you.Thanks", "@UsharaniPagadala \r\nThanks, the problem persists on my laptop even after installing tf-nightly (2.6.0). \r\n\r\nMore details about the environment  (long part removed):\r\n```\r\n\r\n== check python ===================================================\r\npython version: 3.9.4\r\npython branch: \r\npython build version: ('default', 'Apr 20 2021 15:51:38')\r\npython compiler version: GCC 10.2.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 10.2.0\r\nCopyright (C) 2020 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy                   1.19.5\r\nprotobuf                3.15.8\r\ntensorflow              2.5.0rc1\r\ntensorflow-estimator    2.5.0rc0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.5.0-rc1\r\ntf.version.GIT_VERSION = v2.5.0-rc0-36-g0d1805aede0\r\ntf.version.COMPILER_VERSION = 7.3.1 20180303\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nMon May  3 14:20:13 2021       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 306...  Off  | 00000000:01:00.0  On |                  N/A |\r\n| N/A   39C    P8    12W /  N/A |    585MiB /  5921MiB |      1%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A       620      G   /usr/lib/Xorg                     495MiB |\r\n|    0   N/A  N/A      1237      G   picom                               2MiB |\r\n|    0   N/A  N/A      2499      G   ...AAAAAAAA== --shared-files       71MiB |\r\n|    0   N/A  N/A      3276      G   /usr/lib/firefox/firefox            2MiB |\r\n|    0   N/A  N/A      3567      G   /usr/lib/firefox/firefox            2MiB |\r\n|    0   N/A  N/A      3786      G   /usr/lib/firefox/firefox            2MiB |\r\n|    0   N/A  N/A      3838      G   /usr/lib/firefox/firefox            2MiB |\r\n|    0   N/A  N/A      4791      G   /usr/lib/firefox/firefox            2MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.5.0rc1\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /home/pedro/venv/lib/python3.9/site-packages\r\nRequired-by: \r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 9, 4, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\n```", "@PetrDvoracek \r\nAs this issue is not reflecting in our colab gist, can you please confirm if you face this issue on stable version 2.4.1 along with cuda 11.0 [cuda version 11.2 is tested with tf 2.5, there is no update on 11.3] \r\nalso please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/33484#issuecomment-555299647) and let us know if it helps.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48873\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48873\">No</a>\n", "Commenting to link [a newer issue, #50171](https://github.com/tensorflow/tensorflow/issues/50171) which says that this issue has been resolved"]}, {"number": 48872, "title": "[Go] simplify generation of go protos", "body": "Simplify generation of protos for Go installation.  Fixes #48870.", "comments": ["The force-push amends the earlier commit which had added a call to `go get`.  I've removed the call in favor of #50312.  This PR still intends to address the problems associated with having generate.sh create a vendor directory. ", "@gharibian  Can you please review this PR ? Thanks!"]}, {"number": 48871, "title": "Fix compilation error caused by cuda and cusparse stub files", "body": "This pr fix compilation error caused by cuda and cusparse stub files, tested in cuda 10.1.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48871) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "As written, I'm not sure if this PR is correct.  Can you please share some more details on what the root cause was and how you fixed it?", "Of course.\r\nWhen compiling `//tensorflow/stream_executor/cuda:cudart_stub` in cuda 9.0/10.0/10.1/11.2, In function `cudaChannelFormatDesc cudaCreateChannelDesc(int, int, int, int, cudaChannelFormatKind)`, the return value type of `GetSymbolNotFoundError()` is `cudaError_t`, and it does not match the return value type expected by `cudaCreateChannelDesc`. These changes refer to `cuda_runtime_11_0.inc`. The changes in file `cusparese_x_x.inc` are similar.", "@sanjoy Can you please assist on above comments from @xcnick. Thanks!", "Close this pr since it has been fixed."]}, {"number": 48870, "title": "Go generation of protos during install is problematic", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Debian Buster\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5.0-rc2\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 8.3.0-6\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the problem**\r\n\r\nThere exists a general issue, of which this specific issue contributes, that installation and use of Tensorflow in Golang is complicated. Use of `go get` to obtain Tensorflow fails.  The reason for this is that the protos need to be generated; see #44655 and discussion that including generated protos would create a maintenance issue.  To resolve this, a user must fetch the repo and then issue the following command:\r\n\r\n```sh\r\ngo generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\n```\r\n\r\nThis results in two problems:\r\n\r\n1. The `go generate` command errors and completes with a non-zero exit status:\r\n\r\n```\r\n../genop/internal/api_def_map.go:34:2: no required module provides package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/api_def_go_proto; to add it:\r\n        go get github.com/tensorflow/tensorflow/tensorflow/go/core/framework/api_def_go_proto\r\n../genop/internal/api_def_map.go:35:2: no required module provides package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/op_def_go_proto; to add it:\r\n        go get github.com/tensorflow/tensorflow/tensorflow/go/core/framework/op_def_go_proto\r\ngenerate.go:18: running \"go\": exit status 1\r\n```\r\n\r\n2. The generated protos are written to a vendor directory (`tensorflow/go/vendor`), although Go will not search for them there. The `vendor` directory is not meant for adding arbitrary modules (see [https://github.com/golang/go/issues/29079](https://github.com/golang/go/issues/29079)).  Thus, the contents must be manually relocated from the vendor directory to `tensorflow/go`.\r\n\r\n### Proposed resolution\r\n\r\nTo make installation more straightforward, I propose that the protos be output in their correct location with the source tree (not in `vendor`).  Indeed, `tensorflow/go/op/generate.go` does this to some extent now, overwriting `wrappers.go` in the source tree. \r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48870\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48870\">No</a>\n"]}, {"number": 48869, "title": "Flag TF_GPU_ALLOCATOR=cuda_malloc_async ( to work with large tensors),  results in: \" Error in py_call_impl(callable, dots$args, dots$keywords) :    InternalError: No allocator statistics \"", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): my code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Rstudio\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): \"v2.5.0-rc0-36-g0d1805aede0\"\r\n- Python version: 3.7.3\r\n\r\n- CUDA/cuDNN version: 11.2.1\r\n- GPU model and memory: 3070/8G\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nTo work with large files, like 3GB, it returns an error asking for setting that flag. \r\nThe flat set, TF_GPU_ALLOCATOR=cuda_malloc_async , it can handle the\r\nobject fine, but tensorflow no longer is able to run training, or load\r\nsaved models, even from keras.applications\r\n\r\n**Describe the expected behavior**\r\nLoad models without any error\r\n\r\n**Standalone code to reproduce the issue**\r\non rstudio, but i belive would be the same on python \r\n\r\na<- application_densenet121(input_shape = c(256,256,3), include_top = F)\r\n\r\n2021-05-02 07:59:46.375811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-05-02 07:59:46.376160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-05-02 07:59:46.376323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-05-02 07:59:46.376479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2021-05-02 07:59:46.376581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n Error in py_call_impl(callable, dots$args, dots$keywords) : \r\n  InternalError: No allocator statistics \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThis error, \" Error in py_call_impl(callable, dots$args, dots$keywords) : \r\n  InternalError: No allocator statistics \"\r\nhappens in many other circunstancies, loading saved model, or even to run any model.\r\n\r\nhappend on tf 2.5.0-rc1/ 2.5.0-rc2/2.4.1. If disable the flag, the error doesnt happen, but \r\ntensorflow cant handle larger tensors, like images over 2GB.\r\n\r\n\r\n", "comments": ["@trentlo @chsigg Any idea what's going on?", "> @trentlo @chsigg Any idea what's going on?\r\n\r\nThis is a known issue that we mention to you in the last meeting.\r\n\r\n@nouiz is back. He knows more. (@bas-aarts FYI.)\r\n", "This diff fix at least part of the problem:\r\n```\r\ndiff --git a/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h b/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h\r\nindex 8c7613992ea..b04c592046e 100644\r\n--- a/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h\r\n+++ b/tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.h\r\n@@ -67,7 +67,7 @@ class GpuCudaMallocAsyncAllocator : public Allocator {\r\n   explicit GpuCudaMallocAsyncAllocator(PlatformDeviceId platform_device_id,\r\n                                        size_t pool_size,\r\n                                        bool reserve_memory = false,\r\n-                                       bool compute_stats = false);\r\n+                                       bool compute_stats = true);\r\n   ~GpuCudaMallocAsyncAllocator() override;\r\n   string Name() override { return name_; }\r\n   void* AllocateRaw(size_t alignment, size_t num_bytes) override;\r\n```\r\n\r\nBut I have problems building upstream TF in our container. So I have difficulty investigating this. Here is the error in case you have an idea what is going on:\r\n\r\n```\r\nExecution platform: @local_execution_config_platform//:platform\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: /root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/t\r\nensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow7functor12UnaryFunctorIN5Eigen9GpuDeviceENS0_3negINS2_4halfEEEEclERKS3_NS2_9TensorMapINS2_6TensorIS5_Li1ELi1ElEELi16ENS2_11MakePointerEEENSA_\r\nINSB_IKS5_Li1ELi1ElEELi16ESD_EE\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/tools/api/generator/create_python_api.py\", line 26, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/eager/context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensor\r\nflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: /root/.cache/bazel/_bazel_root/45a7ca8b5c99c684c2d5c22cdd8175f0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/t\r\nensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow7functor12UnaryFunctorIN5Eigen9GpuDeviceENS0_3negINS2_4halfEEEEclERKS3_NS2_9TensorMapINS2_6TensorIS5_Li1ELi1ElEELi16ENS2_11MakePointerEEENSA_\r\nINSB_IKS5_Li1ELi1ElEELi16ESD_EE\r\n```\r\n", "I fixed the above link error. But now compiling TF is way longer... So I'm still blocked. See this new nvbug:\r\nhttps://github.com/tensorflow/tensorflow/issues/48966", "There is more ( maybe it helps): I trained a model on images data using tensorflow 2.5.0-rc3.  when making predicitnons, it resulted in Out of Memory error.  Then i downgraded to 2.4.1, loading the same pre-trainned model and data ( same batch_size,etc). The predicitons were just fine, using at least, 1.5GB less of my GPU memory ( it has 8GB).  ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48869\">No</a>\n"]}, {"number": 48868, "title": "\"Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\"", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.0\r\n- Python version: 3.8.8\r\n- Installed using virtualenv? pip? conda?: pip inside a virtualenv.\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: v11.0.3_451.82 / cudnn-11.0-windows-x64-v8.0.4.30.zip\r\n- GPU model and memory: 2080 8G\r\n-Nvidia driver version: 465.89\r\n\r\n\r\n**Describe the problem**\r\n\r\nA similar issue as to #46606, #43193, and #45055. When attempting to run `python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"`, I get the following trace;\r\n\r\n`2021-05-02 16:52:00.618495: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\r\n2021-05-02 16:52:00.618653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2021-05-02 16:52:02.101881: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-05-02 16:52:02.102613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-05-02 16:52:02.130031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\r\ncoreClock: 1.845GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.23GiB/s\r\n2021-05-02 16:52:02.130365: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\r\n2021-05-02 16:52:02.130609: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\r\n2021-05-02 16:52:02.130862: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\r\n2021-05-02 16:52:02.131045: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\r\n2021-05-02 16:52:02.131225: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\r\n2021-05-02 16:52:02.131484: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n2021-05-02 16:52:02.131796: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\r\n2021-05-02 16:52:02.132066: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\r\n2021-05-02 16:52:02.132188: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2021-05-02 16:52:02.132804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-05-02 16:52:02.133414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-05-02 16:52:02.133546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]\r\n2021-05-02 16:52:02.133646: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\ntf.Tensor(-115.45033, shape=(), dtype=float32)`\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI continue to get the above issue despite following the steps and suggestions in each of the other similar issues.\r\n\r\nI tried adding the environmental variables through cmd, which wasn't mirrored in the GUI so I added them there as well. This did not fix the issue.\r\n\r\nI re-installed the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. This did not fix the issue.\r\n\r\nI enabled long paths. This did not fix the issue.\r\n\r\nI was already on a 64bit release of Python 3.8.8, which the venv I'm using was created with.\r\n\r\nI've restarted the terminal and restarted my PC several times, which did not fix the issue.\r\n\r\nI created the C:\\tools\\cuda folder and extracted the contents of the cuDNN there, and ensured that it was on PATH. This confuses me since it's not mentioned as a necessity in the installation process of cuDNN itself. Either way, this did not fix the issue.\r\n\r\n**Any other info / logs**\r\ndeviceQuery running.\r\n![image](https://user-images.githubusercontent.com/16676174/116808189-0c872a80-ab6a-11eb-995e-87fd672736f8.png)\r\nAll the items in PATH.\r\n![image](https://user-images.githubusercontent.com/16676174/116808218-30e30700-ab6a-11eb-86e8-8ea6e6caae1e.png)\r\nThe contents of the CUDA bin folder, showing the supposedly missing files exist.\r\n![image](https://user-images.githubusercontent.com/16676174/116808272-7dc6dd80-ab6a-11eb-9561-18d6b2edc3be.png)\r\n\r\nThank you in advance for your help.\r\n", "comments": ["@willawebb \r\nCould you please try with cuda 11.0 and cudnn 8.0 as i see you have mentioned cudnn 11 in the template.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I was able to get past this error by doing `os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")` before importing tensorflow", "> I was able to get past this error by doing `os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")` before importing tensorflow\r\n\r\nThanks, it saved my day!", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48868\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48868\">No</a>\n", "bumping this here because the fix looks like temporary. I did not face this issue using python 3.8 in a virtualenv but occured in system python 3.9 on windows. From the people it also looks like a windows issue. Even though the cuda paths added to path correctly, it still doesn't recognize the appropriate dll's.\r\n\r\n# EDIT\r\n\r\nI can confirm the fault is on windows. If you install the python from store, python doesn't load the path. Install it from python official website.", "> I was able to get past this error by doing `os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")` before importing tensorflow\r\n\r\nOh my god I've been 3 days through this error and I was desperated. You saved me I love you bro", "Can anyone please say where should one add  `os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")` this to get through this error?", "@karthik-653 Before impoting anything(besides os ofc) should work. ", "I am currently facing this same issue however when try to use os.add_dll_directory I get an error saying it is not recognised as an internal or external command, operable program or batch file. Does anyone have any idea why this could be or how to fix it as have been struggling to get tensorflow up and running for weeks?\r\n  ", "This solution (the answer on the issue) is for PYTHON. THIS IS PYTHON ISSUE. SPECIFICALLY STORE INSTALLED WHATEVER YOUR PYTHON CODE YOU ARE RUNN\u0130NG. ADD THIS TO THE TOP OF THE FILE. E.G. IF YOU ARE RUNNING THE CODE WITH `python main.py`, add below code to top of the main.py file\r\n\r\n\r\n```python\r\nimport os\r\nos.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\r\n```\r\nChange path accordingly with your cuda version.", "Thank you, but this still didn't solve my error. I had to copy the files into System32 in order for it to find the correct file. Im not sure why this worked but it did. \r\n", "Hi I am also facing the issue...\r\n\r\n`AttributeError: module 'os' has no attribute 'add_dll_directory'`\r\n\r\nmy main error being:\r\n\r\n`\r\n2021-10-06 16:50:11.172266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\r\n2021-10-06 16:50:11.172767: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\ntensorflow version 2.6.0\r\n2021-10-06 16:50:14.261542: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\r\n2021-10-06 16:50:14.265953: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PARTH\r\n2021-10-06 16:50:14.266241: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PARTH\r\n2021-10-06 16:50:14.267446: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n`", "> os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\r\n\r\nThank you, saved my day! Still works for 11.5.", "> I was able to get past this error by doing `os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")` before importing tensorflow\r\n\r\nThanks so much! I've spent far too long looking at this. They should add this to the Windows setup in the tensorflow docs, or fix the issue.", "> subtype:windows\r\n\r\nYes it really was windows program. It is working fine now... thnx", "I know this is a bit older now but I also ran into this issue.  All my paths are fine, and in a conda env it works but using a python env seems to throw that error no matter what I tried, until I found this thread with the workaround.\r\n\r\nAnyone ever figure this issue out?"]}]