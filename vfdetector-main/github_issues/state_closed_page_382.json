[{"number": 42533, "title": "Pin numpy version to 1.19", "body": "Pin numpy version to 1.19.0", "comments": []}, {"number": 42532, "title": "[TF:MLIR] Add complex type reciprocal pattern to TF to TF lowerings", "body": "", "comments": []}, {"number": 42531, "title": "[Horovod Unittest] - Script Fix", "body": "@pkanwar23 I fixed the code and tested in the container: `nvidia/cuda:11.0-devel-ubuntu18.04` it works \r\n@tgaddair I switched the script to use master as you requested ;)", "comments": ["@pkanwar23 I added it back.\r\nThis line made the install to fain on my side. If it keeps on fail. I would advise to look into that line", "@DEKHTIARJonathan Can you please resolve conflicts? Thanks!"]}, {"number": 42530, "title": "Remove _filtered_call and reduce isinstance checks for Tensors/Variables", "body": "", "comments": ["Benchmarks over 3 batches of 10 trials each\r\n\r\nMinimum\r\ndefun_matmul_2_by_2_CPU: 153.5 -> 157 us\r\ndefun_matmul_2_by_2_CPU_async: 80.5 -> 78 us\r\ndefun_matmul_2_by_2_with_signature_CPU: 211 -> 219.5 us\r\n\r\nMean\r\ndefun_matmul_2_by_2_CPU: 178.5 -> 172 us\r\ndefun_matmul_2_by_2_CPU_async: 84 -> 82 us\r\ndefun_matmul_2_by_2_with_signature_CPU: 244.5 -> 246 us\r\n\r\nMedian\r\ndefun_matmul_2_by_2_CPU: 178-> 176.5 us\r\ndefun_matmul_2_by_2_CPU_async: 83.5 -> 81.5 us\r\ndefun_matmul_2_by_2_with_signature_CPU: 233.5 -> 233 us\r\n\r\nSlight improvement, if at all"]}, {"number": 42529, "title": "Reform the benchmark rules.", "body": "We provide the benchmarks by sorted batch_size, and also provide GPU benchmark with maximum batch_size for current model. For `cifar10_cnn_benchmark_test`, we used the small epochs to get the results quickly.", "comments": ["@yhliang2018 I think this PR should be approved."]}, {"number": 42528, "title": "Model.save(...) throws exception ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nModel.save() throws exceptions when having \"kernel_initializer=tf.initializers.zeros\" to Dense. If it is removed, the \"save()\" works.  The exception is:\r\n\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in serialize_keras_object(instance)\r\n...\r\n    243     name = get_registered_name(instance.__class__)\r\n    244     try:\r\n--> 245       config = instance.get_config()\r\n    246     except NotImplementedError as e:\r\n    247       if _SKIP_FAILED_SERIALIZATION:\r\n\r\nTypeError: get_config() missing 1 required positional argument: 'self'\r\n```\r\n\r\nThe complete model is:\r\n\r\n```\r\nmulti_lstm_model = tf.keras.Sequential([\r\n    # Shape [batch, time, features] => [batch, lstm_units]\r\n    # Adding more `lstm_units` just overfits more quickly.\r\n    tf.keras.layers.LSTM(32, return_sequences=False),\r\n    # Shape => [batch, out_steps*features]\r\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\r\n                          kernel_initializer=tf.initializers.zeros),\r\n    # Shape => [batch, out_steps, features]\r\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\r\n])\r\n```\r\n\r\nThe save is: \r\n`multi_lstm_model.save('multi_lstm_model')`\r\n\r\n\r\n\r\nThe code is from: https://www.tensorflow.org/tutorials/structured_data/time_series\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@dyu41,\r\nOn changing `kernel_initializer=tf.initializers.zeros` to `kernel_initializer=tf.initializers.zeros()` I was able to save the model without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/4a45f62c7c310a5950777a5e33bddeb0/42528.ipynb#scrollTo=mspbNLWN_TY0&line=1&uniqifier=1). Thanks!", "The workaround works! Thank you very much!\r\n\r\nOn Fri, Aug 21, 2020 at 8:38 AM Abhilash Mahendrakar <\r\nnotifications@github.com> wrote:\r\n\r\n> @dyu41 <https://github.com/dyu41>,\r\n> On changing kernel_initializer=tf.initializers.zeros to\r\n> kernel_initializer=tf.initializers.zeros() I was able to save the model\r\n> without any issues. Please find the gist of it here\r\n> <https://colab.research.google.com/gist/amahendrakar/4a45f62c7c310a5950777a5e33bddeb0/42528.ipynb#scrollTo=mspbNLWN_TY0&line=1&uniqifier=1>.\r\n> Thanks!\r\n>\r\n> \u2014\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/42528#issuecomment-678268757>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AQAYXPHOBDGTVQHGSL5K743SBZTFZANCNFSM4QGTCC2Q>\r\n> .\r\n>\r\n", "@dyu41,\r\nThank you for the update. Marking this issue as closed since it is resolved. Please feel free to re-open the issue if necessary. "]}, {"number": 42527, "title": "Revert \"Update CONTRIBUTING.md\"", "body": "Reverts tensorflow/tensorflow#42501", "comments": []}, {"number": 42526, "title": "Fix README.md", "body": "", "comments": []}, {"number": 42525, "title": "[TF:MLIR] Add TF to TF lowering patterns to legalize_tf pass for TFLite", "body": "The TF lowering patterns are useful across multiple different backends. This PR adds the lowering patterns from TF to TFLite so  that TFLite specific code can focus on lowerings unique to it. We can also automatically benefit from any TF lowerings that get added without having to manually sync it with TFLite if TFLite didn't use the lowering patterns of TF directly. \r\n\r\n", "comments": ["@ahmedsabie  Can you please check @smit-hinsu's comments and resolve conflicts?. Thanks!", "@ahmedsabie  Can you please resolve conflicts? Thanks!", "Instead of importing all the lowering patterns, it would be better to apply a subset since TFLite offers a fused operation for example, SpaceToBatchND op and so on.", "> Instead of importing all the lowering patterns, it would be better to apply a subset since TFLite offers a fused operation for example, SpaceToBatchND op and so on.\r\n\r\nThe issue is that then we have to sync everytime a new lower operation is adder that would be useful. Also the test coverage has tests to ensure these fused ops are the chosen ones rather than the TF which is how an issue was caught with the first iteration of the PR", "It would be better to have our own method for pattern registration for TFLite conversion path. Also, leave some comments for future contributor to lowering patterns in order to register both patterns when the new ones are appropriate to TFLite conversion pipeline.", "As discussed offline, we can proceed with the original change.", "Hey @gbaned I noticed that the oneDNN unit tests have failed in multiple PRs made around the same time as my last update. Looking through the error output it wasn't too clear what failed in the test is this an unrelated issue? Or do you have any suggestions on how I can debug this? Thanks!"]}, {"number": 42524, "title": "Error building custom op with g++", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n```\r\n# /usr/bin/g++ -I /usr/local/lib/python3.7/site-packages/tensorflow_core/include disparity_prop.cc -std=c++11\r\nUndefined symbols for architecture x86_64:\r\n  \"tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)\", referenced from:\r\n      ___cxx_global_var_init.4 in disparity_prop-a72fe1.o\r\n  \"tensorflow::OpDefBuilder::SetShapeFn(std::__1::function<tensorflow::Status (tensorflow::shape_inference::InferenceContext*)>)\", referenced from:\r\n      tensorflow::register_op::OpDefBuilderWrapper<true>::SetShapeFn(tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*)) in disparity_prop-a72fe1.o\r\n  \"tensorflow::OpDefBuilder::Input(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >)\", referenced from:\r\n      tensorflow::register_op::OpDefBuilderWrapper<true>::Input(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >) in disparity_prop-a72fe1.o\r\n  \"tensorflow::OpDefBuilder::Output(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >)\", referenced from:\r\n      tensorflow::register_op::OpDefBuilderWrapper<true>::Output(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >) in disparity_prop-a72fe1.o\r\n  \"tensorflow::OpDefBuilder::OpDefBuilder(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >)\", referenced from:\r\n      tensorflow::register_op::OpDefBuilderWrapper<true>::OpDefBuilderWrapper(char const*) in disparity_prop-a72fe1.o\r\n  \"tensorflow::OpDef::~OpDef()\", referenced from:\r\n      tensorflow::OpRegistrationData::~OpRegistrationData() in disparity_prop-a72fe1.o\r\n  \"tensorflow::internal::LogMessageFatal::LogMessageFatal(char const*, int)\", referenced from:\r\n      tensorflow::core::RefCounted::~RefCounted() in disparity_prop-a72fe1.o\r\n  \"tensorflow::internal::LogMessageFatal::~LogMessageFatal()\", referenced from:\r\n      tensorflow::core::RefCounted::~RefCounted() in disparity_prop-a72fe1.o\r\n  \"tensorflow::internal::CheckOpMessageBuilder::ForVar2()\", referenced from:\r\n      std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >* tensorflow::internal::MakeCheckOpString<int, int>(int const&, int const&, char const*) in disparity_prop-a72fe1.o\r\n  \"tensorflow::internal::CheckOpMessageBuilder::NewString()\", referenced from:\r\n      std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >* tensorflow::internal::MakeCheckOpString<int, int>(int const&, int const&, char const*) in disparity_prop-a72fe1.o\r\n  \"tensorflow::internal::CheckOpMessageBuilder::CheckOpMessageBuilder(char const*)\", referenced from:\r\n      std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >* tensorflow::internal::MakeCheckOpString<int, int>(int const&, int const&, char const*) in disparity_prop-a72fe1.o\r\n  \"tensorflow::internal::CheckOpMessageBuilder::~CheckOpMessageBuilder()\", referenced from:\r\n      std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >* tensorflow::internal::MakeCheckOpString<int, int>(int const&, int const&, char const*) in disparity_prop-a72fe1.o\r\n  \"_main\", referenced from:\r\n     implicit entry/start for main executable\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe .cc should compile successfully.\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\n\r\nclass DisparityPropOp : public OpKernel {\r\npublic:\r\n  explicit DisparityPropOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    // Grab the input tensor\r\n    const Tensor& input_tensor = context->input(0);\r\n\r\n    // Create an output tensor\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n                                                     &output_tensor));\r\n  }\r\n};\r\n\r\n//REGISTER_KERNEL_BUILDER(Name(\"DisparityProp\").Device(DEVICE_CPU), DisparityPropOp);\r\n\r\n// Disparity propagation\r\nREGISTER_OP(\"DisparityProp\")\r\n.Input(\"to_disparity_prop: float32\")\r\n.Output(\"disparity_proped: float32\")\r\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n              c->set_output(0, c->input(0));\r\n              return Status::OK();\r\n            });\r\n```", "comments": ["@zendevil \r\nPlease refer to this issue and let us know\r\n #31190 [link1](https://forum.unity.com/threads/il2cpp-build-error-missing-libatomic-a.786005/)  [link2](https://stackoverflow.com/questions/52366135/android-ndk-cmake-linker-so-no-such-file-or-directory) (verify if you have NDK related issue)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42524\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42524\">No</a>\n"]}, {"number": 42523, "title": "Error building custom op", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tensorflow/tensorflow docker image on macOS Catalina\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.6.0\r\n- GCC/Compiler version (if compiling from source): gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n```\r\n# g++ -I /usr/local/lib/python3.6/dist-packages/tensorflow/include disparity_prop.cc\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/Scrt1.o: In function `_start':\r\n(.text+0x20): undefined reference to `main'\r\n/tmp/ccyNizdq.o: In function `__static_initialization_and_destruction_0(int, int)':\r\ndisparity_prop.cc:(.text+0x5a7): undefined reference to `tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)'\r\n/tmp/ccyNizdq.o: In function `tensorflow::OpRegistrationData::~OpRegistrationData()':\r\ndisparity_prop.cc:(.text._ZN10tensorflow18OpRegistrationDataD2Ev[_ZN10tensorflow18OpRegistrationDataD5Ev]+0x26): undefined reference to `tensorflow::OpDef::~OpDef()'\r\n/tmp/ccyNizdq.o: In function `tensorflow::register_op::OpDefBuilderWrapper<true>::OpDefBuilderWrapper(char const*)':\r\ndisparity_prop.cc:(.text._ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EEC2EPKc[_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EEC5EPKc]+0x52): undefined reference to `tensorflow::OpDefBuilder::OpDefBuilder(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)'\r\n/tmp/ccyNizdq.o: In function `tensorflow::register_op::OpDefBuilderWrapper<true>::Input(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)':\r\ndisparity_prop.cc:(.text._ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE[_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE]+0x4d): undefined reference to `tensorflow::OpDefBuilder::Input(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)'\r\n/tmp/ccyNizdq.o: In function `tensorflow::register_op::OpDefBuilderWrapper<true>::Output(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)':\r\ndisparity_prop.cc:(.text._ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE6OutputENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE[_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE6OutputENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE]+0x4d): undefined reference to `tensorflow::OpDefBuilder::Output(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)'\r\n/tmp/ccyNizdq.o: In function `tensorflow::register_op::OpDefBuilderWrapper<true>::SetShapeFn(std::function<tensorflow::Status (tensorflow::shape_inference::InferenceContext*)>)':\r\ndisparity_prop.cc:(.text._ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE10SetShapeFnESt8functionIFNS_6StatusEPNS_15shape_inference16InferenceContextEEE[_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE10SetShapeFnESt8functionIFNS_6StatusEPNS_15shape_inference16InferenceContextEEE]+0x4d): undefined reference to `tensorflow::OpDefBuilder::SetShapeFn(std::function<tensorflow::Status (tensorflow::shape_inference::InferenceContext*)>)'\r\n/tmp/ccyNizdq.o: In function `tensorflow::core::RefCounted::~RefCounted()':\r\ndisparity_prop.cc:(.text._ZN10tensorflow4core10RefCountedD2Ev[_ZN10tensorflow4core10RefCountedD5Ev]+0xf4): undefined reference to `tensorflow::internal::LogMessageFatal::LogMessageFatal(char const*, int)'\r\ndisparity_prop.cc:(.text._ZN10tensorflow4core10RefCountedD2Ev[_ZN10tensorflow4core10RefCountedD5Ev]+0x11c): undefined reference to `tensorflow::internal::LogMessageFatal::~LogMessageFatal()'\r\n/tmp/ccyNizdq.o: In function `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* tensorflow::internal::MakeCheckOpString<long, int>(long const&, int const&, char const*)':\r\ndisparity_prop.cc:(.text._ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc[_ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc]+0x33): undefined reference to `tensorflow::internal::CheckOpMessageBuilder::CheckOpMessageBuilder(char const*)'\r\ndisparity_prop.cc:(.text._ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc[_ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc]+0x5d): undefined reference to `tensorflow::internal::CheckOpMessageBuilder::ForVar2()'\r\ndisparity_prop.cc:(.text._ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc[_ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc]+0x7b): undefined reference to `tensorflow::internal::CheckOpMessageBuilder::NewString[abi:cxx11]()'\r\ndisparity_prop.cc:(.text._ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc[_ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc]+0x8a): undefined reference to `tensorflow::internal::CheckOpMessageBuilder::~CheckOpMessageBuilder()'\r\ndisparity_prop.cc:(.text._ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc[_ZN10tensorflow8internal17MakeCheckOpStringIliEEPNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_RKT0_PKc]+0xad): undefined reference to `tensorflow::internal::CheckOpMessageBuilder::~CheckOpMessageBuilder()'\r\ncollect2: error: ld returned 1 exit status\r\n```\r\n**Describe the expected behavior**\r\nThe .cc source should compile successfully. \r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\n\r\nclass DisparityPropOp : public OpKernel {\r\npublic:\r\n  explicit DisparityPropOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    // Grab the input tensor\r\n    const Tensor& input_tensor = context->input(0);\r\n\r\n    // Create an output tensor\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n                                                     &output_tensor));\r\n  }\r\n};\r\n\r\n//REGISTER_KERNEL_BUILDER(Name(\"DisparityProp\").Device(DEVICE_CPU), DisparityPropOp);\r\n\r\n// Disparity propagation\r\nREGISTER_OP(\"DisparityProp\")\r\n.Input(\"to_disparity_prop: float32\")\r\n.Output(\"disparity_proped: float32\")\r\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n              c->set_output(0, c->input(0));\r\n              return Status::OK();\r\n            });\r\n```", "comments": ["@zendevil \r\n\r\nLooks like duplicate of #42524. Can we close the issue here and can track the issue in #42524 \r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42523\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42523\">No</a>\n"]}, {"number": 42522, "title": "GatherV2 checks batch_dims falsely in graph mode", "body": "\r\n**Describe the current behavior**\r\nIn graph mode, `GatherV2` checks `batch_dims` with the rank of `param`\r\n\r\n**Describe the expected behavior**\r\nBy definition and the kernel implementation, should check\r\n`batch_dims` with the rank of `indices`\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n@tf.function\r\ndef gather_fn(x, indices, axis, batch_dims):\r\n    return tf.gather(x, indices, axis=axis, batch_dims=batch_dims)\r\n\r\n# 2-D input with shape (2, 3)\r\nx = tf.constant(np.arange(6).reshape(2, 3), dtype=tf.int32)\r\n# 3-D indices with shape (2, 1, 2)\r\nindices = tf.constant([[[0,1]], [[1,0]]], dtype=tf.int32)\r\naxis = 1\r\nbatch_dims = -3\r\n# Eager mode computes correctly\r\nprint('Eager gather:', tf.gather(x, indices, axis=axis, batch_dims=batch_dims))\r\n# Error in graph mode\r\nprint('Function gather', gather_fn(x, indices, axis=axis, batch_dims=batch_dims))\r\n```\r\n\r\n**Other info / logs** \r\n```\r\nEager gather: tf.Tensor(\r\n[[[[0 1]]\r\n\r\n  [[1 0]]]\r\n\r\n\r\n [[[3 4]]\r\n\r\n  [[4 3]]]], shape=(2, 2, 1, 2), dtype=int32)\r\nTraceback (most recent call last):\r\n  File \"gather_function.py\", line 14, in <module>\r\n    print('Function gather', gather_fn(x, indices, axis=axis, batch_dims=batch_dims))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    gather_function.py:6 gather_fn  *\r\n        return tf.gather(x, indices, axis=axis, batch_dims=batch_dims)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper  **\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:4541 gather_v2\r\n        batch_dims=batch_dims)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:4518 gather\r\n        params, indices, axis, batch_dims=batch_dims, name=name)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:3762 gather_v2\r\n        batch_dims=batch_dims, name=name)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\r\n        attrs=attr_protos, op_def=op_def)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\r\n        compute_device)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\r\n        op_def=op_def)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\r\n        control_input_ops, op_def)\r\n    /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\r\n        raise ValueError(str(e))\r\n\r\n    ValueError: Shape must be at least rank 3 but is rank 2 for '{{node GatherV2}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_INT32, batch_dims=-3](x, indices, GatherV2/axis)' with input shapes: [2,3], [2,1,2], [] and with computed input tensors: input[2] = <1>.\r\n```\r\n\r\nThis issue might come from https://github.com/tensorflow/tensorflow/blob/e7d27d850737cc11235df1a206ee8bd3efab1761/tensorflow/core/ops/array_ops.cc#L1219-L1224", "comments": ["Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/6b83b64430a0181a042c3280456cb3c9/42522.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a66eb01a0b9126a8a601a87d6396ff5f/42522-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42522\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42522\">No</a>\n"]}, {"number": 42520, "title": "ReduceLROnPlateau not logging LR to tensorboard anymore", "body": "I use the `ReduceLROnPlateau` callback and LR used to be logged to tensorboard. However since 2.3.0 it isn't showing up anymore. I tried to find a change that may explain the issue, but can't find anything. Was this some deliberate change?\r\n", "comments": ["@lminer \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nPlease, share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42520\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42520\">No</a>\n"]}, {"number": 42519, "title": "'undefined reference' error to \"cxx11\" / \"std\" (Tensorflow-Lite C++ build for Android's NDK)", "body": "\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device: Samsung Galaxy S10\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.2 / 2.3\r\n\r\n\r\n**Describe the problem**\r\n\r\nTrying to build Tensorflow-Lite for Android Studio's NDK (C++ API) using Cross-compile for ARM64 with Make.\r\n\r\nAfter creating `libtensorflow-lite.a` using the [Docker container](https://hub.docker.com/r/tensorflow/tensorflow/tags/), and copying all header files of `tensorflow`, `flatbuffers` and `absl` to Android project: trying to build results in `undefined reference` errors.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Created Android Studio C++ project\r\n2. Created JNI Folders: `src/main/jni`, `src/main/jniLibs` (with `arm64-v8a`)\r\n3. Placed static library `libtensorflow-lite.a` under `src/main/jni/arm64-v8a`\r\n4. Placed all header files (in their directory structure) in `src/main/jniLibs/arm64-v8a`\r\n5. In `build.gradle` (app) added the following:\r\n```\r\n...\r\nandroid {\r\n    compileSdkVersion 29\r\n    buildToolsVersion \"29.0.3\"\r\n\r\n    defaultConfig {\r\n        ...\r\n        minSdkVersion 29\r\n        targetSdkVersion 29\r\n        ...\r\n        externalNativeBuild {\r\n            cmake {\r\n                cppFlags \"-std=c++11 -frtti -fexceptions\"\r\n                arguments \"-DANDROID_ARM_NEON=ON\"\r\n            }\r\n        }\r\n        ndk {\r\n            abiFilters 'arm64-v8a'\r\n        }\r\n    }\r\n    ...\r\n    sourceSets {\r\n        main {\r\n            jni.srcDirs = ['src/main/jni']\r\n            jniLibs.srcDirs = ['src/main/jniLibs']\r\n        }\r\n    }\r\n    splits {\r\n        abi {\r\n            enable true\r\n            reset()\r\n            include \"arm64-v8a\"\r\n            universalApk true\r\n        }\r\n    }\r\n}\r\n...\r\n```\r\n6. In `CMakeLists.txt` added the following:\r\n```\r\nset(CMAKE_CXX_STANDARD 11)\r\nset(JNI_DIR ${CMAKE_CURRENT_SOURCE_DIR}/../jni)\r\nset(JNI_LIBS_DIR ${CMAKE_CURRENT_SOURCE_DIR}/../jniLibs)\r\nadd_library(\r\n        tflite-lib\r\n        STATIC\r\n        IMPORTED)\r\nset_target_properties(tflite-lib\r\n        PROPERTIES IMPORTED_LOCATION\r\n        ${JNI_DIR}/${ANDROID_ABI}/libtensorflow-lite.a)\r\ninclude_directories(\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/flatbuffers\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/flatbuffers/include\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/absl\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/absl/absl\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow/lite\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow/lite/c)\r\nadd_library(\r\n        native-lib\r\n        SHARED\r\n        native-lib.cpp\r\n        tfl-lib.cpp)\r\n...\r\ntarget_link_libraries(\r\n        native-lib\r\n        tflite-lib\r\n        ${log-lib})\r\n```\r\n7. created `tfl-lib.cpp` and `tfl-lib.h` and changed header files to relative paths, for example `lib-tfl.h`:\r\n```\r\n...\r\n#include \"../jniLibs/arm64-v84/tensorflow/lite/allocation.h\"\r\n#include \"../jniLibs/arm64-v84/tensorflow/lite/arena_planner.h\"\r\n#include \"../jniLibs/arm64-v84/tensorflow/lite/builtin_op_data.h\"\r\n...\r\n```\r\nand so on in the header files themselves, for example on `allocation.h`:\r\n```\r\n...\r\n//#include \"tensorflow/lite/c/common.h\"\r\n#include \"c/common.h\"\r\n...\r\n```\r\n8. Include any dummy Tensorflow-Lite reference in `lib-tfl.cpp`, for example:\r\n```\r\nint load_model(char * filename, tflite::ErrorReporter * error_reporter){\r\n    std::unique_ptr<tflite::FlatBufferModel> model =\r\n            tflite::FlatBufferModel::BuildFromFile(filename);\r\n    return 0;\r\n}\r\n```\r\n9. Make Project\r\nIn this example the reference is to `BuildFromFile` from `model_builder.cc` as seen above - see \"Any other info / logs\" section for errors.\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nBuild command failed.\r\nError while executing process /path/to/Android/Sdk/cmake/3.10.2.4988404/bin/ninja with arguments {-C /path/to/app/.cxx/cmake/debug/arm64-v8a native-lib}\r\nninja: Entering directory `/path/to/app/.cxx/cmake/debug/arm64-v8a'\r\n[1/4] Building CXX object CMakeFiles/native-lib.dir/ocv-lib.cpp.o\r\n[2/4] Building CXX object CMakeFiles/native-lib.dir/native-lib.cpp.o\r\n[3/4] Building CXX object CMakeFiles/native-lib.dir/tfl-lib.cpp.o\r\n[4/4] Linking CXX shared library /path/to/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so\r\nFAILED: /path/to/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so \r\n: && /path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android29 --gcc-toolchain=/path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64 --sysroot=/path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64/sysroot -fPIC -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++11 -frtti -fexceptions -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc_real.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments -shared -Wl,-soname,libnative-lib.so -o /path/to/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so CMakeFiles/native-lib.dir/native-lib.cpp.o CMakeFiles/native-lib.dir/tfl-lib.cpp.o CMakeFiles/native-lib.dir/ocv-lib.cpp.o  /path/to/app/src/main/cpp/../jni/arm64-v8a/libtensorflow-lite.a /path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64/sysroot/usr/lib/aarch64-linux-android/29/liblog.so -latomic -lm && :\r\n/path/to/app/src/main/cpp/../jni/arm64-v8a/libtensorflow-lite.a(model_builder.o): In function `tflite::FlatBufferModel::GetMinimumRuntime[abi:cxx11]() const':\r\nmodel_builder.cc:(.text+0x278): undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::compare(char const*) const'\r\nmodel_builder.cc:(.text+0x3c0): undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)'\r\nmodel_builder.cc:(.text+0x4bc): undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_M_create(unsigned long&, unsigned long)'\r\nmodel_builder.cc:(.text+0x514): undefined reference to `std::__throw_logic_error(char const*)'\r\n/path/to/app/src/main/cpp/../jni/arm64-v8a/libtensorflow-lite.a(allocation.o): In function `tflite::FileCopyAllocation::FileCopyAllocation(char const*, tflite::ErrorReporter*)':\r\nallocation.cc:(.text+0x130): undefined reference to `__fxstat'\r\n/path/to/app/src/main/cpp/../jni/arm64-v8a/libtensorflow-lite.a(minimal_logging_default.o): In function `tflite::logging_internal::MinimalLogger::LogFormatted(tflite::LogSeverity, char const*, std::__va_list)':\r\nminimal_logging_default.cc:(.text+0x3c): undefined reference to `__fprintf_chk'\r\nminimal_logging_default.cc:(.text+0x60): undefined reference to `__vfprintf_chk'\r\n/path/to/app/src/main/cpp/../jni/arm64-v8a/libtensorflow-lite.a(mmap_allocation.o): In function `tflite::MMAPAllocation::MMAPAllocation(char const*, tflite::ErrorReporter*)':\r\nmmap_allocation.cc:(.text+0x114): undefined reference to `__fxstat'\r\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\r\nninja: build stopped: subcommand failed.\r\n```\r\n\r\n**Question**\r\n\r\nIt looks like the static library matches a different `std` (not `clang++`?)\r\nAm I missing some configuration on the Docker container for `clang++`?", "comments": ["I created the `libtensorflowlite.so` shared library with the Docker containter, and replaced the static library with the shared one. Also changed the `CMakeLists.txt` file accordingly:\r\n```\r\n...\r\nadd_library(tflite-lib\r\n        SHARED\r\n        IMPORTED)\r\n...\r\nset_target_properties(tflite-lib\r\n        PROPERTIES IMPORTED_LOCATION\r\n        ${JNI_DIR}/${ANDROID_ABI}/libtensorflowlite.so)\r\n...\r\n```\r\n\r\nAnd I get a linkage error when I try to call the GPU delegate, in the following piece of code (following the [label_image example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/label_image)):\r\n\r\n### Code\r\n\r\n```\r\n...\r\n#include \"/tensorflow/lite/tools/evaluation/utils.h\"\r\n#include \"/tensorflow/lite/delegates/gpu/delegate.h\"\r\n...\r\nTfLiteDelegate * gpu_delegte_pointer = TfLiteGpuDelegateV2Create(&gpu_opts);\r\nauto delegate = tflite::evaluation::CreateGPUDelegate(&gpu_opts);\r\n```\r\n\r\n### Error\r\n\r\n```\r\nFAILED: /path/to/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so \r\n: && /path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android29 --gcc-toolchain=/path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64 --sysroot=/path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64/sysroot -fPIC -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++11 -frtti -fexceptions -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc_real.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments -shared -Wl,-soname,libnative-lib.so -o /path/to/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so CMakeFiles/native-lib.dir/native-lib.cpp.o CMakeFiles/native-lib.dir/tfl-lib.cpp.o CMakeFiles/native-lib.dir/ocv-lib.cpp.o  /path/to/app/src/main/cpp/../jni/arm64-v8a/libtensorflowlite.so /path/to/Android/Sdk/ndk/21.0.6113669/toolchains/llvm/prebuilt/linux-x86_64/sysroot/usr/lib/aarch64-linux-android/29/liblog.so -latomic -lm && :\r\nCMakeFiles/native-lib.dir/tfl-lib.cpp.o: In function `my_function(std::__ndk1::vector<cv::Mat, std::__ndk1::allocator<cv::Mat> >, std::__ndk1::vector<cv::Mat, std::__ndk1::allocator<cv::Mat> >, char)':\r\n/path/to/app/src/main/cpp/tfl-lib.cpp:line_number_x: undefined reference to `TfLiteGpuDelegateV2Create'\r\n/path/to/app/src/main/cpp/tfl-lib.cpp:line_number_y: undefined reference to `tflite::evaluation::CreateGPUDelegate(TfLiteGpuDelegateOptionsV2*)'\r\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\r\nninja: build stopped: subcommand failed.\r\n```\r\n\r\nIsn't the GPU delegate included in the `libtensorflowlite.so` shared library?", "Trying to create the GPU delegate as a shared library also fails with `no toolchain for cpu 'arm64-v8a'`  error:\r\n\r\n### Error 1\r\n\r\n```\r\nroot@tflite-docker-1:/tensorflow_src# bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=204\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:android_arm64 in file /tensorflow_src/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nINFO: Found applicable config definition build:android in file /tensorflow_src/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Build options --copt, --crosstool_top, --define, and 2 more have changed, discarding analysis cache.\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nERROR: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/local_config_cc/BUILD:47:1: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'arm64-v8a'\r\nINFO: Repository flatbuffers instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule third_party_http_archive defined at:\r\n  /tensorflow_src/third_party/repo.bzl:216:28: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed\r\nINFO: Elapsed time: 0.530s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded, 64 targets configured)\r\n    currently loading: tensorflow/lite/delegates/gpu/cl\r\n```\r\n\r\n### Error 2\r\n\r\n```\r\nroot@tflite-docker-2:/tensorflow_src# bazel build -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip always tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=204\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:android_arm64 in file /tensorflow_src/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nINFO: Found applicable config definition build:android in file /tensorflow_src/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Build options --copt and --strip have changed, discarding analysis cache.\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nERROR: /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/local_config_cc/BUILD:47:1: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'arm64-v8a'\r\nINFO: Repository flatbuffers instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule third_party_http_archive defined at:\r\n  /tensorflow_src/third_party/repo.bzl:216:28: in <toplevel>\r\nERROR: Analysis of target '//tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed\r\nINFO: Elapsed time: 0.507s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded, 64 targets configured)\r\n    currently loading: tensorflow/lite/delegates/gpu/cl\r\n```", "I managed to create the `libtensorflowlite_gpu_delegate.so` shared library by using the Docker container from the [tflite-android.Dockerfile](https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/dockerfiles/tflite-android.Dockerfile), running the container with `sudo` and using the following steps:\r\n\r\n1. `# android update sdk --no-ui -a --filter tools,platform-tools,android-${ANDROID_API_LEVEL},build-tools-${ANDROID_BUILD_TOOLS_VERSION}`\r\n2. `# apt-get update`\r\n3. `# apt-get install crossbuild-essential-arm64`\r\n4. `# /tensorflow_src/tensorflow/lite/tools/make/download_dependencies.sh`\r\n5. `# bazel build -c opt --config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so`\r\n\r\nI included the shared library by adding the following to `CMakeLists.txt`:\r\n```\r\nadd_library(tflite-gpu-delegate-lib\r\n        SHARED\r\n        IMPORTED)\r\nset_target_properties(tflite-gpu-delegate-lib\r\n        PROPERTIES IMPORTED_LOCATION\r\n        ${JNI_DIR}/${ANDROID_ABI}/libtensorflowlite_gpu_delegate.so)\r\ninclude_directories(\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/flatbuffers\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/flatbuffers/include\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/flatbuffers/include/flatbuffers\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/absl\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/absl/base\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow/lite\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow/lite/delegates\r\n        ${JNI_LIBS_DIR}/${ANDROID_ABI}/tensorflow/lite/delegates/gpu\r\n)\r\ntarget_link_libraries(\r\n        ...\r\n        tflite-gpu-delegate-lib\r\n        ...\r\n        )\r\n```\r\n\r\nand now I can build with the reference to `TfLiteGpuDelegateV2Create(...)`, but I still get an error referencing the `evaluation` namespace:\r\n\r\n`undefined reference to 'tflite::evaluation::CreateGPUDelegate(TfLiteGpuDelegateOptionsV2*)'`", "I ended up writing the part of the code from `evaluation`'s namespace that I needed - so I just bypassed the use of it.\r\nI didn't get any response on this issue for a week now, so I'm closing it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42519\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42519\">No</a>\n"]}, {"number": 42518, "title": "Python crashes when running inference (interpreter.invoke()) on BERT (official.nlp.bert) converted saved model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `YES`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `NO`\r\n- TensorFlow installed from (source or binary): `binary`\r\n- TensorFlow version (use command below): `2.4.0-dev20200819`\r\n- Python version: `Python 3.7.6`\r\n- CUDA/cuDNN version: \r\n- GPU model and memory: `Quadro P2000 computeCapability: 6.1, 4Gb`\r\n\r\n**Describe the current behavior**\r\nBasically I'm trying to quantize a BERT model (with a classifier head) using the [dynamic range post training quantization technique](https://www.tensorflow.org/lite/performance/post_training_quant) in order to improve serving speed.\r\nThis is how I proceeded:\r\n- I use the BERT code of [google official](https://github.com/tensorflow/models/tree/master/official/nlp/bert): I executed [this](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb#scrollTo=y_ACvKPsVUXC)  notebook to obtain a BERT Classifier model in the `Saved Model` format. It's easy to obtain just run all cells and save the model, I can also link mine if need be.\r\n- I am able to convert the model to a TFlite model (and serialize it to a FlatBuffer) (I get this log which kind of sounds like things are doing ok for the conversion part...: \r\n```INFO: TfLiteFlexDelegate delegate: 96 nodes delegated out of 620 nodes with 60 partitions.```\r\n\r\nand then when trying out the inference (following the [basic TFLite inference tutorial in Python](https://www.tensorflow.org/lite/guide/inference) my program just crashes\r\n\r\n\r\n**Describe the expected behavior**\r\nI would like to be able to serve a TFLite model converted from a BERT Classifier of `official.nlp.bert` to be able to execute inference :D \r\n\r\n**Standalone code to reproduce the issue**\r\nThese are the few lines that I try to run but just can't seem to make work:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\npath_saved = \"path\\\\to\\\\saved\\\\model\"\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(path_saved)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_quant_model = converter.convert()\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.int32)\r\n\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nprint(output_data)\r\n```\r\n\r\nAlso I'm able to save the TFLite model to a FlatBuffer easily, I've tried loading it in a different process but I get the same crash.\r\n\r\n\r\n**Other info / logs**\r\n\r\nThis is the full log I obtain:\r\n\r\n```\r\n2020-08-20 16:51:03.475275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-20 16:51:05.781037: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:05.782856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-08-20 16:51:06.621258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2020-08-20 16:51:06.621417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-20 16:51:06.626743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-20 16:51:06.630233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-20 16:51:06.631445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-08-20 16:51:06.635791: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-20 16:51:06.637905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-20 16:51:06.646389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-20 16:51:06.647139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-20 16:51:06.647268: I tensorflow/compiler/jit/xla_gpu_device.cc:69] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:06.647593: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-20 16:51:06.648170: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:06.649130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2020-08-20 16:51:06.649270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-20 16:51:06.649361: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-20 16:51:06.649436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-20 16:51:06.649597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-08-20 16:51:06.649683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-20 16:51:06.649799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-20 16:51:06.649901: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-20 16:51:06.650420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-20 16:51:07.326160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-20 16:51:07.326260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-08-20 16:51:07.327667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-08-20 16:51:07.328315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2984 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-08-20 16:51:07.329077: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:13.831685: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:315] Ignored output_format.\r\n2020-08-20 16:51:13.831813: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:318] Ignored drop_control_dependency.\r\n2020-08-20 16:51:13.835168: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: C:\\tensorflow\\models-master\\saved_model\r\n2020-08-20 16:51:13.884559: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\r\n2020-08-20 16:51:13.885104: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: C:\\tensorflow\\models-master\\saved_model\r\n2020-08-20 16:51:13.886647: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:13.886780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-20 16:51:13.886911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]\r\n2020-08-20 16:51:13.887017: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:14.027709: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:198] None of the MLIR optimization passes are enabled (registered 0 passes)\r\n2020-08-20 16:51:14.046369: I tensorflow/cc/saved_model/loader.cc:190] Restoring SavedModel bundle.\r\n2020-08-20 16:51:14.692613: I tensorflow/cc/saved_model/loader.cc:174] Running initialization op on SavedModel bundle at path: C:\\tensorflow\\models-master\\saved_model\r\n2020-08-20 16:51:14.805651: I tensorflow/cc/saved_model/loader.cc:261] SavedModel load for tags { serve }; Status: success: OK. Took 970481 microseconds.\r\n2020-08-20 16:51:15.612211: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:15.612614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2020-08-20 16:51:15.614030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-20 16:51:15.614146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-20 16:51:15.614256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-20 16:51:15.614370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-08-20 16:51:15.614484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-20 16:51:15.614595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-20 16:51:15.614705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-20 16:51:15.615136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-20 16:51:15.615291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-20 16:51:15.615398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-08-20 16:51:15.615500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-08-20 16:51:15.615944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2984 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-08-20 16:51:15.616086: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nINFO: Created TensorFlow Lite delegate for select TF ops.\r\n2020-08-20 16:51:20.577713: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 16:51:20.578074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.468GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2020-08-20 16:51:20.578209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-20 16:51:20.578327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-20 16:51:20.578447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-20 16:51:20.578568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-08-20 16:51:20.578695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-20 16:51:20.578818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-20 16:51:20.578939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-20 16:51:20.579359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-20 16:51:20.579508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-20 16:51:20.579604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-08-20 16:51:20.579694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-08-20 16:51:20.580139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2984 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-08-20 16:51:20.580258: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nINFO: TfLiteFlexDelegate delegate: 96 nodes delegated out of 620 nodes with 60 partitions.\r\n\r\n2020-08-20 16:51:20.586343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n\r\n```\r\n\r\nPS1: if that can help, when running it with PyCharm I get a weird exit code: `Process finished with exit code -1073741819 (0xC0000005)`\r\n\r\nPS2: I've also linked the end of the logs when I activate CPP logging (with `TF_CPP_MIN_VLOG_LEVEL=2`) if that can help...\r\n\r\n[logs_cpp.txt](https://github.com/tensorflow/tensorflow/files/5103844/logs_cpp.txt)\r\n\r\nI guess my next step will be to try to run inference in CPP directly\r\n", "comments": ["@basilevancooten \r\nPlease share the saved model (colab) for us to replicate the issue faced or if possible share a colab gist with the error.", "hello, \r\n\r\nthank you for your quick reply!\r\n\r\nyou can find the saved model folder as well as the converted tflite model here:\r\n\r\nhttps://wetransfer.com/downloads/5b436414cae588daccaddeb1d0a6739e20200821121511/1e0daef1f46137b7e7221f5bbc2c5d7520200821121527/ae6dc9?utm_campaign=WT_email_tracking&utm_content=general&utm_medium=download_button&utm_source=notify_recipient_email\r\n\r\ntell me if that works ok\r\n\r\n", "Hello,\r\n\r\nseems to work fine with the latest nightly `2.4.0-dev20200828`\r\n\r\nthere's also was problem in my script: I didn't fill up all 3 input tensors (which might by why it crashed: when I tried the same using the C API I got an access violation so my wild guess would be at serving time the program tried to access the input tensors that were not filled yet and maybe the memory span that was allocated for it was used by something else, I'm not a c++ expert so I may be completely wrong)\r\nany ways sorry and thanks for the help!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42518\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42518\">No</a>\n"]}, {"number": 42517, "title": "Lite: Hello world, Sparkfun Edge", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git\r\n- Tensorflow version (commit SHA if source): commit 6787ce30efdfefbf69681ca9795959fb7244240b\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Sparkfun Edge\r\n\r\n**Describe the problem**\r\nHello world example: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin\r\ntensorflow/lite/micro/tools/make/Makefile:303: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'\r\ntensorflow/lite/micro/tools/make/Makefile:303: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'\r\ntensorflow/lite/micro/tools/make/Makefile:303: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'\r\ntensorflow/lite/micro/tools/make/Makefile:303: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'\r\ntensorflow/lite/micro/tools/make/Makefile:303: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/tools/make/Makefile:303: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/arm-none-eabi-g++ -std=c++11 -Wstrict-aliasing -DTF_LITE_STATIC_MEMORY -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -DNDEBUG -O3 -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DNDEBUG -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wno-missing-field-initializers -Wno-strict-aliasing -Wno-type-limits -Wno-unused-function -Wno-unused-parameter -fno-delete-null-pointer-checks -fno-threadsafe-statics -fomit-frame-pointer -fno-use-cxa-atexit -nostdlib -ggdb -O3 -I. -Itensorflow/lite/micro/tools/make/downloads/ -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/common/third_party/hm01b0 -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/regs -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/hal -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/edge/bsp -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/devices/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/utils/  -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/common/third_party/lis2dh12/ -Itensorflow/lite/micro/tools/make/downloads/kissfft -c tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc -o tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.o\r\ntensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc: In function 'void HandleOutput(tflite::ErrorReporter*, float, float)':\r\ntensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:58:17: error: implicit conversion from 'float' to 'double' to match other operand of binary expression [-Werror=double-promotion]\r\n     if (y_value <= -0.75) {\r\n         ~~~~~~~~^~~~~~~~\r\ntensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:71:17: error: implicit conversion from 'float' to 'double' to match other operand of binary expression [-Werror=double-promotion]\r\n     if (y_value >= 0.75) {\r\n         ~~~~~~~~^~~~~~~\r\nIn file included from ./tensorflow/lite/micro/micro_error_reporter.h:20:0,\r\n                 from ./tensorflow/lite/micro/examples/hello_world/output_handler.h:20,\r\n                 from tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:16:\r\n./tensorflow/lite/core/api/error_reporter.h:53:70: error: implicit conversion from 'float' to 'double' when passing argument to function [-Werror=double-promotion]\r\n     static_cast<tflite::ErrorReporter*>(reporter)->Report(__VA_ARGS__); \\\r\n                                                                      ^\r\ntensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:78:3: note: in expansion of macro 'TF_LITE_REPORT_ERROR'\r\n   TF_LITE_REPORT_ERROR(error_reporter, \"x_value: %f, y_value: %f\\n\", x_value,\r\n   ^~~~~~~~~~~~~~~~~~~~\r\n./tensorflow/lite/core/api/error_reporter.h:53:70: error: implicit conversion from 'float' to 'double' when passing argument to function [-Werror=double-promotion]\r\n     static_cast<tflite::ErrorReporter*>(reporter)->Report(__VA_ARGS__); \\\r\n                                                                      ^\r\ntensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.cc:78:3: note: in expansion of macro 'TF_LITE_REPORT_ERROR'\r\n   TF_LITE_REPORT_ERROR(error_reporter, \"x_value: %f, y_value: %f\\n\", x_value,\r\n   ^~~~~~~~~~~~~~~~~~~~\r\ncc1plus: all warnings being treated as errors\r\nmake: *** [tensorflow/lite/micro/tools/make/Makefile:315: tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/examples/hello_world/sparkfun_edge/output_handler.o] Error 1\r\n\r\n", "comments": ["I tested this fix and it works. Thank You."]}, {"number": 42516, "title": "Include jsonCPP headers via #include \"json/json.h\"", "body": "Don't use #include \"include/json/json.h\" which is unusual and therefore confusing\r\nThis allows to remove the header symlinking done for the system lib version\r\n\r\nCloses #42303\r\n\r\nDisclaimer: I've tested the system build with this which works, not 100% sure about Bazel as I'm not very familiar with it but the `    includes = [\"include\"],` in the `cc_library` rule should mean this works.", "comments": ["Thanks for doing this, the symlinking in jsoncpp systemlibs has annoyed me since the beginning. I made a PR some time ago ( https://github.com/tensorflow/tensorflow/pull/38327 ) but hit some test failures and was too busy to resolve the last ones.\r\nI kicked off the tests on this one so lets see if it works better now.\r\n\r\nAgain thanks so much for taking the time to work on this!", "Seems like the build worked. Seeing some strange errors on OSX related to `tf::DataType*` or so which looks unrelated and `LLVM ERROR: Building op `std.return` but it isn't registered in this MLIRContext` which does too but I have no idea what those errors are and if they already exist in current master\r\n\r\nNote: I have a similar PR open but for system nasm: #42266 Would be great if you can have a look or assign someone to take care of it. Change is trivial "]}, {"number": 42515, "title": "LSTM don't work with RuntimeError: Attempting to capture an EagerTensor without building a function, but GRU work", "body": "*System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Mac OS 10.14.4 ):\r\n- tensorflow-2.1.0 \r\n-Keras 2.3.1\r\n- Python 3.6 :,\r\n\r\n\r\n**Describe the current behavior**\r\nLSTM occur error:\"raise RuntimeError(\"Attempting to capture an EagerTensor without \"\r\nRuntimeError: Attempting to capture an EagerTensor without building a function.\"\r\nHowever, If I change LSTM to GRU(as shown in comment code), it work! \r\n\r\n**Standalone code to reproduce the issue**\r\nfrom Logger import log\r\nfrom keras.models import Model\r\nfrom keras.layers import LSTM, Dense, Conv1D, Flatten, Reshape,Lambda, dot, Activation, concatenate, Bidirectional, GRU\r\nfrom keras.utils import print_summary, plot_model\r\nimport numpy as np\r\nimport keras.backend as K\r\nimport os\r\nimport tensorflow as tf\r\n\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_eager_execution()\r\n   F = 16\r\n    K = 4\r\n    H = 512\r\n    #window_length = L = 1536\r\n    reshape = Reshape((window_length, 1),\r\n                      )(input_tensor)\r\n    cnn1 = Conv1D(F, K, activation=\"linear\", strides=1)(reshape)\r\n    cnn2 = Conv1D(F, K, activation=\"linear\", strides=1)(cnn1)\r\n    # Bi-directional LSTM\r\n    # lstm1 = Bidirectional(GRU(H, activation='tanh',return_sequences=True), merge_mode='concat')(cnn2)\r\n    lstm1 = Bidirectional(LSTM(H, return_sequences=True))(cnn2)\r\n    attention1 = attention_3d_block(lstm1)\r\n    dense1 = Dense(window_length*F, use_bias=False, activation='relu')(attention1)\r\n    dense2 = Dense(window_length*F, use_bias=False, activation='relu')(dense1)\r\n    r = Reshape((window_length*F, 1))(dense2)\r\n    cnn3 = Conv1D(F, K, activation=\"linear\", strides=1)(r)\r\n    cnn4 = Conv1D(1, K, activation=\"linear\", strides=1)(cnn3)\r\n    # x = Reshape((window_length,), input_shape=(window_length, 1))(cnn4)\r\n    flat = Flatten(name='flatten')(cnn4)\r\n    d_out = Dense(window_length)(flat)\r\n    model = Model(inputs=input_tensor, outputs=d_out)\r\n\r\n**Other info / logs** \r\n2020-08-20 22:15:03,052 [INFO ]  Parameters: \r\n2020-08-20 22:15:03,053 [INFO ]  Machine name: Ziyues-MacBook-Pro.local\r\nUsing TensorFlow backend.\r\n2020-08-20 22:15:05,618 [WARNI]  From /Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\n2020-08-20 22:15:05,669 [DEBUG]  CACHEDIR=/Users/Ziyue/.matplotlib\r\n2020-08-20 22:15:05,673 [DEBUG]  Using fontManager instance from /Users/Ziyue/.matplotlib/fontlist-v310.json\r\n2020-08-20 22:15:05,799 [DEBUG]  Loaded backend module://backend_interagg version unknown.\r\n2020-08-20 22:15:05,802 [INFO ]  Arguments: \r\n2020-08-20 22:15:05,802 [INFO ]  Namespace(appliance_name='washingmachine', batchsize=128, cnn='kettle', crop_dataset=None, datadir='./dataset_management/redd/', dense_layers=1, gpus=-1, n_epoch=2, pretrainedmodel_dir='./pretrained_model', ram=500000, save_dir='./trained_model_s2swA', save_model=-1, transfer_cnn=False, transfer_model=False)\r\n2020-08-20 22:15:05.803552: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-08-20 22:15:05.817249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2a6b92740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-20 22:15:05.817263: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-20 22:15:05,817 [INFO ]  Training dataset: ./dataset_management/redd/washingmachine/washingmachine_training_.csv\r\n2020-08-20 22:15:05,817 [INFO ]  washingmachine_validation_.csv\r\n2020-08-20 22:15:05,817 [INFO ]  Validation dataset: ./dataset_management/redd/washingmachine/washingmachine_validation_.csv\r\n2020-08-20 22:15:05,838 [WARNI]  From /Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"/Users/Ziyue/Desktop/BitcnNILM-master/s2swA_train.py\", line 189, in <module>\r\n    pretrainedmodel_dir=args.pretrainedmodel_dir)\r\n  File \"/Users/Ziyue/Desktop/BitcnNILM-master/s2swA_Model.py\", line 70, in get_model\r\n    lstm1 = Bidirectional(LSTM(512, return_sequences=True, stateful=True))(cnn2)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 437, in __call__\r\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 75, in symbolic_fn_wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 463, in __call__\r\n    self.build(unpack_singleton(input_shapes))\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 581, in build\r\n    self.forward_layer.build(input_shape)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 502, in build\r\n    self.cell.build(step_input_shape)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 1942, in build\r\n    constraint=self.bias_constraint)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 282, in add_weight\r\n    constraint=constraint)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 620, in variable\r\n    value, dtype=dtype, name=name, constraint=constraint)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 814, in variable\r\n    constraint=constraint)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 260, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 254, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 235, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2645, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1411, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1543, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/Users/Ziyue/opt/anaconda3/envs/nilmtk-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1280, in convert_to_tensor\r\n    raise RuntimeError(\"Attempting to capture an EagerTensor without \"\r\nRuntimeError: Attempting to capture an EagerTensor without building a function.\r\n", "comments": ["@Hessen525,\r\nOn running the given code snippet, I am facing an error stating `NameError: name 'input_tensor' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7202568de924e469ee1e443175f7c6d3/42515.ipynb#scrollTo=UwO_p4c6VzuK).\r\n\r\nCould you please provide the complete code and the dataset to reproduce the issue reported here.\r\n\r\nAlso, please take a look at this similar issue [#42254](https://github.com/tensorflow/tensorflow/issues/42254) and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42514, "title": "How to get the MKL version linked with Tensorflow", "body": "**System information**\r\n- OS Platform and Distribution : Windows 10\r\n- TensorFlow installed from: Both binary and source\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: pip and conda\r\n- Bazel version (if compiling from source): 0.29.1\r\n\r\n\r\n**Describe the problem**\r\nI am able to check whether mkl is installed or not, but how to get the mkl version installed with tensorflow? I see some performance difference across tensorflow versions so want to know mkl versions supported. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nconda create -n \"TFMKL\" tensorflow-mkl python==3.7\r\n\r\n\r\n", "comments": ["@manidevi Please go through the following [doc](https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html) and let me know if it helps. ", "@gowthamkpr \r\nThe doc does not have relevant information on how to know MKL version supported by the install tensorflow. It has information to only check whether mkl is supported or not", "@manidevi \r\n\r\nHi,\r\n  Please try with following cmd:\r\n\r\n  For Windows:    \r\n       \r\n       set MKLDNN_VERBOSE=1\r\n\r\n  For Linux: \r\n\r\n       export MKLDNN_VERBOSE=1\r\n \r\n   You will see the detailed log as following.\r\n   There is print info: **mkldnn_verbose,info,Intel MKL-DNN v0.20.3 (commit N/A)**\r\n\r\n\r\n2020-11-18 14:12:59.250769: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 AVX512F FMA\r\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-18 14:12:59.302349: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2020-11-18 14:12:59.324680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5469b90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-11-18 14:12:59.324711: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-11-18 14:12:59.342758: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nEpoch 1/3\r\n**mkldnn_verbose,info,Intel MKL-DNN v0.20.3 (commit N/A)**\r\nmkldnn_verbose,info,Detected ISA is Intel AVX-512 with Intel DL Boost\r\n\r\n\r\n", "@manidevi \r\n\r\nDo it resolve your issue?\r\nIf yes, could you close this issue?", "@manidevi \r\nCould you feedback?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42514\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42514\">No</a>\n", "@manidevi \r\n\r\nThank you very much!", "Yes, It helped. Thanks!"]}, {"number": 42512, "title": "tensorflow.keras Conv2D layers complain if the input is a sparse Input layer.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\nTensorFlow installed from (source or binary): conda installed from source\r\nTensorFlow version (use command below): 2.1.0\r\nPython version: 3.7\r\nCUDA/cuDNN version: CUDA 10.1\r\nGPU model and memory: Quadro M1200. 8GB RAM\r\n\r\n**Describe the current behavior**\r\nSee code below. \r\n\r\nmodel = create_model_sparse()\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-78-9c562e12ef50>\", line 1, in <module>\r\n    model = create_model_sparse()\r\n\r\n  File \"C:\\Users\\Floor\\Documents\\Basic model\\Model1.py\", line 59, in create_model_sparse\r\n    C1 = Conv2D(32, (6, 6),activation='relu')(input_img)\r\n\r\n  File \"C:\\Users\\Floor\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 748, in __call__\r\n    self._maybe_build(inputs)\r\n\r\n  File \"C:\\Users\\Floor\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 2116, in _maybe_build\r\n    self.build(input_shapes)\r\n\r\n  File \"C:\\Users\\Floor\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\", line 148, in build\r\n    input_channel = self._get_input_channel(input_shape)\r\n\r\n  File \"C:\\Users\\Floor\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\", line 295, in _get_input_channel\r\n    raise ValueError('The channel dimension of the inputs '\r\n\r\nValueError: The channel dimension of the inputs should be defined. Found `None`.\r\n\r\n\r\n**Describe the expected behavior**\r\nI expect the model to compile. \r\n\r\n**Standalone code to reproduce the issue**\r\ndef create_model_sparse(img_width=108, imgh_height=71, dim=10):\r\n    input_img = Input(shape=(img_width, imgh_height, dim), dtype = 'float32', sparse = True)\r\n\r\n    C1 = Conv2D(32, (6, 6),activation='relu')(input_img)\r\n    M1 = MaxPooling2D(pool_size=(2,2))(C1)\r\n    \r\n    C2 = Conv2D(32, (6, 6),activation='relu')(M1)\r\n    M2 = MaxPooling2D(pool_size=(2,2))(C2)\r\n    \r\n    C3 = Conv2D(32, (6, 6),activation='relu')(M2)\r\n    M3 = MaxPooling2D(pool_size=(2,2))(C3)\r\n\r\n    F = Flatten()(M3)\r\n    D1 = Dense(256, activation='relu')(F)\r\n    D2 = Dense(1, activation = \"sigmoid\")(D1)\r\n    model = Model(x,D2)\r\n    \r\n    model.compile(optimizer=Adam(lr=0.0005), loss='mean_squared_error')\r\n    return(model) \r\n\r\n", "comments": ["@HelloFloor,\r\nI was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/cbeb734bf3b326381b37a866bb376199/42512-2-1.ipynb). \r\n\r\nHowever, with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/6fd0d7277657434feaeb09353ed2b5b7/42512.ipynb#scrollTo=RZdZCA14K-15), I am facing a different error stating `TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"input_3/indices:0\", shape=(None, 4), dtype=int64), values=Tensor(\"input_3/values:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"input_3/shape:0\", shape=(4,), dtype=int64)). Consider casting elements to a supported type.`\r\n\r\nCould you please update TensorFlow to v2.3 and check if you are able to resolve the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42511, "title": "Native crash when using GpuDelegate() on Android 11", "body": "We found out that issue is reproducing on Android 11, and works fine for Android 10 and less.\r\nHowever this is our current crash rate distribution, maybe it can vary when we will get more data.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Android 11: 100%\r\n- Mobile device: Google Pixel 4 XL (34.35%), Google Pixel 3 (17.54%), Google Pixel 3 XL (14.84%), Google Pixel 3a (11.0%), Other devices (22.27%)\r\n- TensorFlowLite installed from binary\r\n- TensorFlowLite version:\r\n\"org.tensorflow:tensorflow-lite:0.0.0-nightly\"\r\n\"org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly\"\r\n\r\n**Describe the current behavior**\r\nCrash happens when we are trying to access `org.tensorflow.lite.gpu.GpuDelegate()` constructor.\r\n\r\n**Describe the expected behavior**\r\nNo crash\r\n\r\n**Other info / logs**\r\n```\r\njava.lang.Runtime.loadLibrary0(Runtime.java:1067)\r\njava.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file \"/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/base.apk\", zip file \"/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/split_config.en.apk\", zip file \"/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/split_config.xxhdpi.apk\"],nativeLibraryDirectories=[/data/app/com.bumble.app-8irvW4hQxSV1mR3fxr2zRQ==/lib/arm64, /system/lib64, /system/product/lib64]]] couldn't find \"libtensorflowlite_gpu_jni.so\"\r\n```\r\n\r\n```\r\njava.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol \"log2\" referenced by \"/data/app/~~_HPfJLFw-mGTIuaom9KTxg==/com.bumble.app-_q0StbZdkqA1sVAJw4oWDQ==/lib/arm64/libtensorflowlite_gpu_jni.so\"...\r\n\u2003\u2003at java.lang.Runtime.loadLibrary0(Runtime.java:1087)\r\n\u2003\u2003at java.lang.Runtime.loadLibrary0(Runtime.java:1008)\r\n\u2003\u2003at java.lang.System.loadLibrary(System.java:1664)\r\n\u2003\u2003at org.tensorflow.lite.gpu.GpuDelegate.<clinit>(:165)\r\n```", "comments": ["@Nublo \r\nPlease share the code that leads to crash for su to replicate the issue faced or if possible share a colab gist with the error.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "We tried to migrate to the latest versions without using nightly builds and it helped.\r\n\"org.tensorflow:tensorflow-lite:2.3.0\"\r\n\"org.tensorflow:tensorflow-lite-gpu:2.3.0\"\r\n\r\nLet's close this issue in this case.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42511\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42511\">No</a>\n", "I had a similar issue where the GpuDelegate() constructor was sometimes throwing a \"cannot locate symbol\" error for `ceilf` and `frexpf` when running on Android 11.  I switched from 1.14.0 to 2.3.0 of the `tensorflow-lite` and `tensorflow-lite-gpu` libraries, and the error seems to have gone away now.  Thanks for the suggestion, @Nublo !"]}, {"number": 42510, "title": "Cannot confine TensorFlow C API to use not more than 1 threads in total", "body": "<em>TensorFlow C API is generating at least one thread on each of the available CPUs. The available instructions/guidlines do not take effect to confine TensorFlow C API to only one CPU. I have 8 CPUs and want TensorFlow C API to use only 1, thus generating one and only one thread. How can I confine TensorFlow to use only one CPU (and only one thread) out of available CPUs?</em>\r\nProcessor (lscpu command on Ubuntu):\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\nThread(s) per core:    2\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 142\r\nModel name:            Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\r\nStepping:              10\r\nCPU MHz:               1122.143\r\nCPU max MHz:           3400.0000\r\nCPU min MHz:           400.0000\r\nBogoMIPS:              3600.00\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              6144K\r\nNUMA node0 CPU(s):     0-7\r\nThe following code can reduce the number of threads to 1 per core and the top command cou\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.6.1810\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): https://www.tensorflow.org/install/lang_c\r\n- TensorFlow version (use command below): TensorFlow C API 1.15.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):No\r\n- GCC/Compiler version (if compiling from source):4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)\r\n- CUDA/cuDNN version:NO\r\n- GPU model and memory:No\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nTensorFlow C API is generating multiple threads, at least one thread on each of the available CPUs. \r\n\r\n**Describe the expected behavior**\r\nOne and only one thread for tensorflow, no matter how many cpus, cores or sockets.\r\n\r\n**Standalone code to reproduce the issue**\r\nGraph = TF_NewGraph();\r\nStatus = TF_NewStatus();\r\nSessionOpts = TF_NewSessionOptions();  \r\n  \r\n  // limit number of threads  \r\n  uint8_t intra_op_parallelism_threads = 1;\r\n  uint8_t inter_op_parallelism_threads = 1;\r\n  uint8_t device_count = 1;  \r\n  uint8_t config[15] = {0xa, 0x7, 0xa, 0x3, 0x43, 0x50, 0x55, 0x10, device_count, 0x10, intra_op_parallelism_threads, 0x28, intra_op_parallelism_threads,0x40, 0x1};\r\n  TF_SetConfig(SessionOpts, (void*)config, 13, Status);\r\n\r\n  if (TF_GetCode(Status)!= TF_OK)\r\n    std::cout << \"\\nERROR: \" << TF_Message(Status);\r\n  RunOpts = NULL;\r\n\r\n  // load model\r\n  Session = TF_LoadSessionFromSavedModel(SessionOpts, RunOpts, saved_model_dir, &tags, ntags, Graph, NULL, Status);\r\n  if( TF_GetCode(Status) != TF_OK ) {\r\n    std::cout << \"\\nERROR: Failed to load SavedModel.\" << TF_Message(Status);\r\n    return -1;  }\r\n  assert( TF_GetCode(Status) == TF_OK);\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@penpornk do you know if there is away to use just one thread? Feel free to reassign if you are not the right owner for this issue.", "As soon as I create a graph or load a .pb model, thread count reaches the number of cores.\r\n\r\nThe following is my code to load a savedmodel (.pb) and it increases the number of threads from 1 to 8 (using \"top -H -b -n1 | grep example | wc -l\" command on linux).\r\n\r\n```\r\nStatus LoadGraph(string graph_file_name, std::unique_ptr<tensorflow::Session>* session) {\r\n  tensorflow::GraphDef graph_def;\r\n  Status load_graph_status =\r\n      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\r\n  if (!load_graph_status.ok()) {\r\n    return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\r\n                                        graph_file_name, \"'\");\r\n  }\r\n  \r\n  // initialize the number of worker threads\r\n    tensorflow::SessionOptions options;\r\n    tensorflow::ConfigProto & config = options.config;\r\n    config.set_inter_op_parallelism_threads(1);\r\n    config.set_intra_op_parallelism_threads(1);\r\n    config.set_use_per_session_threads(false); \r\n\r\n  session->reset(tensorflow::NewSession(options));\r\n  Status session_create_status = (*session)->Create(graph_def);\r\n  if (!session_create_status.ok()) {\r\n    return session_create_status;\r\n  }\r\n\r\n  //std::cout << \"RunOption...\\n\";\r\n  //RunOptions run_options;\r\n  //run_options.mutable_experimental()->set_use_run_handler_pool(true);\r\n  //RunMetadata run_metadata;\r\n  //Status status = session->Run(run_options, input, output_node_names, {}, &output, &run_metadata);\r\n\r\n  return Status::OK();\r\n}\r\n```", "Hi @fisakhan , below is my CC case which met similar issue before, I used the flag `set_use_run_handler_pool` to solve this issue as I mentioned:\r\n```c++\r\nbool Predict(Session* session, vector<int>& in, vector<vector<float>>& out) {\r\n    ...\r\n    // run\r\n    RunOptions run_options;\r\n    run_options.mutable_experimental()->set_use_run_handler_pool(true);\r\n    RunMetadata run_metadata;\r\n    Status status = session->Run(run_options, input, output_node_names, {}, &output, &run_metadata);\r\n    if (!status.ok()) {\r\n        cout << \"[Predict] failed! \" << status.ToString() << endl;\r\n        return false;\r\n    }\r\n    const Tensor& output_tensor = output[0];\r\n    auto out_map = output_tensor.tensor<float, 3>();\r\n    col = 20;\r\n    int row = output_tensor.NumElements()/ col;\r\n\r\n    for(size_t i=0; i<row; i++){\r\n        vector<float> row_out;\r\n        for(size_t k=0; k<col; k++)\r\n            row_out.push_back(out_map(0, i, k));\r\n        out.push_back(row_out);\r\n    }\r\n    return true;\r\n}\r\n```\r\nBecause you can't use it in C case, I think you may change this condition(https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/core/common_runtime/direct_session.cc#L600-L601) to `true`  and source build TF to see whether it works ", "@Zantares I implemented your suggestion/recommendation in the following example (from tensorflow) using tensorflow C++ Api  and it is not working. You can just copy-paste-execute the following code without errors and will notice that it is generating multiple threads.\r\n```\r\n#include <fstream>\r\n#include <utility>\r\n#include <vector>\r\n#include \"tensorflow/cc/ops/const_op.h\"\r\n#include \"tensorflow/cc/ops/image_ops.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/graph.pb.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n#include \"tensorflow/core/graph/default_device.h\"\r\n#include \"tensorflow/core/graph/graph_def_builder.h\"\r\n#include \"tensorflow/core/lib/core/errors.h\"\r\n#include \"tensorflow/core/lib/core/stringpiece.h\"\r\n#include \"tensorflow/core/lib/core/threadpool.h\"\r\n#include \"tensorflow/core/lib/io/path.h\"\r\n#include \"tensorflow/core/lib/strings/str_util.h\"\r\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n#include \"tensorflow/core/platform/init_main.h\"\r\n#include \"tensorflow/core/platform/logging.h\"\r\n#include \"tensorflow/core/platform/types.h\"\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/util/command_line_flags.h\"\r\n\r\nusing tensorflow::Flag;\r\nusing tensorflow::int32;\r\nusing tensorflow::Status;\r\nusing tensorflow::string;\r\nusing tensorflow::Tensor;\r\nusing tensorflow::tstring;\r\n\r\nStatus ReadLabelsFile(const string& file_name, std::vector<string>* result,\r\n                      size_t* found_label_count) {\r\n  std::ifstream file(file_name);\r\n  if (!file) {\r\n    return tensorflow::errors::NotFound(\"Labels file \", file_name,\r\n                                        \" not found.\");\r\n  }\r\n  result->clear();\r\n  string line;\r\n  while (std::getline(file, line)) {\r\n    result->push_back(line);\r\n  }\r\n  *found_label_count = result->size();\r\n  const int padding = 16;\r\n  while (result->size() % padding) {\r\n    result->emplace_back();\r\n  }\r\n  return Status::OK();\r\n}\r\n\r\nstatic Status ReadEntireFile(tensorflow::Env* env, const string& filename,\r\n                             Tensor* output) {\r\n  tensorflow::uint64 file_size = 0;\r\n  TF_RETURN_IF_ERROR(env->GetFileSize(filename, &file_size));\r\n\r\n  string contents;\r\n  contents.resize(file_size);\r\n\r\n  std::unique_ptr<tensorflow::RandomAccessFile> file;\r\n  TF_RETURN_IF_ERROR(env->NewRandomAccessFile(filename, &file));\r\n\r\n  tensorflow::StringPiece data;\r\n  TF_RETURN_IF_ERROR(file->Read(0, file_size, &data, &(contents)[0]));\r\n  if (data.size() != file_size) {\r\n    return tensorflow::errors::DataLoss(\"Truncated read of '\", filename,\r\n                                        \"' expected \", file_size, \" got \",\r\n                                        data.size());\r\n  }\r\n  output->scalar<tstring>()() = tstring(data);\r\n  return Status::OK();\r\n}\r\n\r\nStatus ReadTensorFromImageFile(const string& file_name, const int input_height,\r\n                               const int input_width, const float input_mean,\r\n                               const float input_std,\r\n                               std::vector<Tensor>* out_tensors) {\r\n  auto root = tensorflow::Scope::NewRootScope();\r\n  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\r\n\r\n  string input_name = \"file_reader\";\r\n  string output_name = \"normalized\";\r\n\r\n  // read file_name into a tensor named input\r\n  Tensor input(tensorflow::DT_STRING, tensorflow::TensorShape());\r\n  TF_RETURN_IF_ERROR(\r\n      ReadEntireFile(tensorflow::Env::Default(), file_name, &input));\r\n\r\n  // use a placeholder to read input data\r\n  auto file_reader =\r\n      Placeholder(root.WithOpName(\"input\"), tensorflow::DataType::DT_STRING);\r\n\r\n  std::vector<std::pair<string, tensorflow::Tensor>> inputs = {\r\n      {\"input\", input},\r\n  };\r\n\r\n  // Now try to figure out what kind of file it is and decode it.\r\n  const int wanted_channels = 3;\r\n  tensorflow::Output image_reader;\r\n  if (tensorflow::str_util::EndsWith(file_name, \".png\")) {\r\n    image_reader = DecodePng(root.WithOpName(\"png_reader\"), file_reader,\r\n                             DecodePng::Channels(wanted_channels));\r\n  } else if (tensorflow::str_util::EndsWith(file_name, \".gif\")) {\r\n    // gif decoder returns 4-D tensor, remove the first dim\r\n    image_reader =\r\n        Squeeze(root.WithOpName(\"squeeze_first_dim\"),\r\n                DecodeGif(root.WithOpName(\"gif_reader\"), file_reader));\r\n  } else if (tensorflow::str_util::EndsWith(file_name, \".bmp\")) {\r\n    image_reader = DecodeBmp(root.WithOpName(\"bmp_reader\"), file_reader);\r\n  } else {\r\n    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.\r\n    image_reader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), file_reader,\r\n                              DecodeJpeg::Channels(wanted_channels));\r\n  }\r\n  // Now cast the image data to float so we can do normal math on it.\r\n  auto float_caster =\r\n      Cast(root.WithOpName(\"float_caster\"), image_reader, tensorflow::DT_FLOAT);\r\n  auto dims_expander = ExpandDims(root, float_caster, 0);\r\n  // Bilinearly resize the image to fit the required dimensions.\r\n  auto resized = ResizeBilinear(\r\n      root, dims_expander,\r\n      Const(root.WithOpName(\"size\"), {input_height, input_width}));\r\n  // Subtract the mean and divide by the scale.\r\n  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),\r\n      {input_std});\r\n\r\n  tensorflow::GraphDef graph;\r\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));\r\n\r\n  std::unique_ptr<tensorflow::Session> session(\r\n      tensorflow::NewSession(tensorflow::SessionOptions()));\r\n  TF_RETURN_IF_ERROR(session->Create(graph));\r\n  TF_RETURN_IF_ERROR(session->Run({inputs}, {output_name}, {}, out_tensors));\r\n  return Status::OK();\r\n}\r\n\r\nStatus LoadGraph(const string& graph_file_name,\r\n                 std::unique_ptr<tensorflow::Session>* session) {\r\n  std::cout << \"Thread count: \" << system(\"top -H -b -n1 | grep example | wc -l\") << \"\\n\";\r\n\r\n  tensorflow::GraphDef graph_def;\r\n  Status load_graph_status =\r\n      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);\r\n  if (!load_graph_status.ok()) {\r\n    return tensorflow::errors::NotFound(\"Failed to load compute graph at '\",\r\n                                        graph_file_name, \"'\");\r\n  }\r\n  \r\n  **std::cout << \"Thread count: \" << system(\"top -H -b -n1 | grep example | wc -l\") << \"\\n\";**\r\n  **// initialize the number of worker threads\r\n  tensorflow::SessionOptions options;\r\n  tensorflow::ConfigProto & config = options.config;\r\n  config.set_inter_op_parallelism_threads(1);\r\n  config.set_intra_op_parallelism_threads(1);**\r\n\r\n  session->reset(tensorflow::NewSession(options));\r\n  Status session_create_status = (*session)->Create(graph_def);\r\n  if (!session_create_status.ok()) {\r\n    return session_create_status;\r\n  }\r\n  **std::cout << \"Thread count: \" << system(\"top -H -b -n1 | grep example | wc -l\") << \"\\n\";**\r\n\r\n  return Status::OK();\r\n}\r\n\r\nStatus GetTopLabels(const std::vector<Tensor>& outputs, int how_many_labels,\r\n                    Tensor* indices, Tensor* scores) {\r\n  auto root = tensorflow::Scope::NewRootScope();\r\n  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\r\n\r\n  string output_name = \"top_k\";\r\n  TopK(root.WithOpName(output_name), outputs[0], how_many_labels);\r\n  tensorflow::GraphDef graph;\r\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));\r\n\r\n  std::unique_ptr<tensorflow::Session> session(\r\n      tensorflow::NewSession(tensorflow::SessionOptions()));\r\n  TF_RETURN_IF_ERROR(session->Create(graph));\r\n  std::vector<Tensor> out_tensors;\r\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name + \":0\", output_name + \":1\"},\r\n                                  {}, &out_tensors));\r\n  *scores = out_tensors[0];\r\n  *indices = out_tensors[1];\r\n  return Status::OK();\r\n}\r\n\r\nStatus PrintTopLabels(const std::vector<Tensor>& outputs,\r\n                      const string& labels_file_name) {\r\n  std::vector<string> labels;\r\n  size_t label_count;\r\n  Status read_labels_status =\r\n      ReadLabelsFile(labels_file_name, &labels, &label_count);\r\n  if (!read_labels_status.ok()) {\r\n    LOG(ERROR) << read_labels_status;\r\n    return read_labels_status;\r\n  }\r\n  const int how_many_labels = std::min(5, static_cast<int>(label_count));\r\n  Tensor indices;\r\n  Tensor scores;\r\n  TF_RETURN_IF_ERROR(GetTopLabels(outputs, how_many_labels, &indices, &scores));\r\n  tensorflow::TTypes<float>::Flat scores_flat = scores.flat<float>();\r\n  tensorflow::TTypes<int32>::Flat indices_flat = indices.flat<int32>();\r\n  for (int pos = 0; pos < how_many_labels; ++pos) {\r\n    const int label_index = indices_flat(pos);\r\n    const float score = scores_flat(pos);\r\n    LOG(INFO) << labels[label_index] << \" (\" << label_index << \"): \" << score;\r\n  }\r\n  return Status::OK();\r\n}\r\n\r\nStatus CheckTopLabel(const std::vector<Tensor>& outputs, int expected,\r\n                     bool* is_expected) {\r\n  *is_expected = false;\r\n  Tensor indices;\r\n  Tensor scores;\r\n  const int how_many_labels = 1;\r\n  TF_RETURN_IF_ERROR(GetTopLabels(outputs, how_many_labels, &indices, &scores));\r\n  tensorflow::TTypes<int32>::Flat indices_flat = indices.flat<int32>();\r\n  if (indices_flat(0) != expected) {\r\n    LOG(ERROR) << \"Expected label #\" << expected << \" but got #\"\r\n               << indices_flat(0);\r\n    *is_expected = false;\r\n  } else {\r\n    *is_expected = true;\r\n  }\r\n  return Status::OK();\r\n}\r\n\r\nint main(int argc, char* argv[]) {\r\n  string image = \"/home/twenty/Projects/C++/tf_threads/images/grace_hopper.jpg\";\r\n  string graph = \"/home/twenty/Projects/C++/tf_threads/examples/example3/data/inception_v3_2016_08_28_frozen.pb\";\r\n  string labels = \"/home/twenty/Projects/C++/tf_threads/examples/example3/data/imagenet_slim_labels.txt\";\r\n  int32 input_width = 299;\r\n  int32 input_height = 299;\r\n  float input_mean = 0;\r\n  float input_std = 255;\r\n  string input_layer = \"input\";\r\n  string output_layer = \"InceptionV3/Predictions/Reshape_1\";\r\n  bool self_test = false;\r\n  string root_dir = \"\";\r\n  std::vector<Flag> flag_list = {\r\n      Flag(\"image\", &image, \"image to be processed\"),\r\n      Flag(\"graph\", &graph, \"graph to be executed\"),\r\n      Flag(\"labels\", &labels, \"name of file containing labels\"),\r\n      Flag(\"input_width\", &input_width, \"resize image to this width in pixels\"),\r\n      Flag(\"input_height\", &input_height,\r\n           \"resize image to this height in pixels\"),\r\n      Flag(\"input_mean\", &input_mean, \"scale pixel values to this mean\"),\r\n      Flag(\"input_std\", &input_std, \"scale pixel values to this std deviation\"),\r\n      Flag(\"input_layer\", &input_layer, \"name of input layer\"),\r\n      Flag(\"output_layer\", &output_layer, \"name of output layer\"),\r\n      Flag(\"self_test\", &self_test, \"run a self test\"),\r\n      Flag(\"root_dir\", &root_dir,\r\n           \"interpret image and graph file names relative to this directory\"),\r\n  };\r\n  string usage = tensorflow::Flags::Usage(argv[0], flag_list);\r\n  const bool parse_result = tensorflow::Flags::Parse(&argc, argv, flag_list);\r\n  if (!parse_result) {\r\n    LOG(ERROR) << usage;\r\n    return -1;\r\n  }\r\n\r\n  // We need to call this to set up global state for TensorFlow.\r\n  tensorflow::port::InitMain(argv[0], &argc, &argv);\r\n  if (argc > 1) {\r\n    LOG(ERROR) << \"Unknown argument \" << argv[1] << \"\\n\" << usage;\r\n    return -1;\r\n  }\r\n\r\n  std::cout << \"Loading model...\\n\\n\";\r\n  // First we load and initialize the model.\r\n  std::unique_ptr<tensorflow::Session> session;\r\n  string graph_path = tensorflow::io::JoinPath(root_dir, graph);\r\n  Status load_graph_status = LoadGraph(graph_path, &session);\r\n  if (!load_graph_status.ok()) {\r\n    LOG(ERROR) << load_graph_status;\r\n    return -1;\r\n  }\r\n\r\n  std::cout << \"Preparing input tensors...\\n\\n\";\r\n  // Get the image from disk as a float array of numbers, resized and normalized\r\n  // to the specifications the main graph expects.\r\n  std::vector<Tensor> resized_tensors;\r\n  string image_path = tensorflow::io::JoinPath(root_dir, image);\r\n  Status read_tensor_status =\r\n      ReadTensorFromImageFile(image_path, input_height, input_width, input_mean,\r\n                              input_std, &resized_tensors);\r\n  if (!read_tensor_status.ok()) {\r\n    LOG(ERROR) << read_tensor_status;\r\n    return -1;\r\n  }\r\n  const Tensor& resized_tensor = resized_tensors[0];\r\n\r\n  std::cout << \"Running the image through the model...\\n\\n\";\r\n  **std::cout << \"Thread count: \" << system(\"top -H -b -n1 | grep example | wc -l\") << \"\\n\";\r\n  // Actually run the image through the model.\r\n  tensorflow::RunOptions run_options;\r\n  run_options.mutable_experimental()->set_use_run_handler_pool(true);\r\n  tensorflow::RunMetadata run_metadata;\r\n\r\n  std::vector<Tensor> outputs;\r\n  //Status run_status = session->Run({{input_layer, resized_tensor}}, {output_layer}, {}, &outputs);\r\n  Status run_status = session->Run(run_options, {{input_layer, resized_tensor}}, {output_layer}, {}, &outputs, &run_metadata);**\r\n  if (!run_status.ok()) {\r\n    LOG(ERROR) << \"Running model failed: \" << run_status;\r\n    return -1;\r\n  }\r\n  **std::cout << \"Thread count: \" << system(\"top -H -b -n1 | grep example | wc -l\") << \"\\n\";**\r\n\r\n  std::cout << \"Automated testing...\\n\\n\";\r\n  if (self_test) {\r\n    bool expected_matches;\r\n    Status check_status = CheckTopLabel(outputs, 653, &expected_matches);\r\n    if (!check_status.ok()) {\r\n      LOG(ERROR) << \"Running check failed: \" << check_status;\r\n      return -1;\r\n    }\r\n    if (!expected_matches) {\r\n      LOG(ERROR) << \"Self-test failed!\";\r\n      return -1;\r\n    }\r\n  }\r\n\r\n  // Do something interesting with the results we've generated.\r\n  Status print_status = PrintTopLabels(outputs, labels);\r\n  if (!print_status.ok()) {\r\n    LOG(ERROR) << \"Running print failed: \" << print_status;\r\n    return -1;\r\n  }\r\n\r\n  return 0;\r\n}\r\n```", "Hi, it seems TF changed the environment variable name to : `TF_NUM_INTEROP_THREADS` and `TF_NUM_INTRAOP_THREADS` you can set both to 1, works for me.\r\n\r\n```\r\nexport TF_NUM_INTEROP_THREADS=1\r\nexport TF_NUM_INTRAOP_THREADS=1\r\n```", "@roywei how did you count the threads? Did you use \"top -H -b -n1 | grep example | wc -l\"? The environement variables that you use are equivalent to ```\r\nconfig.set_inter_op_parallelism_threads(1);\r\n  config.set_intra_op_parallelism_threads(1);\r\n``` in TensorFlow C++ API.", "What source code of TensorFlow 2.3 C++ API to change if I want to build TF from source for keeping it to single-threaded?", "@Zantares @roywei Do you agree with the reason given at the following link? It explains that TensorFlow cannot be a single threaded. https://stackoverflow.com/questions/48696900/why-tensorflow-creates-so-many-cpu-threads", "> @Zantares @roywei Do you agree with the reason given at the following link? It explains that TensorFlow cannot be a single threaded. https://stackoverflow.com/questions/48696900/why-tensorflow-creates-so-many-cpu-threads\r\n\r\nNot exactly, this answer said that GPU has CUDA runtime and GRPC engine to generate multi-threads, but as I said CPU can be executed as \"single thread\" mode.\r\n\r\nYou can use \"single thread\" mode on CPU with python API definitely. but it may become complex with C API. Because I didn't have your dataset and can't run your case directly, I don't know what the issue is in your case. You can roughly modified TF source code to set all thread number to 1 if have no other good solution.", "@Zantares How to use \"single thread\" mode on CPU wiht Python API?", "@fisakhan you can start from a python model, and:\r\n1. if you are using TF 1.x, you need to set inter/intra config in session like [this](https://github.com/google-research/bert/pull/876/files#diff-51759dcea7f50f6314e4b971c159bf19846d38e5705567b36d09b42dfb61410dR833). But this configuration will be ignored sometimes due to TF internal issue of TF, so it's not the best way to use.\r\n2. if you are using TF .2x, you can set the environment var(TF_NUM_INTEROP_THREADS/TF_NUM_INTRAOP_THREADS) directly.\r\n\r\nBecause TF uses a multilayer structure, you can see 3 threads at least even you set all thread configuration to 1: one is python thread, one is inter thread and one is intra thread.\r\n\r\nThe reason why these configuration doesn't work for C API is that you may lack some default configuration when run C API directly and it may change the behavior of thread pool. Currently I know  that `set_use_run_handler_pool` is an issue.", "If I have N cores, then I get Total number of threads: N (and not 3)  \r\nI executed the following code with Python 3.6 and TensorFlow 2.3.\r\n\r\n```\r\nimport os\r\n\r\n# disable GPU\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\n# reduce number of threads\r\nos.environ['TF_NUM_INTEROP_THREADS'] = '1'\r\nos.environ['TF_NUM_INTRAOP_THREADS'] = '1'\r\n\r\nimport tensorflow\r\n\r\nprint('\\n\\nTotal number of threads: ')\r\nos.system( \"top -H -b -n1 | grep python3 | wc -l\")\r\n\r\n# LOAD ANY MODEL USING TENSORFLOW\r\n    \r\nprint('\\n\\nTotal number of threads: ')\r\nos.system( \"top -H -b -n1 | grep python3 | wc -l\")\r\n\r\n# PREDICT USING THE LOADED MODEL\r\nprint('\\n\\nTotal number of threads: ')\r\nos.system( \"top -H -b -n1 | grep python3 | wc -l\")\r\n```\r\n", "Maybe some implicit behavior created more threads than expected:\r\nI got **22** threads in my below case when set inter/intra to 1, and it will increase to **40** if I set each of them to 10. These 2 options are working well to control work thread number, but TF has created other threads and showed confusing information in **top**.\r\n\r\n\r\nMy cmd\r\n```shell\r\nnumactl -C 0-7 -l python conv.py\r\n```\r\nAnd I got\r\n```\r\nTotal number of threads: \r\n22\r\n```\r\nAfter increasing inter/intra to 10, I got\r\n```\r\nTotal number of threads: \r\n40\r\n```\r\n\r\nMy case **conv.py**:\r\n```python\r\nimport tensorflow as tf\r\nimport os\r\n\r\n# reduce number of threads\r\nos.environ['TF_NUM_INTEROP_THREADS'] = '1' \r\nos.environ['TF_NUM_INTRAOP_THREADS'] = '1' \r\n\r\nprint('\\n\\nTotal number of threads: ')\r\nos.system( \"top -H -b -n1 | grep python | wc -l\")\r\n\r\ndef my_model():\r\n  layer_input = tf.random.uniform((1, 2, 3, 3), minval=0, maxval=100, dtype=tf.float32)\r\n  weights = tf.random.uniform((1, 2, 3, 3), minval=0, maxval=100, dtype=tf.float32)\r\n\r\n  with tf.compat.v1.variable_scope(\"output_1\"):\r\n    outputs_1 = tf.nn.conv2d(\r\n        input=layer_input, filters=weights, strides=1,\r\n        # padding=[[0, 0], [1, 1], [1, 1], [0, 0]])\r\n        padding='SAME')\r\n    outputs_1 = tf.nn.bias_add(outputs_1, tf.constant([1, 1, 1], dtype=tf.float32))\r\n\r\n  return outputs_1\r\n\r\nwith tf.compat.v1.Session() as sess:\r\n  loss = my_model()\r\n  print('\\n\\nTotal number of threads: ')\r\n  os.system( \"top -H -b -n1 | grep python | wc -l\")\r\n  init = tf.compat.v1.initialize_all_variables()\r\n  sess.run(init)\r\n  sess.run((loss))\r\n  print('\\n\\nTotal number of threads: ')\r\n  os.system( \"top -H -b -n1 | grep python | wc -l\")\r\n```", "In PyTorch it is as simple as \"torch.set_num_threads(1)\". It works and generates 3 threads in total (including 1 for python).", "If I build TensorFlow from source then what code should I change to disable threading by TensorFlow?", "> If I build TensorFlow from source then what code should I change to disable threading by TensorFlow?\r\n\r\n[Here](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/core/common_runtime/process_util.cc#L100) to set inter and [here ](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/core/common_runtime/local_device.cc#L73)to set intra. It works for python API but not sure work for C/C++ API or not.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42510\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42510\">No</a>\n"]}, {"number": 42509, "title": "[MLIR] Add folder for mhlo get_dimension_size", "body": "Add folder for mhlo GetDimensionSizeOp (`mhlo.get_dimension_size`).\r\n`get_dimension_size` folds to a constant when the corresponding tensor\r\ndimension size is statically known / constant.", "comments": ["@sherhut @stellaraccident @River707 ", "Fixed dialect name in test cases: xla_hlo -> mhlo", "@sherhut @joker-eph  The internal builds here may fail here since a lot of ops would get folded away (since shapes are typically constant, and more operands would become constant with this folding).", "@bondhugula can you please fix ubuntu sanity build failures ?", "Seems like in conflicts, can you rebase?", "> Seems like in conflicts, can you rebase?\r\n\r\nDone.", "Rebased and fixed conflict."]}, {"number": 42508, "title": "[MLIR] Erase dead lmhlo.constant ops", "body": "An lmhlo.constant op on an memref that is locally allocated and with\r\nno users other than dealloc's can be deleted. Add a canonicalization \r\npattern for this.", "comments": ["@River707 @sherhut @stellaraccident for visibility.", "That's exactly what I had in mind and was also related to the question on the memory effect interface I posted on discord. It'd require a bit more thought to design that.", "Can you add a TODO in the pattern?", "> Can you add a TODO in the pattern?\r\n\r\nDone. In fact, the generalization would go beyond dead stores -- to also transparently cover other ops like DMA operations transferring to that memref.", "(I used \"store\" in a liberal way)", "Fixed dialect names in test cases: `xla_lhlo` -> `lmhlo`", "`//tensorflow/tools/ci_build:gen_ci_sanity_out` is failing here. ", "@bondhugula please fix ubuntu sanity build failures ?", "You got unlucky: the build was broken last night, please rebase and retry.\r\n\r\n", "The build still fails and the failure is unrelated to this PR. The failing test is: //tensorflow/compiler/xla/service:memory_space_assignment_test", "> @bondhugula please fix ubuntu sanity build failures ?\r\n\r\n@rthadur  The build failure is unrelated to my revision.", "This is an existing failure at HEAD", "Build is back green, feel free to rebase!", "Actually I think we will be able to integrate directly.", "> Actually I think we will be able to integrate directly.\r\n\r\nAnyway, rebased and pushed.", "It got pushed here: https://github.com/tensorflow/tensorflow/commit/aaed01bdb99945d671ac28bb0d3203cc50028b87\r\n\r\nI don't know why it didn't mark the PR as closed?", "@joker-eph sometimes auto-merge does not happen ,it is something to do with copybara."]}, {"number": 42507, "title": "changes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 5, Oppo F11 Pro\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: RTX 2060 6 GB\r\n\r\n**Describe the current behavior**\r\n\r\nI have created a Super Resolution model using tf 1.13.1 and used the tflite benchmark tool to benchmark the timing on my android device. The timing which I'm getting is around 31-35ms by using the command ``` adb shell taskset f0 /data/local/tmp/benchmark_model \\\r\n  --graph=/data/local/tmp/main.tflite \\\r\n  --enable_op_profiling=true --num_threads=4 ``` \r\n\r\n**Here is the output from the benchmark tool -** \r\n", "comments": ["@anidh,\r\nIn the issue template you have mentioned the TensorFlow version as v1.15 and later you have stated that you have built the model using TF v2.0. Could you please specify the exact TensorFlow version you are using?\r\n\r\nAlso, please update TensorFlow to the latest version v2.3 and check if you are facing the same issue. Thanks!"]}, {"number": 42506, "title": "tf.keras.applications.EfficientNetB- not running as expected", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow version (use command below): v2.3.0-0-gb36436b087 2.3.0\r\n\r\n**Describe the current behavior**\r\n\r\n[tf.keras.applications.EfficientNetB-](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) not behaving like other tf.keras.applications modules.\r\n\r\nIn seems any of the EfficientNet modules I try to use don't function as expected as when using other modules such as [ResNet50V2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50V2) (using the same code/data setups).\r\n\r\nUnless this is stated somewhere, I'm not sure what I'm getting wrong.\r\n\r\nI've tried the TF Hub versions of EfficientNetB- and as feature extractors and they seem to be working fine.\r\n\r\n**Describe the expected behavior**\r\n\r\nEfficientNetB- modules should function like other modules in tf.keras.applications.\r\n\r\n**Standalone code to reproduce the issue**\r\nRunning Colab notebook: https://colab.research.google.com/drive/1m3U3wREqWLCKqLhh5Gzuy_mdq5mk6h_r?usp=sharing\r\n\r\n**Other info / logs** \r\n\r\nResNetV250 output:\r\n```Epoch 1/10\r\n24/24 [==============================] - 17s 701ms/step - loss: 2.2448 - accuracy: 0.2240 - val_loss: 2.0786 - val_accuracy: 0.4660\r\nEpoch 2/10\r\n24/24 [==============================] - 16s 674ms/step - loss: 1.9990 - accuracy: 0.5800 - val_loss: 1.8562 - val_accuracy: 0.6896\r\nEpoch 3/10\r\n24/24 [==============================] - 16s 665ms/step - loss: 1.8456 - accuracy: 0.7000 - val_loss: 1.7827 - val_accuracy: 0.7476\r\nEpoch 4/10\r\n24/24 [==============================] - 16s 672ms/step - loss: 1.7713 - accuracy: 0.7667 - val_loss: 1.7561 - val_accuracy: 0.7608\r\nEpoch 5/10\r\n24/24 [==============================] - 16s 664ms/step - loss: 1.7313 - accuracy: 0.8053 - val_loss: 1.7457 - val_accuracy: 0.7616\r\nEpoch 6/10\r\n24/24 [==============================] - 16s 667ms/step - loss: 1.7049 - accuracy: 0.8187 - val_loss: 1.7340 - val_accuracy: 0.7712\r\nEpoch 7/10\r\n24/24 [==============================] - 16s 668ms/step - loss: 1.6779 - accuracy: 0.8347 - val_loss: 1.7246 - val_accuracy: 0.7824\r\nEpoch 8/10\r\n24/24 [==============================] - 16s 667ms/step - loss: 1.6577 - accuracy: 0.8520 - val_loss: 1.7222 - val_accuracy: 0.7760\r\nEpoch 9/10\r\n24/24 [==============================] - 16s 665ms/step - loss: 1.6476 - accuracy: 0.8747 - val_loss: 1.7189 - val_accuracy: 0.7772\r\nEpoch 10/10\r\n24/24 [==============================] - 16s 661ms/step - loss: 1.6372 - accuracy: 0.8853 - val_loss: 1.7163 - val_accuracy: 0.7764\r\n```\r\n\r\n\r\nEfficientNetB0 output (using same code and data as above, except for EfficientNetB0 not ResNet50V2):\r\n```\r\nEpoch 1/10\r\n24/24 [==============================] - 18s 735ms/step - loss: 2.3056 - accuracy: 0.0787 - val_loss: 2.3026 - val_accuracy: 0.1000\r\nEpoch 2/10\r\n24/24 [==============================] - 16s 654ms/step - loss: 2.3048 - accuracy: 0.0827 - val_loss: 2.3026 - val_accuracy: 0.1000\r\nEpoch 3/10\r\n24/24 [==============================] - 16s 654ms/step - loss: 2.3048 - accuracy: 0.0907 - val_loss: 2.3026 - val_accuracy: 0.1000\r\nEpoch 4/10\r\n24/24 [==============================] - 15s 639ms/step - loss: 2.3051 - accuracy: 0.0867 - val_loss: 2.3027 - val_accuracy: 0.1000\r\nEpoch 5/10\r\n24/24 [==============================] - 15s 631ms/step - loss: 2.3052 - accuracy: 0.0773 - val_loss: 2.3026 - val_accuracy: 0.1000\r\nEpoch 6/10\r\n24/24 [==============================] - 15s 632ms/step - loss: 2.3052 - accuracy: 0.0800 - val_loss: 2.3026 - val_accuracy: 0.1000\r\nEpoch 7/10\r\n24/24 [==============================] - 15s 634ms/step - loss: 2.3059 - accuracy: 0.1040 - val_loss: 2.3027 - val_accuracy: 0.1000\r\nEpoch 8/10\r\n24/24 [==============================] - 15s 623ms/step - loss: 2.3055 - accuracy: 0.0907 - val_loss: 2.3027 - val_accuracy: 0.1000\r\nEpoch 9/10\r\n24/24 [==============================] - 15s 631ms/step - loss: 2.3037 - accuracy: 0.0947 - val_loss: 2.3026 - val_accuracy: 0.1000\r\nEpoch 10/10\r\n24/24 [==============================] - 15s 621ms/step - loss: 2.3044 - accuracy: 0.0907 - val_loss: 2.3026 - val_accuracy: 0.1000\r\n```\r\n", "comments": ["Tweaking the Learning Rate or Changing the optimizer might help you...I think this is caused due to the mismatch dataset with the optimizer....", "> Tweaking the Learning Rate or Changing the optimizer might help you...I think this is caused due to the mismatch dataset with the optimizer....\r\n\r\nI've tried several different optimizers/learning rates but for some reason each model never moves off guessing level performance, e.g. 10% accuracy with 10 classes", "I am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/38619eec760a7d0ceedebf8da8410c3b/untitled383.ipynb). Thanks!", "I'm also experiencing this exact same issue, was about to open a ticket myself... :-)", "FYI, on my side it was an input scaling issue - and looking at your gist this may be your case too!  EfficientNet is \"weird\" in that it simply wants untouched 0-255 inputs, while you've scaled them 0-1.", "> FYI, on my side it was an input scaling issue - and looking at your gist this may be your case too! EfficientNet is \"weird\" in that it simply wants untouched 0-255 inputs, while you've scaled them 0-1.\r\n\r\nYou're completely right. It turns out EfficientNet has normalization built-in.\r\n\r\nThank you for this.\r\n\r\nAlso found this information buried in this guide: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\r\n\r\n```\r\nfrom tensorflow.keras.applications import EfficientNetB0\r\nmodel = EfficientNetB0(weights='imagenet')\r\n```\r\n\"This model takes input images of shape (224, 224, 3), and the input data should range [0, 255]. Normalization is included as part of the model.\"", "Hmm... seems the inputs for EfficientNet are different depending on whether you're using TensorFlow Hub or `tensorflow.keras.applications`. \r\n\r\nTensorFlow Hub version of EfficientNet takes inputs in range [0, 1] : https://tfhub.dev/tensorflow/efficientnet/b0/classification/1\r\n\r\n> For this model, the size of the input image is flexible, but it would be best to match the model training input, which is height x width = 224 x 224 pixels for this model. The input images are expected to have color values in the range [0,1], following the common image input conventions.\r\n\r\n`tensorflow.keras.applications` version of EfficientNet takes inputs in range [0, 255]: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\r\n\r\n> This model takes input images of shape (224, 224, 3), and the input data should range [0, 255]. Normalization is included as part of the model.\r\n\r\nMy assumption is that they'd be the same?", "@mrdbourke Yes you are right. The inputs are different for hub module and keras applications module and thats the cause of the behavior that you are observing.", "@gowthamkpr do you know why the inputs are different for each model?", "Normalization was moved into the model code keeping in mind the Serving use-case. \r\n\r\nSo for desired behaviors\r\n**If you import model from `tf.keras.applications` : DO NOT Normalize the inputs**\r\n", "@mrdbourke,\r\nYes, there are differences between **`tf.keras.applications`** and the `Models` in `Tensorflow Hub`. In addition to above comments, please refer this [Stack Overflow](https://stackoverflow.com/a/60284154/11530462) issue, Answered by Tensorflow Hub Engineer, Arno. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42506\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42506\">No</a>\n"]}, {"number": 42505, "title": "Custom Constraint not working", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nIf I use custom constraint as `kernel_constraint` when I create a model:\r\n\r\n    model = keras.Sequential([keras.layers.Dense(y.shape[1], activation='softplus',\r\n                                                 kernel_constraint=SumConstraint(axis=0),\r\n                                                 # kernel_constraint=keras.constraints.MinMaxNorm(),\r\n                                                 bias_constraint=keras.constraints.MinMaxNorm(min_value=-100,\r\n                                                                                              max_value=100),\r\n                                                 input_shape=[x.shape[1]])])\r\n\r\nI always got this `ValueError: Unknown constraint: SumConstraint`.\r\n\r\nEven if I use the same class as @ymodak showed or use the example in document https://keras.io/api/layers/constraints/.\r\n\r\nrefer to: https://github.com/tensorflow/tensorflow/issues/39009\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@OnlyBelter \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "It seems like both v2.2 and v2.3 can work well on [colab](https://colab.research.google.com/gist/OnlyBelter/31fc0f61dd94117d170111bb50236197), but both versions cannot work on windows 10.\r\n\r\nSo I think this may a problem depends on operation system.", "I find this error showed when I try to load model instead of create model:\r\n\r\n```\r\nmodel = keras.models.load_model('model_reg.h5', compile=False)\r\n```\r\n\r\nEven if I set `compile` to False or pass `custom_objects` like this [issue](https://github.com/keras-team/keras/issues/5916) said or this question https://stackoverflow.com/a/57985788/2803344.", "@OnlyBelter I ran your code in Windows10, and I see the following output. It didn't throw any error as you mentioned. Thanks!\r\n```\r\n(10, 1)\r\n2020-08-20 12:27:10.424721: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 12:27:10.443085: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-20 12:27:10.464796: I tensorflow/compiler/jit/xla_cpu_device.cc:54] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-08-20 12:27:11.785275: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)\r\nEpoch 1/20\r\n2/2 [==============================] - 1s 736ms/step - loss: 72.3553 - mae: 7.1552\r\nEpoch 2/20\r\n2/2 [==============================] - 0s 999us/step - loss: 50.0566 - mae: 5.4311\r\nEpoch 3/20\r\n2/2 [==============================] - 0s 997us/step - loss: 32.1105 - mae: 4.1114\r\nEpoch 4/20\r\n2/2 [==============================] - 0s 3ms/step - loss: 31.2048 - mae: 4.0403\r\nEpoch 5/20\r\n2/2 [==============================] - 0s 997us/step - loss: 30.0318 - mae: 4.1776\r\nEpoch 6/20\r\n2/2 [==============================] - 0s 997us/step - loss: 32.6021 - mae: 4.0476\r\nEpoch 7/20\r\n2/2 [==============================] - 0s 996us/step - loss: 25.2929 - mae: 3.4210\r\nEpoch 8/20\r\n2/2 [==============================] - 0s 984us/step - loss: 30.3775 - mae: 4.2098\r\nEpoch 9/20\r\n2/2 [==============================] - 0s 2ms/step - loss: 31.6408 - mae: 3.9248\r\nEpoch 10/20\r\n2/2 [==============================] - 0s 997us/step - loss: 29.7707 - mae: 3.9027\r\nEpoch 11/20\r\n2/2 [==============================] - 0s 1ms/step - loss: 32.0798 - mae: 3.9232\r\nEpoch 12/20\r\n2/2 [==============================] - 0s 997us/step - loss: 34.9411 - mae: 3.9599\r\nEpoch 13/20\r\n2/2 [==============================] - 0s 998us/step - loss: 35.0551 - mae: 4.0664\r\nEpoch 14/20\r\n2/2 [==============================] - 0s 997us/step - loss: 23.1408 - mae: 3.3541\r\nEpoch 15/20\r\n2/2 [==============================] - 0s 487us/step - loss: 29.1516 - mae: 4.7043\r\nEpoch 16/20\r\n2/2 [==============================] - 0s 997us/step - loss: 26.7001 - mae: 3.8203\r\nEpoch 17/20\r\n2/2 [==============================] - 0s 997us/step - loss: 29.6401 - mae: 4.4714\r\nEpoch 18/20\r\n2/2 [==============================] - 0s 997us/step - loss: 28.8710 - mae: 4.7452\r\nEpoch 19/20\r\n2/2 [==============================] - 0s 997us/step - loss: 30.0289 - mae: 3.7971\r\nEpoch 20/20\r\n2/2 [==============================] - 0s 1ms/step - loss: 32.4385 - mae: 4.4056\r\n```", "@OnlyBelter As mentioned above, I cannot reproduce the error in my Windows10 desktop. Thanks!\r\n\r\nPlease verify and close the issue if this was already resolved for you. Thanks!", "Can you load saved model, like below:\r\n\r\n`model = keras.models.load_model('model_reg.h5', compile=False)`\r\n\r\nI can train model, but cannot load pre-trained model.", "@OnlyBelter I was able to load the saved model after adding `custom_objects` argument as shown below\r\n\r\n```\r\n# saved model as follows\r\nmodel.save('model_reg.h5',save_format='h5')\r\n\r\n# loaded the model as shown below\r\nmodel = keras.models.load_model('model_reg.h5', compile=False,custom_objects={'SoftMax':SoftMax})\r\n```\r\nIt runs in Windows10 as well as in colab. \r\n\r\nPlease verify once and close the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42505\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42505\">No</a>\n"]}, {"number": 42504, "title": "Duplicated target in TFLite Makefile ?", "body": "**Describe the current behavior**\r\nIt seems that there is a duplicated target in `lite/tools/make/Makeflie`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/make/Makefile#L318-L320\r\n\r\n```makefile\r\n# For normal manually-created TensorFlow Lite C++ source files.\r\n$(OBJDIR)%.o: %.cpp\r\n\t@mkdir -p $(dir $@)\r\n\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\r\n\r\n$(OBJDIR)%.o: %.cc\r\n\t@mkdir -p $(dir $@)\r\n\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\r\n\r\n# For normal manually-created TensorFlow Lite C source files.\r\n$(OBJDIR)%.o: %.c\r\n\t@mkdir -p $(dir $@)\r\n\t$(CC) $(CFLAGS) $(INCLUDES) -c $< -o $@\r\n$(OBJDIR)%.o: %.cpp  # Is this proper target?\r\n\t@mkdir -p $(dir $@)\r\n\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n```makefile\r\n# For normal manually-created TensorFlow Lite C++ source files.\r\n$(OBJDIR)%.o: %.cpp\r\n\t@mkdir -p $(dir $@)\r\n\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\r\n\r\n$(OBJDIR)%.o: %.cc\r\n\t@mkdir -p $(dir $@)\r\n\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\r\n\r\n# For normal manually-created TensorFlow Lite C source files.\r\n$(OBJDIR)%.o: %.c\r\n\t@mkdir -p $(dir $@)\r\n\t$(CC) $(CFLAGS) $(INCLUDES) -c $< -o $@\r\n#$(OBJDIR)%.o: %.cpp\r\n#\t@mkdir -p $(dir $@)\r\n#\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\r\n```\r\n", "comments": ["Thanks for reporting this. I'll prepare a PR.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42504\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42504\">No</a>\n"]}, {"number": 42807, "title": "cannot load the datasets", "body": "when i run: \r\nimport tensorflow_datasets as tfds\r\nmnist_train = tfds.load(name=\"mnist\", split=\"train\")\r\nwrong occured like this:\r\n2020-08-20 09:52:45.879679: W tensorflow/core/platform/cloud/google_auth_provider.cc:178] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Aborted: All 10 retry attempts failed. The last failure: Unavailable: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'\".\r\n2020-08-20 09:53:46.902189: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396edb1ff0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.038829 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:54:48.722926: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396eeb1ef0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.070107 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:55:50.452114: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396edee160 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.039491 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:56:57.020900: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396efbecd0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 5.08334 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\n2020-08-20 09:57:59.414296: E tensorflow/core/platform/cloud/curl_http_request.cc:596] The transmission  of request 0x56396f20f780 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fmnist%2F3.0.1?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.039584 (No error), connect time: 0 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)\r\ni want to know how can i solve it , thank you", "comments": ["I  solved  it with https://github.com/tensorflow/datasets/issues/2182, downgrade `tensorflow-datases` to 3.1.0. Hope it works for you.  ", "thank you so much\r\n"]}, {"number": 42503, "title": "[TF:MLIR] Convert FusedBatchNorm to FusedBatchNormV3 in prepare TFLite pass", "body": "", "comments": ["@ahmedsabie  Can you please check @smit-hinsu's comments and keep us posted ? Thanks!"]}]