[{"number": 8149, "title": "import tensorflow as tf ,display \"Segmentation fault\" And exit python env", "body": "os: CentOS Linux release 7.0.1406 (Core)\r\nos kernel:.10.0-123.9.3.el7.x86_64\r\npython version:Python 2.7.5\r\ngcc version:GCC 4.8.5 20150623\r\n         i download tensorflow-1.0.0-cp27-none-linux_x86_64.whl and install it.when i open python,input \"import tensorflow as tf\",display \"Segmentation fault\" and exit python;", "comments": ["i download setup file md5sum hash is :842f6e69897c4dbb583f855fb685c2e7\r\n.download source from github description \u201cInstallation\u201d.Then i try use \" pip install --upgrade tensorflow\",download setup tensorflow version is tensorflow-1.0.0-cp27-cp27mu-manylinux1_x86_64.whl,  runing normal.", "Could you please clarify what you mean by 'download source from github description \u201cInstallation\u201d'?  Are you downloading using the links in the README.md on [this](https://github.com/tensorflow/tensorflow) page ?  \r\n\r\nIf so, then please note that the link on that page to **stable** binary releases is currently down, so is it possible that you are using the links under \"People who are a little more adventurous can also try our nightly binaries:\" ?   These are from a live repo and so not guaranteed to be bug free!\r\n\r\nCould you please try following the instructions on this page: https://www.tensorflow.org/install/install_linux\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8148, "title": "[Java] Ability to load from SavedModel", "body": "This PR is exactly the same as #7688 with updates to the BUILD file to make tests pass so that we can merge the changes in.\r\n\r\nCloses #7134 and #7688 \r\n\r\n@EronWright : Not sure if you saw updates to #7688 asking for tweaks to the PR to make the tests pass. If you want to update that PR instead, I'm happy to abandon this one. Otherwise, will merge this one in and abandon the other.\r\n", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Setting \"cla:yes\" since the commits authored by @EronWright are exactly the same as in PR #7688 which he proposed.", "Jenkins, test this please", "Thanks @asimshankar for the tweaks and for driving this through.", "Ah, I probably shouldn't have squashed so we could preserve the correct `git blame` history.", "@jhseu yes that saddens me a little but don't worry about it\r\n"]}, {"number": 8147, "title": "RELEASE.md changes", "body": "Updating the RELEASE.md for patch version 1.0.1", "comments": ["I have a couple other addition requests to this file.\r\nCould you add the changes mentioned in https://github.com/tensorflow/tensorflow/issues/7836 and https://github.com/tensorflow/tensorflow/issues/8034#event-986058509 to the `Breaking changes to the API` section in 1.0.0 release notes? You can edit the 1.0.0 notes section in place, as these were actual changes made in 1.0.0 but forgotten to be added to the release notes.\r\n\r\nIn 1.0.1, Let's also mention:\r\nRemoved `tf.core` and `tf.python` modules from the API. These were never intended to be exposed. Please use the same objects through top-level `tf` module instead.", "Updated with your changes @gunan "]}, {"number": 8146, "title": "Using tensorflow.contrib with cv_bridge causes tcmalloc error", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nNone.\r\n\r\n### Environment info\r\nOperating System:\r\n```\r\n\u276f uname -a \r\nLinux dos 3.13.0-76-generic #120-Ubuntu SMP Mon Jan 18 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n\u276f ls -l /path/to/cuda/lib/libcud*\r\nls: cannot access /path/to/cuda/lib/libcud*: No such file or directory\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\n\u276f python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n1.0.0\r\n```\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```python\r\nimport tensorflow.contrib\r\nimport cv_bridge\r\n\r\nimport rospy\r\nrospy.init_node('node')\r\n```\r\nThis throws the following error:\r\n```\r\n/usr/bin/python2.7 /home/ethan/.PyCharmCE2016.3/config/scratches/scratch_4.py\r\nsrc/tcmalloc.cc:277] Attempt to free invalid pointer 0xa2e78616d5f7475 \r\n\r\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\r\n```\r\nI'll also post to stackoverflow and to the cv_bridge page (https://github.com/ros-perception/vision_opencv/issues/161).\r\n\r\n### What other attempted solutions have you tried?\r\nI tried reinstalling ros and tensorflow. No change. I also tried `print(cv_bridge.__file__)` to make sure I was importing the right directory for `cv_bridge`.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["@jhseu Could you please comment on whether recent jemalloc/tcmalloc changes might affect this?", "It's unrelated to jemalloc. My guess is it's an issue with your usage of tcmalloc.\r\n\r\nThat error would happen if you call tcmalloc's malloc() and try to free with glibc malloc() and vice-versa. Disable tcmalloc?", "@jhseu , I'm not exactly sure how to disable tcmalloc. I assume it's getting called either from tensorflow or cv_bridge, so would the best way be to find the actual `tcmalloc` function call and change it to `malloc`?", "It's definitely not in TensorFlow. We don't use tcmalloc anywhere.\r\n\r\nSo it's either coming from your environment or being used by cv_bridge. You can track it down through `gdb python` and `run /path/to/your/script.py`.", "This was the output:\r\n```\r\n(gdb) run test.py\r\nStarting program: /usr/bin/python test.py\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff2eda700 (LWP 5777)]\r\n[New Thread 0x7ffff26d9700 (LWP 5778)]\r\n[New Thread 0x7fffefed8700 (LWP 5779)]\r\n[New Thread 0x7fffed6d7700 (LWP 5780)]\r\n[New Thread 0x7fffeaed6700 (LWP 5781)]\r\n[New Thread 0x7fffe86d5700 (LWP 5782)]\r\n[New Thread 0x7fffe5ed4700 (LWP 5783)]\r\n[Thread 0x7fffe86d5700 (LWP 5782) exited]\r\n[Thread 0x7fffe5ed4700 (LWP 5783) exited]\r\n[Thread 0x7fffed6d7700 (LWP 5780) exited]\r\n[Thread 0x7fffeaed6700 (LWP 5781) exited]\r\n[Thread 0x7ffff2eda700 (LWP 5777) exited]\r\n[Thread 0x7fffefed8700 (LWP 5779) exited]\r\n[Thread 0x7ffff26d9700 (LWP 5778) exited]\r\n[New Thread 0x7fffe5ed4700 (LWP 5788)]\r\nsrc/tcmalloc.cc:277] Attempt to free invalid pointer 0xa2e78616d5f7475 \r\n\r\nProgram received signal SIGABRT, Aborted.\r\n[Switching to Thread 0x7fffe5ed4700 (LWP 5788)]\r\n0x00007ffff75e2cc9 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56\r\n56\t../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n```\r\nI wasn't really able to make sense of it. I also searched through all of `/opt/ros/indigo/` for `tcmalloc` with no results.\r\n\r\nIn a debugger, I stepped through the program until it threw the error. The offending line was `/opt/ros/indigo/lib/python2.7/dist-packages/rosgraph/xmlrpc.py:199`: \r\n```\r\n    def start(self):\r\n        \"\"\"\r\n        Initiate a thread to run the XML RPC server. Uses thread.start_new_thread.\r\n        \"\"\"\r\n        _thread.start_new_thread(self.run, ())\r\n```\r\n\r\nIs it possible that cv_bridge is using a version of OpenCV that is not compatible with the recent Tensorflow update?\r\n\r\n```\r\n\u276f pkg-config --modversion opencv\r\n2.4.13\r\n```", "We don't depend on opencv in TensorFlow, so I'm not sure. Closing out, though, because this bug is unlikely to be an issue in TensorFlow.", "That may be, but the script does not throw the error without the `import tensorflow.contrib` line.", "It's still unlikely to be in TensorFlow. My best guess without trying it out is that there's a shared module dependency somewhere, TF is using glibc malloc upon module import, and somewhere along the long someone is using tcmalloc and freeing.\r\n\r\nLibraries shouldn't be switching out malloc implementations unless its usage is completely self-contained.", "I (sort of) fixed it:\r\n```python\r\nimport cv_bridge  # <-- note: switched with\r\nimport tensorflow.contrib  # this\r\nimport rospy\r\nrospy.init_node('node')\r\n```\r\nThis does not throw an error. Why the order of imports matters is beyond me. These kinds of things seem to crop up often when working with ros.", "Yeah, import order affects symbol resolution order. My explanation before is most likely right, and it's a bug in cv_bridge.", "@lobachevzky Thanks for following up with the workaround.  It does indeed look like cv_bridge is doing something bad with tc_malloc.", "Ok. I did a little more digging and I found this line in my `.zshrc`:\r\n```bash\r\nexport LD_PRELOAD=\"/usr/lib/libtcmalloc_minimal.so.4\"  \r\n```\r\nCommenting this out solved the problem. I'm not really sure which of the three libraries that were involved would be responsible, but it might be good to include a more informative error message."]}, {"number": 8145, "title": "tensorflow r1.0 does not report training speed in the log any more", "body": "I used tensorflow r0.10 before with contrib.learn.\r\nWhen I set \r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\nafter imports, I would get the following info from the training log:\r\n\r\nINFO:tensorflow:Results after 10 steps (0.185 sec/batch): loss = 0.0644001, auc = 0.73555, accuracy/threshold_0.500000_mean = 0.988108\r\n\r\nBut with tensorflow r1.0, no such info in the training log any more.\r\nWhy is it removed? It is such a useful information.\r\nor do I need to set something else in the script?\r\n\r\nThanks for help.\r\n\r\n", "comments": ["That log message appears to still be in the source code here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/graph_actions.py#L786\r\n\r\nHowever, it is predicated on the `log_every_steps` parameter.  Perhaps this is being configured differently by default.\r\n\r\nIn any event, this code appears to be deprecated now, so I wouldn't suggest depending on the existence of this particular log message.  @ispirmustafa may know more.\r\n\r\nI'm closing this issue, since it's unlikely to be reverted."]}, {"number": 8144, "title": "Use vector constructor to initialize Array3D.", "body": "Current constructor of Array3D calls resize to initialize the inner vector of\r\nArray3D and follows up with a Fill call. This can be replaced with a simple\r\ncall to vector constructor. Vector constructor might also be more efficient.", "comments": ["Can one of the admins verify this patch?", "@hawkinsp Please review. Array2D has been covered in https://github.com/tensorflow/tensorflow/pull/8115.", "@hawkinsp Added Array4D changes.\r\n\r\n", "@tensorflow-jenkins Test this please", "The XLA test looks like a flake - retriggering.\r\n@tensorflow-jenkins Test this please"]}, {"number": 8143, "title": "Is unpack of TensorFlow deprecated?", "body": "I noticed that when I run the following code in v1.0.0 which was working well in v0.11.0 and v0.12.0, it's failed and told me that \r\n\r\n```\r\n new_shape = [batch_size, new_rows, new_cols, num_filters]\r\n tf_shape = tf.pack(new_shape)\r\n```\r\nerror:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'pack'\r\n```\r\n\r\nAnd I also can't find that in [tf api docs](https://www.tensorflow.org/api_guides/python/array_ops). I  am wondering what API to replace it? I didn't see any deprecated hint in [v0.12 api docs](https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops/)", "comments": ["Yes, you want to use `tf.unstack` instead.\r\n\r\nThis was mentioned in the [release notes](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md), though perhaps could have been advertised more.", "Thanks."]}, {"number": 8142, "title": "'Download and Setup' link in README.md is dead", "body": "The link points to: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md", "comments": ["@josh11b I think you just moved the docs that this link used to point to?", "New link is https://www.tensorflow.org/install/", "I found some references to os_setup.md and will update them.", "Pull request: #8169"]}, {"number": 8141, "title": "Error Compiling with XLA", "body": "I'm attempting to build Tensorflow from source with XLA, and am not able to run my test code. My test code: \r\n```\r\ndef main(_):\r\n    config = tf.ConfigProto(log_device_placement=True)\r\n    jit_level = 0 \r\n    if FLAGS.xla:\r\n        # Turns on XLA JIT compilation.\r\n        jit_level = tf.OptimizerOptions.ON_1\r\n\r\n    config.graph_options.optimizer_options.global_jit_level = jit_level\r\n    # Creates a session with log_device_placement set to True.\r\n    with tf.Session(config=config) as sess:\r\n        # Creates a graph.\r\n        with tf.device('/job:localhost/replica:0/task:0/device:XLA_CPU:0'):\r\n            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n            c = tf.matmul(a, b)\r\n\r\n        # Runs the op.\r\n        print(sess.run(c))\r\n```\r\nThe error I get:\r\n```\r\n$ TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python xla_test.py\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nDevice mapping: no known devices.\r\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\r\n\r\nTraceback (most recent call last):\r\n  File \"xla_test.py\", line 49, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"xla_test.py\", line 37, in main\r\n    run_metadata=run_metadata))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'MatMul': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:XLA_CPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\r\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](a, b)]]\r\n\r\nCaused by op u'MatMul', defined at:\r\n  File \"xla_test.py\", line 49, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"xla_test.py\", line 33, in main\r\n    c = tf.matmul(a, b)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1855, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\r\n    transpose_b=transpose_b, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'MatMul': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:XLA_CPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\r\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:XLA_CPU:0\"](a, b)]]\r\n\r\n```\r\n\r\nBuilding with:\r\n```\r\nPYTHON_BIN_PATH=/usr/bin/python3 TF_NEED_GCP=0 TF_NEED_HDFS=0 PYTHON_LIB_PATH=/usr/lib/python3/dist-packages TF_NEED_OPENCL=0 TF_NEED_CUDA=0 TF_ENABLE_XLA=1 TF_NEED_JEMALLOC=1 CC_OPT_FLAGS=\"-march=native\" ./configure && \\\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package && \\\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg && \\\r\nsudo pip3 install --upgrade /tmp/tensorflow_pkg/tensorflow-1.0.0*.whl\r\n```\r\n\r\nI am working on the master branch\r\n```\r\n$ git log | head -1\r\ncommit e6f547e4645f4922c50abb7d0506b1f9a6bd81c7\r\n$ git branch\r\n* master\r\n```\r\n\r\nI've posted on stackoverflow: http://stackoverflow.com/questions/42541323/error-running-tensorflow-with-xla", "comments": ["It looks like you haven't configure/linked in XLA JIT support for your binary.  The XLA_CPU  JIT device isn't registered, so the placer can't assign the matmul op there.\r\n\r\nI assume you're following the instructions here: https://www.tensorflow.org/versions/master/experimental/xla/jit ?\r\n\r\n> `Note: TensorFlow must be compiled from source to include XLA.`\r\n\r\nDid you enable XLA as part of the `./configure` process?\r\n(see https://github.com/tensorflow/tensorflow/blob/master/configure#L234)", "I am working with @lwogulis. We are building from source with the command above (broken below for better visibility),\r\n\r\n```\r\nPYTHON_BIN_PATH=/usr/bin/python3 \\\r\nTF_NEED_GCP=0 \\\r\nTF_NEED_HDFS=0 \\\r\nPYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\nTF_NEED_OPENCL=0 \\\r\nTF_NEED_CUDA=0 \\\r\nTF_ENABLE_XLA=1 \\\r\nTF_NEED_JEMALLOC=1 \\\r\nCC_OPT_FLAGS=\"-march=native\" \\\r\n./configure\r\n```\r\n\r\nSee above for the rest of the compile/install commands.", "I think with XLA, you still need to link in CUDA to be able to use GPU.\r\n\r\nEdit: sorry I misread the device you are using as XLA_GPU. Please disregard my comment.", "I was using python 2 when calling my function previously, but I was installing with python 3. Running with 3 now works."]}, {"number": 8140, "title": "Fix tf.contrib.framework.init_from_checkpoint", "body": "Loading to variables in the root scope (`/`) was not supported.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@tensorflow-jenkins test this please", "@vihanjain @ispirmustafa can you take a look?"]}, {"number": 8139, "title": "Misunderstood noise with moments of reused variables", "body": "I'm getting small variations in the result of running the same op repeatedly on what should be the same data for every sess.run().  \r\n\r\nThe included script demonstrates the issue.  Similar to batch norm, the function normalizer() maintains moving averages of the mean and var of the input tensor, but only updates those values when 'update=True'.  Whether True of False, the function returns the input tensor scaled and centered by the current moving average statistics. \r\n\r\nIn this example, I first normalize the input by its moments, and print out the new moments, only to validate that I get the same result every time, since the input is a constant.\r\n\r\nNext, I compute the moments of the output repeatedly when normalizer() is configured with update =True, so I can see the moments converging as expected towards their final state, but stop after only 20 steps.\r\n\r\nThese first two steps behave as expected.\r\n\r\nLastly, I compute the moments of the same output tensor repeatedly when normalizer() is configured with update=False. In this case, the moving averages shouldn't be updating so I expect to see the same moment values at every step. This is almost true, but there is a small amount noise that I wouldn't expect. Is this a tensorflow bug? \r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem? \r\n\r\nNone\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n-rw-r--r-- 1 root   root    556000 Jan 26 18:48 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root   root        16 Jan 26 18:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root   root        19 Jan 26 18:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rw-r--r-- 1 root   root    415432 Jan 26 18:48 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root   root    775162 Jan 26 18:48 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 bmages users       13 Jul 27  2016 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 bmages users       17 Jul 27  2016 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxrwxr-x 1 bmages users 79337624 Jul 27  2016 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-rw-r-- 1 bmages users 69756172 Jul 27  2016 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\nTensorflow 1.0.0\r\n\r\n### Code\r\n\r\n```\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\ndef normalizer(tensor,shape,axis=[0],decay = .999,update=True,\r\n                          epsilon = 1e-10,scope='normalizer' ):\r\n\r\n    with tf.variable_scope(scope,reuse=not(update)):\r\n\r\n        ma_mean = tf.get_variable(\r\n                      'ma_mean',\r\n                      shape=shape,\r\n                      initializer=tf.zeros_initializer(),\r\n                      trainable=False)\r\n        ma_var = tf.get_variable(\r\n              'ma_variance',\r\n              shape=shape,\r\n              initializer=tf.ones_initializer(),\r\n              trainable=False)\r\n\r\n        if update:\r\n\r\n            tensor_mean,tensor_var = tf.nn.moments(tensor,axis)\r\n            mean = tf.assign(ma_mean,ma_mean*decay + (1-decay)*tensor_mean)\r\n            var = tf.assign(ma_var,ma_var*decay + (1-decay)*tensor_var)\r\n\r\n            with tf.control_dependencies([mean, var]):\r\n                return tf.rsqrt(var+epsilon)*(tensor-mean)\r\n        else:\r\n\r\n            return tf.rsqrt(ma_var+epsilon)*(tensor-ma_mean)\r\n\r\n# random frame with scale and bias\r\nxdata = np.random.randn(16394,2)*np.array([10,20]) + np.array([-5,5])\r\nbatch = tf.constant(xdata,dtype=tf.float32)\r\n\r\n# normalize the input batch with its moments,\r\nxmean,xvar = tf.nn.moments(batch,axes=[0])\r\nxnorm = tf.rsqrt(xvar)*(batch-xmean)\r\nmoments_x = tf.nn.moments(xnorm,axes=[0])\r\n\r\n# create normalizer in update mode\r\ny = normalizer(batch,shape=[2],axis=[0],decay = .99,update=True)\r\nmoments_y = tf.nn.moments(y,axes=[0])\r\n# create in test mode\r\ny_test = normalizer(batch,shape=[2],axis=[0],decay = .99,update=False)\r\nmoments_test = tf.nn.moments(y_test,axes=[0])\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.group(tf.global_variables_initializer(),tf.local_variables_initializer()))\r\n\r\n    print('\\nRun input moments for 10 steps for sanity check,every step should be identical...\\n')\r\n    for _ in range(10):\r\n        mean,var = sess.run(moments_x)\r\n        print(mean,var)\r\n    print('\\nRun update for 20 steps...\\n')\r\n    for _ in range(20):\r\n        mean,var = sess.run(moments_y)\r\n        print(mean,var)\r\n    print('\\nRun test for 20 steps, every step should be identical...\\n')\r\n    for _ in range(20):\r\n        mean,var = sess.run(moments_test)\r\n        print(mean,var)\r\n```\r\nHere is a print out that I get from running this script:\r\n```\r\nRun input moments for 10 steps for sanity check,every step should be identical...\r\n\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n[ -8.81308182e-09  -2.29443700e-08] [ 1.00000048  1.00000143]\r\n\r\nRun update for 20 steps...\r\n\r\n[-3.51247048  2.21043849] [ 50.22803497  80.21085358]\r\n[-2.84657669  1.6346755 ] [ 33.65858841  44.75781631]\r\n[-2.44675541  1.34974301] [ 25.37238884  31.13418961]\r\n[-2.17202067  1.17136073] [ 20.40036011  23.92469788]\r\n[-1.96787024  1.04593885] [ 17.08568954  19.46290207]\r\n[-1.80818331  0.95137215] [ 14.71818542  16.4295311 ]\r\n[-1.67866027  0.876652  ] [ 12.94268036  14.2333889 ]\r\n[-1.57072532  0.81559616] [ 11.56188488  12.56995583]\r\n[-1.47887969  0.76442826] [ 10.45738792  11.26643467]\r\n[-1.3994118   0.72069311] [  9.55385685  10.21746349]\r\n[-1.32971382  0.68271512] [ 8.80101871  9.35515976]\r\n[-1.26789105  0.64930677] [ 8.16414165  8.63379192]\r\n[-1.21253002  0.6195991 ] [ 7.61835909  8.02145481]\r\n[-1.16255021  0.59293979] [ 7.14544487  7.4951849 ]\r\n[-1.11711097  0.56882787] [ 6.73175192  7.03804827]\r\n[-1.07554555  0.5468713 ] [ 6.3668232   6.63729095]\r\n[-1.03731847  0.52675873] [ 6.04253292  6.2830925 ]\r\n[-1.00199318  0.50823855] [ 5.75246429  5.96780682]\r\n[-0.96920985  0.49110541] [ 5.49148464  5.68536663]\r\n[-0.93866938  0.47518966] [ 5.25543642  5.43090725]\r\n\r\nRun test for 20 steps, every step should be identical...\r\n\r\n[-0.93866932  0.47518966] [ 5.25543785  5.43090677]\r\n[-0.93866938  0.47518966] [ 5.2554369   5.43090773]\r\n[-0.93866938  0.47518966] [ 5.25543928  5.43090773]\r\n[-0.93866938  0.47518963] [ 5.25543547  5.43090773]\r\n[-0.93866938  0.47518966] [ 5.25543976  5.43090773]\r\n[-0.93866938  0.47518963] [ 5.25543642  5.43090725]\r\n[-0.93866938  0.47518966] [ 5.25543976  5.43090582]\r\n[-0.93866938  0.47518966] [ 5.2554388   5.43090677]\r\n[-0.93866932  0.47518966] [ 5.25543737  5.43090725]\r\n[-0.93866938  0.47518966] [ 5.25543642  5.43090677]\r\n[-0.93866938  0.47518963] [ 5.2554388   5.43090725]\r\n[-0.93866932  0.47518963] [ 5.25543642  5.43090773]\r\n[-0.93866938  0.47518966] [ 5.25543928  5.43090677]\r\n[-0.93866932  0.47518966] [ 5.25543737  5.43090725]\r\n[-0.93866932  0.47518966] [ 5.2554388   5.43090582]\r\n[-0.93866938  0.47518963] [ 5.25543642  5.4309082 ]\r\n[-0.93866932  0.47518966] [ 5.25543737  5.43090582]\r\n[-0.93866938  0.47518966] [ 5.25543594  5.43090725]\r\n[-0.93866932  0.47518966] [ 5.2554369   5.43090677]\r\n[-0.93866938  0.47518963] [ 5.25543547  5.43090677]\r\n```\r\n### What other attempted solutions have you tried?\r\nI've tried many variants of this but without any difference.  This is a stripped down example.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["@lw394 Could you please let me know whether you are running on GPU or CPU?  \r\n`tf.nn.moments` is basically doing a parallel reduce_sum over the tensor, and on GPU it's quite possible that large reductions have non-deterministic floating point rounding errors. \r\n\r\n@rmlarsen @zheng-xq  Do either of you know whether moments is expected/promised to be 100% deterministic?", "thank you for the quick response.  I'm using a GPU machine, however, before I got around to submitting this I had included a `with tf.device('/cpu:0'):` statement to wrap the normalizer() function, and that didn't change anything.  However, I just realized I didn't wrap the other moments ops following normalizer calls, and when I just tried that, I'm getting exact results between successive steps as expected. thank you for pointing this out.  It sounds like it must be non-deterministic GPU rounding errors.", "In general, many GPU reduction ops in TensorFlow uses atomic operations, which are non-deterministic. Normally, this is considered fine. It is only an indication of errors if there are large difference within a single step. ", "thank you. ", "Closing this as \"expected\" behavior.  "]}, {"number": 8138, "title": "gradient_override_map should raise an error if passed invalid gradient names.", "body": "Currently, gradient_override_map does not complain if passed in nonsensical information (apart from the simple check to make sure the map is a map from strings to strings).\r\n\r\nFor instance, the following lines of code run without issue:\r\n\r\n` with graph.gradient_override_map({\"nonsense\": \"more_nonsense\"}):\r\n      input = tf.sign(input)`\r\n\r\nA more subtle point (that happened with me), when attempting to override sign's gradient, the following typo ran without problem:\r\n\r\n` with graph.gradient_override_map({\"sign\": \"Identity\"}):\r\n      input = tf.sign(input)`\r\n(\"sign\" should be \"Sign\").\r\n\r\nSeems like a fairly simple issue, but I am not quite versed enough in the Tensorflow backend to suggest a fix to this problem.", "comments": ["@mrry It looks from the code that this would be difficult to do since `tf.gradient_override_map` is a Python construct and (presumably) doesn't have an easy way to validate the args against all registered op names? \r\n\r\nFWIW, the documentation [here](https://www.tensorflow.org/versions/master/api_docs/python/framework/core_graph_data_structures), does show a clear example where the name of the op whose gradient is being overridden is capitalized whilst the python op wrapper uses the PEP11 naming convention.\r\n\r\nIt's also still labelled as EXPERIMENTAL in the docs ... Is this still the case, or is it part of the TF1.0 API?", "Unfortunately it's now part of the 1.0 API so we can't easily change it. It might be possible to validate the names of ops against the `OpDef` registry, which should catch some errors. Over time, however, I think we'll want to standardize on TF functions (which I guess are not yet part of the stable `tf.*` API) as the way to specify overridden gradients for subgraphs and individual ops.", "Agreed that in general the names should match the python functions. I haven't delved into the code as much as I should have, but wouldn't it be possible just to keep a list around in python of everything that got \"tf.RegisterGradient(...)\"-d and check `gradient_override_map` against it?", "I don't think the set of names for which `tf.RegisterGradient()` has been called is sufficient for validating the override map keys... for example a common use is to register a temporary gradient for an op that doesn't in general have one."]}, {"number": 8136, "title": "Unified mechanism for setting process-level settings ", "body": "Some settings in TensorFlow apply to all sessions in the process. Examples: size of Eigen thread-pool, allocator growth strategy, logging verbosity\r\n\r\nThere are currently two places where such process properties are set:\r\n1. Environment variables\r\n2. tf.ConfigProto passed to the first tf.Session() or tf.Server() call\r\n\r\nthe 1. lacks discoverability. For instance required SM count to make GPU visible to TensorFlow is set through `TF_MIN_GPU_MULTIPROCESSOR_COUNT` which is not documented outside of `gpu_device.cc`. Additionally, it has unclear semantics. When does changing `TF_CPP_MIN_VLOG_LEVEL` environment variable have an effect on logging? Empirically, changing it after `import tf` has an effect, changing it after first `tf.Session` call has no effect.\r\n\r\nthe 2. leads to confusion when you specify conflicting settings. For instance, in https://github.com/tensorflow/tensorflow/issues/4455 the user was confused that  `config=tf.ConfigProto(intra_op_parallelism_threads=1` had no effect. The reason is that `intra_op_parallelism_threads` specifies the size of process global ThreadPool, and this setting was already fixed when user called `tf.Server` earlier. (we also ran into this issue on our deployment)\r\n\r\ncc @mrry \r\nassigning to @tatatodd for triage since he asked me to file this issue", "comments": ["Thanks for filing this feature-request issue @yaroslavvb, and the great analysis!\r\n\r\nAssigning to @mrry since he knows about Session subtleties much better than I do.\r\n\r\n", "It turns out there are some even subtler subtleties related to the ownership of GPU devices, allocators, and streams, which ought to be solved before we change anything else about configuration.\r\n\r\nAssigning this to @zheng-xq and @poxvoculi, who're looking into the GPU issues.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I agree with Derek that these are indeed subtle issues. We are systematically changing devices, allocators and streams to global resources. But the API still at the session level for backward compatibility.\r\n\r\nClosing this one for now. Feel free to reopen if someone wants to contribute a new design. ", "Another kind of failure:\r\n```python\r\n# running on a machine with >1 GPUs\r\nprint(tf.test.is_gpu_available())\r\n# or call list_devices()\r\n\r\ncfg = tf.ConfigProto()\r\ncfg.gpu_options.visible_device_list = '1'\r\nsess = tf.Session(config=cfg)   # fail\r\n```\r\nThis is quite annoying: some line of code executed earlier leads to an error later with strange error message.", "same question for me, thanks", "It's so tricky in the tensorflow session.", "> Another kind of failure:\r\n> \r\n> ```python\r\n> # running on a machine with >1 GPUs\r\n> print(tf.test.is_gpu_available())\r\n> # or call list_devices()\r\n> \r\n> cfg = tf.ConfigProto()\r\n> cfg.gpu_options.visible_device_list = '1'\r\n> sess = tf.Session(config=cfg)   # fail\r\n> ```\r\n> \r\n> This is quite annoying: some line of code executed earlier leads to an error later with strange error message.\r\n\r\nWRT to this problem, moving the `tf.test.is_gpu_available()` to after `sess = tf.Session(config=cfg)` fixes the memory/cpu error that you probably are seeing. What's happening is `tf.test.is_gpu_available()` has to start a session to check the resources. This session is started with the default config (which has a setting that allows it to consume all of the cpu/ram resources). Then, when you try to initialize your own session, it throws an error because there are no gpu resources left for it.\r\n\r\nIMO, one of two corrections should be used.\r\n1. If `tf.test.is_gpu_available()` has the authority to start it's own session, it should kill that session after the resources have been checked.\r\n2. This really needs to be in the docs, since it isn't obvious to new users, or even ones that have been using the codebase for awhile. "]}, {"number": 8135, "title": "Remove the extra linkopt in ci_parameterized_build script.", "body": "/CC @av8ramit ", "comments": ["Will merge back the branch after the release.\r\nWanted to make this quick to unblock the release.", "Note if you merge back: I made some Ubuntu 14.04-specific Docker changes in r1.0 that don't belong in master.\r\n\r\nI think just these changes need to be ignored:\r\nhttps://github.com/tensorflow/tensorflow/commit/49b8223c307151a396830049ac07bc871d66334c\r\nhttps://github.com/tensorflow/tensorflow/commit/b0c34b0a6e87733ec51a28ee6c4232f3a95ebf37"]}, {"number": 8134, "title": "Download of test data not working", "body": "The get started part has a section MNIST for ML Beginners. In this tutorial you should download the test data via:\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n\r\nUnfortunately that's not working because of an connection error. ", "comments": ["The MNIST example downloads its dataset from `http://yann.lecun.com/exdb/mnist`.\r\nIf this site is temporarily down or unreachable then the download will fail. \r\n\r\nPlease can you try accessing the URL directly in a web browser?  (it is currently unreachable for me) \r\nOnce the page is accessible in a browser, then please try the tutorial again.", "Hi!\r\nThanks for the fast reply. No, it is not reachable in the browser. Is there an alternative way to get the relevant data?", "Duplicate of #8126", "I am getting \" HTTP Error 403: Forbidden\" while trying to download MNIST dataset using ```input_data.read_data_sets(\"MNIST_data/\", one_hot=True)``` command, though the data is downloadable from Yann LeCun website. \r\n\r\nTensorflow version 1.4"]}, {"number": 8133, "title": "About using tf.contrib.layers.optimize_loss with optimizer=\"Momentum\" as arg ", "body": "I'm trying to implement a train op using tf.contrib.layers.optimize_loss. I would like to use the optimizer train.MomentumOptimizer . One way to do it is to pass the arg \"Momentum\" to the parameter optimizer like this:\r\n\r\n```python\r\n    train_op = tf.contrib.layers.optimize_loss(\r\n        loss=loss,\r\n        global_step=tf.contrib.framework.get_global_step(),\r\n        learning_rate=0.001,\r\n        optimizer=\"Momentum\")\r\n```\r\nIt turns out I get an error:\r\n```\r\n__init__() missing 1 required positional argument: 'momentum'\r\n```\r\nI think the reason is that when the function optimize_loss wants to instanciate a new optimizer by looking into ```OPTIMIZER_CLS_NAMES``` it calls  tensorflow\\contrib\\layers\\python\\layers\\optimizers.py\", line 195, in optimize_loss : \r\n```python\r\nopt = OPTIMIZER_CLS_NAMES[optimizer](learning_rate=lr)\r\n```\r\nHowever, among the whole list of optimizers in ```OPTIMIZER_CLS_NAMES```, train.MomentumOptimizer is the only one that needs a second mandatory parameter in its ```__init__``` method:\r\n```python\r\nclass MomentumOptimizer(optimizer.Optimizer):\r\n  \"\"\"Optimizer that implements the Momentum algorithm.\r\n\r\n  @@__init__\r\n  \"\"\"\r\n\r\n  def __init__(self, learning_rate, momentum,\r\n               use_locking=False, name=\"Momentum\", use_nesterov=False):\r\n```\r\n... whereas the other ones don't. Am I missing something?\r\nThank you in advance", "comments": ["I believe the answer you're looking for is at the docs of the said function:\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/layers/optimize_loss\r\n\r\n> function, takes learning rate Tensor as argument and must return Optimizer instance. E.g. `optimize_loss(..., optimizer=lambda lr: tf.train.MomentumOptimizer(lr, momentum=0.5))`. Alternatively, if learning_rate is None, the function takes no arguments. E.g. `optimize_loss(..., learning_rate=None, optimizer=lambda: tf.train.MomentumOptimizer(0.5, momentum=0.5))`.", "This question would be better suited for StackOverflow. That said, @MicaelCarvalho is correct."]}, {"number": 8132, "title": "One shot learning example", "body": "It might be a good thing to give an example of one shot learning :)", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 8131, "title": "Better document when to use tf.sparse_tensor_dense_matmul vs embedding lookup", "body": "`tf.sparse_tensor_dense_matmul` has a regular (non-sparse) tensor gradient ([source](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/sparse_grad.py#L153)):\r\n\r\n```python\r\n  # gradient w.r.t. dense\r\n  b_grad = sparse_ops.sparse_tensor_dense_matmul(sp_t, grad,\r\n                                                 adjoint_a=not adj_a)\r\n```\r\n\r\nwhere `sparse_ops.sparse_tensor_dense_matmul` returns a regular tensor.\r\n\r\nThe [documentation](https://www.tensorflow.org/api_docs/python/tf/sparse_tensor_dense_matmul) does not note this and it may be confusing for people coming from e.g. NLP where you frequently work with dense-sparse multiplications with sparse gradients.  \r\n\r\nIn many cases where you might naively think you want to use `tf.sparse_tensor_dense_matmul` you actually want to use [`tf.nn.embedding_lookup_sparse`](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse), even if your task has nothing to do with embeddings.  It would be helpful if there were a cross-reference in the documentation to guide users in the right direction.\r\n", "comments": ["Does that pr address the question of sparse updates when working with an\noptimiser?\n\nOn May 1, 2017 9:22 AM, \"Vijay Vasudevan\" <notifications@github.com> wrote:\n\n> Closed #8131 <https://github.com/tensorflow/tensorflow/issues/8131> via\n> 998baa0\n> <https://github.com/tensorflow/tensorflow/commit/998baa0f1fa8aee4382be1a00e4ae9ee70a6b194>\n> .\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8131#event-1064152201>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8Mbs9Vq7S7zW7KGCOs1fdDfpHMGks5r1gbagaJpZM4MUUvF>\n> .\n>\n"]}, {"number": 8130, "title": "TensorFlow 1.0 error messages point to broken link", "body": "When `import tensorflow` fails in TF 1.0, we print an error message containing the following text:\r\n\r\n```\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions. Include the entire stack trace above this error message when asking for help.\r\n```\r\n\r\nUnfortunately, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error is a broken link. I realize this is probably because we've moved all the docs around, but is there some way we could leave a breadcrumb there for our unfortunate users?\r\n\r\nThe proper link should include the `r1.0` branch: https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n", "comments": ["(Just saw that PR #8075 should fix this.)"]}, {"number": 8129, "title": "No event files found within logdir in tensorboard", "body": "Dear Sir/mam\r\n\r\nI confuse how to display using tensorboard. here is my program\r\ngraph = \"d://\"\r\nimport tensorflow as tf\r\n\r\n# Build our graph nodes, starting from the inputs\r\na = tf.constant(5, name=\"input_a\")\r\nb = tf.constant(3, name=\"input_b\")\r\nc = tf.multiply(a,b, name=\"mul_c\")\r\nd = tf.add(a,b, name=\"add_d\")\r\ne = tf.add(c,d, name=\"add_e\")\r\n\r\n# Open up a TensorFlow Session\r\nsess = tf.Session()\r\n\r\n# Execute our output node, using our Session\r\noutput = sess.run(e)\r\n\r\n# Open a TensorFlow SummaryWriter to write our graph to disk\r\nwriter = tf.summary.FileWriter(graph, sess.graph)\r\n\r\n# Close our SummaryWriter and Session objects\r\nwriter.close()\r\nsess.close()\r\n\r\nthe events file has been created in drive D (i'm using windows 8.1, and tensorflow 1.0). and i found it when using explorer\r\n\r\nWhen I type \r\ntensorboard --inspect --logdir =\"d:\\\\\"\r\ntensorboard --inspect --logdir =\"d:\\\"\r\ntensorboard --inspect --logdir =\"d://\"\r\ntensorboard --inspect --logdir =\"d:/\"\r\n\r\ntensorboard --inspect --logdir ='d:\\\\'\r\ntensorboard --inspect --logdir ='d:\\'\r\ntensorboard --inspect --logdir ='d://'\r\ntensorboard --inspect --logdir ='d:/'\r\n\r\nthe result are : No event files found within logdir, \r\n\r\npls tell me why this happened.\r\n\r\nThx\r\n", "comments": ["Closing as a duplicate of #7856. \r\nPlease reopen if the workaround in that issue doesn't fix the problem.", "Dear prb12\r\n\r\nI already changed the windows command prompt to d: and write like this\r\n\r\nd:>tensorboard --logdir = D:\\ \r\nbut the data still not shown, even in drive D there are several events data.\r\n\r\nThx", "Could you please reread the comment from mrry@ in the issue I referenced which explains that file name parsing interprets the leading drive letter component as a \u2018tag\u2019 and hence you will need to prefix your pathname with an extra \u2018tag:\u2019 to workaround this on Windows.\n\nOn March 6, 2017 at 6:25:59 PM, MyAusweis (notifications@github.com) wrote:\n\nDear prb12\n\nI already changed the windows command prompt to d: and write like this\n\nd:>tensorboard --logdir = D:\\\nbut the data still not shown, even in drive D there are several events data.\n\nThx\n\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n", "(i) Open a command prompt in admin mode \r\n(ii) Change your directory to where your event files are located;\r\n run tensor board works with the appropriate logdir, works beautifully !"]}, {"number": 8128, "title": "fix a typo in tf.cond docstring", "body": "pref->pred", "comments": ["@tensorflow-jenkins test this please."]}, {"number": 8127, "title": "AttributeError: module 'tensorflow' has no attribute 'streaming_accuracy'", "body": "```\r\naccuracy = tf.streaming_accuracy (y_pred,y_true,name='acc')\r\nrecall = tf.streaming_recall (y_pred,y_true,name='acc')\r\nprecision = tf.streaming_precision(y_pred,y_true,name='acc')\r\nconfusion = tf.confuson_matrix(Labels, y_pred,num_classes=10,dtype=tf.float32,name='conf')\r\n```\r\nfor the above code, I have received the same error in past few days. \r\nIs the syntax same as its in the API documentation?", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8126, "title": "yann.lecun.com/exdb/mnist/ down", "body": "The website of Yann LeCun is down at the moment. \r\nTherefore the MNIST-Script for downloading the files doesn't work either. (-> learn/python/learn/datasets/mnist.py won't work)\r\nAre there any mirrors?", "comments": ["Apparently (according to @kakawait) you can download dataset via archive machine, e.g. https://web.archive.org/web/20160828233817/http://yann.lecun.com/exdb/mnist/index.html \r\n\r\nYou will need to download and copy the files to your training data directory manually."]}, {"number": 8125, "title": "Fix broken links to docs_src/get_started/get_started.md", "body": "Fix broken links to tensorflow/tensorflow/docs_src/get_started/get_started.md", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Can you repro that the links are broken? They seem to be working on tensorflow.org. If there is a bug, we would want to fix our custom link generator rather than short-circuiting it and using raw markdown.", "I don't know why I cannot access tensorflow.org, so I can only learn TensorFlow from github, Is there anyway that the links work well in both link generator and markdown environment?", "It sounds like the root issue to debug is that you can't access tensorflow.org. I don't think we're aiming to maintain the doc links in pure-markdown, but I'll let @josh11b comment on that.", "I agree with @dandelionmane , our strategy is described in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/g3doc\r\n\r\nMaybe @martinwicke can offer suggestions for accessing these docs without tensorflow.org (a case we would like to support, for e.g. people who know they will be offline).", "Actually, you can follow the instructions in that README, to generate an offline copy of the docs with the links fixed.", "Closing this PR since the site is working as intended.", "I got it, thank you. "]}, {"number": 8124, "title": "Build failure, XLA, OS/X", "body": "I've written OS/X, but I'm pretty sure this is going to fail on all platforms:\r\n\r\n```\r\ntensorflow/compiler/tf2xla/xla_compiler.cc:228:44: error: no type named 'size_typ' in 'std::__1::vector<tensorflow::XlaCompiler::Argument, std::__1::allocator<tensorflow::XlaCompiler::Argument> >'; did you mean 'size_type'?\r\n  for (std::vector<XlaCompiler::Argument>::size_typ i = 0;\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~\r\n                                           size_type\r\n/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/vector:470:54: note: 'size_type' declared here\r\n    typedef typename __base::size_type               size_type;\r\n                                                     ^\r\ntensorflow/compiler/tf2xla/xla_compiler.cc:480:33: error: no member named 'VariableWrite' in 'tensorflow::XlaCompiler'\r\n  for (std::vector<XlaCompiler::VariableWrite>::size_type  i = 0;\r\n                   ~~~~~~~~~~~~~^\r\ntensorflow/compiler/tf2xla/xla_compiler.cc:480:47: error: no template named 'size_type' in the global namespace; did you mean 'std::__size_type'?\r\n  for (std::vector<XlaCompiler::VariableWrite>::size_type  i = 0;\r\n                                              ^~~~~~~~~~~\r\n                                              std::__size_type\r\n/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/memory:1090:8: note: 'std::__size_type' declared here\r\nstruct __size_type\r\n       ^\r\ntensorflow/compiler/tf2xla/xla_compiler.cc:480:49: error: use of class template '::__size_type' requires template arguments\r\n  for (std::vector<XlaCompiler::VariableWrite>::size_type  i = 0;\r\n                                                ^\r\n/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/memory:1090:8: note: template is declared here\r\nstruct __size_type\r\n       ^\r\n4 errors generated.\r\n\r\n```\r\n", "comments": ["I see that this is in the process of being fixed.\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/8039\r\n\r\n"]}, {"number": 8123, "title": "Build failure, XLA, OS/X", "body": "Maybe OS/X only.   I have Apple clang 8.0.0 (clang-800.0.42.1)\r\n\r\n```\r\ntensorflow/compiler/xla/service/allocation_tracker.cc:178:54: error: non-constant-expression cannot be narrowed from type 'std::vector<se::DeviceMemoryBase>::size_type' (aka 'unsigned long') to 'long long' in initializer list [-Wc++11-narrowing]\r\n        ShapeUtil::GetSubshape(allocation->shape(), {i}),\r\n                                                     ^\r\ntensorflow/compiler/xla/service/allocation_tracker.cc:178:54: note: insert an explicit cast to silence this issue\r\n        ShapeUtil::GetSubshape(allocation->shape(), {i}),\r\n                                                     ^\r\n                                                     static_cast<long long>( )\r\n\r\n```\r\n\r\n", "comments": ["I see that this has been mentioned before:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/8024\r\n\r\n", "related?\r\n\r\nERROR: /Users/davidlaxer/tensorflow/tensorflow/compiler/xla/service/BUILD:412:1: C++ compilation of rule '//tensorflow/compiler/xla/service:allocation_tracker' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 105 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ntensorflow/compiler/xla/service/allocation_tracker.cc:178:54: error: non-constant-expression cannot be narrowed from type 'std::vector<se::DeviceMemoryBase>::size_type' (aka 'unsigned long') to 'long long' in initializer list [-Wc++11-narrowing]\r\n        ShapeUtil::GetSubshape(allocation->shape(), {i}),\r\n                                                     ^\r\ntensorflow/compiler/xla/service/allocation_tracker.cc:178:54: note: insert an explicit cast to silence this issue\r\n        ShapeUtil::GetSubshape(allocation->shape(), {i}),\r\n                                                     ^\r\n                                                     static_cast<long long>( )\r\n1 error generated.\r\n"]}, {"number": 8122, "title": "A Bug Report about TensorBoard", "body": "# Bug Description:\r\nOn win10 platform, you use command __tensorboard --logdir=path/to/logdir__ where located to __another driver__ which don't include the logdir. __TensorBoard will think the logdir in that driver__.\r\n# Example:\r\nIn VS Prompt:\r\n\r\n1.  **F**:\\Program Files (x86)\\Microsoft Visual Studio 14.0>tensorboard --logdir=**G:\\machine_learning\\models\\Alexnet_tf\\log_** --debug\r\n\r\n__cmd output__:\r\nINFO:tensorflow:TensorBoard is in debug mode.\r\nINFO:tensorflow:Starting TensorBoard in directory F:\\Program Files (x86)\\Microsoft Visual Studio 14.0\r\nINFO:tensorflow:**TensorBoard path_to_run is: {'F:\\\\machine_learning\\\\models\\\\Alexnet_tf\\\\log_': 'G'}**\r\nINFO:tensorflow:Event Multiplexer initializing.\r\nINFO:tensorflow:Event Multiplexer done initializing\r\nINFO:tensorflow:TensorBoard reload process beginning\r\nINFO:tensorflow:Starting AddRunsFromDirectory: F:\\machine_learning\\models\\Alexnet_tf\\log_\r\nINFO:tensorflow:Done with AddRunsFromDirectory: F:\\machine_learning\\models\\Alexnet_tf\\log_\r\nINFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer\r\nINFO:tensorflow:Beginning EventMultiplexer.Reload()\r\nINFO:tensorflow:Finished with EventMultiplexer.Reload()\r\nINFO:tensorflow:TensorBoard done reloading. **Load took 0.000 secs**\r\nINFO:tensorflow:TensorBoard is tag: b'41'\r\nStarting TensorBoard b'41' on port 6006\r\n(You can navigate to http://192.168.1.202:6006)\r\n\r\n__Nothing you can see in Chrome, a blank page.__\r\n\r\n2.  **G**:\\>tensorboard --logdir=**G:\\machine_learning\\models\\Alexnet_tf\\log_** --debug\r\n\r\n__cmd output__:\r\nINFO:tensorflow:TensorBoard is in debug mode.\r\nINFO:tensorflow:Starting TensorBoard in directory G:\\\r\nINFO:tensorflow:**TensorBoard path_to_run is: {'G:\\\\machine_learning\\\\models\\\\Alexnet_tf\\\\log_': 'G'}**\r\nINFO:tensorflow:Event Multiplexer initializing.\r\nINFO:tensorflow:Event Multiplexer done initializing\r\nINFO:tensorflow:TensorBoard reload process beginning\r\nINFO:tensorflow:Starting AddRunsFromDirectory: G:\\machine_learning\\models\\Alexnet_tf\\log_\r\nINFO:tensorflow:Adding events from directory G:\\machine_learning\\models\\Alexnet_tf\\log_\r\nINFO:tensorflow:Constructing EventAccumulator for G:\\machine_learning\\models\\Alexnet_tf\\log_\r\nINFO:tensorflow:Done with AddRunsFromDirectory: G:\\machine_learning\\models\\Alexnet_tf\\log_\r\nINFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer\r\nINFO:tensorflow:Beginning EventMultiplexer.Reload()\r\nDEBUG:tensorflow:Opening a record reader pointing at G:\\machine_learning\\models\\Alexnet_tf\\log_\\events.out.tfevents.1488779830.ubuntu-Default-string\r\nINFO:tensorflow:TensorBoard is tag: b'41'\r\nStarting TensorBoard b'41' on port 6006\r\n(You can navigate to http://192.168.1.202:6006)\r\nDEBUG:tensorflow:No more events in G:\\machine_learning\\models\\Alexnet_tf\\log_\\events.out.tfevents.1488779830.ubuntu-Default-string\r\nINFO:tensorflow:No path found after G:\\machine_learning\\models\\Alexnet_tf\\log_\\events.out.tfevents.1488779830.ubuntu-Default-string\r\nINFO:tensorflow:Finished with EventMultiplexer.Reload()\r\nINFO:tensorflow:TensorBoard done reloading. **Load took 4.234 secs**\r\n\r\n__Now Scalars page has loss graph defined.__\r\n\r\n# Question:\r\nWhy TensorBoard reads event-file depend on the command where inputed(As shown abone, logdir in G: but go to F: ? It shouldn't be.", "comments": ["Thanks for reporting this! We're already tracking this problem as part of issue #7856, so please follow the discussion there.", "@mrry Thanks for your reminder, I should have checked whether it was reported."]}, {"number": 8121, "title": "tensorflow.contrib.distributions.python.ops.distribution_util' has no attribute 'get_logits_and_probs'", "body": "windows 10\r\nupgraded with pip install to tensorflow 1.0\r\n\r\nI got this error after trying to use Binomial.py\r\n\r\n self._logits, self._probs = distribution_util.get_logits_and_probs(\r\nAttributeError: module 'tensorflow.contrib.distributions.python.ops.distribution_util' has no attribute 'get_logits_and_probs'\r\n\r\n", "comments": []}, {"number": 8120, "title": "Inconsistency in Variable Creation Methods", "body": "Currently it is not possible to scope all variables cleanly when using RNN cells and Optimizers. RNN cells create variables with tf.get_variable and optimizers create variables with tf.Variable. These two methods don't get along, creating messy variable names when variable scopes are handled differently by the two methods.\r\n\r\nScript for testing different variable creation and scoping combinations.\r\n```python\r\n# -*- coding: utf-8 -*-\r\n\r\nimport tensorflow as tf\r\n\r\n\r\ndef build_loss(use_get_variable=True):\r\n    y = tf.placeholder('int32', [None], name='y')\r\n    x = tf.placeholder('float32', shape=[None, None, 10], name='x')\r\n    cell = tf.contrib.rnn.GRUCell(128)  # RNN cell\r\n    if use_get_variable:\r\n        # Create variable with tf.get_variable\r\n        w = tf.get_variable('w', dtype='float32', initializer=tf.random_normal([128, 10]))\r\n    else:\r\n        # Create variable with tf.Variable\r\n        w = tf.Variable(initial_value=tf.random_normal([128, 10]), dtype='float32', name='w')\r\n    rnn_out, _ = tf.nn.dynamic_rnn(cell, x, dtype='float32', time_major=False)  # RNN\r\n    rnn_out = rnn_out[:, -1, :]  # Last timestep\r\n    rnn_out = tf.matmul(rnn_out, w)  # Output layer projection\r\n    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=rnn_out))  # Cross entropy\r\n    return loss_op\r\n\r\n\r\ndef inspect(use_get_variable=True, scope_optimizer=True, re_enter_scope=None, optimizer=tf.train.AdamOptimizer):\r\n    scope = 'scope'\r\n    if re_enter_scope:\r\n        with tf.variable_scope(scope) as variable_scope:  # Capture variable scope\r\n            if re_enter_scope == 'object':\r\n                # Save captured object for re-entering scope with captured variable scope object\r\n                scope = variable_scope\r\n            elif re_enter_scope == 'original_name_scope':\r\n                # Save original name scope of captured variable scope for re-entering the scope with original name scope\r\n                scope = variable_scope.original_name_scope\r\n    with tf.variable_scope(scope):  # (Re-)enter scope\r\n        loss_op = build_loss(use_get_variable=use_get_variable)\r\n        if scope_optimizer:\r\n            # Create optimizer in the variable scope\r\n            train_op = optimizer(0.1).minimize(loss_op)\r\n    if not scope_optimizer:\r\n        # Create optimizer outside of variable scope\r\n        train_op = optimizer(0.1).minimize(loss_op)\r\n    with tf.Session() as sess:\r\n        # Initialize variables\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n    description = 'optimizer ' + ('NOT' if not scope_optimizer else 'IS') + ' scoped, '\r\n    if not re_enter_scope:\r\n        description += 'using ORIGINAL scope, '\r\n    elif re_enter_scope == 'object':\r\n        description += 're-entering scope with OBJECT, '\r\n    elif re_enter_scope == 'original_name_scope':\r\n        description += 're-entering scope with ORIGINAL_NAME_SCOPE, '\r\n    description += 'variables created with ' + ('tf.get_variable' if use_get_variable else 'tf.Variable')\r\n    print(description)\r\n\r\n    print('\\n'.join(['  '+var.name for var in tf.global_variables()]))\r\n    print()\r\n\r\n    tf.reset_default_graph()\r\n\r\n\r\ndef main():\r\n    # Ideally scope everything with re-entered scope, leads to double scoping of gradient variables and having duplicate\r\n    # scope (with unique name) for Adam optimizer beta power variables\r\n    inspect(use_get_variable=True, scope_optimizer=True, re_enter_scope='object')\r\n    # Not scoping optimizer fixes double scoping of RNN variables but leads to having AdamOptimizer beta_powers not\r\n    # scoped\r\n    inspect(use_get_variable=True, scope_optimizer=False, re_enter_scope='object')\r\n    # Using tf.Variable for variable creation when re-entering scope with scope object leads to creation of duplicate\r\n    # scope (with unique name) for non-RNN variables\r\n    inspect(use_get_variable=False, scope_optimizer=False, re_enter_scope='object')\r\n    # Changing scope re-entering method to variable_scope.original_name_scope fixes the problem of duplicate scope\r\n    # when using tf.Variable for variable creation, but creates additional problem of having double slashes in\r\n    # scope hierarchy path with RNN variables.\r\n    inspect(use_get_variable=False, scope_optimizer=False, re_enter_scope='original_name_scope')\r\n    # Similar problem is observed when using tf.get_variable for variable creation and re-entering scope with\r\n    # original_name_scope but this time double slashes are observed also with non-RNN variables.\r\n    inspect(use_get_variable=True, scope_optimizer=False, re_enter_scope='original_name_scope')\r\n    # Scoping optimizer without re-entering the scope fixes scoping of Adam optimizer beta power variables but does not\r\n    # fix the problem of having double scopes for RNN variables. However re-entering scopes is desired for OOP.\r\n    inspect(use_get_variable=False, scope_optimizer=True, re_enter_scope=False)\r\n    # Using tf.get_variable for variable creation won't help since Optimizer creates variables with tf.Variable and RNN\r\n    # cells create variables with tf.get_variable, these two methods don't get along\r\n    inspect(use_get_variable=True, scope_optimizer=True, re_enter_scope=False)\r\n    # Swapping AdamOptimizer for RMSPropOptimizer fixes the problem with AdamOptimizer's beta power variables\r\n    inspect(use_get_variable=True, scope_optimizer=False, re_enter_scope='object', optimizer=tf.train.RMSPropOptimizer)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\noutputs\r\n```\r\noptimizer IS scoped, re-entering scope with OBJECT, variables created with tf.get_variable\r\n  scope/w:0\r\n  scope/rnn/gru_cell/gates/weights:0\r\n  scope/rnn/gru_cell/gates/biases:0\r\n  scope/rnn/gru_cell/candidate/weights:0\r\n  scope/rnn/gru_cell/candidate/biases:0\r\n  scope_1/beta1_power:0\r\n  scope_1/beta2_power:0\r\n  scope/scope/w/Adam:0\r\n  scope/scope/w/Adam_1:0\r\n  scope/scope/rnn/gru_cell/gates/weights/Adam:0\r\n  scope/scope/rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope/scope/rnn/gru_cell/gates/biases/Adam:0\r\n  scope/scope/rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope/scope/rnn/gru_cell/candidate/weights/Adam:0\r\n  scope/scope/rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope/scope/rnn/gru_cell/candidate/biases/Adam:0\r\n  scope/scope/rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer NOT scoped, re-entering scope with OBJECT, variables created with tf.get_variable\r\n  scope/w:0\r\n  scope/rnn/gru_cell/gates/weights:0\r\n  scope/rnn/gru_cell/gates/biases:0\r\n  scope/rnn/gru_cell/candidate/weights:0\r\n  scope/rnn/gru_cell/candidate/biases:0\r\n  beta1_power:0\r\n  beta2_power:0\r\n  scope/w/Adam:0\r\n  scope/w/Adam_1:0\r\n  scope/rnn/gru_cell/gates/weights/Adam:0\r\n  scope/rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope/rnn/gru_cell/gates/biases/Adam:0\r\n  scope/rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope/rnn/gru_cell/candidate/weights/Adam:0\r\n  scope/rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope/rnn/gru_cell/candidate/biases/Adam:0\r\n  scope/rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer NOT scoped, re-entering scope with OBJECT, variables created with tf.Variable\r\n  scope_1/w:0\r\n  scope/rnn/gru_cell/gates/weights:0\r\n  scope/rnn/gru_cell/gates/biases:0\r\n  scope/rnn/gru_cell/candidate/weights:0\r\n  scope/rnn/gru_cell/candidate/biases:0\r\n  beta1_power:0\r\n  beta2_power:0\r\n  scope_1/w/Adam:0\r\n  scope_1/w/Adam_1:0\r\n  scope/rnn/gru_cell/gates/weights/Adam:0\r\n  scope/rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope/rnn/gru_cell/gates/biases/Adam:0\r\n  scope/rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope/rnn/gru_cell/candidate/weights/Adam:0\r\n  scope/rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope/rnn/gru_cell/candidate/biases/Adam:0\r\n  scope/rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer NOT scoped, re-entering scope with ORIGINAL_NAME_SCOPE, variables created with tf.Variable\r\n  scope/w:0\r\n  scope//rnn/gru_cell/gates/weights:0\r\n  scope//rnn/gru_cell/gates/biases:0\r\n  scope//rnn/gru_cell/candidate/weights:0\r\n  scope//rnn/gru_cell/candidate/biases:0\r\n  beta1_power:0\r\n  beta2_power:0\r\n  scope/w/Adam:0\r\n  scope/w/Adam_1:0\r\n  scope//rnn/gru_cell/gates/weights/Adam:0\r\n  scope//rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope//rnn/gru_cell/gates/biases/Adam:0\r\n  scope//rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope//rnn/gru_cell/candidate/weights/Adam:0\r\n  scope//rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope//rnn/gru_cell/candidate/biases/Adam:0\r\n  scope//rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer NOT scoped, re-entering scope with ORIGINAL_NAME_SCOPE, variables created with tf.get_variable\r\n  scope//w:0\r\n  scope//rnn/gru_cell/gates/weights:0\r\n  scope//rnn/gru_cell/gates/biases:0\r\n  scope//rnn/gru_cell/candidate/weights:0\r\n  scope//rnn/gru_cell/candidate/biases:0\r\n  beta1_power:0\r\n  beta2_power:0\r\n  scope//w/Adam:0\r\n  scope//w/Adam_1:0\r\n  scope//rnn/gru_cell/gates/weights/Adam:0\r\n  scope//rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope//rnn/gru_cell/gates/biases/Adam:0\r\n  scope//rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope//rnn/gru_cell/candidate/weights/Adam:0\r\n  scope//rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope//rnn/gru_cell/candidate/biases/Adam:0\r\n  scope//rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer IS scoped, using ORIGINAL scope, variables created with tf.Variable\r\n  scope/w:0\r\n  scope/rnn/gru_cell/gates/weights:0\r\n  scope/rnn/gru_cell/gates/biases:0\r\n  scope/rnn/gru_cell/candidate/weights:0\r\n  scope/rnn/gru_cell/candidate/biases:0\r\n  scope/beta1_power:0\r\n  scope/beta2_power:0\r\n  scope/scope/w/Adam:0\r\n  scope/scope/w/Adam_1:0\r\n  scope/scope/rnn/gru_cell/gates/weights/Adam:0\r\n  scope/scope/rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope/scope/rnn/gru_cell/gates/biases/Adam:0\r\n  scope/scope/rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope/scope/rnn/gru_cell/candidate/weights/Adam:0\r\n  scope/scope/rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope/scope/rnn/gru_cell/candidate/biases/Adam:0\r\n  scope/scope/rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer IS scoped, using ORIGINAL scope, variables created with tf.get_variable\r\n  scope/w:0\r\n  scope/rnn/gru_cell/gates/weights:0\r\n  scope/rnn/gru_cell/gates/biases:0\r\n  scope/rnn/gru_cell/candidate/weights:0\r\n  scope/rnn/gru_cell/candidate/biases:0\r\n  scope/beta1_power:0\r\n  scope/beta2_power:0\r\n  scope/scope/w/Adam:0\r\n  scope/scope/w/Adam_1:0\r\n  scope/scope/rnn/gru_cell/gates/weights/Adam:0\r\n  scope/scope/rnn/gru_cell/gates/weights/Adam_1:0\r\n  scope/scope/rnn/gru_cell/gates/biases/Adam:0\r\n  scope/scope/rnn/gru_cell/gates/biases/Adam_1:0\r\n  scope/scope/rnn/gru_cell/candidate/weights/Adam:0\r\n  scope/scope/rnn/gru_cell/candidate/weights/Adam_1:0\r\n  scope/scope/rnn/gru_cell/candidate/biases/Adam:0\r\n  scope/scope/rnn/gru_cell/candidate/biases/Adam_1:0\r\n\r\noptimizer NOT scoped, re-entering scope with OBJECT, variables created with tf.get_variable\r\n  scope/w:0\r\n  scope/rnn/gru_cell/gates/weights:0\r\n  scope/rnn/gru_cell/gates/biases:0\r\n  scope/rnn/gru_cell/candidate/weights:0\r\n  scope/rnn/gru_cell/candidate/biases:0\r\n  scope/w/RMSProp:0\r\n  scope/w/RMSProp_1:0\r\n  scope/rnn/gru_cell/gates/weights/RMSProp:0\r\n  scope/rnn/gru_cell/gates/weights/RMSProp_1:0\r\n  scope/rnn/gru_cell/gates/biases/RMSProp:0\r\n  scope/rnn/gru_cell/gates/biases/RMSProp_1:0\r\n  scope/rnn/gru_cell/candidate/weights/RMSProp:0\r\n  scope/rnn/gru_cell/candidate/weights/RMSProp_1:0\r\n  scope/rnn/gru_cell/candidate/biases/RMSProp:0\r\n  scope/rnn/gru_cell/candidate/biases/RMSProp_1:0\r\n```\r\n\r\nWorkaround for clean scoping is to create optimizer op outside of the variable scope and using eg. `RMSPropOptimizer`. However this is confusing behaviour, ideally everything should be able to be scoped. Unfortunately there is nothing to get variable names clean when using `AdamOptimizer`. `AdamOptimizer` creates variables for beta powers with `tf.Variable`.\r\n\r\nAll of the mentioned problems would probably be fixed by using `tf.get_variable` everywhere. Until (and if) this change happens users should be instructed to use `tf.get_variable` only, creating optimizer outside of variable scope and avoid using `AdamOptimizer` if clean scoping is desired. Double scoping of RNN gradient variables would be tolerable but having several nested classes implementing different models with their own variable scopes lead to extremely messy variable names making debugging more difficult.\r\n\r\nTested on Ubuntu 16.04 with Tensorflow 1.0.0 installed with pip.\r\n\r\nRelated issues:\r\n#5786 \r\n#6189 \r\n#6007 \r\n", "comments": ["Does seem like the optimizers should be using tf.get_variable.  Lukasz,\nwdyt - can we do this in a backwards compatible way?\n\nOn Mon, Mar 6, 2017 at 9:28 AM, Paul Barham <notifications@github.com>\nwrote:\n\n> Assigned #8120 <https://github.com/tensorflow/tensorflow/issues/8120> to\n> @ebrevdo <https://github.com/ebrevdo>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8120#event-988133359>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9MW_ft7z-0H3BseF2uDzJz7YK4Wks5rjEIqgaJpZM4MUBsz>\n> .\n>\n", "Oh yes, optimizers should use get_variable. I think slot_creator already does (as you can see above, the big Adam and Adam_1 variables are already scoped correctly). But we missed the scalars (beta1_power beta2_power). It might apply only to Adam, but I don't see how we can be fully backwards-compatible here, since the goals is to change the name of the Variable. Eugene, do you see a way out? Can we break it? (Most people have optimizers in top-scope I think, they'll be fine, but some will be broken.)", "Summarizing outside discussions: We should not break people, but we are making a new optimizer with the correct behavior, and may deprecate Adam. \r\n\r\nCorrect me if I said something silly.", "@ebrevdo @lukaszkaiser feel free to close this issue if you think that is an appropriate resolution, once it's implemented.", "Looks like the right thing to do. Closing."]}, {"number": 8119, "title": ".", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": []}]