[{"number": 51242, "title": "TypeError: Input 'y' of 'Sub' Op has type int32 that does not match type float32 of argument 'x'.", "body": "**System information**\r\n- Have I written custom code: [posted below]\r\n- Done on Google Colab using TF 2.5\r\n\r\nI have done with building model but these some problem when training.  The errors are not clear enough I have no idea about which causes these errors.\r\n\r\nTraceback is:\r\n```\r\nEpoch 1/5\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476\r\n  return py_builtins.overload_of(f)(*args)\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-27-1b7e06547f26> in <module>()\r\n      1 history = MODEL.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,\r\n----> 2                     validation_split=0.1, verbose=2)\r\n\r\n9 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    984           except Exception as e:  # pylint:disable=broad-except\r\n    985             if hasattr(e, \"ag_error_metadata\"):\r\n--> 986               raise e.ag_error_metadata.to_exception(e)\r\n    987             else:\r\n    988               raise\r\n\r\nTypeError: in user code:\r\n\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:142 __call__  *\r\n        losses = call_fn(y_true, y_pred)\r\n    <ipython-input-25-f9adc600d49b>:7 call  *\r\n        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\r\n        raise e\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\r\n        return func(x, y, name=name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\r\n        return gen_math_ops.sub(x, y, name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10562 sub\r\n        \"Sub\", x=x, y=y, name=name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\r\n        inferred_from[input_arg.type_attr]))\r\n\r\n    TypeError: Input 'y' of 'Sub' Op has type int32 that does not match type float32 of argument 'x'.\r\n```\r\nLink to colab: https://colab.research.google.com/drive/1eRN8yxM4TyQ7JmO-hxjM76dIQz2_Hpga?usp=sharing\r\nLink to dataset: https://drive.google.com/file/d/1cVRPolctpCgcQontLDm8OmNHUMBM1KSp/view?usp=sharing\r\n\r\nPlease help me with fixing this bug.", "comments": ["Hi @tranduchuy682  \r\nIn the custom loss function that you are using y_pred is of data type tf.int32 whereas 0.5 is is tf,float32. To subtract two eager tensor both should be of same data type and hence you have to cast y_pred to float32 as well in  the regularizing parameter.", "@tranduchuy682 \r\n\r\nCould you please move this to closed status, if it is resolved.Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51242\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51242\">No</a>\n"]}, {"number": 51240, "title": "the calculation results of matmul OP are inconsistent", "body": "I was running the following code, the results were supposed to be the same but they did not.\r\n\r\n```python\r\ndef run_matmul_test():\r\n    a = tf.random.normal([2452,2992], dtype=tf.float16)\r\n    a_b = tf.random.normal([2992], dtype=tf.float16)\r\n\r\n    b = tf.random.normal([1, 2452], dtype=tf.float16)\r\n    c = tf.repeat(b, 8, 0)\r\n\r\n    out1_1 = tf.matmul(b, a)\r\n    out1 = tf.nn.bias_add(out1_1, a_b)\r\n\r\n    out2_1 = tf.matmul(c, a)\r\n    out2  = tf.nn.bias_add(out2_1, a_b)\r\n\r\n\r\n    with tf.Session() as sess:\r\n        a_out,b_out = sess.run([out1, out2])\r\n\r\n        print(a_out[0] - b_out[0])\r\n        print((a_out[0] - b_out[0]).max())\r\n        print((a_out - b_out[1]).max())\r\n        print((a_out - b_out[2]).max())\r\n        print((a_out - b_out[3]).max())\r\n```\r\n\r\nResult for 1 test run.\r\n\r\n```\r\n[-0.01563 -0.0742   0.1289  ... -0.1406  -0.0625   0.02344]\r\n0.625\r\n0.625\r\n0.625\r\n0.625\r\n```", "comments": ["@LeonardoPhysh  I tried to run your code on **`colab`** with **`TF v2.5`** and didn't get the error reported here.Please find the [gist](https://colab.research.google.com/gist/sushreebarsa/0bb85b609b5740755c20553eb45f58b2/untitled356.ipynb#scrollTo=j3gX_Z5kOpH2) for your reference .Thank you!", "\r\n\r\n\r\n> @LeonardoPhysh I tried to run your code on **`colab`** with **`TF v2.5`** and didn't get the error reported here.Please find the [gist](https://colab.research.google.com/gist/sushreebarsa/0bb85b609b5740755c20553eb45f58b2/untitled356.ipynb#scrollTo=j3gX_Z5kOpH2) for your reference .Thank you!\r\n\r\n@sushreebarsa I was running the above code on CPU with TF V1.15(sorry for missing the version info), and I checked with TF v2.5 and it has no error also. \r\n\r\nI also tested on GPU(also v1.15), It has no error on GPU\u3002", "@LeonardoPhysh Thank you for the update.Could you please let us know if the issue is resolved for you & please confirm if we can close the issue ? Thanks!", "@sushreebarsa Is it a known issue in TF v1.15? if it is, I think the issue can be closed.", "@LeonardoPhysh Thank you for the response .Closing this issue as it is resolved in latest version of TF 2.5. Thanks!", "Hi, thanks for bringing up this issue, can I know how this inconsistency bug is fixed? Maybe a related PR link can help?"]}, {"number": 51239, "title": "Make some of the private members of MicroInterpreter protected so derived classes can access them", "body": "I would like some of the members of the MicroInterpreter class to be protected rather than private as I would like to write a derived class that has access to the allocations with graph_. In the past we(Xmos) had a derived class of the MicroInterpreter that implemented timing hooks (function calls that profiled the execution time of each operator) by patching the registrations, maybe there is a better way of doing this? Thanks", "comments": ["sorry, was meant for micro"]}, {"number": 51238, "title": "In ResNet50, It is unequal to actual structure of library in the keras.applications.Resnet50", "body": "As you know, in the CNN, only layers of Convolution, BatchNormalization and Dense have weights. And Usually, they are constructed by this way. Input - Conv - BN - ReLU - Conv - BN - ReLU ... - Dense. But, As you can see, below the structure remain unusual.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/83423286/128308372-357e542a-7197-46cc-9fce-536c7331bdce.png)\r\n\r\n\r\n```\r\nconv2_block1_0_conv/kernel:0\r\nconv2_block1_0_conv/bias:0\r\nconv2_block1_3_conv/kernel:0\r\nconv2_block1_3_conv/bias:0\r\nconv2_block1_1_bn/gamma:0\r\nconv2_block1_1_bn/beta:0\r\nconv2_block1_1_bn/moving_mean:0\r\nconv2_block1_1_bn/moving_variance:0\r\nconv2_block1_3_bn/gamma:0\r\nconv2_block1_3_bn/beta:0\r\nconv2_block1_3_bn/moving_mean:0\r\nconv2_block1_3_bn/moving_variance:0\r\n```\r\nYou can find this result by:\r\n\r\n```\r\nmodel = tf.keras.application.ResNet50()\r\n#The unusual phenomenon begins with index 18.\r\nmodel.weights[18]\r\n```\r\n_I recommend that you use debugging mode in your IDE. Then you'll find it easier._\r\n\r\nIn the below lines, the ResNet50 has stack_fn function for creating layers\r\n\r\n```\r\ndef ResNet50():\r\n.\r\n.\r\n  def stack_fn(x):\r\n    x = stack1(x, 64, 3, stride1=1, name='conv2')\r\n    x = stack1(x, 128, 4, name='conv3')\r\n    x = stack1(x, 256, 6, name='conv4')\r\n    return stack1(x, 512, 3, name='conv5')\r\n.\r\n.\r\n\r\n```\r\nIn the below codes, the stack1 is for simplifying repeated residential blocks.\r\n\r\n```\r\ndef stack1(x, filters, blocks, stride1=2, name=None):\r\n\r\n\r\n  x = block1(x, filters, stride=stride1, name=name + '_block1')\r\n  for i in range(2, blocks + 1):\r\n    x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\r\n  return x\r\n```\r\n\r\nIn the below structure, the block1 is Residential layers in ResNet50.\r\n\r\n```\r\ndef block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\r\n\r\n  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\r\n\r\n  if conv_shortcut:\r\n    shortcut = layers.Conv2D(\r\n        4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\r\n    shortcut = layers.BatchNormalization(\r\n        axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut) \r\n  else:\r\n    shortcut = x\r\n\r\n  x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\r\n  x = layers.BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_1_relu')(x)\r\n\r\n  x = layers.Conv2D(\r\n      filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\r\n  x = layers.BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_2_relu')(x)\r\n\r\n  x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\r\n  x = layers.BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\r\n\r\n  x = layers.Add(name=name + '_add')([shortcut, x]) \r\n  x = layers.Activation('relu', name=name + '_out')(x)\r\n  return x\r\n```\r\nMy problem is why are the model instance different from the actual structures?", "comments": ["@ahyunsoo2 \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "As I got this answer, and I leave [it](https://stackoverflow.com/questions/68629607/in-keras-the-resnet50-has-a-strange-pattern).\r\n\r\n\r\n@Saduf2019 \r\nNext, I will do so in this case about _keras_.\r\n\r\nThank you for guiding me."]}, {"number": 51237, "title": "Training weak learners in using video or image dataset on TensorFlow", "body": "Hi I have a problem statement where I have to train an action recognizer using videos.\r\nbut due to non availability of good dataset there is a slight misclassification.\r\nIs there any setting or function where I can train the misclassified or weak learners by assigning them more weights.\r\nIts sounds similar like Xgboost but I want something which can work on Deeplearning frame works and on Image and Video data set\r\n\r\nThanks.", "comments": ["@Srkshaikh5 Can you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51237\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51237\">No</a>\n"]}, {"number": 51236, "title": "How can I use multi_gpu in tf.keras?", "body": "How can I use multi_gpu in tf.keras?\r\nWARNING:tensorflow:From train_conv.py:214: multi_gpu_model (from tensorflow.python.keras.utils.multi_gpu_utils) is deprecated and will be removed after 2020-04-01.", "comments": ["@llfzllfz Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51235, "title": "[TF:TRT] Reorganize testing utilities.", "body": "Creates TF-TRT \"testutils\" library and replaces some utility functions with gMock matchers. Renames GetTestDims to CreateDims. Adds ostream<< printers for nvinfer1 types. Replaces \"const char*\" usage in test fixtures with \"std::string\" types.\r\nMoves two std::vector templated utility functions `InitTestVector` and `CastTestVector` to `trt_testutils.h` from `convert_nodes_test.cc`, and renamed to `CreateVectorIota` and `CastVector` respectively.", "comments": ["@tfeher ", "@bixia1 Can you help review? Thanks", "Thanks for this PR @christopherbate, it is nice to see some clean up in the test routines! In an offline discussion you have mentioned that \"replacing ExpectsX functions with GMock matchers eliminates indirection in the test error result so the test error reports the actual failing line in the test [...] and correctly prints the nvinfer types.\" Could you update the PR description to include this information?", "@bixia1,\r\nUpdated based on your comments, and fixed a subtle issue with the TRT_ShapedWeights gMock matcher. Tests look good to go on my end.\r\nI have a follow on PR for additional test refactoring which I'm about to create. I can either create a new PR or append to this one? Thanks.", "@christopherbate Please create another PR. It is preferable to have small PRs.", "@bixia1 I applied your asks/recommendations.", "> Would you please also do these before I will approve the PR:\r\n> (1) squash the commits into one commit. This is because we don't want the commit history for this PR to show in the final change, to simplify the commit message for the change.\r\n> (2) Would you please revise/simplify your PR description, such as removing \"Added (8/10)\" etc? This is because the PR description will become part of commit message, and we only want to keep the description about the final code change in the PR.\r\n\r\nWill do, thanks", "@bixia1 Can you please take a look on above comments from @christopherbate. Thanks!", "@gbaned I am still waiting for @christopherbate to address https://github.com/tensorflow/tensorflow/pull/51235#issuecomment-899784046", "@bixia1 done!", "@christopherbate Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned I applied the buildifier recommended changes.", "Rebased on master ", "@bixia1 @gbaned Please merge these queued dynamic shape support PRs first, then I will rebase this if required:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/51468\r\nhttps://github.com/tensorflow/tensorflow/pull/51462\r\n", "> @bixia1 @gbaned Please merge these queued dynamic shape support PRs first, then I will rebase this if required:\r\n> \r\n> #51468\r\n> #51462\r\n\r\nThese are merged, and it looks like there are no conflicts", "I applied the change", "@bixia1 I added the suggested change for the empty dims `DimsAreArray({})`"]}, {"number": 51233, "title": "tensorflow saved model to tf dialect mlir", "body": "May I know command available in tensorflow to convert saved_model.pb to model_tf_dialect.mlir?\r\n\r\n\r\nThanks\r\n", "comments": ["@ArunaKote Could you please have a look on the [link ](https://www.tensorflow.org/guide/saved_model)and let us know if it helps? Thanks!", "Thank You .But this link does not show about getting tf dialect(mlir).I tried tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate --savedmodel-objectgraph-to-mlir --tf-savedmodel-exported-names=saved_model /path/to/savedmodel -o out.mlir using this I am getting tf dialect but it is encapsulated with tf.excutor .it also contains  %72 = \"tf.PartitionedCall\"(%71) {_collective_manager_ids = [], _read_only_resource_inputs = [], config = \"\", config_proto = \"\\0A\\07\\0A\\03CPU\\10\\01\\0A\\07\\0A\\03GPU\\10\\002\\02J\\008\\01\\82\\01\\00\", device = \"\", executor_type = \"\", f = @__inference_conv3_block4_1_relu_layer_call_and_return_conditional_losses_127420} : (tensor<*xf32>) -> tensor<*xf32>\r\n\r\nand is not exactly  in the tf dialect form. May I know If I am doing any mistake in command line options?\r\n\r\n\r\nThanks.", "Have you tried [tf.mlir.experimental.convert_graph_def()](https://www.tensorflow.org/api_docs/python/tf/mlir/experimental/convert_graph_def) for your case?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51233\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51233\">No</a>\n"]}, {"number": 51232, "title": "Add remaining missing validation to `BoostedTreesCalculateBestFeature\u2026", "body": "\u2026Split`\r\n\r\nPiperOrigin-RevId: 387423006\r\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443", "comments": []}, {"number": 51231, "title": "Add remaining missing validation to `BoostedTreesCalculateBestFeature\u2026", "body": "\u2026Split`\r\n\r\nPiperOrigin-RevId: 387423006\r\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443", "comments": []}, {"number": 51230, "title": "Add remaining missing validation to `BoostedTreesCalculateBestFeature\u2026", "body": "\u2026Split`\r\n\r\nPiperOrigin-RevId: 387423006\r\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443", "comments": []}, {"number": 51229, "title": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStrea\u2026", "body": "\u2026mResource\r\n\r\nPiperOrigin-RevId: 387452765\r\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495", "comments": []}, {"number": 51228, "title": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStrea\u2026", "body": "\u2026mResource\r\n\r\nPiperOrigin-RevId: 387452765\r\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495", "comments": []}, {"number": 51227, "title": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStrea\u2026", "body": "\u2026mResource\r\n\r\nPiperOrigin-RevId: 387452765\r\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495", "comments": []}, {"number": 51226, "title": "No performance improvement when I change prefetch() to prefetch_to_device()", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos \r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): devtools gcc 9.3.0\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory:  single card 40536MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\nbash: v1.15.4-830-g656e13f8ba: command not found(custom version)\r\n\r\nI decode the features in the CPU and run the model in the GPU, so I need to synchronize the movement of the features from the CPU to the GPU. I found from the timeline that it took a long time to move the features. like:\r\n![image](https://user-images.githubusercontent.com/33950866/128280087-279bb510-73f5-431b-8474-3935083a52bf.png)\r\n\r\n so, I would like to async memcpyH2D features by ```prefetch_to_device```, then I get a new timeline:\r\n![image](https://user-images.githubusercontent.com/33950866/128280627-469e6a7b-b1a1-4a5b-b879-bb0aa26b7373.png)\r\n\r\nFrom the timeline point of view, I expect to improve performance by more than 30%.\r\nI successfully async memcpyH2D, but global_steps/s is same as sync memcpyH2D. I have no idea about this. please help~\r\n", "comments": ["@zhaozheng09 We see that you are using older version of tensorflow 1.15 which is officially considered as end of life, We recommend that you upgrade to latest stable version of TF(2.5) and let us know if the issue still persists in newer versions .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51225, "title": "Fix FPE in inpace update ops.", "body": "PiperOrigin-RevId: 388303197\r\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83", "comments": []}, {"number": 51224, "title": "Fix FPE in inpace update ops.", "body": "PiperOrigin-RevId: 388303197\r\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83", "comments": []}, {"number": 51223, "title": "Fix FPE in inpace update ops.", "body": "PiperOrigin-RevId: 388303197\r\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83", "comments": []}, {"number": 51222, "title": "Fix FPE in inpace update ops.", "body": "PiperOrigin-RevId: 388303197\r\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83", "comments": []}, {"number": 51221, "title": "Fix nullptr deref and heap OOB access in binary cwise ops.", "body": "PiperOrigin-RevId: 387936777\r\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f", "comments": []}, {"number": 51220, "title": "Fix nullptr deref and heap OOB access in binary cwise ops.", "body": "PiperOrigin-RevId: 387936777\r\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f", "comments": []}, {"number": 51219, "title": "Fix nullptr deref and heap OOB access in binary cwise ops.", "body": "PiperOrigin-RevId: 387936777\r\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f", "comments": []}, {"number": 51218, "title": "Add one missing valdiation to `matrix_set_diag_op.cc`", "body": "PiperOrigin-RevId: 387923408\r\nChange-Id: If6a97b9098c13879400f56c22f91555cdf0ce5d7", "comments": []}, {"number": 51217, "title": "Add one missing valdiation to `matrix_set_diag_op.cc`", "body": "PiperOrigin-RevId: 387923408\r\nChange-Id: If6a97b9098c13879400f56c22f91555cdf0ce5d7", "comments": []}, {"number": 51216, "title": "Add one missing valdiation to `matrix_set_diag_op.cc`", "body": "PiperOrigin-RevId: 387923408\r\nChange-Id: If6a97b9098c13879400f56c22f91555cdf0ce5d7", "comments": []}, {"number": 51215, "title": "Add missing validation to `matrix_diag_op.cc`", "body": "PiperOrigin-RevId: 387923533\r\nChange-Id: Idfffeb328d5f9c6748d992d28a56d6e9e45103a0", "comments": []}, {"number": 51214, "title": "Add missing validation to `matrix_diag_op.cc`", "body": "PiperOrigin-RevId: 387923533\r\nChange-Id: Idfffeb328d5f9c6748d992d28a56d6e9e45103a0", "comments": []}, {"number": 51213, "title": "Add missing validation to `matrix_diag_op.cc`", "body": "PiperOrigin-RevId: 387923533\r\nChange-Id: Idfffeb328d5f9c6748d992d28a56d6e9e45103a0", "comments": []}, {"number": 51212, "title": "Add missing validation to `RaggedTensorToSparse`.", "body": "There needs to be a check that the splits allow for valid ragged tensors.\r\n\r\nPiperOrigin-RevId: 387712169\r\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d", "comments": []}, {"number": 51211, "title": "Add missing validation to `RaggedTensorToSparse`.", "body": "There needs to be a check that the splits allow for valid ragged tensors.\r\n\r\nPiperOrigin-RevId: 387712169\r\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d", "comments": []}]