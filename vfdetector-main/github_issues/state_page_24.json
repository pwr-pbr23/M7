[{"number": 50797, "title": "Documented and more fine grained XLA auto-clustering flags in ConfigProto", "body": "**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it: Probably not\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, to enable XLA auto-clustering, you have to either use global configuration flags (`TF_XLA_FLAGS`) or `config.proto` options.  However, several options from the global flags are missing from `config.proto`, most importantly to do it on CPU (`--tf_xla_cpu_global_jit`), but also including debug settings.\r\n\r\nI would like the option to set all relevant XLA options (but especially to enable it on CPU) in `config.proto` in addition to the global settings.  It avoids forcing global (JVM-wide in this case) configuration and allows setting it from code.\r\n\r\n\r\n**Will this change the current api? How?**\r\nIt will add properties to `config.proto`.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone wanting to use XLA auto-clustering programmatically.  The motivating use case was for Graphs in tensorflow/java.\r\n", "comments": []}, {"number": 50796, "title": "ResourceVariable GC bug", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.5.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing): Fix ResourceVariable gc bug when it works with tf.cond \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow_addons.utils import types\r\nfrom typeguard import typechecked\r\n\r\n\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.set_logical_device_configuration(\r\n    physical_devices[0],\r\n    [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\r\n    tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\r\nl_devices = tf.config.list_logical_devices('GPU')\r\n\r\n@tf.keras.utils.register_keras_serializable(package=\"Addons\")\r\nclass GradientAccumulator(tf.keras.optimizers.Optimizer):\r\n    \"\"\"Optimizer wrapper for gradient accumulation.\"\"\"\r\n\r\n    @typechecked\r\n    def __init__(\r\n        self,\r\n        optimizer: types.Optimizer,\r\n        accum_steps: types.TensorLike = 4,\r\n        name: str = \"GradientAccumulator\",\r\n        **kwargs,\r\n    ):\r\n        r\"\"\"Construct a new GradientAccumulator optimizer.\r\n\r\n        Args:\r\n            optimizer: str or `tf.keras.optimizers.Optimizer` that will be\r\n                used to compute and apply gradients.\r\n            accum_steps: int > 0. Update gradient in every accumulation steps.\r\n            name: Optional name for the operations created when applying\r\n                gradients. Defaults to \"GradientAccumulator\".\r\n            **kwargs: keyword arguments. Allowed to be {`clipnorm`,\r\n                `clipvalue`, `lr`, `decay`}. `clipnorm` is clip gradients by\r\n                norm; `clipvalue` is clip gradients by value, `decay` is\r\n                included for backward compatibility to allow time inverse\r\n                decay of learning rate. `lr` is included for backward\r\n                compatibility, recommended to use `learning_rate` instead.\r\n        \"\"\"\r\n        super().__init__(name, **kwargs)\r\n        self._optimizer = tf.keras.optimizers.get(optimizer)\r\n        self._gradients = []\r\n        self._accum_steps = accum_steps\r\n\r\n    def _create_slots(self, var_list):\r\n        self._optimizer._create_slots(var_list=var_list)\r\n        for var in var_list:\r\n            self.add_slot(var, \"ga\")\r\n\r\n        self._gradients = [self.get_slot(var, \"ga\") for var in var_list]\r\n\r\n    @property\r\n    def gradients(self):\r\n        \"\"\"The accumulated gradients on the current replica.\"\"\"\r\n        if not self._gradients:\r\n            raise ValueError(\r\n                \"The accumulator should be called first to initialize the gradients\"\r\n            )\r\n        return list(\r\n            gradient.read_value() if gradient is not None else gradient\r\n            for gradient in self._gradients\r\n        )\r\n\r\n    def apply_gradients(self, grads_and_vars, name=None, **kwargs):\r\n        self._optimizer._iterations = self.iterations\r\n        return super().apply_gradients(grads_and_vars, name, **kwargs)\r\n\r\n    def _resource_apply_dense(self, grad, var, apply_state=None):\r\n        accum_gradient = self.get_slot(var, \"ga\")\r\n        if accum_gradient is not None and grad is not None:\r\n            accum_gradient.assign_add(\r\n                grad, use_locking=self._use_locking, read_value=False\r\n            )\r\n\r\n        def _apply():\r\n            if \"apply_state\" in self._optimizer._dense_apply_args:\r\n                train_op = self._optimizer._resource_apply_dense(\r\n                    accum_gradient.read_value(), var, apply_state=apply_state\r\n                )\r\n            else:\r\n                train_op = self._optimizer._resource_apply_dense(\r\n                    accum_gradient.read_value(), var\r\n                )\r\n            reset_op = accum_gradient.assign(\r\n                tf.zeros_like(accum_gradient),\r\n                use_locking=self._use_locking,\r\n                read_value=False,\r\n            )\r\n            return tf.group(train_op, reset_op)\r\n\r\n        apply_op = tf.cond(\r\n            (self.iterations+1) % self._accum_steps == 0, _apply, lambda: tf.no_op()\r\n        )\r\n        return apply_op\r\n\r\n    def _resource_apply_sparse(self, grad: types.TensorLike, var, indices, apply_state):\r\n        accum_gradient = self.get_slot(var, \"ga\")\r\n        if accum_gradient is not None and grad is not None:\r\n            self._resource_scatter_add(accum_gradient, indices, grad)\r\n\r\n        def _apply():\r\n            if \"apply_state\" in self._optimizer._sparse_apply_args:\r\n                train_op = self._optimizer._resource_apply_sparse(\r\n                    accum_gradient.sparse_read(indices),\r\n                    var,\r\n                    indices,\r\n                    apply_state=apply_state,\r\n                )\r\n            else:\r\n                train_op = self._optimizer._resource_apply_sparse(\r\n                    accum_gradient.sparse_read(indices), var, indices\r\n                )\r\n            reset_op = accum_gradient.assign(\r\n                tf.zeros_like(accum_gradient),\r\n                use_locking=self._use_locking,\r\n                read_value=False,\r\n            )\r\n            return tf.group(train_op, reset_op)\r\n\r\n        apply_op = tf.cond(\r\n            (self.iterations+1) % self._accum_steps == 0, _apply, lambda: tf.no_op()\r\n        )\r\n        return apply_op\r\n\r\n    def reset(self):\r\n        \"\"\"Resets the accumulated gradients on the current replica.\"\"\"\r\n        assign_ops = []\r\n        if not self._gradients:\r\n            return assign_ops\r\n\r\n        for gradient in self._gradients:\r\n            if gradient is not None:\r\n                assign_ops.append(\r\n                    gradient.assign(\r\n                        tf.zeros_like(gradient),\r\n                        use_locking=self._use_locking,\r\n                        read_value=False,\r\n                    )\r\n                )\r\n\r\n        return tf.group(assign_ops)\r\n\r\n    @property\r\n    def lr(self):\r\n        return self._optimizer._get_hyper(\"learning_rate\")\r\n\r\n    @lr.setter\r\n    def lr(self, lr):\r\n        self._optimizer._set_hyper(\"learning_rate\", lr)  #\r\n\r\n    @property\r\n    def learning_rate(self):\r\n        return self._optimizer._get_hyper(\"learning_rate\")\r\n\r\n    @learning_rate.setter\r\n    def learning_rate(self, learning_rate):\r\n        self._optimizer._set_hyper(\"learning_rate\", learning_rate)\r\n\r\n    def get_config(self):\r\n        config = {\r\n            \"accum_steps\": self._accum_steps,\r\n            \"optimizer\": tf.keras.optimizers.serialize(self._optimizer),\r\n        }\r\n        base_config = super().get_config()\r\n        return {**base_config, **config}\r\n\r\n    @classmethod\r\n    def from_config(cls, config, custom_objects=None):\r\n        optimizer = tf.keras.optimizers.deserialize(\r\n            config.pop(\"optimizer\"), custom_objects=custom_objects\r\n        )\r\n        return cls(optimizer, **config)\r\n\r\n\r\ndef main():\r\n    for precision_policy in ['mixed_float16']:\r\n        print('#' * 72)\r\n        print(f'Setting precision-policy to \"{precision_policy}\"')\r\n\r\n        tf.keras.mixed_precision.set_global_policy(precision_policy)\r\n        strategy = tf.distribute.MirroredStrategy(devices=l_devices)\r\n\r\n        with strategy.scope():\r\n            mnist = tf.keras.datasets.mnist\r\n\r\n            (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n            x_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\n            model = tf.keras.models.Sequential([\r\n                tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n                tf.keras.layers.Dense(128, activation='relu'),\r\n                tf.keras.layers.Dropout(0.2),\r\n                tf.keras.layers.Dense(10)\r\n            ])\r\n\r\n            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n            model.compile(optimizer=GradientAccumulator(tf.keras.optimizers.Adam()),\r\n                          loss=loss_fn,\r\n                          metrics=['accuracy'])\r\n            model.fit(x_train, y_train, epochs=5)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\n2021-07-16 09:15:20.111909: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n   2/1875 [..............................] - ETA: 8:34 - loss: 2.3555 - accuracy: 0.1406   Traceback (most recent call last):\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-42bda5d10b07>\", line 3, in <module>\r\n    runfile('/media/fangsixie/data/automl/efficientdet/mAP.py', wdir='/media/fangsixie/data/automl/efficientdet')\r\n  File \"/media/fangsixie/data/pycharm-2019.3/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"/media/fangsixie/data/pycharm-2019.3/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/media/fangsixie/data/automl/efficientdet/mAP.py\", line 218, in <module>\r\n    main()\r\n  File \"/media/fangsixie/data/automl/efficientdet/mAP.py\", line 214, in main\r\n    model.fit(x_train, y_train, epochs=5)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3024, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1961, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 596, in call\r\n    ctx=ctx)\r\n  File \"/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: 3 root error(s) found.\r\n  (0) Failed precondition:  Could not find variable _AnonymousVar58. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar58/N10tensorflow3VarE does not exist.\r\n\t [[{{node cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/then/_200/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/Cast/ReadVariableOp}}]]\r\n\t [[cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update_1/update_1/add/_86]]\r\n  (1) Failed precondition:  Could not find variable _AnonymousVar58. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar58/N10tensorflow3VarE does not exist.\r\n\t [[{{node cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/then/_200/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/Cast/ReadVariableOp}}]]\r\n\t [[cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update_2/update_1/mod/_100]]\r\n  (2) Failed precondition:  Could not find variable _AnonymousVar58. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar58/N10tensorflow3VarE does not exist.\r\n\t [[{{node cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/then/_200/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/Cast/ReadVariableOp}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_3163]\r\nFunction call stack:\r\ntrain_function -> train_function -> train_function\r\n\r\n```\r\nChange (self.iterations+1) to self.iterations fix the bug.\r\n", "comments": ["@ymodak ,\r\nI was able to reproduce the issue in tf v2.4,2.5 and nightly.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/f4e3adeb5ecfc3647128c6e121ab3e68/untitled50796.ipynb).", "@fsx950223 thanks for finding this.  We will gladly welcome a fix."]}, {"number": 50790, "title": "Out of memory when using MultiWorkerMirroredStrategy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): REHEL 7.9\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): 3.7.1\r\n- GCC/Compiler version (if compiling from source): 8.3.0\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: GTX 1080Ti\r\n\r\n**Describe the current behavior**\r\n\r\nWhen running a trivial example TF starts allocation gigabytes of memory continously until it runs out of memory.\r\nThis does only happen when running on more than 2 nodes, not when running on only 1 or 2 nodes and it happens in the creation of MultiWorkerMirroredStrategy\r\nI can also start e.g. 6 tasks on 2 nodes (3 tasks each) without problems, but 3 tasks on 3 nodes (1 task each) does not work\r\n\r\nI also observed that it happens only one 1 of the ranks used, the other workers are fine and waiting for that one to finish init (I suppose)\r\n\r\n**Describe the expected behavior**\r\n\r\nIt works or a reasonable error.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom mpi_cluster_resolver import MPIClusterResolver\r\n\r\nresolver = MPIClusterResolver()\r\nstrategy = tf.distribute.MultiWorkerMirroredStrategy(cluster_resolver=resolver)\r\n```\r\n\r\nWith \r\n[mpi_cluster_resolver.py.txt](https://github.com/tensorflow/tensorflow/files/6823734/mpi_cluster_resolver.py.txt)\r\n\r\nThis is so that running distributed TF is possible via SLURM/MPI on HPC clusters", "comments": ["Same happens with 2.5.0", "Thanks for the report @Flamefire - does this only happen when using a `MPIClusterResolver` or it happens in general with `MultiWorkerMirroredStrategy`, regardless of the cluster resolver being used?", "Can you help me test this with another cluster resolver? Not sure how to do that as creating that class was required to make it run on our HPC system. Guess something about env vars?\r\n\r\nCould also be related to CUDA versions:\r\n- OOM: GeForce GTX 1080 TI, CUDA 11.0, 450.36.06\r\n- No OOM: A100, CUDA 11.2, 460.32.03\r\n\r\nRest of the software stack is virtually the same. Having other problems on the A100s though during shutdown of TF (force terminating due to something with Python threads and TF cleanup)", "Interesting, so using some CUDA version completely prevents the code from going OOM?", "It might be related at least, yes. However as this is a different cluster (different hardware) it might as well have other reasons. Only the software stack is the same as much as possible.\r\nIt is also strange that using only 2 nodes does not cause the issue, but 3 do. The working cluster has (much) more main memory, so maybe it will happen later there too. But that is speculation", "Ok, setting (via Python `os.environ`) the TF_CONFIG variables as follows (4 ranks):\r\n\r\n```\r\nSet TF_CONFIG={\"cluster\": {\"worker\": [\"taurusa10:8888\", \"taurusa11:8888\", \"taurusa8:8888\", \"taurusa9:8888\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}, \"rpc_layer\": \"grpc\"}\r\nSet TF_CONFIG={\"cluster\": {\"worker\": [\"taurusa10:8888\", \"taurusa11:8888\", \"taurusa8:8888\", \"taurusa9:8888\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}, \"rpc_layer\": \"grpc\"}\r\nSet TF_CONFIG={\"cluster\": {\"worker\": [\"taurusa10:8888\", \"taurusa11:8888\", \"taurusa8:8888\", \"taurusa9:8888\"]}, \"task\": {\"type\": \"worker\", \"index\": 3}, \"rpc_layer\": \"grpc\"}\r\nSet TF_CONFIG={\"cluster\": {\"worker\": [\"taurusa10:8888\", \"taurusa11:8888\", \"taurusa8:8888\", \"taurusa9:8888\"]}, \"task\": {\"type\": \"worker\", \"index\": 2}, \"rpc_layer\": \"grpc\"}\r\n```\r\n\r\nSame: OOM. Does this look wrong anyhow?", "Can't spot anything wrong as far as I can tell.", "Same problem"]}, {"number": 50786, "title": "[TFLite] Add int8 and int16x8 support for the ROUND operator", "body": "Hi,\r\n\r\nThis PR adds int16x8 support for the ROUND operator in TensorFlow Lite.\r\n\r\nThere is a restriction on the inputs: they need to have the quantization scale <= 1.0f. This is necessary, along with the output quantization scale = 1.0f and zero-point = 0. These requirements support rounding of a value, converting it directly from a quantization mode to another.\r\n\r\nEddie", "comments": ["@georgeedward2000  Can you please resolve conflicts? Thanks!", "@gbaned I solved the conflicts. Thanks!", "Hi @georgeedward2000 ,\r\n\r\nThanks for PR and really sorry for delayed review. Adding @renjie-liu for more wisdom.\r\n\r\nCan you explain what use cases are you trying to enable with this? To check the input scale during the quantization, I think there should be fixes in the quantizers (both legacy and the new MLIR one). The quantized kernel has limited use case, and not sure if we can allow the quantizer to quantize the round op by default.\r\n\r\nIf others agree, here are additional changes I suggest:\r\n\r\n1. Add ` FixedOutputRangeInterface` and corresponding extra class declaration to `TFL_RoundOp` accordingly, and remove `NoQuantizableResult` trait. This has a downside that the range would be fixed to certain zero point. (e.g. -127~128, or 0~255).\r\n2. You'd also need to come up with a logic that checks input's scale < 1.0f for round ops. Bad news is that the 16x8 quantization still relies on old quantizer, while int8 quantization works with the new quantizer by default, so you'd need to modify both.\r\n\r\n", "Hi @teijeong \r\n\r\nEven though a floating-point rounding operator isn't too costly in itself, it's problematic on hardware that doesn't have a a floating-point unit. Without quantized support for the rounding we have to either emulate the floating-point operations (dequantize, round, quantize) or transfer the data to a unit that natively supports floating-point. Having a quantized rounding would allow us to avoid the dequantize/quantize nodes and have a fully integer model for the ones that have a rounding operation.\r\n\r\nLooking a bit more though, we could support input scales > 1.0 by setting the output scale to `output_scale = ceil(input_scale)` and keep the output zero-point to the same value as the input zero-point. We would lose some precision though for input scales > 1.0 (it should be a really rare occurrence for int16 inputs).\r\n\r\nI checked the MLIR quantizer but there doesn't seem to be an easy way to do that currently. I will need to check a bit more how we could implement that but any insight is welcome. Note that we could start by only adding 8-bit supports and add 16-bit once the MLIR quantizer supports 16-bit.", "@teijeong Can you please review this PR ? Thanks!", "@georgeedward2000 Can you please resolve conflicts? Thanks!", "@georgeedward2000 Can you please resolve conflicts? Thank you!"]}, {"number": 50776, "title": "MKL XLA CPU Runtime Test Failure", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen MKL is enabled, the `tensorflow/compiler/xla/service/cpu:cpu_runtime_test` unit test fails while attempting to load the  [third_party/intel_mkl_ml/include/mkl_cblas.h](https://github.com/tensorflow/tensorflow/blob/81b2bcb9ba3316759a08db614bd76d572a1cb320/tensorflow/compiler/xla/service/cpu/runtime_matmul_mkl.h#L22) header file.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`bazel test --config=mkl //tensorflow/compiler/xla/service/cpu:cpu_runtime_test`\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nERROR: /opt/tensorflow/tensorflow-source/tensorflow/compiler/xla/service/cpu/BUILD:858:11: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu:cpu_runtime_test' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/cpu_runtime_test/cpu_runtime_test.d ... (remaining 390 argument(s) skipped)\r\ncc1plus: warning: command line option \u2018-Wno-pointer-sign\u2019 is valid for C/ObjC but not for C++\r\nIn file included from tensorflow/compiler/xla/service/cpu/cpu_runtime_test.cc:28:\r\n./tensorflow/compiler/xla/service/cpu/runtime_matmul_mkl.h:22:10: fatal error: third_party/intel_mkl_ml/include/mkl_cblas.h: No such file or directory\r\n   22 | #include \"third_party/intel_mkl_ml/include/mkl_cblas.h\"\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n```\r\n", "comments": []}, {"number": 50774, "title": "tf.keras.models.save_model not saving the probabilistic_model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Tensorflow_probability.__version__:  '0.13.0'\r\n- Python version: 3.8.10\r\n- CUDA/cuDNN version: cuda_11.2.r11.2/compiler.29373293_0 \r\n- GPU model and memory: 12Gb TitanXP\r\n\r\n**Describe the current behavior**\r\nTensorflow model with tensorflow_probability layers creates errors while saving using \r\n\r\n** The model is created using the below code**\r\n`\r\n_model = Sequential([\r\n        Conv2D(8, 5, activation='relu', padding='valid', input_shape=input_shape),\r\n        MaxPooling2D(6),\r\n        Flatten(),\r\n        Dense(10),\r\n        tfpl.OneHotCategorical(10)\r\n    ])\r\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n\r\nprobabilistic_model = get_probabilistic_model(\r\n    input_shape=(28, 28, 1), \r\n    loss=nll, \r\n    optimizer=RMSprop(), \r\n    metrics=['accuracy']\r\n\r\nprobabilistic_model.fit(x_train, y_train_oh, epochs=5)\r\n\r\n_\r\n`\r\n\r\n![probabilistic_model_summary](https://user-images.githubusercontent.com/70491128/125684752-f0aaec59-e4a3-45a6-8acd-dfdd5589851d.png)\r\n\r\n**For saving the model**\r\n`_probabilistic_model.save('/tmp/model/probabilistic_model')_\r\n`\r\nThe saving steps create the error as shown below.\r\n\r\n`\r\n_OperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n/tmp/ipykernel_11377/1109926494.py in <module>\r\n----> 1 probabilistic_model.save('/tmp/model/probabilistic_model')\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\r\n   2109     \"\"\"\r\n   2110     # pylint: enable=line-too-long\r\n-> 2111     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n   2112                     signatures, options, save_traces)\r\n   2113 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\r\n    148   else:\r\n    149     with generic_utils.SharedObjectSavingScope():\r\n--> 150       saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n    151                             signatures, options, save_traces)\r\n    152 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\r\n     87   with K.deprecated_internal_learning_phase_scope(0):\r\n     88     with utils.keras_option_scope(save_traces):\r\n---> 89       saved_nodes, node_paths = save_lib.save_and_return_nodes(\r\n     90           model, filepath, signatures, options)\r\n     91 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in save_and_return_nodes(obj, export_dir, signatures, options, raise_metadata_warning, experimental_skip_checkpoint)\r\n   1101 \r\n   1102   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\r\n-> 1103       _build_meta_graph(obj, signatures, options, meta_graph_def,\r\n   1104                         raise_metadata_warning))\r\n   1105   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, signatures, options, meta_graph_def, raise_metadata_warning)\r\n   1288 \r\n   1289   with save_context.save_context(options):\r\n-> 1290     return _build_meta_graph_impl(obj, signatures, options, meta_graph_def,\r\n   1291                                   raise_metadata_warning)\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph_impl(obj, signatures, options, meta_graph_def, raise_metadata_warning)\r\n   1205   checkpoint_graph_view = _AugmentedGraphView(obj)\r\n   1206   if signatures is None:\r\n-> 1207     signatures = signature_serialization.find_function_to_export(\r\n   1208         checkpoint_graph_view)\r\n   1209 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py in find_function_to_export(saveable_view)\r\n     97   # If the user did not specify signatures, check the root object for a function\r\n     98   # that can be made into a signature.\r\n---> 99   functions = saveable_view.list_functions(saveable_view.root)\r\n    100   signature = functions.get(DEFAULT_SIGNATURE_ATTR, None)\r\n    101   if signature is not None:\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in list_functions(self, obj)\r\n    152     obj_functions = self._functions.get(obj, None)\r\n    153     if obj_functions is None:\r\n--> 154       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\r\n    155           self._serialization_cache)\r\n    156       self._functions[obj] = obj_functions\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _list_functions_for_serialization(self, serialization_cache)\r\n   2711     self.test_function = None\r\n   2712     self.predict_function = None\r\n-> 2713     functions = super(\r\n   2714         Model, self)._list_functions_for_serialization(serialization_cache)\r\n   2715     self.train_function = train_function\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _list_functions_for_serialization(self, serialization_cache)\r\n   3014 \r\n   3015   def _list_functions_for_serialization(self, serialization_cache):\r\n-> 3016     return (self._trackable_saved_model_saver\r\n   3017             .list_functions_for_serialization(serialization_cache))\r\n   3018 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py in list_functions_for_serialization(self, serialization_cache)\r\n     90       return {}\r\n     91 \r\n---> 92     fns = self.functions_to_serialize(serialization_cache)\r\n     93 \r\n     94     # The parent AutoTrackable class saves all user-defined tf.functions, and\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in functions_to_serialize(self, serialization_cache)\r\n     71 \r\n     72   def functions_to_serialize(self, serialization_cache):\r\n---> 73     return (self._get_serialized_attributes(\r\n     74         serialization_cache).functions_to_serialize)\r\n     75 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes(self, serialization_cache)\r\n     87       return serialized_attr\r\n     88 \r\n---> 89     object_dict, function_dict = self._get_serialized_attributes_internal(\r\n     90         serialization_cache)\r\n     91 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)\r\n     51     # the ones serialized by Layer.\r\n     52     objects, functions = (\r\n---> 53         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(\r\n     54             serialization_cache))\r\n     55     functions['_default_save_signature'] = default_signature\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)\r\n     97     \"\"\"Returns dictionary of serialized attributes.\"\"\"\r\n     98     objects = save_impl.wrap_layer_objects(self.obj, serialization_cache)\r\n---> 99     functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n    100     # Attribute validator requires that the default save signature is added to\r\n    101     # function dict, even if the value is None.\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in wrap_layer_functions(layer, serialization_cache)\r\n    202           if isinstance(fn, LayerCall):\r\n    203             fn = fn.wrapped_call\r\n--> 204           fn.get_concrete_function()\r\n    205 \r\n    206   # Restore overwritten functions and losses\r\n\r\n/usr/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback)\r\n    118         if type is None:\r\n    119             try:\r\n--> 120                 next(self.gen)\r\n    121             except StopIteration:\r\n    122                 return False\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in tracing_scope()\r\n    365       if training is not None:\r\n    366         with K.deprecated_internal_learning_phase_scope(training):\r\n--> 367           fn.get_concrete_function(*args, **kwargs)\r\n    368       else:\r\n    369         fn.get_concrete_function(*args, **kwargs)\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)\r\n   1365       ValueError: if this object has not yet been called on concrete values.\r\n   1366     \"\"\"\r\n-> 1367     concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n   1368     concrete._garbage_collector.release()  # pylint: disable=protected-access\r\n   1369     return concrete\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\r\n   1282       # In this case we have not created variables on the first call. So we can\r\n   1283       # run the first trace but we should fail if variables are created.\r\n-> 1284       concrete = self._stateful_fn._get_concrete_function_garbage_collected(  # pylint: disable=protected-access\r\n   1285           *args, **kwargs)\r\n   1286       if self._created_variables:\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\r\n   3098       args, kwargs = None, None\r\n   3099     with self._lock:\r\n-> 3100       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   3101       seen_names = set()\r\n   3102       captured = object_identity.ObjectIdentitySet(\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3442 \r\n   3443           self._function_cache.missed.add(call_context_key)\r\n-> 3444           graph_function = self._create_graph_function(args, kwargs)\r\n   3445           self._function_cache.primary[cache_key] = graph_function\r\n   3446 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3277     arg_names = base_arg_names + missing_arg_names\r\n   3278     graph_function = ConcreteFunction(\r\n-> 3279         func_graph_module.func_graph_from_py_func(\r\n   3280             self._name,\r\n   3281             self._python_function,\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    997         _, original_func = tf_decorator.unwrap(python_func)\r\n    998 \r\n--> 999       func_outputs = python_func(*func_args, **func_kwargs)\r\n   1000 \r\n   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    670         # the function a weak reference to itself to avoid a reference cycle.\r\n    671         with OptionalXlaContext(compile_with_xla):\r\n--> 672           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    673         return out\r\n    674 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in wrapper(*args, **kwargs)\r\n    597       with autocast_variable.enable_auto_cast_variables(\r\n    598           layer._compute_dtype_object):  # pylint: disable=protected-access\r\n--> 599         ret = method(*args, **kwargs)\r\n    600     _restore_layer_losses(original_losses)\r\n    601     return ret\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in wrap_with_training_arg(*args, **kwargs)\r\n    163       return wrapped_call(*args, **kwargs)\r\n    164 \r\n--> 165     return control_flow_util.smart_cond(\r\n    166         training, lambda: replace_training_and_call(True),\r\n    167         lambda: replace_training_and_call(False))\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/control_flow_util.py in smart_cond(pred, true_fn, false_fn, name)\r\n    107     return control_flow_ops.cond(\r\n    108         pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n--> 109   return smart_module.smart_cond(\r\n    110       pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n    111 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py in smart_cond(pred, true_fn, false_fn, name)\r\n     52   if pred_value is not None:\r\n     53     if pred_value:\r\n---> 54       return true_fn()\r\n     55     else:\r\n     56       return false_fn()\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in <lambda>()\r\n    164 \r\n    165     return control_flow_util.smart_cond(\r\n--> 166         training, lambda: replace_training_and_call(True),\r\n    167         lambda: replace_training_and_call(False))\r\n    168 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in replace_training_and_call(training)\r\n    161     def replace_training_and_call(training):\r\n    162       set_training_arg(training, training_arg_index, args, kwargs)\r\n--> 163       return wrapped_call(*args, **kwargs)\r\n    164 \r\n    165     return control_flow_util.smart_cond(\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in call(inputs, *args, **kwargs)\r\n    679     return layer.keras_api.__call__  # pylint: disable=protected-access\r\n    680   def call(inputs, *args, **kwargs):\r\n--> 681     return call_and_return_conditional_losses(inputs, *args, **kwargs)[0]\r\n    682   return _create_call_fn_decorator(layer, call)\r\n    683 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in __call__(self, *args, **kwargs)\r\n    637   def __call__(self, *args, **kwargs):\r\n    638     self._maybe_trace(args, kwargs)\r\n--> 639     return self.wrapped_call(*args, **kwargs)\r\n    640 \r\n    641   def get_concrete_function(self, *args, **kwargs):\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    887 \r\n    888       with OptionalXlaContext(self._jit_compile):\r\n--> 889         result = self._call(*args, **kwds)\r\n    890 \r\n    891       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    922       # In this case we have not created variables on the first call. So we can\r\n    923       # run the first trace but we should fail if variables are created.\r\n--> 924       results = self._stateful_fn(*args, **kwds)\r\n    925       if self._created_variables:\r\n    926         raise ValueError(\"Creating variables on a non-first call to a function\"\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   3020     with self._lock:\r\n   3021       (graph_function,\r\n-> 3022        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n   3023     return graph_function._call_flat(\r\n   3024         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3442 \r\n   3443           self._function_cache.missed.add(call_context_key)\r\n-> 3444           graph_function = self._create_graph_function(args, kwargs)\r\n   3445           self._function_cache.primary[cache_key] = graph_function\r\n   3446 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3277     arg_names = base_arg_names + missing_arg_names\r\n   3278     graph_function = ConcreteFunction(\r\n-> 3279         func_graph_module.func_graph_from_py_func(\r\n   3280             self._name,\r\n   3281             self._python_function,\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    997         _, original_func = tf_decorator.unwrap(python_func)\r\n    998 \r\n--> 999       func_outputs = python_func(*func_args, **func_kwargs)\r\n   1000 \r\n   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    670         # the function a weak reference to itself to avoid a reference cycle.\r\n    671         with OptionalXlaContext(compile_with_xla):\r\n--> 672           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    673         return out\r\n    674 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in wrapper(*args, **kwargs)\r\n    597       with autocast_variable.enable_auto_cast_variables(\r\n    598           layer._compute_dtype_object):  # pylint: disable=protected-access\r\n--> 599         ret = method(*args, **kwargs)\r\n    600     _restore_layer_losses(original_losses)\r\n    601     return ret\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in wrap_with_training_arg(*args, **kwargs)\r\n    163       return wrapped_call(*args, **kwargs)\r\n    164 \r\n--> 165     return control_flow_util.smart_cond(\r\n    166         training, lambda: replace_training_and_call(True),\r\n    167         lambda: replace_training_and_call(False))\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/control_flow_util.py in smart_cond(pred, true_fn, false_fn, name)\r\n    107     return control_flow_ops.cond(\r\n    108         pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n--> 109   return smart_module.smart_cond(\r\n    110       pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n    111 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py in smart_cond(pred, true_fn, false_fn, name)\r\n     52   if pred_value is not None:\r\n     53     if pred_value:\r\n---> 54       return true_fn()\r\n     55     else:\r\n     56       return false_fn()\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in <lambda>()\r\n    164 \r\n    165     return control_flow_util.smart_cond(\r\n--> 166         training, lambda: replace_training_and_call(True),\r\n    167         lambda: replace_training_and_call(False))\r\n    168 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in replace_training_and_call(training)\r\n    161     def replace_training_and_call(training):\r\n    162       set_training_arg(training, training_arg_index, args, kwargs)\r\n--> 163       return wrapped_call(*args, **kwargs)\r\n    164 \r\n    165     return control_flow_util.smart_cond(\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in call_and_return_conditional_losses(*args, **kwargs)\r\n    661   def call_and_return_conditional_losses(*args, **kwargs):\r\n    662     \"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\r\n--> 663     call_output = layer_call(*args, **kwargs)\r\n    664     if version_utils.is_v1_layer_or_model(layer):\r\n    665       conditional_losses = layer.get_losses_for(\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in call(self, inputs, training, mask)\r\n    378       if not self.built:\r\n    379         self._init_graph_network(self.inputs, self.outputs)\r\n--> 380       return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n    381 \r\n    382     outputs = inputs  # handle the corner case where self.layers is empty\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py in call(self, inputs, training, mask)\r\n    418         a list of tensors if there are more than one outputs.\r\n    419     \"\"\"\r\n--> 420     return self._run_internal_graph(\r\n    421         inputs, training=training, mask=mask)\r\n    422 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py in _run_internal_graph(self, inputs, training, mask)\r\n    554 \r\n    555         args, kwargs = node.map_arguments(tensor_dict)\r\n--> 556         outputs = node.layer(*args, **kwargs)\r\n    557 \r\n    558         # Update tensor_dict.\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow_probability/python/layers/distribution_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    228   def __call__(self, inputs, *args, **kwargs):\r\n    229     self._enter_dunder_call = True\r\n--> 230     distribution, _ = super(DistributionLambda, self).__call__(\r\n    231         inputs, *args, **kwargs)\r\n    232     self._enter_dunder_call = False\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __iter__(self)\r\n    518   def __iter__(self):\r\n    519     if not context.executing_eagerly():\r\n--> 520       self._disallow_iteration()\r\n    521 \r\n    522     shape = self._shape_tuple()\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _disallow_iteration(self)\r\n    511       self._disallow_when_autograph_disabled(\"iterating over `tf.Tensor`\")\r\n    512     elif ag_ctx.control_status_ctx().status == ag_ctx.Status.ENABLED:\r\n--> 513       self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\r\n    514     else:\r\n    515       # Default: V1-style Graph execution.\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _disallow_when_autograph_enabled(self, task)\r\n    487 \r\n    488   def _disallow_when_autograph_enabled(self, task):\r\n--> 489     raise errors.OperatorNotAllowedInGraphError(\r\n    490         \"{} is not allowed: AutoGraph did convert this function. This might\"\r\n    491         \" indicate you are trying to use an unsupported feature.\".format(task))\r\n\r\nOperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature._\r\n`\r\n\r\n**Workaround works with limited capability** as shown in [https://github.com/tensorflow/probability/issues/325#issuecomment-477213850](url)\r\nBut this only saves the weights and not other details of the model.\r\n\r\n**Workaround works with h5 format**\r\nh5 format saving works, but cannot load the model\r\n\r\n`\r\nloaded_model = tf.keras.models.load_model('/tmp/model/probabilistic_model.h5')\r\n\r\n`\r\nError while using h5 format for saving and then loading the model is shown below.\r\n`\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_11377/686337657.py in <module>\r\n----> 1 loaded_model = tf.keras.models.load_model('/tmp/model/probabilistic_model.h5')\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)\r\n    199         if (h5py is not None and\r\n    200             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\r\n--> 201           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\r\n    202                                                   compile)\r\n    203 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\r\n    178       model_config = model_config.decode('utf-8')\r\n    179     model_config = json_utils.decode(model_config)\r\n--> 180     model = model_config_lib.model_from_config(model_config,\r\n    181                                                custom_objects=custom_objects)\r\n    182 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)\r\n     57                     '`Sequential.from_config(config)`?')\r\n     58   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top\r\n---> 59   return deserialize(config, custom_objects=custom_objects)\r\n     60 \r\n     61 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)\r\n    157   \"\"\"\r\n    158   populate_deserializable_objects()\r\n--> 159   return generic_utils.deserialize_keras_object(\r\n    160       config,\r\n    161       module_objects=LOCAL.ALL_OBJECTS,\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    666 \r\n    667       if 'custom_objects' in arg_spec.args:\r\n--> 668         deserialized_obj = cls.from_config(\r\n    669             cls_config,\r\n    670             custom_objects=dict(\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in from_config(cls, config, custom_objects)\r\n    495     model = cls(name=name)\r\n    496     for layer_config in layer_configs:\r\n--> 497       layer = layer_module.deserialize(layer_config,\r\n    498                                        custom_objects=custom_objects)\r\n    499       model.add(layer)\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)\r\n    157   \"\"\"\r\n    158   populate_deserializable_objects()\r\n--> 159   return generic_utils.deserialize_keras_object(\r\n    160       config,\r\n    161       module_objects=LOCAL.ALL_OBJECTS,\r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    651     # In this case we are dealing with a Keras config dictionary.\r\n    652     config = identifier\r\n--> 653     (cls, cls_config) = class_and_config_for_serialized_keras_object(\r\n    654         config, module_objects, custom_objects, printable_module_name)\r\n    655 \r\n\r\n~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)\r\n    554   cls = get_registered_object(class_name, custom_objects, module_objects)\r\n    555   if cls is None:\r\n--> 556     raise ValueError(\r\n    557         'Unknown {}: {}. Please ensure this object is '\r\n    558         'passed to the `custom_objects` argument. See '\r\n\r\nValueError: Unknown layer: OneHotCategorical. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\r\n`\r\n\r\n\r\n**Describe the expected behavior**\r\n_Saves a probabilistic_model as a TensorFlow SavedModel_ \r\n", "comments": ["@rrklearn2020 \r\n\r\nCould you please provide the colab gist with the required dependencies to analyse the issue better. Thanks\r\n\r\n\r\n\r\n", "@UsharaniPagadala \r\nI have uploaded the file to GitHub and the link is shared below. \r\n\r\n[https://github.com/rrklearn2020/probabilistic_model_trials.git](https://github.com/rrklearn2020/probabilistic_model_trials.git)\r\n\r\n", "> @rrklearn2020\r\n> \r\n> Could you please provide the collab gist with the required dependencies to analyze the issue better. Thanks\r\n\r\n@UsharaniPagadala\r\nI have uploaded the file to GitHub and the link is shared below.\r\n\r\nhttps://github.com/rrklearn2020/probabilistic_model_trials.git\r\n\r\nComplete details are shared with this link. ", "@rrklearn2020 \r\n\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue is not yet solved, waiting for support. ", "@rrklearn2020 \r\n\r\nIt looks like the Issue relates to the Keras component. Please submit it to the [github.com/keras-team/keras](https://github.com/keras-team/keras/issues) repository instead. As previously [announced](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) all future development of Keras is expected to happen in the keras-team/keras repository. If your issue lies with the TF-Core area please comment back with your explanation and we can look into it further. Thanks!\r\n", "@UsharaniPagadala  \r\nthe issue was posted to Keras git (link shared - 12 days before), but till today, no solution. \r\n\r\nIt would be a great help if the Tensorflow team and Keras team can support together as one team to solve this issue of saving a TF probabilistic_model as a 'TensorFlow SavedModel'", "@rrklearn2020 \r\nCould you please share that issue link posted in Keras-team/keras. Thanks", "@UsharaniPagadala I had already posted the issue link posted in Keras-team/keras, 19 days ago, \r\n\r\nThe link is shared below.\r\nhttps://github.com/keras-team/keras/issues/15024\r\n", "@rrklearn2020 \r\n\r\nCould you please move this to closed status as it is tracking  in keras-team/keras repo. Thanks", "Before closing the ticket, It would be a great help if the Tensorflow team and Keras team can support together as one team to solve this issue of saving a TF probabilistic_model as a 'TensorFlow SavedModel'", "@rrklearn2020 \r\n\r\nThanks for the update,sure we will do that", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue is not yet solved, waiting for support."]}, {"number": 50765, "title": "Memory leak in custom training loop + tf.function ", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18 (google colab)\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below):  v2.5.0-0-ga4dfb8d1a71 2.5.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: Build cuda_11.0_bu.TC445_37.28845127_0\r\n- GPU model and memory: Tesla T4 - 15109MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm encountering a subtle memory leak, and unable to determine the source using tracemalloc. I run the code in google colab, which is meant to optimize hyperparameters for a custom ppo agent. Also, the speed at which the leak happens varies: sometimes it happens within 10-20 minutes of runtime / 5-10 iterations while on other times it may take up to an hour.\r\n\r\n**Describe the expected behavior**\r\n\r\nMemory usage should be constant over time, since there are no objects stored in memory intentionally as the training progresses.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHere's a colab [notebook](https://colab.research.google.com/drive/1mIO3Pd-HSskvIrcl3Bp3Evg_MzAEuwPc?usp=sharing)\r\n\r\n**Other info / logs**\r\n\r\nAnd here are the resulting [memory snapshots](https://drive.google.com/file/d/1RH89X5B5xsUY8a1RA4Gh9WmEIqXhs84R/view?usp=sharing) at 15 consecutive iterations up to the crash, which do not show any particular red flags. Besides, by summing up the `size` column of the most recent snapshot, it totals 967249710 bytes ~= 1GB, which is weird because the available memory on colab ~= 12GB. \r\n\r\nHere's a log after crashing:\r\n\r\n\r\n```\r\n   Timestamp                  Level    Message\r\n\r\nJul 14, 2021, 11:07:41 AM | WARNING | WARNING:root:kernel a3ecdd9e-1765-4f67-af0e-60c198c896ec restarted\r\nJul 14, 2021, 11:07:41 AM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports\r\nJul 14, 2021, 10:22:16 AM | WARNING | 2021-07-14 08:22:16.518184: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\nJul 14, 2021, 10:22:13 AM | WARNING | 2021-07-14 08:22:13.939377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\nJul 14, 2021, 10:21:50 AM | WARNING | 2021-07-14 08:21:50.140299: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\r\nJul 14, 2021, 10:21:47 AM | WARNING | 2021-07-14 08:21:47.841310: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\nJul 14, 2021, 10:21:44 AM | WARNING | 2021-07-14 08:21:44.642335: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\r\nJul 14, 2021, 10:21:44 AM | WARNING | 2021-07-14 08:21:44.559306: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.355834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.355771: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.354979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.354000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.352104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.351844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.351828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 0\r\nJul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.351772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.206565: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.203344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.202526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.201577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:25 AM | WARNING | coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\r\nJul 14, 2021, 10:21:25 AM | WARNING | pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.201438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.200536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.199581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.195723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.194598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.194398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.190679: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\nJul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.144200: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.851273: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.832903: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.660570: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.660379: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.533359: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\nJul 14, 2021, 10:21:24 AM | WARNING | coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\r\nJul 14, 2021, 10:21:24 AM | WARNING | pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.533253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.532176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nJul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.461038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\nJul 14, 2021, 10:21:07 AM | WARNING | 2021-07-14 08:21:07.977292: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\nJul 14, 2021, 10:20:27 AM | INFO | Adapting to protocol v5.1 for kernel a3ecdd9e-1765-4f67-af0e-60c198c896ec\r\nJul 14, 2021, 10:20:26 AM | INFO | Kernel started: a3ecdd9e-1765-4f67-af0e-60c198c896ec\r\nJul 14, 2021, 10:20:20 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\nJul 14, 2021, 10:20:20 AM | INFO | http://172.28.0.12:9000/\r\nJul 14, 2021, 10:20:20 AM | INFO | The Jupyter Notebook is running at:\r\nJul 14, 2021, 10:20:20 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\nJul 14, 2021, 10:20:20 AM | INFO | 0 active kernels\r\nJul 14, 2021, 10:20:20 AM | INFO | http://172.28.0.2:9000/\r\nJul 14, 2021, 10:20:20 AM | INFO | The Jupyter Notebook is running at:\r\nJul 14, 2021, 10:20:20 AM | INFO | Serving notebooks from local directory: /\r\nJul 14, 2021, 10:20:20 AM | INFO | 0 active kernels\r\nJul 14, 2021, 10:20:20 AM | INFO | Serving notebooks from local directory: /\r\nJul 14, 2021, 10:20:20 AM | INFO | google.colab serverextension initialized.\r\nJul 14, 2021, 10:20:20 AM | INFO | google.colab serverextension initialized.\r\nJul 14, 2021, 10:20:20 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\r\nJul 14, 2021, 10:20:20 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\r\n```", "comments": ["@jvishnuvardhan ,\r\nI was able to reproduce the issue in tf [v2.5](https://colab.research.google.com/gist/tilakrayal/3d1a169da227be5d965e926a36c474e4/2-5memory_leak.ipynb) and [v2.4](https://colab.research.google.com/gist/tilakrayal/0d2f1ff4ef758672adf1b1838f4b8d23/2-4memory_leak.ipynb) it is giving error.Please find the gist here."]}, {"number": 50762, "title": "Not linking properly on XCode with Mac M1", "body": "Platform: MacBook M1 BigSur\r\nInstalled: CocoaPods\r\n\r\n**Describe the problem**\r\nI have created a new project and added a Podfile from here: https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/ios\r\n\r\nWhen I build in XCode I get \r\n\r\n`building for iOS Simulator, but linking in object file built for iOS, file.\r\n'/Users/name/Code/name2/ios/SwingAIAnalyzer/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC' for architecture arm64`\r\n\r\nBut when I try the example `ImageClassification` directly it works. I have check the settings of the two projects but cannot find any differences.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1 Create a new project\r\n2 Copy the Podfile in ImageClassfication and change project name in podfile.\r\n3 Run pod install or pod update\r\n4 Open .xcworkspace\r\n5 Build and here I fail\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Looks like you are running into problems when trying to run [customized image classification](https://www.tensorflow.org/lite/examples/image_classification/overview#customize-model) example whereas the standalone example works successfully. Is that correct?", "No, I have not done anything with TensorFlow in my code. I have just run CocoaPods, and then I cannot build."]}, {"number": 50758, "title": "Dynamic-sized CoreML Delegate", "body": "**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe TensorflowLite Core ML delegate currently does not support graphs with dynamic-sized tensors. However, Core ML can in fact support dynamic re-shaping, as demonstrated by the `coremltools` package being able to create dynamic-sized core ML models since WWDC 2020. Therefore, it should hopefully be possible to get the Core ML delegate to support dynamic shapes.\r\n\r\n**Will this change the current api? How?**\r\nThe API will be the same, but it will no longer throw this error:\r\n```\r\nTensorFlow Lite Error: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\n```\r\n\r\n**Who will benefit with this feature?**\r\niOS developers building complex models with dynamic-sized tensors for mobile who wish to maintain just one tflite mobile model for both Android and iOS devices, instead of converting the tensorflow models to Core ML to support dynamic sizes.", "comments": ["Hi Youngseok,\r\n\r\nCould you have a look on this iOS related issue?\r\n\r\nThanks,\r\nTiezhen", "Hi @tylerweitzman, thanks for filing the feature request. Unfortunately we don't have plans to add support for this in the near future, but would be happy to review any PRs related to this."]}, {"number": 50747, "title": "MLIR converter quantizes conv2d before bias when dilaition rate > 1", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n\r\n#### Option A: Reference colab notebooks\r\n\r\nReference [TensorFlow Model Colab](https://colab.research.google.com/drive/1Pp0ZwbHTz3QjC2YxTn6l2kIro_DNxDqx?usp=sharing): Demonstrate how to build your TF model, convert to TFLite, and infer.\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\nWhen creating a Conv2D with a dilation rate that is greater than 1, and the Conv2D has a bias, the MLIR converter splits the bias to a separate layer, and quantizes the tensor between them, thus causing accuracy degradation.\r\n\r\n\r\n### 5. (optional) Any other info / logs\r\n![image](https://user-images.githubusercontent.com/44209964/125436409-85a7a2e9-3158-4622-846e-baf1e08eae75.png)\r\n", "comments": ["@reuvenperetz ,\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue.Thanks!", "Reproducing steps with the dedicated model would be really helpful!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n```python\r\n\r\nimport pathlib\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\ni = tf.keras.layers.Input(shape=(32, 32, 3))\r\no = tf.keras.layers.Conv2D(3, 3, dilation_rate=2)(i)\r\nmodel = tf.keras.Model(inputs=[i], outputs=[o])\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ndef representative_data_gen():\r\n    yield [np.random.random((1, 32, 32, 3)).astype(np.float32)]\r\n\r\n\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n\r\ntflite_models_dir = pathlib.Path(\"/tmp/\")\r\ntflite_model_file = tflite_models_dir / \"dilation_model.tflite\"\r\ntflite_model_file.write_bytes(tflite_model)\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()[0]\r\n\r\ninterpreter.set_tensor(input_details[\"index\"], np.random.random((1, 32, 32, 3)).astype(np.float32))\r\ninterpreter.invoke()\r\noutput_details = interpreter.get_output_details()[0]\r\noutput = interpreter.get_tensor(output_details[\"index\"])[0]\r\n\r\n```\r\n\r\n\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\n- Model produces wrong results and/or has lesser accuracy.\r\n\r\nWhen creating a Conv2D with a dilation rate that is greater than 1, and the Conv2D has a bias, the MLIR converter splits the bias to a separate layer, and quantizes the tensor between them, thus causing accuracy degradation.\r\n\r\n### 4. (optional) RNN conversion support\r\nNot relaevant\r\n\r\n### 5. (optional) Any other info / logs\r\n![image](https://user-images.githubusercontent.com/44209964/126648418-0eda4143-9b85-44c7-9c21-1a1ba2bdef7a.png)\r\n"]}, {"number": 50740, "title": "Dataset.as_numpy_iterator() throws error inside tensorflow.numpy_function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Google Colab \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: CPU 8GB\r\n\r\n\r\n**Describe the expected behavior** tensorflow.data.Dataset.as_numpy_iterator should return iterator when called from inside tensorflow.py_func used inside Dataset.interleave's map_function.\r\n\r\n\r\n**Describe the current behavior** Throwing error 'Tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]'\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing): NA\r\n\r\n**Standalone code to reproduce the issue**\r\n````\r\nimport tensorflow as tf\r\npath = \"saved_data_2\"\r\n\r\n# Save a dataset\r\ndataset = tf.data.Dataset.range(10)\r\ntf.data.experimental.save(dataset, path)\r\nnew_dataset = tf.data.experimental.load(path)\r\nfor elem in new_dataset:\r\n  print(elem)\r\n\r\n\r\n#flat_map code error below\r\nfilenames = [path]\r\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\r\n\r\n\r\ndef parse_fn(filename):\r\n    part_ds = tf.data.experimental.load(bytes.decode(filename),compression='GZIP')\r\n    ar = []\r\n    for i in part_ds.as_numpy_iterator():\r\n        ar.append(i)\r\n    return ar\r\n\r\ndataset = dataset.interleave(lambda x:tf.data.Dataset.from_tensor_slices(\r\n            tf.numpy_function(parse_fn,[x],[tf.int64])),\r\n            cycle_length=4, block_length=16)\r\n\r\nfor item in dataset.as_numpy_iterator():\r\n    print(item)\r\n````\r\n\r\n**Other info / logs** \r\n\r\n````\r\nC:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\python.exe C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py\r\n2021-07-12 21:14:47.985114: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\r\n2021-07-12 21:14:47.985404: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2021-07-12 21:14:50.932059: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n2021-07-12 21:14:50.932192: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-07-12 21:14:50.935815: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: LAPTOP-76MAP85S\r\n2021-07-12 21:14:50.936005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: LAPTOP-76MAP85S\r\n2021-07-12 21:14:50.936609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-07-12 21:14:50.967628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-07-12 21:14:51.013124: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.\r\ntf.Tensor(0, shape=(), dtype=int64)\r\ntf.Tensor(1, shape=(), dtype=int64)\r\ntf.Tensor(2, shape=(), dtype=int64)\r\ntf.Tensor(3, shape=(), dtype=int64)\r\ntf.Tensor(4, shape=(), dtype=int64)\r\ntf.Tensor(5, shape=(), dtype=int64)\r\ntf.Tensor(6, shape=(), dtype=int64)\r\n2021-07-12 21:14:51.017583: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.\r\ntf.Tensor(7, shape=(), dtype=int64)\r\ntf.Tensor(8, shape=(), dtype=int64)\r\ntf.Tensor(9, shape=(), dtype=int64)\r\n2021-07-12 21:14:51.102540: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.\r\n2021-07-12 21:14:51.109462: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.\r\n2021-07-12 21:14:51.133405: W tensorflow/core/framework/op_kernel.cc:1755] Unknown: DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py\", line 20, in parse_fn\r\n    for i in part_ds.as_numpy_iterator():\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 4194, in __next__\r\n    return nest.map_structure(to_numpy, next(self._iterator))\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 761, in __next__\r\n    return self._next_internal()\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 744, in _next_internal\r\n    ret = gen_dataset_ops.iterator_get_next(\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2727, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6897, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n\r\n  File \"<string>\", line 3, in raise_from\r\n\r\ntensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py\", line 28, in <module>\r\n    for item in dataset.as_numpy_iterator():\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 4194, in __next__\r\n    return nest.map_structure(to_numpy, next(self._iterator))\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 761, in __next__\r\n    return self._next_internal()\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 744, in _next_internal\r\n    ret = gen_dataset_ops.iterator_get_next(\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2727, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6897, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnknownError: DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py\", line 20, in parse_fn\r\n    for i in part_ds.as_numpy_iterator():\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 4194, in __next__\r\n    return nest.map_structure(to_numpy, next(self._iterator))\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 761, in __next__\r\n    return self._next_internal()\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 744, in _next_internal\r\n    ret = gen_dataset_ops.iterator_get_next(\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2727, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6897, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n\r\n  File \"<string>\", line 3, in raise_from\r\n\r\ntensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]\r\n\r\n\r\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]\r\n\r\nProcess finished with exit code 1\r\n\r\n````", "comments": ["@kurudinesh \r\n\r\nCould you please refer these [link1](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) and [link2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py) and let us know if  it helps.Thanks", "@UsharaniPagadala  \r\n\r\nI am trying to convert dataset loaded using tf.data.experimental.load method to a numpy array in Eager mode and in the documentation link it mentioned 'as_numpy_iterator' works in eager mode. ", "@rmothukuru \r\n\r\nI was able to replicate the issue reported here in tf 2.5 and tf-nightly.Please find  the [gist](https://colab.research.google.com/gist/UsharaniPagadala/08f1f940d0637fe3b55a942daa01865a/-50740.ipynb).Thanks", "@kurudinesh,\r\nWhile we look into the issue, I feel that you have swapped the content for **Current Behavior** and the **Expected Behavior**. If it is so, please correct it in the issue, order to avoid confusion. Thanks!", "@kurudinesh There were two issues with the code:\r\n\r\n1) The code was being saved as uncompressed data, but loaded as compressed data. The `compression` argument needs to match between `save` and `load`.\r\n2) tf.numpy_function must return a numpy array, so the list you are returning must be converted to a list, e.g. with `np.asarray(ar)`\r\n\r\nWith these changes the below code runs successfully:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\npath = \"saved_data_2\"\r\n\r\n# Save a dataset\r\ndataset = tf.data.Dataset.range(10)\r\ntf.data.experimental.save(dataset, path, compression=\"GZIP\")\r\nfilenames = [path]\r\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\r\n\r\ndef parse_fn(filename):\r\n    part_ds = tf.data.experimental.load(bytes.decode(filename), compression=\"GZIP\")\r\n    ar = []\r\n    for i in part_ds.as_numpy_iterator():\r\n        ar.append(i)\r\n    return np.asarray(ar)\r\n\r\ndataset = dataset.interleave(lambda x:tf.data.Dataset.from_tensor_slices(\r\n            tf.numpy_function(parse_fn,[x],[tf.int64])),\r\n            cycle_length=4, block_length=16)\r\n\r\nlist(dataset)\r\n```", "@aaudiber Thank you for your corrections. Small suggestion please change `load` method to threw `FileNotFoundError` when it could not find dataset file in gzip file format. ", "> @kurudinesh There were two issues with the code:\r\n> \r\n> 1. The code was being saved as uncompressed data, but loaded as compressed data. The `compression` argument needs to match between `save` and `load`.\r\n> 2. tf.numpy_function must return a numpy array, so the list you are returning must be converted to a list, e.g. with `np.asarray(ar)`\r\n> \r\n> With these changes the below code runs successfully:\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> import numpy as np\r\n> path = \"saved_data_2\"\r\n> \r\n> # Save a dataset\r\n> dataset = tf.data.Dataset.range(10)\r\n> tf.data.experimental.save(dataset, path, compression=\"GZIP\")\r\n> filenames = [path]\r\n> dataset = tf.data.Dataset.from_tensor_slices(filenames)\r\n> \r\n> def parse_fn(filename):\r\n>     part_ds = tf.data.experimental.load(bytes.decode(filename), compression=\"GZIP\")\r\n>     ar = []\r\n>     for i in part_ds.as_numpy_iterator():\r\n>         ar.append(i)\r\n>     return np.asarray(ar)\r\n> \r\n> dataset = dataset.interleave(lambda x:tf.data.Dataset.from_tensor_slices(\r\n>             tf.numpy_function(parse_fn,[x],[tf.int64])),\r\n>             cycle_length=4, block_length=16)\r\n> \r\n> list(dataset)\r\n> ```\r\n\r\nI got single element of size (1,10) as output. I was expecting dataset to be of shape (10,1).", "@kurudinesh That is happening because the numpy_function's `Tout` is set to `[tf.int64]` instead of `tf.int64`. As a result, the output of `parse_fn` being wrapped in an extra dimension. Removing the list around the `tf.int64` should give the expected (10, 1) shape", "> @kurudinesh That is happening because the numpy_function's `Tout` is set to `[tf.int64]` instead of `tf.int64`. As a result, the output of `parse_fn` being wrapped in an extra dimension. Removing the list around the `tf.int64` should give the expected (10, 1) shape\r\n\r\n@aaudiber \r\nThank you. \r\n\r\nI am still unclear about `Tout \u2013 A list or tuple of tensorflow data types or a single tensorflow data type if there is only one, indicating what `func` returns.`  Did they mean list or tuple of single tensorflow data type or can we mix it like [tf.int32,tf.double]?\r\n\r\nIn the below code I am trying to return data array of size `[432,3]`, type `numpy.float64` along with its label(`numpy.int32`) from numpy_function. Tried two approaches using parse_fn and parse_fn2.\r\n\r\nInside `parse_fn2`, I tried to return a `numpy.ndarray` of `tuples(list (shape =[432,3] ), int32)`  and could not find corresponding tensorflow datatype for numpy object dtype.\r\n\r\nIn '`parse_fn`' method I tried to return data array and label array separately and got errors.\r\n\r\nCurrently, I am using two numpy arrays inside from_tensorflow_slices which return list of data, labels.\r\n\r\n#50594  I tried this before and could not get help.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\npath = \"saved_data_2\"\r\n\r\n\r\n\r\n# Save a dataset\r\nar = np.random.randn(10,482,3)\r\ndataset = tf.data.Dataset.from_tensor_slices(ar)\r\ntf.data.experimental.save(dataset, path, compression=\"GZIP\")\r\n\r\n#creating dataset with labels\r\nfilenames = [path]\r\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\r\n\r\ndef parse_fn(filename):\r\n    part_ds = tf.data.experimental.load(bytes.decode(filename), compression=\"GZIP\")\r\n    ar = []\r\n    label=[]\r\n    for i in part_ds.as_numpy_iterator():\r\n        ar.append(i)\r\n        label.append(1)\r\n    # print(ar[0])\r\n    return np.asarray(ar),label\r\n\r\ndef parse_fn2(filename):\r\n    part_ds = tf.data.experimental.load(bytes.decode(filename), compression=\"GZIP\")\r\n    ar = []\r\n    # label=[]\r\n    for i in part_ds.as_numpy_iterator():\r\n        ar.append((i,1))\r\n        # label.append(1)\r\n    # print(ar[0])\r\n    return np.asarray(ar)\r\n\r\n\r\ndataset = dataset.interleave(lambda x:tf.data.Dataset.from_tensor_slices((\r\n            tf.numpy_function(parse_fn,[x],[tf.double,tf.int64]))),\r\n            cycle_length=4).cache()\r\n\r\nfor i in dataset.take(3).take(1).as_numpy_iterator():\r\n    print(i[0].shape,i[1].shape)\r\n    print(i.shape)#expeting element with size 1 but getting i with shape (1,10)\r\n    # break;\r\n\r\nprint(tf.data.experimental.cardinality(dataset))\r\n\r\n\r\n# tf.keras.Sequential\r\n```"]}, {"number": 50735, "title": "CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**This is an urgent issue! It has caused a production problem!**\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Amazon Sagemaker)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): **latest**: 2.5\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.020/8.202\r\n- GPU model and memory: Tesla T4/13.8 GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI updated my model and when I train, I get the following error:\r\n\r\n`\r\n2021-07-11T23:08:22.514-04:00\t2021-07-12 03:08:22.053193: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14474280960 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\r\n\r\n2021-07-11T23:08:22.514-04:00\t2021-07-12 03:08:22.053330: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14474280960 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\r\n\r\n2021-07-11T23:08:32.516-04:00\t2021-07-12 03:08:32.060022: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n\r\n2021-07-11T23:08:34.517-04:00\t2021-07-12 03:08:34.183639: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\r\n\r\n2021-07-11T23:08:36.517-04:00\t2021-07-12 03:08:36.256607: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n\r\n2021-07-11T23:08:38.518-04:00\t2021-07-12 03:08:38.161603: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n\r\n2021-07-11T23:08:50.608-04:00\r\n\r\n**2021-07-12 03:08:50.058288: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2021-07-12 03:08:50.058288: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountere**d`\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n**LOGS:**\r\n[logs.txt](https://github.com/tensorflow/tensorflow/files/6801798/logs.txt)\r\n\r\n", "comments": ["@nectario ,\r\n\r\n Can you please try installing TensorFlow v2.5 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error.For more information please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu). Thanks!\r\n", "> @nectario ,\r\n> \r\n> Can you please try installing TensorFlow v2.5 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error.For more information please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu). Thanks!\r\n\r\nThank you. Running on my my local machine, where I have these versions, it works fine. But the real issue is that I am using Amazon Sagemaker and that build is fixed. The Docker image I am pulling is tensorflow/tensorflow:latest-gpu-jupyter \r\nI also tried pulling the Nvidia image of tensorflow from nvcr.io/nvidia/tensorflow:21.06-tf2-py3 \r\nbut I still have the same problem. This happens with the specific deep learning architecture I am using. My older architecture does not have this problem. My local GPU is Titan V. The Sagemaker GPU is Tesla T4.\r\n\r\n\r\n", "This issue has completely derailed our production release. I hope it's given some urgency.", "Is there a tensorflow docker image where I can specify the CUDA/CUDNN version specifically?\r\n\r\nFrom my Dockerfile I am calling:\r\n\r\n`FROM tensorflow/tensorflow:latest-gpu-jupyter`\r\n\r\n", "From the logs, I see it's loading CUDNN version 8.2:\r\n\r\n`2021-07-13 21:21:35.642481: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202`\r\n\r\n", "This error also happens with the tf-nightly image.", "I got it to work when I use the tensorflow Docker image for TF 2.4.2: \r\n\r\ntensorflow/tensorflow:2.4.2-gpu-jupyter\r\n\r\nSo it is clearly a problem with later versions of CUDA/CUDNN!", "This is the Google Colab with the code that triggers this error. If you run this here, it will not happen as it happens mainly in the Docker image tensorflow/tensorflow:latest-gpu-jupyter\r\n\r\nCode:\r\n\r\nhttps://colab.research.google.com/drive/1E_IZ3zmPrQHbuiYl47gvL591hHfS-VkN#scrollTo=ts7l0877A0_d\r\n", "Is there any update on this? I really would like to use version 2.6, but cannot.", "Hi @nectario,\r\n\r\nCan you try running with `CUDA_LAUNCH_BLOCKING=1` in the environment & share the logs?  That should isolate the error to the actual GPU operation that caused it.\r\n\r\nAlso: do you have a reproducer that does not depend on separate data files, like `./y_val_two_week_return.pkl`?", "Hi @sanjoy \r\n\r\nSorry for my late response. I just came back from vacation. I did as you said, but surprisingly, the issue is not reproduceable now. I tried running it in the different environments in AWS and also my local machine, where it was happening, and it does not happen now. The version of tensorflow I tested with  was 2.6. Fyi, when this first happened, it was under 2.5. Anyway, I do remember testing also with 2.6 back then, and it was happening when 2.6 first came out.\r\n\r\nIf you want me to run it with 2.5 with the above setting, let me know.", "@sanjoy I take it back. This error did manage to happen again. Surprisingly it happened when I removed the above flag CUDA_LAUNCH_BLOCKING=1. From my 250 model training 13 succeeded but the rest all failed with that error. Unfortunately it was without the flag. Will run it  with it and will attach the logs.", "@sanjoy Now that I think about it, the day before yesterday I trained my 250 models with the flag on and the error did not happen. Although training seemed a little bit slower than usual. And today I trained with the flag removed, and 200+ model trainings failed.", "@sanjoy The same thing happened with us as well, I launched with CUDA_LAUNCH_BLOCKING, but then no errors occurred. FYI, we started running into this problem while trying to use cuDNN LSTM/GRU layer in our model. Earlier the input was left-padded which is why cuDNN kernel was not being used, we just switched the padding & this issue started happening.\r\n\r\nConfig:\r\nUbuntu 20.04.3 LTS\r\nDocker 20.10.8\r\nImage: tensorflow/tensorflow:2.6.0-gpu-jupyter\r\nGPU: Telsa P40 (Azure VM)\r\nDrivers: 470.57.02\r\nCUDA: 11.4", "This problem continues to happen and it only stops happening if I include the env flag: CUDA_LAUNCH_BLOCKING=1", "> This problem continues to happen and it only stops happening if I include the env flag: CUDA_LAUNCH_BLOCKING=1\r\n\r\nUnfortunately this means this is a heisenbug. :(\r\n\r\nRunning with `CUDA_LAUNCH_BLOCKING=1` \"for real\" is not a good idea since it affects performance, as you indicated in https://github.com/tensorflow/tensorflow/issues/50735#issuecomment-917314918.\r\n\r\nWill you be able to extract a minimal reproducer that shows the issue?  Ideally something that only has a few ops?", "@sanjoy I just emailed you a file with the code that reproduces this issue on a Linux box. \r\n\r\n> > This problem continues to happen and it only stops happening if I include the env flag: CUDA_LAUNCH_BLOCKING=1\r\n> \r\n> Unfortunately this means this is a heisenbug. :(\r\n> \r\n> Running with `CUDA_LAUNCH_BLOCKING=1` \"for real\" is not a good idea since it affects performance, as you indicated in [#50735 (comment)](https://github.com/tensorflow/tensorflow/issues/50735#issuecomment-917314918).\r\n> \r\n> Will you be able to extract a minimal reproducer that shows the issue? Ideally something that only has a few ops?\r\n\r\n"]}, {"number": 50727, "title": "Translate use of Adam Optimizer from TF 1 to TF2 causing TF2 to coredump", "body": "**System information**\r\n\r\n- OS Platform and Distribution: Ubuntu 21.04\r\n- TensorFlow installed from (source or binary): pip install tensorflow=2.5.0\r\n- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version: 3/8/10\r\n- CUDA/cuDNN version: cuda_11.3.r11.3/compiler.29920130_0\r\n- GPU model and memory: NVIDIA GeForce RTX 2080 Ti, 11GB\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying to translate this [Tensorflow 1 notebook](https://github.com/mgroncki/IPythonScripts/blob/master/BermudanTensorFlow.ipynb) by Matthias Groncki to do Bermudan option pricing, from Tensorflow 1 to Tensorflow 2.\r\n\r\nTo move from non-eager graph mode with placeholders to eager mode with `tf.function`s, I have had to unroll his code and isolate spots where the unrolling runs into problems.\r\n\r\nMy use of the Adam optimizer is causing Tensorflow versions 2.4.1 and 2.5 with GPU to coredump. \r\n\r\nNOTE: This is pure Tensorflow 2 code with eager mode on, no use of TF 1 compatibility features, and no use of NumPy.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo coredump.  I think it's coredumping because the expression `y = E_t[:, i+1:i+2]`, where `i=1` and the shape of `E` is (10000,2), is giving an empty tensor for `y` with signature\r\n\r\n`    <tf.Tensor: shape=(10000, 0), dtype=float32, numpy=array([], shape=(10000, 0), dtype=float32)>`\r\n\r\nTensorflow could do better than to coredump in this case, there should be guards in the tensor operations to raise exceptions in Python rather than simply die.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\nI don't know candidate solution, I am not a TF internals programmer.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nN_samples_learn = 10000\r\nN_samples_pricing = 100000\r\ncalldates = 2\r\ntf.random.set_seed(7)\r\n\r\nN = tf.random.normal((N_samples_learn,calldates))\r\nN_pricing = tf.random.normal((N_samples_pricing,calldates))\r\n(S_0, strike, exTimes, impliedvol, riskfree_r) = (100., 110., tf.constant([1., 1.]), 0.2, 0.03)\r\n\r\nnumber_call_dates = len(exTimes)       \r\ndW = tf.sqrt(exTimes)*N\r\n\r\nS=tf.Variable(S_0)\r\nr=tf.Variable(riskfree_r)\r\nsigma=tf.Variable(impliedvol)\r\nprevious_exercises = 0\r\n\r\n# Last exercise date\r\nwith tf.GradientTape() as tape:\r\n    S_t = S * tf.math.cumprod(tf.exp((r-sigma**2/2)*exTimes + sigma*dW), axis=1)\r\n    E_t = tf.exp(-r*tf.cumsum(exTimes))*tf.maximum(S_t-strike, 0)\r\n    inMoney = tf.cast(tf.greater(E_t[:,-1], 0.), tf.float32)\r\n    exercise = inMoney * (1-previous_exercises)\r\n    npv = exercise*E_t[:,-1]\r\n    npv = tf.reduce_mean(npv)\r\n\r\ngreeks = tape.gradient(npv, [S, r, sigma])\r\n\r\ntraining_functions = []\r\nfor i in range(number_call_dates):\r\n    w = tf.Variable(tf.random.normal((3,1))*0.1)\r\n    b = tf.Variable(tf.ones(1)*1)\r\n    training_functions.append((w, b))\r\n    state = S_t[:, i]\r\n    feature_0 = tf.pow(state,0)\r\n    feature_1 = tf.pow(state,1)\r\n    feature_1_mean = tf.reduce_mean(feature_1)\r\n    feature_1_std = tf.sqrt(tf.reduce_sum(tf.square(feature_1 - feature_1_mean))/(N_samples_pricing+1))\r\n    feature_1_norm = (feature_1 - feature_1_mean) / feature_1_std\r\n    feature_2 = 2*tf.pow(state,2)-1\r\n    feature_2_mean = tf.reduce_mean(feature_2)\r\n    feature_2_std = tf.sqrt(tf.reduce_sum(tf.square(feature_2 - feature_2_mean))/(N_samples_pricing+1))\r\n    feature_2_norm = (feature_2 - feature_2_mean) / feature_2_std\r\n    feature_3 = 4*tf.pow(state,3)-3*feature_1\r\n    feature_3_mean = tf.reduce_mean(feature_3)\r\n    feature_3_std = tf.sqrt(tf.reduce_sum(tf.square(feature_3 - feature_3_mean))/(N_samples_pricing+1))\r\n    feature_3_norm = (feature_3 - feature_3_mean) / feature_3_std\r\n    features = tf.stack([feature_1_norm, feature_2_norm, feature_3_norm])\r\n    X = tf.transpose(features)\r\n    contValue = tf.add(tf.matmul(X, w),b)\r\n    inMoney = tf.cast(tf.greater(E_t[:,i], 0.), tf.float32)\r\n    exercise = tf.cast(tf.greater(E_t[:,i], contValue[:,0]), tf.float32) * inMoney * (1-previous_exercises)\r\n    previous_exercises += exercise\r\n    npv += exercise*E_t[:,i]\r\n\r\ni=number_call_dates-1\r\n\r\n(w, b) = training_functions[i]\r\ny = E_t[:, i+1:i+2]\r\nX = S_t[:, i]\r\n\r\nX = tf.stack([X**1, 2*X**2-1, 4*X**3 - 3 * X], axis=1)\r\n\r\nX = (X - tf.reduce_mean(X, axis=0)) / tf.math.reduce_std(X, axis=0)\r\n\r\nepoch = 0\r\n\r\ninput_x = X[E_t[:,i]>0]\r\ninput_y = y[E_t[:,i]>0]\r\ny_hat = tf.Variable(tf.add(tf.matmul(input_x,w), b))\r\npre_error = tf.Variable(tf.pow(input_y-y_hat,2))\r\nerror = lambda: tf.reduce_mean(pre_error)\r\n\r\nopt = tf.keras.optimizers.Adam(learning_rate=0.1)\r\n\r\ntrain = opt.minimize(error, [pre_error])  ### COREDUMP\r\n```\r\n**Note:** I tried to create a simpler coredumpy example like\r\n\r\n```\r\nimport tensorflow as tf\r\nfoo=tf.Variable([[1.,1.]])\r\nfoo=foo[:,2:3]\r\nbar=lambda: foo\r\nopt = tf.keras.optimizers.Adam(learning_rate=0.1)\r\ntrain = opt.minimize(bar, [foo])\r\n```\r\nHowever, this shorter version doesn't coredump, it instead raises the exception\r\n\r\n`AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_in_graph_mode'`\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n[tf_log.txt](https://github.com/tensorflow/tensorflow/files/6797227/tf_log.txt)\r\n", "comments": ["@Saduf2019 ,\r\nI was able to reproduce the issue in tf v2.4,v2.5 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/88a77af10d777c8263540f515001476f/untitled50727.ipynb).", "@catskillsresearch \r\nCan you please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/26922#issuecomment-498812923) and let us know if it helps.", "@Saduf2019 I know I can fix the problem for my purposes by not passing a tensor slice which has a 0-d axis.\r\n\r\nHowever it remains that TF is coredumping in that case, which is reproducible.  Coredump is never a good way to raise an exception.  There should be some checking somewhere in the process so that if it is likely to coredump on a tensor with a 0-d axis, then it raises an exception instead."]}, {"number": 50726, "title": "Print a warning or error when an empty TFRecord file is used.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\nThis is a feature request in the sense that it's asking for a new functionality to make a scenario not fail silently. Not a substantial feature for TF, just a quality of life change.\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nMany people use TFRecord generation scripts that fail silently if they can't find images and generate empty TFRecords. When Tensorflow encounters empty TFRecords, it fails silently, leaving users confused:\r\n\r\nhttps://github.com/tensorflow/models/issues/9581\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAll new users\r\n\r\n**Any Other info.**\r\n", "comments": []}, {"number": 50714, "title": "RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 13 (FlexRandomStandardNormal) failed to prepare.", "body": "hi\r\n\r\ni use colab to train and  save an VAE model (use default colab environment ,tensorflow version is 2.5.0)\r\ni want deploy model on jetson nano ,\r\ni install tflite_runtime version is  2.5.0 \r\n\r\nwhen running(  interpreter.allocate_tensors() ) error come:\r\n\r\nusr/bin/python3 /home/jz/Desktop/test/demo/testTFLiteRuntime.py\r\nTraceback (most recent call last):\r\nFile \"/home/jz/Desktop/test/demo/testTFLiteRuntime.py\", line 6, in <module>\r\ninterpreter.allocate_tensors()\r\nFile \"/home/jz/.local/lib/python3.6/site-packages/tflite_runtime/interpreter.py\", line 259, in allocate_tensors\r\nreturn self._interpreter.AllocateTensors()\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 13 (FlexRandomStandardNormal) failed to prepare.\r\n\r\ni think tflite_runtime 2.5.0 is supported RandomStandardNormal op\r\nso i don't know what i missing...\r\n\r\nedit:\r\nin colab enviroment,\r\ni install tflite_runtime 2.5.0  and test \r\ninterpreter init well and allocate_tensors() run well too \r\n\r\nhttps://stackoverflow.com/questions/68341183/jetson-nano-install-tflite-runtime-2-5-0-didt-supported-randomstandardnormal-op\r\n\r\nthank you for any help~!!\r\n", "comments": []}, {"number": 50713, "title": "tf.math.segment_sum XLA", "body": "tf.math.unsorted_segment_sum works on XLA (jit_compile=True), but tf.math.segment_sum is reported as missing op.\r\nIs it possible to implement tf.math.segment_sum on XLA?", "comments": []}, {"number": 50705, "title": "tf.saved_model.save() much slower than tf.compat.v1.saved_model.loader.load()", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: Ubuntu 18.04.5 LTS\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.3.2\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: 11.1.74 / 8.0.5\r\n- GPU model and memory: NVidia Tesla V100-SXM2-32GB\r\n\r\n**Describe the current behavior**\r\nTo load a `tf.Module` saved with `tf.saved_model.save()`, `tf.saved_model.load()` is much slower than `tf.compat.v1.saved_model.loader.load()`\r\n(4x slower in the attached colab)\r\n\r\n**Describe the expected behavior**\r\nShould be approximately the same time.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1baHS4efEYUP_BCvP8OzStMe9zv92vQhs?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nWe have strict latency requirements and need to use `tf.compat.v1.saved_model.loader.load()`, extract operations and tensors from the graph to use `session.run()` to meet them.\r\n\r\nThe same was observed with TF2.5.0", "comments": ["@jvishnuvardhan ,\r\nI was able to reproduce the issue in tf [v2.4](https://colab.research.google.com/gist/tilakrayal/7ab322cbb7d7dd770b165ed1af3ebdd1/2-4latency_of_loading_saved_model.ipynb),[v2.5](https://colab.research.google.com/gist/tilakrayal/bfe2a0d3d9eeacfde723419c7ae67c7d/2-5latency_of_loading_saved_model.ipynb) and nightly.Please find the gist here."]}, {"number": 50695, "title": "TFLite Variable Batch Size for Models", "body": "Lets say my TFLite Model (mobilenet_v1) whose size is [1,224,224,3] where 1 is batch size.\r\n\r\nI want to run for batch size 2. \r\n\r\n```\r\nl = np.ones((2,224,224,3), dtype = 'float32');\r\ninterpreter.reset_all_variables()\r\ninterpreter.resize_tensor_input(0, [2, 224, 224, 3])\r\ninterpreter.allocate_tensors()\r\ninterpreter.set_tensor(input_details[0][\"index\"], l)\r\ninterpreter.invoke()\r\n```\r\n\r\nWill the code I mentioned works for any TFLite model irrespective of any operations involved in model ?\r\nCan I rely on the code for any TFLite Model ?\r\n\r\n\r\nI got issue with Variable sequence length for few models. So wanted to confirm whether the same issue holds for variable batch size . \r\nVariable Sequence length is not supported for few operations - https://github.com/tensorflow/tensorflow/issues/44819 (confirmed from this issue).\r\nSo needed a confirmation regarding the support of variable batch size and usage of the code I mentioned.\r\n", "comments": ["Needed update "]}, {"number": 50691, "title": "Custom training and and inference functions defined outside k-fold loop cause FailedPreconditionError", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.9.6\r\n- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.29)\r\n\r\nI am not running this code on a GPU on my personal computer, but a colleague has run it on a computer with an NVIDIA card and has confirmed this error.\r\n\r\n**Describe the current behavior**\r\nI have implemented k-fold cross-validation for use on a custom Tensorflow model (extending tf.keras.Model). At the start of each loop the model is instantiated, the weights are initialised (with `model.build()`) and so is the Adam optimiser, since it has its own learned variables. The `_train_step` and `_inference_step` functions are called outside the fold while-loop since they are the same for each model and Tensorflow warns that retracing is an expensive process.\r\n\r\nThe code throws a `FailedPreconditionError`, however, complaining of some variable being missing. It is never the same variable.\r\n\r\nThe error disappears when I enable eager execution, by which I mean that I comment out the decorator `@tf.function` and use gradient tape.\r\n\r\n**Describe the expected behavior**\r\nI expect that this error wouldn't be thrown, and that I wouldn't have to redefine the aforementioned functions each time the loop is called.\r\n\r\n**Standalone code to reproduce the issue**\r\n[Working and faulty code.](https://colab.research.google.com/drive/1mUKEOcQqGYX4YC-mrX1WgzWHbLL5JpXL?usp=sharing)\r\n\r\n**Other info / logs**\r\n```\r\npython3.9/bin/python3.9 \"training_example.py\"\r\n2021-07-09 11:25:50.103064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-07-09 11:25:50.957307: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\nfold 0: epoch 1: train_loss: 0.99761 train_prec: 1.00000 train_recall: 0.30856\r\nfold 0: epoch 1: val_loss: 0.98867 val_prec: 1.00000 val_recall: 0.23142\r\nfold 0: epoch 2: train_loss: 0.99167 train_prec: 1.00000 train_recall: 0.13224\r\nfold 0: epoch 2: val_loss: 0.98676 val_prec: 1.00000 val_recall: 0.11571\r\nTraceback (most recent call last):\r\n  File \"training_example.py\", line 118, in <module>\r\n    for batch_features, batch_labels in training_set: _train_step(batch_features,\r\n  File \"python3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"python3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"python3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3023, in __call__\r\n    return graph_function._call_flat(\r\n  File \"python3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"python3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"python3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError:  Could not find variable _AnonymousVar13. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar13/N10tensorflow3VarE does not exist.\r\n\t [[node test_model/dense_2/Tensordot/ReadVariableOp (defined at training_example.py:32) ]] [Op:__inference__train_step_1082]\r\n\r\nFunction call stack:\r\n_train_step\r\n```", "comments": ["@Saduf2019 ,\r\nI was able to to reproduce the issue in tf [v2.4](https://colab.research.google.com/gist/tilakrayal/f288a30344ae20134e81bc3bb5aefed8/2-4broken_training_example.ipynb) and [v2.5](https://colab.research.google.com/gist/tilakrayal/4db737ebdfb6e35835ebc811a3097076/2-5broken_training_example.ipynb).Please find the gist here."]}, {"number": 50689, "title": "\"RuntimeError: Division by 0Node number 1252 (FLOOR_MOD) failed to invoke.\" after conversion from TensorFlow to tflite", "body": "### 1. System information\r\n\r\n-    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n-    TensorFlow installation (pip package or built from source): `tb-nightly==2.6.0a20210706` installed via pip\r\n\r\n\r\n### 2. Code\r\n\r\nI am trying to convert a model from Pytorch -> ONNX -> Tensorflow -> tflite. The conversion works, but the results diverge between Tensorflow and tflite.\r\n\r\nThe original model is a Faster-RCNN with a MobileNet backbone (`fasterrcnn_mobilenet_v3_large_320_fpn` to be exact). I am having a similar, but different issue when converting the same model with a Resnet backbone (see my other issue for that: https://github.com/tensorflow/tensorflow/issues/50676 )\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# tensorflow inference: works\r\nmodel_tf = tf.saved_model.load('assets/tfsavedmodel')\r\nsample = np.zeros((1, 3, 256, 256), dtype=np.float32)\r\nmodel_tf(input=sample)  #works\r\n\r\n# tflite inference: fails\r\ninterpreter = tf.lite.Interpreter('assets/model.tflite')\r\nprint(interpreter.get_input_details()[0]['shape'])  # array([  1,   3, 256, 256], dtype=int32)\r\nmodel_tflite = interpreter.get_signature_runner()\r\nout_tflite = model_tflite(input=sample)\r\n```\r\n\r\nFails with error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/convert.py\", line 375, in <module>\r\n    Converter().verify()\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/convert.py\", line 371, in verify\r\n    verify_tflite(self.target_dir/self.fname_tflite, x)\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/convert.py\", line 45, in verify_tflite\r\n    output = signature(input=tf.constant(np.zeros_like(sample)))  # FIXME: get actual sample in\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/venv/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py\", line 239, in __call__\r\n    self._interpreter.invoke()\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/venv/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py\", line 905, in invoke\r\n    self._interpreter.Invoke()\r\nRuntimeError: Division by 0Node number 1252 (FLOOR_MOD) failed to invoke.\r\n```\r\n\r\nModel files mentioned can be found here: https://florianletsch.de/media/assets-tflite.zip (468 MB)\r\n\r\nThis is how I converted the model (note that this takes >1hr, not sure why)\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('assets/tfsavedmodel')\r\nconverter.experimental_enable_resource_variables = True  # requires tf-nightly or tf-nightly-cpu\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS,\r\n  tf.lite.OpsSet.SELECT_TF_OPS\r\n]\r\n\r\ntflite_model = converter.convert()\r\nwith open('assets/model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n\r\n### 3. Failure after conversion\r\n\r\n- Conversion works but model can't be loaded for inference, see error message above.\r\n\r\n### Environment \r\n\r\nOutput of `pip freeze`\r\n\r\n```\r\nabsl-py==0.13.0\r\nastunparse==1.6.3\r\ncachetools==4.2.2\r\ncertifi==2021.5.30\r\nchardet==4.0.0\r\nflatbuffers==1.12\r\ngast==0.4.0\r\ngoogle-auth==1.32.1\r\ngoogle-auth-oauthlib==0.4.4\r\ngoogle-pasta==0.2.0\r\ngrpcio==1.38.1\r\nh5py==3.1.0\r\nidna==2.10\r\nkeras-nightly==2.6.0.dev2021062500\r\nKeras-Preprocessing==1.1.2\r\nlibclang==12.0.0\r\nMarkdown==3.3.4\r\nnetron==5.0.0\r\nnumpy==1.19.2\r\noauthlib==3.1.1\r\nonnx==1.9.0\r\nonnx-tf==1.8.0\r\nonnxruntime==1.8.0\r\nopt-einsum==3.3.0\r\nPillow==8.3.1\r\nprotobuf==3.17.3\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\nPyYAML==5.4.1\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7.2\r\nsix==1.15.0\r\ntb-nightly==2.6.0a20210706\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorflow-addons==0.13.0\r\ntermcolor==1.1.0\r\ntf-estimator-nightly==2.6.0.dev2021062501\r\ntf-nightly-cpu==2.7.0.dev20210706\r\ntorch==1.9.0\r\ntorchvision==0.10.0\r\ntypeguard==2.12.1\r\ntyping-extensions==3.7.4\r\nurllib3==1.26.6\r\nWerkzeug==2.0.1\r\nwrapt==1.12.1\r\n```\r\n", "comments": ["@thaink Can you take a look at this?"]}, {"number": 50687, "title": "Failed to convert mhlo dialect to Linalg dialect when the layout of Conv2d is NCHW", "body": "I want to convert the conv2d operator from mhlo to linalg dialect. It seems like that it can't process the situation when the  layout of conv2d is NCHW.\r\nThe mhlo dialect of conv2d.mlir is shown below:\r\n```\r\nmodule  {\r\n  func @main(%arg0: tensor<64x3x7x7xf32>, %arg1: tensor<1x3x224x224xf32>) -> tuple<tensor<1x64x112x112xf32>> {\r\n    %0 = \"mhlo.convolution\"(%arg1, %arg0) {batch_group_count = 1 : i64, dimension_numbers = {input_batch_dimension = 0 : i64, input_feature_dimension = 1 : i64, input_spatial_dimensions = dense<[2, 3]> : tensor<2xi64>, kernel_input_feature_dimension = 1 : i64, kernel_output_feature_dimension = 0 : i64, kernel_spatial_dimensions = dense<[2, 3]> : tensor<2xi64>, output_batch_dimension = 0 : i64, output_feature_dimension = 1 : i64, output_spatial_dimensions = dense<[2, 3]> : tensor<2xi64>}, feature_group_count = 1 : i64, lhs_dilation = dense<1> : tensor<2xi64>, padding = dense<3> : tensor<2x2xi64>, precision_config = [\"DEFAULT\", \"DEFAULT\"], rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x3x224x224xf32>, tensor<64x3x7x7xf32>) -> tensor<1x64x112x112xf32>\r\n    %1 = \"mhlo.tuple\"(%0) : (tensor<1x64x112x112xf32>) -> tuple<tensor<1x64x112x112xf32>>\r\n    return %1 : tuple<tensor<1x64x112x112xf32>>\r\n  }\r\n}\r\n```\r\nI use \"./mlir-hlo-opt ./conv2d.mlir -hlo-legalize-to-linalg -o conv2d_linalg.mlir\" to do the transformation.\r\nI traced the workflow and found out when it checks \"HasCanonicalDimensionNumbers()\", it returns false.\r\n[legalize_to_linalg.cc:1771](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/legalize_to_linalg.cc#L1771)\r\n```\r\n  if (dimension_numbers.input_batch_dimension().getInt() != 0 ||\r\n      dimension_numbers.input_feature_dimension().getInt() !=\r\n          (input_spatial_rank + 1)) {\r\n    return false;\r\n  }\r\n```", "comments": [" The input with input size (NCHW), filter (FCHW), I've checked [Linalg Dialect - MLIR](https://mlir.llvm.org/docs/Dialects/Linalg/#linalg), \r\n[linalg.conv_2d_input_nchw_filter_hwcf](https://mlir.llvm.org/docs/Dialects/Linalg/#linalgconv_2d_input_nchw_filter_hwcf-mlirlinalgconvinputnchwfilterhwcfop) supports NCHW input, but the filter should be HWCF, also it doesn't support padding according to the description of Interface; \r\nThen I saw these Interface: [linalg.conv_2d_nchw](https://mlir.llvm.org/docs/Dialects/Linalg/#linalgconv_2d_nchw-mlirlinalgconvnchwop) and [linalg.conv](https://mlir.llvm.org/docs/Dialects/Linalg/#linalgconv-mlirlinalgconvop). I'm not sure which one is better for supporting Conv2D with input (NCHW) and filter (FCHW).\r\nMaybe we need to add some transpose OPs for supporting it. I'm not familiar with Linalg. This is just my thought, not sure if it is correct.\r\n", "@hanhanW : wanna chime in here?", "> @hanhanW : wanna chime in here?\r\nOk, if it is convenient for you.\r\n", "Sure, I'm happy to! We've been experimenting conv op in IREE repo. In that time, we only see this form of convolution. So only it is supported when we upstream the pattern.\r\nPlease do not use linalg.conv op because\r\n\r\n- It only works on memrefs.\r\n- Padding attribute would stop many opportunities of Linalg transforms. E.g., we are not able to fuse operations if it has padding attributes.\r\n- It should be deprecated at some point.\r\n- ETC\r\n\r\nThere are couple options to support conv_2d_input_nchw_filter_hwcf op.\r\n\r\n1) You can create a pass to legalize the conv op to such form, like inserting some transpose op before/after the conv op, and recreate the conv op. (Because the dim numbers would be different.)\r\n\r\n2) Add a linalg.conv_2d_input_nchw_filter_hwcf to Linalg dialect, and add a pattern to lower the conv op to Linalg ops.\r\n - We added the operation to TC files while yaml gen was in progress. Now you can follow the [doc](https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/) to add the operation to yaml file.\r\n \r\n\r\nFor padding attribute, IREE has a pass to extract the padding attributes to a mhlo.pad op. You can either add a similar pass to your pipeline, or create a linalg.pad_tensor op when there are padding attributes. The latter approach make more sense to me.", "Thank you very much for your detailed suggestions! I'll try it."]}, {"number": 50681, "title": "Provide XLA as a standalone library", "body": "**System information**\r\n- TensorFlow version (you are using): n/a\r\n- Are you willing to contribute it (Yes/No): Maybe, depends on the complexity of the problem (my C++ knowledge is minimal).\r\n\r\n**Describe the feature and the current behavior/state.**\r\nXLA is packaged with TensorFlow. I'd like to be able to install it as a standalone library.\r\n\r\n**Will this change the current api? How?**\r\nI don't really know. It may change the location of XLA files, but not the functionality itself.\r\n\r\n**Who will benefit with this feature?**\r\nPeople using XLA without TensorFlow, such as (possibly) JAX, but also my (far smaller) project.", "comments": ["This would be useful for me, as well.", "This would also be useful for me! We want to use XLA for a research project.", "for those who want something now, have a look at [elixir-nx/xla](https://github.com/elixir-nx/xla), see [this comment](https://github.com/google/jax/issues/2861#issuecomment-920410280)"]}, {"number": 50676, "title": "\"Given shapes (...) are not broadcastable\" after conversion from tensorflow to tflite", "body": "### 1. System information\r\n\r\n-    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n-    TensorFlow installation (pip package or built from source): `tb-nightly==2.6.0a20210706` installed via pip\r\n\r\n\r\n### 2. Code\r\n\r\nI am trying to convert a model from Pytorch -> ONNX -> Tensorflow -> tflite. The conversion works, but the results diverge between Tensorflow and tflite.\r\n\r\nThe original model is a Faster-RCNN with a ResNet backbone (`torchvision.models.detection.fasterrcnn_resnet50_fpn` to be exact).\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# tensorflow inference: works\r\nmodel_tf = tf.saved_model.load('assets/tfsavedmodel')\r\nsample = np.zeros((1, 3, 256, 256), dtype=np.float32)\r\nmodel_tf(input=sample)  #works\r\n\r\n# tflite inference: fails\r\ninterpreter = tf.lite.Interpreter('model-conversion/assets/model.tflite')\r\nmodel_tflite = interpreter.get_signature_runner()\r\nout_tflite = model_tflite(input=sample)\r\n```\r\n\r\nFails with error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/venv/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py\", line 231, in __call__\r\n    self._interpreter.allocate_tensors()\r\n  File \"/home/florian/projects/video-analysis-prototype/model-conversion/venv/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py\", line 453, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\nRuntimeError: Given shapes, [1, 199, 199, 256] and [1, 200, 200, 256], are not broadcastable.Node number 365 (ADD) failed to prepare.\r\n```\r\n\r\nModel files mentioned can be found here: https://florianletsch.de/media/assets-tflite.zip (468 MB)\r\n\r\nThe model was converted following the answer on that issue: https://github.com/tensorflow/tensorflow/issues/50635\r\n**Conversion code** (full conversion code:  https://github.com/florianletsch/torch2tflite-failing):\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('assets/tfsavedmodel')\r\nconverter.experimental_enable_resource_variables = True  # requires tf-nightly or tf-nightly-cpu\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS,\r\n  tf.lite.OpsSet.SELECT_TF_OPS\r\n]\r\n\r\ntflite_model = converter.convert()\r\nwith open('assets/model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n\r\n### 3. Failure after conversion\r\n\r\n- Conversion works but model can't be loaded for inference, see error message above.\r\n\r\n### Environment \r\n\r\nOutput of `pip freeze`\r\n\r\n```\r\nabsl-py==0.13.0\r\nastunparse==1.6.3\r\ncachetools==4.2.2\r\ncertifi==2021.5.30\r\nchardet==4.0.0\r\nflatbuffers==1.12\r\ngast==0.4.0\r\ngoogle-auth==1.32.1\r\ngoogle-auth-oauthlib==0.4.4\r\ngoogle-pasta==0.2.0\r\ngrpcio==1.38.1\r\nh5py==3.1.0\r\nidna==2.10\r\nkeras-nightly==2.6.0.dev2021062500\r\nKeras-Preprocessing==1.1.2\r\nlibclang==12.0.0\r\nMarkdown==3.3.4\r\nnetron==5.0.0\r\nnumpy==1.19.2\r\noauthlib==3.1.1\r\nonnx==1.9.0\r\nonnx-tf==1.8.0\r\nonnxruntime==1.8.0\r\nopt-einsum==3.3.0\r\nPillow==8.3.1\r\nprotobuf==3.17.3\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\nPyYAML==5.4.1\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7.2\r\nsix==1.15.0\r\ntb-nightly==2.6.0a20210706\r\ntensorboard-data-server==0.6.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorflow-addons==0.13.0\r\ntermcolor==1.1.0\r\ntf-estimator-nightly==2.6.0.dev2021062501\r\ntf-nightly-cpu==2.7.0.dev20210706\r\ntorch==1.9.0\r\ntorchvision==0.10.0\r\ntypeguard==2.12.1\r\ntyping-extensions==3.7.4\r\nurllib3==1.26.6\r\nWerkzeug==2.0.1\r\nwrapt==1.12.1\r\n```\r\n", "comments": ["@wangtz Re-assigning to support rotation. \r\n\r\nInitial debugging:\r\nPossible issues:\r\n1. TF model - Not possible (the model works as shows by the user)\r\n2. TFLite model (error during conversion)- Possible. It looks there is an issue with the TFLite model itself as the interpreter is unable to allocate tensors. \r\n3. TF and TFLite model input - Not possible. Unlike similar issues that have the same error (eg: #46686), in this issue the TF & TFLite model input type is correct. (Refer to below code snippet (the commented print and Output statements)).\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# # tensorflow inference: works\r\nmodel_tf = tf.saved_model.load('gdrive/MyDrive/Colab Notebooks/tfsavedmodel')\r\n# print(\"TF model Input shape: \", model_tf.signatures['serving_default'].structured_input_signature[1]['input'])\r\n# Output: TensorSpec(shape=(None, 3, 256, 256), dtype=tf.float32, name='input')\r\nsample = np.zeros((1, 3, 256, 256), dtype=np.float32)\r\nmodel_tf(input=sample)  #works\r\n\r\n# tflite inference: fails\r\ninterpreter = tf.lite.Interpreter('model.tflite')\r\n# print(\"TFLite model input shape: \", interpreter.get_input_details()[0]['shape'])\r\n# Output: [  1   3 256 256]\r\ninterpreter.allocate_tensors() \r\n# Fails here with error: RuntimeError: Given shapes, [1, 199, 199, 256] and [1, 200, 200, 256], are not broadcastable.Node number 365 (ADD) failed to prepare.\r\n# model_tflite = interpreter.get_signature_runner()\r\n# out_tflite = model_tflite(input=sample)\r\n```\r\n\r\n", "I managed to reproduce this issue in https://colab.research.google.com/drive/1B88EAjAvXw0RKhM_mDN6OEbWznLfcz2_#scrollTo=7ZG29GucZ6J6\r\n\r\n\r\nThe model seems to be alright. Node 365 has both input tensors with shape [1, 200, 200, 256] \r\nI didn't find where 199 is coming from. My best guess is that some where in the Prepare method, the shape was changed incorrectly.\r\n\r\n<img width=\"999\" alt=\"Screen Shot 2021-07-26 at 7 51 55 PM\" src=\"https://user-images.githubusercontent.com/34290063/126984391-ea92e23d-01a6-4c9f-8269-67d14bd3de05.png\">\r\n\r\n"]}, {"number": 50662, "title": "transpose op code behavior mismatch with comments in xla", "body": "tensorflow 1.15.5\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.15.5/tensorflow/compiler/xla/service/shape_inference.cc#L2740\r\n\r\n```c++\r\n  // Permute(dimensions,input) computes output[dimensions[i]]=input[i]. However,\r\n  // we need output[i]=input[dimensions[i]] which is\r\n  // Permute(Inverse(dimensions),input).\r\n  return ShapeUtil::PermuteDimensions(InversePermutation(dimensions), operand);\r\n```\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.15.5/tensorflow/compiler/xla/util.h#L340\r\n\r\n```c++\r\n// Applies `permutation` on `input` and returns the permuted array.\r\n// For each i, output[permutation[i]] = input[i].\r\n//\r\n// Precondition:\r\n// 1. `permutation` is a permutation of 0..permutation.size()-1.\r\n// 2. permutation.size() == input.size().\r\ntemplate <typename Container>\r\nstd::vector<typename Container::value_type> Permute(\r\n    absl::Span<const int64> permutation, const Container& input) {\r\n  using T = typename Container::value_type;\r\n  absl::Span<const T> data(input);\r\n  CHECK(IsPermutation(permutation, data.size()));\r\n  std::vector<T> output(data.size());\r\n  for (size_t i = 0; i < permutation.size(); ++i) {\r\n    output[permutation[i]] = data[i];\r\n  }\r\n  return output;\r\n}\r\n```\r\n\r\nmy question is \r\naccoding to the comments, **if using inverse permutation, we should use output[i]=input[dimensions[i]].**\r\n**but, code still use  output[dimensions[i]]=input[i].**\r\n\r\nseems like a bug or mismatch?\r\nI checked latest code, this is still there, but inverse moved to other place.\r\nso I used 1.15.5, as the inverse code is together with permute.\r\n\r\n\r\n\r\nBR.\r\nMingting\r\n\r\n", "comments": ["@hawkinsp can you help to check this?"]}, {"number": 50658, "title": "Tensorflow 2.3.x link error when use delay load", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 / Visual Studio 2017\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0~2.3.3\r\n- Python version: N/A\r\n- CUDA/cuDNN version: cuda 10.1 cudnn 7.6.5\r\n- GPU model and memory: NVIDIA Quadro P4000\r\n\r\n**Describe the current behavior**\r\nI try to use delay load tensorflow and it work for TF 1.15.0 and 2.4.0 but not for all 2.3.x version.\r\nNote I need stick with TF 2.3.x and error in build Release not Debug\r\nGet link error as:\r\nError\tLNK1194\tcannot delay-load 'tensorflow.dll' due to import of data symbol '__imp_TF_DeleteStatus'; link without /DELAYLOAD:tensorflow.dll\r\n\r\n`\r\n#include <windows.h>\r\n#include <delayimp.h>\r\n#include <mutex>\r\n\r\nnamespace\r\n{\r\n    bool tf_useGPU = true;// true;\r\n    bool tf_dllLoaded = false;\r\n\r\n    FARPROC WINAPI DelayLoadHook(unsigned dliNotify, PDelayLoadInfo pdli)\r\n    {\r\n        switch (dliNotify)\r\n        {\r\n            //case dliNotePreLoadLibrary:\r\n        case dliFailLoadLib:\r\n            if (lstrcmpiA(pdli->szDll, \"tensorflow.dll\") == 0)\r\n            {\r\n                FARPROC p = NULL;\r\n                if (tf_useGPU)\r\n                {\r\n                    // Disable the error window if the dll cannot be loaded\r\n                    // Save the original mode and restore it after the load\r\n                    UINT origin_mode = SetErrorMode(SEM_FAILCRITICALERRORS);\r\n\r\n                    // Load the dll\r\n                    p = (FARPROC)LoadLibraryA(\"tensorflow_gpu.dll\");\r\n\r\n                    // Restore the original mode.\r\n                    SetErrorMode(origin_mode);\r\n\r\n                    if (p)\r\n                    {\r\n                        std::cout << \"TensorFlow GPU dll loaded\\n\" << std::endl;\r\n                    }\r\n                }\r\n\r\n                if (!p)\r\n                {\r\n                    p = (FARPROC)LoadLibraryA(\"tensorflow_cpu.dll\");\r\n\r\n                    if (p)\r\n                    {\r\n                        std::cout <<\"TensorFlow CPU dll loaded\\n\" << std::endl;\r\n                    }\r\n                }\r\n\r\n                tf_dllLoaded = p != NULL;\r\n\r\n                return p;\r\n            }\r\n        default:\r\n            return NULL;\r\n        }\r\n\r\n        return NULL;\r\n    }\r\n\r\n    extern \"C\" const PfnDliHook __pfnDliFailureHook2 = DelayLoadHook;\r\n}\r\n\r\nvoid LoadTensorFlow(int iGPUOption)\r\n{\r\n    // dll can only be loaded once\r\n    if (tf_dllLoaded)\r\n    {\r\n        assert(0);\r\n        return;\r\n    }\r\n    tf_useGPU = iGPUOption != 0;\r\n\r\n    // Call any tensorflow function to trigger the dll load\r\n    const char* version = TF_GetVersion();\r\n}\r\n`\r\n\r\n**Describe the expected behavior**\r\nLink without error as other version of Tensorflow.", "comments": ["Can you please try building TF with MSVC 2019 as mentioned in this tested build configurations chart\r\nhttps://www.tensorflow.org/install/source_windows#cpu Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi,\r\nThis issue because of download file directly from tensorflow website.\r\nAnd I compiled with vs 2017 without issue. Because of QA we need to use release from tensorflow website.\r\n", "I am sorry but I don't think I follow.  Can you please elaborate how you solved the issue? ", "I am using the dll/lib provided on the web site directly (C API - https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-windows-x86_64-2.3.0.zip). We also do not have access to VS2019 to try in production. We are working with VS2017 (sorry I mistook my above comment this is tensorflow 2.4.1 and vs 2019 on my personal computer). I did build the dll/lib myself and I am getting the same issue than the downloaded files. We want to use the pre-built files for production.\r\n\r\nThe problem is not solved, I am still getting the linker error regardless if I used downloaded files or built.\r\n"]}, {"number": 50656, "title": "Which is the smallest SSD model to use in a MCU like ESP-EYE and using tensorflow lite micro?", "body": "Hi,\r\n\r\nI am trying to work with the smallest SSD model of tensorflow, but my problem is that I am working with an [ESP-EYE](https://www.espressif.com/en/products/devkits/esp-eye/overview) and this MCU has only 4 MB of memory.\r\n\r\nAll SSD models that I saw in the [pretrained models Garden of tensorflow](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md), are too big (more than 4 MB) or they dont have a \".tflite\" file. \r\nIn this last case, I saw that there is a way to convert the file \".pb\" to \".tflite\" [HERE](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/r1/convert/python_api.md#convert-a-frozen-graphdef-from-file-) and a video where explain which parameters you must use [VIDEO](https://youtu.be/EAE-vjL2Nps?t=238), but the size of the files increase a lot.\r\nFor example, if the size of a \".pb\" file is 5 MB, the conversion makes a file of 25 MB and things like this.\r\n\r\nHere is a example of the code in python that I use for the conversion:\r\n\r\n\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# Convert the model.\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\r\n    graph_def_file='tflite/tflite_graph.pb', # Dir of the \".pb\" file\r\n    input_arrays=['normalized_input_image_tensor'],\r\n    input_shapes={'normalized_input_image_tensor' : [1, 300, 300,3]}, # Shape of the images of the model you will need to change the 300 and 300\r\n    output_arrays=['TFLite_Detection_PostProcess', 'TFLite_Detection_PostProcess:1', 'TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'],\r\n)\r\nconverter.allow_custom_ops=True\r\n\r\n# converter.quantized_input_stats = {'input' : (0., 1.)}  # mean, std_dev (input range is [-1, 1])\r\n# converter.inference_type = tf.int8 # this is the recommended type.\r\n# converter.inference_input_type=tf.uint8 #optional\r\n# converter.inference_output_type=tf.uint8 #optional\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('quantized_model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\nSoo my questions are:\r\n\r\n1. Do you know some SSD model with a size less than 4 MB, for example, 3MB or 2MB, with the capability to detect persons?\r\n2. Is posible to work with a SSD model and make the \"Invoke\"(prediction) of the model in the ESP-EYE or is a lot of work for a MCU?\r\nI found some documentation, but I\u00b4m not sure if it works:\r\n- [Documentation of tensorflow](https://github.com/tensorflow/tflite-support/tree/master/tensorflow_lite_support/cc/task#object-detector)\r\n- [Code](https://github.com/tensorflow/tflite-support/tree/master/tensorflow_lite_support/cc/task#object-detector)\r\n\r\nThanks for read and have a good day.\r\n\r\nSee you XD\r\n", "comments": ["Did you refer person detection example for tf lite micro to get some pointers?\r\nhttps://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/person_detection/training_a_model.md", "Hi,\r\n\r\nI saw that tutorial, but they explain how to train a classification model where the model can say if there is a person in the image, but not how many.\r\nIn my case, I would need a very lite SSD model(less than 2MB or 1MB), that can detected multiple objects in the same image, specifically people.\r\n", "Hi,\r\n\r\nMy main question is:\r\n\r\nCould I work with an object detection model in a MCU like ESP-EYE, with 4MB of size, using TFLiteMicro or TFLiteMicro only can support object classification models, like this [example](https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/person_detection#running-on-esp32)? \r\n\r\nBecause all object detection models that I saw are more heavy than 4MB.\r\n\r\nSee you XD"]}, {"number": 50654, "title": "Tensorflow int32 matmul slower than float32 matmul", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.4\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nv1.15.3-68-gdf8c55c 1.15.4\r\n\r\n**Describe the current behavior**\r\nint32 matmul is almost twice as slow as float32 matmul for large-ish matrices.\r\n\r\n**Describe the expected behavior**\r\nint32 multiplication is typically faster on CPU, so I expect matmul speed should be at least close to that of float32. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport time\r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\nfor dtype in [tf.float32, tf.int32, tf.float32, tf.int32]:\r\n  a = tf.constant([list(range(int(1e6), int(1e6) + 1024)) for _ in range(1024)], dtype=dtype)\r\n  start = time.time()\r\n  with tf.Session() as sess:\r\n    for _ in range(100):\r\n        sess.run(tf.matmul(a, a))\r\n  end = time.time()\r\n  print(dtype, end - start)\r\n```\r\nprint result:\r\n\r\n> <dtype: 'float32'> 5.6830058097839355\r\n> <dtype: 'int32'> 7.759643077850342\r\n> <dtype: 'float32'> 3.646965742111206\r\n> <dtype: 'int32'> 8.087013483047485\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@yunjiangster ,\r\n\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to 2.x and let us know if you are using same issue.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@tilakrayal I tried this on tf2.5 (latest from pip packages) and the same issue persists and in fact much worse:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport time\r\nfor dtype in [tf.float32, tf.int32, tf.float32, tf.int32]:\r\n  a = tf.constant([list(range(int(1e6), int(1e6) + 1024)) for _ in range(1024)], dtype=dtype)\r\n  start = time.time()\r\n  for _ in range(100):\r\n    tf.matmul(a, a)\r\n  end = time.time()\r\n  print(dtype, end - start)\r\n```\r\n\r\n> <dtype: 'float32'> 0.3444669246673584\r\n> <dtype: 'int32'> 2.04129958152771\r\n> <dtype: 'float32'> 0.2095959186553955\r\n> <dtype: 'int32'> 2.0492682456970215", "@rmothukuru ,\r\nI was able to reproduce the issue in tf v2.4,v2.5 and nightly.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/22cdd66c42b58dc3d2a09e1b6aaec601/untitled50654.ipynb).", "If this is running on CPU via Eigen, note that Eigen has optimized implementations for float that uses explicit AVX simd instructions.  This is not currently implemented for int32 (though there is an MR [here](https://gitlab.com/libeigen/eigen/-/merge_requests/489))."]}, {"number": 50649, "title": "same host memory address copy tensor to different device memory address", "body": "I have a question. I export TF_CPP_MIN_VLOG_LEVEL=3 want to dump the log, then I find something I can't understand. I saw tensorflow from the same host memory address copy tensor to different device memory address, I want to know why does tensor flow do this? What are the advantages?\r\nI think it will rely on CUDA Events for synchronization. Why not from different host memory  address?  \r\nLooking forward to a reply.\r\n\r\n![tf_log](https://user-images.githubusercontent.com/27774893/124728011-d0918c80-df41-11eb-8168-598cf9803599.jpg)\r\n\r\n", "comments": ["There are many possible reasons for this.\r\n\r\nIf you have a beefy machine that can build TensorFlow, I'd suggest rebuilding TF and using a [`CurrentStackTrace`](https://github.com/tensorflow/tensorflow/blob/91ec0d83972d2c73facaf80e0da3c755ff5910e9/tensorflow/core/platform/default/stacktrace.h#L42) call in `ThenMemcpy` to figure out where the copies are coming from."]}, {"number": 50645, "title": "The word vector obtained by the word2vec tutorial is very bad", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/text/word2vec\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI run the word2vec code (without change) from the tutorial. But the word vector from the model is very bad, not reflect the semantic meaning at all.\r\n\r\nHere is the result shown in the embedding projector:\r\n![Selection_002](https://user-images.githubusercontent.com/1263428/124710517-7be51600-df2f-11eb-9dfb-7efd80bedeb6.png)\r\n\r\n", "comments": ["@howl-anderson \r\n\r\nPlease fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Abug&template=00-bug-issue.md)\r\n\r\nCould you please share the code/colab gist that you have implemented.Thanks", "@UsharaniPagadala \r\nI don't think it is a kind of bug of tensorflow, it more like a hyperparameter setting issue.\r\n\r\n> Could you please share the code/colab gist that you have implemented.Thanks\r\n\r\nI  use the jupyter notebook (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb) provided by the tutorial (https://www.tensorflow.org/tutorials/text/word2vec). It will reproduce the result (not reflect the semantic meaning) in the embedding projector.", "@howl-anderson \r\n\r\nCould please open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow)/ Tensorflow discussion [forum](https://discuss.tensorflow.org/) issue as this is not a bug or feature request and move this to closed status.\r\n", "As I said before, it is not a bug of TensorFlow, it is a \"bug\" of the tutorial (something wrong with hyperparameter setting or corpus). I was being told (from tensorflow/docs) if there is an issue in docs, go here to report it. From the users' view, this tutorial is wrong. it is not a bug caused by the user.", "<img width=\"373\" alt=\"Screen Shot 2021-07-09 at 11 16 52 AM\" src=\"https://user-images.githubusercontent.com/42785357/125120336-2d5a8780-e0a7-11eb-980e-b7551ec30819.png\">\r\n\r\n\r\nI see relatively valid results. Can you please try again?\r\nhttp://projector.tensorflow.org/", "Hi @ymodak, Thank your reply. But what you show in the previous comment is not the word embedding view. It is the view that the projector helps you (using edit distance or something) to choose what word do you want to query. It is NOT the query result. After you choose the query word, then it will give some nearest words with scores or distances. Also, Please also notice that we are discussing word embedding from the tutorial at https://www.tensorflow.org/tutorials/text/word2vec. In the tutorial, it using the corpus from Shakespeare's writing. I don't think Shakespeare knows the word \"batman\", which is the one of words in your previous image. It is more likely you are using the default embedding from the http://projector.tensorflow.org/. ", "Also, I have already run the model more than 5 times, every time it gives meanless embedding.", "@ymodak \r\nIs this issue solved in any way? Because even i am getting the same issue of bad word embeddings after trying a lot on different datasets and tuning the hyper-parameters as well.", "@howl-anderson Did you find any solution regarding this? If so please share\r\n@MarkDaoust Could you please help us regarding this, have tried everything around the code but nothing works\r\n", "@enigmaeth\r\n\r\nAfroz you're the original author of this doc, do you have any ideas?"]}, {"number": 50643, "title": "[Adaptation] Indices of SparseTensor should adapt with current indices if (explicitly/implicitly) specified", "body": "**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it (Yes/No):\r\n\r\nI am using TensorFlow version 2.5.0 and try to adapt Sparse Tensor into Deep Learning model. However, interestingly that despite the indices has been specified by numpy, the indices always cast to uint64 despite our trial, even from numpy or tensorflow (tf.convert_to_tensor || tf.constant). As our matrix has its shape (10000, 7465), it is recommended to use uint16 as datatype indices rather than uint64. \r\n\r\nIf indices was pass as Python List or Tuple, casting to uint64 is prefered, but if numpy array as input, it would be great to be modified with respective datatype with equivalent range rather than safely cast to uint64 as input\r\n\r\nThis implementation can help to reduce maximum of computing resources as storing indices may quite costly even if the matrix was not sparse enough. In my case, luckily, the data is uint8 with 2.24 % density so there are no problems about that. \r\n\r\nExample:\r\nCurrent Version: Memory Cost: data (uint8), indices (uint64) -> Memory Cost: 38.08% compared to dense array\r\nThis implementation 1: data (uint8), indices (uint16) -> Memory Cost: 11.02% compared to dense array\r\nThis implementation 2: data (uint8), indices (uint32) -> Memory Cost: 20.16% compared to dense array\r\n\r\nMoreover, it should be possible to make keras.Input(sparse=True) be compatible with Scipy.sparse rather than making warnings", "comments": []}]