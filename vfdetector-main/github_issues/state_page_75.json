[{"number": 17851, "title": "[Feature Request] Multiple GPU Training using Eager Execution", "body": "I'm a starter in eager execution and not familiar in DL framework. However, in practice, multiple GPUs training is an important feature. PyTorch has nn.DataParallel and distributed package to support distributed training. Recently, I'm working on training model using eager execution with multiple gpus, and I have noticed that in https://hn.svelte.technology/item/15595123 @alextp said:\r\n\r\n> We're still fairly early in the project, so _for now threading is the only supported way_.\r\n\r\nI have two questions about it:\r\n1. If there is an example about using threading to train with multiple gpus in eager execution? It will help a lot to starters.\r\n2. I have concerns about performance using threading(only one thread can run python at one time in Cython implementation). Could threading speed up the training process? For example, if I have some python operations betweens tf operations(eg. [*DenseLayer*, *some operations using numpy, python list, etc.*, *DenseLayer*]), those tf operations(DenseLayer) in different threads could be parallelized, but those numpy operations in different threads are not going to be parallelizable?\r\n\r\nSorry for my poor english, please correct me if I'm wrong. Thank you!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@josh11b @isaprykin @guptapriya , feel like commenting?", "Thank you for your question. We are actively working on a multi-GPU solution for eager that will be easy to use and performant. It will be using the Distribution Strategy API we recently released. As part of that we are looking into whether threading will give us good performance, or we may need to look into other approaches.", "Hi @guptapriya, is there any update on this issue ? When can we expect to have multi-gpu support running in eager mode ?", "Hi @jrabary, i am working on an example right now to train MNIST using multi GPU in eager mode. It works, but it is very slow right now, so as of now it will not actually be useful to scale things up. I will share it when it is submitted so you can get an idea of how the API will be used (by next week).\r\nWe will look into the performance, but I don't have an ETA on that yet. \r\n", "Hi @jrabary here is the example: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/mnist_eager_multigpu.py\r\n\r\nIt is in contrib right now but we will move it to a better place soon. \r\nAs I said before, it is quite slow right now as MirroredStrategy has lot of overhead in pure eager mode. I have a pending change to this example that will wrap most of the computation in a tf.function to improve the performance. Will be submitting that in a couple days. \r\n\r\nHope this helps. \r\n", "@guptapriya Is there any guide to using the distribute with eager?", "Thanks @guptapriya. Is it the same API for TF 2.0 ?", "Yes, actually I've now modified the same example to be using 2.0 and tf.function. Take a look :https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/mnist_eager_multigpu.py\r\n\r\n", "What is alternative to train model written with eager execution on multi-gpu?", "@Oktai15 do you mean without using tf.function? ", "@guptapriya I will be happy to see any solution to do it :) Imagine that I have a model that is keras.Model and I want to train it on multi-gpu AND have benefits from multi-gpu. Example with tf.function would be okay)", "Can I convert my keras.model to static graph so that I can train it with benefits of multi-gpu?", "@Oktai15 if you're using keras with the functional API it should already work natively with distribution strategies. If not, you can use tf.function + strategy.experimental_run to make it work with multi-gpu.", "@Oktai15 https://www.tensorflow.org/alpha/guide/distribute_strategy covers various ways in which you can use tf.distribute.MirroredStrategy to do multi GPU training (and links to tutorials and examples)", "Is there a way to do distributed training without a `@tf.function`? Implementing the training step in graph mode is making it difficult to 1) work with multiple losses that might change between runs, and 2) write detailed per-loss information with `tf.summary`.", "Not currently in a fast way, but the tf.device APIs to run ops on different\ndevices work with eager execution and you can use multiple python threads\nto coordinate things.\n\nOn Thu, Nov 21, 2019 at 7:35 AM Noah Trenaman <notifications@github.com>\nwrote:\n\n> Is there a way to do distributed training without a @tf.function?\n> Implementing the training step in graph mode is making it difficult to 1)\n> work with multiple losses that might change between runs, and 2) write\n> detailed per-loss information with tf.summary.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17851?email_source=notifications&email_token=AAABHRIQQH53F4OKULMW6RDQU2TE5A5CNFSM4EWE76EKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE2UHJA#issuecomment-557138852>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRPPYTL2XQRPW2DUYGDQU2TE5ANCNFSM4EWE76EA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp thanks for the quick reply! I ended up accomplishing what I wanted to do with a simple `model.fit` and custom callbacks."]}, {"number": 17783, "title": "Segmentation fault in Eigen::internal::InnerMostDimReducer<...>::reduce when passing large tensor to sparse_softmax_cross_entropy_with_logits", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have written custom code. A simple reproduction script is included below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 (also occurring on Linux Ubuntu 14.04)\r\n- **TensorFlow installed from (source or binary)**: TensorFlow installed from binary (also occurring after building from source)\r\n- **TensorFlow version (use command below)**: TensorFlow v1.6 (also occurring on v1.4, v1.5, v1.7rc0)\r\n- **Python version**: Python 2.7 (Ubuntu base and also occurring on Anaconda Python 2.7)\r\n- **Bazel version (if compiling from source)**: Bazel version: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**: GCC 4.9.4\r\n- **CUDA/cuDNN version**: CUDA not used, CPU only\r\n- **GPU model and memory**: GPU not used, CPU only (Intel(R) Xeon(R) CPU E5-2650 and Intel(R) Xeon(R) Platinum 8175M)\r\n- **Exact command to reproduce**: Command to reproduce using script given below: \"python sfi.py 300000\"\r\n\r\n### Describe the problem\r\nA segmentation fault is occurring with the following gdb backtrace when a \"logits\" tensor of sufficient size is passed to `sparse_softmax_cross_entropy_with_logits`. The single argument to the demonstration code below adjusts the size. I have found that there is a point below which the SegFault does not seem to ever occur and above which the SegFault always seems to occur, but around that point (e.g. within +/- 2) the SegFault behaviour is intermittent. Right on the change point I can run the same code with the same argument and it will sometimes generate a SegFault and sometimes not (though the random data generated in the demo code may be causing this randomness).\r\n\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7fffcdffb700 (LWP 2440)]\r\n0x00007fffef12a590 in Eigen::internal::InnerMostDimReducer<Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::internal::MaxReducer<float>, true>::reduce(Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice> const&, int, int, Eigen::internal::MaxReducer<float>&) ()\r\n   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n(gdb) bt\r\n#0  0x00007fffef12a590 in Eigen::internal::InnerMostDimReducer<Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::internal::MaxReducer<float>, true>::reduce(Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const, Eigen::ThreadPoolDevice> const&, int, int, Eigen::internal::MaxReducer<float>&) ()\r\n   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#1  0x00007fffef12a90f in Eigen::internal::EvalRange<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, int, true>::run(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>*, int, int) () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fffedcd5541 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fffedcd5511 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&, std::function<long (long)>, std::function<void (long, long)>) const::{lambda(long, long)#1}::operator()(long, long) const () from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00007fffebcecb70 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()\r\n   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#11 0x00007fffebceb8e2 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from <home_dir>/.conda/envs/research/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#12 0x00007fffe20355b0 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#13 0x00007ffff77e7184 in start_thread (arg=0x7fffcdffb700) at pthread_create.c:312\r\n#14 0x00007ffff6e0703d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111\r\n```\r\n\r\nThe problem occurs in all of these configurations:\r\n\r\n- Binary CPU-only install of TF: v1.4, v1.5, v1.6, and v1.7\r\n- Build from source code: v1.6, v1.7\r\n- Building with MKL and without MKL\r\n- Ubuntu Python and Anaconda Python (but only Python 2.7 in both cases)\r\n- In clean virtual/conda envs with only the minimum TF dependencies installed\r\n\r\n### Source code / logs\r\n\r\nI've been able to distil the problem down to the following code which reliably reproduces the problem for me on my local hardware and also on a m5.2xlarge EC2 instance running Ubuntu 16.04 Server or Amazon Linux. The following code has no external data or code dependencies other than tensorflow.\r\n\r\nThe script has a single argument which sets the \"vocabulary size\" (this was originally an RNN LM); if this value is large enough a SegFault occurs. The only operation of note is the `sparse_softmax_cross_entropy_with_logits`.\r\n\r\n```\r\n#!/usr/bin/env python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport sys\r\nimport tensorflow as tf\r\n\r\ndef main():\r\n    vocabulary_size = int(sys.argv[1])\r\n    batch_size = 256\r\n    step_size = 32\r\n\r\n    print(\"Vocabulary size:\", vocabulary_size)\r\n\r\n    labels = tf.get_variable(\"labels\", shape=[batch_size, step_size], dtype=tf.int32)\r\n    logits = tf.get_variable(\"logits\", shape=[batch_size, step_size, vocabulary_size])\r\n    costs = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\r\n\r\n    with tf.Session() as session:\r\n        session.run(tf.global_variables_initializer())\r\n\r\n        print(\"Executing...\")\r\n        session.run(costs)\r\n        print(\"SUCCESS!\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I have updated the issue to use the template headings. Hopefully this is now correctly viewed as complete.", "I've updated the issue after discovering that the only operation needed to generate the SegFault is `sparse_softmax_cross_entropy_with_logits`.", "I've tried compiling TF with the latest version of Eigen but the SegFault still occurs.", "I've been unable to fix this problem directly so I'm now using a workaround. I believe these two functions are equivalent as long as logits is of rank 3. Thankfully, the `alt` function does not appear to be any slower.\r\n\r\n```\r\ndef base_sparse_softmax_cross_entropy_with_logits(logits, labels):\r\n    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\r\n\r\n\r\ndef alt_sparse_softmax_cross_entropy_with_logits(logits, labels):\r\n    log_softmax = tf.nn.log_softmax(logits)\r\n    logits_shape = tf.shape(logits)\r\n    y, x = tf.meshgrid(tf.range(logits_shape[1]), tf.range(logits_shape[0]))\r\n    indexes = tf.stack([x, y, labels], axis=-1)\r\n    return -tf.gather_nd(log_softmax, tf.cast(indexes, tf.int64))\r\n```\r\n", "While developing that alternative code I found I needed to cast the indexes to `int64` since the total number of elements exceeded `2**31` and this caused `gather_nd` problems. I wonder whether this is actually the cause of the problem in `tf.nn.sparse_softmax_cross_entropy_with_logits`; is it assuming the total number of elements is less than `2**31`?", "@ebrevdo, can you take a look?", "I tried changing the `dtype` of the labels passed to `tf.nn.sparse_softmax_cross_entropy_with_logits` to be `tf.int64` instead of `tf.int32` but the problem remains.", "I think we optimize using int32 indexing. We could change this to int64 on\nthe CPU path maybe.\n\nOn Sat, Apr 21, 2018, 11:27 AM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Assignee @ebrevdo <https://github.com/ebrevdo>: It has been 14\n> days with no activity and this issue has an assignee. Please update the\n> label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17783#issuecomment-383318472>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim-ou72GLufRcPF-kC26N1Y4TwH-kks5tq3n_gaJpZM4SuZnL>\n> .\n>\n"]}, {"number": 17707, "title": "Centered padded batch on tf.data.dataset with image-features and bounding boxes", "body": "Hello everyone,\r\n\r\nI have a feature request to the `tf.data.dataset` API which might also benefit many other users.\r\nThe use case is this:\r\nSuppose you have a regular instance based segmentation dataset containing images features, image-targets (for segmentation), bounding boxes, and a class- and instance id to each bounding box. ([Mapillary](https://blog.mapillary.com/product/2017/05/03/mapillary-vistas-dataset.html) is a nice example for that, even though it natively does not contain bounding boxes, but they can be inferred, because it has pixel wise instances)\r\n\r\nIf you use the `tf.data.dataset` API to create a dataset in one or another way (for instance use a `generator` and then create the dataset with `tf.data.Dataset.from_generator`), you can create a dataset including the feature_images, target_images and bounding boxes.\r\n\r\nNow you want to batch them together.\r\nThe problem is, that the images may have different sizes and the number of bounding boxes per image may be different for each entry of the dataset. Therefore you can not batch them unless you make sure they have the same size. To keep the aspect ratio in the images one could consider padding the images according to the biggest size in the batch. Also the bounding boxes can be padded, according to the maximum number of bounding boxes in the batch. And there already is a function that does that: `tf.data.dataset.padded_batch`. Unfortunately the padding is always applied to the end of the dimension:\r\nA picture with\r\n```\r\n[[1,1,1,1]\r\n [1,1,1,1]\r\n [1,1,1,1]\r\n [1,1,1,1]]\r\n```\r\n\r\npadded by 2 would look like:\r\n```\r\n[[1,1,1,1,0,0]\r\n [1,1,1,1,0,0]\r\n [1,1,1,1,0,0]\r\n [1,1,1,1,0,0]\r\n [0,0,0,0,0,0]\r\n [0,0,0,0,0,0]]\r\n```\r\n\r\nThis would likely lead to dead or irrelevant neurons within the receptive field at the right or bottom of the image. Therefore a centered padding would be nice:\r\n```\r\n[[0,0,0,0,0,0]\r\n [0,1,1,1,1,0]\r\n [0,1,1,1,1,0]\r\n [0,1,1,1,1,0]\r\n [0,1,1,1,1,0]\r\n [0,0,0,0,0,0]]\r\n```\r\n\r\nUp until here there already exists an issue that covers the behaviour [here](https://github.com/tensorflow/tensorflow/issues/13969#issuecomment-370902365) . But now comes the tricky part: If we pad the image at the top or the left, we need an offset to the bounding boxes according to the padding because the edges of the bounding boxes are in image coordinates and shift when the image is padded.\r\n\r\nSo here is my suggestion:\r\nOne could extend the `tf.data.dataset.padded_patch` to perform centered padding on each dimension with an additional `centered` flag or so, similar as suggested in the issue above, but also returns the maximum dimension within each element of the batch. This information can then be used to adjust the bounding box location.\r\n\r\nAlternative:\r\nOne could also consider an operator to return the maximum dimensions within the bath to use that information for padding. I could imagine, to have a `self written padding function` and use `tf.data.map` and the maximum batch dimensions information to incorporate the padding to the dataset per element using `tf.pad` or similar. The nice thing about this alternative approach is, that the users can build the padding as they want since `tf.pad` already can do central padding and other styles.\r\n\r\nI had a little dive into the functionality of `padded_batch` and it seems that the calculation of the maximum dimension is done in `tensorflow/core/kernels/data/padded_batch_dataset_op.cc` line 264 ff. This however is in the iterator class, which I presume is called when the data is actually passed through. So I'm not sure if or how to return the maximum batch dimensions from there to the point where I can use it to pad the images. If this is indeed not possible, I'd appreciate other suggestions because the way it is, the `tf.data.dataset` can not be used for this kind of data.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@mrry would this be a welcome feature?", "I'd be interested to see proposals in `tf.contrib.data` to begin with. Marking as \"Contributions welcome\"."]}, {"number": 17502, "title": "Tensorflow failed when build with MSVC + /permissive-", "body": "System information\r\n\u2022\tHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nN/A \r\n\u2022\tOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows server 2016\r\n\u2022\tTensorFlow installed from (source or binary):\r\nSource\r\n\u2022\tTensorFlow version (use command below):\r\nMaster branch latest revison\r\n\u2022\tPython version:\r\nAnaconda 4.1.1 (Python 3.5 64-bit) \r\n\u2022\tBazel version (if compiling from source):\r\nN/A\r\n\u2022\tGCC/Compiler version (if compiling from source):\r\nVS2017 15.5.7\r\n\u2022\tCUDA/cuDNN version:\r\nNVidia CUDA Toolkit 8.0\r\nNVidia CUDNN 5.1\r\n\u2022\tGPU model and memory:\r\nN/A\r\n\u2022\tExact command to reproduce:\r\nN/A\r\n\r\nDescribe the problem\r\nTensorflow failed when build with /permissive- by using msvc on windows. This should be tensorflow source issue, could you help fix it?\r\n\r\nThe failures like:\r\nD:\\Tensorflow\\src\\tensorflow/core/util/memmapped_file_system.h(61): error C2440: 'initializing': cannot convert from 'const char [21]' to 'char *const '\r\nD:\\Tensorflow\\src\\tensorflow/core/util/memmapped_file_system.h(61): note: Conversion from string literal loses const qualifier (see /Zc:strictStrings)\r\nD:\\Tensorflow\\src\\tensorflow/core/util/memmapped_file_system.h(69): error C2440: 'initializing': cannot convert from 'const char [22]' to 'char *const '\r\nD:\\Tensorflow\\src\\tensorflow/core/util/memmapped_file_system.h(69): note: Conversion from string literal loses const qualifier (see /Zc:strictStrings)\r\nD:\\Tensorflow\\src\\tensorflow\\core\\util\\memmapped_file_system.cc(182): error C2737: 'tensorflow::MemmappedFileSystem::kMemmappedPackagePrefix': 'constexpr' object must be initialized\r\nD:\\Tensorflow\\src\\tensorflow\\core\\util\\memmapped_file_system.cc(182): error C2734: 'tensorflow::MemmappedFileSystem::kMemmappedPackagePrefix': 'const' object must be initialized if not 'extern'\r\nD:\\Tensorflow\\src\\tensorflow\\core\\util\\memmapped_file_system.cc(183): error C2737: 'tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef': 'constexpr' object must be initialized\r\nD:\\Tensorflow\\src\\tensorflow\\core\\util\\memmapped_file_system.cc(183): error C2734: 'tensorflow::MemmappedFileSystem::kMemmappedPackageDefaultGraphDef': 'const' object must be initialized if not 'extern'\r\n\r\nRepro steps:\r\n1.\tgit clone  https://github.com/tensorflow/tensorflow D:\\Tensorflow\\src\r\n2.\tpushd D:\\Tensorflow\r\n3.\tset PreferredToolArchitecture=x64\r\n4.\tset rel=Release\r\n5.\tset CUDNN_HOME=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\cuda\"\r\n6.\tset PY=C:\\ProgramData\\Anaconda3\r\n7.\tset _CL_=/FS /permissive-\r\n8.\tcmake D:\\Tensorflow\\src\\tensorflow\\contrib\\cmake -A x64 -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=C:\\ProgramData\\Anaconda3\\python.exe -DPYTHON_LIBRARIES=C:\\ProgramData\\Anaconda3\\libs\\python36.lib -DSWIG_EXECUTABLE=D:\\Tensorflow\\swigwin-3.0.12\\swig.exe -Dtensorflow_BUILD_PYTHON_TESTS=ON -Dtensorflow_BUILD_SHARED_LIB=ON\r\n9. MSBuild /m /p:Configuration=Release;Platform=x64 /p:WindowsTargetPlatformVersion=10.0.16299.0 tensorflow.sln /t:Rebuild\r\n", "comments": ["/Zc:strictStrings and along other /Zc: C++ standard conformance behaviors are turned on by default under the /permissive- mode in MSVC. Starting with VS2017 15.5 update release, /permissive- is turned on for new Visual C++ Console applications and Windows SDK headers with Redstone 3 release (Nov 2017) are clean with this mode. MSVC's plan is in not-so-distant future to turn on the /permissive- switch by default in the compiler. Making these source changes in Tensorflow will better align with more conformance MSVC compiler as well as be compatible with other C++ compilers GCC/Clang.\r\nThank you,", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "My post was supplemental information for the previous bug report from Phoebe Ma.\r\n\r\nThanks,\r\nBat-Ulzii \u041b\u0443\u0432\u0441\u0430\u043d\u0431\u0430\u0442\r\nCell: +1 (425) 551-9551<tel:%2B1%20%28425%29%20551-9551>\r\n\r\nFrom: Alfred Sorten Wolf [mailto:notifications@github.com]\r\nSent: Wednesday, March 7, 2018 12:15 PM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Bat-Ulzii Luvsanbat <ulzii@live.com>; Comment <comment@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] Tensorflow failed when build with MSVC + /permissive- (#17502)\r\n\r\n\r\nThank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\nHave I written custom code\r\nOS Platform and Distribution\r\nTensorFlow installed from\r\nTensorFlow version\r\nBazel version\r\nCUDA/cuDNN version\r\nGPU model and memory\r\nExact command to reproduce\r\n\r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F17502%23issuecomment-371269099&data=02%7C01%7C%7Cfdb8fab3da2642e748bc08d58469cfb7%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636560512337936547&sdata=GQ5VGIOsj%2Bwxmg8gbzxUkq8mj1cbLRB6sw32rWUzaGk%3D&reserved=0>, or mute the thread<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAZbVkVlZNvA7-yTL4AtLdg1Set-8ZyWWks5tcD_UgaJpZM4SgGmh&data=02%7C01%7C%7Cfdb8fab3da2642e748bc08d58469cfb7%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C636560512338092800&sdata=TXPR5qUk6W8bLWPJqCnGBXj3SPvJ3gAriCGQvIE2fOw%3D&reserved=0>.\r\n", "Update the Environment information.", "@mrry @gunan PTAL: seems like a reasonable request, which isn't breaking the build yet but will do so in once /permissive becomes the default. ", "Seems reasonable, but not a priority for me, so I'm marking it \"Contributions Welcome\".", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 17417, "title": "embed_sequence and embedding_lookup behave differently on CPU vs. GPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.6\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen using `tf.nn.embedding_lookup` or `tf.contrib.layers.embed_sequence` with -1 in the indexes the corresponding embeddings should be 0 vectors, in the same way that `tf.feature_column.categorical_column_with_identity` ignores negative values. This works correctly when trying on Colaboratory but fails on my Windows installation using the same Tensorflow version v1.6.\r\n\r\n### Source code / logs\r\nBoth ways of initializing the embeddings produce the same error, only on Windows, may it be related to the version of the `gather` function being used from `python\\ops\\array_ops.py`?\r\n```python\r\ntf.reset_default_graph()\r\na = tf.constant(np.array([[0, 1, 2, -1, 4]]))\r\n# b = tf.contrib.layers.embed_sequence(a, 5, 3, initializer=tf.random_uniform_initializer(-1.0, 1.0))\r\nb = tf.nn.embedding_lookup(tf.get_variable('embeddings', [5, 3], initializer=tf.random_uniform_initializer(-1.0, 1.0)), a)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    print(sess.run(b))\r\n```\r\n\r\nThe error goes like this\r\n> InvalidArgumentError: indices[..] = -1 is not in [0, ..)", "comments": ["@ilblackdragon can you please take a look?", "Actually, I have some more insight to add, since by trying something else I have discovered that the issue is not with the OS, but it has to do with whether you are using a GPU or not. Running the same code on Linux (for instance in Colaboratory) will throw the same error about -1 values if you disable GPU support. \r\n\r\nHope this further helps to nail down the issue.", "embedding_lookup doesn't support invalid ids. InvalidArgumentError is the right behavior.  FeatureColumns are handling them. We implemented _safe_embedding_lookup_sparse. Making those functions public make sense. I added contributions welcome to make them public.", "Thanks for the pointer to `safe_embedding_lookup`.\r\n \r\nLooking at this a little more I see that the CPU/GPU inconsistency is described in the `embedding_lookup` docs.\r\n", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "the difference seems related to tf.gather. @alextp do you know who can give us some background info here?", "Is this related to GPU gather setting out-of-range indices to zero ( https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/gather_functor_gpu.cu.h#L58 ) ?", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "It is still replicating in[ 2.8](https://colab.sandbox.google.com/gist/mohantym/a6746a2aa7a9988ed10c8cde68c8f996/github_17417.ipynb) version."]}, {"number": 17356, "title": "[suggestion][tf.estimator] model with multiple labels", "body": "How about let `labels` provided to `def model_fn(features, labels, mode, params):` be `dict` but not a tensor.\r\nI'm now modeling a model with multiple outputs to be optimized, however, I can only use `features` to substitute `labels` because it only allow a tensor. I'm using version 1.4", "comments": ["I probably misunderstand your post but it seems that tf.estimator handles multi-dimension outputs (with labels taking in input a dict for multi-head models) - see tf.estimator.Estimator class definition:\r\n \r\nArgs:\r\n      model_fn: Model function. Follows the signature:\r\n        * Args:\r\n          * `features`: This is the first item returned from the `input_fn`\r\n                 passed to `train`, `evaluate`, and `predict`. This should be a\r\n                 single `Tensor` or `dict` of same.\r\n          * `labels`: This is the second item returned from the `input_fn`\r\n                 passed to `train`, `evaluate`, and `predict`. This should be a\r\n                 single `Tensor` or `dict` of same (for multi-head models). If\r\n                 mode is `ModeKeys.PREDICT`, `labels=None` will be passed. If\r\n                 the `model_fn`'s signature does not accept `mode`, the\r\n                 `model_fn` must still be able to handle `labels=None`.\r\n          * `mode`: Optional. Specifies if this training, evaluation or\r\n                 prediction. See `ModeKeys`.\r\n          * `params`: Optional `dict` of hyperparameters.  Will receive what\r\n                 is passed to Estimator in `params` parameter. This allows\r\n                 to configure Estimators from hyper parameter tuning.\r\n          * `config`: Optional configuration object. Will receive what is passed\r\n                 to Estimator in `config` parameter, or the default `config`.\r\n                 Allows updating things in your model_fn based on configuration\r\n                 such as `num_ps_replicas`, or `model_dir`.", "Oh, I found that I only checked the following link:\r\nhttps://www.tensorflow.org/versions/r1.4/extend/estimators\r\nAnd in the link, `lables` in `model_fn` is only explained as:\r\n\r\n> labels: A Tensor containing the labels passed to the model via input_fn. Will be empty for predict() calls, as these are the values the model will infer.\r\n\r\nSo did i make such a suggestion.\r\n\r\n> * labels: This is the second item returned from the input_fn passed to train, evaluate, and predict. This should be a single Tensor or dict of same (for multi-head models). \r\n\r\nSo this means that I can have multiple objective functions and different dimensions of label values? e.g.  the label of the first objective function with 5 dimension vector and the label of the second objective function with 2 dimension vector.", "Yes, you can indeed. tf.estimator allows to handle it, then you can handle the multiple objectives however you want in your model_fn. See simple example bellow (taken from the TF website and modified for multi-dimension labels):\r\n```import os\r\nimport urllib\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\n# Data sets\r\nIRIS_TRAINING = \"iris_training.csv\"\r\nIRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\r\n\r\nIRIS_TEST = \"iris_test.csv\"\r\nIRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\r\n\r\n# If the training and test sets aren't stored locally, download them.\r\nif not os.path.exists(IRIS_TRAINING):\r\n  raw = urllib.urlopen(IRIS_TRAINING_URL).read()\r\n  with open(IRIS_TRAINING, \"w\") as f:\r\n    f.write(raw)\r\n\r\nif not os.path.exists(IRIS_TEST):\r\n  raw = urllib.urlopen(IRIS_TEST_URL).read()\r\n  with open(IRIS_TEST, \"w\") as f:\r\n    f.write(raw)\r\n\r\n# Load datasets.\r\ntraining_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n    filename=IRIS_TRAINING,\r\n    target_dtype=np.int,\r\n    features_dtype=np.float32)\r\ntest_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n    filename=IRIS_TEST,\r\n    target_dtype=np.int,\r\n    features_dtype=np.float32)\r\n\r\ndef build_estimator(\r\n  model_dir,\r\n  hidden_units,\r\n  feature_columns,\r\n  n_classes,\r\n  output_dim):\r\n  \r\n\r\n  def _model_fn(features, labels, mode, params):\r\n    \"\"\"Model function for Estimator.\"\"\"\r\n    \r\n    # One-hot encoding on targets\r\n    print 'label shapes', [labels[l].shape for l in labels]\r\n    \r\n    labels = labels['y1']\r\n    targets = tf.one_hot(labels, n_classes)\r\n\r\n    # Connect the first hidden layer to input layer\r\n    # (features[\"x\"]) with relu activation\r\n    first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\r\n    # Connect the second hidden layer to first hidden layer with relu\r\n    second_hidden_layer = tf.layers.dense(\r\n        first_hidden_layer, 20, activation=tf.nn.relu)\r\n    \r\n    # Connect the third hidden layer to second hidden layer with relu\r\n    third_hidden_layer = tf.layers.dense(\r\n        second_hidden_layer, 20, activation=tf.nn.relu)\r\n\r\n    # Connect the output layer to third hidden layer (no activation fn)\r\n    output_layer = tf.layers.dense(third_hidden_layer, n_classes)\r\n\r\n    # Reshape output layer to 1-dim Tensor to return predictions\r\n    predictions = tf.argmax(output_layer, axis=1)\r\n\r\n    # Provide an estimator spec for `ModeKeys.PREDICT`.\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n      return tf.estimator.EstimatorSpec(\r\n          mode=mode,\r\n          predictions={\"predictions\": predictions})\r\n\r\n    # Calculate loss using mean squared error\r\n    loss = tf.losses.softmax_cross_entropy(targets, output_layer)\r\n\r\n    # Calculate root mean squared error as additional eval metric\r\n    eval_metric_ops = {\r\n        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions)\r\n    }\r\n    \r\n    optimizer = tf.train.GradientDescentOptimizer(\r\n        learning_rate=0.1)\r\n    train_op = optimizer.minimize(\r\n        loss=loss, global_step=tf.train.get_global_step())\r\n\r\n    # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\r\n    return tf.estimator.EstimatorSpec(\r\n        mode=mode,\r\n        loss=loss,\r\n        train_op=train_op,\r\n        eval_metric_ops=eval_metric_ops)\r\n\r\n  return tf.estimator.Estimator(\r\n    model_fn=_model_fn)\r\n\r\n# Specify that all features have real-value data\r\nfeature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\r\n\r\n# Build 3 layer DNN with 10, 20, 10 units respectively.\r\nestimator = build_estimator# (#\r\nclassifier = estimator(feature_columns=feature_columns,\r\n                                        hidden_units=[10, 20, 10],\r\n                                        n_classes=3,\r\n                                        output_dim=2,\r\n                                        model_dir=\"/tmp/iris_model\")\r\n# Define the training inputs\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": np.array(training_set.data)},\r\n    y={\r\n        \"y1\": np.array(training_set.target),\r\n        \"y2\": np.stack(\r\n            [np.array(training_set.target) for i in xrange(2)],\r\n            axis=1)\r\n    },\r\n    num_epochs=None,\r\n    shuffle=True)\r\n\r\n# Train model.\r\nclassifier.train(input_fn=train_input_fn, steps=2000)\r\n```", "> Yes, you can indeed. tf.estimator allows to handle it, then you can handle the multiple objectives however you want in your model_fn. See simple example bellow (taken from the TF website and modified for multi-dimension labels):\r\n> \r\n> ```\r\n> import urllib\r\n> \r\n> import numpy as np\r\n> import tensorflow as tf\r\n> \r\n> \r\n> # Data sets\r\n> IRIS_TRAINING = \"iris_training.csv\"\r\n> IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\r\n> \r\n> IRIS_TEST = \"iris_test.csv\"\r\n> IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\r\n> \r\n> # If the training and test sets aren't stored locally, download them.\r\n> if not os.path.exists(IRIS_TRAINING):\r\n>   raw = urllib.urlopen(IRIS_TRAINING_URL).read()\r\n>   with open(IRIS_TRAINING, \"w\") as f:\r\n>     f.write(raw)\r\n> \r\n> if not os.path.exists(IRIS_TEST):\r\n>   raw = urllib.urlopen(IRIS_TEST_URL).read()\r\n>   with open(IRIS_TEST, \"w\") as f:\r\n>     f.write(raw)\r\n> \r\n> # Load datasets.\r\n> training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n>     filename=IRIS_TRAINING,\r\n>     target_dtype=np.int,\r\n>     features_dtype=np.float32)\r\n> test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\r\n>     filename=IRIS_TEST,\r\n>     target_dtype=np.int,\r\n>     features_dtype=np.float32)\r\n> \r\n> def build_estimator(\r\n>   model_dir,\r\n>   hidden_units,\r\n>   feature_columns,\r\n>   n_classes,\r\n>   output_dim):\r\n>   \r\n> \r\n>   def _model_fn(features, labels, mode, params):\r\n>     \"\"\"Model function for Estimator.\"\"\"\r\n>     \r\n>     # One-hot encoding on targets\r\n>     print 'label shapes', [labels[l].shape for l in labels]\r\n>     \r\n>     labels = labels['y1']\r\n>     targets = tf.one_hot(labels, n_classes)\r\n> \r\n>     # Connect the first hidden layer to input layer\r\n>     # (features[\"x\"]) with relu activation\r\n>     first_hidden_layer = tf.layers.dense(features[\"x\"], 10, activation=tf.nn.relu)\r\n>     # Connect the second hidden layer to first hidden layer with relu\r\n>     second_hidden_layer = tf.layers.dense(\r\n>         first_hidden_layer, 20, activation=tf.nn.relu)\r\n>     \r\n>     # Connect the third hidden layer to second hidden layer with relu\r\n>     third_hidden_layer = tf.layers.dense(\r\n>         second_hidden_layer, 20, activation=tf.nn.relu)\r\n> \r\n>     # Connect the output layer to third hidden layer (no activation fn)\r\n>     output_layer = tf.layers.dense(third_hidden_layer, n_classes)\r\n> \r\n>     # Reshape output layer to 1-dim Tensor to return predictions\r\n>     predictions = tf.argmax(output_layer, axis=1)\r\n> \r\n>     # Provide an estimator spec for `ModeKeys.PREDICT`.\r\n>     if mode == tf.estimator.ModeKeys.PREDICT:\r\n>       return tf.estimator.EstimatorSpec(\r\n>           mode=mode,\r\n>           predictions={\"predictions\": predictions})\r\n> \r\n>     # Calculate loss using mean squared error\r\n>     loss = tf.losses.softmax_cross_entropy(targets, output_layer)\r\n> \r\n>     # Calculate root mean squared error as additional eval metric\r\n>     eval_metric_ops = {\r\n>         \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions)\r\n>     }\r\n>     \r\n>     optimizer = tf.train.GradientDescentOptimizer(\r\n>         learning_rate=0.1)\r\n>     train_op = optimizer.minimize(\r\n>         loss=loss, global_step=tf.train.get_global_step())\r\n> \r\n>     # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\r\n>     return tf.estimator.EstimatorSpec(\r\n>         mode=mode,\r\n>         loss=loss,\r\n>         train_op=train_op,\r\n>         eval_metric_ops=eval_metric_ops)\r\n> \r\n>   return tf.estimator.Estimator(\r\n>     model_fn=_model_fn)\r\n> \r\n> # Specify that all features have real-value data\r\n> feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\r\n> \r\n> # Build 3 layer DNN with 10, 20, 10 units respectively.\r\n> estimator = build_estimator# (#\r\n> classifier = estimator(feature_columns=feature_columns,\r\n>                                         hidden_units=[10, 20, 10],\r\n>                                         n_classes=3,\r\n>                                         output_dim=2,\r\n>                                         model_dir=\"/tmp/iris_model\")\r\n> # Define the training inputs\r\n> train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n>     x={\"x\": np.array(training_set.data)},\r\n>     y={\r\n>         \"y1\": np.array(training_set.target),\r\n>         \"y2\": np.stack(\r\n>             [np.array(training_set.target) for i in xrange(2)],\r\n>             axis=1)\r\n>     },\r\n>     num_epochs=None,\r\n>     shuffle=True)\r\n> \r\n> # Train model.\r\n> classifier.train(input_fn=train_input_fn, steps=2000)\r\n> ```\r\n\r\nHello,I see this is for training label for y1,but how can it train y2?Since the EstimatorSpec takes only one loss argument?", "Tf.estimator.Estimator uses Tensorflow 1 style of coding and is not recommended for Tensorflow 2.x. There will not be any new addition to the estimators. \r\nYou can follow. the detailed explanation [here](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator) and close this issue. Thanks!"]}, {"number": 17353, "title": "Error indices[0] = 0 is not in [0, 0) while training an object-detection model with tensorflow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8\r\n- **GPU model and memory**:   Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8755 , 11GB\r\n- **Exact command to reproduce**: \r\nfloyd run --gpu --env tensorflow-1.5 --data valiok98/datasets/raspberrypi2/3:/data --data valiok98/datasets/raspberrypi2/8:/mobilenet --data valiok98/datasets/raspberrypi2/9:/images --data valiok98/datasets/raspberrypi2/10:test_ckpt 'python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config'\r\n\r\nFor the record I tried with previous TF versions and it did not make  a diffrence.\r\nSo I am currently attempting to train a custom object-detection model on tensorflow to recognize images of a raspberrypi2. Everything is already set up and running on my hardware,but due to limitations of my gpu I settled for the cloud. I have uploaded my data(train & test records ans csv-files) and my checkpoint model. That is what I get from the logs:\r\n\r\ntensorflow:Restoring parameters from /mobilenet/model.ckpt\r\n\r\ntensorflow:Starting Session.\r\n\r\ntensorflow:Saving checkpoint to path training/model.ckpt\r\n\r\ntensorflow:Starting Queues.\r\n\r\ntensorflow:Error reported to Coordinator: <class tensorflow.python.framework.errors_impl.InvalidArgumentError'>,\r\nindices[0] = 0 is not in [0, 0)\r\n\r\nI also have a folder called images with the actual .jpg files and it is also on the cloud, but for some reason I must specify every directory with a preceeding forward slash / and that might be a problem, as I currently do not know whether some of the files are trying to import these images ,but could not find the path because of the missing /. If any of you happens to share a solution I would be really thankful.\r\n\r\nAnd so here are my full logs:\r\n\r\n\r\nPSTINFO:tensorflow:Restoring parameters from /mobilenet/model.ckpt\r\nPSTINFO:tensorflow:Starting Session.\r\nPSTINFO:tensorflow:Saving checkpoint to path training/model.ckpt\r\nPSTINFO:tensorflow:Starting Queues.\r\nPSTINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, indices[0] = 0 is not in [0, 0)\r\nPST[[Node: cond_4/RandomCropImage/Gather = Gather[Tindices=DT_INT64, Tparams=DT_BOOL, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](cond_4/Switch_4:1, cond_4/RandomCropImage/PruneCompleteleyOutsideWindow/Reshape)]]\r\nPSTINFO:tensorflow:global_step/sec: 0\r\nPSTINFO:tensorflow:Caught OutOfRangeError. Stopping Training.\r\nPSTINFO:tensorflow:Finished training! Saving model to disk.\r\nPSTTraceback (most recent call last):\r\nPSTFile \"train.py\", line 167, in <module>\r\nPSTtf.app.run()\r\nPSTFile \"/usr/local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\nPST_sys.exit(main(argv))\r\nPSTFile \"train.py\", line 163, in main\r\nPSTworker_job_name, is_chief, FLAGS.train_dir)\r\nPSTFile \"/code/trainer.py\", line 359, in train\r\nPSTsaver=saver)\r\nPSTFile \"/usr/local/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 782, in train\r\nPSTignore_live_threads=ignore_live_threads)\r\nPSTFile \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py\", line 826, in stop\r\nPSTignore_live_threads=ignore_live_threads)\r\nPSTFile \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 387, in join\r\nPSTsix.reraise(*self._exc_info_to_raise)\r\n", "comments": ["Your error looks like an empty image is entering image preprocessing.  You mention that you're not sure whether your input data is actually readable in the execution environment.  Can you write some small test python programs to confirm that the pathnames you're using actually work and the data read has the expected sizes?", "Hi @poxvoculi and thanks for answering. I fixed the issue by using an earlier tensorflow models commit(about 6 months ago). Since I was following a tutorial I thought that some changes in the newer version might be causing the problem and indeed that was the case.  My data is indeed readable in the execution environment, the sizes are correct and I have already trained my model ,so I do not think that I might have caused the issue(not trying to be rude!) . I provide the tf commit for the models and my FloydHub job that trained the model:\r\nTF  : http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz\r\nFloydHub Job : https://www.floydhub.com/valiok98/projects/image_raspberrypi2/82\r\nHope I was able to provide help", "Thanks for the report, I'm not familiar with these models and I'm trying to understand what the problem might be.  It sounds like you're able to train on older versions with your data, but syncing to newer versions results in some kind of index exception.   Looking at this page:\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\r\n\r\nit looks like there are a lot of versions of MobileNet each of which has different dimensions and requires a different checkpointed model to load from.  Are you trying to load a newer model version with a checkpoint from an older version?  Can you confirm the expected dimensions match those of the checkpoint you're trying to load?\r\n ", "I just want to point out that I encountered the same error using the newest version of the tensorflow models repository. I tried the newest versions of the pretrained nets from\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nwith the example config files from the repository. None of them worked and i got pretty much the same error that valiok98 got. Reverting to a commit a couple of months older did the trick for me too.\r\nSo it seems to me, there is some kind of problem with the newest version of the repo.", "Reassigning to @jch1, since this seems to be related to the object detection API.", "Lots of object detection API code has been changed since this issue was filed. Could you please sync to latest and follow the instructions to try again? ", "I can confirm that with the newest version of tensorflow and the object_detection repository this Error disappeared. It seems to me though, that it is not possible anymore, to get separate precision values for each category which worked with the PASCAL metric before.", "I am still facing this issue in the newer version of tensroflow object detection api...can someone help\r\nThis happens when I use the oxford pets train record file also for the pascal voc file. Not sure what's going on here\r\nindices[0] = 0 is not in [0, 0)\r\n\t [[{{node GatherV2_2}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@RandomHorizontalFlip/cond_2/Switch_1\"], _device=\"/device:CPU:0\"](cond/Merge, Reshape_8, GatherV2_4/axis)]]\r\n", "Can you share your config file?", "@pkulzc \r\nattached here\r\n[config file.txt](https://github.com/tensorflow/tensorflow/files/2474335/config.file.txt)\r\n", "Experiencing a similar issue with a fresh install of TF models:\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 0 is not in [0, 0)\r\n\t [[{{node GatherV2_4}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_INT64, _device=\"/device:CPU:0\"](cond_1/Merge, Reshape_8, GatherV2_3/axis)]]\r\n\t [[node IteratorGetNext (defined at object_detection/model_main.py:106)  = IteratorGetNext[output_shapes=[[128], [128,640,640,3], [128,2], [128,3], [128,100], [128,100,4], [128,100,90], [128,100,90], [128,100], [128,100], [128,100], [128]], output_types=[DT_INT32, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_BOOL, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\r\n```", "Exactly same error as @jattenberg said. Any help plz..", "> Hi @poxvoculi and thanks for answering. I fixed the issue by using an earlier tensorflow models commit(about 6 months ago). Since I was following a tutorial I thought that some changes in the newer version might be causing the problem and indeed that was the case. My data is indeed readable in the execution environment, the sizes are correct and I have already trained my model ,so I do not think that I might have caused the issue(not trying to be rude!) . I provide the tf commit for the models and my FloydHub job that trained the model:\r\n> TF : http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz\r\n> FloydHub Job : https://www.floydhub.com/valiok98/projects/image_raspberrypi2/82\r\n> Hope I was able to provide help\r\n\r\nwhere did you find the old version of the model?\r\n\r\nI want to find one for Mask-RCNN can you help me?", "Hi @lunasdejavu \r\nI haven't taken a look at the thread since a long time ago, but the original link for the object-detection repository ist : https://github.com/tensorflow/models/commits/master/research/object_detection\r\nYou can browse back to before March 2018(when I was having the issue). Unfortunately I don't remember the exact commit. Alternatively you can clone my project from\r\nhttps://github.com/valiok98/Python-Qt5-Tensorflow/tree/master/PyQt5/object_detection\r\nbut yet again it's not using Mask-RCNN", "I may have stumbled across the same issue.  I got the error when I trained the model on the GPU and then saved the model and weights and separately loaded and then tested the model on the CPU.\r\n\r\nWhen I both test and train using the GPU, my model works without issue.", "If you are having a similar error you might have made a mistake in creating the tfrecords (as I did)\r\n\r\nhttps://github.com/tensorflow/models/issues/2312\r\n", "> If you are having a similar error you might have made a mistake in creating the tfrecords (as I did)\r\n> \r\n> [tensorflow/models#2312](https://github.com/tensorflow/models/issues/2312)\r\n\r\nI did indeed make a mistake.  Thanks for pointing it out.  My embedding layer was off by one.\r\n\r\nIt's interesting that running on the GPU quashes the error.  I wonder what it did to my model.  I guess I will have to do a quick run on the CPU in the future to catch this sort of thing (or be more thorough on my part).", "> If you are having a similar error you might have made a mistake in creating the tfrecords (as I did)\r\n> \r\n> [tensorflow/models#2312](https://github.com/tensorflow/models/issues/2312)\r\n\r\nya I found the blog I followed is wrong with creating TFrecords,\r\nI found a better [blog](https://blog.csdn.net/qq_29462849/article/details/85342153) to beginners ,just use  the google translate ,it is very useful.", "Hi All,\r\n\r\nI am training a MaskRCNN model on COCO dataset. I have created TFrecord file for the training and evaluation data. However, I am getting the error:\r\n\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = 2 is not in [0, 0)\r\n\t [[{{node GatherV2_4}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@RandomHorizontalFlip/cond_2/Switch_1\"], _device=\"/device:CPU:0\"](cond/Merge, Reshape_8, GatherV2_3/axis)]]\r\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[1], [1,?,?,3], [1,2], [1,3], [1,100], [1,100,4], [1,100,90], [1,100,90], [1,100], [1,100,?,?], [1,100], [1,100], [1]], output_types=[DT_INT32, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_BOOL, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\r\n\r\nI am not sure how to go about this as I referred to the create_coco_tf_record.py provided in the model folder. Can someone help me with this?", "> Hi All,\r\n> \r\n> I am training a MaskRCNN model on COCO dataset. I have created TFrecord file for the training and evaluation data. However, I am getting the error:\r\n> \r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = 2 is not in [0, 0)\r\n> [[{{node GatherV2_4}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@RandomHorizontalFlip/cond_2/Switch_1\"], _device=\"/device:CPU:0\"](cond/Merge, Reshape_8, GatherV2_3/axis)]]\r\n> [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[1], [1,?,?,3], [1,2], [1,3], [1,100], [1,100,4], [1,100,90], [1,100,90], [1,100], [1,100,?,?], [1,100], [1,100], [1]], output_types=[DT_INT32, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_BOOL, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\r\n> \r\n> I am not sure how to go about this as I referred to the create_coco_tf_record.py provided in the model folder. Can someone help me with this?\r\n\r\nI am also getting the same error and cannot find the reason...", "> @pkulzc\r\n> attached here\r\n> [config file.txt](https://github.com/tensorflow/tensorflow/files/2474335/config.file.txt)\r\n\r\n@pkulzc Waiting for reply", "> > Hi All,\r\n> > I am training a MaskRCNN model on COCO dataset. I have created TFrecord file for the training and evaluation data. However, I am getting the error:\r\n> > tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = 2 is not in [0, 0)\r\n> > [[{{node GatherV2_4}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@RandomHorizontalFlip/cond_2/Switch_1\"], _device=\"/device:CPU:0\"](cond/Merge, Reshape_8, GatherV2_3/axis)]]\r\n> > [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[1], [1,?,?,3], [1,2], [1,3], [1,100], [1,100,4], [1,100,90], [1,100,90], [1,100], [1,100,?,?], [1,100], [1,100], [1]], output_types=[DT_INT32, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_FLOAT, DT_BOOL, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\r\n> > I am not sure how to go about this as I referred to the create_coco_tf_record.py provided in the model folder. Can someone help me with this?\r\n> \r\n> I am also getting the same error and cannot find the reason...\r\n\r\nI find  my error is that I didn't use --include_masks when building coco tfrecord.", "I got the same issue while training both MobileNet SSD as well as Faster RCNN for object detection. I tried running both locally on my PC and on Google colab. Can anyone help me out ?", "Changing the way I created TF Records worked out for me. Have a look at the following code -\r\n\r\n```\r\n example = tf.train.Example(\r\n                            features= tf.train.Features(\r\n                                feature={\r\n                                    'image/height': dataset_util.int64_feature(height),\r\n                                    'image/width': dataset_util.int64_feature(width),\r\n                                    'image/filename': dataset_util.bytes_feature(filename_str.encode('utf-8')),\r\n                                    'image/source_id': dataset_util.bytes_feature(filename_str.encode('utf-8')),\r\n                                    'image/format': dataset_util.bytes_feature(image_format),\r\n                                    'image/encoded': dataset_util.bytes_feature(image_data),\r\n                                    'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\r\n                                    'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\r\n                                    'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\r\n                                    'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\r\n                                    'image/object/class/text': dataset_util.bytes_list_feature(labels_text),\r\n                                    'image/object/class/label': dataset_util.int64_list_feature(labels),\r\n                                }\r\n                            )\r\n                        )\r\n```\r\n\r\nMake sure that the TF Records have the same keys as the ones shown above. This is due to the fact that the model that you use would be expecting keys similar to the ones above. I hope this helps.\r\n\r\nEarlier, I had made use of the following, which did not work out-\r\n\r\n```\r\nexample = tf.train.Example(\r\n                            features= tf.train.Features(\r\n                                feature={\r\n                                    'image/height': dataset_util.int64_feature(shape[0]),\r\n                                    'image/width': dataset_util.int64_feature(shape[1]),\r\n                                    'image/channels': dataset_util.int64_feature(shape[2]),\r\n                                    'image/shape': dataset_util.int64_list_feature(shape),\r\n                                    'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\r\n                                    'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\r\n                                    'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\r\n                                    'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\r\n                                    'image/object/bbox/class/label': dataset_util.int64_list_feature(labels),\r\n                                    'image/object/bbox/class/text': dataset_util.bytes_list_feature(labels_text),\r\n                                    'image/object/bbox/difficult': dataset_util.int64_list_feature(difficult),\r\n                                    'image/object/bbox/truncated': dataset_util.int64_list_feature(truncated),\r\n                                    'image/format': dataset_util.bytes_feature(image_format),\r\n                                    'image/encoded': dataset_util.bytes_feature(image_data),\r\n                                    'image/filename': dataset_util.bytes_feature(filename_str.encode('utf-8')),\r\n                                    'image/source_id': dataset_util.bytes_feature(filename_str.encode('utf-8'))\r\n                                }\r\n                            )\r\n                        )\r\n```\r\n\r\nAs you observe, I had written image/object/bbox/class/label instead of image/object/class/label. I hope this helps.", "> I am still facing this issue in the newer version of tensroflow object detection api...can someone help\r\n> This happens when I use the oxford pets train record file also for the pascal voc file. Not sure what's going on here\r\n> indices[0] = 0 is not in [0, 0)\r\n> [[{{node GatherV2_2}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[\"loc:@RandomHorizontalFlip/cond_2/Switch_1\"], _device=\"/device:CPU:0\"](cond/Merge, Reshape_8, GatherV2_4/axis)]]\r\n\r\nI am having the same issues with Mask RCNN", "i am getting this issue during usage of \"mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8\" this model and I have follow this tutorial https://towardsdatascience.com/how-to-train-a-tensorflow-2-object-detection-model-25d4da64b817\r\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\", line 67, in wait\r\n    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 0 is not in [0, 0)\r\n\t [[{{node GatherV2_4}}]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\r\nhttps://colab.research.google.com/drive/1O9uu2-kO-TeBgdDnl7mS3nsZ4fqOLMYs#scrollTo=ku2p5w0pkn_g  my colab notebook", "I have the same issue, here is my TFrecords conversions, can someone help?\r\n\r\n\r\nI am trying to write the equivalent of this [code][1] which converts CSV to TF records but instead, I am trying to convert from JSON to TFrecords. I am trying to generate TFrecords for using it in [object detection API][2]. \r\n\r\nHere is my full error message\r\n\r\n    Traceback (most recent call last):\r\n      File \"model_main_tf2.py\", line 113, in <module>\r\n        tf.compat.v1.app.run()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n        _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n        _run_main(main, args)\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n        sys.exit(main(argv))\r\n      File \"model_main_tf2.py\", line 109, in main\r\n        record_summaries=FLAGS.record_summaries)\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 561, in train_loop\r\n        unpad_groundtruth_tensors)\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 342, in load_fine_tune_checkpoint\r\n        features, labels = iter(input_dataset).next()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 645, in next\r\n        return self.__next__()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 649, in __next__\r\n        return self.get_next()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 694, in get_next\r\n        self._iterators[i].get_next_as_list_static_shapes(new_name))\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\distribute\\input_lib.py\", line 1474, in get_next_as_list_static_shapes\r\n        return self._iterator.get_next()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\multi_device_iterator_ops.py\", line 581, in get_next\r\n        result.append(self._device_iterators[i].get_next())\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 825, in get_next\r\n        return self._next_internal()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 764, in _next_internal\r\n        return structure.from_compatible_tensor_list(self._element_spec, ret)\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\contextlib.py\", line 99, in __exit__\r\n        self.gen.throw(type, value, traceback)\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 2105, in execution_mode\r\n        executor_new.wait()\r\n      File \"C:\\ProgramData\\anaconda3\\envs\\4_SOA_OD_v2\\lib\\site-packages\\tensorflow\\python\\eager\\executor.py\", line 67, in wait\r\n        pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[12] = 12 is not in [0, 0)\r\n             [[{{node GatherV2_4}}]]\r\n             [[MultiDeviceIteratorGetNextFromShard]]\r\n             [[RemoteCall]]\r\n\r\n\r\nAnd here is my code, which is an attempt to convert JSON files into TFrecords\r\n\r\nSample JSON file\r\n\r\n    {\r\n      \"0.jpg59329\": {\r\n        \"filename\": \"0.jpg\",\r\n        \"size\": 59329,\r\n        \"regions\": [{\r\n          \"shape_attributes\": {\r\n            \"name\": \"rect\",\r\n            \"x\": 412,\r\n            \"y\": 130,\r\n            \"width\": 95,\r\n            \"height\": 104\r\n          },\r\n          \"region_attributes\": {}\r\n        }, {\r\n          \"shape_attributes\": {\r\n            \"name\": \"rect\",\r\n            \"x\": 521,\r\n            \"y\": 82,\r\n            \"width\": 126,\r\n            \"height\": 106\r\n          },\r\n          \"region_attributes\": {}\r\n        }\r\n    }\r\n\r\nMy Python Code\r\n\r\n    # Ref 1: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md\r\n    # Ref 2: https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py\r\n    \r\n    import json\r\n    import glob\r\n    from object_detection.utils import dataset_util\r\n    import tensorflow as tf\r\n    from pathlib import Path\r\n    \r\n    flags = tf.compat.v1.app.flags\r\n    flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\r\n    FLAGS = flags.FLAGS\r\n    \r\n    \r\n    def json_to_tf(jsonFile, im):\r\n        with open(im, \"rb\") as image:\r\n            encoded_image_data = image.read()\r\n    \r\n        with open(jsonFile) as json_file:\r\n            data = json.load(json_file)\r\n    \r\n            for key, value in data.items():\r\n                width = 1920\r\n                height = 1080\r\n                filename = value[\"filename\"]\r\n                filename = filename.encode('utf8')\r\n                image_format = b'jpeg'\r\n                xmins = []\r\n                xmaxs = []\r\n                ymins = []\r\n                ymaxs = []\r\n                classes_text = []\r\n                classes = []\r\n    \r\n                for x in value[\"regions\"]:\r\n                    xmins.append(x[\"shape_attributes\"]['x'])\r\n                    xmaxs.append(x[\"shape_attributes\"]['width'] + x[\"shape_attributes\"]['x'])\r\n                    ymins.append(x[\"shape_attributes\"]['y'])\r\n                    ymaxs.append(x[\"shape_attributes\"]['height'] + x[\"shape_attributes\"]['y'])\r\n                    classes_text.append(\"cars\".encode('utf8'))\r\n                    classes.append(1)\r\n    \r\n                tf_example = tf.train.Example(features=tf.train.Features(feature={\r\n                    'image/height': dataset_util.int64_feature(height),\r\n                    'image/width': dataset_util.int64_feature(width),\r\n                    'image/filename': dataset_util.bytes_feature(filename),\r\n                    'image/source_id': dataset_util.bytes_feature(filename),\r\n                    'image/encoded': dataset_util.bytes_feature(encoded_image_data),\r\n                    'image/format': dataset_util.bytes_feature(image_format),\r\n                    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\r\n                    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\r\n                    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\r\n                    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\r\n                    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\r\n                    'image/object/class/label': dataset_util.int64_list_feature(classes),\r\n                }))\r\n    \r\n                return tf_example\r\n    \r\n    \r\n    writer = tf.compat.v1.python_io.TFRecordWriter(\"train.record\")\r\n    \r\n    for fn in glob.glob(\"annotation_refined\\\\*.json\"):\r\n        for img in glob.glob(\"images\\\\*.jpg\"):\r\n            if Path(fn).stem == Path(img).stem:\r\n                tf_example_1 = json_to_tf(fn, img)\r\n                writer.write(tf_example_1.SerializeToString())\r\n    \r\n    writer.close()\r\n\r\nCan someone give any tips on what is going wrong?\r\n\r\n  [1]: https://github.com/abdelrahman-gaber/tf2-object-detection-api-tutorial/blob/master/data_gen/generate_tfrecord.py\r\n  [2]: https://github.com/tensorflow/models/tree/master/research/object_detection\r\n\r\n", "> Experiencing a similar issue with a fresh install of TF models:\r\n> \r\n> ```\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 0 is not in [0, 0)\r\n> \t [[{{node GatherV2_4}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_INT64, _device=\"/device:CPU:0\"](cond_1/Merge, Reshape_8, GatherV2_3/axis)]]\r\n> \t [[node IteratorGetNext (defined at object_detection/model_main.py:106)  = IteratorGetNext[output_shapes=[[128], [128,640,640,3], [128,2], [128,3], [128,100], [128,100,4], [128,100,90], [128,100,90], [128,100], [128,100], [128,100], [128]], output_types=[DT_INT32, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_BOOL, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorV2)]]\r\n> ```\r\n\r\nme too", "I am having the exact same issue:\r\n\r\n`Successfully opened dynamic library libcublas.so.10\r\nTraceback (most recent call last):\r\n  File \"/home/achyut/projects/tf_models/official/vision/detection/main.py\", line 263, in <module>\r\n    app.run(main)\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/achyut/projects/tf_models/official/vision/detection/main.py\", line 258, in main\r\n    run()\r\n  File \"/home/achyut/projects/tf_models/official/vision/detection/main.py\", line 252, in run\r\n    callbacks=callbacks)\r\n  File \"/home/achyut/projects/tf_models/official/vision/detection/main.py\", line 124, in run_executor\r\n    save_config=True)\r\n  File \"/home/achyut/projects/tf_models/official/modeling/training/distributed_executor.py\", line 491, in train\r\n    tf.convert_to_tensor(num_steps, dtype=tf.int32))\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 840, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\r\n    cancellation_manager=cancellation_manager)\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 550, in call\r\n    ctx=ctx)\r\n  File \"/home/achyut/anaconda3/envs/keras_tf_2.2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.\r\n  (0) Invalid argument:  indices[0] = 0 is not in [0, 0)\r\n\t [[{{node parser/GatherV2}}]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNext]]\r\n\t [[Identity_15/_2552]]\r\n  (1) Invalid argument:  indices[0] = 0 is not in [0, 0)\r\n\t [[{{node parser/GatherV2}}]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNext]]\r\n  (2) Invalid argument:  indices[0] = 0 is not in [0, 0)\r\n\t [[{{node parser/GatherV2}}]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNext]]\r\n\t [[while/LoopControlInputs/_1755/_2399]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_step_182532]\r\n\r\nFunction call stack:\r\ntrain_step -> train_step -> train_step`\r\n\r\n**I solved the issue** by editing the following from create_coco_tf_record.py\r\nIf you have used this script from the research/object_detection/dataset_tools/create_coco_tf_record.py\r\n\r\nmodify the following first block of code with the second block. Now it works on all the devices. Cheers!\r\n\r\n`'image/object/class/text':\r\n          dataset_util.bytes_list_feature(category_names),`\r\n\r\n`'image/object/bbox/class/label':\r\n          dataset_util.int64_list_feature(category_ids),\r\n      'image/object/class/text':\r\n          dataset_util.bytes_list_feature(category_names),\r\n      'image/object/class/label':\r\n          dataset_util.int64_list_feature(category_ids),`\r\n\r\n\r\n@poxvoculi\r\nNo luck on GPU, TPU, CPU. Please help. I am training using my custom dataset. I was using the official create_tf_record_from_coco.py script from the dataset_tools folder. Can't this script automate the sanity check of the data?", "> **I solved the issue** by editing the following from create_coco_tf_record.py\r\n> If you have used this script from the research/object_detection/dataset_tools/create_coco_tf_record.py\r\n> \r\n> modify the following first block of code with the second block. Now it works on all the devices. Cheers!\r\n> \r\n> `'image/object/class/text': dataset_util.bytes_list_feature(category_names),`\r\n> \r\n> `'image/object/bbox/class/label': dataset_util.int64_list_feature(category_ids), 'image/object/class/text': dataset_util.bytes_list_feature(category_names), 'image/object/class/label': dataset_util.int64_list_feature(category_ids),`\r\n> \r\n> @poxvoculi\r\n> No luck on GPU, TPU, CPU. Please help. I am training using my custom dataset. I was using the official create_tf_record_from_coco.py script from the dataset_tools folder. Can't this script automate the sanity check of the data?\r\n\r\n@mhs-achyut \r\n\r\nHow do you know that modification is correct? Are you sure the modification is not going to mess with the other parts of the code? \r\n\r\nAlso after the line `'image/object/class/text': dataset_util.bytes_list_feature(category_names),`, there are two more entries. \r\n\r\n```\r\n'image/object/is_crowd': dataset_util.int64_list_feature(is_crowd),\r\n'image/object/area': dataset_util.float_list_feature(area),\r\n```\r\n\r\nshould I keep them as they are?", "\r\n \r\n> **I solved the issue** by editing the following from create_coco_tf_record.py\r\n> If you have used this script from the research/object_detection/dataset_tools/create_coco_tf_record.py\r\n> \r\n> modify the following first block of code with the second block. Now it works on all the devices. Cheers!\r\n> \r\n> `'image/object/class/text': dataset_util.bytes_list_feature(category_names),`\r\n> \r\n> `'image/object/bbox/class/label': dataset_util.int64_list_feature(category_ids), 'image/object/class/text': dataset_util.bytes_list_feature(category_names), 'image/object/class/label': dataset_util.int64_list_feature(category_ids),`\r\n> \r\n> @poxvoculi\r\n> No luck on GPU, TPU, CPU. Please help. I am training using my custom dataset. I was using the official create_tf_record_from_coco.py script from the dataset_tools folder. Can't this script automate the sanity check of the data?\r\n\r\nTried this solution on my GPU instance, unfortunately, the fix doesn't work for me", "> i am getting this issue during usage of \"mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8\" this model and I have follow this tutorial https://towardsdatascience.com/how-to-train-a-tensorflow-2-object-detection-model-25d4da64b817\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\", line 67, in wait\r\n> pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 0 is not in [0, 0)\r\n> [[{{node GatherV2_4}}]]\r\n> [[MultiDeviceIteratorGetNextFromShard]]\r\n> [[RemoteCall]]\r\n> \r\n> https://colab.research.google.com/drive/1O9uu2-kO-TeBgdDnl7mS3nsZ4fqOLMYs#scrollTo=ku2p5w0pkn_g my colab notebook\r\n\r\nAny luck with this? I'm on same boat...", "I was having this issue using the centernet_mobilenetv2 model, I solved it by deleting the _num_keypoints_ parameter from the pipeline.config file, I was able to run the training without this. I guess there is some kind of problem setting that parameter. Hope this helps someone.", "> I was having this issue using the centernet_mobilenetv2 model, I solved it by deleting the _num_keypoints_ parameter from the pipeline.config file, I was able to run the training without this. I guess there is some kind of problem setting that parameter. Hope this helps someone.\r\n\r\nWhat do you mean by 'num_keypoints'?\r\n", "There are two lines in pipeline.config with `num_kepoints: 17` for CenterNet MobilenetV2, in `train_input_reader` and `eval_input_reader`. Just delete both lines to solve this error.\r\n\r\nLink to the centernet object detection model \r\nhttp://download.tensorflow.org/models/object_detection/tf2/20210210/centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz\r\n\r\nThis model is Object Detection only, it's not doing keypoints (that's the other CenterNet model that does keypoints too)\r\n", "For mask RCNN, I have used a different script to generate my TFrecord files and it works now.\r\n\r\nI used the read_pbtxt_file.py and TFrecord_json.py downloaded from [here](https://www.protocols.io/view/protocol-mask-rcnn-ct-tensorflow-buusnwwe?step=7.2) which split the data into train and val and then convert the LabelMe .json files into TFrecord files.\r\n\r\nLines must be modified in read_pbtxt_file.py by changing \"tf.gfile.GFile\" by \"tf.io.gfile.GFile*\" and \"tf.gfile.Exists(path)\" by \"tf.io.gfile.exists(path)\".\r\nLines must be modified in TFrecord_json.py by changing \"import tensorflow as tf\" by \"import tensorflow.compat.v1 as tf\" and by changing the \"PNG\" to whatever format you need.\r\n\r\nThen you can use the command:\r\npython TFrecord_json.py --images_dir=./json_test --label_map_path=./liver_lesion_map.pbtxt --output_path=./"]}, {"number": 17274, "title": "Unable to get FLOPs on model with tf.nn.bidirectional_dynamic_rnn", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian/Sid\r\n- **TensorFlow installed from (source or binary)**: binary, tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA 9.0/CuDNN v7\r\n- **GPU model and memory**: GTX1080, 8GB\r\n\r\nRunning the model under `benchmark_model`, I'm unable to get any FLOPs value, and there are several strange pieces in the output:\r\n```\r\n2018-02-26 14:37:55.738267: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/fw/fw/while/Switch\r\n2018-02-26 14:37:55.738500: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/bw/bw/while/Switch_1\r\n2018-02-26 14:37:55.738507: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/bw/bw/while/Switch\r\n2018-02-26 14:37:55.739153: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/fw/fw/while/Switch_3\r\n2018-02-26 14:37:55.739165: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/fw/fw/while/Switch_2\r\n2018-02-26 14:37:55.739171: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/fw/fw/while/Switch_4\r\n2018-02-26 14:37:55.739300: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/bw/bw/while/Switch_3\r\n2018-02-26 14:37:55.739307: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/bw/bw/while/Switch_4\r\n2018-02-26 14:37:55.739311: W tensorflow/core/util/stat_summarizer.cc:78] Output tensor changed between runs for 'bidirectional_rnn/bw/bw/while/Switch_2\r\n```\r\n\r\nAnd\r\n```\r\n2018-02-26 14:38:33.921383: E tensorflow/tools/benchmark/benchmark_model.cc:579] FLOPs calculation failed with Internal: Retval[4] has already been set.\r\n```", "comments": ["Generate the model: `python make_rnn_test.py test_benchmark.pb`\r\nRun the benchmark: `./bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=test_benchmark.pb.pb --input_layer=\"garbage_batch_x:0\" --input_layer_type=float --input_layer_shape=\"1,1,492\" --input_layer_values=\"0.0\" --output_layer=\"garbage_outputs:0\" --show_flops=true --max_num_runs=1000`", "[log run](https://github.com/tensorflow/tensorflow/files/1758801/test_benchmark.log)", "```\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\nfrom __future__ import absolute_import, division, print_function\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.tools import freeze_graph\r\n\r\nimport re\r\nimport os\r\nimport sys\r\n\r\nif len(sys.argv) != 2:\r\n    print(\"%s: graphName\" % (sys.argv[0]))\r\n    print(\"will produce: graphName.{pb,pbtxt} and graphName.dot\")\r\n    print(\"got:\", sys.argv)\r\n    sys.exit(1)\r\n\r\ngraph_pb   = os.path.abspath(\"%s.pb\" % sys.argv[1])\r\ngraph_ckpt = os.path.abspath(\"%s.ckpt\" % sys.argv[1])\r\ntemp_pb    = os.path.abspath(\"%s.non-frozen.pb\" % sys.argv[1])\r\nconfig_pb  = os.path.abspath(\"%s.pbtxt\" % sys.argv[1])\r\ngraph_dot  = os.path.abspath(\"%s.dot\" % sys.argv[1])\r\n\r\nuse_rnn = False\r\n\r\ng = tf.Graph()\r\nwith g.as_default() as g:\r\n    n_input    = 26\r\n    n_context  = 9\r\n    n_cell_dim = 2\r\n    n_hidden_3 = 2 * n_cell_dim\r\n\r\n    batch_x = tf.placeholder(tf.float32, [None, None, n_input + 2*n_input*n_context], name='garbage_batch_x')\r\n    seq_length = tf.placeholder(tf.int32, [None], name='garbage_seq_length')\r\n\r\n    batch_x_shape = tf.shape(batch_x, name='garbage_batch_x_shape')\r\n    batch_x = tf.transpose(batch_x, [1, 0, 2], name='garbage_batch_x_transpose')\r\n    batch_x = tf.reshape(batch_x, [-1, n_input + 2*n_input*n_context], name='garbage_batch_x_reshape')\r\n    layer_input = tf.reshape(batch_x, [-1, batch_x_shape[0], n_hidden_3], name='garbage_layer_input')\r\n\r\n    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_cell_dim, forget_bias=1.0, state_is_tuple=True)\r\n    lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_cell_dim, forget_bias=1.0, state_is_tuple=True)\r\n\r\n    rnn_fw_cell = tf.contrib.rnn.BasicRNNCell(n_cell_dim)\r\n    rnn_bw_cell = tf.contrib.rnn.BasicRNNCell(n_cell_dim)\r\n\r\n    outputs, output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw=rnn_fw_cell if use_rnn else lstm_fw_cell,\r\n                                                             cell_bw=rnn_bw_cell if use_rnn else lstm_bw_cell,\r\n                                                             inputs=layer_input,\r\n                                                             dtype=tf.float32,\r\n                                                             time_major=True,\r\n                                                             sequence_length=None)\r\n\r\n    outputs = tf.concat(outputs, 2, name='garbage_outputs')\r\n\r\nsession_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\r\n\r\nwith tf.Session(graph=g, config=session_config) as sess:\r\n    init_op = tf.global_variables_initializer()\r\n    saver = tf.train.Saver()\r\n\r\n    r = sess.run(init_op)\r\n    #sess.run(outputs)\r\n\r\n    tf.train.write_graph(g, os.path.dirname(temp_pb), os.path.basename(temp_pb), as_text=False)\r\n\r\n    # Save the variables to disk.\r\n    save_path = saver.save(sess, graph_ckpt)\r\n    print(\"Model saved in path: %s\" % save_path)\r\n\r\n    # Freeze graph\r\n    input_graph_path = temp_pb\r\n    input_saver_def_path = ''\r\n    input_binary = True\r\n    output_node_names = 'garbage_outputs'\r\n    restore_op_name = 'save/restore_all'\r\n    filename_tensor_name = 'save/Const:0'\r\n    output_graph_path = graph_pb\r\n    clear_devices = False\r\n    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\r\n                               input_binary, save_path, output_node_names,\r\n                               restore_op_name, filename_tensor_name,\r\n                               output_graph_path, clear_devices, '')\r\n```", "Switching to RNN cell does not help, removing the layer `tf.nn.bidirectional_dynamic_rnn` helps.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@angersson I'm not asking now how to use `benchmark_model`, I'm reporting that a model with a `tf.nn.bidirectional_dynamic_rnn` is actually breaking (at least some) features of `benchmark_model`.", "@ebrevdo, can you comment on this?", "@petewarden do you have experience with dynamic rnn and benchmark_model?", "I am facing the same issue, look like `dynamic rnn` is a problem for `benchmark_model`. Any new progress?", "I encountered the same issue, trying to utilize benchmark_model to evaluate the FLOPS for my custom RNN model.\r\n\r\nAny solution?", "We're moving away from `bidirectional_dynamic_rnn` :/", "@lissyx \r\n\r\nthere is a utility inside tensorflow, i.e. tfprof (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/tfprof), which can be used to compute the FLOPs for rnn models.\r\n\r\nyou may want to have a try.", "Thanks, this was not documented anywhere when we started that."]}, {"number": 17266, "title": "'num' must be either a scalar or vector in tf.unstack?", "body": "```\r\nbatch_size = tf.placeholder([],dtype=tf.int32) \r\ntf_x = tf.placeholder(tf.float32, [None,timestep_size,input_size])     \r\n  \r\nlstm_cell = rnn.BasicLSTMCell(num_units=hidden_size, forget_bias=1.0, state_is_tuple=True)\r\ninit_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\r\n\r\ninputs = tf.unstack(tf_x,num=batch_size,axis=0)\r\n\r\nValueError: 'num' must be either a scalar or vector, but saw tensor\r\n```\r\n\r\nWhen training and test, I want to use the different batch size. But in `unstack` function, the `num` parameter doesn't support a tensor as input. However, in `zero_state` function, the first parameter can support a tensor as input. I think the new version should support this practical feature. Thanks!", "comments": ["@angersson can I add a fix to this issue??", "@kdhingra307 Please do! If you plan to contribute the code yourself, please have a look at [CONTRIBUTING.md](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md).", "@angersson i will, thanks", "@angersson  I finished the implementation.", "@jason9693 Could you open a PR? I think it can be more convenient for review. By the way, perhaps we'd better let `gen_array_ops.unpack` supports `num` Tensor, rather than convert Tensor back to int :-)", "@facaiy https://github.com/tensorflow/tensorflow/pull/19146\r\n yeah, I agree. We'd better to change gen_array_ops.unpack.\r\nbut, gen_array_ops.py is immutable (it generated by .cc file...), So we'd let array_ops.cc supports num Tensor.  \r\nOpen a PR means open a Pull Request on my repository(forked repository)? ", "@jason9693 Yes, happy to see your pull request :-)  I agree that it's better to modify c++ code to support num Tensor. ", "@facaiy https://github.com/tensorflow/tensorflow/pull/19146\r\nIt's my pull request :-)"]}, {"number": 17203, "title": "Modify distributed TF examples to take kubeflow's TF_CONFIG as well as command line arguments.", "body": "Currently most of the examples under `tensorflow/tools/dist_test` require command line arguments to be passed in to construct the cluster spec.\r\n\r\nThe tensorflow operator is standardizing under a representation of the cluster spec within a variable called `TF_CONFIG`, which looks like this:\r\n\r\n```\r\n{\"cluster\":{\"master\":[\"myjob237-master-06pz-0:2222\"],\"ps\":[\"myjob237-ps-06pz-0:2222\",\"myjob237-ps-06pz-1:2222\"],\"worker\":[\"myjob237-worker-06pz-0:2222\"]},\"task\":{\"type\":\"master\",\"index\":0},\"environment\":\"cloud\"}\r\n```\r\n\r\nIt would be ideal of the examples were modified to take this variable so we can reduce the shimming required in Kubeflow related efforts, without breaking backward compatibility and keeping the command line args.", "comments": ["@yifeif what do you think about this proposal?\r\n", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@caisq how does this sound?", "Not sure why did you assign it to me.", "As a follow up to this, it looks like tf.Estimator automatically processes TF_CONFIG. So maybe the better idea is to just switch all examples to tf.Estimator?", "@sguada - I assigned you by mistake and unassigned almost immediately.\r\n@caisq - Would any of @elsonrodriguez proposals be a welcome contribution?", "Yes, @tatinashp @elsonrodriguez contributions are welcome. I may have time to work on that this month, too. If I start working, I'll send a note here. Otherwise, assume I haven't started working on it yet.", "@elsonrodriguez  If you would like to submit PR for the functionality that you mentioned it would be great. Please post here if you do.  Let us know if you need further clarification. Thanks!\r\n", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 17136, "title": "Feature Request: Make beam_search_decoder use multiple CPU threads.", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:N.A.\r\n- **GCC/Compiler version (if compiling from source)**:4.9.4\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: GTX 1080Ti\r\n- **Exact command to reproduce**: N.A.\r\n\r\n### Describe the problem\r\nAdd multiple threads support for tf.nn.ctc_beam_search_decoder, for now the tf.nn.ctc_beam_search_decoder is using CPU and only run on 1 thread(although multiple threads has been provided), make it use several CPU threads to run would be very useful as the decoding process of the beam_search_decoder is now the bottleneck of the inference.\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nI use the nvidia-smi and htop to observe the CPU and GPU usage when running a test CTC decoding process, only 1 CPU thread is used and 0 GPU-Utilitiy has been observed during decoding.", "comments": ["I don't believe we have anyone actively working on this, however, contributions are welcome. \r\nThe change would likely involve updating the C++ implementation of the operation in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ctc_decoder_ops.cc#L178 to utilize multiple threads.", "@asimshankar , I would like to work on this issue. ", "@asimshankar ,Can you please check the PR and give feedback? If everything is okay, I will move to parallelize beam search and a GPU implementation of CTC. Thank you very much. ", "> @asimshankar ,Can you please check the PR and give feedback? If everything is okay, I will move to parallelize beam search and a GPU implementation of CTC. Thank you very much.\r\n\r\nThx! By the way, is there a parallel CTC beam search decoder?"]}, {"number": 17097, "title": "Feature request: complex support in initializers", "body": "AFAIK no initializers work with tf.complex64 and tf.complex128 (is there a mathematical reason for this?).\r\n\r\nMy current workaround is to call them twice (once for the real part and once for the imaginary), as\r\n```py\r\ndef complex_initializer(base_initializer):\r\n    f = base_initializer()\r\n\r\n    def initializer(*args, dtype=tf.complex64, **kwargs):\r\n        real = f(*args, **kwargs)\r\n        imag = f(*args, **kwargs)\r\n        return tf.complex(real, imag)\r\n\r\n    return initializer\r\n\r\n\r\ntf.get_variable(\r\n        name='my_complex_variable',\r\n        shape=[1],\r\n        dtype=tf.complex64,\r\n        initializer=complex_initializer(tf.random_normal_initializer))\r\n```\r\nwhich seems to work fine so I'm wondering why this isn't built-in already?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: any\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.6.0-rc1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9/7.5\r\n- **GPU model and memory**: Titan X\r\n- **Exact command to reproduce**: `tf.get_variable('x', [1], tf.complex64, tf.random_normal_initializer)`", "What do you think about a complex number initializer? @mrry \r\n", "Sounds like it could be a useful feature to add.", "Having read up more, complex weight initialization is actually more subtle than I hoped, and somewhat uncharted territory, so if it were to be merged into TensorFlow it probably fits better into contrib somewhere at the moment.\r\n\r\nJust doing the real and imaginary part separately like I proposed above might be too naive because in terms of polar coordinates we probably only want normal distributed magnitudes while the argument should be invariant for full rotations. [Here's the Keras implementation of Deep Complex Networks](https://github.com/ChihebTrabelsi/deep_complex_networks/blob/master/complexnn/init.py#L130-L191) that should correspond to `tf.orthogonal_initializer` with complex dtypes, for example.", "Ping @ChihebTrabelsi for input. \ud83d\ude03 ", "May I ask you if there has been made any progress? I found out a weird behavior for initializing complex-valued tensors:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport time as time\r\n\r\nmysize = 256\r\nmymat = np.ones((mysize,mysize,mysize))\r\nmymat_cmplx = mymat+1j*mymat\r\n\r\n# convertinig complex numpy to tensor\r\nt1 = time.time()\r\nTF_mymat_cmplx = tf.constant(mymat_cmplx)\r\nt2 = time.time()\r\nprint('Time is: '+str(t2-t1))\r\n\r\n# convertinig complex numpy to tensor\r\nt1 = time.time()\r\nTF_mymat_cmplx = tf.complex(np.real(mymat_cmplx), np.imag(mymat_cmplx))\r\nt2 = time.time()\r\nprint('Time is: '+str(t2-t1))\r\n```\r\nwhich gives:\r\n```\r\nTime is: 20.639596700668335\r\nTime is: 3.303292989730835\r\n```\r\nBoth parts should do the same, but the latter one is approx. 6x faster. Any ideas? \r\nIt was measured on Mac/Ubuntu/Windows with TF 1.13 GPU and CPU. \r\n\r\nKind regards!", "Are there any plans to implement this?\r\n\r\nIf no, I am happy to offer up a contribution.  All I would need are some links to where the code would need to be added to add a new type of initializer to support complex64/128s"]}, {"number": 17076, "title": "Sample for report_tensor_allocations_upon_oom and RunOptions", "body": "This is a feature request.\r\n\r\nPlease add some example to the docs describing how to use report_tensor_allocations_upon_oom and other options of RunOptions\r\n\r\nAll I could find is this file:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/model_analyzer_test.py\r\n\r\nBut it is not obvious. For example, it contains:\r\n\r\n    from tensorflow.core.protobuf import config_pb2\r\n\r\nand then\r\n\r\n    with session.Session() as sess:\r\n        sess.run(c, options=config_pb2.RunOptions(\r\n            report_tensor_allocations_upon_oom=True))\r\n\r\nAnd more questions arise like: \"What is config_pb2?\" etc.\r\n\r\nThanks.", "comments": ["@Yagun Do you care about CPU, GPU, or both?", "I got it work like this:\r\n```\r\nrun_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\r\nsess.run(op, feed_dict=fdict, options=run_options)\r\n```\r\nThis will produce messages like this :\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[Node: Tile = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, Tile/multiples)]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from cKR/sub\r\n\r\n         [[Node: concat/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8207_concat\", tensor_type=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from cKR/sub\r\n```\r\n\r\nBut it seems like - it does not contain all allocation, rendering it a bit pointless :/\r\nThe error message above is for a 15GB p100 gpu and it says it only allocated 145 MB, but fails on allocating  a tesnor of shape [100000,60,190] -> around 9GB.\r\n\r\n@cy89 is there a way to get even more details? \r\n\r\n@Yagun for more Information regarding runoptions you may look here:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/protobuf/config.proto\r\nBut it is really limited and not a real tutorial.\r\n\r\nI think TF is in a real need of an in deep Tutorial for understanding its core and how to debug in case of errors. Handling OOM on the GPU is quiet a pain without understanding the allocations\r\n\r\n\r\n", "@cy89, I care about GPU more, because it usually has 2 to 4 GB RAM.\r\n\r\n@georgh, thank you very much for this example.", "@zheng-xq can you please point @georgh at tools he can use to better inspect GPU memory allocation? Or is there a docs page we can point him at, or build for him?", "@cy89 @zheng-xq \r\nThe main problem I encountered was the missing allocation information for placeholders. My findings regarding the problem are summarized in #17092 (would be great if a tensorflower would take a look at this)\r\nI think doc pages for inspecting GPU allocation would be great. But I just found \r\nhttps://www.tensorflow.org/programmers_guide/debugger and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/README.md\r\nso this might be the tool / docs I didn't find before. (Side has changed quite a bit since the last time I had a look) Maybe they even display placeholder memory usage. Have to test them now. ", "I agree that this is a good feature request, i.e. there should be a guide to memory use debugging in TF, especially GPU memory use since there are some non-obvious tricks going on.   Eventually someone from TF will probably get around to doing it, but probably not soon, so I'm going to mark it contributions welcome.  @geogh I see that you made some progress in the other thread, using @yaroslavvb 's tool.  It would be great if either of you want to contribute some notes on this topic.", "Kindly requesting what is the status of this ticket?", "I would like to know most recent status of this ticket.", "Also pinging in here. TF reports\r\n> Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info\r\n\r\nBut there doesn't seem to be a way to do that in TF 2.x", "@Yagun,\r\nDebugging of Performance Bottlenecks can be done using **`Profiler Tool`**. Please find the [Explanation in TF Site](https://www.tensorflow.org/guide/profiler#memory_profile_tool) and the  [Example Code](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras). \r\n\r\nHope this helps.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "My previous comment seems to have been missed: There still doesn't seem to be a way to get the OOM info in TF 2 as indicated by the error message shown by TF 2. See also https://github.com/tensorflow/tensorflow/issues/37556 and https://github.com/tensorflow/tensorflow/blob/78d7f8b2ef12509d5f47f16ccf242f861f222636/tensorflow/core/common_runtime/executor.cc#L989-L991", "@Flamefire,\r\nThank you for your response. Did you try **`Profiler Tool`**, mentioned in [this comment](https://github.com/tensorflow/tensorflow/issues/17076#issuecomment-793674481)? ", "Not yet as it involves some setup and usage of a notebook which is a bit involved when running on HPC nodes. Adding some option to have some output on the stdout/stderr in case of failure would have been much more usable in that context.\r\n\r\nAnd if  that is not possible, then TF should not tell you so in its error message. I spend quite some time looking how to follow the advice of \"add report_tensor_allocations_upon_oom to RunOptions\".\r\nIn the end this is what this issue is about: Either there is a way to do that in TF2, then some documentation is needed, or there is not, then it should be added (preferably) or the error message changed.", "Closing as stale. Please reopen if you'd like to work on this further.\n", "What's wrong with the bot? There has been activity here since its last comment, so why close it?", "@Flamefire,\r\nSorry for the inconvenience. Reopened the issue.  ", "amazing. this bug is 3 years old and still open"]}, {"number": 17064, "title": "Allocating C++ types instead of Tensors in a new Op - Feature Request", "body": "### System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version: 1.5\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n- Exact command to reproduce: N/A\r\n\r\n### Feature Request\r\n##### Feature requested: the ability to allocate memory in a new op as C++ types and not only as tensors;\r\n\r\nI have been implementing a new op on Tensorflow following the [guide](https://www.tensorflow.org/extend/adding_an_op) and have noticed what could be a useful feature for people implementing new ops in C++/CUDA.\r\n\r\nCurrently using `OpKernelConstruction* context` it is only possible to allocate memory (CPU or GPU) in the form of tensors. For basic  C++ types you can obtain  a pointer for that type easily, for example:\r\n\r\n```\r\nTensor tensor;\r\nOP_REQUIRES_OK(context, context->allocate_temp(DT_FLOAT,  TensorShape({5}), &tensor));\r\nfloat * ptr = tensor.flat<float>.data();\r\n```\r\n\r\nHowever, for more complex types like `structs` this is not possible (or at least not direct). Why not have something like:\r\n\r\n```\r\nstruct A {\r\n    int a;\r\n    int b;\r\n};\r\nA * a = nullptr;\r\nOP_REQUIRES_OK(context, context->allocate_bytes(n_bytes=sizeof(A), address = a));\r\n```\r\n\r\nI think this could be useful when porting C++ code from elsewhere and simplifies memory allocation of non-tensor types in C++.\r\nCould this be a useful feature or is there a good reason it's not implemented?\r\n\r\n### Note:\r\nOne possible work-around with the current system is to allocate a tensor of type `UINT_8`with the number of bytes required and then used `reinterpret_cast `:\r\n\r\n```\r\nstruct A {\r\n    int a;\r\n    int b;\r\n};\r\nA * a = nullptr;\r\nTensor tensor;\r\nOP_REQUIRES_OK(context, context->allocate_temp(DT_UINT8, TensorShape({sizeof(A)}), &tensor));\r\na = reinterpret_cast<A*>(tensor.flat<unsigned char>().data());\r\n```\r\nThis kind of feels like cheating and over complex just for allocating memory.\r\n", "comments": ["@josh11b this one seems like your territory. PTAL. ", "I'm not sure why you are not just using `new`. Is the goal to be able to allocate memory on the device? If so, it is surprising that using a Tensor wouldn't suit your needs. Perhaps you could explain more context.", "The goal is indeed to allocate memory on the device.\r\nThe situation is when you need an array of structs. For instance, when you want to replace the following CUDA code:\r\n```\r\nstruct A {\r\nint a;\r\nint b;\r\nfloat c;\r\n};\r\n\r\nA* a;\r\nint n = 10; // number of elements in the array\r\ncudaMalloc((void**)&a, n * sizeof(A));\r\n```\r\nIt's true that I could allocate three separate tensors but if the structure is more complex this quickly becomes a hassle plus I lose a lot of readability in the code the natural \"belongingness\" of things to classes/structs.\r\n\r\nIn addition, using the CUDA API directly becomes a problem since Tensorflow allocates most of the GPU memory even if it is not going to use it (this is my understanding not 100% sure).", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I don't know much about Cuda memory, maybe @michaelisard @yuefengz or @zheng-xq would know more.  I do know that there is an allocator member of the context but it doesn't look like it is exposed. Perhaps rewriting as Struct of Arrays instead of Array of Structs would be both more aligned with our APIs and faster?", ">  I do know that there is an allocator member of the context but it doesn't look like it is exposed. \r\n\r\nI think it is exposed, but my doubt about it was if it gave back a pointer to pre-allocated memory or if it tried to allocate more GPU memory (which would already be running low if this is the case). Perhaps the people you mentioned can shed some light on this issue.\r\n\r\n> Perhaps rewriting as Struct of Arrays instead of Array of Structs would be both more aligned with our APIs and faster?\r\n\r\nIt definitely would be more aligned with the current APIs, don't know about faster, and there are probably many others ways to achieve the same result. I more coming from the side of from a human programmer perspective there is a difference between an array of structs and a struct of arrays (even if the compiler and subsequent machine code don't care).", "The Tensor in C++ backend is mostly used for reference counting. So your \"cheating\" code looks reasonable for what it does. I agree that wrapping it in a helper function and localize the hackiness might make the overall codebase look better. \r\n\r\nOne potential problem is pointer alignment. But currently TF has very largely alignment by default, so this is not a problem. \r\n\r\nHowever, I agree with Josh that it might not be very performant if your kernel doesn't not use it wisely. With your example, \r\n\r\nstruct A {\r\n    int a;\r\n    int b;\r\n};\r\n\r\nAnd your custom kernel reads: \r\n\r\nA* v1 = ....\r\nint a = v1->a; \r\n\r\nThe reading pattern for that coalesce much worse across Cuda threads than if it is struct of arrays. So you have to be very careful. That's why most Cuda kernels in TensorFlow uses structs of arrays anyway.\r\n", "Thank you for pointing that out, I will find a suitable solution for my own code in the meantime.\r\nGetting back to my initial suggestion, it still seems that only being able to allocate memory in the device as Tensors to be quite limiting and that a little more control for the programmer could be beneficial in some cases.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It looks like this has boiled down to a feature request, so I've tagged it as such to keep the issue tracker focused.", "I also meet this problem, and using\r\n```cpp\r\n        Tensor icfo_tensor;\r\n        OP_REQUIRES_OK(ctx,\r\n                       ctx->allocate_temp(DT_FLOAT,\r\n                                          TensorShape({batch, hiddensize * 4}),\r\n                                          &icfo_tensor));\r\n        float* icfo_tensor_t = icfo_tensor.flat<float>.data();\r\n```\r\nand comes errors with \r\ntensorflow.python.framework.errors_impl.NotFoundError: ./cuda_lstm_forward.so: undefined symbol: _Z18dynamic_layer_calliiiiiPfS_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_S_bffi\r\n"]}, {"number": 17018, "title": "Feature/PR Idea - mean IoU for vector of thresholds", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: `False`\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.0.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: `None`\r\n- **GCC/Compiler version (if compiling from source)**: `None`\r\n- **CUDA/cuDNN version**: `None`\r\n- **GPU model and memory**: Radeon Pro 560 4096 MB - Intel HD Graphics 630 1536 MB\r\n- **Exact command to reproduce**: `None`\r\n\r\n### Summary\r\nI'd love to have a convenient, clean API for expressing the calculation of mean IoU for a set of thresholds instead of a single value. \r\nLike the way it's described here: https://www.kaggle.com/c/data-science-bowl-2018#evaluation\r\n\r\nI'm planning on submitting a PR with a solution unless I get told here that the idea is explicitly being opposed by the decision-makers. Please let me know if you'd consider merging something like this in and I'll move to the next phase.\r\n\r\nI'm assuming that the implementation is possible without having to get knee deep in CUDA C/C++ given that there's already a mean IoU feature here and I would (hopefully) just need to extend that in a backward compatible way so that it takes some optional extra information in the form of a vector of thresholds =>\r\n https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/metrics_impl.py#L948:\r\n\r\nTips and guidance are most welcome, thank you in advance for any help and the verdict as well.\r\n", "comments": ["@drpngx looks like \"mean_iou\" is your code. How do you feel about @petermetz 's proposal?", "Sounds like a good idea.\r\nCC @aquariusjay ", "Thanks @drpngx @cy89 I'll move on to the next phase."]}, {"number": 17012, "title": "LNK2019\tunresolved external symbol __std_reverse_trivially_swappable_8  when compiling proto_text.vcxproj", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: Cmake 3.10.2, swigwin 3.0.12, Visual studio 2017, but toolset 2015 v140\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\nI'm following the CMake guide as described here: https://github.com/tensorflow/tensorflow/blob/fbddebee0bf07dadfb2b15ec678291dd5730ca99/tensorflow/contrib/cmake/README.md.\r\n\r\nError appears after following command:\r\n`MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj`\r\n\r\n### Describe the problem\r\nError when compiling the proto_text.vcxproj\r\n\r\n### Source code / logs\r\n```\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_tutorials_example_trainer.vcxproj\" (default target) (1) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_framework.vcxproj\" (default target) (3) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj\" (default target) (4) ->\r\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\proto_text.vcxproj\" (default target) (5) ->\r\n(Link target) ->\r\n  libprotobuf.lib(text_format.obj) : error LNK2019: unresolved external symbol __std_reverse_trivially_swappable_8 referenced in function \"void __cdecl std::_Buffered_inplace_merge_d\r\nivide_and_conquer2<class google::protobuf::Message const * *,__int64,class google::protobuf::Message const *,class google::protobuf::MapEntryMessageComparator>(class google::protobuf\r\n::Message const * *,class google::protobuf::Message const * *,class google::protobuf::Message const * *,__int64,__int64,struct std::_Temporary_buffer<class google::protobuf::Message\r\nconst *> &,class google::protobuf::MapEntryMessageComparator,class google::protobuf::Message const * *,class google::protobuf::Message const * *,__int64,__int64)\" (??$_Buffered_inpla\r\nce_merge_divide_and_conquer2@PEAPEBVMessage@protobuf@google@@_JPEBV123@VMapEntryMessageComparator@23@@std@@YAXPEAPEBVMessage@protobuf@google@@00_J1AEAU?$_Temporary_buffer@PEBVMessage\r\n@protobuf@google@@@0@VMapEntryMessageComparator@23@0011@Z) [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\proto_text.vcxproj]\r\n  C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\Release\\proto_text.exe : fatal error LNK1120: 1 unresolved externals [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\proto_text.vcxproj]\r\n```\r\n\r\n", "comments": ["@MennoK I'm not sure that you're running any of the \"known-good\" configurations in that README.md file (please correct me if that's wrong). I think we'll need to ask for help from the wider community. ", "I'm using:\r\n\r\nMicrosoft Visual Studio 2017 with Visual C++ toolset 2015 (v140)\r\nAnaconda 4.1.1 (Python 3.5 64-bit)\r\nswigwin-3.0.12\r\nCuda and Cudnn aren't applicable in this case\r\nCMake 3.10.2\r\nWindows 10, but the target platform is set to 8.1\r\n\r\n", "I have both VS2015 and VS2017 installed but I build TF with VS2015 by using `cmake -G \"Visual Studio 14 2015 Win64\"`. But this setting is not transmitted to the child builds and therefore external projects, including protobuf, are built with VS2017. And in this case the build fails with exactly the error reported here.\r\n\r\nHowever, if I rename the VS2017 installation directory to some nonsense so that CMake cannot find it, then also the externals use VS2015 and the build succeeds. So apparently this problem arises from mixing two different toolsets.\r\n\r\nSimilarly, if you are using the CMake `-T` switch to select the toolset, this selection does not propagate to the external builds.", "In my case, the error has been resolved by using CMake 3.6.0 known as good configurations version described here:\r\nhttps://github.com/tensorflow/tensorflow/blob/fbddebee0bf07dadfb2b15ec678291dd5730ca99/tensorflow/contrib/cmake/README.md"]}, {"number": 16888, "title": "tfcompile fails with Executor failed to create kernel. Not found: No registered 'ResizeNearestNeighbor' ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, very simple CNN (attached)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.13.3\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 926fc13\r\n- **Python version**: python 3.6.4\r\n- **Bazel version (if compiling from source)**: 0.10\r\n- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: ./bazel-bin/tensorflow/compiler/aot/tfcompile  --graph=\"/data/models/tensorflow/testmodel.pb\" --config=\"/data/models/tensorflow/testmodel.pbtxt\"\r\n\r\n### Describe the problem\r\nTrying to compile a trivial model, consisting of a single nearest-neighbour resize layer, I get an abort trap 6. The model graph and config can be [found here](https://github.com/tensorflow/tensorflow/files/1710673/testmodel.zip).\r\n\r\n### Source code / logs\r\n```bash\r\n./bazel-bin/tensorflow/compiler/aot/tfcompile  --graph=\"/data/models/tensorflow/testmodel.pb\" --\r\nconfig=\"/data/models/tensorflow/testmodel.pbtxt\"\r\n2018-02-09 11:45:13.215728: E tensorflow/compiler/tf2xla/graph_compiler.cc:115] Executor failed to create kernel. Not found: No registered 'ResizeNearestNeighbor' OpKernel for XLA_CPU_JIT devices compatible with node out/ResizeNearestNeighbor = ResizeNearestNeighbor[T=DT_FLOAT, align_corners=false](aot_feed_0/in, out/mul)\r\n        .  Registered:  <no registered kernels>\r\n\r\n         [[Node: out/ResizeNearestNeighbor = ResizeNearestNeighbor[T=DT_FLOAT, align_corners=false](aot_feed_0/in, out/mul)]]\r\n2018-02-09 11:45:13.216094: F tensorflow/compiler/aot/tfcompile_main.cc:148] Non-OK-status: status status: Not found: No registered 'ResizeNearestNeighbor' OpKernel for XLA_CPU_JIT devices compatible with node out/ResizeNearestNeighbor = ResizeNearestNeighbor[T=DT_FLOAT,\r\nalign_corners=false](aot_feed_0/in, out/mul)\r\n        .  Registered:  <no registered kernels>\r\n\r\n         [[Node: out/ResizeNearestNeighbor = ResizeNearestNeighbor[T=DT_FLOAT, align_corners=false](aot_feed_0/in, out/mul)]]\r\nAbort trap: 6\r\n```", "comments": ["@hawkinsp have you thought about how hard this would be to implement in XLA?", "This op would not be terribly hard to implement via XLA (although perhaps not performantly on CPU).\r\n\r\nThere's already a bilinear resize op (although I suspect it isn't fast on CPU) and one possible implementation strategy is to use almost the same code but with a different convolution kernel. This would at least fix the immediate error here, but I have no idea if it would meet any performance requirements.\r\n\r\nOr if the resize here is an integer-multiple resize, then there are some special case implementations that would be easy to add.\r\n\r\n", "For now I will leave it as contributions welcome in case anyone wants to try to generalize the existing bilinear resize op.", "@michaelisard  : I would love to work on this. Can you share some more info on this.\r\nThanks."]}, {"number": 16856, "title": "Loading model from local in RNN prediction is slower than from HDFS due to page fault ", "body": "We have trained a RNN model and use it to predict. We feed some data and calculate QPS in prediction. We find that when CPU usage is above than 30%, the QPS always stayed in 900+. And not increasing linearly by CPU usage. But if we put the model in HDFS, The QPS can reach 2400+.\r\n\r\nOur system infomation:\r\n```\r\n    OS:  RedHat 7.2\r\n    CPU:  2 * 16 core * 2 thread\r\n    Memory: 512G in 1 node\r\n```\r\n\r\nIn local model case, we use performance tool to trace function call time and find nearly 20% time hanged in page fault which lead to spin_lock.  Those page fault occurs less than 1% in hdfs situation. \r\n\r\nOur performance result listed as below:\r\n\r\n**model loading from local**:\r\n![local](https://user-images.githubusercontent.com/36218095/35960886-6ab0bbf6-0ce6-11e8-9923-63fc9257112f.png)\r\n\r\n**model loading from hdfs**:\r\n![hdfs](https://user-images.githubusercontent.com/36218095/35960906-7e8d9158-0ce6-11e8-896e-a52fced8c02a.png)\r\n\r\nWe check the source code (both eigen and tensorflow ) again and again and can not find any suspectable code which lead to page fault. we test loading model (wide and deep, cnn), page fault not happened. In RNN model we modify the code use HDFS file sytem instead of posix file system. page fault not happend too. we print log in every function in core/platform/posix/posix_file_system.cc. The log is only displayed in model loading, not occurs in prediction process. \r\n\r\nIs anyone can help us to find out this problem? Thank you!\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@jhseu any comment?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Fixes are welcome.", "@kdmxen could you provide a demo to trigger this problem?"]}, {"number": 16839, "title": "Feature request: Enable validate_args for all distributions based on a global parameter", "body": "The probability distributions in Tensorflow have a `validate_args` argument that is initially set to `False`. This is a request for a feature that initializes the value of `validate_args` to the value of a global flag (that can be set from the command line or the preferences).\r\n\r\nRationale: Currently, when the user sets up the model incorrectly e.g. wrong parameter values are provided for the distributions, or data values don't match the support for the distribution, the program silently fails and produces nans in the output (or worse, wrong values). The user has no way to debug this easily because `validate_args` is `False` by default, and manually adding `validate_args=True` while initializing each distribution can be tedious for the user.\r\n\r\nI would be happy to contribute this feature to tensorflow if this seems reasonable. Do you have any suggestions on how to go forward?", "comments": ["Send a pull request and we'll discuss there."]}, {"number": 16835, "title": "Optimized einsum", "body": "In Numpy, it's my understanding that the np.einsum function has been extended with the functionality of\r\n[opt_einsum](https://github.com/dgasmith/opt_einsum), \r\nwhich computes an optimal (or near-optimal) way to perform the tensor contractions.\r\nAs far as I've heard, the Tensorflow einsum is a lot more basic (but extremely convenient), and cannot be relied upon for performance. Also, even though `opt_einsum` can give allegedly perfect decomposition paths, these optimizations appear to not always work well in Tensorflow - which might be down to memory order, available numerical routines, views vs reshapes, etc. \r\n\r\nAs a feature request, I think it would be hugely beneficial to have a high-performing version of `tf.einsum` in Tensorflow, as it makes it easy to handle many complicated linear algebra tasks compactly.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n", "comments": ["@jhseu @rmlarsen do you know if anyone works on einsum? I'm gonna mark contributions welcome for now, as I'm not sure anyone is currently maintaining einsum.", "cc @mstreeter", "@skye I agree that contributions welcome seems right. I don't know of anybody working actively on this.", "Hi, I would like to contribute, can anyone guide for my first contribution.\r\n\r\nThanks!\r\n"]}, {"number": 16779, "title": "Cross-Compiling the TensorFlow wheel for NVIDIA Jetson with CUDA support", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**:  3.5.2\r\n- **Bazel version (if compiling from source)**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: Irrelevant\r\n- **Exact command to reproduce**:\r\n\r\n* Install gcc cross-compiler: `sudo apt-get install gcc-aarch64-linux-gnu g++-aarch64-linux-gnu`\r\n* Install the CUDA `cross-aarch64` packages\r\n* Build Python 3.5.2 for the target\r\n* I wrote a short blog post with the details: https://jany.st/post/2018-02-05-cross-compiling-tensorflow-for-jetson-tx1-with-bazel.html\r\n\r\n```\r\ngit clone https://github.com/ljanyst/tensorflow.git\r\ncd tensorflow\r\ngit checkout v1.5.0-cross-jetson-tx1\r\ncd third_party/toolchains/cpus/aarch64\r\n./configure.py\r\ncd ../../../..\r\n./configure\r\nbazel build  --config=opt --config=cuda \\\r\n   --crosstool_top=//third_party/toolchains/cpus/aarch64:toolchain \\\r\n    --cpu=arm  --compiler=cuda \\\r\n    //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n### Describe the problem\r\nI have succeeded, but I encountered a bunch of issues on the way. Due to my unfamiliarity with Bazel, my solution is rather hacky. It looks to me like properly fixing it is a rather low hanging fruit for a person familiar with Bazel, so I document what I have discovered here.\r\n\r\n#### 1. Configuring CUDA for the target\r\n\r\nI could not find a way in the to check CUDA configuration script whether the source is supposed to be configured for a cross build, so I ended up changing the hardcoded paths: https://github.com/ljanyst/tensorflow/commit/1a2a75fed9a9576c4e9e8f89ee556263cf22deaf If there was a way to check if we're building for a platform that is different from the one of the build host, this could be easily turned into some sort of an if statement.\r\n\r\n#### 2. Specifying target Python installation\r\n\r\nI could not find an easy way to patch that through, so I ended up putting it in the [CROSSTOOL](https://github.com/ljanyst/tensorflow/blob/v1.5.0-cross-jetson-tx1/third_party/toolchains/cpus/aarch64/CROSSTOOL.in) file:\r\n\r\n```\r\ncxx_flag: \"-isystem\"\r\ncxx_flag: \"__TARGET_PYTHON_INCLUDES__\"\r\n```\r\n\r\n#### 3. Code generators depend on `libtensorflow_framework.so` which, in turn, depends on CUDA\r\n\r\nThis means that I needed to have the CUDA and cuDNN libraries for the build host and needed to pass the relevant library paths to the compiler [in a wrapper script](https://github.com/ljanyst/tensorflow/blob/v1.5.0-cross-jetson-tx1/third_party/toolchains/cpus/aarch64/crosstool_wrapper_host_tf_framework#L41).\r\n\r\n#### 4. Linking of the code generators fails on the build-host side\r\n\r\nBazel builds both the code generators and `libtensorflow_framework.so` for the host, but does not link the binaries against the framework library.\r\n\r\nI have worked around the two above issues by writing a compiler wrapper scripts doing the following:\r\n\r\n```python\r\nif ofile is not None:\r\n    is_gen = ofile.endswith('py_wrappers_cc') or ofile.endswith('gen_cc')\r\n    if is_cuda == 'yes' and (ofile.endswith('libtensorflow_framework.so') or is_gen):\r\n        cuda_libdirs = [\r\n            '-L', '{}/targets/x86_64-linux/lib'.format(cuda_dir),\r\n            '-L', '{}/targets/x86_64-linux/lib/stubs'.format(cuda_dir),\r\n            '-L', '{}/lib64'.format(cudnn_dir),\r\n        ]\r\n\r\n    if is_gen:\r\n        tf_libs += [\r\n            '-L', 'bazel-out/host/bin/tensorflow',\r\n            '-ltensorflow_framework'\r\n]\r\n\r\ncall([find_executable('gcc')] + cuda_libdirs + args + tf_libs)\r\n```\r\n\r\n#### 5. Incomplete RPATH in the target-side `libtensorflow_framwork.so`\r\n\r\nThe library gets linked using a bunch of RPATH parameters, but one seems to be missing. It causes linking errors down the road. I have added the following to the original `crosstool_wrapper_driver_is_not_gcc` script to fix the problem:\r\n\r\n```python\r\n  ofile = GetOptionValue(sys.argv[1:], 'o')\r\n  if ofile and ofile[0].endswith('libtensorflow_framework.so'):\r\n    cpu_compiler_flags += [\r\n        '-Wl,-rpath,'+os.getcwd()+'/bazel-out/arm-py3-opt/genfiles/external/local_config_cuda/cuda/cuda/lib',\r\n    ]\r\n```\r\n\r\n#### 6. Platform metadata of the resulting wheel package\r\n\r\nSince the build host platform is `linux_x86_64`, this ends up being written in the wheel metadata. The issue can be fixed by manually passing the `--plat-name` parameter to distutils. I have, therefore, added https://github.com/ljanyst/tensorflow/commit/a9b952e3850b0c416a37f4f4b488adf8189638a7 to `build_pip_package.sh`. Please let me know if you'd like a pull request.\r\n\r\nIt hope it's helpful.\r\n", "comments": ["You might be interested in the binaries I have built for jetson tx2 with CUDA 9 and the last version of L4T\r\nhttps://github.com/Davidnet/JetsonTFBuilds/releases", "Thanks! I actually have no problems with building the wheels on the device, it just takes too long to do that. TensorFlow cross-builds for Jetson on my Core i7 workstation in ~20 minutes.", "Hi @ljanyst ! First , thank you for this issue and for your blog post. I'm trying to reproduce what you've done on my pc because compiling tensorflow on my Xavier took me almost 9 hours. I'm at the start of your tutorial but I think I'm missing something. The compilation of my hello.cxx is working well but then \" scp a.out jetson:\" is giving me an error since my system doesn't know the \"jetson\" hostname which is normal but I wanted to know how can I setup this so that my pc knows what jetson is ?\r\n\r\nThanks a lot ! \r\n\r\nEDIT : I added my xavier to the /etc/hosts file of my computer but now I canno't connect the pc to the Xavier.. Every time I try to connect to it with my password, I have \"Permission denied, please try again\" like if my password was wrong .....\r\n\r\nEdit bis : Everything is fine, forget this message\r\n\r\n", "> Hi @ljanyst ! First , thank you for this issue and for your blog post. I'm trying to reproduce what you've done on my pc because compiling tensorflow on my Xavier took me almost 9 hours. I'm at the start of your tutorial but I think I'm missing something. The compilation of my hello.cxx is working well but then \" scp a.out jetson:\" is giving me an error since my system doesn't know the \"jetson\" hostname which is normal but I wanted to know how can I setup this so that my pc knows what jetson is ?\r\n\r\nCreate a file named config in your .ssh folder, with the content\r\n\r\n```\r\nHost JetsonTX2\r\n\tHostName <IP HERE>\r\n\tUser <USER HERE>\r\n```\r\nAfter this you can use ssh JetsonTX2 (<-- you can rename this) to connect to the server or use scp to copy a file to it.\r\n\r\n\r\n"]}, {"number": 16772, "title": "XLA with frozen protobuf: Tuples do not have a rank error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, model inference script.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.3 LTS (Xenial Xerus)\r\n- **TensorFlow installed from (source or binary)**: Source **with XLA support**\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**: c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: cuda-8.0/cuDNN-6.0.21\r\n- **GPU model and memory**: Tesla K80, 12 Gb\r\n- **Exact command to reproduce**: `CUDA_VISIBLE_DEVICES='0'  TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python name_of_script.py`\r\n\r\n### Describe the problem\r\nI am trying to run model (SSD with MobileNetV1 from [tf-models](https://github.com/tensorflow/models/tree/master/research/object_detection)) with XLA optimization. I am trained this model on my own data set and generated **frozen** protobuf file with provide script [export_inference_graph.py](https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py). \r\n**Note**: Script that run inference works fine **without** XLA. Models from `keras.application` works fine **with** XLA, so I think there are some problems with support of frozen protobufs. \r\n\r\n### Source code / logs\r\nSource code:\r\nAll test completed with next session config:\r\n```\r\ngpu_options = tf.GPUOptions(\r\n            allocator_type='BFC',\r\n            allow_growth=True,\r\n            per_process_gpu_memory_fraction=True\r\n        )\r\n\r\nconfig = tf.ConfigProto(\r\n            allow_soft_placement=True,\r\n            gpu_options=gpu_options\r\n       )\r\n\r\nconfig.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\r\n```\r\n\r\nLog:\r\n```\r\n(tf-models-env) alexkirnas@host:~/scrips/tfDetector$ CUDA_VISIBLE_DEVICES='0'  TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python ssd_model_inference_time_test_random.py              \r\n/tf-models-env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `n\r\np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2018-02-05 10:55:01.159354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero\r\n2018-02-05 10:55:01.160137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:1e.0\r\ntotalMemory: 11.17GiB freeMemory: 11.11GiB\r\n2018-02-05 10:55:01.160163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability\r\n: 3.7)\r\n2018-02-05 10:55:03.544862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability\r\n: 3.7)\r\n2018-02-05 10:55:06.752946: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x7f6454024500 executing computations on platform CUDA. Devices:\r\n2018-02-05 10:55:06.752997: I tensorflow/compiler/xla/service/service.cc:170]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\r\n2018-02-05 10:55:06.757697: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:1254] computation cluster_22[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v9 [optimization: pipeli\r\nne start, before CallInliner]: /tmp/hlo_graph_0.GS9qJI.dot\r\n2018-02-05 10:55:06.757963: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:1254] computation cluster_22[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v9 [optimization: after\r\nCallInliner, before simplification]: /tmp/hlo_graph_1.KFEf5N.dot\r\n\r\n....\r\nLot of such lines as above\r\n.... \r\n\r\n2018-02-05 10:55:45.106105: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:1254] computation cluster_9[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v163 [optimization: after\r\n cse, before dce]: /tmp/hlo_graph_401.V0lBLH.dot\r\n2018-02-05 10:55:45.112071: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:1254] computation cluster_9[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v163 [optimization: after\r\n dce, pipeline end]: /tmp/hlo_graph_402.I2Gnpl.dot\r\n2018-02-05 10:55:45.117834: I tensorflow/compiler/xla/service/hlo_graph_dumper.cc:1254] computation cluster_9[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0].v163 [fusion: pipeline st\r\nart, before fusion]: /tmp/hlo_graph_403.Jmq33Y.dot\r\n2018-02-05 10:55:45.122108: F tensorflow/compiler/xla/shape_util.cc:118] Check failed: !ShapeUtil::IsTuple(shape) Tuples do not have a rank\r\nAborted (core dumped)\r\n```", "comments": ["@hawkinsp what do you think is the best next step to debug this?", "```\r\n2018-02-05 10:55:45.122108: F tensorflow/compiler/xla/shape_util.cc:118] Check failed: !ShapeUtil::IsTuple(shape) Tuples do not have a rank\r\nAborted (core dumped)\r\n```\r\n\r\n[This](https://github.com/tensorflow/tensorflow/blob/a3d90a967e3c1c8d93928ca6620bbfa2fc8ce3a1/tensorflow/compiler/xla/shape_util.cc#L156) is the only `CHECK(!ShapeUtil::IsTuple())` call in shape_util.cc (though the user is reporting TF version 1.4, I doubt invariants to `ShapeUtil::Rank` have changed since).\r\n\r\nUsually failed `CHECK` calls give a stack trace?  I assume we make a bad call to `ShapeUtil::Rank()` on a tuple somewhere."]}, {"number": 16689, "title": "Feature request: Support SparseTensor in Dataset.from_generator ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin c02ql2p2fvh7-c 16.7.0 Darwin Kernel Version 16.7.0: Mon Nov 13 21:56:25 PST 2017; root:xnu-3789.72.11~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.6\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.0.0 (clang-900.0.39.2)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin c02ql2p2fvh7-c 16.7.0 Darwin Kernel Version 16.7.0: Mon Nov 13 21:56:25 PST 2017; root:xnu-3789.72.11~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.14.0)\r\nprotobuf (3.5.1)\r\ntensorflow (1.5.0)\r\ntensorflow-tensorboard (1.5.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.5.0\r\ntf.GIT_VERSION = v1.5.0-0-g37aa430d84\r\ntf.COMPILER_VERSION = v1.5.0-0-g37aa430d84\r\nSanity check: array([1], dtype=int32)\r\n/Users/rbp/anaconda/envs/python3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\r\n  return f(*args, **kwds)\r\n/Users/rbp/anaconda/envs/python3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n- **Exact command to reproduce**:\r\n\r\n```\r\n        def generator():\r\n            indices = [(1, 1)]\r\n            values = (1.,)\r\n            shape = (3, 3)\r\n            while True:\r\n                yield tf.SparseTensor(indices, values, shape)\r\n\r\n        iterator = tf.data.Dataset.from_generator(generator, tf.float32, (3,3)).make_one_shot_iterator()\r\n\r\n        sample = iterator.get_next()\r\n        ss = tf.sparse_reduce_sum(sample)\r\n        with tf.Session() as sess:\r\n            _ss = sess.run(ss)\r\n```\r\n\r\n### Describe the problem\r\n\r\nAbove code throws `AttributeError: 'Tensor' object has no attribute 'indices'`\r\n\r\nIt seems the `from_generator` always expects Tensors as output.", "comments": ["/CC @mrry, can you comment?", "It should be possible to do something here, although the `from_generator()` signature would need to expand (e.g. with `output_classes`?) to provide a way for the caller to specify that an output should be interpreted as a `tf.SparseTensor`. I've marked this as \"contributions welcome\", since it is unlikely that anyone on the team will get to this for a while, and there is a workaround as follows:\r\n\r\n```python\r\ndef generator():\r\n    indices = [(1, 1)]\r\n    values = (1.,)\r\n    shape = (3, 3)\r\n    while True:\r\n        yield (indices, values, shape)\r\n\r\ndataset = tf.data.Dataset.from_generator(generator, (tf.int64, tf.float32, tf.int64))\r\ndataset = dataset.map(lambda i, v, s: tf.SparseTensor(i, v, s))\r\niterator = dataset.make_one_shot_iterator()\r\n\r\nsample = iterator.get_next()\r\nss = tf.sparse_reduce_sum(sample)\r\nwith tf.Session() as sess:\r\n    _ss = sess.run(ss)\r\n```\r\n\r\n/cc @jsimsa ", "@mrry  if two  or  more  sparse tensor ,how to  code?", "@qiang2008 You can extend the `output_types` arguments in that example to return as many sparse tensors as you like. For example:\r\n\r\n```python\r\ndef generator():\r\n    indices = [(1, 1)]\r\n    values = (1.,)\r\n    shape = (3, 3)\r\n    while True:\r\n        yield (indices, values, shape), (indices, values, shape)\r\n\r\ndataset = tf.data.Dataset.from_generator(generator, ((tf.int64, tf.float32, tf.int64), (tf.int64, tf.float32, tf.int64)))\r\n\r\n```", "@mrry I'm seeing a difference in behavior between `from_tensor_slices` and your proposed solution when batching the resulting dataset:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\nfrom __future__ import absolute_import, division, print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef to_sparse_tuple(sequences, dtype=np.int32):\r\n    indices = []\r\n    values = []\r\n\r\n    for n, seq in enumerate(sequences):\r\n        indices.extend(zip([n]*len(seq), range(len(seq))))\r\n        values.extend(seq)\r\n\r\n    indices = np.asarray(indices, dtype=np.int64)\r\n    values = np.asarray(values, dtype=dtype)\r\n    shape = np.asarray([len(sequences), indices.max(0)[1]+1], dtype=np.int64)\r\n\r\n    return indices, values, shape\r\n\r\n\r\ndef to_sparse_tensor(sequences, dtype=np.int32):\r\n    return tf.SparseTensor(*to_sparse_tuple(sequences, dtype))\r\n\r\n\r\nprint('Using from_tensor_slices:')\r\nsparse = to_sparse_tensor([[0], [1, 2, 3]])\r\ndset = tf.data.Dataset.from_tensor_slices(sparse).batch(2)\r\nfor t in dset:\r\n    print(t)\r\n\r\n\r\nprint('Using from_generator:')\r\ndef generate_values():\r\n    yield to_sparse_tuple([[0]])\r\n    yield to_sparse_tuple([[1, 2, 3]])\r\n\r\ndset = (tf.data.Dataset.from_generator(generate_values, output_types=(tf.int64, tf.int32, tf.int64))\r\n                       .map(lambda i, v, s: tf.SparseTensor(i, v, s))\r\n                       .batch(2))\r\nfor t in dset:\r\n    print(t)\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nUsing from_tensor_slices:\r\nSparseTensor(indices=tf.Tensor(\r\n[[0 0]\r\n [1 0]\r\n [1 1]\r\n [1 2]], shape=(4, 2), dtype=int64), values=tf.Tensor([0 1 2 3], shape=(4,), dtype=int32), dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\r\nUsing from_generator:\r\nSparseTensor(indices=tf.Tensor(\r\n[[0 0 0]\r\n [1 0 0]\r\n [1 0 1]\r\n [1 0 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([0 1 2 3], shape=(4,), dtype=int32), dense_shape=tf.Tensor([2 1 3], shape=(3,), dtype=int64))\r\n```\r\n\r\nThe source of the problem seems to be that you can't create a 1D SparseTensor, so each individual tensor yielded by the generator is 2D, and then when you batch them the result is 3D.\r\n\r\nThis 3D result can't be used for example with CTCLoss, it complains about the shape (the 2D output using `from_tensor_slices` works fine):\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\nfrom __future__ import absolute_import, division, print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef to_sparse_tuple(sequences, dtype=np.int32):\r\n    indices = []\r\n    values = []\r\n\r\n    for n, seq in enumerate(sequences):\r\n        indices.extend(zip([n]*len(seq), range(len(seq))))\r\n        values.extend(seq)\r\n\r\n    indices = np.asarray(indices, dtype=np.int64)\r\n    values = np.asarray(values, dtype=dtype)\r\n    shape = np.asarray([len(sequences), indices.max(0)[1]+1], dtype=np.int64)\r\n\r\n    return indices, values, shape\r\n\r\n\r\ndef to_sparse_tensor(sequences, dtype=np.int32):\r\n    return tf.SparseTensor(*to_sparse_tuple(sequences, dtype))\r\n\r\n\r\ndef generate_values():\r\n    yield to_sparse_tuple([[0]])\r\n    yield to_sparse_tuple([[1, 2, 3]])\r\n\r\ndset = (tf.data.Dataset.from_generator(generate_values, output_types=(tf.int64, tf.int32, tf.int64))\r\n                       .map(lambda i, v, s: tf.SparseTensor(i, v, s))\r\n                       .batch(2))\r\nfor t in dset:\r\n    loss = tf.nn.ctc_loss(t, np.random.rand(3, 2, 5), [1, 3])\r\n```\r\n\r\nResult:\r\n```\r\n2019-03-16 12:01:40.561683: W tensorflow/core/framework/op_kernel.cc:1431] OP_REQUIRES failed at ctc_loss_op.cc:106 : Invalid argument: Order length must be SparseTensor rank.\r\nTraceback (most recent call last):\r\n  File \"test_sparse_from_generator.py\", line 38, in <module>\r\n    loss = tf.nn.ctc_loss(t, np.random.rand(3, 2, 5), [1, 3])\r\n  File \"/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/ops/ctc_ops.py\", line 175, in ctc_loss\r\n    ignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs)\r\n  File \"/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/ops/gen_ctc_ops.py\", line 309, in ctc_loss\r\n    name=name, ctx=_ctx)\r\n  File \"/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/ops/gen_ctc_ops.py\", line 378, in ctc_loss_eager_fallback\r\n    ctx=_ctx, name=name)\r\n  File \"/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Order length must be SparseTensor rank. [Op:CTCLoss]\r\n```", "Workaround using `tf.sparse.reshape`:\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\nfrom __future__ import absolute_import, division, print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef to_sparse_tuple(sequences, dtype=np.int32):\r\n    indices = []\r\n    values = []\r\n\r\n    for n, seq in enumerate(sequences):\r\n        indices.extend(zip([n]*len(seq), range(len(seq))))\r\n        values.extend(seq)\r\n\r\n    indices = np.asarray(indices, dtype=np.int64)\r\n    values = np.asarray(values, dtype=dtype)\r\n    shape = np.asarray([len(sequences), indices.max(0)[1]+1], dtype=np.int64)\r\n\r\n    return indices, values, shape\r\n\r\n\r\ndef to_sparse_tensor(sequences, dtype=np.int32):\r\n    return tf.SparseTensor(*to_sparse_tuple(sequences, dtype))\r\n\r\n\r\nprint('Using from_tensor_slices:')\r\nsparse = to_sparse_tensor([[0], [1, 2, 3]])\r\ndset = tf.data.Dataset.from_tensor_slices(sparse).batch(2)\r\nfor t in dset:\r\n    print(t)\r\n\r\n\r\nprint('Using from_generator:')\r\ndef generate_values():\r\n    yield to_sparse_tuple([[0]])\r\n    yield to_sparse_tuple([[1, 2, 3]])\r\n\r\ndef sparse_reshape(sparse):\r\n    shape = sparse.dense_shape\r\n    return tf.sparse.reshape(sparse, [shape[0], shape[2]])\r\n\r\ndset = (tf.data.Dataset.from_generator(generate_values, output_types=(tf.int64, tf.int32, tf.int64))\r\n                       .map(lambda i, v, s: tf.SparseTensor(i, v, s))\r\n                       .batch(2)\r\n                       .map(sparse_reshape))\r\nfor t in dset:\r\n    print(t)\r\n    loss = tf.nn.ctc_loss(t, np.random.rand(3, 2, 5), [1, 3])\r\n```\r\n\r\nResult:\r\n\r\n```\r\nUsing from_tensor_slices:\r\nSparseTensor(indices=tf.Tensor(\r\n[[0 0]\r\n [1 0]\r\n [1 1]\r\n [1 2]], shape=(4, 2), dtype=int64), values=tf.Tensor([0 1 2 3], shape=(4,), dtype=int32), dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\r\nUsing from_generator:\r\nSparseTensor(indices=tf.Tensor(\r\n[[0 0]\r\n [1 0]\r\n [1 1]\r\n [1 2]], shape=(4, 2), dtype=int64), values=tf.Tensor([0 1 2 3], shape=(4,), dtype=int32), dense_shape=tf.Tensor([2 3], shape=(2,), dtype=int64))\r\n```", "What about the following?\r\n\r\n```python\r\ndef dataset_from_sparse_tensor_slices(sparse_tensors):\r\n  \"\"\"\r\n  Similar to tf.data.Dataset.from_tensor_slices but from sparse tensors.\r\n  \"\"\"\r\n  def gen():\r\n    for x in sparse_tensors:\r\n      yield (x.indices, x.values, x.dense_shape)\r\n\r\n  # Assumes non empty.\r\n  first = next(gen())\r\n  tuples = tf.data.Dataset.from_generator(gen, tuple(map(lambda x: x.dtype, first)))\r\n  return tuples.map(lambda indices, values, dense_shape: tf.SparseTensor(indices, values, dense_shape))\r\n```\r\n\r\nJust for testing (in TensorFlow 2.0 eager mode):\r\n```python\r\nsparse_tensors = [\r\n tf.SparseTensor(indices = [[0, 0], [0, 1]], values=[2, 3], dense_shape=[2, 2]),\r\n tf.SparseTensor(indices = [[1, 0], [0, 1]], values=[5, 7], dense_shape=[2, 2]),\r\n tf.SparseTensor(indices = [[0, 0], [0, 1], [1, 1]], values=[-2, 7, 18], dense_shape=[2, 2])\r\n]\r\n\r\nfor x in dataset_from_sparse_tensor_slices(sparse_tensors):\r\n  print(x)\r\n```\r\n\r\nPrints:\r\n```\r\nSparseTensor(indices=tf.Tensor(\r\n[[0 0]\r\n [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([2 3], shape=(2,), dtype=int32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))\r\nSparseTensor(indices=tf.Tensor(\r\n[[1 0]\r\n [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([5 7], shape=(2,), dtype=int32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))\r\nSparseTensor(indices=tf.Tensor(\r\n[[0 0]\r\n [0 1]\r\n [1 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([-2  7 18], shape=(3,), dtype=int32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))\r\n```"]}, {"number": 16381, "title": "Distributed TensorFlow without shared directory", "body": "It seems like there is an inherent assumption in Distributed TensorFlow that all nodes must share a common file system, such as google cloud or NFS. \r\n\r\nI've found in testing that models will train just fine without a common file system, but the final trained model doesn't save properly when you try something like: \r\n`builder = tf.saved_model_builder.SavedModelBuilder(export_dir) \r\n...\r\nbuilder.save()`\r\n\r\nThe issue seems to be that the parameter server has the variables and the chief node has the graph. \r\n\r\nIt'd be great if TensorFlow added a function to allow us to consolidate the graph and variables at the end of training onto the chief node in order to save the trained model. Right now there doesn't seem to be an easy way to do this.\r\n\r\nThanks.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Yes. This is a feature request that a google engineer asked me to place. So\nit applies to all platforms.\n\n\nThanks\n\nOn Jan 24, 2018 11:15 PM, \"Alfred\" <notifications@github.com> wrote:\n\n> Thank you for your post. We noticed you have not filled out the following\n> field in the issue template. Could you update them if they are relevant in\n> your case, or leave them as N/A? Thanks.\n> Have I written custom code\n> OS Platform and Distribution\n> TensorFlow installed from\n> TensorFlow version\n> Bazel version\n> CUDA/cuDNN version\n> GPU model and memory\n> Exact command to reproduce\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16381#issuecomment-360381023>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEpvmYyeAqXCfDJ86iiScXfY-9R8cks5tOColgaJpZM4RsHbI>\n> .\n>\n", "@mas-dse-greina if there's any other context behind your request (e.g. other github stackoverflow issues, or other public discussion), please include it to this issue.\r\n\r\n@mrry @suharshs might have some thoughts on whether this is feasible.", "I've been emailing Martin Wicke and Magnus Hyttsten. drpngx on the boards\nrecommended that I make it a feature request.\n\nI've attached the conversation:\n\nThat will put everything (depending on where you put the device statement)\non the CPU, but not necessarily on the right worker. If it works for you,\ngreat, but it may not be doing what you want.\n\n\nOn Fri, Jan 26, 2018 at 2:26 PM, Todd Wang <notifications@github.com> wrote:\n\n> @mas-dse-greina <https://github.com/mas-dse-greina> if there's any other\n> context behind your request (e.g. other github stackoverflow issues, or\n> other public discussion), please include it to this issue.\n>\n> @mrry <https://github.com/mrry> @suharshs <https://github.com/suharshs>\n> might have some thoughts on whether this is feasible.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16381#issuecomment-360921120>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEmtKJrgIgWGC_yWLSlecztgCdHvTks5tOlEngaJpZM4RsHbI>\n> .\n>\n\n\nOn Fri, Jan 26, 2018 at 2:26 PM, Todd Wang <notifications@github.com> wrote:\n\n> @mas-dse-greina <https://github.com/mas-dse-greina> if there's any other\n> context behind your request (e.g. other github stackoverflow issues, or\n> other public discussion), please include it to this issue.\n>\n> @mrry <https://github.com/mrry> @suharshs <https://github.com/suharshs>\n> might have some thoughts on whether this is feasible.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16381#issuecomment-360921120>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEmtKJrgIgWGC_yWLSlecztgCdHvTks5tOlEngaJpZM4RsHbI>\n> .\n>\n", "I should think it's feasible.", "Thanks Derek.\n\nIf I understand the system correctly, there just needs to be a method that\ncan be called to push the checkpoints all onto the chief node. Of course\nthis would just be a snapshot that would be called at the end of training.\n\nI've been developing a distributed TF script for Intel and have a public\nrepo if you all are interested in seeing what we've done.\n\nBest,\nTony\n\nOn Jan 26, 2018 4:39 PM, \"Derek Murray\" <notifications@github.com> wrote:\n\n> I should think it's feasible.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16381#issuecomment-360943134>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEoQHArpcK-KZnhXZy7UZiDr32juLks5tOnBcgaJpZM4RsHbI>\n> .\n>\n", "@shivaniag is this related to your work at all?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I have this problem with shared \r\n\r\nCMakeFiles/tensorflow_shared.dir/all] Error 2\r\nMakefile:127: fallo en las instrucciones para el objetivo 'all'\r\nmake: *** [all] Error 2\r\n", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Assigning to @martinwicke, who might have more context.", "@skye I am not working on this, apologies for the delayed response.  @mas-dse-greina It would be great if you would like to submit a PR for this. Thanks!\r\n", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 16365, "title": "Include grpc_tensorflow_std_server in Docker image", "body": "It would be nice if the grpc_tensorflow_std_server was included in the Docker image.\r\n\r\nThis would prevent users from having to write code just to launch a parameter server because they could just run the stock binary.\r\n\r\nSome context in: tensorflow/k8s#16", "comments": ["@angersson, could you please take a look.", "This would be nice, but work on the Docker images is not currently high-priority for us, so we're not likely to have time to work on this. Please feel free to make a contribution.", "I would like to work on it. Could you please provide me some additional information related to it?\r\n"]}, {"number": 16276, "title": "Linking against system-installed cuda and cudnn", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian sid\r\n- **TensorFlow installed from (source or binary)**: source (trying)\r\n- **TensorFlow version (use command below)**: git master (commit 9fb9ac66ce) or any version before.\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 6.0\r\n- **GPU model and memory**: GeForce GTX 1070\r\n- **Exact command to reproduce**:\r\n`bazel build --config=opt --config=mkl --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n### Describe the problem\r\nThe build system currently require that all the libraries from the CUDA toolkit are stored in a specific directory called `cuda_toolkit_path`, both in the bazel scripts and in the `configure.py` script. However, some systems (like Debian) have a packaged version of CUDA which installs the libraries in the standard path which cannot be found by `configure.py`.\r\n\r\nThe compiler can find those libraries just right with nothing more than `-lcuda`. It would be nice if the build system could rely on the compiler's ability to find its libraries instead of relying on the knowledge of their full path.\r\n\r\n### Source code / logs\r\nAs a feature-request / enhancement-request, this section seems irrelevant.", "comments": ["/CC @gunan I think that'd be a great contribution if you're willing to send something.", "For what it's worth, I have patched (hacked) the build scripts and a few lines of code to make it compile and link on my computer. Using the system-installed CUDA / cuDNN, of course.\r\nhttps://github.com/Celelibi/tensorflow/tree/wip-system-cuda\r\n(current latest commit Celelibi/tensorflow@c87884ddfbd419ff6663b9aef160fd45577280e0)\r\n\r\nIf you're interested, I can continue to work on it and make a pull request with a cleaner version. Or it might serve as a basis for a seasoned tensorflow developer to make the necessary modifications that follows tensorflow's guidelines much more quickly than I would.", "That looks reasonable. Feel free to send the PR!"]}, {"number": 16226, "title": "Include netstat in the tensorflow docker container", "body": "### Describe the problem\r\nThis is a feature request to add net-tools to the Tensorflow docker containers.  Having netstat in the Tensorflow container will make it easier to find open ports in a multi-tenant environment when launching Tensorflow Distributed or Tensorboard.\r\n\r\nNote, I have found how to add netstat (see URL below), but would prefer not having to change or maintain a modified version of the Tensorflow container.\r\n\r\nhttps://stackoverflow.com/questions/41961217/installing-netstat-on-docker-linux-container\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:tensorflow/tensorflow:1.3.0 docker container\r\n- **TensorFlow installed from (source or binary)**:docker container\r\n- **TensorFlow version (use command below)**:1.3.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:NA\r\n- **GCC/Compiler version (if compiling from source)**:NA\r\n- **CUDA/cuDNN version**:NA\r\n- **GPU model and memory**:NA\r\n- **Exact command to reproduce**:netstat\r\n", "comments": ["@jswelch would you mind to share some details about your use case? Maybe there are some other ways to achieve it without adding net-tools.", "The use case is running Distributed Tensorflow in a grid or cluster of compute nodes where there will be multiple users submitting work.  In order to start the Distributed Tensorflow job, you need to know the PS and WORK ports up front to launch any of the tasks.  Here is my example below:\r\n\r\ncompute1: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=ps --task_index=0\r\ncompute2: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=1\r\ncompute3: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=2\r\ncompute4: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=3\r\n\r\nTrying to avoid the same ports being used by a different user or another application across multiple compute nodes is not easy.   A better request for change might be to have Distributed Tensorflow work similar to MPI (Message Passing Interface) where I believe with MPI the worker tasks start with the port for the Server/PS port and the work task finds an open port and sends it to the Server/PS.    \r\n\r\nIs this helpful?\r\n", "@jswelch It looks like the containers might be launched through commands. I am wondering if container orchestration systems like kubernetes/kubeflow may help?", "Kubeflow can alleviate some of this - if the job is running in a k8s environment. My use case is in HPC - where distributed tensorflow is running under an HPC workload management system such as Slurm, PBSPRo or LSF. When someone runs an MPI application, they don't have to worry about multiple MPI jobs clashing with each other as MPI sets up its communications automatically. Forcing the end user to select (hopefully) free ports on every node really hampers usability.\r\n\r\nI can see where kubeflow/docker's own port mapping can help with a single instance of tensorflow - the app uses the same fixed port inside the container and mapped to some chosen port outside. For distributed tensorflow, conceptually every communication could be to the same port number, and the port mapper handles it -- but we're back to the same problem - the port mapper needs to map unused ports on every host, and the user needs to manually select them. Port mapping would also not work when multiple jobs are sharing the same host - they can't all send to the same port.\r\n", "@jswelch I am not very familiar with the HPC/Slurm so I might be ignorant in this topic. Though from docker's point of view, if you invoke your container with `--net=host`:\r\n```\r\ndocker run --net=host busybusy ...\r\n```\r\n\r\nThen you essentially get the same network stack inside and outside of the container. There is no need to do a port mapping of container vs host any more with `--net=host`. You still have all the other benefits like process isolation, etc, though.\r\n\r\nWith the same network stack, your current port management scheme will work like before. In other words, if Slurm already handled port management at the host level, then with `--net=host` it will \"just work\" I assume.", "Correct, we already use the docker option \"--net=host\" along with --rm --ipc=host and -v for volume mappings.\r\n\r\n>With the same network stack, your current port management scheme will work like before.\r\n\r\nThere is no current port management scheme.  SLURM, PBSPro and LSF do not handle network port management.\r\n\r\nFYI, many HPC application (including at least one Deep Learning Framework) use MPI."]}, {"number": 16104, "title": "Feature request: Allow the build to use the system-installed protobuf lib", "body": "### Describe the problem\r\nCurrently, it's impossible to use the system-installed protobuf library because the tensorflow build always uses the `protobuf_archive` version. There should be an option to use the one installed in the system.\r\n\r\nBackground: I package tensorflow for Arch Linux and we run into symbol conflicts if a user wants to use protobuf and tensorflow together in a binary because tensorflow's protobuf symbols conflict with the one installed in the system already.\r\n\r\nOriginal Arch bug report: https://bugs.archlinux.org/task/56943", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "*sigh* for this kind of issue, it really doesn't matter but for the sake of automation, here I go:\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.1\r\n- **CUDA/cuDNN version**: 9.1.85/7.0.5\r\n- **GPU model and memory**: 1080 TI with 11711807488 bytes\r\n- **Exact command to reproduce**: N/A", "I think there was a similar question but can't seem to find it.\r\n\r\n@gunan what's our position here?", "Eventually, we would like to enable this.\r\nMaybe we can control this using environment variables just like we do for MKL?", "@drpngx could it be this question I posted a while ago https://github.com/tensorflow/tensorflow/issues/8403 ? I'd be very interested as well if any progress is made on this!", "@danbarnes333 yes that's right on.\r\n\r\nMaybe a stepping stone would be to allow people to link against the system protobuf during the `configure` step, via some environment variable or a configure flag. I think that would be a good contribution.\r\n\r\nWe should also consider, at some point, distributing pip packages that are dependent on a libprotobuf package.\r\n\r\nCC @allenlavoie @skye ", "This would be useful to us as well.  We are currently stuck in a situation where the protobuf symbols in libtensorflow_framework.so are being clobbered by symbols in a custom libprotobuf from a different API revision that is being loaded to support the operations of our custom backend to TensorFlow.\r\n\r\nIn other words, we have this library dependency tree right now:\r\n* _pywrap_tensorflow_internal.so\r\n  * libtensorflow_framework.so (contains protobuf 3.4 library)\r\n  * our_high_level_library.so\r\n    * our_device_library.so\r\n      * libprotobuf.so (version 3.x)", "We found a workaround by forcing bazel to use a protobuf version that matched the one used elsewhere on the system.  Here is a patch that will force usage of the 3.4.0 library, but one can also point to any other archive tag on github.\r\n[patch.tar.gz](https://github.com/tensorflow/tensorflow/files/1795439/patch.tar.gz)\r\n\r\n", "@RichDubielzig that is what we have been doing, as well as hiding more symbols in the tensorflow shared library, and has been working ok. However @drpngx mentioned on my original issue that this isnt completely safe unless I misunderstood (about halfway down https://github.com/tensorflow/tensorflow/issues/8403) but perhaps things have changed since then. Either way simply building against the system protobuf would be great.", "@RichDubielzig  Do you mind to tell more detail about how to use the file you gave? Like where should I put it and how can I make it work? Thanks alot.", "If this ever gets picked up you'll probably need protobuf to enable dynamic linking as well - https://github.com/protocolbuffers/protobuf/issues/8291"]}, {"number": 16054, "title": "Lack of Complex64 support for Java API", "body": "This issue is not about a bug, but I will fill in the form anyhow ;-)\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac 10.13.2\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nmaster branch at commit: b86dc365ebbef64daceced37026518696ede5b7b\r\n- **Python version**:\r\nN/A Using Java version \"1.8.0_152\"\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.8.1-homebrew\r\nBuild target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Dec 5 19:29:04 2017 (1512502144)\r\n- **GCC/Compiler version (if compiling from source)**:\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/c++/4.2.1\r\nApple LLVM version 9.0.0 (clang-900.0.39.2)\r\nTarget: x86_64-apple-darwin17.3.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n- **CUDA/cuDNN version**:\r\nN/A not using CUDA\r\n- **GPU model and memory**:\r\nN/A not using GPU\r\n- **Exact command to reproduce**:\r\nThere is no bug to reproduce\r\n\r\n### Describe the problem\r\nThere is not really a problem. I have need to build TensorFlow computations in Java and have support for complex numbers. Because the C API already supports COMPLEX64 tensors, it was a straight forward effort to expose them in the Java API. Along with unit tests, I have also added a Java example based on the Python tutorial that builds an image that displays the Mandelbrot fractal to show that the complex number support works correctly.\r\n\r\n### Source code / logs\r\nHere is a very short example of using the API, clearly there are functions in the example that are not available defined in the example, but it gets the point across. This example is basically lifted from a new java example I created called MandelbrotExample.java\r\n```\r\nTensor<Complex64> resultZ = null;\r\ntry(Graph g = new Graph()) {\r\n    //We create a meshgrid based on two numeric ranges, by wrapping the ranges\r\n    //in Tensors and then pulling out sub grids to make complex numbers\r\n    try (Tensor<Float> meshGridT = buildMeshGrid(range1Spec, range2Spec);\r\n         Tensor<Integer> zeroT = Tensors.create(new int[]{0});\r\n         Tensor<Integer> oneT = Tensors.create(new int[]{1});\r\n         Tensor<Complex64> jTensor = Tensors.create(0.0f, 1.0f)) {\r\n    \r\n        Output<Integer> zero = buildConstant(g, \"0\", zeroT);\r\n        Output<Integer> one = buildConstant(g, \"1\", oneT);\r\n\r\n        Output<Float> meshGrid = buildConstant(g, \"meshgrid\", meshGridT);\r\n\r\n        Output<Complex64> j = buildConstant(g, \"imagUnit\", jTensor);\r\n\r\n        //We use GatherNd to pull out the two parts of the original mesh grid\r\n        //the Z complex tensor\r\n        Output<Float> Yfloat = g.opBuilder(\"GatherNd\", \"get_y\")\r\n                .addInput(meshGrid)\r\n                .addInput(zero) //use zero\r\n                .build().output(0);\r\n        Output<Float> Xfloat = g.opBuilder(\"GatherNd\", \"get_x\")\r\n                .addInput(meshGrid)\r\n                .addInput(one) //use one\r\n                .build().output(0);\r\n\r\n        Output<Complex64> Y = g.opBuilder(\"Cast\", \"castYtoComplex\")\r\n                .addInput(Yfloat)\r\n                .setAttr(\"DstT\", DataType.COMPLEX64)\r\n                .build().output(0);\r\n\r\n        Output<Complex64> X = g.opBuilder(\"Cast\", \"castXtoComplex\")\r\n                .addInput(Xfloat)\r\n                .setAttr(\"DstT\", DataType.COMPLEX64)\r\n                .build().output(0);\r\n\r\n        //Z is constructed by X + Yj\r\n        Output<Complex64> mulYj = g.opBuilder(\"Mul\", \"mulYj\")\r\n                .addInput(Y)\r\n                .addInput(j)\r\n                .build()\r\n                .output(0);\r\n        Output<Complex64> Z = g.opBuilder(\"Add\", \"addZ\")\r\n                .addInput(X)\r\n                .addInput(mulYj)\r\n                .build()\r\n                .output(0);\r\n\r\n        try(Session s = new Session(g)){\r\n            resultZ = s.runner().fetch(Z).run().get(0).expect(Complex64.class);\r\n        }\r\n    }\r\n}\r\n```\r\nI would like to get my local branched pushed to GitHub and then a pull request put in with these changes. I have attached a diff file for the curious. I am still working on getting a corporate CLA put into place.\r\nThanks for your time and consideration!\r\n[java-complex64.patch.txt](https://github.com/tensorflow/tensorflow/files/1624251/java-complex64.patch.txt)\r\n\r\n", "comments": ["@rajha-korithrien - Seems like you have a patch. Wonderful! You're welcome to submit a pull request.\r\n(I'd suggest keeping the PR focused - so mostly adding the type and perhaps leaving the detailed example out).", "@asimshankar Thanks for the note. Will submit a request as soon as I get the CLA straightened out.", "Apparently one should pay attention and not press the close and comment button if one does not mean to close the ticket ;-)"]}, {"number": 16028, "title": "Optimzer: Better handling of gradients for min/max ops.", "body": "Please don't kick me too hard for this. If this ticket should not be here, please direct me to the proper place. It's not a help or support request, just a very naive idea/request/improvement.\r\n\r\nImage a model has this op in the graph: `y = tf.maximum(a, b)`. If `y` is contributing error to the loss (higher `y` higher is loss), then you are interested in minimizing both `a` and `b`. Otherwise, your optimizer will play whack-a-mole game forever. Especially, if you have something like this in your model: `b = 1 - a` and `y = tf.maximum(a, b)`\r\n\r\nI've researching how does optimizer works and looks like each op has a function that defines how to calculate its gradients. \r\nIn the current implementation for maximum/minimum (python's version) is located here: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py#L901\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_grad.py#L883\r\n\r\nIn the current implementation, it discards gradients for `a`, if `b` is bigger than `a` and other way around. \r\n\r\nI think, that there is some place for improvement of training speed simply by considering gradients for all variables in min/max operations (including reduce_min/reduce_max and all max/min pooling). There are a lot of models with max pooling. It makes sense that they will train faster if they stop playing whack-a-feature each time it has max pooling layer.\r\n\r\nIf it make sense, I would like to do a small PoC.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "**Mandatory questions:**\r\nHave I written custom code: N/A? Yes? I have no idea.\r\nOS Platform and Distribution - Any N/A\r\nTensorFlow installed from - pypi\r\nTensorFlow version - '1.4.1'\r\nBazel version - N/A\r\nCUDA/cuDNN version - N/A\r\nGPU model and memory - N/A\r\nExact command to reproduce.\r\n\r\n**Slow optimizer:**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(10.0)\r\nb = tf.Variable(9.0)\r\nloss = tf.maximum(a, b)\r\n\r\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\r\n\r\nsess = tf.InteractiveSession()\r\n\r\ntf.global_variables_initializer().run()\r\n\r\n\r\ndef print_state(sess, step, a, b, loss):\r\n    ret = sess.run({\r\n        'a': a,\r\n        'b': b,\r\n        'loss': loss\r\n    }, feed_dict={})\r\n    \r\n    print (\"Step: %3s:\\ta=%04.01f\\tb=%04.01f\\tloss=%04.01f\" % (\r\n        step,\r\n        ret['a'],\r\n        ret['b'],\r\n        ret['loss']\r\n    ))\r\n\r\n\r\nprint_state(sess, -1, a, b, loss)\r\n\r\nfor step in range(10):\r\n    sess.run(train_step, feed_dict={})\r\n\r\n    print_state(sess, step, a, b, loss)\r\n\r\n```\r\nOutputs:\r\n```\r\nStep:  -1:\ta=10.0\tb=09.0\tloss=10.0\r\nStep:   0:\ta=09.5\tb=09.0\tloss=09.5\r\nStep:   1:\ta=09.0\tb=09.0\tloss=09.0\r\nStep:   2:\ta=08.5\tb=09.0\tloss=09.0\r\nStep:   3:\ta=08.5\tb=08.5\tloss=08.5\r\nStep:   4:\ta=08.0\tb=08.5\tloss=08.5\r\nStep:   5:\ta=08.0\tb=08.0\tloss=08.0\r\nStep:   6:\ta=07.5\tb=08.0\tloss=08.0\r\nStep:   7:\ta=07.5\tb=07.5\tloss=07.5\r\nStep:   8:\ta=07.0\tb=07.5\tloss=07.5\r\nStep:   9:\ta=07.0\tb=07.0\tloss=07.0\r\n```\r\n\r\nAs you can see it is pulling `a` down, then `b`, and then again. It will require less steps if it is going to change both `a` and `b` together.\r\n\r\n**Optimizer playing whack-a-feature game**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(10.0)\r\nb = 10.0 - a\r\nloss = tf.maximum(a, b)\r\n\r\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\r\n\r\nsess = tf.InteractiveSession()\r\n\r\ntf.global_variables_initializer().run()\r\n\r\n\r\ndef print_state(sess, step, a, b, loss):\r\n    ret = sess.run({\r\n        'a': a,\r\n        'b': b,\r\n        'loss': loss\r\n    }, feed_dict={})\r\n    \r\n    print (\"Step: %3s:\\ta=%04.01f\\tb=%04.01f\\tloss=%04.01f\" % (\r\n        step,\r\n        ret['a'],\r\n        ret['b'],\r\n        ret['loss']\r\n    ))\r\n\r\n\r\nprint_state(sess, -1, a, b, loss)\r\n\r\nfor step in range(20):\r\n    sess.run(train_step, feed_dict={})\r\n\r\n    print_state(sess, step, a, b, loss)\r\n```\r\n\r\n```\r\nStep:  -1:\ta=10.0\tb=00.0\tloss=10.0\r\nStep:   0:\ta=09.5\tb=00.5\tloss=09.5\r\nStep:   1:\ta=09.0\tb=01.0\tloss=09.0\r\nStep:   2:\ta=08.5\tb=01.5\tloss=08.5\r\nStep:   3:\ta=08.0\tb=02.0\tloss=08.0\r\nStep:   4:\ta=07.5\tb=02.5\tloss=07.5\r\nStep:   5:\ta=07.0\tb=03.0\tloss=07.0\r\nStep:   6:\ta=06.5\tb=03.5\tloss=06.5\r\nStep:   7:\ta=06.0\tb=04.0\tloss=06.0\r\nStep:   8:\ta=05.5\tb=04.5\tloss=05.5\r\nStep:   9:\ta=05.0\tb=05.0\tloss=05.0\r\nStep:  10:\ta=04.5\tb=05.5\tloss=05.5\r\nStep:  11:\ta=05.0\tb=05.0\tloss=05.0\r\nStep:  12:\ta=04.5\tb=05.5\tloss=05.5\r\nStep:  13:\ta=05.0\tb=05.0\tloss=05.0\r\nStep:  14:\ta=04.5\tb=05.5\tloss=05.5\r\nStep:  15:\ta=05.0\tb=05.0\tloss=05.0\r\nStep:  16:\ta=04.5\tb=05.5\tloss=05.5\r\nStep:  17:\ta=05.0\tb=05.0\tloss=05.0\r\nStep:  18:\ta=04.5\tb=05.5\tloss=05.5\r\nStep:  19:\ta=05.0\tb=05.0\tloss=05.0\r\n```\r\n\r\nAs you can see, it is stuck in a cycle. If it considered loss for both `a` and `b` it would have quickly come to the equilibrium.\r\n\r\n\r\n\r\n\r\n", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "So the canonical way to tackle this problem is probably to \"soften\" the non-linear function, e.g use something like:\r\n```\r\na_is_bigger = tf.sigmoid((a-b) / width)\r\ny = a_is_bigger * a + (1 - a_is_bigger) * b\r\n```\r\nand increase `width` over time.\r\n\r\nThe second canonical way is to use an optimizer that implements the proximal [gradients](http://www.stat.cmu.edu/~ryantibs/convexopt-S15/lectures/08-prox-grad.pdf).\r\n\r\nIf you have a practical solution, we're always open to good algorithms! In general if it's been tested on a competitive benchmark and it works, it would be great to contribute.", "@drpngx I am going to try your proposal to implement an argmax gradient on my #affinelayer fork : https://github.com/julien2512/pix2pix-tensorflow/tree/snes9x?files=1\r\n", "Nice!\n\nOn Mon, Apr 23, 2018, 8:26 AM julien2512 <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> I am going to try your proposal to\n> implement an argmax gradient on my #affinelayer fork :\n> https://github.com/julien2512/pix2pix-tensorflow/tree/snes9x?files=1\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16028#issuecomment-383614521>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbbX22ac2b-QCPnIl9byy7_O3uw4zks5trfKJgaJpZM4RaUJC>\n> .\n>\n", "@drpngx Should we use something like that \r\n\r\n> http://163.172.41.53:8080/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-maximum&learningRate=0.0001&regularizationRate=0&noise=0&networkShape=3,2&seed=0.29413&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=regression&initZero=false&hideText=false\r\n\r\nto implement the maximum function in order the gradient to work (with static values rather than variables) ?\r\nWidth seems not to be necessary this way.", "Hi @julien2512 can you clarify? I am not sure I get this.", "I am not confortable with the \"width\" parameter in\r\n`a_is_bigger = tf.sigmoid((a-b) / width)`\r\n\r\nSo I tried to keep your main idea in a different form (there it is 2 hidden layer network using tanh activation to emulate the maximum function).\r\nI am on it right now.", "My method only works with a given radius (a and b between [-radius, radius] for example).\r\nAlso, their might be biases near 0 on both a and b.\r\n\r\nI got bad results by now. May be I missed something.", "Alright, I got it. I was looking for something too much complicated : a single hidden layer is enough for argmax.\r\n\r\nI have soften argmax that way\r\n`V (a,b) C [-6,6]\u00b2 ,  argmax(a,b) = 0,5\u00d7 (tanh (-6,7\u00d7a+6,7\u00d7b\u22125))+0,5`\r\nThat's what I am going to test.\r\n\r\nSoften max is a bit harder but seem to be possible a similar way (with more hidden layers).", "The derivative of argmax at the point 0 will then be 1.\r\nApplying a gradient when a=b will lead to an infinite loop (we can't decide which direction to take).\r\n\r\ntf.maximum will have the same problem. We can't find an answer with the tf.argmax or tf.max only I guess.", "This is not about the value we want to get, but how we want it to behave.\r\nI need to think a bit more on it, may be tf.maximum nor tf.argmax are not what I am looking for.", "@drpngx now I understood your proposal :\r\n```\r\na_is_bigger = tf.tanh((a-b) / width)\r\ny = a_is_bigger * a + (1 - a_is_bigger) * b\r\n```\r\nWhen a is close to b, the growing parameter width will increase the difference between a and b to make a_is_bigger be 1 or 0.\r\n\r\nWhat do you think about\r\n`width = 10^(floor(log(abs(a-b))))`\r\n?\r\n\r\nEven with a-b = 10^-9, a_is_bigger will be about 0.7. I think we can improve this. \r\n\r\nI do not know about floor and abs gradient thus.\r\n\r\nAnd finally, it still do not work when a=b. may be we should add an epsilon like a-b+epsilon.", "https://www.desmos.com/calculator/dwiaagflr3\r\n\r\nIt still do not work near 0. The derivative of a_is_bigger is just too high.", "The code for current max (and min !) gradient : \r\n```\r\ndef _MinOrMaxGrad(op, grad):\r\n  \"\"\"Gradient for Min or Max. Amazingly it's precisely the same code.\"\"\"\r\n  input_shape = array_ops.shape(op.inputs[0])\r\n  output_shape_kept_dims = math_ops.reduced_shape(input_shape, op.inputs[1])\r\n  y = op.outputs[0]\r\n  y = array_ops.reshape(y, output_shape_kept_dims)\r\n  grad = array_ops.reshape(grad, output_shape_kept_dims)\r\n\r\n  # Compute the number of selected (maximum or minimum) elements in each\r\n  # reduction dimension. If there are multiple minimum or maximum elements\r\n  # then the gradient will be divided between them.\r\n  indicators = math_ops.cast(math_ops.equal(y, op.inputs[0]), grad.dtype)\r\n  num_selected = array_ops.reshape(\r\n      math_ops.reduce_sum(indicators, op.inputs[1]), output_shape_kept_dims)\r\n\r\nreturn [math_ops.div(indicators, num_selected) * grad, None]\r\n```", "Gradient for abs :\r\n```\r\n@ops.RegisterGradient(\"Abs\")\r\ndef _AbsGrad(op, grad):\r\n  x = op.inputs[0]\r\nreturn grad * math_ops.sign(x)\r\n```\r\n\r\nbut floor is not implemented :\r\n```\r\n@ops.RegisterGradient(\"Floor\")\r\ndef _FloorGrad(_, unused_grad):\r\nreturn [None]\r\n```", "For all of these reasons, despite the tentation to soften max (nor argmax) I think I will use tf.cond instead.\r\nI keep you in touch with my results.", "Just a comment,\r\n\r\nLet y = max( a, b) such that a >> b,\r\nthen we can approximate it as \r\ny = log(e^a + e^b)\r\nIf we compute the gradient with respect to x, \r\n\u2202y/\u2202x = \u2202a/\u2202x e^a / (e^a+e^b) + \u2202b/\u2202x e^b / (e^a+e^b)\r\nNotice that with the assumption a >> b, the first term approaches to \u2202a/\u2202x and the second term vanishes. This means if a >> b, it is enough to propagate gradients and update parameters associated only with **a** whenever expression max(a,b) appears. \r\n\r\nIf the assumption that (a >> b) or (b >> a) is true, only then max(a, b) can be converted to a continuous function as done above. Otherwise we need another measure, say a distance measure to approximate non-continuous max with a  continuous function in a fuzzy sense. This 'distance' in essence is a fuzzification parameter that will help relatively define whether a and b are 'similar' or 'way too different'. But this distance measure depends on the nature and distribution of data, so it has to be either supplied by the user or discovered from the data itself (if at all a broader view of data is available). ", "I am agree, I realized it was better to use a custom gradient.", "I haven't tried this myself but the concept of Lp-norm seems to me like a natural approach for \"softening\" the max function. For your two number case, the Lp-norm is defined as \r\n`y = (|a|^p + |b|^p)^(1/p)`\r\nwhere p is a free parameter.\r\n\r\nThe case p->\u221e corresponds to\r\n`y = tf.maximum(a,b)`\r\nand the case p=2 corresponds to the familiar Eucledian distance. Perhaps there could be an intermediate p value which would suit your use case."]}]