[{"number": 15864, "title": "Fix docs", "body": "", "comments": ["@asimshankar is there an automated way to rebuild that file? I'm not sure. I've fixed the other two suggestions.", "Sorry, I don't know why I said \"rebuilt\" :) I meant updated."]}, {"number": 15863, "title": "Fix typo in eager value_and_gradients docstring", "body": "The function is computing gradients with respect to `f`, so this is possessive of the function if I'm reading this properly.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15862, "title": "extract populate weight collection.", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15861, "title": "Fix LSTM Layer Normalization implementation to match original paper", "body": "The Layer Norm paper (https://arxiv.org/abs/1607.06450) applies layer norm to LSTMs by separately normalizing the linear transformation of the inputs and the linear transformation of the recurrent cell state. See equation (20) in the Supplementary Material (page 13).\r\n\r\nThe current contrib LSTM layer norm implementations apply layer norm to LSTMs by separately normalizing each of the gate/cell update preactivations (separate columns of the sum of the linear transformations of the inputs and recurrent cell state). This is very different from the paper (different tensors are being normalized).\r\n\r\nThis PR changes the two implementations to match the paper. There is one slight difference with the paper: I omit two of the layer norm offset _\u03b2_ parameters because there is a bias term already.\r\n  \r\n  \r\n  ", "comments": ["Can one of the admins verify this patch?", "@bchu Will this introduce backward compatibility issues?", "@caisq Yes. Different tensors are being normalized.\r\n  ", "@ebrevdo I've updated the comments. I've added a flag for the different behavior (`layer_norm_columns`). Let me know if other updates are needed.", "@ebrevdo could you take another look, please?", "Normalizing gates individually feels nicer. Any experimental results with pros/cons of the respective methods?\r\n\r\nAlso, why not keep the offset parameters and remove the bias term instead (as in tf.contrib.layers)?", "@carlthome I think it also makes sense from the perspective of normalizing each linear transformation separately. Presumably the recurrent states and the recurrent inputs have different distributions. I'm not aware of any experimental comparisons. I omitted the offset because that saves us an extra parameter.", "Happy to resolve any merge conflicts if there's still interest in this PR.", "Hi Brian Chu @bchu ,\r\nWe are researchers working on identifying redundant development and duplicated pull requests. We have found there is a pull request: https://github.com/tensorflow/tensorflow/pull/14578 which might be a potentially duplicate to this one. We would like to build the link between developers to reduce redundant development. We would really appreciate if you could help us to validate and give us feedback.\r\nThank you very much for your time!", "@ebrevdo , is there still interest in this PR? @bchu and @KiewanVillatel to comment on the helpful suggestion that this might be a dupe with #14578 ?", "Also @drpngx , who was reviewing #14578", "#14578 implements Layer Norm for GRUs, while this PR deals with fixing the current LSTM Layer Norm implementation.", "Please pull rebase and push again.\r\n\r\nI wonder if there is a way to get a cleaner terminology -- center, columns, and axis?", "Thank you for your work to fix this!  I think we should proactively take your version of the code and call it \"class LayerNormLSTMCellV2\"; in TensorFlow 2.0 we can get remove of the old one from the public API and call this one \"LayerNormLSTMCell\" in the public API.\r\n\r\nIn order to get there, I think you should cut out the pieces implement the correct version (your new code) into the new class.  Get rid of the following `__init__` arguments: scope (no longer used), layer_norm (assume true), and layer_norm_columns (assume true).  Move all variable creation to the `build` method and the computation to the `call` method.  For an example, see The [LSTMCell implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell_impl.py#L781).\r\n\r\nDo you have cycles to do this?", "Err (in the new cell for `layer_norm_columns` assume False: that's your code :)", "Sure. One question I have is that the cell `call` method currently calls `tf.contrib.layers.layer_norm`, which relies on variable scopes to create the scale/offset variables. Should I just copy layer norm code into `LayerNormLSTMCellV2`, or is there some way I can still use `tf.contrib.layers.layer_norm`?", "Is there an existing LayerNorm keras cell?  If so you can use that.\nOtherwise you should abstract the layer norm code into a helper function\nyou can use in both.\n\nOn Thu, Sep 6, 2018, 7:20 PM Brian Chu <notifications@github.com> wrote:\n\n> Sure. One question I have is that the cell call method currently calls\n> tf.contrib.layers.layer_norm, which relies on variable scopes to create\n> the scale/offset variables. Should I just copy layer norm code into\n> LayerNormLSTMCellV2, or is there some way I can still use\n> tf.contrib.layers.layer_norm?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15861#issuecomment-419299360>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim5TyvplFNPt30S2-7aw0xdwwuuhtks5uYdf7gaJpZM4RTwFk>\n> .\n>\n", "xref #14578 which is implementing LayerNormGRUCell and will need to have the same layer norm helper function.", "Is this worth fixing up, or will classes like `LayerNormBasicLSTMCell` be deprecated in favor of Keras in Tensorflow 2.0?", "> Is this worth fixing up, or will classes like `LayerNormBasicLSTMCell` be deprecated in favor of Keras in Tensorflow 2.0?\r\n\r\n@ebrevdo @karmel gentle ping ", "https://github.com/tensorflow/addons/pull/205.\r\n\r\nThe contrib is going away in TF 2.0 and we are moving selected APIs to tf addons.\r\n\r\nI am also kind of curious about the whether the norm should be applied to the fused gates (paper version) or the individual gate separately (current implementation). I think the current implementation makes more sense since each gate carries different mathematical meaning. Unless those gates have similar numerical distribution, norm them together seems wrong to me.", "https://github.com/tensorflow/addons/pull/210 has been submitted to addons.\r\n\r\nThe change includes:\r\n1. Update the implementation to match keras style in 2.0, eg add_weights in build(), and get rid of variable_scope.\r\n2. Implementation is now matching with the original paper. Normalization is now done with fused gates. The reference implementation from the original paper author can be found in https://github.com/ryankiros/layer-norm/blob/master/layers.py#L457-L475.\r\n3 Fix the missing bias when normalization is enabled, which is an oversight in the original implementation.\r\n\r\nWith that, I think this PR can be closed.\r\n\r\nThanks for the contribution."]}, {"number": 15860, "title": "Branch 180746153", "body": "", "comments": ["Can one of the admins verify this patch?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "@tensorflow-jenkins  \"test this please\". ", "Please address the test failures.", "To make the CLA check pass, you may have to re-submit this pull request after changing your git email configuration to your Google email etc. The email in the merge commit (https://github.com/tensorflow/tensorflow/commit/ba22790f511d494416fbbb9a6c7f4bb013060b50) says raghuraman@raghuraman.mtv.corp.google.com, which isn't what you want."]}, {"number": 15859, "title": "Eager mode: create_file_writer cannot be called twice", "body": "Have I written custom code: No\r\nOS Platform and Distribution: OS X 10.13.2\r\nTensorFlow installed from: Source\r\nTensorFlow version: cc9bdb70b88c76f293f27e29e91cb7739ba3fdc4\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()\r\ntf.contrib.summary.create_file_writer(\"/Users/malmaud/tmp/summaries\")\r\ntf.contrib.summary.create_file_writer(\"/Users/malmaud/tmp/summaries\")\r\n```\r\n\r\nThe second call to `create_file_writer` gives:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAlreadyExistsError                        Traceback (most recent call last)\r\n<ipython-input-5-4583ede32bc2> in <module>()\r\n----> 1 tf.contrib.summary.create_file_writer(\"/Users/malmaud/tmp/summaries\")\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/summary/summary_ops.py in create_file_writer(logdir, max_queue, flush_millis, filename_suffix, name)\r\n    210         max_queue=max_queue,\r\n    211         flush_millis=flush_millis,\r\n--> 212         filename_suffix=filename_suffix)\r\n    213 \r\n    214 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/summary/summary_ops.py in _make_summary_writer(name, factory, **kwargs)\r\n    271   #   ops.get_default_session().run(node)\r\n    272   ops.add_to_collection(_SUMMARY_WRITER_INIT_COLLECTION_NAME,\r\n--> 273                         factory(resource, **kwargs))\r\n    274   return SummaryWriter(resource)\r\n    275 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/summary/gen_summary_ops.py in create_summary_file_writer(writer, logdir, max_queue, flush_millis, filename_suffix, name)\r\n    145     _result = _execute.execute(b\"CreateSummaryFileWriter\", 0,\r\n    146                                inputs=_inputs_flat, attrs=_attrs, ctx=_ctx,\r\n--> 147                                name=name)\r\n    148     _result = None\r\n    149   return _result\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   # pylint: enable=protected-access\r\n     68   return tensors\r\n\r\n~/anaconda3/lib/python3.6/site-packages/six.py in raise_from(value, from_value)\r\n\r\nAlreadyExistsError: Resource localhost//N10tensorflow22SummaryWriterInterfaceE [Op:CreateSummaryFileWriter]\r\n```\r\n\r\nExplicitly calling `create_file_writer` with a unique `name` keyword argument solves the issue, but I'd have thought the name should be auto-uniquefied like with other TensorFlow ops.\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "The template has been updated.", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "/CC @aselle, can you comment?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Overall it's not safe to create two writers with the same logdir. If you build from HEAD and try with different logdirs does it work?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I had run into this issue today when I'm using Google Colab.\r\n\r\nSo I try to write like this:\r\n\r\n```python\r\n    try:\r\n      summary_writer\r\n    except NameError:\r\n      summary_writer = tf.contrib.summary.create_file_writer('./data/tensorboard')\r\n```\r\n\r\nbut it did not resolve the problem."]}, {"number": 15858, "title": "Add unsortedsegment(prod/min/max/sqrt_n/mean).", "body": "\r\nThis pull request\r\n- adds CPU/GPU implementations of\r\n  - `tf.unsorted_segment_min`,\r\n  - `tf.unsorted_segment_prod` and a\r\n  - GPU implementation for `tf.unsorted_segment_max`.\r\n- adds python implementations of:\r\n  - `tf.unsorted_segment_mean`\r\n  - `tf.unsorted_segment_sqrt_n`\r\n- fixes the gradient calculation for unsorted_segment_sum/max.\r\n  #13055 introduced silent dropping of negative values on the cpu.\r\n  However, the gradient of e.g. unsorted_segment_sum used tf.gather\r\n  and therefore failed for negative indices on cpu.\r\n  \r\nI tried to simplify the code and to remove code duplication,\r\naddressing this [todo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops.cc#L362).\r\n(Also I once filed an  [issue](https://github.com/tensorflow/tensorflow/issues/7389)  to add these ops but only now had time to finish it ;).)\r\n\r\n\r\nSome notes on this pull request:\r\n\r\n- tf.gather returns zero on GPU for negative indices and raises an exception on\r\n  CPU. To overcome this, the current implementation masks negative indices and\r\n  sets them to zero later. This is of course not as efficient as the original gather.\r\n  Would it make sense to use something like `if \"gpu\" in op.device.lower():` to run\r\n  different functions, depending on the device?\r\n- Instead of having a native op for mean/sqrt_n I added them in python.\r\n  Making them native would require two additional template arguments\r\n  (a functor to process the counter), resulting in more complicated code with\r\n  probably only minor performance improvement, if at all. In my quick\r\n  benchmarks, the python ops are nearly as fast as unsorted_segment_sum. However,\r\n  they use more memory than a native op would, due to creating a tensor of ones.\r\n  (bincount doesn't work here as it doesn't support negative indices)\r\n- I simply copy-pasted some atomicOp code in `cuda_kernel_helper.h` instead of\r\n  writing this more nicely as for a short period there was a completely different\r\n  version of this file online and I wanted to check back with you before\r\n  doing something more sophisticated. What's the status of this?\r\n\r\n  Additionally, I guess the function `AccumulateInto` in `segment_reduction_ops_gpu.cu.cc`\r\n  could be removed? CudaAtomicAdd has specializations for complex types in\r\n  cuda_kernel_helper.h\r\n\r\nCheers,\r\nPhil", "comments": ["Can one of the admins verify this patch?", "What\n\n4 Oca 2018 23:09 tarihinde \"Tensorflow Jenkins\" <notifications@github.com>\nyazd\u0131:\n\n> Can one of the admins verify this patch?\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15858#issuecomment-355384930>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/APamuW3YLn30uY6xiS9OZ5o3sxjq4Coyks5tHS-SgaJpZM4RTgLn>\n> .\n>\n", "I rebased and updated the golden API, this should fix the test failures.", "Hey Phil\r\n\r\nThanks for those updates needed them for some ray-tracing operations. In addition I also need the argmax/argmin operations. Could you direct me how I could add those operations.\r\n\r\nCheers", "@rmlarsen\r\n- How do I update the golden API for MacOS? The api_compatibility tests pass for python3. (I can't access the build log of Ubuntu python2)\r\n- The new `cuda_kernel_helper.h` / `cuda_device_functions.h` are back in the master, I rebased, adapted this pull request accordingly and squashed commits.\r\n\r\n\r\n@ub216  Do you want to implement this as a native op or are you fine with a composition of native ops? For the composition you could take a look at the implementation of the gradient of unsorted_segment_max. I.e. something like this should work (untested):\r\n```\r\nunsorted_max = tf.unsorted_segment_max(params, ids)\r\ngathered_max = tf.gather(unsorted_max, ids)\r\narg_max = tf.where(tf.equal(gathered_max, params))\r\n```\r\nIn any case, I think this is not the right thread to discuss this, if you're interested in implementing this as a cpp op I suggest to open a feature request issue to discuss it there ;)", "Apologies for crashing the thread. Will start a new thread for the cpp op and thanks for the composition of ops.", "@PhilJd Great work!\r\n\r\nDo you think it is possible to have an unsorted_segment_matmul op within your framework?", "@PhilJd you have to install Python 2.7 and run the api_compatibility test to add golden's with it, I believe.", "@PhilJd Sorry for the delay. I'll review this within the next couple of days.", "@rmlarsen \r\nThanks for triggering the tests, I'll look into the failures tomorrow! \r\nRegarding the api compatibility tests: I ran the command in a virtual environment with python2.7 on an Ubuntu 16.04 machine for the current commit, this doesn't seem to have solved the problem.\r\n\r\n\r\n@mehmetbasbug \r\nAs the current implementation flattens the array there's no straightforward way to integrate it without adapting some of the code. Also, I guess this will be specific for your use case, e.g. how would you define the order of multiplication?", "@PhilJd What you describe usually resolves the API compatibility issues. @gunan @wicke do you have any additional advice?", "@PhilJD in the virtual environment you may need to rerun configure, rebuild and then run the commands.\r\nDid you build within the virtual environment, or did you just run the binary inside the environment (just making sure).", "@PhilJd could you also please rebase to resolve the conflicts?", "@rmlarsen  @gunan \r\nThanks for the help! I rebased and after cleaning `.cache/bazel` and rebuilding I could successfully update the golden API (at least it generated some lines in `/tensorflow/tools/api/golden/tensorflow.pbtxt`). I built tf in the virtual environment before as well, so I think removing the cache somehow did the trick.\r\n\r\nI'm a bit clueless regarding the build failures (see below). These tests build and run fine locally on two different machines (Ubuntu 16.04 and Arch Linux, python2/3, w. CUDA 9 and CUDNN 7, Pascal GPUs). Do the test servers run with cuda_arch < 600? This is [handled separately](https://github.com/PhilJd/tensorflow/blob/eaa764379a46ac967c683987a98687f8716798e8/tensorflow/core/util/cuda_device_functions.h#L474), however, I didn't touch these lines.\r\n\r\nCheers\r\n```\r\nerror: no instance of overloaded function \"atomicAdd\" matches the argument list\r\n            argument types are: (double *, double)\r\n          detected during instantiation of \"tensorflow::detail::ToTypeIfConvertible<U, T> tensorflow::CudaAtomicAdd(T *, U) [with T=double, U=double]\" \r\n```\r\n", "Okay, I was just too tired yesterday to remember that the complex specialization for atomicAdd relies on the double specialization. I switched the order, i.e. moved the complex specialization below the special case for double and cuda_arch < 600. Now compilation for cuda_arch 5.1 works. Sorry for the confusion! Could you trigger the tests again? Thanks!", "@PhilJd would you consider adding support for fp16 (DT_HALF) and bfloat16 (DT_BFLOAT16)? Could be done as a followup PR.", "Thanks for the comments!\r\nI tried to enable bfloat16, but I struggle to do so for `unsorted_segment_{mean,sqrt_n}`. I enabled bfloat16 for cwise_max and fixed double registration in the reshape op but I don't know enough about the inner workings of tf to quickly implement the real_div op for bfloat16. So for now I disabled the test cases for mean/sqrtn + bfloat16. \r\nIn theory, these ops should work with bfloat16 once real_div is implemented. Would you be fine with enabling the test cases as soon as someone implemented `div`?", "@PhilJd Thanks a lot for adding partial support for additional types! We can certainly leave complete support for bfloat16 for a future change.", "I'll look into the test failures tomorrow morning!", "The GPU CC build should be fixed, the failure of the Android Demo App seems unrelated (tar exited with 1). I'm not sure why Ubuntu Python3 PIP failed,  I can't reproduce it locally...", "@PhilJd Thanks again for a great contribution!"]}, {"number": 15857, "title": "Update documentation for gather_nd/gather to specify behaviors for out-of-bound indices", "body": "This fix updates documentation for gather_nd/gather/scatter_nd to specify behaviors for out-of-bound indices. Basically, on CPU an error will be returned and on GPU 0 value will be filled to the expected positions of the output.\r\n\r\nThis fix closes #13687. This fix closes #12608.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @ebrevdo for the review. The previous build failure in `//tensorflow/core:api_test` was caused by the docstring changes. I have applied `tensorflow/core/api_def/update_api_def.sh` to fix it. This is just to accommodate the changes in doc string of the API, there is no actual API changes.", "Sounds good.\n\nOn Thu, Jan 4, 2018, 10:06 PM Yong Tang <notifications@github.com> wrote:\n\n> Thanks @ebrevdo <https://github.com/ebrevdo> for the review. The previous\n> build failure in //tensorflow/core:api_test was caused by the docstring\n> changes. I have applied tensorflow/core/api_def/update_api_def.sh to fix\n> it. This is just to accommodate the changes in doc string of the API, there\n> is no actual API changes.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15857#issuecomment-355480079>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimz4WV2-xwC4JoygirpNFK-8jUMjaks5tHbvugaJpZM4RTf9e>\n> .\n>\n"]}, {"number": 15856, "title": "MKL DNN: Implementing MKL DNN version of Softmax", "body": "New MKL DNN implementation of Softmax is added. ", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 15855, "title": "Export inception model after retrain", "body": "The are many issues and Stackoverflow posts asking how to export a retrained Inception model: https://github.com/tensorflow/serving/issues/449, https://github.com/tensorflow/serving/issues/33, https://github.com/tensorflow/serving/issues/7. It would be nice if retrain.py did this so that it's easier for newcomers to use Tensorflow Serving.\r\n\r\nThis PR exports the model after retrain is finished. I've also added a comment on how to serve the retrained model.\r\n\r\nConfirmed works for tensorflow version 1.4.1.\r\n  \r\n  ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@andrewharp @petewarden could you please take a look?", "Hello @ksindi ,\r\nI tried exporting model for serving using your code. It generates model as well as variable but also throws some kind of error message after this line \"builder.save()\"\r\nThe error and info are as follows:\r\n\r\n> ipdb> INFO:tensorflow:SavedModel written to: b'model/1\\\\saved_model.pb'\r\n> ipdb> An exception has occurred, use %tb to see the full traceback.\r\n> SystemExit\r\n> ERROR: execution aborted\r\n\r\nAlso while serving the generated model files on tensorflow servings does not have any problem. I can run the ModelServer at 0.0.0.0:9000 inside docker container(CPU) on Ubuntu but while doing the prediction job, it always fails with an error msg:\r\n```\r\nuser@ubuntu:~/tensorflow_serving/example$ python inception_client.py --server=172.17.0.2:9000 --image=./testdata/dog.jpg\r\nTraceback (most recent call last):\r\n  File \"inception_client.py\", line 47, in <module>\r\n    tf.app.run()\r\n  File \"/home/user/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"inception_client.py\", line 42, in main\r\n    result = stub.Predict(request, 60.0)  # 60 secs timeout\r\n  File \"/home/user/.local/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py\", line 310, in __call__\r\n    self._request_serializer, self._response_deserializer)\r\n  File \"/home/user/.local/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py\", line 196, in _blocking_unary_unary\r\n    raise _abortion_error(rpc_error_call)\r\ngrpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=\"input tensor alias not found in signature: images. Inputs expected to be in the set {image}.\")\r\n``` \r\n\r\nIs there anything I'm missing or any additional setting is needed?\r\n\r\nSaugat", "@saugat what version of tensorflow and tensorflow-serving are you using? It worked for 1.4.1.", "@saugat check this line:\r\n\r\n`request.inputs['image'].CopyFrom(tf.contrib.util.make_tensor_proto(data,))`\r\n\r\nit looks like you have a versions with an added 's', like so:\r\n\r\n`request.inputs['images'].CopyFrom(tf.contrib.util.make_tensor_proto(data,))`", "@ksindi I am using TF 1.4.1 and TF Serving 1.5.0 on a docker container under Ubuntu 16.1\r\n@pgpgpg Yes I was using version that uses 'images'. Changed it to 'image' and now getting different kind of error.\r\n```\r\nuser@ubuntu:~/tensorflow_serving/example$ python inception_client.py --server=172.17.0.2:9000 --image=./testdata/dog.jpg\r\nTraceback (most recent call last):\r\n  File \"inception_client.py\", line 47, in <module>\r\n    tf.app.run()\r\n  File \"/home/user/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"inception_client.py\", line 42, in main\r\n    result = stub.Predict(request, 60.0)  # 60 secs timeout\r\n  File \"/home/user/.local/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py\", line 310, in __call__\r\n    self._request_serializer, self._response_deserializer)\r\n  File \"/home/user/.local/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py\", line 196, in _blocking_unary_unary\r\n    raise _abortion_error(rpc_error_call)\r\ngrpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=\"contents must be scalar, got shape [1]\r\n     [[Node: DecodeJpeg = DecodeJpeg[_output_shapes=[[?,?,3]], acceptable_fraction=1, channels=3, dct_method=\"\", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_DecodeJpeg/contents_0_0)]]\")\r\n```", "@ksindi @pgpgpg  Got the result.  Took a reference from ksindi's response to this issue which solved the problem. [https://github.com/tensorflow/serving/issues/449](url)", "thanks @martinwicke @petewarden "]}, {"number": 15854, "title": "Enable tilde expansion in debug wrappers", "body": "This commit allows paths beginning with '~' to be used when specifying where\r\ndebug files should be dumped. The tilde will now be expanded to the user's\r\nhome directory.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks, @pvaneck !"]}, {"number": 15853, "title": "Fixes and formatting to configure.py", "body": "* Fix a bug in error generation regarding true/false string parsing\r\n* Some minor style fixes", "comments": ["Done reducing the number of lines. Thanks."]}, {"number": 15852, "title": "Eager: crashed when using embedding_lookup in tfe.defun in tfe.GradientTape", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.5.0dev20171230\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:9.0/7.0\r\n- **GPU model and memory**:pascal\r\n- **Exact command to reproduce**:N/A\r\n### Describe the problem\r\nWhen I train a seq2seq model in eager, backward will raise a error:\r\n```Python\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in get_attr(self, name)\r\n   2162           with errors.raise_exception_on_not_ok_status() as status:\r\n-> 2163             c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf, status)\r\n   2164           data = c_api.TF_GetBuffer(buf)\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    472             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 473             c_api.TF_GetCode(self.status.status))\r\n    474     # Delete the underlying status object from memory otherwise it stays alive\r\n\r\nInvalidArgumentError: Operation 'embedding_lookup' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    369     try:\r\n--> 370       xla_compile = op.get_attr(\"_XlaCompile\")\r\n    371       xla_separate_compiled_gradients = op.get_attr(\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in get_attr(self, name)\r\n   2166         # Convert to ValueError for backwards compatibility.\r\n-> 2167         raise ValueError(str(e))\r\n   2168       x = attr_value_pb2.AttrValue()\r\n\r\nValueError: Operation 'embedding_lookup' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-1-ed6ea9045e3f> in <module>()\r\n     12         embed = tfe.Variable(np.ones((10, 100)).astype(np.float32))\r\n     13         toy_data = np.ones((1, 10)).astype(np.int64)\r\n---> 14         embedding_crash(toy_data, embed)\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in decorated(*args, **kwds)\r\n    639       arguments_to_functions[cache_key] = _defun_internal(\r\n    640           name, func, args, kwds)\r\n--> 641     return arguments_to_functions[cache_key](*args)\r\n    642 \r\n    643   return decorated\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in __call__(self, *args)\r\n    461         self._extra_inputs):\r\n    462       if not self._has_backprop:\r\n--> 463         self._compute_backprop()\r\n    464       return self._backprop_call(tensor_inputs)\r\n    465 \r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _compute_backprop(self)\r\n    359             filtered_outputs,\r\n    360             self._input_placeholders,\r\n--> 361             grad_ys=self._out_grad_placeholders)\r\n    362         shapes = tuple(x.shape for x in in_gradients if x is not None)\r\n    363     captures = list(sorted(c.captured_tensors, key=lambda x: x.name))\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\r\n    607                 # functions.\r\n    608                 in_grads = _MaybeCompile(\r\n--> 609                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n    610               else:\r\n    611                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    373       xla_scope = op.get_attr(\"_XlaScope\").decode()\r\n    374     except ValueError:\r\n--> 375       return grad_fn()  # Exit early\r\n    376 \r\n    377   if not xla_compile:\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py in <lambda>()\r\n    607                 # functions.\r\n    608                 in_grads = _MaybeCompile(\r\n--> 609                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n    610               else:\r\n    611                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in _GatherGrad(op, grad)\r\n    895     # TODO(apassos): implement this for EAGER mode.\r\n    896     while handle.op.type != \"VarHandleOp\":\r\n--> 897       handle = handle.op.inputs[0]\r\n    898   params_shape = gen_resource_variable_ops.variable_shape(handle)\r\n    899   size = array_ops.expand_dims(array_ops.size(indices), 0)\r\n\r\nc:\\users\\yanyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in __getitem__(self, i)\r\n   1992 \r\n   1993     def __getitem__(self, i):\r\n-> 1994       return self._inputs[i]\r\n   1995 \r\n   1996 # pylint: enable=protected-access\r\n\r\nIndexError: list index out of range\r\n```\r\nNo problem when remove @tfe.defun, but eager is very slow without defun so I need to compile model with tfe.defun.\r\ncode to reproduce error:\r\n```Python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport numpy as np\r\ntfe.enable_eager_execution()\r\n@tfe.defun\r\ndef embedding_crash(x, embedding):\r\n    return tf.nn.embedding_lookup(embedding, x)\r\nwith tf.device(\"gpu:0\"):\r\n    with tfe.GradientTape() as g:\r\n        embed = tfe.Variable(np.ones((10, 100)).astype(np.float32))\r\n        toy_data = np.ones((1, 10)).astype(np.int64)\r\n        embedding_crash(toy_data, embed)\r\n```\r\n  ", "comments": ["@akshayka @alextp - mind taking a look?", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 15851, "title": "Tensorflow: Non-deterministic behaviour with large model using while_loop", "body": "Hello!\r\nI believe to have found a bug in Tensorflow when running the code below. I am currently trying to build a neural transducer, and have stumbled across TF sometimes not returning any values for a function. I have not had the chance yet to test this out on another machine (no GPU, TF 1.4.1, Ubuntu 17.10). I am not sure whether this is indeed a bug or not, so I'm first posting it here. The code is redacted a bit to highlight only the parts that fail. [I've also posted to StackOverflow](https://stackoverflow.com/questions/48081063/tensorflow-non-deterministic-behaviour-with-large-model-using-while-loop) considering it might be an error in my code, but haven't got any response yet.\r\n\r\nNotes:\r\n\r\n- I believe the bug occurs around line 160, in the body of the while loop in the function run_full_transducer\r\n- The session is returning [encoder_outputs, transducer_outputs]\r\n- I do not use random functions\r\n- As far as I can tell, if I remove the Print OP in line 164, the output is always 0\r\n\r\nExample of a correct return value (more or less):\r\n```\r\narray([[[ 0.00811536, -0.00200322, -0.01177037,  0.03676344, -0.01909475,\r\n             -0.03157664,  0.026092  ,  0.02367685, -0.01894805,  0.02832799,\r\n              0.0377345 , -0.02583589, -0.02908566,  0.0299024 ,  0.00518877,\r\n             -0.00064737,  0.01431572, -0.01053502, -0.01783628, -0.00382657,\r\n              0.00076749, -0.02705991,  0.00112415, -0.0193013 ,  0.02346764,\r\n              0.03014467,  0.02663364,  0.02503882,  0.03362656, -0.01877708,\r\n              0.01859642,  0.02460729, -0.01395229, -0.03033791,  0.01177907,\r\n             -0.03049169, -0.00389978,  0.02221515, -0.00073605,  0.01248251,\r\n              0.00424051,  0.01070387,  0.02818898,  0.0321721 , -0.02462685,\r\n              0.03495178, -0.02408989, -0.02742486,  0.00331823, -0.02311424,\r\n             -0.01327039,  0.01095297,  0.02584363,  0.02083527, -0.01588045,\r\n              0.02837921,  0.02100117,  0.00918638,  0.00109535, -0.02965789,\r\n              0.01040822, -0.03240473,  0.00453057, -0.00603903]],\r\n    \r\n           [[ 0.01053647, -0.00457577, -0.01939731,  0.06317309, -0.03113565,\r\n             -0.05525927,  0.04647589,  0.04213476, -0.03498235,  0.04962765,\r\n              0.05989208, -0.04340284, -0.04777668,  0.05346756,  0.00395604,\r\n             -0.0005207 ,  0.02079381, -0.01424338, -0.02584206, -0.00530154,\r\n             -0.00031365, -0.04966826, -0.00091683, -0.03025239,  0.04526306,\r\n              0.0595435 ,  0.0463665 ,  0.04578522,  0.05916505, -0.031725  ,\r\n              0.03164144,  0.04257958, -0.02865831, -0.04795898,  0.01856991,\r\n             -0.05512668, -0.00730711,  0.03953242,  0.00017992,  0.01710426,\r\n              0.00754557,  0.01975578,  0.0469296 ,  0.05237873, -0.04435374,\r\n              0.05924731, -0.04474678, -0.04605344,  0.00947831, -0.04284734,\r\n             -0.01979787,  0.02003288,  0.04196753,  0.03900779, -0.02887472,\r\n              0.05130195,  0.03419674,  0.0105699 ,  0.001114  , -0.0524303 ,\r\n              0.01738651, -0.06084244,  0.01364262, -0.01153531]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\r\n```\r\nIncorrect:\r\n```\r\n [array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\r\n    \r\n           [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\r\n              0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32), array([], shape=(0, 1, 3), dtype=float32)]\r\n```\r\n\r\nCode:\r\n``` python\r\n import tensorflow as tf\r\n    from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\r\n    from tensorflow.python.layers import core as layers_core\r\n    import numpy as np\r\n    # NOTE: Time major\r\n    \r\n    # Constants\r\n    input_dimensions = 1\r\n    vocab_size = 3\r\n    input_embedding_size = 20\r\n    encoder_hidden_units = 64\r\n    inputs_embedded = True\r\n    transducer_hidden_units = 64\r\n    batch_size = 1\r\n    GO_SYMBOL = vocab_size - 1  # TODO: Make these constants correct\r\n    END_SYMBOL = vocab_size\r\n    input_block_size = 2\r\n    log_prob_init_value = 0\r\n    \r\n    \r\n    # ---------------- Helper classes -----------------------\r\n    \r\n    \r\n    # ----------------- Model -------------------------------\r\n    embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\r\n    \r\n    \r\n    class Model(object):\r\n        def __init__(self):\r\n            self.encoder_inputs, self.encoder_inputs_length, self.encoder_hidden_state, \\\r\n            self.encoder_outputs, self.encoder_hidden_state_new = self.build_encoder_model()\r\n            self.encoder_raw_outputs, self.trans_hidden_state, self.transducer_amount_outputs, \\\r\n            self.transducer_hidden_state_new, self.logits, self.decoder_prediction = self.build_transducer_model()\r\n    \r\n        def build_encoder_model(self):\r\n            encoder_inputs = tf.Variable(tf.zeros(shape=(input_block_size, batch_size, input_dimensions)),\r\n                                         dtype=tf.float32, name='encoder_inputs', trainable=False)\r\n            encoder_inputs_length = tf.Variable([tf.shape(encoder_inputs)[0]], dtype=tf.int32,\r\n                                                name='encoder_inputs_length', trainable=False)\r\n            encoder_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, encoder_hidden_units)), dtype=tf.float32,\r\n                                               name='encoder_hidden_state')  # Save the state as one tensor\r\n    \r\n            if inputs_embedded is True:\r\n                encoder_inputs_embedded = encoder_inputs\r\n            else:\r\n                encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\r\n    \r\n            # Build model\r\n            encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\r\n    \r\n            # Build previous state\r\n            encoder_hidden_c, encoder_hidden_h = tf.split(encoder_hidden_state, num_or_size_splits=2, axis=0)\r\n            encoder_hidden_c = tf.reshape(encoder_hidden_c, shape=[-1, encoder_hidden_units])\r\n            encoder_hidden_h = tf.reshape(encoder_hidden_h, shape=[-1, encoder_hidden_units])\r\n            encoder_hidden_state_t = LSTMStateTuple(encoder_hidden_c, encoder_hidden_h)\r\n    \r\n            #   encoder_outputs: [max_time, batch_size, num_units]\r\n            encoder_outputs, encoder_hidden_state_new = tf.nn.dynamic_rnn(\r\n                encoder_cell, encoder_inputs_embedded,\r\n                sequence_length=encoder_inputs_length, time_major=True,\r\n                dtype=tf.float32, initial_state=encoder_hidden_state_t)\r\n    \r\n            # Modify output of encoder_hidden_state_new so that it can be fed back in again without problems.\r\n            encoder_hidden_state_new = tf.concat([encoder_hidden_state_new.c, encoder_hidden_state_new.h], axis=0)\r\n            encoder_hidden_state_new = tf.reshape(encoder_hidden_state_new, shape=[2, -1, encoder_hidden_units])\r\n    \r\n            return encoder_inputs, encoder_inputs_length, encoder_hidden_state, encoder_outputs, encoder_hidden_state_new\r\n    \r\n        def build_transducer_model(self):\r\n            encoder_raw_outputs = tf.Variable(tf.zeros(shape=(input_block_size, 1, encoder_hidden_units)),\r\n                                              dtype=tf.float32,\r\n                                              name='encoder_raw_outputs')\r\n            trans_hidden_state = tf.Variable(tf.zeros(shape=(2, 1, transducer_hidden_units)),\r\n                                             dtype=tf.float32,\r\n                                             name='trans_hidden_state')  # Save the state as one tensor\r\n            transducer_amount_outputs = tf.Variable(0, dtype=tf.int32, name='transducer_amount_outputs',\r\n                                                    trainable=False)\r\n    \r\n            # Model building\r\n            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\r\n                embedding=embeddings,\r\n                start_tokens=tf.tile([GO_SYMBOL], [batch_size]),\r\n                end_token=END_SYMBOL)\r\n    \r\n            attention_states = tf.transpose(encoder_raw_outputs,\r\n                                            [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]\r\n    \r\n            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n                encoder_hidden_units, attention_states)\r\n    \r\n            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n                tf.contrib.rnn.LSTMCell(transducer_hidden_units),\r\n                attention_mechanism,\r\n                attention_layer_size=transducer_hidden_units)\r\n    \r\n            projection_layer = layers_core.Dense(vocab_size, use_bias=False)\r\n    \r\n            # Build previous state\r\n            trans_hidden_c, trans_hidden_h = tf.split(trans_hidden_state, num_or_size_splits=2, axis=0)\r\n            trans_hidden_c = tf.reshape(trans_hidden_c, shape=[-1, transducer_hidden_units])\r\n            trans_hidden_h = tf.reshape(trans_hidden_h, shape=[-1, transducer_hidden_units])\r\n            trans_hidden_state_t = LSTMStateTuple(trans_hidden_c, trans_hidden_h)\r\n    \r\n            decoder = tf.contrib.seq2seq.BasicDecoder(\r\n                decoder_cell, helper,\r\n                decoder_cell.zero_state(1, tf.float32).clone(cell_state=trans_hidden_state_t),\r\n                output_layer=projection_layer)\r\n    \r\n            outputs, transducer_hidden_state_new, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\r\n                                                                                        output_time_major=True,\r\n                                                                                        maximum_iterations=transducer_amount_outputs)\r\n            logits = outputs.rnn_output  # logits of shape [max_time,batch_size,vocab_size]\r\n            decoder_prediction = outputs.sample_id  # For debugging\r\n    \r\n            # Modify output of transducer_hidden_state_new so that it can be fed back in again without problems.\r\n            transducer_hidden_state_new = tf.concat(\r\n                [transducer_hidden_state_new[0].c, transducer_hidden_state_new[0].h],\r\n                axis=0)\r\n            transducer_hidden_state_new = tf.reshape(transducer_hidden_state_new,\r\n                                                     shape=[2, -1, transducer_hidden_units])\r\n    \r\n            return encoder_raw_outputs, trans_hidden_state, transducer_amount_outputs, transducer_hidden_state_new, \\\r\n                   logits, decoder_prediction\r\n    \r\n    \r\n    model = Model()\r\n    \r\n    \r\n    # ----------------- Alignment -------------------------\r\n    \r\n    # ----------------- Training --------------------------\r\n    \r\n    def run_full_transducer():\r\n        # Inputs\r\n        max_blocks = tf.placeholder(dtype=tf.int32, name='max_blocks')\r\n        inputs_full_raw = tf.placeholder(shape=(None, batch_size, input_dimensions), dtype=tf.float32,\r\n                                         name='inputs_full_raw')\r\n        transducer_list_outputs = tf.placeholder(shape=(None,), dtype=tf.int32,\r\n                                                 name='transducer_list_outputs')  # amount to output per block\r\n    \r\n        # Turn inputs into tensor which is easily readable\r\n        inputs_full = tf.reshape(inputs_full_raw, shape=[max_blocks, input_block_size, batch_size, input_dimensions])\r\n    \r\n        # Outputs\r\n        outputs_ta = tf.TensorArray(dtype=tf.float32, size=max_blocks)\r\n    \r\n        # Hidden states\r\n        # TODO: make these correct\r\n        encoder_hidden_init = tf.ones(shape=(2, 1, encoder_hidden_units))\r\n        trans_hidden_init = tf.ones(shape=(2, 1, transducer_hidden_units))\r\n    \r\n        init_state = (0, outputs_ta, encoder_hidden_init, trans_hidden_init)\r\n    \r\n        def cond(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n            return current_block < max_blocks\r\n    \r\n        def body(current_block, outputs_int, encoder_hidden, trans_hidden):\r\n            # Process encoder\r\n            model.encoder_inputs = model.encoder_inputs.assign(inputs_full[current_block])\r\n            model.encoder_inputs_length = model.encoder_inputs_length.assign([tf.shape(model.encoder_inputs)[0]])\r\n            model.encoder_hidden_state = model.encoder_hidden_state.assign(encoder_hidden)\r\n    \r\n            # TODO: Error is SOMETIMES gone when using tf.Print\r\n            current_block = tf.Print(current_block, [model.encoder_inputs], message='Enc in: ')\r\n            #current_block = tf.Print(current_block, [model.encoder_outputs], message='Enc out: ')\r\n    \r\n            # Flow data from encoder to transducer\r\n            model.encoder_raw_outputs = model.encoder_raw_outputs.assign(model.encoder_outputs)\r\n            model.trans_hidden_state = model.trans_hidden_state.assign(trans_hidden)\r\n            model.transducer_amount_outputs = model.transducer_amount_outputs.assign(transducer_list_outputs[current_block])\r\n    \r\n            # Note the outputs\r\n            outputs_int = outputs_int.write(current_block, model.logits)\r\n    \r\n            return current_block + 1, outputs_int, model.encoder_hidden_state_new, model.transducer_hidden_state_new\r\n    \r\n        _, outputs_final, _, _ = tf.while_loop(cond, body, init_state)\r\n    \r\n        # Process outputs\r\n        outputs = outputs_final.stack()  # Now the outputs are of shape [block, amount_of_trans_out, batch_size, vocab]\r\n        outputs = tf.reshape(outputs, shape=(-1, 1, vocab_size))  # And now its [amount_outputs, batch_size, vocab]\r\n    \r\n        model.encoder_outputs = tf.Print(model.encoder_outputs, [model.encoder_outputs], message='Current block enc out: ')\r\n    \r\n        return max_blocks, inputs_full_raw, transducer_list_outputs, outputs, model.encoder_outputs\r\n    \r\n    # ---------------------- Testing -----------------------------\r\n    \r\n    \r\n    # ---------------------- Management -----------------------------\r\n    \r\n    init = tf.global_variables_initializer()\r\n    \r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n    \r\n        inp_max_blocks, inp_inputs_full_raw, inp_trans_list_out, out_outputs, enc_out = run_full_transducer()\r\n    \r\n        print sess.run([enc_out, out_outputs], feed_dict={\r\n            inp_max_blocks: 3,\r\n            inp_inputs_full_raw: np.ones(shape=(3 * input_block_size, 1, input_dimensions)),\r\n            inp_trans_list_out: [1, 3, 2]\r\n        })\r\n```\r\n\r\nInfo about machine:\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"17.10 (Artful Aardvark)\"\r\nVERSION_ID=\"17.10\"\r\nVERSION_CODENAME=artful\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.5.1)\r\ntensorflow (1.4.1)\r\ntensorflow-tensorboard (0.4.0rc3)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.1\r\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\r\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```\r\nHave I written custom code Yes\r\nOS Platform and Distribution Ubuntu 17.10 (Artful Aardvark)\r\nTensorFlow installed from binary\r\nTensorFlow version 1.4.1\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce Execute the code block as a python file a few times.\r\n\r\nThanks!\r\nNikita\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Reposting due to lack of response."]}, {"number": 15850, "title": "unable to install from source with undefined external dependency target error", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: r1.4.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**:\r\n`sudo bazel build --config=opt --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package`\r\n### Describe the problem\r\n I'm trying to install r1.4.0 from source with CPU version and follow the install guidelines on the official website.  But some errors occur. (The errors are shown in \"Source code / logs\" )\r\n(1) It seems that the undefined external dependency target \"@local_config_sycl\" is referred in some files (eg. //tensorflow-1.4.0/ third_party/eigen3/build ).\r\n(2) I am sure the openCL suppurt is disabled when configure.\r\n(3) I tried to install version r1.0.1 from source, but the same errors occur.\r\n(4) I tried to install version r1.4.0 from binary, and success.\r\n\r\nWhy this happens and how can I fix it? Thank you!\r\n\r\n### Source code / logs\r\n`ERROR: /home/tangdehong/.cache/bazel/_bazel_root/4bf03e1269a0e4905c62fa69a980acb4/external/local_config_sycl/sycl/BUILD:4:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.\r\nERROR: /home/tangdehong/.cache/bazel/_bazel_root/4bf03e1269a0e4905c62fa69a980acb4/external/local_config_sycl/sycl/BUILD:6:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.\r\nERROR: /home/tangdehong/.cache/bazel/_bazel_root/4bf03e1269a0e4905c62fa69a980acb4/external/local_config_sycl/sycl/BUILD:30:9: Traceback (most recent call last):\r\n\tFile \"/home/tangdehong/.cache/bazel/_bazel_root/4bf03e1269a0e4905c62fa69a980acb4/external/local_config_sycl/sycl/BUILD\", line 27\r\n\t\tcc_library(name = \"syclrt\", srcs = [sycl_libr...\")], <3 more arguments>)\r\n\tFile \"/home/tangdehong/.cache/bazel/_bazel_root/4bf03e1269a0e4905c62fa69a980acb4/external/local_config_sycl/sycl/BUILD\", line 30, in cc_library\r\n\t\tsycl_library_path\r\nname 'sycl_library_path' is not defined\r\nERROR: /home/tangdehong/.cache/bazel/_bazel_root/4bf03e1269a0e4905c62fa69a980acb4/external/local_config_sycl/sycl/BUILD:39:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'\r\nERROR: /home/tangdehong/OpenSourceCode/tensorflow-1.4.0/third_party/eigen3/BUILD:20:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//third_party/eigen3:eigen3'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed\r\nINFO: Elapsed time: 0.745s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/contrib/losses ... (17 packages)\r\n`\r\nThank you!", "comments": ["@yifeif @gunan any ideas?", "I think there was a change in bazel that made our bazel files break.\r\nIf you need 1.4 release, you may need to roll back your bazel version to 0.5.4 or something close.\r\nOtherwise, please try with 1.5 release.\r\n\r\nCould you try one of the above ant let me know if it solves your problem?", "I get the same error : \r\n\r\n`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n........\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:98:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:100:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:102:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:104:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:106:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:108:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:110:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:112:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:114:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:116:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:118:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:120:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:122:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:124:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:126:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:131:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:136:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:141:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:146:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/com_googlesource_code_re2/BUILD:151:1: name 're2_test' is not defined (did you mean 'ios_test'?)\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD:4:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD:6:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD:41:9: Traceback (most recent call last):\r\n\tFile \"/home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD\", line 38\r\n\t\tcc_library(name = \"syclrt\", srcs = [sycl_libr...\")], <3 more arguments>)\r\n\tFile \"/home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD\", line 41, in cc_library\r\n\t\tsycl_library_path\r\nname 'sycl_library_path' is not defined\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD:50:1: Target '@local_config_sycl//sycl:using_sycl_ccpp' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'\r\nERROR: /home/xavier/.cache/bazel/_bazel_xavier/ef54af8645dec4f38c438d8e1c779747/external/local_config_sycl/sycl/BUILD:50:1: Target '@local_config_sycl//sycl:using_sycl_trisycl' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'\r\nERROR: /home/xavier/Bureau/developpement/NeuralNetwork/tensorflow/third_party/eigen3/BUILD:20:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//third_party/eigen3:eigen3'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed\r\nINFO: Elapsed time: 4.217s\r\nFAILED: Build did NOT complete successfully (101 packages loaded)\r\n    currently loading: tensorflow/core ... (2 packages)\r\n`\r\n\r\nI can't solve it. Can someone help me ?", "@xav12358 Please see my comment right above your question.\r\nOr the other option is, in the 2nd line of your log:\r\n```\r\nUse --incompatible_load_argument_is_label=false to temporarily disable this check.\r\n```", "@gunan Thank you very much for your help. \r\n1. I try to build tensorflow-1.5.0rc0 with bazel 0.9.0, and success.Although there are still some warnings like comparison between signed int and unsigned int, breaking strict-aliasing rules.\r\n2. The \"Hello, tensorflow!\" example runs well.", "@xav12358 \r\nI build tensorflow-1.5.0rc0 with bazel 0.9.0 following gunan's comment, and success. Maybe you can have a try."]}, {"number": 15849, "title": "gcc: error: unrecognized command line option '-fcolor-diagnostics'", "body": "The issue is similar to [#1192](https://github.com/tensorflow/tensorflow/issues/1192) \r\n\r\nI am trying build Tensorflow from source on UBUNTU machine (16.04 LTS)\r\nI am using following version of gcc and bazel\r\n\r\n- gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\n- bazel Build label: 0.9.0\r\n\r\n### Problem Description\r\nI get a number of build errors during the **bazel build** phase.\r\nAll errors are similar to one below (I used --verbose_failures option for **bazel build**):\r\n\r\n\r\n`ERROR: /home/murthy/tensorflow/tensorflow/core/BUILD:1656:1: Couldn't build file tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.o: C++ compilation of rule '//tensorflow/core:version_lib' failed (Exit 1): gcc failed: error executing command \r\n  (cd /home/murthy/.cache/bazel/_bazel_murthy/72b24eaacfd1d73bef6a8acb540b8c44/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/home/murthy/.virtualenvs/dl4cv/bin/python \\\r\n    PYTHON_LIB_PATH=/home/murthy/.virtualenvs/dl4cv/lib/python3.5 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-march=native' -mssse3 -mfma -mcx16 -msse4.1 -msse4.2 -mpopcnt -mavx '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.d '-frandom-seed=bazel-out/k8-py3-opt/bin/tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.o' -fPIC -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c bazel-out/k8-py3-opt/genfiles/tensorflow/core/util/version_info.cc -o bazel-out/k8-py3-opt/bin/tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.pic.o)\r\ngcc: error: unrecognized command line option '-fcolor-diagnostics'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n`\r\n## What did I do?\r\nI manually removed the `-fcolor-diagnostics` flag and gcc did not give an error.\r\nfurther I looked up the man pages for gcc and was surprised to find\r\n\r\n` Language Independent Options\r\n           -fmessage-length=n \r\n           -fdiagnostics-show-location=[once|every-line] \r\n           -fdiagnostics-color=[auto|never|always]\r\n           -fno-diagnostics-show-option -fno-diagnostics-show-caret\r\n`\r\n\r\n**Note**: the interchange in the words 'diagnostics' and 'color' in the man pages as compared to that in flags for **bazel build**\r\n\r\nI am not sure if this is Tensorflow issue or bazel issue but am looking for a way to suppress the `-fcolor-diagnostics' flag or change it to `-fdiagnostics-color`\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code : N/A\r\nOS Platform and Distribution: UBUNTU LTS 16.04\r\nTensorFlow installed from : source cloned from https://github.com/tensorflow/tensorflow\r\nTensorFlow version : N/A\r\nBazel version : 0.9.0\r\nCUDA/cuDNN version : N/A\r\nGPU model and memory : N/A\r\nExact command to reproduce : see below the shell script I used to build\r\n`\r\n#!/bin/bash\r\n#3/Jan/2018\r\n#Murthy made changes to the section marked below\r\n\r\n#original Author: Sasha Nikiforov\r\n#source of inspiration\r\n#https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions\r\n\r\n#check if VirtuelEnv activated\r\nif [ -z \"$VIRTUAL_ENV\" ]; then\r\n\techo \"VirtualEnv is not activated\"\r\n\texit -1\r\nfi\r\n\r\nVENV_BIN=$VIRTUAL_ENV/bin\r\nVENV_LIB=$VIRTUAL_ENV/lib\r\n\r\n#bazel tf needs these env vars\r\nexport PYTHON_BIN_PATH=$VENV_BIN/python\r\nexport PYTHON_LIB_PATH=$VENV_LIB/`ls $VENV_LIB | grep python`\r\n\r\necho Python bin path: $PYTHON_BIN_PATH\r\necho Python lib path: $PYTHON_LIB_PATH\r\n\r\n#changes made by Murthy start here\r\nraw_cpu_flags=`sudo lscpu  | grep 'Flags'`\r\nCOPT=\"--copt=-march=native\"\r\n\r\nfor cpu_feature in $raw_cpu_flags\r\ndo\r\n\tcase \"$cpu_feature\" in\r\n\t\t\"ssse3\" | \"fma\" | \"cx16\" | \"popcnt\" | \"maes\")\r\n\t\t    COPT+=\" --copt=-m$cpu_feature\"\r\n\t\t;;\r\n\t\t\"avx\")\r\n\t\t    COPT+=\" --copt=-mavx\"\r\n\t\t;;\r\n\t\t\"sse4_1\")\r\n\t\t    COPT+=\" --copt=-msse4.1\"\r\n\t\t;;\r\n\t\t\"sse4_2\")\r\n\t\t    COPT+=\" --copt=-msse4.2\"\r\n\t\t;;\r\n\t\t*)\r\n\t\t\t# noop\r\n\t\t;;\r\n\tesac\r\ndone\r\necho Options: $COPT\r\n#end of section within with changes were made by murthy\r\nbazel clean\r\n./configure\r\nbazel build --verbose_failures -c opt $COPT -k //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\n#pip install --upgrade /tmp/tensorflow_pkg/`ls /tmp/tensorflow_pkg/ | grep tensorflow`\r\n\r\n`", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "@ugmurthy can you give the exact bazel command used to build? It's hard to tell from the shell script. Running the script with `bash -x script.sh` will show you what command is used.", "here is the bazel command in expanded form:\r\n`bazel build --verbose_failures -c opt --copt=-march=native --copt=-mssse3 --copt=-mfma --copt=-mcx16 --copt=-msse4.1 --copt=-msse4.2 --copt=-mpopcnt --copt=-mavx -k //tensorflow/tools/pip_package:build_pip_package\r\n`", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I wasn't able to reproduce with that `bazel build` command on Ubuntu 16.04 with bazel 0.9.0.\r\n\r\n@gunan, any ideas what the issue could be?", "Not sure where that flag may be coming from. We may want to check that with bazel team.\r\n@mhlopko Could you redirect this to someone who may be able to answer?", "It's coming from bazel [autodetected crosstool](https://source.bazel.build/bazel/+/master:tools/cpp/unix_cc_configure.bzl;l=290), but this option should be only added when the compiler understands given flag. So it's very weird that bazel autodetected this flag for you. The only explanation I could find is that you had a symlink from gcc -> clang, then bazel autodetected the toolchain, and then you removed the symlink and installed gcc. Bazel would not notice the change in the system and would not regenerate the toolchain. You can test if smth similar is happening by running `bazel clean --expunge` and then building again. If the problem persists, it must be something else.", "@mhlopko, the `bazel clean -expunge` worked. Sucessfully compiled Tensorflow.\r\nthanks a ton.", "I just hit this too. expunge worked for me as well", "Also hit this and expunge also resolved it for me.  I do not have clang installed on my system and have never symlinked gcc to it.  Note that I did have gcc aliased as:\r\n\r\n`alias gcc='gcc -fdiagnostics-color=auto -Wall -Wextra -pedantic -std=c99'`\r\n\r\nbut those are all valid gcc options.  @mhlopko sure this isn't a bug in bazel?\r\n\r\nOne additional thing I should note:  I did switch from a checkout of `v1.11.0` to `master`, but don't see why that would affect the generated toolchain", "Dylan, well, the problem Bazel does have is that it doesn't notice changes/upgrade of your compiler, if you don't put all the files as `cc_toolchain` inputs, which we don't in our autodetection of C++ toolchain.\r\n\r\nWhat version of bazel do you have, and on what platforms are you on? Did you use cuda?", "```\r\n$ bazel version\r\nBuild label: 0.17.2\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Sep 21 10:31:42 2018 (1537525902)\r\nBuild timestamp: 1537525902\r\nBuild timestamp as int: 1537525902\r\n\r\n# Linux Mint 18.2:\r\n$ uname -a\r\nLinux precision 4.15.0-34-generic #37~16.04.1-Ubuntu SMP Tue Aug 28 10:44:06 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nI'm not purposely using cuda, but it looks like I do have libcuda installed, could that affect things?\r\n\r\n```\r\n$ dpkg -l | grep -i cuda\r\nii  libcuda1-384                                384.130-0ubuntu0.16.04.1                                amd64        NVIDIA CUDA runtime library\r\n```\r\n\r\nChecking my apt history my last gcc upgrade was 2018-09-30  07:01:36, so long before that bazel run... and again the weird thing is previous bazel builds ran fine... it was just that one run after switching branches which added the errant option and required an expunge.\r\n\r\nOh well, the reality is this isn't reproducible at the moment, so impossible to effectively debug.  If I do hit it again anywhere in particular I should look to help debug?  You mentioned autodetected crosstool above, anywhere else?", "@ugmurthy, \r\nThanks, its working fine with the command, \r\n\r\n`bazel build --verbose_failures -c opt --copt=-march=native --copt=-mssse3 --copt=-mfma --copt=-mcx16 --copt=-msse4.1 --copt=-msse4.2 --copt=-mpopcnt --copt=-mavx -k //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nAfter that, when I import the tf in python code got an error,\r\n\r\n```\r\nPython 3.6.8 (default, Jan 14 2019, 11:02:34) \r\n[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n>>> import tensorflow as tf\r\n\r\n2019-07-03 07:42:54.607158: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use FMA instructions, but these aren't available on your machine.\r\nAborted (core dumped)\r\n```\r\n**Note: AWS Instance type: g2.2xlarge**\r\n\r\nCan I remove this option \" --copt=-mfma\" and build the bazel again?"]}, {"number": 15848, "title": "*** Error in `python': double free or corruption (out): 0x00007fc5d674d9b0 ***", "body": "I've built the latest version of TensorFlow from github repository with the following commands.\r\n\r\nbazel build -s --config=mkl -c opt --copt=-msse4.1 --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package\r\n\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\npip install /tmp/tensorflow_pkg/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl\r\n\r\nAnd get the following error after the import tensorflow command in python\r\n\r\nPython 3.6.3 |Anaconda custom (64-bit)| (default, Oct 16 2017, 15:28:36) \r\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\nIntel(R) Distribution for Python is brought to you by Intel Corporation.\r\nPlease check out: https://software.intel.com/en-us/python-distribution\r\n>>> import tensorflow as tf\r\n*** Error in `python': double free or corruption (out): 0x00007fc5d674d9b0 ***\r\n\r\nAny suggestions on how to fix this issue?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code\r\n> No, only built and ran the test program.\r\nOS Platform and Distribution\r\n> SLES12\r\nTensorFlow installed from\r\n> github repository\r\nTensorFlow version\r\n> release 1.5.0\r\nBazel version\r\n> 0.9.0\r\nCUDA/cuDNN version\r\n> Not using CUDA\r\nGPU model and memory\r\n> Not using GPU\r\nExact command to reproduce\r\n> import tensorflow as tf\r\n\r\n", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "Do you have a stack trace?\r\n\r\nCC @gunan ", "@tfboyd to redirect the MKL issue to intel.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This issues can be closed. As after updating Python the error went away."]}, {"number": 15846, "title": "tf.losses.sigmoid_cross_entropy", "body": "Hi,\r\nit seems that there is a mistake in the api doc:\r\nlogits: Float [batch_size, num_classes] logits outputs of the network. \r\nhowever it should be:\r\nlogits: Float [batch_size, num_classes] Unscaled log probabilities.\r\nsince it said it is going to \"Creates a cross-entropy loss using tf.nn.sigmoid_cross_entropy_with_logits\"", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@drpngx Is the 'logits' argument not actually logits? ", "I think it's fine in that case since the labels are binary. it's individual log odds ratios.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "This is very confusing. What does the loss function want?"]}, {"number": 15845, "title": "Support RNNs and LSTMs", "body": "Feature Request for TF Lite - support for the following:\r\ntd_split\r\ntf_pad (Padding is something that an RNN needs de-facto unless tensorflow RNNs accept lists of variously shaped tensors.)\r\ntf_gather\r\ntf_slice\r\nLSTM Cells\r\nDynamic RNNs\r\nAre there alternatives to the above in TF Lite?\r\n\r\nHave I written custom code - No\r\nOS Platform and Distribution - Android\r\nTensorFlow installed from - https://github.com/tensorflow\r\nTensorFlow version - 1.4\r\nBazel version - 0.5.4\r\nCUDA/cuDNN version - NA\r\nGPU model and memory - Na\r\nExact command to reproduce - NA\r\n\r\n\r\n\r\n\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Updated.\n\n--\nShradha\n\nOn Fri, Jan 5, 2018 at 12:40 AM, Alfred <notifications@github.com> wrote:\n\n> Thank you for your post. We noticed you have not filled out the following\n> field in the issue template. Could you update them if they are relevant in\n> your case, or leave them as N/A? Thanks.\n> Have I written custom code\n> OS Platform and Distribution\n> TensorFlow installed from\n> TensorFlow version\n> Bazel version\n> CUDA/cuDNN version\n> GPU model and memory\n> Exact command to reproduce\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15845#issuecomment-355369693>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFlnwRqSItA0gRH2t5uO-IG_iRiO_iHdks5tHSIygaJpZM4RS40K>\n> .\n>\n", "@shradhab Thanks! Support for gather and pad will come soon, with split and possibly slice following right after. We do have op for LSTMs and RNNs in the interpreter, but the conversion step still needs some careful work.", "Thanks! Will TF Lite automatically target Qualcomm DSP speed up or will it still require a separate binary?\r\n", "The plan is to have one binary that can work with or without hardware acceleration.", "are there any pretrained RNN/LSTM models in googl's model zoo? I cannot find any google links regarding that matter", "Seems like somebody figured out how to convert a specific LSTM model. I am trying to test, but my computer is taking a while to build toco:\r\nhttps://github.com/tensorflow/tensorflow/issues/15805\r\n\r\nMaybe you guys can also try it", "I was also able to convert the LSTM graph in FLOAT. I just cannot quantize to UINT8 because Unpack operation is not supported by TOCO", "This is so great. Thanks for the answers guys", "Please take a look at the recent example we added for Unidirectional LSTM test case. It may help your use case:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/unidirectional_sequence_lstm_test.py", "Looks like it's a very old issue. we have some RNN/LSTMs support already,\r\n\r\nplease see here for more examples: \r\nhttps://www.tensorflow.org/lite/convert/rnn", "@shradhab \r\nplease update as per above comment,", "Support available "]}, {"number": 15844, "title": "MonitoredTrainingSession aborts without error or exeption", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04.3\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary, pip install\r\n- **TensorFlow version (use command below)**:\r\nv1.4.0-19-ga52c8d9 1.4.1\r\n- **Python version**: \r\nPython 3.6.3 :: Anaconda, Inc.\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\ncuda_8.0.61.2, libcudnn.so.6.0.21\r\n- **GPU model and memory**:\r\nTitan-X, 32GB\r\n- **Exact command to reproduce**:\r\nDuring some training runs, this script just ends after few epochs with printing 'eval done'. It doesn't print any error nor an exception. In other runs, with the same setup in runs through. How could this happen that the for-loop stops even the epochs is smaller than 100?\r\n\r\nEdit: I tried it also without the try-except block around the `MonitoredTrainingSession`, but it was the same: no exception, no error, epoch ~ 15 and printing \"eval done\"\r\n\r\n\r\n```python\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\r\n\r\n    listener_eval = ExampleCheckpointSaverListener(fun_after_save=eval_model)\r\n    listener_generate = ExampleCheckpointSaverListener(fun_after_save=generate)\r\n    hooks_train = [\r\n      tf.train.SummarySaverHook(output_dir=model_path, save_secs=60, scaffold=scaffold_train),\r\n      tf.train.LoggingTensorHook(train_log_tensors, every_n_secs=30),\r\n      tf.train.CheckpointSaverHook(checkpoint_dir=model_path, save_secs=600, scaffold=scaffold_train,\r\n                                   listeners=[listener_eval, listener_generate])\r\n    ]\r\n\r\n    try:\r\n      with tf.train.MonitoredTrainingSession(is_chief=True, checkpoint_dir=model_path, save_checkpoint_secs=None,\r\n                                             hooks=hooks_train, save_summaries_secs=None, save_summaries_steps=None,\r\n                                             config=sess_config, scaffold=scaffold_train, log_step_count_steps=1000, stop_grace_period_secs=20) as sess:\r\n\r\n        for epochs in range(0, 100):\r\n          print(epochs)\r\n          try:\r\n            while True:\r\n              sess.run([train_op])\r\n          except tf.errors.OutOfRangeError as e:\r\n            print(\"Epoch %d end.\" % epochs)\r\n            sess.run(train_reader.iterator.initializer)\r\n    except:\r\n      print(\"MonitoredTrainingSession\")\r\n      print(sys.exc_info())\r\n\r\n    print(\"eval done\")\r\n```\r\n\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/1603159/tf_env.txt)\r\n\r\n\r\n  ", "comments": ["Hello, I think I had a similar Issue today, (see #15847).\r\nBasically, for every call of ```sess.run(train_reader.iterator.initializer)```, the Hooks are also called. Depending on what they do, they can advance the iterator, which fails with an OutOfRangeError when the iterator was fully consumed.\r\n\r\nI suspect one or several Tensor in the train_log_tensors needs data from the iterator and try to fetch an element from it, which then throws an OutOfRangeError and the Session terminates. This may not always happen during the ```sess.run(train_reader.iterator.initializer)``` call, as the LoggingTensorHook only runs every 30 seconds.", "Hey!\r\nThanks a lot for your answer and the helpful information - good catch!\r\nHowever, what I didn't get. If a `OutOfRangeError` occurs, then it should be catched outside of the `with tf.MonitoredTrainingSession(...)` and at least prints that an error occured - or am I wrong and missing something?  ", "The ```tf.MonitoredTrainingSession``` itself checks if an OutOfRangeError occured inside an ```with``` statement and suppresses it. You can check this by simply running the following snippet: \r\n```\r\nwith tf.train.MonitoredTrainingSession() as sess:\r\n    raise tf.errors.OutOfRangeError(None, None, None)\r\n```\r\nIf you raise another error instead of ```tf.errors.OutOfRangeError```, then it is propagated like usual.\r\n\r\nThis is intended behaviour, as the OutOfRangeError signals the end of the training set. \r\n\r\n@tensorflow-team I would suggest displaying an Log-Message instead of just silently ignoring it, as it could point to a potential issue (INFO or maybe DEBUG level would be enough).", "You are totally right. Its even stated in the method header - should have seen that:\r\n\r\n```\r\n  * suppresses `OutOfRange` error which indicates that all inputs have been\r\n    processed if the monitored_session is used as a context\r\n```\r\n\r\nThanks again for pointing out the case with the hook and the empty iterator."]}, {"number": 15843, "title": "WIP: LSTMBlockFusedCell supports Dropout", "body": "Fix #13649.\r\n\r\nThe work has not been done yet. However I'm not sure whether the solution is approved, I mean, using DropoutWrapper for inner implementation. So I open the PR early to collect feedback. cc @ebrevdo.\r\n\r\nI'll add test case later.\r\n  ", "comments": ["Can one of the admins verify this patch?", "I'll close the PR until we really need it."]}, {"number": 15842, "title": "Windows: Disable bfloat16_test and framework_dtypes_test", "body": "Reenable after fixing\r\nhttps://github.com/tensorflow/tensorflow/issues/15297\r\n\r\n@gunan ", "comments": ["http://ci.tensorflow.org/view/TF%20pull%20requests/job/tensorflow-pr-win-bazel/51/console", "@tensorflow-jenkins test this please", "The reported failure is unrelated. Merging."]}, {"number": 15841, "title": "MultiRNNCell with attention cause Dimensions error", "body": "when i use MultiRNNCell  and attention for decoding,it goes to \r\n\r\n> ValueError: Dimensions must be equal, but are 2048 and 3072 for 'read/decode/seq_decode/while/BasicDecoderStep/seq_decode/attention_wrapper/attention_wrapper/multi_rnn_cell/cell_0/cell_0/lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [?,2048], [3072,4096].\r\n\r\nI trace the code,and found it maybe a bug:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/rnn_cell_impl.py:\r\nline:1066 calls to LSTMCell(line:600),its _linear1 is initialization from the first LSTMCELL, and will not initialization from the second LSTMCELL. my first LSTMCELL input is with attention.its shape is (?, emb+attention)\r\nbut,my second LSTMCELL input is without attention because it called in the while loop, which shape is (?, emb).,When second LSTMCELL use _linear1 is initialization from the first LSTMCELL,it goes to this error\r\n\r\n\r\n\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "yes ", "Please edit your original post to include the information requested by the butler above (or if you wish, close this issue and fill out a new one using the issue template, which requests the same information). We need this information to reproduce the problem you're experiencing, among other reasons. Thanks.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing since the issue template is not filled out. Please reopen and fill out the template if you are still encountering the issue."]}, {"number": 15840, "title": "Numerous ::`anonymous namespace':: Linking errors in Tensorflow 1.3.1 Windows build with GPU", "body": "\r\nBuilding with VS 2015 64bit and CUDA 8 and Cudnn v7 (cudnn64_7.dll).\r\n\r\nAll other projects in the solution got built. Even the project pywrap_tensorflow_internal_static got built. But, when building the project pywrap_tensorflow_internal for the dll one, it compiles successfully but gives numerous linking errors as below:\r\n\r\nI also see that (probably) all of them contain the anonymous namespace - ``class tensorflow::`anonymous namespace'::``.\r\n\r\n```\r\n1>pywrap_tensorflow_internal.exp : warning LNK4070: /OUT:_pywrap_tensorflow_internal.pyd directive in .EXP differs from output filename 'D:\\rough\\tensorflow-1.3.1\\tensorflow\\contrib\\cmake\\build\\Release\\pywrap_tensorflow_internal.dll'; ignoring directive\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: void __cdecl tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16>::Initialize<1>(class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int)'::`2'::$TSS0\" (?$TSS0@?1???$Initialize@$00@?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@QEAAXAEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@H@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: void __cdecl tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16>::Initialize<0>(class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int)'::`2'::$TSS0\" (?$TSS0@?1???$Initialize@$0A@@?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@QEAAXAEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@H@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"TSS0<`template-parameter-2',tensorflow::`anonymous namespace'::M::cale_independent_strtonum,cointerface ?? :: ?? ::HA::tensorflow::Z::AMPEBDPEAPEBD>\" (?$TSS0@?1???$locale_independent_strtonum@M@?A0x77a2fbcf@tensorflow@@YAMPEBDPEAPEBD@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"TSS0<`template-parameter-2',tensorflow::`anonymous namespace'::N::cale_independent_strtonum,cointerface ?? :: ?? ::HA::tensorflow::Z::ANPEBDPEAPEBD>\" (?$TSS0@?1???$locale_independent_strtonum@N@?A0x77a2fbcf@tensorflow@@YANPEBDPEAPEBD@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `private: static void __cdecl tensorflow::SparseMatMul<float,float>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<float> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<float> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0\" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@MM@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBM$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `private: static void __cdecl tensorflow::SparseMatMul<float,struct tensorflow::bfloat16>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<float> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<float> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0\" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@MUbfloat16@tensorflow@@@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@M@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,float>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0\" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@M@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBM$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,struct tensorflow::bfloat16>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`2'::$TSS0\" (?$TSS0@?1??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@U12@@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `bool __cdecl tensorflow::`anonymous namespace'::IsGradientNode(class tensorflow::Graph const *,class tensorflow::Node const *)'::`2'::$TSS0\" (?$TSS0@?1??IsGradientNode@?A0xd76da148@tensorflow@@YA_NPEBVGraph@3@PEBVNode@3@@Z@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<signed char>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@C@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<unsigned char>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@E@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<short>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@F@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<int>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@H@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<float>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@M@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<double>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@N@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QInt16>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@UQInt16@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QInt32>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@UQInt32@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QInt8>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@UQInt8@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QUInt16>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@UQUInt16@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::QUInt8>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@UQUInt8@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<struct Eigen::half>::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@Uhalf@Eigen@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"int `public: virtual class tensorflow::gtl::InlinedVector<enum tensorflow::DataType,4> const & __cdecl tensorflow::`anonymous namespace'::DenseToSparseBatchDatasetOp::Dataset<class std::complex<float> >::output_dtypes(void)const '::`2'::$TSS0\" (?$TSS0@?1??output_dtypes@?$Dataset@V?$complex@M@std@@@DenseToSparseBatchDatasetOp@?A0x0fde61d7@tensorflow@@UEBAAEBV?$InlinedVector@W4DataType@tensorflow@@$03@gtl@5@XZ@4HA)\r\n...\r\n...\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"class Eigen::array<int,2> const `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,float>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`26'::zero\" (?zero@?BK@??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@M@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBM$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4V?$array@H$01@7@B)\r\n1>pywrap_tensorflow_internal.exp : error LNK2001: unresolved external symbol \"class Eigen::array<int,2> const `private: static void __cdecl tensorflow::SparseMatMul<struct tensorflow::bfloat16,struct tensorflow::bfloat16>::ComputeOutputBlock(class std::vector<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *,class std::allocator<struct tensorflow::`anonymous namespace'::SparseSlice<struct tensorflow::bfloat16> *> > const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,2,1,__int64>,16,struct Eigen::MakePointer> const &,int,int,int,bool,bool,class Eigen::TensorMap<class Eigen::Tensor<float,2,1,__int64>,16,struct Eigen::MakePointer> *)'::`26'::zero\" (?zero@?BK@??ComputeOutputBlock@?$SparseMatMul@Ubfloat16@tensorflow@@U12@@tensorflow@@CAXAEBV?$vector@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@V?$allocator@PEAU?$SparseSlice@Ubfloat16@tensorflow@@@?A0x20ed32c2@tensorflow@@@std@@@std@@AEBV?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@HHH_N2PEAV?$TensorMap@V?$Tensor@M$01$00_J@Eigen@@$0BA@UMakePointer@2@@7@@Z@4V?$array@H$01@7@B)\r\n1>D:\\rough\\tensorflow-1.3.1\\tensorflow\\contrib\\cmake\\build\\Release\\pywrap_tensorflow_internal.dll : fatal error LNK1120: 1937 unresolved externals\r\n========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========\r\n\r\n```\r\nBy any chance, does anyone know what these errors are hinting towards?\r\n\r\nThanks in advance.\r\n\r\n\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler: This was regarding the build process from sources only. I cannot edit the previous post as I had deleted that account unfortunately.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 7 64bit\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.1\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: Visual Studio 2015.\r\n- **CUDA/cuDNN version**: 8.0/7\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Cmake-build\r\n\r\nI used Cmake-gui with GPU enabled and all other default-set e.g. gRPC enabled, etc.\r\n \r\nI found that my problem was in the VS project \"**pywrap_tensorflow_internal**\".  When I was building this particular project, there was a \"**pywrap_tensorflow_internal.def**\" definition file (which I didn't notice from where it was created) in the 'cmake-build' folder that was being used to generate the DLL file \"**pywrap_tensorflow_internal.dll**\".  However, it seemed to me that there were these extra (maybe erroneous) function names in the .def file that were actually not present in the intermediate \".lib\" file generated by this project. And thus the above unresolved linking errors.\r\n\r\nWhat I later went on doing is the following:\r\n-  I simply deleted this definition file \"**pywrap_tensorflow_internal.def**\"  and also removed from the VS project configuration that was originally present as \r\n```\r\n<Link>\r\n<ModuleDefinitionFile>\r\npath/tensorflow-1.3.1/tensorflow/contrib/cmake/build/pywrap_tensorflow.def\r\n</ModuleDefinitionFile>\r\n</Link>.\r\n```\r\n\r\n(Had I known how this  .def was generated, I would have regenerated it and tested without this manual modification of the project configuration.)\r\n\r\nHowever, after this only, it successfully exported the functions into the final DLL file \"**pywrap_tensorflow_internal.dll**\". \r\n\r\n  \r\n  ", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I'm guessing this occurred when you tried to build that library in a directory that contained artifacts from a previous build, perhaps based on a different version of the source.\r\n\r\nWe only maintain the CMake build in a state where it can build from a clean repository (as part of the CI and release processes), and this is intended to be a temporary state of affairs until we can switch to using Bazel. I'd recommend cleaning out your build directory before each build, to avoid this kind of issue.\r\n\r\nWe'd welcome contributions to improve the CMake build so that it doesn't fail in other scenarios, which I expect would involve changes to this part of the build script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/926fc13f7378d14fa7980963c4fe774e5922e336/tensorflow/contrib/cmake/tf_python.cmake#L544-L557\r\n\r\n/cc @guschmue in case you have an idea about how to regenerate the `.def` file at the appropriate time, or know another workaround for this problem.\r\n/cc @ewilderj FYI, another CMake issue that might be relevant to the tf-distribute SIG.", "Contrib has been deprecated please refer to tensorflow/addons for latest updates. "]}, {"number": 15839, "title": "Problem in \"/tensorflow/examples\" project to build an android app", "body": "## As we know, there will build three APP and one TF speech app in the 'tensorflow/examples'. \r\n## But, I just want to use the  detectorActivity to build an app, aim at to use this app to do a porject named 'Image Recognition'.\r\n##  So I need to delete three other java file like ClassifierActivity\u3001StylizeActivity\u3001SpeechActvity and so on, and download the model that detectorActivity need. like this\r\n\r\n![1](https://user-images.githubusercontent.com/33651882/34554975-6605fa0e-f16a-11e7-889a-418d99ac1498.png)\r\n\r\n## But, when I choose to build apk, there was a problem that \"Execution failed for task: downloadFile  org.apache.http.conn.ConnectTineoutException:.......\" \r\n## I use the windows and android studio to build this project. \r\n#  **Is anyone can help me to separate this example just retain the  detectorActivity  and use our's model in android:assets , to help me build an app to do 'Image Recognition' Project. Thx every friends**\r\n  \r\n  \r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 15838, "title": "Gif can't be decoded. InvalidArgumentError: Invalid GIF data", "body": "## System information\r\n**Have I written custom code : yes\r\nOS Platform and Distribution : Mac OS 10.12.3\r\nTensorFlow installed from : pip3\r\nTensorFlow version : 1.4\r\nBazel version : N/A\r\nCUDA/cuDNN version : N/A\r\nGPU model and memory : N/A**\r\n\r\n## Describe the problem\r\n![0071qvrrgy1fn3h6v55gag308w0adx6p](https://user-images.githubusercontent.com/8256827/34550343-04b28b42-f14b-11e7-9b8a-729a82ba4742.gif)\r\n\r\nThe gif can be decoded by PIL,but the error occurred when I used tf.image.decode_gif to decode.\r\n\r\n```\r\ndef load_gif(image_path, sess):\r\n    image = tf.read_file(image_path)\r\n    image = tf.image.decode_gif(image)\r\n    return sess.run(image)\r\n\r\nload_gif('0071Qvrrgy1fn3h6v55gag308w0adx6p',sess))\r\n```\r\n\r\nThe error is:\r\n```\r\nNotFoundError                             Traceback (most recent call last)\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1322     try:\r\n-> 1323       return fn(*args)\r\n   1324     except errors.OpError as e:\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1301                                    feed_dict, fetch_list, target_list,\r\n-> 1302                                    status, run_metadata)\r\n   1303 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    472             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 473             c_api.TF_GetCode(self.status.status))\r\n    474     # Delete the underlying status object from memory otherwise it stays alive\r\n\r\nNotFoundError: /Users/chunchang/Downloads/0071Qvrrgy1fn3h6v55gag308w0adx6p; No such file or directory\r\n\t [[Node: ReadFile_21 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile_21/filename)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-70-7b1d3fa2f712> in <module>()\r\n      1 print(load_gif('/Users/chunchang/Downloads/0071Qvrrgy1fn3h6v55gag308w0adx6p',\r\n----> 2                sess))\r\n\r\n<ipython-input-55-fd8c43263043> in load_gif(image_path, sess)\r\n      3     # image = tf.image.decode_png(image, channels=3)\r\n      4     image = tf.image.decode_gif(image)\r\n----> 5     return sess.run(image)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    887     try:\r\n    888       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 889                          run_metadata_ptr)\r\n    890       if run_metadata:\r\n    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1119       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1120                              feed_dict_tensor, options, run_metadata)\r\n   1121     else:\r\n   1122       results = []\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1315     if handle is None:\r\n   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\r\n-> 1317                            options, run_metadata)\r\n   1318     else:\r\n   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1334         except KeyError:\r\n   1335           pass\r\n-> 1336       raise type(e)(node_def, op, message)\r\n   1337 \r\n   1338   def _extend_graph(self):\r\n\r\nNotFoundError: /Users/chunchang/Downloads/0071Qvrrgy1fn3h6v55gag308w0adx6p; No such file or directory\r\n\t [[Node: ReadFile_21 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile_21/filename)]]\r\n\r\nCaused by op 'ReadFile_21', defined at:\r\n  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-70-7b1d3fa2f712>\", line 2, in <module>\r\n    sess))\r\n  File \"<ipython-input-55-fd8c43263043>\", line 2, in load_gif\r\n    image = tf.read_file(image_path)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 376, in read_file\r\n    \"ReadFile\", filename=filename, name=name)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): /Users/chunchang/Downloads/0071Qvrrgy1fn3h6v55gag308w0adx6p; No such file or directory\r\n\t [[Node: ReadFile_21 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile_21/filename)]]```\r\n  \r\n  \r\n  \r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@SmartCC Your log is actually misleading. In the title it was specified as `InvalidArgumentError: Invalid GIF data` yet the log shows `NotFoundError: ...No such file or directory`.", "Run through the image, below is the correct output:\r\n```\r\nubuntu@ip-172-28-47-33:~$ python\r\nPython 2.7.12 (default, Nov 20 2017, 18:23:56) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> image_path='test.gif'\r\n>>> image = tf.read_file(image_path)\r\n>>> image = tf.image.decode_gif(image)\r\n>>> tf.Session().run(image)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid GIF data, size 2091369\r\n\t [[Node: DecodeGif = DecodeGif[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile)]]\r\n\r\nCaused by op u'DecodeGif', defined at:\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 551, in decode_gif\r\n    \"DecodeGif\", contents=contents, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3176, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1617, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Invalid GIF data, size 2091369\r\n\t [[Node: DecodeGif = DecodeGif[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReadFile)]]\r\n\r\n>>> \r\n```", "With log enabled, here is the actual issue:\r\n```\r\n2018-01-14 17:59:43.561411: E tensorflow/core/lib/gif/gif_io.cc:86] Can't process optimized gif.\r\n2018-01-14 17:59:43.642173: E tensorflow/core/lib/gif/gif_io.cc:86] Can't process optimized gif.\r\n```\r\n\r\nI think it make sense to at least propagate the error message to the exception information. Created a PR #16113 so that `can't process optimized gif` shows up in the exception thrown.", "@SmartCC I created a PR #16804 which should be able to process the gif file you posted. Please take a look if interested."]}, {"number": 15837, "title": "occurs error to convert from pb to tflite file format", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:  v1.4.0\r\n- **Python version**: 3.4\r\n- **Bazel version (if compiling from source)**:  0.5.4\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\nbazel build -c opt --copt=-msse4.1 --copt=-msse4.2 tensorflow/contrib/lite/toco:toco\r\nbazel-bin/tensorflow/contrib/lite/toco/toco  \\\r\n  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\r\n  --input_file=/home/yh/tttt/aaa.pb \\\r\n  --output_file=/home/yh/tttt/aaa.lite \\\r\n  --inference_type=FLOAT \\\r\n  --input_type=FLOAT \\\r\n  --input_arrays=input \\\r\n  --output_arrays=MobilenetV1/Predictions/ArgMax_2 \\\r\n  --input_shapes=1,64,64,3\r\n\r\n### Describe the problem\r\n\r\ncurrent tensorflow lite couldn't support below operation?\r\nIf we use below operation, how can I do something?\r\nHere is the warning and error message I got :\r\n### Source code / logs\r\n2018-01-04 16:04:35.910769: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.910856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.910902: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.910928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.910971: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911011: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911035: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911066: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911089: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911129: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911165: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911188: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911260: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911283: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911320: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911355: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911377: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911415: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911450: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911473: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911513: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911547: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911571: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911601: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911624: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911654: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911677: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911707: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911730: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911759: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911781: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911834: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911873: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.911907: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.911931: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.911968: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.912003: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912026: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912063: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.912097: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.912192: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912215: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912252: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.912286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912308: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912337: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912390: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912412: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912442: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912496: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912520: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912550: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912572: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912602: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912625: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912655: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912678: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912708: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912730: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912760: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912782: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912812: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912837: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912867: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912919: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912943: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.912973: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.912996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913026: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913050: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913080: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913102: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913184: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913218: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913258: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913282: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913312: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913365: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913388: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913418: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913441: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913471: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913494: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913525: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913547: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913577: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913630: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913653: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913682: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913705: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913734: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913757: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913786: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913808: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913838: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913861: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913913: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913942: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.913965: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.913994: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914016: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914097: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914183: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914209: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914238: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914260: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914289: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914310: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914360: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914408: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914457: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Pow\r\n2018-01-04 16:04:35.914500: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914523: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914557: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914580: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914695: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914721: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914754: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914778: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914812: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914835: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914864: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914885: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.914966: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.914993: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915026: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915049: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915078: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915099: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915127: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915149: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915274: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915297: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915326: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915347: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915376: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915397: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915472: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915498: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915528: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915549: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915578: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915599: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915627: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915649: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915745: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915774: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915795: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915823: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915845: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915873: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915895: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.915971: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.915998: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916027: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916049: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916098: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916126: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916147: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916217: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916243: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916271: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916292: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916320: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916342: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916391: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916524: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916545: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916573: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916594: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916622: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916644: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916713: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916768: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916790: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916817: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916839: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916866: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916888: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.916964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.916991: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917019: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917041: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917089: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917117: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917138: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917234: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917263: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917288: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917317: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917338: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917366: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917463: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomUniform\r\n2018-01-04 16:04:35.917497: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917547: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.917568: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917702: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: SoftmaxCrossEntropyWithLogits\r\n2018-01-04 16:04:35.917801: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: SaveV2\r\n2018-01-04 16:04:35.917850: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.917873: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917901: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.917922: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917949: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.917971: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.917998: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918019: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918067: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918094: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918115: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918152: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918175: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918216: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918239: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918269: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918308: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918325: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918346: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918362: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918384: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918399: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918421: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918438: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918477: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918535: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918562: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918583: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918630: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918657: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918678: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918705: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918725: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918752: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918774: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918801: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918821: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918848: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918867: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918895: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918916: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918943: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.918963: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.918990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919010: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919037: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919057: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919084: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919104: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919131: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919151: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919178: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919199: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919246: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919273: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919294: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919321: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919341: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919368: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919388: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919415: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919435: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919461: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919480: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919506: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919527: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919553: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919574: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919647: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919669: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919696: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919743: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919763: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919789: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919809: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919835: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919855: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919882: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919901: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919948: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.919974: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.919996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920042: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920088: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920114: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920135: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920161: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920181: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920228: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920278: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920305: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920326: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920353: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920373: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920400: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920447: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920494: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920516: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920542: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920563: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920589: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920636: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920656: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920682: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920702: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920775: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920796: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920823: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920843: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920938: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.920964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.920984: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921011: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921031: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921057: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921104: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921125: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921152: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921172: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921199: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921246: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921268: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921294: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921341: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921362: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921389: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921410: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921437: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921486: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921507: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921533: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921553: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921580: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921599: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921626: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921647: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921674: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921694: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921720: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921740: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921767: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921787: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921814: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921834: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921862: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921882: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921908: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921929: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.921956: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.921976: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922002: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922049: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922095: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922115: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922187: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922210: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922247: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922264: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922285: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922301: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922322: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922361: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922377: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922398: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922430: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922458: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922478: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922505: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922526: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922553: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922573: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922621: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922648: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922668: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922695: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922715: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922763: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922790: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RestoreV2\r\n2018-01-04 16:04:35.922811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922854: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: VariableV2\r\n2018-01-04 16:04:35.922878: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Assign\r\n2018-01-04 16:04:35.922918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Equal\r\n2018-01-04 16:04:35.922964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: ScalarSummary\r\n2018-01-04 16:04:35.922987: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: ScalarSummary\r\n2018-01-04 16:04:35.923009: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: ScalarSummary\r\n2018-01-04 16:04:35.923028: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: MergeSummary\r\n2018-01-04 16:04:35.923082: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Prod\r\n2018-01-04 16:04:35.923107: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: Prod\r\n2018-01-04 16:04:35.923150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: ZerosLike\r\n2018-01-04 16:04:35.923209: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: BiasAddGrad\r\n2018-01-04 16:04:35.923248: F tensorflow/contrib/lite/toco/import_tensorflow.cc:924] Check failed: GetBoolAttr(node, \"transpose_b\") == false (1 vs. 0)\r\nAborted (core dumped)\r\n\r\n", "comments": []}, {"number": 15836, "title": "Add axis support for `tf.nn.crelu`", "body": "This fix tries to address the issue raised in #15619 where it was not possible to specify an `axis` for\r\n`tf.nn.crelu`. By default, `axis=-1` was used for concatenation implicitly.\r\n\r\nThis fix adds the support of `axis` for `tf.nn.crelu`, and adds test cases for it.\r\n\r\nThis fix fixes #15619.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Add @martinwicke for API change review.", "@caisq Thanks for the review. The PR has been updated.", "By the way, there are quite some failures on Jenkins due to:\r\n```\r\ndocker: Error response from daemon: devmapper: Thin Pool has 981366 free data blocks which is less than minimum required 983040 free data blocks. Create more free space in thin pool or use dm.min_free_space option to change behavior.\r\n```\r\n\r\nI don't know enough about the infrastructure platform of TensorFlow for Jenkins servers, though I would suggest to take a look at overlay2 storage driver (vs.  devmapper). \r\n\r\nThe overlay2 is considered as mature as of now. On most of the Linux platforms it probably would be better performant than devmapper.\r\n\r\nThere might be issues with REHL 7's SELinux for overlay2 but that may have been fixed as well. For other Linux kernels most likely overlay2 would be better.\r\n\r\nIf the docker version on Jenkins is newer enough then overlay2 probably will be an option to consider.\r\n  ", "Looks good for API change.", "@tensorflow-jenkins test this please", "Thanks @asimshankar @caisq for the review. The Jenkins failed because of the Api changes. As API review already done, I updated golden with\r\n```\r\nbazel-bin/tensorflow/tools/api/tests/api_compatibility_test\r\n           --update_goldens True\r\n```\r\n\r\nand pushed the PR.\r\n\r\nThe Jenkins should pass now.", "@tensorflow-jenkins test this please"]}, {"number": 15835, "title": "When data become large,parition variables can not initialized successfully", "body": "i use tensorflow to distributed trainning models, i use the partition valriables to store an array data, when the data is not so bigger, everything looks ok,but when the array data become larger, when the session initialize, the partition variables can not initialized and the session will wait util time out.\r\n\r\nDescribe the problem\r\n\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. the feat_info can initialize successfully, but the adj_info cannot initialized. the adj_info is larger than feat_info\r\n\r\n i use monitored_session or supervisor to do the initialize_variables, when data is not so large, it will initialize successfully, my machine have more than 300GB memory is enough for the larger variable\r\n\r\nHave I written custom code\r\nyes\r\nOS Platform and Distribution\r\nlinux platform\r\nTensorFlow installed from\r\nN/A\r\nTensorFlow version\r\nr1.4\r\nBazel version\r\nCUDA/cuDNN version\r\nno gpu\r\nGPU model and memory\r\nno gpu\r\nExact command to reproduce\r\nN/A\r\n\r\nSource code / logs\r\n\r\ni use ps_num = 4, worker_num =4 and i also try some other distributed config, like ps_num=1, worker_num=4, the result is the same\r\nsource code:\r\nwith tf.device(tf.train.replica_device_setter(\r\nworker_device=\"/job:worker/task:%d\" % task_id,\r\ncluster=cluster_spec)):\r\n\r\n  feat_info = tf.get_variable(\"feature_info\", (len(id_map),FLAGS.features_column), tf.float32, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))\r\n  adj_info = tf.get_variable(\"adj_info\", (len(id_map),FLAGS.max_degree), tf.int64, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))\r\n \r\n  with tf.device('/job:worker/task:%d' %task_id):\r\n      adj_local = tf.Variable(tf.constant(minibatch.adj, dtype=tf.int64), trainable=False, name=\"adj_local\", collections=[tf.GraphKeys.LOCAL_VARIABLES])\r\n      feat_local = tf.Variable(tf.constant(features, dtype=tf.float32), trainable=False, name=\"feat_local\", collections=[tf.GraphKeys.LOCAL_VARIABLES])\r\n \r\n  length, begin, end = split_node_by_task(len(id_map), task_id, num_workers)\r\n  adj = tf.nn.embedding_lookup(adj_info, [x for x in range(begin, end)])\r\n  adj = adj_local\r\n  \r\n  feat = tf.nn.embedding_lookup(feat_info, [x for x in range(begin, end)])\r\n  feat = feat_local\r\nlog:\r\n2017-12-08 23:54:17.377290: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session c2b3ba9b700261ba with config:\r\nINFO:tensorflow:Waiting for model to be ready. Ready_for_local_init_op: None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15\r\n2017-12-09 00:00:35.637019: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session f35fcf332e3908ec with config:\r\nINFO:tensorflow:Waiting for model to be ready. Ready_for_local_init_op: None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15\r\nand it will alway waiting adj_info to initialize", "comments": ["@mrry, I'm hestitating to just refer to Stack Overflow because this seems pretty specific. Do you have any advice to offer?", "There's nothing obviously wrong in the code, but there a lot of unbound values. We'd need a self-contained reproduction to be able to investigate further. ", "@mrry  these proble bother me long time, so please help me to solve it", "@weidong8405347 please give a (ideally short) self-contained code sample that we can run to reproduce the problem.", "    with tf.device(tf.train.replica_device_setter(\r\n        worker_device=\"/job:worker/task:%d\" % task_id,\r\n        cluster=cluster_spec)):\r\n       \r\n      feat_info = tf.get_variable(\"feature_info\", (len(id_map),FLAGS.features_column), tf.float32, trainable=False, partitioner=tf.                                    \r\nfixed_size_partitioner(num_workers * 100))\r\n      adj_info = tf.get_variable(\"adj_info\", (len(id_map),FLAGS.max_degree), tf.int64, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers * 100))\r\n       \r\n      with tf.device('/job:worker/task:%d' %task_id):\r\n          adj_local = tf.Variable(tf.constant(minibatch.adj, dtype=tf.int64), trainable=False, name=\"adj_local\", collections=[tf.GraphKeys.LOCAL_VARIABLES])\r\n          feat_local = tf.Variable(tf.constant(features, dtype=tf.float32), trainable=False, name=\"feat_local\", collections=[tf.GraphKeys.LOCAL_VARIABLES])\r\n       \r\n      length, begin, end = split_node_by_task(len(id_map), task_id, num_workers)\r\n      adj = tf.nn.embedding_lookup(adj_info, [x for x in range(begin, end)])\r\n      adj = adj_local\r\n       \r\n      feat = tf.nn.embedding_lookup(feat_info, [x for x in range(begin, end)])\r\n      feat = feat_local            \r\n      grads_and_vars = model.optimizer.compute_gradients(model.loss)\r\n      clipped_grads_and_vars = [(tf.clip_by_value(grad, -5.0, 5.0) if grad is not None else None, var)\r\n                                for grad, var in grads_and_vars]\r\n      rep_op = tf.train.SyncReplicasOptimizer(model.optimizer,\r\n                                              replicas_to_aggregate=num_workers,\r\n                                              total_num_replicas=num_workers,\r\n                                              use_locking=True)\r\n      tf.logging.info('[%s] Build train op ...' % datetime.now())\r\n      summaries = tf.get_collection(tf.GraphKeys.SUMMARIES)\r\n                             \r\n      apply_gradient_op = rep_op.apply_gradients(clipped_grads_and_vars, global_step=global_step)                                                                      \r\n      init_token_op = rep_op.get_init_tokens_op()\r\n      chief_queue_runner = rep_op.get_chief_queue_runner()\r\n                             \r\n      saver = tf.train.Saver(max_to_keep=FLAGS.max_to_keep)\r\n                             \r\n      summary_op = tf.summary.merge(summaries)\r\n      init_op = tf.global_variables_initializer()\r\n      local_init_op = tf.local_variables_initializer()\r\n      table_op = tf.tables_initializer()\r\n      merge_op = tf.group(init_op, table_op)\r\n    tf.logging.info('[%s] Build Supervisor ...' % datetime.now())\r\n    sv = tf.train.Supervisor(is_chief=is_chief,\r\n                             logdir=FLAGS.checkpoint,\r\n                             init_op=merge_op,\r\n                             local_init_op=local_init_op,\r\n                             summary_op=None,\r\n                             saver=saver,\r\n                             global_step=global_step,\r\n                             recovery_wait_secs=FLAGS.recovery_wait_secs,\r\n                             save_summaries_secs=None,\r\n                             save_model_secs=None)                                                                                                                     \r\n                              \r\n    sess_config = tf.ConfigProto(\r\n        allow_soft_placement=False,\r\n        log_device_placement=FLAGS.log_device_placement)\r\n    if is_chief:              \r\n        tf.logging.info('[%s] Worker %d, Initialize session...' %\r\n                        (datetime.now(), task_id))\r\n    else:                     \r\n        tf.logging.info('[%s] Worker %d, Wait for session to be initialized..' %\r\n                        (datetime.now(), task_id))\r\n                              \r\n    with sv.prepare_or_wait_for_session(target, config=sess_config, max_wait_secs=FLAGS.max_wait_secs) as sess:", "@weidong8405347, the example is not completely self contained, since you have some unset variables like `cluster_spec`. Can you give a self-contained example?", "I meet the same problem, when variable is large and in distribution environment.  chief worker can't initializer the large variable correctly, so i guess it is bug!\r\nthe large variable i define is:\r\n```\r\n### problem code\r\nw0 = tf.get_variable('w_0', dtype=dtype, initializer=tf.random_uniform([100000, 256, 32], minval=minval, maxval=maxval, dtype=dtype)) \r\n\r\n### correct code \uff08 just smaller first dimention size\uff09\r\nw0 = tf.get_variable('w_0', dtype=dtype, initializer=tf.random_uniform([30000, 256, 32], minval=minval, maxval=maxval, dtype=dtype)) \r\n```\r\nI use tf.estimator.train_and_evaluate api to do distributed training, and define w0 in the model_fn.  when i define w0 using[100000, 256, 32]  , I can run the code in the single machine( local mode) correctly, but Error \uff1a\r\n```\r\n### in chief\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n2018-03-02 12:53:31.539989: I tensorflow/core/distributed_runtime/master_session.cc:1017] Start master session 001a93d5f7256838 with config: device_count { key: \"GPU\" value: 0 }\r\n[[[[  blocked here ]]]]]\r\n\r\n### in worker 0\r\nINFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: w_0, ready: None\r\n```\r\nwhen i only change w0 from [100000, 256, 32] to [30000, 256, 32], I can run the code correctly both in local mode and distribution mode. So large variable can't initialize correctly in distribution mode", "still a bug", " @weidong8405347 is this still a problem? apologize for delayed response here.", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I ran Tensorflow Object Detection project with fasterrcnn_resnet50 on distributed training. All I modified is to add a convLSTM layer after feature extractor.\r\nRecently I want to run on distributed machines through legacy/train.py, and I faced same problem like this issue.\r\n\r\nMy cluster spec is as below:\r\n```\r\n{\r\n  \"cluster\": {\r\n    \"ps\": [\r\n      \"localhost:3000\"\r\n    ],\r\n    \"master\": [\r\n      \"localhost:3001\"\r\n    ],\r\n    \"worker\": [\r\n      \"localhost:3002\"\r\n    ]\r\n  },\r\n  \"task\": {\r\n    \"type\": \"ps/master/worker\", \r\n    \"index\": 0\r\n  }\r\n}\r\n``` \r\n\r\nFor **ps** machine, I set task.type in cluster spec as **ps**, and it runs well.\r\nFor **master** machine, I set task.type in cluster spec as **master**, and it runs well too.\r\nIt starts training since the default setting of synchronize training in config file is false.\r\n\r\nHowever, for **worker** machine, I set task.type as **worker**, and it repeatedly shows:\r\n```\r\nINFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: rnn/convlstm_cell/kernel, rnn/convlstm_cell/biases, rnn/convlstm_cell/kernel/Momentum, rnn/convlstm_cell/biases/Momentum\r\n```\r\n\r\nI'm wondering if it's a bug for slim.learning.train / supervisor in legacy/trainer.py or not,\r\nshould I change to MonitoredTrainingSession ?", "meet the same problem too", "Hi i meet the same problem with tf1.12 CPU version on Windows.\r\nWhen create a PartitionedVariable with        \r\n\r\n`\r\nps_count = 5\r\nembeddings = tf.get_variable(\r\n                    \"embeddings\", [term_hash_bucket_size, embedding_count], dtype=tf.float32,\r\n                    initializer=variable_initializer, partitioner=tf.fixed_size_partitioner(ps_count))\r\n`\r\n\r\nit will cost 20mins for sees.run(tf.global_variable_initializer())\r\nWhen the ps_count=20, it will cost more than 80mins.\r\n\r\n\r\n "]}, {"number": 15834, "title": "I think some bug in  tf.contrib.layers.l2_regularizer", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10\r\n- **TensorFlow installed from (source or binary)**:install\r\n- **TensorFlow version (use command below)**:1.5\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nwhen I call the  tf.contrib.layers.l2_regularizer(0.5)(w), I was toll that \"Expected int64, got 0.5 of type 'float' instead.\" But the doc says that it need a float clearly and as a weight it can't be an integer.\r\n\r\n### Source code / logs\r\n` l2 = 0\r\nfor w in tf.global_variables():\r\n    l2 += tf.contrib.layers.l2_regularizer(0.5)(w)\r\nloss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels,logits=result_vector)+l2`\r\n\r\n  ", "comments": ["Your variables have int64 type."]}]