[{"number": 36313, "title": "make_tensor_proto for float16 ndarray", "body": "make_tensor_proto works too slow for float16 arrays because dtypes.float16 not in [_TENSOR_CONTENT_TYPES](https://github.com/tensorflow/tensorflow/blob/339b76d4f1e420d070559051403c71c185df1d57/tensorflow/python/framework/tensor_util.py#L237) list. Is there any reason not to add it to the list?\r\n```\r\nIn [58]: a = np.ones((7, 400, 400, 12), dtype=np.float16)\r\n\r\nIn [59]: b = np.ones((7, 400, 400, 12), dtype=np.float32)\r\n\r\nIn [60]: %timeit make_tensor_proto(a)\r\n1 loop, best of 3: 1.68 s per loop\r\n\r\nIn [61]: %timeit make_tensor_proto(b)\r\n10 loops, best of 3: 106 ms per loop\r\n```", "comments": ["I understood that it also requires some changes in Tensor::FromProto"]}, {"number": 36312, "title": "Update README.md", "body": "fix an incomplete sentence.", "comments": []}, {"number": 36311, "title": "Why tflite model runs on GPU, and multi batch speed is very slow", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@rzyangKyle \r\n\r\nWill it be possible to share the related code to reproduce the issue in our environment. It helps us in localizing the issue faster.Please, fill the issue template. Thanks!", "> @rzyangKyle\r\n> \r\n> Will it be possible to share the related code to reproduce the issue in our environment. It helps us in localizing the issue faster.Please, fill the issue template. Thanks!\r\n\r\nI run the model to compare single batch and multiple batches, but multiple batches are not accelerated because there is no parallel computing\uff1f", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 36310, "title": "Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, ...) Internal: invalid configuration argument when using the tf.keras MaxPooling3D layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I have written my own model training script.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 19.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): From binary (pip)\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de (2.1.0)\r\n- Python version: 3.7.5 (pip version 20.0.2)\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: CUDA V10.1.243 (10.1), cuDNN 7.6.5.32-1+cuda10.1\r\n- GPU model and memory: 2x Nvidia GeForce GTX 1070 Ti (8GB VRAM each)\r\n\r\n**Describe the current behavior**\r\nWhen using tensorflow's `tensorflow.distribute.MirrorStrategy` to scale a `tf.keras`-based model with the `tf.keras.layers.MaxPooling3D` layer, tensorflow outputs the error: \r\n`2020-01-29 13:14:07.089464: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument`, followed by `Aborted (core dumped)` when trying to train the model.\r\nI was able to verify that the MaxPooling3D layer appears to be the issue, because when taking it out of the test script (see \"Code to reproduce the issue\"), the issue does not persist.\r\nThe same issue also occurs when using the, now deprecated, `tf.keras.utils.multi_gpu_model`.\r\nI am yet unsure whether this is a problem in tensorflow itself or any of the used frameworks.\r\nPlease note, that this issue is most likely not related to #30665 or #33696 since they describe an issue related to the internal CUDA kernel `FillPhiloxRandomKernelLaunch<Distribution>` rather than the `SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>` described here.\r\nI am happy to provide further, more specific information on the used training script or the issue itself, if requested.\r\n\r\n**Describe the expected behavior**\r\nThe model should train normally and not output any errors, as it does when executed without the distributed scope or when reducing the MirroredStrategy to only use one GPU.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nfrom tensorflow.keras.models import *\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras import *\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nstrat = tf.distribute.MirroredStrategy(devices=['/gpu:0', '/gpu:1'])\r\n\r\nwith strat.scope():\r\n    model = Sequential()\r\n    model.add(MaxPooling3D((1, 2, 2), input_shape=(None, 640, 480, 1)))\r\n    model.add(ConvLSTM2D(16, kernel_size=(3,3)))\r\n    model.add(Flatten())\r\n    model.add(Dense(1))\r\n    model.summary()\r\n    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\r\n\r\n    x = np.random.rand(1, 10, 640, 480, 1)\r\n    y = np.random.rand(1, 1)\r\n    model.fit(x=x, y=y, epochs=10)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nFull console output:\r\n```\r\n(venv) [REDACTED]@[REDACTED]:[REDACTED]$ python test.py\r\n2020-01-29 13:32:31.798280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-01-29 13:32:31.799195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2020-01-29 13:32:32.130276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-01-29 13:32:32.168392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.168824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1\r\ncoreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.91GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-01-29 13:32:32.168866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.169410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1\r\ncoreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-01-29 13:32:32.169467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-01-29 13:32:32.169549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-01-29 13:32:32.170673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-01-29 13:32:32.170902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-01-29 13:32:32.171948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-01-29 13:32:32.172544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-01-29 13:32:32.172565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-01-29 13:32:32.172641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.172988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.173522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.173857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.174368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2020-01-29 13:32:32.174654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-01-29 13:32:32.198716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz\r\n2020-01-29 13:32:32.199091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47afc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-01-29 13:32:32.199105: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-01-29 13:32:32.293103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.303707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.304142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4845b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-01-29 13:32:32.304154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1\r\n2020-01-29 13:32:32.304159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1\r\n2020-01-29 13:32:32.304924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.305196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1\r\ncoreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.91GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-01-29 13:32:32.305233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.305503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1\r\ncoreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-01-29 13:32:32.305520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-01-29 13:32:32.305527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-01-29 13:32:32.305535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-01-29 13:32:32.305543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-01-29 13:32:32.305551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-01-29 13:32:32.305558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-01-29 13:32:32.305565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-01-29 13:32:32.305593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.305872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.306159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.306438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.306747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2020-01-29 13:32:32.306766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-01-29 13:32:32.546439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-29 13:32:32.546463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 \r\n2020-01-29 13:32:32.546468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y \r\n2020-01-29 13:32:32.546471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N \r\n2020-01-29 13:32:32.546636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.546935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.547217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.547478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6807 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-01-29 13:32:32.547823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-29 13:32:32.548093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7562 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nmax_pooling3d (MaxPooling3D) (None, None, 320, 240, 1) 0         \r\n_________________________________________________________________\r\nconv_lst_m2d (ConvLSTM2D)    (None, 318, 238, 16)      9856      \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 1210944)           0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 1)                 1210945   \r\n=================================================================\r\nTotal params: 1,220,801\r\nTrainable params: 1,220,801\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nTrain on 1 samples\r\nEpoch 1/10\r\n2020-01-29 13:32:35.394061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-01-29 13:32:35.638536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-01-29 13:32:35.639247: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument\r\nAborted (core dumped)\r\n```\r\n\r\nLast few lines of output with the `TF_CPP_MIN_VLOG_LEVEL=2` environment variable set:\r\n```\r\n2020-01-29 13:42:39.018679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/Cast op Cast on GPU 1 stream[0]\r\n2020-01-29 13:42:39.018689: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: \"replica_1/Cast\" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } dim { size: 640 } dim { size: 480 } dim { size: 1 } } } }\r\n2020-01-29 13:42:39.018696: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 167 step -6348371833153678773 {{node replica_1/Cast}} = Cast[DstT=DT_FLOAT, SrcT=DT_DOUBLE, Truncate=false, _XlaHasReferenceVars=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](cond_3/output/_37) device: /job:localhost/replica:0/task:0/device:GPU:1\r\n2020-01-29 13:42:39.018703: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 168 step -6348371833153678773 {{node replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze}} = Squeeze[T=DT_FLOAT, _XlaHasReferenceVars=false, squeeze_dims=[-1], _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](replica_1/metrics/acc/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1\r\n2020-01-29 13:42:39.018709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze op Squeeze on GPU 1 stream[0]\r\n2020-01-29 13:42:39.018720: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: \"replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze\" tensor { dtype: DT_FLOAT shape { dim { } } } }\r\n2020-01-29 13:42:39.018726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze op Squeeze on GPU 1 stream[0]\r\n2020-01-29 13:42:39.018734: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: \"replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze\" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } } } }\r\n2020-01-29 13:42:39.018740: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 168 step -6348371833153678773 {{node replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze}} = Squeeze[T=DT_FLOAT, _XlaHasReferenceVars=false, squeeze_dims=[-1], _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](replica_1/metrics/acc/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1\r\n2020-01-29 13:42:39.018750: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 169 step -6348371833153678773 {{node replica_1/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, _XlaHasReferenceVars=false, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](replica_1/Shape, replica_1/strided_slice/stack, replica_1/strided_slice/stack_1, replica_1/strided_slice/stack_1) device: /job:localhost/replica:0/task:0/device:GPU:1\r\n2020-01-29 13:42:39.018755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/strided_slice op StridedSlice on GPU 1 stream[0]\r\n2020-01-29 13:42:39.018763: I tensorflow/core/common_runtime/bfc_allocator.cc:227] AllocateRaw gpu_host_bfc  4\r\n2020-01-29 13:42:39.018775: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: \"replica_1/strided_slice\" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 256 allocator_name: \"gpu_host_bfc\" allocation_id: 193 has_single_reference: true ptr: 140615866159616 } } }\r\n2020-01-29 13:42:39.018785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/strided_slice op StridedSlice on GPU 1 stream[0]\r\n2020-01-29 13:42:39.018793: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: \"replica_1/strided_slice\" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 256 allocator_name: \"gpu_host_bfc\" allocation_id: 193 has_single_reference: true ptr: 140615866159616 } } }\r\n2020-01-29 13:42:39.018801: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 169 step -6348371833153678773 {{node replica_1/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, _XlaHasReferenceVars=false, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](replica_1/Shape, replica_1/strided_slice/stack, replica_1/strided_slice/stack_1, replica_1/strided_slice/stack_1) device: /job:localhost/replica:0/task:0/device:GPU:1\r\n2020-01-29 13:42:39.018808: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 16619 allocator_name: \"cpu\" }\r\n2020-01-29 13:42:39.018819: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 170 step -6348371833153678773 {{node replica_1/sequential/max_pooling3d/MaxPool3D}} = MaxPool3D[T=DT_FLOAT, _XlaHasReferenceVars=false, data_format=\"NDHWC\", ksize=[1, 1, 2, 2, 1], padding=\"VALID\", strides=[1, 1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](replica_1/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1\r\n2020-01-29 13:42:39.018824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/sequential/max_pooling3d/MaxPool3D op MaxPool3D on GPU 1 stream[0]\r\n2020-01-29 13:42:39.018838: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: \"replica_1/sequential/max_pooling3d/MaxPool3D\" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } dim { size: 320 } dim { size: 240 } dim { size: 1 } } } }\r\n2020-01-29 13:42:39.018849: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: \"replica_1/sequential/max_pooling3d/MaxPool3D\" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 1 } dim { size: 10 } dim { size: 640 } dim { size: 480 } } } }\r\n2020-01-29 13:42:39.018862: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument\r\nAborted (core dumped)\r\n```", "comments": ["After a bit more testing, I came to the conclusion that the issue only occurs when using the `MaxPooling3D` layer as the input layer of the model. Is this expected behaviour? If so, why does the model work as a single-GPU model?\r\nAfter placing the layer behind the `ConvLSTM2D` layers of my model, the issue has disappeared, however now it seems like tensorflow is only using the compute capabilities of one of my graphics cards, even with the distributed strategy, since nvidia-smi shows full memory usage on both cards, increased wattage on both cards, but only increased activity on one card, much like in [this Stackexchange post](https://datascience.stackexchange.com/questions/63609/tensorflow-mirroredstrategy-looks-like-it-may-only-be-working-on-one-gpu). I cannot confirm that the issues are related, though.\r\n", "@lennyerik it looks like your data contains 1 sample and you don't specify a batch size which causes this error. We should be handling this use case and I still need to identify the root case. In the meantime you can increase the number of input samples which should work (i tried number of samples= 2, 3). ", "Thank you for attending to this issue and providing me with a working solution!\r\nI am looking forward to seeing a fix for this specific issue in the future.", "In case anyone else is going crazy because of the `GpuLaunchKernel(...) status: Internal: invalid configuration argumnent` error, please note that this may also occur if the batch size you use is such that there will be an odd batch with a single record, in my case, the error occurred with the following numbers, when distributed across 4 GPUs:\r\n\r\n```python\r\n# Assuming `ds` has 89 records in total\r\nnum_records = 89\r\nbatch_size = 8\r\nds = ds.batch(batch_size).repeat().cache().prefetch(tf.data.experimental.AUTOTUNE) # i.e., 11 batches of 8 records, and 1 batch of 1 record\r\nstep_size = math.ceil(num_records / batch_size) # i.e., 12\r\n...\r\nmodel.fit(\r\n  ds,\r\n  steps_per_epoch=step_size,\r\n  # other arguments\r\n  )\r\n```\r\n\r\nTo fix the issue, change your batch size such that there won't be an odd batch with a single record.", "Thank you @YongJieYongJie , also see this solution: https://stackoverflow.com/a/59971264/2468587, make sure the total number of data can be divided by the batch_size.", "Thanks @YongJieYongJie, that worked for me ! As suggestion, you can set the option `tf.data.Dataset.batch(batch_size, drop_remainder=True)`  and you don't have to take care about whether your last batch is an odd batch or not.", "This problem seems only happens when using multiple GPUs training. For single GPU training, even the number of samples is NOT divisible by batch_size, NO such error will be raised. Hence this may be a bug.\r\n\r\nThe solution proposed by @JTorres258 is simple but not suitable for model.predict() since in prediction we are not allowed to drop any samples.\r\nThe solution proposed by @YongJieYongJie is not the best solution since batch_size is a important hyper-parameter that need to be fine-tuned.\r\n\r\nFor training phase, I suggest to use the solution by @JTorres258 , drop few examples will be affect training.\r\nFor predict phase, I suggest to use single GPU only, or use the solution by @YongJieYongJie to set dynamic batch_size since batch_size won't affect prediction.\r\n\r\nBy the way, if you tend to use model.predict() with single GPU right after model.fit() with multiple GPUs in same .py file. You can save the trained model first and then load it back to do prediction.", "I can confirm this problem with two GPUs in mirrored strategy, 6105 records and a batch size of 4, i.e. 1 remaining record for the last step.", "I faced the same issue this week when I migrated from tensorflow 2.1 to 2.3. \r\nIt does not matter the version of my python env. I tried 3.6, 3.7 and 3.8 the result was the same \r\nI don't think the issue is connected to python as other folks suggested. I ran the binary in C the result was the same. \r\nMy assumption is that the new build has some incompatibility with my GPU card and Nvidia tool kit.\r\n\r\nHere you are a couple of outputs from my tests\r\n\r\n===================================================================================\r\n**Error: Non-OK-status: GpuLaunchKernel(BlockReduceKernel**\r\n**C# binding and tensorflow-gpu 2.3.1**\r\nTest: tf.reduce_sum\r\n\r\nD:\\Development\\blazor-ml\\GPUTest\\bin\\Debug\\netcoreapp3.1>GPUTest.exe\r\n2020-10-09 20:41:29.568433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:41:29.634163: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-09 20:41:29.662615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26ce71f4010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-09 20:41:29.662701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-10-09 20:41:29.664614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-10-09 20:41:30.212957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 20:41:30.213137: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:41:30.218036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 20:41:30.222788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 20:41:30.224161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 20:41:30.234935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 20:41:30.237664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 20:41:30.250487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 20:41:30.250741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-09 20:41:30.331397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-09 20:41:30.331557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-10-09 20:41:30.332424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-10-09 20:41:30.333246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-10-09 20:41:30.344382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26cf2de55c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-10-09 20:41:30.344498: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0\r\n2020-10-09 20:41:30.813185: F .\\tensorflow/core/kernels/reduction_gpu_kernels.cu.h:670] Non-OK-status: GpuLaunchKernel(BlockReduceKernel<IN_T, T*, num_threads, Op>, num_blocks, num_threads, 0, cu_stream, in, (T*)temp_storage.flat<int8_t>().data(), in_size, op, init) status: Internal: no kernel image is available for execution on the device\r\n\r\n===================================================================================\r\n**ERROR: Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch**\r\n**Python 3.8 Tensorflow-gpu 2.3.1**\r\nx = Input(shape=(32,))\r\ny = Dense(16, activation='softmax')(x)\r\nmodel1 = Model(x, y)\r\n\r\n\r\n    To access the notebook, open this file in a browser:\r\n        file:///D:/Development/Tensorflow/Model/WPy64-3850/settings/runtime/nbserver-5672-open.html\r\n    Or copy and paste one of these URLs:\r\n        http://localhost:8888/?token=16d7994d801fd8e90e8340fa1fbc47712a74654b1df77f1f\r\n     or http://127.0.0.1:8888/?token=16d7994d801fd8e90e8340fa1fbc47712a74654b1df77f1f\r\n[W 20:51:38.774 NotebookApp] 404 GET /nbextensions/jupyter_tensorboard/tree.js?v=20201009205136 (::1) 11.97ms referer=http://localhost:8888/tree\r\n[W 20:51:38.778 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20201009205136 (::1) 3.02ms referer=http://localhost:8888/tree\r\n[W 20:51:41.012 NotebookApp] Notebook keras_freeze_tf_pb.ipynb is not trusted\r\n[W 20:51:41.060 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20201009205136 (::1) 3.98ms referer=http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb\r\n[W 20:51:41.105 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20201009205136 (::1) 2.04ms referer=http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb\r\n[I 20:51:42.312 NotebookApp] Kernel started: 8cbadda4-3af2-4e8f-bcd4-4d3ba04a3d11, name: python3\r\n2020-10-09 20:51:51.863055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:51:56.427210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-10-09 20:51:56.983650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 20:51:56.983827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:51:56.991328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 20:51:57.011813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 20:51:57.016791: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 20:51:57.038352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 20:51:57.042855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 20:51:57.101006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 20:51:57.101325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-09 20:51:59.525460: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-09 20:51:59.536727: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b5355a73f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-09 20:51:59.536898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-10-09 20:51:59.873720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 20:51:59.873956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:51:59.883568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 20:51:59.884599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 20:51:59.885629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 20:51:59.886257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 20:51:59.886318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 20:51:59.886376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 20:51:59.886493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-09 20:51:59.979884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-09 20:51:59.980110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-10-09 20:51:59.982977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-10-09 20:51:59.983718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-10-09 20:51:59.990807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b538186e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-10-09 20:51:59.991051: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0\r\n2020-10-09 20:52:00.278898: F .\\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device\r\n[I 20:52:12.311 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports\r\nWARNING:root:kernel 8cbadda4-3af2-4e8f-bcd4-4d3ba04a3d11 restarted\r\n\r\n\r\n===================================================================================\r\n**Failed with an error Non-OK-status: GpuLaunchKernel\r\npython 3.7 Tensorflow-gpu 2.3.1**\r\nTest:\r\nx = Input(shape=(32,))\r\ny = Dense(16, activation='softmax')(x)\r\nmodel1 = Model(x, y)\r\n\r\n    Or copy and paste one of these URLs:\r\n        http://localhost:8888/?token=66fb5843df207dd0b557b47408b83906d62d9592f2916484\r\n     or http://127.0.0.1:8888/?token=66fb5843df207dd0b557b47408b83906d62d9592f2916484\r\n[W 21:04:14.850 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20201009210412 (::1) 10.96ms referer=http://localhost:8888/tree\r\n[W 21:04:19.657 NotebookApp] Notebook keras_freeze_tf_pb.ipynb is not trusted\r\n[W 21:04:19.712 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20201009210412 (::1) 5.97ms referer=http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb\r\n[I 21:04:20.873 NotebookApp] Kernel started: 12a69ce5-7a94-40fe-88ae-a8fbe6271ed6, name: python3\r\n[W 21:04:21.279 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20201009210412 (::1) 2.00ms referer=http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb\r\n2020-10-09 21:04:23.113979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 21:04:27.120750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-10-09 21:04:27.662137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 21:04:27.662346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 21:04:27.670493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 21:04:27.689090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 21:04:27.694532: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 21:04:27.717405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 21:04:27.720870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 21:04:27.775674: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 21:04:27.776096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-09 21:04:28.705622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-09 21:04:28.719573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x245c22e0920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-09 21:04:28.719775: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-10-09 21:04:29.052348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 21:04:29.052810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 21:04:29.055798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 21:04:29.061761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 21:04:29.062368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 21:04:29.063025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 21:04:29.063610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 21:04:29.064345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 21:04:29.065137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-09 21:04:29.165120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-09 21:04:29.165332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0\r\n2020-10-09 21:04:29.166904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N\r\n2020-10-09 21:04:29.172752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-10-09 21:04:29.178803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x245c2837720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-10-09 21:04:29.179925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0\r\n2020-10-09 21:04:29.465815: F .\\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device\r\n[I 21:04:38.860 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports\r\n\r\n\r\n===================================================================================\r\n**Test SUCCEEDED**\r\n**python 3.7 Tensorflow-gpu 2.1**\r\nTest:\r\nx = Input(shape=(32,))\r\ny = Dense(16, activation='softmax')(x)\r\nmodel1 = Model(x, y)\r\n\r\n\r\n    To access the notebook, open this file in a browser:\r\n        file:///D:/Development/Tensorflow/Model/WPy64-3771/settings/runtime/nbserver-18700-open.html\r\n    Or copy and paste one of these URLs:\r\n        http://localhost:8888/?token=1dce3844acff60aa0479a92618c3b9935dd49fdde742d900\r\n     or http://127.0.0.1:8888/?token=1dce3844acff60aa0479a92618c3b9935dd49fdde742d900\r\n[W 20:54:22.526 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20201009205419 (::1) 9.83ms referer=http://localhost:8888/tree\r\n[W 20:54:24.928 NotebookApp] Notebook keras_freeze_tf_pb.ipynb is not trusted\r\n[W 20:54:24.983 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20201009205419 (::1) 7.98ms referer=http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb\r\n[I 20:54:26.204 NotebookApp] Kernel started: 4f4a70a5-ed88-4dff-8a60-958fbd5d277c, name: python3\r\n[W 20:54:26.412 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20201009205419 (::1) 2.00ms referer=http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb\r\n2020-10-09 20:54:28.598195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:54:31.123064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-10-09 20:54:31.670977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 20:54:31.671158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:54:31.679963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 20:54:31.700293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 20:54:31.705279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 20:54:31.731012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 20:54:31.734385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 20:54:31.794893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 20:54:31.795184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-10-09 20:54:32.848984: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-10-09 20:54:33.172382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0\r\ncoreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s\r\n2020-10-09 20:54:33.172844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-10-09 20:54:33.175709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 20:54:33.180437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-09 20:54:33.180989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-10-09 20:54:33.181848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-10-09 20:54:33.182635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-10-09 20:54:33.183265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 20:54:33.184016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-10-09 20:54:36.193571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-09 20:54:36.193648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-10-09 20:54:36.194359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-10-09 20:54:36.195110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3033 MB memory) -> physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-10-09 20:56:00.634227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-10-09 20:56:00.917849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-10-09 20:56:01.860562: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\r\nRelying on driver to perform ptx compilation. This message will be only logged once.\r\n\r\n\r\n\r\n", "@lennyerik Closing this issue as of now  since the necessary changes are done. Please feel free to re-open the issue if needed. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36310\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36310\">No</a>\n", "> Closing this issue as of now since the necessary changes are done. Please feel free to re-open the issue if needed. Thanks!\r\n\r\n@saikumarchalla In which commit / release?", "I faced error :  \r\n`F .\\tensorflow/core/kernels/conv_2d_gpu.h:1028] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, kNumThreads, kTileSize, kTileSize, conjugate>, total_tiles_count, kNumThreads, 0, d.stream(), input, input_dims, output) status: Internal: the launch timed out and was terminated` \r\nin the middle of an epoch with TF 2.5.0 (CUDA 11.2.2 and CuDNN 8.1.0), with a `tf.keras.applications.EfficientNetB2`, and single GPU training (but no error with `tf.keras.applications.ResNet50`).  \r\nI did not have this error with same EfficientNetB2 with TF 2.3.2 and CUDA 10.1 and CuDNN 7.6.   \r\n\r\nSo there is certainly a regression that appeared either between TF 2.3.2 and TF 2.5.0 or CUDA 10.1 and CUDA 11.2 or CuDNN 7.6 and CuDNN 8.1, or it is an issue because of the combination of TF/CUDA/CuDNN/EfficientNetB2."]}, {"number": 36309, "title": "test that the full precision model runs on the CPU and GPU, but it takes 800ms to initialize on the GPU, but it only takes a few milliseconds to initialize on the CPU, how should I optimize", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@rzyangKyle,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "> @rzyangKyle,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n\r\nI use mobilenetv2 float model run cpu and gpu by benchmark, you can try it", "> @rzyangKyle,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n\r\ntf2.0", "@rzyangKyle,\r\nI have tried to reproduce the issue with [GPU](https://colab.sandbox.google.com/gist/amahendrakar/e7fb2047a9ad5aeadef9918461e07a14/36309_gpu.ipynb) and [CPU](https://colab.sandbox.google.com/gist/amahendrakar/d0a4bc51ea01c88ef9f5a3e650247f67/36309_cpu.ipynb) but could not find much difference in the initialization time. Could you please take a look at the Gist. Thanks!", "> @rzyangKyle,\r\n> I have tried to reproduce the issue with [GPU](https://colab.sandbox.google.com/gist/amahendrakar/e7fb2047a9ad5aeadef9918461e07a14/36309_gpu.ipynb) and [CPU](https://colab.sandbox.google.com/gist/amahendrakar/d0a4bc51ea01c88ef9f5a3e650247f67/36309_cpu.ipynb) but could not find much difference in the initialization time. Could you please take a look at the Gist. Thanks!\r\n\r\nI use tflite version is 2.0.", "@rzyangKyle Can you share a sample code that shows the error using latest TF release or nightly\r\n\r\nThanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36308, "title": "Incorrect Error TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Error is not OS specific. Can be reproduced in Google Colab.\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: %tensorflow_version 2.x\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Please find this [Github Gist](https://colab.research.google.com/gist/rmothukuru/505e7dfe61f9e236c8fc4b77e434b8aa/word_embeddings.ipynb#scrollTo=7SN5USFEIIK3)\r\n\r\n### Describe the problem\r\nAs per the Source Code of [Padded_Batch](https://github.com/tensorflow/tensorflow/blob/c4ec9389364cb8d1bff451ab8baf55d25cabdd1f/tensorflow/python/data/ops/dataset_ops.py#L1375-L1379), only the Argument, `batch_size` is Mandatory and remaining arguments are Optional. But as per the code in [this Tutorial](https://www.tensorflow.org/tutorials/text/word_embeddings#learning_embeddings_from_scratch), if we don't pass the second argument, `padded_shapes = ([None],())` it is resulting in the below error,\r\n`TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'`\r\n\r\n\r\nError Log: \r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-9-a8afa0f91afc> in <module>()\r\n----> 1 train_batches = train_data.shuffle(1000).padded_batch(10)\r\n      2 test_batches = test_data.shuffle(1000).padded_batch(10)\r\n      3 \r\n      4 #Error will be resolved if we uncomment below 3 lines and comment above 2 lines\r\n      5 \r\n\r\nTypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'\r\n\r\n\r\n**Expected Behavior:** Since the argument, `padded_shapes` is an Optional Argument, it shouldn't result in error even when we pass only the argument, `batch_size`", "comments": ["`tf.data.Dataset.padded_batch` method requires two arguments. \r\nNote see stable 2.1, version https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/data/ops/dataset_ops.py#L1383\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch", "Ok.. I might have verified that in the previous version.\r\n\r\nBut the documentation in your 2nd Link, https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch\r\nShows only 1 Mandatory Parameter, \r\n\r\n```\r\npadded_batch(\r\n    batch_size,\r\n    padded_shapes=None,\r\n    padding_values=None,\r\n    drop_remainder=False\r\n)\r\n```", "As I said in previous comment see stable version.\r\n![image](https://user-images.githubusercontent.com/42785357/73479052-0cd3bd00-434c-11ea-84d5-fc7b77c2b7be.png)\r\n![image](https://user-images.githubusercontent.com/42785357/73479082-1a894280-434c-11ea-91c2-11d811096a6a.png)\r\n", "Got it Thanks!", "Got the same error. Can you please update the documentation of this [tutorial](https://www.tensorflow.org/tutorials/keras/text_classification). Weird thing is, this runs on TF 2.2, but not on 2.1 because of the additional required argument. ", "@NielsRogge the documentation of the [official tutorial](https://www.tensorflow.org/tutorials/keras/text_classification) you mentioned does specify to use the latest `nightly` version of TensorFlow, hence I don't think there's any need to update it.\r\n\r\n![image](https://user-images.githubusercontent.com/31373860/77064051-bb1ee900-6a04-11ea-885a-69241f5930b4.png)\r\n\r\nAnyone following the tutorial line-by-line, shouldn't come across that trivial `TypeError`.\r\n\r\n**EDIT**: But regardless here's a heads up for you, if you came across this thread while following the official tutorial.\r\n>Weird thing is, this runs on TF 2.2, but not on 2.1 because of the additional required argument."]}, {"number": 36307, "title": "Wrong CUDA ImportError message in tf-gpu 1.14", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ntensorflow-gpu 1.14 missing CUDA error tells to download CUDA 10.0 but links to CUDA 9.0:\r\n\r\n`ImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive\r\n`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@matthiasseibold \r\n\r\nCan you please let us know which CUDA/cuDNN version you are using. Please, provide us complete error log.Thanks!", "You get this message when you don't have CUDA/cuDNN installed", "@matthiasseibold \r\n\r\nTensorFlow-gpu==1.14 requires CUDA and cuDNN. Please install CUDA 10.0 and cuDNN 7.4 before installing GPU support Tensorflow.Thanks!", "@matthiasseibold \r\n\r\nAny update on this issue please. Thanks!", "As TF1.14 will no longer be updated, can you please switch to 1.15 or 2.1 and tell us if the issue is still present?", "@matthiasseibold Please let us know if the above comment helps resolve the issue.", "It's not an issue for me, I just wanted to let you know that the error message might be irritating because the link is wrong"]}, {"number": 36306, "title": "Gradients do not propagate when iterating over dataset in graph mode", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.15\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0-dev20200128\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\nGradients become `None` if iterating over a `tf.data.Dataset` in graph mode. The correct answer is returned in eager mode.\r\n**Describe the expected behavior**\r\nGradients in eager and graph mode should be the same.\r\n\r\n**Code to reproduce the issue**\r\n Example:\r\n\r\n```\r\ndata = tf.range(10, dtype=tf.float32)\r\nds = tf.data.Dataset.from_tensor_slices(data)\r\nu = tf.Variable(1., dtype=tf.float32)\r\n\r\nwith tf.GradientTape(persistent=True) as g:\r\n    loss1 = ds.reduce(tf.constant(0.), lambda x, y: x + (y - u) ** 2)\r\n    loss2 = tf.reduce_sum([(y - u) ** 2 for y in ds.as_numpy_iterator()])\r\nprint(g.gradient(loss1, u))  # returns None\r\nprint(g.gradient(loss2, u))  # returns correct gradient\r\n```\r\nThe same behavior is observed when using `for x in ds: ...` inside of a `@tf.function`.\r\n\r\nGist [here](https://colab.research.google.com/gist/terhorst/b51638f5e9657eb7f44553922c5a93c5/untitled3.ipynb).", "comments": ["A workaround is to move the GradientTape inside of the accumulated function, and accumulate gradients alongside the loss.", "I have tried on colab with TF version 2.2.0-dev20200129 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/1641e618441ed823560057b4d24c6d75/untitled604.ipynb).Thanks!", "I have tried on colab with TF version 2.3-rc1, 2.4.0-dev20200721 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/750d4f1c916c795e98adad09c28bf03c/untitled163.ipynb).Thanks!", "@terhorst tf.data does not support gradients. Closing this issue as of now since it is the intended behavior.Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36306\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36306\">No</a>\n"]}, {"number": 36305, "title": "Clear caches on eager context reset.", "body": "Clear the caches of the existing eager context before deleting it as some of these caches are cpp static (TFE_TensorHandleCache) and will therefore be inherited by future contexts with some out of date content which might lead to some segfaults.\r\n\r\nFor example in these Keras tests some constant tensors generated by the `add_weights` function inside the convolutions are re-used across tests leading to some segfault because the eager context has been reset between tests and the device they point to no longer exist.\r\n\r\n[sequential_test.py.txt](https://github.com/tensorflow/tensorflow/files/4127467/sequential_test.py.txt)\r\n\r\nPS: The eager context reset for these tests is needed in order to clear the XLA executable cache between tests.", "comments": ["All the failures in the CI seem to be related to MLIR, not this patch."]}, {"number": 36304, "title": "TensorRT native segment lookup error in calibration mode", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Linux Ubuntu 18.04 (docker)\r\n- TensorFlow installed from source\r\n- TensorFlow version: 2.1.0 \r\n- Python version: 3.6.9\r\n- Bazel version: 1.2.1\r\n- GCC/Compiler version : 7.4.0\r\n- CUDA/cuDNN version: 10.2 / 7.6.5\r\n- TensorRT version 7.0\r\n- GPU model and memory: NVIDIA TESLA V100-SXM2-16GB\r\n\r\n**Describe the current behavior**\r\n\r\nUnder specific conditions, there is an error with the native segment lookup for TRTEngineOp. It can happen that we load a native segment that belongs to another graph. In most cases this leads to an error (when the input data is not comptible with the foreign native segment). In an unlucky case, when the input data is compatible, then we have incorrect results.\r\n\r\n**Background**\r\n\r\nTRTEngineOp falls back to execute the native TensorFlow segment in certain cases:\r\n- there is an error in creating the engine, or with its input data\r\n- during calibration https://github.com/tensorflow/tensorflow/blob/e72c2e601aac87faade051d5ca234a2a9b301b2a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L381\r\n- during optimization profile creation [PR #36080] https://github.com/pooyadavoodi/tensorflow/blob/3ae92a3d220a8d84f2d7885423254aabae6bb99d/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L535\r\n\r\nThe error can occur in the last two case. \r\n\r\nThe native segment is added to the graph here https://github.com/tensorflow/tensorflow/blob/e72c2e601aac87faade051d5ca234a2a9b301b2a/tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc#L530-L552\r\nand later it is looked up using its name in https://github.com/tensorflow/tensorflow/blob/e72c2e601aac87faade051d5ca234a2a9b301b2a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L247\r\nFor example, in each converted graph TRTEnginoOp_0 has a corresponding native segment TRTEngineOp_0_native_segment.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behavior is to load the correct native segment, the one which corresponds to the TRTEngineOp being executed.\r\n\r\nDuring normal execution the graph of the previous test should be garbage collected, so it cannot happen that we load an incorrect native segment.\r\n\r\nWe suspect that manipulating the graph during calibration (or build mode) introduces a circular reference that cause the garbage collector to not delete the graph. It is still not clear how does this native segment appear in subsequent tests' graph. The graph is owned by the converter, therefore each test is supposed to have a separate graph.\r\n\r\n**Code to reproduce the issue**\r\nTo reproduce this error, we need to use either\r\n- calibration (in the current master branch) https://github.com/tensorflow/tensorflow/blob/4152ed672ee107fc52f815443bc4601999f42ded/tensorflow/python/compiler/tensorrt/trt_convert.py#L1067-L1087 or\r\n- build mode with profiles (as proposed in PR #36080) https://github.com/pooyadavoodi/tensorflow/blob/3ae92a3d220a8d84f2d7885423254aabae6bb99d/tensorflow/python/compiler/tensorrt/trt_convert.py#L1102-L1168\r\n\r\nThe problem is illustrated in the branch https://github.com/tfeher/tensorflow/tree/native_segment_bug This branch extends the test coverage of tf_trt_integration tests by [enabling calibration test](https://github.com/tfeher/tensorflow/commit/3c0d9e8da189bc8dc4e3020204e3080f5fa0d227) in V2 mode. The calibration needs to execute the native segment. \r\n\r\nA simple test file is prepared to reproduce the problem:\r\nhttps://github.com/tfeher/tensorflow/blob/native_segment_bug/tensorflow/python/compiler/tensorrt/test/native_segment_test.py\r\n\r\nThe test file defines two tests: AddTest and MulTest, the first one takes one tensor as input, the second takes two tensors. If we call the tests individually, then they work:\r\n```\r\npython tensorflow/python/compiler/tensorrt/test/native_segment_test.py AddTest # works\r\npython tensorflow/python/compiler/tensorrt/test/native_segment_test.py MulTest # works\r\n```\r\nWhen we try to execute both test then it fails:\r\n```\r\npython tensorflow/python/compiler/tensorrt/test/native_segment_test.py\r\n...\r\nERROR: testTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration (__main__.MulTest)\r\ntestTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration (__main__.MulTest)\r\n...\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Expects 1 arguments, but 2 is provided\r\n         [[node TRTEngineOp_0 (defined at /usr/lib/python3.6/unittest/case.py:605) ]] [Op:__inference_pruned_2770]\r\n```\r\nThe `InvalidArgumentError` apperas, because AddTest's native segment was loaded instead of MulTest's native segment. This can be confirmed if we add a printout \r\n`VLOG(2) << SummarizeGraphDef(segment_graph_def_)` to TRTEngineOp's constructor.\r\n\r\nThe error can manifest different ways (but it is always caused by executing the native segment of a different graph):\r\n- Segfault\r\n- Out or range error\r\n- Mismatched value if the foreign native segment is compatible with the input data. An example for that: https://github.com/tfeher/tensorflow/blob/native_segment_bug/tensorflow/python/compiler/tensorrt/test/native_segment_test2.py\r\n- error due to incorrect data type\r\n\r\nTagging @pooyadavoodi @bixia1 and @aaroey ", "comments": ["Are you sure that https://github.com/tfeher/tensorflow/blob/native_segment_bug/tensorflow/python/compiler/tensorrt/test/native_segment_test2.py can be used to reproduce the problem?\r\n\r\nIf that is the case, I expect that removing AddTest from the file the test should pass. \r\n\r\nBut I got this error:\r\nValueError: Fetch argument 'output_0:0' cannot be interpreted as a Tensor. (\"The name 'output_0:0' refers to a Tensor which does not exist. The operation, 'output_0', does not exist in the graph.\")\r\n\r\nI think this is because the test has a problem, in GraphFn.  I fixed GraphDef as follows, and added AddTest back, the test pass.\r\n  def GraphFn(self, inp1):\r\n    \"\"\"Create a graph containing single segment.\"\"\"\r\n    dtype = inp1.dtype\r\n    val = inp1 * inp1\r\n    abs = math_ops.abs(val)\r\n    return array_ops.identity(abs, name=\"output_0\")\r\n\r\n", "Thanks @bixia1 for looking into the problem!\r\n\r\nI have not seen the output_0 error, I think I was disabling v1 test, where the output name is used. Thanks for catching this. As you have suggested I have [updated the native segments test](https://github.com/tfeher/tensorflow/commit/167007c77ea63b39da1a2913e32731130205fe9e).\r\n\r\nI have also added the [printout statement for segment_graph_def](https://github.com/tfeher/tensorflow/commit/8c54af06fcd3d352263c4a397880c5f097e7a0fa) to the TRTEngineOp. Additionally I have[ disabled](https://github.com/tfeher/tensorflow/commit/9d0ff1740ca40a88ed3d8c00d496933d04050e52) all the non relevant tests.\r\n\r\nAfter these modifications, the tests run succesfully if I invoke them using bazel:\r\n```\r\nbazel test --test_env=TF_CPP_VMODULE=trt_engine_op=2,convert_graph=7 -c opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --noincompatible_do_not_split_linking_cmdline --local_test_jobs=1 //tensorflow/python/compiler/tensorrt:native_segment_test\r\n```\r\n\r\nBut if I call the python test directly, I still receive the same errors that I describe above. Here is how to run the tests with debug printouts enabled:\r\n\r\n```\r\nTF_CPP_VMODULE=trt_engine_op=2,convert_graph=7 python tensorflow/python/compiler/tensorrt/test/native_segment_test2.py\r\n```\r\n\r\nThe relevant lines which from the output:\r\n```\r\n[ RUN      ] MulTest.testTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration\r\n....\r\n2020-01-30 12:22:46.623723: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:638] Number of TensorRT candidate segments: 1\r\n2020-01-30 12:22:46.623778: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:137] Node Func/PartitionedCall/input/_0 neither have requested device nor assigned device\r\n2020-01-30 12:22:46.623818: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:200] Input edge = input_0:0\r\n2020-01-30 12:22:46.623826: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:137] Node PartitionedCall/mul neither have requested device nor assigned device\r\n2020-01-30 12:22:46.623848: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:137] Node PartitionedCall/Abs neither have requested device nor assigned device\r\n2020-01-30 12:22:46.623854: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:137] Node PartitionedCall/output_0 neither have requested device nor assigned device\r\n2020-01-30 12:22:46.623877: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:137] Node PartitionedCall/Identity neither have requested device nor assigned device\r\n2020-01-30 12:22:46.623883: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:137] Node Func/PartitionedCall/output/_1 neither have requested device nor assigned device\r\n2020-01-30 12:22:46.623929: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:232] Output edge = Func/PartitionedCall/output/_1:0\r\n2020-01-30 12:22:46.623980: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:254] Converted TensorRT candidate segment 'TRTEngineOp_0' to a GraphDef\r\n2020-01-30 12:22:46.623992: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:97] Found TF GPU 0 at cuda device 0\r\n2020-01-30 12:22:46.624118: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:545] TRTEngineOp_0 Function_Def \r\n2020-01-30 12:22:46.624531: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:546] signature {\r\n  name: \"TRTEngineOp_0_native_segment\"\r\n  input_arg {\r\n    name: \"tensorrtinputph_0\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"tensorrtoutputph_0\"\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nnode_def {\r\n  name: \"Func/PartitionedCall/input/_0\"\r\n  op: \"Identity\"\r\n  input: \"tensorrtinputph_0\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  experimental_debug_info {\r\n    original_node_names: \"Func/PartitionedCall/input/_0\"\r\n  }\r\n}\r\nnode_def {\r\n  name: \"PartitionedCall/mul\"\r\n  op: \"Mul\"\r\n  input: \"Func/PartitionedCall/input/_0:output:0\"\r\n  input: \"Func/PartitionedCall/input/_0:output:0\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  experimental_debug_info {\r\n    original_node_names: \"PartitionedCall/mul\"\r\n  }\r\n}\r\n...\r\n\r\n2020-01-30 12:22:46.624634: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:548] Adding funcdef TRTEngineOp_0_native_segment to graphlib\r\n...\r\n\r\n2020-01-30 12:22:46.641959: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:284] versions = producer: 175;\r\n{{node TensorRTInputPH_0}} = _Arg[T=DT_FLOAT, index=0]();\r\n{{node Func/PartitionedCall/input/_0}} = Identity[T=DT_FLOAT](TensorRTInputPH_0);\r\n{{node PartitionedCall/add}} = AddV2[T=DT_FLOAT](Func/PartitionedCall/input/_0, Func/PartitionedCall/input/_0);\r\n{{node PartitionedCall/Abs}} = Abs[T=DT_FLOAT](PartitionedCall/add);\r\n{{node PartitionedCall/output_0}} = Identity[T=DT_FLOAT](PartitionedCall/Abs);\r\n{{node PartitionedCall/Identity}} = Identity[T=DT_FLOAT](PartitionedCall/output_0);\r\n{{node Func/PartitionedCall/output/_1}} = Identity[T=DT_FLOAT](PartitionedCall/Identity);\r\n{{node TensorRTOutputPH_0}} = _Retval[T=DT_FLOAT, index=0](Func/PartitionedCall/output/_1);\r\n...\r\nFAIL: testTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration (__main__.MulTest)\r\ntestTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration (__main__.MulTest)\r\n...\r\nAssertionError: \r\nNot equal to tolerance rtol=0.01, atol=0.01\r\nMismatched value: a is different from b. \r\nnot close where = (array([0]), array([0]), array([0]), array([0]))\r\nnot close lhs = [0.8641861]\r\nnot close rhs = [1.8592322]\r\nnot close dif = [0.9950461]\r\nnot close tol = [0.02859232]\r\ndtype = float32, shape = (1, 1, 1, 1)\r\nMismatch: 100%\r\nMax absolute difference: 0.9950461\r\nMax relative difference: 0.53519195\r\n x: array([[[[0.864186]]]], dtype=float32)\r\n y: array([[[[1.859232]]]], dtype=float32)\r\n```\r\nPrintouts from 'convert_graph.cc:137' show that the correct subgraph (with mul op) was converted. \r\nThe log from line convert_graph.cc:546 shows that the correct native segment was added to the graph. While later, the message from trt_engine_op.cc:284 shows that the incorrect native segment (with add op) is loaded during calibration.\r\n\r\nI would expect that the test would work even if I run it without bazel. Any idea why is it not the case?", "Can you tell me the detail on how you get the binary \"python\" as in \"TF_CPP_VMODULE=trt_engine_op=2,convert_graph=7 python tensorflow/python/compiler/tensorrt/test/native_segment_test2.py\"?", "I compiled tf inside our docker container `nvcr.io/nvidia/tensorflow:20.01-tf2-py3`, and I use the python binary from the container, if that answers your question.", "@tfeher  Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36304\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36304\">No</a>\n"]}, {"number": 36303, "title": "tensorboard installation issue ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): terminal\r\n- TensorFlow version: tensorflow                         2.1.0              \r\n                                   tensorflow-estimator               2.1.0\r\n- Python version: 3.6.7\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nam done by following steps in this link https://www.tensorflow.org/tensorboard/get_started  but it gives an error message like that \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ntensorboard --logdir logs/fit\r\n\r\n\r\n**Any other info / logs**\r\n2020-01-29 15:42:56.124384: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-01-29 15:42:56.124520: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-01-29 15:42:56.124541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\nTraceback (most recent call last):\r\n  File \"/home/kuppa/anaconda3/bin/tensorboard\", line 8, in <module>\r\n    sys.exit(run_main())\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/main.py\", line 59, in run_main\r\n    default.get_plugins() + default.get_dynamic_plugins(),\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/default.py\", line 115, in get_dynamic_plugins\r\n    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/default.py\", line 115, in <listcomp>\r\n    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2443, in load\r\n    self.require(*args, **kwargs)\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2466, in require\r\n    items = working_set.resolve(reqs, env, installer, extras=self.extras)\r\n  File \"/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 792, in resolve\r\n    raise VersionConflict(dist, req).with_context(dependent_req)\r\npkg_resources.VersionConflict: (grpcio 1.16.1 (/home/kuppa/anaconda3/lib/python3.6/site-packages), Requirement.parse('grpcio>=1.24.3'))", "comments": ["@kuppas, Just to verify, did you install GPU support Tensorflow? If so install TensorRT as well to get rid of this error. Please refer the similar issue [#35968](https://github.com/tensorflow/tensorflow/issues/35968#issuecomment-577327358). Thanks! ", "I just verified GPU version is not installed and current TensorFlow details are\r\n$ pip freeze | grep tensorflow\r\ntensorflow==2.1.0\r\ntensorflow-estimator==2.1.0", "@kuppas Yes that example should be modified. I have modified that example and its running successfully. The problem is the grpcio version 1.16.1. I changed it to 1.24.3 and then I ran into an other problem which is shown [here](https://colab.research.google.com/gist/gowthamkpr/b8100d83e51a0a17424f41d6f02e4cbf/copy-of-get_started.ipynb) and if you uninstall tensorboard at the start, it should fix the error.\r\n\r\nPlease take a look at the final working version of the model [here](https://colab.research.google.com/gist/gowthamkpr/04d772b61745e60a12242c675446028c/get_started.ipynb).\r\n\r\nThanks for reporting.", "The example works successfully now. Tested with default colab TF version 2.4.1. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36303\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36303\">No</a>\n"]}, {"number": 36302, "title": "Tensorflow 2.1 Tracing Error with LSTM layer", "body": "I am implementing a tensorflow model using the keras LSTM layer.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7\r\n- GPU model and memory: CPU\r\n\r\n**Describe the current behavior**\r\nMethod Model.predict raise warning about Tracing\r\n```WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x7eff0c74def0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.```\r\n\r\n**Describe the expected behavior**\r\nSame as Model.predict_on_batch\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nfeature_dimension=2\r\nlstm_size=256\r\nlearning_rate=0.0001\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.Input([None, feature_dimension]),\r\n    tf.keras.layers.LSTM(lstm_size),\r\n    tf.keras.layers.Dense(1, activation='linear')\r\n])\r\n\r\nmodel.compile(loss='mean_squared_error',\r\n              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\r\n              metrics=['mse', 'mae'])\r\n\r\nprint('Model.predict')\r\nst = time.time()\r\nfor i in range(5,100):\r\n    model.predict(np.array([[(0.1,0.1)]*i]*10))\r\nprint(f'Model.predict in {time.time() - st}')\r\n\r\nprint('Model.predict_on_batch')\r\nst = time.time()\r\nfor i in range(5,100):\r\n    np.array(model.predict_on_batch(np.array([[(0.1,0.1)]*i]*10)))\r\n\r\nprint(f'Model.predict_on_batch in {time.time() - st}')\r\n```\r\n\r\n**Other info / logs**\r\nFor me help use predict_on_batch method.\r\n", "comments": ["Was able to replicate the issue on colab with Tf 2.1 and Tf -nightly version.\r\nPlease find the gist [here](https://colab.research.google.com/gist/gadagashwini/2799dacc09fdf988c7c40d4b72bf5d9d/36302.ipynb). Thanks!", "I don't think this is the issue with LSTM. The warning also shows up when LSTM layer is removed.\r\n\r\nThe real issue is that the usage between predict() and predict_on_batch(). Since the predict() is designed to handle large data and process them one batch by one batch, under the hood, we build TF functions. Whereas for predict_on_batch, since there is only one batch, we use more light weighted approach. \r\n\r\nFor this warning, it is expected since your input shape changes everytime, and model as to retrace the function based on that change.\r\n\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=nightly#predict for more details and performance implication of small and large data input.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36302\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36302\">No</a>\n"]}, {"number": 36301, "title": "[MLIR] Swap target names MlirOptLib and MlirOptMain", "body": "This commit swaps the targets name in the Bazel configuration to match with CMake. In MLIR's CMake configuration the targets `MLIRMlirOptLib` and `MLIROptMain` map to source files as follows:\r\n* `MLIRMlirOptLib`\t-> `mlir-opt.cpp`\r\nhttps://github.com/llvm/llvm-project/blob/e06444d982f031ed2de20b8d5d3de2dfadb09e96/mlir/tools/mlir-opt/CMakeLists.txt#L13-L14\r\n\r\n* `MLIROptMain` -> `MlirOptMain.cpp`\r\nhttps://github.com/llvm/llvm-project/blob/e06444d982f031ed2de20b8d5d3de2dfadb09e96/mlir/lib/Support/CMakeLists.txt#L20-L21\r\n\r\nIn the current Bazel configuration it is the other way around:\r\nhttps://github.com/tensorflow/tensorflow/blob/6e4972c241791067c3094bde9d40604b29da872b/third_party/mlir/BUILD#L1710-L1713\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/6e4972c241791067c3094bde9d40604b29da872b/third_party/mlir/BUILD#L1786-L1790", "comments": ["Also supersedes https://github.com/google/iree/pull/569 and https://github.com/google/iree/pull/574.", "(I could also do it if you prefer)", "Sent a PR to LLVM's Phabricator: https://reviews.llvm.org/D73778\r\n\r\nIf accepted, the Bazel configuration needs an update as well, since it also changes files names as proposed by @GMNGeoffrey. Closing this PR."]}, {"number": 36300, "title": "Error message is unclear when we failed to load tflite model.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n   Darwin 19.2.0 \r\n   Android Pixel2 API 29\r\n- TensorFlow installed from (source or binary):\r\n   binary (pip)\r\n- TensorFlow version (or github SHA if from source):\r\n   1.15.0\r\n\r\n**Provide the text output from tflite_convert**\r\ntflite_convert succeeded without any error. \r\n```\r\n$ tflite_convert --saved_model_dir ./tts/exported/more-kss-spk10-tflite \\\r\n    --output_file ./tts/tflite/more-kss-spk10.tflite\r\n\r\n...\r\nWARNING:tensorflow:From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:208: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nW0129 17:08:51.578040 140734888230336 deprecation.py:323] From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:208: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nWARNING:tensorflow:From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nW0129 17:08:51.578234 140734888230336 deprecation.py:323] From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nINFO:tensorflow:Froze 198 variables.\r\nI0129 17:08:53.582584 140734888230336 graph_util_impl.py:334] Froze 198 variables.\r\nINFO:tensorflow:Converted 198 variables to const ops.\r\nI0129 17:08:53.853986 140734888230336 graph_util_impl.py:394] Converted 198 variables to const ops.\r\nWARNING:tensorflow:From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:210: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.remove_training_nodes`\r\nW0129 17:11:05.991335 140734888230336 deprecation.py:323] From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:210: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.remove_training_nodes`\r\n```\r\n\r\nBut when I tried to load this model on both my local machine and android, I got the below message. \r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 6, in <module>\r\n    interpreter = tf.lite.Interpreter(model_path='more-kss-spk10.tflite')\r\n  File \"/Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py\", line 206, in __init__\r\n    model_path))\r\nValueError: Tensor 2711 is a variable tensor with buffer. It's not supported now.\r\n```\r\nI can't guess the Tensor 2711. \r\nMay I delete all get_variable or tf.Variable statements on my model? \r\n\r\n\r\n", "comments": ["@w4-hyunseok Can you please share a standalone code to reproduce the issue? Thanks!", "@jvishnuvardhan Thanks to reply. \r\nMy execution code is below and I want to share our tflite file or saved_model if you want. \r\nIf you give me an email address to get our tflite file or saved_model, I'll send them ASAP. \r\n\r\n```\r\n#!/usr/bin/env python3\r\n\"\"\"\r\nBefore run this, we need to prepare .tflite file.\r\n\r\nThe tflite file can be generated by `tflite_convert` tool.\r\nFor example, if you have saved model, run belows:\r\n\r\n    $ tflite_convert --saved_model_dir <input saved model directory> \\\r\n        --output_file <output tflite file>\r\n\r\nAnd then, run this with above output tflite file.\r\n\"\"\"\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nflags = tf.flags\r\nflags.DEFINE_string('model_path', None, 'The input tflite model path.')\r\nFLAGS = flags.FLAGS\r\n\r\n\r\ndef main(argv):\r\n    del argv    # Unused\r\n\r\n    # Load TFLite model and allocate tensors.\r\n    tf.logging.info('Try to load %s', FLAGS.model_path)\r\n    interpreter = tf.lite.Interpreter(model_path=FLAGS.model_path)\r\n    tf.logging.info('Model loaded: %s', FLAGS.model_path)\r\n    interpreter.allocate_tensors()\r\n\r\n    # Get input and output tensors.\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n    print(input_details)\r\n    print(output_details)\r\n\r\n\r\nif __name__ == '__main__':\r\n    flags.mark_flag_as_required('model_path')\r\n    tf.app.run(main)\r\n```  \r\n", "@w4-hyunseok Please share the link to saved_model and tf_lite model so that it is easy to share, if needed, with other developers. Thanks!", "@miaout17 is there a reason we're allowing conversion of this model, only to fail at runtime?", "@jvishnuvardhan I share the link to download both saved_model and tflite file. For convenience, I exported our model to .pbtxt. If you prefer .pb, please tell me again. Thank you. \r\nhttps://goto.wisefour.com/tfissue_3600.tar.gz ", "I still have the same issue and I keep going to wait for a response.", "Sorry for the delayed response, @w4-hyunseok \r\n\r\nFirst, your TensorFlow version seems very old (1.15.0). Could you try to upgrade to the newest version and try it again?\r\n\r\nI tried to reproduce the issue with the [model](https://github.com/tensorflow/tensorflow/issues/36300#issuecomment-580559088) you uploaded, but I'm running into an irrelevant error:\r\n```\r\nKeyError: u'Generator/decoder1_14/attention_decoder/rnn/while/Identity_8'\r\n```\r\nCould you double check if you can reproduce your original issue with the same model?\r\n\r\nWe are working on replacing the old TensorFlow Lite converter backend with a new one, and I think it has a great chance to solve this issue (because we completely reworked relevant code). To use it, just add `--experimental_new_converter` argument to the command line (it only works in TensorFlow 2.1.0+, or tf-nightly pip), like:\r\n```\r\ntflite_convert --experimental_new_converter \\\r\n    --saved_model_dir ./tts/exported/more-kss-spk10-tflite \\\r\n    --output_file ./tts/tflite/more-kss-spk10.tflite\r\n```\r\n\r\ncc @renjie-liu @ashwinmurthy -- It seems a buffer is incorrectly attached to a variable tensor of an op generated by OpHints, but this was the old converter. I'm hoping the new converter can just solve this issue. \r\n", "Thanks to reply, @miaout17 \r\n\r\nI checked the shared link again which md5 values are below:\r\n```\r\ne56c54a24b4c0967e8292e587ade68cc saved_model/saved_model.pbtxt\r\nc7f2e8785625a13d0d7a9664e0b61467 saved_model/variables/variables.data-00000-of-00001\r\n6205b5126e2ae6bcfa3dc136e2df9370  saved_model/variables/variables.index\r\n```\r\nAnd I got a same results again(I can't see any error messages on **my mac with tf 1.15.0**\r\n```\r\ntflite_convert --saved_model_dir ./tfissue_36300/saved_model --output_file ./temp.tflite\r\n```\r\n\r\nThe transition from tf 1.15.0 to tf 2.1 needs more time because our model uses tf.contrib APIs and we need to succeed to train our model with tf 2.1.  When I just tried a new converter to our current tf 1.15 model, I got the below errors. (Just for a curious)\r\n```\r\nFile \"/Users/hyunseok/.venv/tf/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n   enable_mlir_converter)\r\nException: <unknown>:0: error: Found malformed ophint regions: missing inputs or outputs\r\n``` \r\nIf you give any quick hint about the above message before I dig, it will be really helpful for me.", "Hi,\r\n\r\nIndeed I can see some usage of ophint and seems the conversion failed because of the rnn state.\r\n\r\nI think two options:\r\n\r\n1) if you are using ophinted lstm (lite.experimental.nn.dynamic_rnn), please don't set initial state, and the new converter support is WIP. (so you need to disable new_experimental_converter)\r\n\r\n2) if you are not using ophinted lstm, preferably, keras lstm, you can try  new_experimental_converter\r\n\r\nThanks", "Thank you. @renjie-liu \r\n\r\nOur case is 1. (We used ophinted lstm and we also set the initial state, unfortunately) \r\nI understand the current status of new_experiemental_converter. And I'll try to remove the initial state and succeed to train.\r\n\r\nDoes the tensorflow lite team have the roadmap to support 'initial state' in the future? ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36300\">No</a>\n"]}, {"number": 36299, "title": "Unable to import meta graph using tf.train.import_meta_graph, The name '' refers to an Operation not in the graph", "body": "[model.zip](https://github.com/tensorflow/tensorflow/files/4126895/model.zip)\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: `Ubuntu 18.04`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): `pip install`\r\n- TensorFlow version (use command below): \r\n```\r\ntf.VERSION = 1.13.1                                                            \r\ntf.GIT_VERSION = b'v1.13.1-0-g6612da8951'                                      \r\ntf.COMPILER_VERSION = b'v1.13.1-0-g6612da8951'\r\n```\r\n- Python version: `3.6.10`\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): `4.8.5`\r\n- CUDA/cuDNN version: `10.2`\r\n- GPU model and memory: `Nvidia Tesla V100, 16gb`\r\n\r\n**Describe the current behavior**\r\n\r\nI am not able to import meta graph.\r\nEven If I define `tf.placeholder(name=\"data\", shape=(None,64), dtype=tf.float32)`, error comes for next layer.\r\nI tried using tf2.0 also. But same issue there.\r\n\r\n**Describe the expected behavior**\r\nWe should be able to import the graph\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nmodel_dir=\"./model\"   # change this line to the directory where checkpoint and models are saved\r\ncheckpoint = tf.train.get_checkpoint_state(model_dir)\r\ninput_checkpoint = checkpoint.model_checkpoint_path\r\nclear_devices = True\r\n\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\r\n```\r\nCheckpoint files are attached in **model.zip**.\r\n\r\n**StackTrace**\r\n```\r\nTraceback (most recent call last):\r\n  File \"import_meta_graph.py\", line 11, in <module>\r\n    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\r\n  File \"/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1435, in import_meta_graph\r\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\r\n  File \"/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1457, in _import_meta_graph_with_return_elements\r\n    **kwargs))\r\n  File \"/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\", line 852, in import_scoped_meta_graph_with_return_elements\r\n    ops.prepend_name_scope(value, scope_to_prepend_to_names))\r\n  File \"/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3478, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3538, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'data' refers to an Operation not in the graph.\"\r\n```\r\n", "comments": ["These are all the operations and variables in the graph.\r\nWhy is it looking for '`data`'?\r\nWhere is this data coming from?\r\n\r\n`{'global_tensor_train_flag/train_flag': <tf.Operation 'global_tensor_train_flag/train_flag' type=Placeholder>, 'globals/train_flag': <tf.Operation 'globals/train_flag' type=Identity>, 'extern_data/placeholders/classes/classes': <tf.Operation 'extern_data/placeholders/classes/classes' type=Placeholder>, 'extern_data/placeholders/classes/classes_dim0_size': <tf.Operation 'extern_data/placeholders/classes/classes_dim0_size' type=Placeholder>, 'extern_data/placeholders/data/data': <tf.Operation 'extern_data/placeholders/data/data' type=Placeholder>, 'extern_data/placeholders/data/data_dim0_size': <tf.Operation 'extern_data/placeholders/data/data_dim0_size' type=Placeholder>, 'global_step/Initializer/zeros': <tf.Operation 'global_step/Initializer/zeros' type=Const>, 'global_step': <tf.Operation 'global_step' type=VariableV2>, 'global_step/Assign': <tf.Operation 'global_step/Assign' type=Assign>, 'global_step/read': <tf.Operation 'global_step/read' type=Identity>, 'ff1/W/Initializer/random_uniform/shape': <tf.Operation 'ff1/W/Initializer/random_uniform/shape' type=Const>, 'ff1/W/Initializer/random_uniform/min': <tf.Operation 'ff1/W/Initializer/random_uniform/min' type=Const>, 'ff1/W/Initializer/random_uniform/max': <tf.Operation 'ff1/W/Initializer/random_uniform/max' type=Const>, 'ff1/W/Initializer/random_uniform/RandomUniform': <tf.Operation 'ff1/W/Initializer/random_uniform/RandomUniform' type=RandomUniform>, 'ff1/W/Initializer/random_uniform/sub': <tf.Operation 'ff1/W/Initializer/random_uniform/sub' type=Sub>, 'ff1/W/Initializer/random_uniform/mul': <tf.Operation 'ff1/W/Initializer/random_uniform/mul' type=Mul>, 'ff1/W/Initializer/random_uniform': <tf.Operation 'ff1/W/Initializer/random_uniform' type=Add>, 'ff1/W': <tf.Operation 'ff1/W' type=VariableV2>, 'ff1/W/Assign': <tf.Operation 'ff1/W/Assign' type=Assign>, 'ff1/W/read': <tf.Operation 'ff1/W/read' type=Identity>, 'ff1/b/Initializer/zeros': <tf.Operation 'ff1/b/Initializer/zeros' type=Const>, 'ff1/b': <tf.Operation 'ff1/b' type=VariableV2>, 'ff1/b/Assign': <tf.Operation 'ff1/b/Assign' type=Assign>, 'ff1/b/read': <tf.Operation 'ff1/b/read' type=Identity>, 'ff1/linear/dot/shape_dim/Shape': <tf.Operation 'ff1/linear/dot/shape_dim/Shape' type=Shape>, 'ff1/linear/dot/shape_dim/strided_slice/stack': <tf.Operation 'ff1/linear/dot/shape_dim/strided_slice/stack' type=Const>, 'ff1/linear/dot/shape_dim/strided_slice/stack_1': <tf.Operation 'ff1/linear/dot/shape_dim/strided_slice/stack_1' type=Const>, 'ff1/linear/dot/shape_dim/strided_slice/stack_2': <tf.Operation 'ff1/linear/dot/shape_dim/strided_slice/stack_2' type=Const>, 'ff1/linear/dot/shape_dim/strided_slice': <tf.Operation 'ff1/linear/dot/shape_dim/strided_slice' type=StridedSlice>, 'ff1/linear/dot/shape_dim_1/Shape': <tf.Operation 'ff1/linear/dot/shape_dim_1/Shape' type=Shape>, 'ff1/linear/dot/shape_dim_1/strided_slice/stack': <tf.Operation 'ff1/linear/dot/shape_dim_1/strided_slice/stack' type=Const>, 'ff1/linear/dot/shape_dim_1/strided_slice/stack_1': <tf.Operation 'ff1/linear/dot/shape_dim_1/strided_slice/stack_1' type=Const>, 'ff1/linear/dot/shape_dim_1/strided_slice/stack_2': <tf.Operation 'ff1/linear/dot/shape_dim_1/strided_slice/stack_2' type=Const>, 'ff1/linear/dot/shape_dim_1/strided_slice': <tf.Operation 'ff1/linear/dot/shape_dim_1/strided_slice' type=StridedSlice>, 'ff1/linear/dot/Reshape/shape': <tf.Operation 'ff1/linear/dot/Reshape/shape' type=Const>, 'ff1/linear/dot/Reshape': <tf.Operation 'ff1/linear/dot/Reshape' type=Reshape>, 'ff1/linear/dot/MatMul': <tf.Operation 'ff1/linear/dot/MatMul' type=MatMul>, 'ff1/linear/dot/Reshape_1/shape/2': <tf.Operation 'ff1/linear/dot/Reshape_1/shape/2' type=Const>, 'ff1/linear/dot/Reshape_1/shape': <tf.Operation 'ff1/linear/dot/Reshape_1/shape' type=Pack>, 'ff1/linear/dot/Reshape_1': <tf.Operation 'ff1/linear/dot/Reshape_1' type=Reshape>, 'ff1/linear/add_bias': <tf.Operation 'ff1/linear/add_bias' type=Add>, 'ff1/activation/Relu': <tf.Operation 'ff1/activation/Relu' type=Relu>, 'output/W/Initializer/random_uniform/shape': <tf.Operation 'output/W/Initializer/random_uniform/shape' type=Const>, 'output/W/Initializer/random_uniform/min': <tf.Operation 'output/W/Initializer/random_uniform/min' type=Const>, 'output/W/Initializer/random_uniform/max': <tf.Operation 'output/W/Initializer/random_uniform/max' type=Const>, 'output/W/Initializer/random_uniform/RandomUniform': <tf.Operation 'output/W/Initializer/random_uniform/RandomUniform' type=RandomUniform>, 'output/W/Initializer/random_uniform/sub': <tf.Operation 'output/W/Initializer/random_uniform/sub' type=Sub>, 'output/W/Initializer/random_uniform/mul': <tf.Operation 'output/W/Initializer/random_uniform/mul' type=Mul>, 'output/W/Initializer/random_uniform': <tf.Operation 'output/W/Initializer/random_uniform' type=Add>, 'output/W': <tf.Operation 'output/W' type=VariableV2>, 'output/W/Assign': <tf.Operation 'output/W/Assign' type=Assign>, 'output/W/read': <tf.Operation 'output/W/read' type=Identity>, 'output/b/Initializer/zeros': <tf.Operation 'output/b/Initializer/zeros' type=Const>, 'output/b': <tf.Operation 'output/b' type=VariableV2>, 'output/b/Assign': <tf.Operation 'output/b/Assign' type=Assign>, 'output/b/read': <tf.Operation 'output/b/read' type=Identity>, 'output/linear/dot/shape_dim/Shape': <tf.Operation 'output/linear/dot/shape_dim/Shape' type=Shape>, 'output/linear/dot/shape_dim/strided_slice/stack': <tf.Operation 'output/linear/dot/shape_dim/strided_slice/stack' type=Const>, 'output/linear/dot/shape_dim/strided_slice/stack_1': <tf.Operation 'output/linear/dot/shape_dim/strided_slice/stack_1' type=Const>, 'output/linear/dot/shape_dim/strided_slice/stack_2': <tf.Operation 'output/linear/dot/shape_dim/strided_slice/stack_2' type=Const>, 'output/linear/dot/shape_dim/strided_slice': <tf.Operation 'output/linear/dot/shape_dim/strided_slice' type=StridedSlice>, 'output/linear/dot/shape_dim_1/Shape': <tf.Operation 'output/linear/dot/shape_dim_1/Shape' type=Shape>, 'output/linear/dot/shape_dim_1/strided_slice/stack': <tf.Operation 'output/linear/dot/shape_dim_1/strided_slice/stack' type=Const>, 'output/linear/dot/shape_dim_1/strided_slice/stack_1': <tf.Operation 'output/linear/dot/shape_dim_1/strided_slice/stack_1' type=Const>, 'output/linear/dot/shape_dim_1/strided_slice/stack_2': <tf.Operation 'output/linear/dot/shape_dim_1/strided_slice/stack_2' type=Const>, 'output/linear/dot/shape_dim_1/strided_slice': <tf.Operation 'output/linear/dot/shape_dim_1/strided_slice' type=StridedSlice>, 'output/linear/dot/Reshape/shape': <tf.Operation 'output/linear/dot/Reshape/shape' type=Const>, 'output/linear/dot/Reshape': <tf.Operation 'output/linear/dot/Reshape' type=Reshape>, 'output/linear/dot/MatMul': <tf.Operation 'output/linear/dot/MatMul' type=MatMul>, 'output/linear/dot/Reshape_1/shape/2': <tf.Operation 'output/linear/dot/Reshape_1/shape/2' type=Const>, 'output/linear/dot/Reshape_1/shape': <tf.Operation 'output/linear/dot/Reshape_1/shape' type=Pack>, 'output/linear/dot/Reshape_1': <tf.Operation 'output/linear/dot/Reshape_1' type=Reshape>, 'output/linear/add_bias': <tf.Operation 'output/linear/add_bias' type=Add>, 'output/activation/Softmax': <tf.Operation 'output/activation/Softmax' type=Softmax>, 'learning_rate/initial_value': <tf.Operation 'learning_rate/initial_value' type=Const>, 'learning_rate': <tf.Operation 'learning_rate' type=VariableV2>, 'learning_rate/Assign': <tf.Operation 'learning_rate/Assign' type=Assign>, 'learning_rate/read': <tf.Operation 'learning_rate/read' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Equal': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Equal' type=Equal>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/All': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/All' type=All>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Const_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Const_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Assert/data_0': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Assert/data_0' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Assert/data_3': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Assert/data_3' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Assert': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/assert_equal/Assert/Assert' type=Assert>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/identity_with_dim_equal_check': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal/identity_with_dim_equal_check' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Const_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Const_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Range': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Range' type=Range>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/ExpandDims/dim': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/ExpandDims/dim' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/ExpandDims': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/ExpandDims' type=ExpandDims>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Cast': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Cast' type=Cast>, 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Less': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/SequenceMask/Less' type=Less>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Equal': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Equal' type=Equal>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/All': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/All' type=All>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Assert/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Assert/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Assert/Assert/data_0': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Assert/Assert/data_0' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Assert/Assert': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/assert_equal/Assert/Assert' type=Assert>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/identity_with_dim_equal_check': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_1/identity_with_dim_equal_check' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Equal': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Equal' type=Equal>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/All': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/All' type=All>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Assert/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Assert/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Assert/Assert/data_0': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Assert/Assert/data_0' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Assert/Assert': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/assert_equal/Assert/Assert' type=Assert>, 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/identity_with_dim_equal_check': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/check_dim_equal_2/identity_with_dim_equal_check' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Prod/reduction_indices': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Prod/reduction_indices' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Prod': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Prod' type=Prod>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Shape_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Shape_2' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/strided_slice_2' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/concat/values_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/concat/values_1' type=Pack>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/concat/axis': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/concat/axis' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/concat': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/concat' type=ConcatV2>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape' type=Reshape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_1/shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_1/shape' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_1' type=Reshape>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Where': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Where' type=Where>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Squeeze': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Squeeze' type=Squeeze>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2/axis': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2/axis' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2' type=GatherV2>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Equal': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Equal' type=Equal>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/All': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/All' type=All>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Const_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Const_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Assert/data_0': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Assert/data_0' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Assert/data_3': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Assert/data_3' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Assert': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/assert_equal/Assert/Assert' type=Assert>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/identity_with_dim_equal_check': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal/identity_with_dim_equal_check' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Const_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Const_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Range': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Range' type=Range>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/ExpandDims/dim': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/ExpandDims/dim' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/ExpandDims': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/ExpandDims' type=ExpandDims>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Cast': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Cast' type=Cast>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Less': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/SequenceMask/Less' type=Less>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Equal': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Equal' type=Equal>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/All': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/All' type=All>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Assert/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Assert/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Assert/Assert/data_0': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Assert/Assert/data_0' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Assert/Assert': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/assert_equal/Assert/Assert' type=Assert>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/identity_with_dim_equal_check': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_1/identity_with_dim_equal_check' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Equal': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Equal' type=Equal>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/All': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/All' type=All>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Assert/Const': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Assert/Const' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Assert/Assert/data_0': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Assert/Assert/data_0' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Assert/Assert': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/assert_equal/Assert/Assert' type=Assert>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/identity_with_dim_equal_check': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/check_dim_equal_2/identity_with_dim_equal_check' type=Identity>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Shape' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Prod/reduction_indices': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Prod/reduction_indices' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Prod': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Prod' type=Prod>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Shape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Shape_1' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_1' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Shape_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Shape_2' type=Shape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2/stack': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2/stack' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2/stack_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2/stack_1' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2/stack_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2/stack_2' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/strided_slice_2' type=StridedSlice>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/concat/values_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/concat/values_1' type=Pack>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/concat/axis': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/concat/axis' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/concat': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/concat' type=ConcatV2>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Reshape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Reshape' type=Reshape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Reshape_1/shape': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Reshape_1/shape' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Reshape_1': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Reshape_1' type=Reshape>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Where': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Where' type=Where>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Squeeze': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/Squeeze' type=Squeeze>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/GatherV2/axis': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/GatherV2/axis' type=Const>, 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/GatherV2': <tf.Operation 'objective/loss/loss_init/flatten_with_seq_len_mask_1/boolean_mask/GatherV2' type=GatherV2>, 'objective/loss/loss_init/Const': <tf.Operation 'objective/loss/loss_init/Const' type=Const>, 'objective/loss/loss_init/Sum': <tf.Operation 'objective/loss/loss_init/Sum' type=Sum>, 'objective/loss/loss_init/Cast': <tf.Operation 'objective/loss/loss_init/Cast' type=Cast>, 'objective/loss/loss_init/truediv/x': <tf.Operation 'objective/loss/loss_init/truediv/x' type=Const>, 'objective/loss/loss_init/truediv': <tf.Operation 'objective/loss/loss_init/truediv' type=RealDiv>, 'objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/Shape': <tf.Operation 'objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/Shape' type=Shape>, 'objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits': <tf.Operation 'objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' type=SparseSoftmaxCrossEntropyWithLogits>, 'objective/loss/loss/loss_ce/Const': <tf.Operation 'objective/loss/loss/loss_ce/Const' type=Const>, 'objective/loss/loss/loss_ce/Sum': <tf.Operation 'objective/loss/loss/loss_ce/Sum' type=Sum>, 'objective/loss/error/loss_frame_error/Rank': <tf.Operation 'objective/loss/error/loss_frame_error/Rank' type=Const>, 'objective/loss/error/loss_frame_error/sub/y': <tf.Operation 'objective/loss/error/loss_frame_error/sub/y' type=Const>, 'objective/loss/error/loss_frame_error/sub': <tf.Operation 'objective/loss/error/loss_frame_error/sub' type=Sub>, 'objective/loss/error/loss_frame_error/ArgMax': <tf.Operation 'objective/loss/error/loss_frame_error/ArgMax' type=ArgMax>, 'objective/loss/error/loss_frame_error/Cast': <tf.Operation 'objective/loss/error/loss_frame_error/Cast' type=Cast>, 'objective/loss/error/loss_frame_error/NotEqual': <tf.Operation 'objective/loss/error/loss_frame_error/NotEqual' type=NotEqual>, 'objective/loss/error/loss_frame_error/Cast_1': <tf.Operation 'objective/loss/error/loss_frame_error/Cast_1' type=Cast>, 'objective/loss/error/loss_frame_error/Const': <tf.Operation 'objective/loss/error/loss_frame_error/Const' type=Const>, 'objective/loss/error/loss_frame_error/Sum': <tf.Operation 'objective/loss/error/loss_frame_error/Sum' type=Sum>, 'objective/loss/mul': <tf.Operation 'objective/loss/mul' type=Mul>, 'objective/loss/loss_output/tags': <tf.Operation 'objective/loss/loss_output/tags' type=Const>, 'objective/loss/loss_output': <tf.Operation 'objective/loss/loss_output' type=ScalarSummary>, 'objective/loss/mul_1': <tf.Operation 'objective/loss/mul_1' type=Mul>, 'objective/loss/error_output/tags': <tf.Operation 'objective/loss/error_output/tags' type=Const>, 'objective/loss/error_output': <tf.Operation 'objective/loss/error_output' type=ScalarSummary>, 'objective/add/y': <tf.Operation 'objective/add/y' type=Const>, 'objective/add': <tf.Operation 'objective/add' type=Add>, 'objective/loss/tags': <tf.Operation 'objective/loss/tags' type=Const>, 'objective/loss': <tf.Operation 'objective/loss' type=ScalarSummary>, 'objective/constraints/tags': <tf.Operation 'objective/constraints/tags' type=Const>, 'objective/constraints/values': <tf.Operation 'objective/constraints/values' type=Const>, 'objective/constraints': <tf.Operation 'objective/constraints' type=ScalarSummary>, 'objective/objective/tags': <tf.Operation 'objective/objective/tags' type=Const>, 'objective/objective': <tf.Operation 'objective/objective' type=ScalarSummary>, 'var_initializer/init': <tf.Operation 'var_initializer/init' type=NoOp>, 'optimize/gradients/Shape': <tf.Operation 'optimize/gradients/Shape' type=Const>, 'optimize/gradients/grad_ys_0': <tf.Operation 'optimize/gradients/grad_ys_0' type=Const>, 'optimize/gradients/Fill': <tf.Operation 'optimize/gradients/Fill' type=Fill>, 'optimize/gradients/objective/add_grad/tuple/group_deps': <tf.Operation 'optimize/gradients/objective/add_grad/tuple/group_deps' type=NoOp>, 'optimize/gradients/objective/add_grad/tuple/control_dependency': <tf.Operation 'optimize/gradients/objective/add_grad/tuple/control_dependency' type=Identity>, 'optimize/gradients/objective/add_grad/tuple/control_dependency_1': <tf.Operation 'optimize/gradients/objective/add_grad/tuple/control_dependency_1' type=Identity>, 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Reshape/shape': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Reshape/shape' type=Const>, 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Reshape': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Reshape' type=Reshape>, 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Shape': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Shape' type=Shape>, 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Tile': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/Sum_grad/Tile' type=Tile>, 'optimize/gradients/zeros_like': <tf.Operation 'optimize/gradients/zeros_like' type=ZerosLike>, 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient' type=PreventGradient>, 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim' type=Const>, 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims' type=ExpandDims>, 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul': <tf.Operation 'optimize/gradients/objective/loss/loss/loss_ce/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul' type=Mul>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Shape': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Shape' type=Shape>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/ToInt32': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/ToInt32' type=Cast>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Size': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Size' type=Size>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/ExpandDims/dim': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/ExpandDims/dim' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/ExpandDims': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/ExpandDims' type=ExpandDims>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice/stack': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice/stack' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice/stack_1': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice/stack_1' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice/stack_2': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice/stack_2' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/strided_slice' type=StridedSlice>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/concat/axis': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/concat/axis' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/concat': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/concat' type=ConcatV2>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Reshape': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Reshape' type=Reshape>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Reshape_1': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/GatherV2_grad/Reshape_1' type=Reshape>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Shape': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Shape' type=Shape>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice/stack': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice/stack' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice/stack_1': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice/stack_1' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice/stack_2': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice/stack_2' type=Const>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/strided_slice' type=StridedSlice>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/tensor': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape/tensor' type=UnsortedSegmentSum>, 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape': <tf.Operation 'optimize/gradients/objective/loss/loss_init/flatten_with_seq_len_mask/boolean_mask/Reshape_grad/Reshape' type=Reshape>, 'optimize/gradients/output/linear/add_bias_grad/Shape': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/Shape' type=Shape>, 'optimize/gradients/output/linear/add_bias_grad/Shape_1': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/Shape_1' type=Const>, 'optimize/gradients/output/linear/add_bias_grad/BroadcastGradientArgs': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, 'optimize/gradients/output/linear/add_bias_grad/Sum': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/Sum' type=Sum>, 'optimize/gradients/output/linear/add_bias_grad/Reshape': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/Reshape' type=Reshape>, 'optimize/gradients/output/linear/add_bias_grad/Sum_1': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/Sum_1' type=Sum>, 'optimize/gradients/output/linear/add_bias_grad/Reshape_1': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/Reshape_1' type=Reshape>, 'optimize/gradients/output/linear/add_bias_grad/tuple/group_deps': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/tuple/group_deps' type=NoOp>, 'optimize/gradients/output/linear/add_bias_grad/tuple/control_dependency': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/tuple/control_dependency' type=Identity>, 'optimize/gradients/output/linear/add_bias_grad/tuple/control_dependency_1': <tf.Operation 'optimize/gradients/output/linear/add_bias_grad/tuple/control_dependency_1' type=Identity>, 'optimize/gradients/output/linear/dot/Reshape_1_grad/Shape': <tf.Operation 'optimize/gradients/output/linear/dot/Reshape_1_grad/Shape' type=Shape>, 'optimize/gradients/output/linear/dot/Reshape_1_grad/Reshape': <tf.Operation 'optimize/gradients/output/linear/dot/Reshape_1_grad/Reshape' type=Reshape>, 'optimize/gradients/output/linear/dot/MatMul_grad/MatMul': <tf.Operation 'optimize/gradients/output/linear/dot/MatMul_grad/MatMul' type=MatMul>, 'optimize/gradients/output/linear/dot/MatMul_grad/MatMul_1': <tf.Operation 'optimize/gradients/output/linear/dot/MatMul_grad/MatMul_1' type=MatMul>, 'optimize/gradients/output/linear/dot/MatMul_grad/tuple/group_deps': <tf.Operation 'optimize/gradients/output/linear/dot/MatMul_grad/tuple/group_deps' type=NoOp>, 'optimize/gradients/output/linear/dot/MatMul_grad/tuple/control_dependency': <tf.Operation 'optimize/gradients/output/linear/dot/MatMul_grad/tuple/control_dependency' type=Identity>, 'optimize/gradients/output/linear/dot/MatMul_grad/tuple/control_dependency_1': <tf.Operation 'optimize/gradients/output/linear/dot/MatMul_grad/tuple/control_dependency_1' type=Identity>, 'optimize/gradients/output/linear/dot/Reshape_grad/Shape': <tf.Operation 'optimize/gradients/output/linear/dot/Reshape_grad/Shape' type=Shape>, 'optimize/gradients/output/linear/dot/Reshape_grad/Reshape': <tf.Operation 'optimize/gradients/output/linear/dot/Reshape_grad/Reshape' type=Reshape>, 'optimize/gradients/ff1/activation/Relu_grad/ReluGrad': <tf.Operation 'optimize/gradients/ff1/activation/Relu_grad/ReluGrad' type=ReluGrad>, 'optimize/gradients/ff1/linear/add_bias_grad/Shape': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/Shape' type=Shape>, 'optimize/gradients/ff1/linear/add_bias_grad/Shape_1': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/Shape_1' type=Const>, 'optimize/gradients/ff1/linear/add_bias_grad/BroadcastGradientArgs': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, 'optimize/gradients/ff1/linear/add_bias_grad/Sum': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/Sum' type=Sum>, 'optimize/gradients/ff1/linear/add_bias_grad/Reshape': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/Reshape' type=Reshape>, 'optimize/gradients/ff1/linear/add_bias_grad/Sum_1': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/Sum_1' type=Sum>, 'optimize/gradients/ff1/linear/add_bias_grad/Reshape_1': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/Reshape_1' type=Reshape>, 'optimize/gradients/ff1/linear/add_bias_grad/tuple/group_deps': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/tuple/group_deps' type=NoOp>, 'optimize/gradients/ff1/linear/add_bias_grad/tuple/control_dependency': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/tuple/control_dependency' type=Identity>, 'optimize/gradients/ff1/linear/add_bias_grad/tuple/control_dependency_1': <tf.Operation 'optimize/gradients/ff1/linear/add_bias_grad/tuple/control_dependency_1' type=Identity>, 'optimize/gradients/ff1/linear/dot/Reshape_1_grad/Shape': <tf.Operation 'optimize/gradients/ff1/linear/dot/Reshape_1_grad/Shape' type=Shape>, 'optimize/gradients/ff1/linear/dot/Reshape_1_grad/Reshape': <tf.Operation 'optimize/gradients/ff1/linear/dot/Reshape_1_grad/Reshape' type=Reshape>, 'optimize/gradients/ff1/linear/dot/MatMul_grad/MatMul': <tf.Operation 'optimize/gradients/ff1/linear/dot/MatMul_grad/MatMul' type=MatMul>, 'optimize/gradients/ff1/linear/dot/MatMul_grad/MatMul_1': <tf.Operation 'optimize/gradients/ff1/linear/dot/MatMul_grad/MatMul_1' type=MatMul>, 'optimize/gradients/ff1/linear/dot/MatMul_grad/tuple/group_deps': <tf.Operation 'optimize/gradients/ff1/linear/dot/MatMul_grad/tuple/group_deps' type=NoOp>, 'optimize/gradients/ff1/linear/dot/MatMul_grad/tuple/control_dependency': <tf.Operation 'optimize/gradients/ff1/linear/dot/MatMul_grad/tuple/control_dependency' type=Identity>, 'optimize/gradients/ff1/linear/dot/MatMul_grad/tuple/control_dependency_1': <tf.Operation 'optimize/gradients/ff1/linear/dot/MatMul_grad/tuple/control_dependency_1' type=Identity>, 'optimize/GradientDescent/update_ff1/W/ApplyGradientDescent': <tf.Operation 'optimize/GradientDescent/update_ff1/W/ApplyGradientDescent' type=ApplyGradientDescent>, 'optimize/GradientDescent/update_ff1/b/ApplyGradientDescent': <tf.Operation 'optimize/GradientDescent/update_ff1/b/ApplyGradientDescent' type=ApplyGradientDescent>, 'optimize/GradientDescent/update_output/W/ApplyGradientDescent': <tf.Operation 'optimize/GradientDescent/update_output/W/ApplyGradientDescent' type=ApplyGradientDescent>, 'optimize/GradientDescent/update_output/b/ApplyGradientDescent': <tf.Operation 'optimize/GradientDescent/update_output/b/ApplyGradientDescent' type=ApplyGradientDescent>, 'optimize/GradientDescent': <tf.Operation 'optimize/GradientDescent' type=NoOp>, 'optimizer_init_vars/init_optim_slot_vars': <tf.Operation 'optimizer_init_vars/init_optim_slot_vars' type=NoOp>, 'global_train_step_increment/value': <tf.Operation 'global_train_step_increment/value' type=Const>, 'global_train_step_increment': <tf.Operation 'global_train_step_increment' type=AssignAdd>, 'optim_and_step_incr': <tf.Operation 'optim_and_step_incr' type=NoOp>, 'Merge/MergeSummary': <tf.Operation 'Merge/MergeSummary' type=MergeSummary>, 'check_uninitialized_vars/IsVariableInitialized': <tf.Operation 'check_uninitialized_vars/IsVariableInitialized' type=IsVariableInitialized>, 'check_uninitialized_vars/IsVariableInitialized_1': <tf.Operation 'check_uninitialized_vars/IsVariableInitialized_1' type=IsVariableInitialized>, 'check_uninitialized_vars/IsVariableInitialized_2': <tf.Operation 'check_uninitialized_vars/IsVariableInitialized_2' type=IsVariableInitialized>, 'check_uninitialized_vars/IsVariableInitialized_3': <tf.Operation 'check_uninitialized_vars/IsVariableInitialized_3' type=IsVariableInitialized>, 'check_uninitialized_vars/IsVariableInitialized_4': <tf.Operation 'check_uninitialized_vars/IsVariableInitialized_4' type=IsVariableInitialized>, 'check_uninitialized_vars/stack': <tf.Operation 'check_uninitialized_vars/stack' type=Pack>, 'check_uninitialized_vars/LogicalNot': <tf.Operation 'check_uninitialized_vars/LogicalNot' type=LogicalNot>, 'saver/save/filename/input': <tf.Operation 'saver/save/filename/input' type=Const>, 'saver/save/filename': <tf.Operation 'saver/save/filename' type=PlaceholderWithDefault>, 'saver/save/Const': <tf.Operation 'saver/save/Const' type=PlaceholderWithDefault>, 'saver/save/SaveV2/tensor_names': <tf.Operation 'saver/save/SaveV2/tensor_names' type=Const>, 'saver/save/SaveV2/shape_and_slices': <tf.Operation 'saver/save/SaveV2/shape_and_slices' type=Const>, 'saver/save/SaveV2': <tf.Operation 'saver/save/SaveV2' type=SaveV2>, 'saver/save/control_dependency': <tf.Operation 'saver/save/control_dependency' type=Identity>, 'saver/save/RestoreV2/tensor_names': <tf.Operation 'saver/save/RestoreV2/tensor_names' type=Const>, 'saver/save/RestoreV2/shape_and_slices': <tf.Operation 'saver/save/RestoreV2/shape_and_slices' type=Const>, 'saver/save/RestoreV2': <tf.Operation 'saver/save/RestoreV2' type=RestoreV2>, 'saver/save/Assign': <tf.Operation 'saver/save/Assign' type=Assign>, 'saver/save/Assign_1': <tf.Operation 'saver/save/Assign_1' type=Assign>, 'saver/save/Assign_2': <tf.Operation 'saver/save/Assign_2' type=Assign>, 'saver/save/Assign_3': <tf.Operation 'saver/save/Assign_3' type=Assign>, 'saver/save/Assign_4': <tf.Operation 'saver/save/Assign_4' type=Assign>, 'saver/save/restore_all': <tf.Operation 'saver/save/restore_all' type=NoOp>}`", "@manish-kumar-garg, Thank you for reporting this issue. Can you please provide the complete code to replicate the reported issue. Thanks!", "I have already added the complete code above.\r\n\r\nThis piece of code should be enough to replicate the issue\r\n```\r\nimport tensorflow as tf\r\n\r\nmodel_dir=\"./model\"   # change this line to the directory where checkpoint and models are saved\r\ncheckpoint = tf.train.get_checkpoint_state(model_dir)\r\ninput_checkpoint = checkpoint.model_checkpoint_path\r\nclear_devices = True\r\n\r\nsaver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\r\n```", "@manish-kumar-garg, tried replicating the reported issue but getting different error. Please take a look at [gist](https://colab.research.google.com/gist/gadagashwini/78a463b9216c89766a2655fb51b83bd6/untitled371.ipynb). Thanks!", "@manish-kumar-garg, Did you get a chance to look at gist. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36298, "title": "tf.keras loss/metric argument/return specification", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThis suggestion eases custom loss and custom metrics implementation restrictions. And it removes dirty/tricky codes for text/TensorBoard logging of single-output-multiple-loss-func from user application.\r\n\r\nLosses for `Model.compile()` arguments\r\n\r\n```python\r\n# current befavior\r\n\r\n# model with single output\r\nmodel.compile(.., loss=func, ..) # OK\r\nmodel.compile(.., loss=[func], ..) # OK\r\nmodel.compile(.., loss=[func1, func2], ..) # Error for single output\r\n# model with two outputs\r\nmodel.compile(.., loss=func, ..) # OK\r\nmodel.compile(.., loss=[func1_for_out1, func2_for_out2], ..) # OK\r\nmodel.compile(.., loss=[(func1_for_out1, func2_for_out1), func3_for_out2], ..) # Error\r\n```\r\n\r\n```python\r\n# behavior which I sugest\r\n\r\n# model with single output\r\nmodel.compile(.., loss=[func1, func2], ..)\r\n# OK, func1 and func2 are applied to single output with weight [1., 1.]\r\n\r\n# model with two outputs\r\nmodel.compile(.., loss=[(func1_for_out1, func2_for_out1), func3_for_out2], ..)\r\n# OK, func1 and func2 are applied to output1. func3 is applied to output2\r\n# default weight is [(1., 1.), 1.]\r\n# and joint loss is 1. * func1_for_out1(out1) + 1. * func2_for_out1(out1) + 1. * func3_for_out2(out2)\r\n```\r\n\r\nLoss function return value\r\n\r\n```python\r\n# current befavior\r\ndef my_loss_func(..):\r\n  return [loss1, loss2] # Error\r\n  return (loss1, loss2) # Error\r\n  return dict(my_loss_name1=loss1, my_loss_name2=loss2) # Error\r\n```\r\n\r\n```python\r\n# behavior which I sugest\r\n# loss function can return list or tuple\r\ndef my_loss_func(..):\r\n  return [loss1, loss2]\r\n  return (loss1, loss2)\r\n\r\nmodel.compile(.., loss=[my_loss_func], loss_weights=[1.2])\r\n# joint loss = loss1 * 1.2 / 2 + loss2 * 1.2 / 2\r\n# and loss names on logging are [my_loss_func_1, my_loss_func_2]\r\n\r\n# loss function can return dict\r\ndef my_loss_func(..):\r\n  return dict(my_loss_name1=loss1, my_loss_name2=loss2) # Error\r\n\r\nmodel.compile(.., loss=[my_loss_func], loss_weights=[1.2])\r\n# joint loss = loss1 * 1.2 / 2 + loss2 * 1.2 / 2\r\n# and loss names on logging are [my_loss_name1, my_loss_name2]\r\n```\r\n\r\nMetrics\r\n\r\n```python\r\n# current befavior\r\n# Metric function can't return list or tuple or dict in current version.\r\ndef my_metrics(..):\r\n  return [metric1, metric2] # Error\r\n  return (metric1, metric2) # Error\r\n  return dict(metric_name_1=metric1, metric_name_2=metric2) # Error\r\n```\r\n\r\n```python\r\n# behavior which I sugest\r\n# Metric function can return list or tuple or dict, and metric names are set properly.\r\ndef my_metrics(..):\r\n  return [metric1, metric2] # OK, with names [my_metrics_1, my_metrics_2]\r\n  return (metric1, metric2) # OK, with names  [my_metrics_1, my_metrics_2]\r\n  return dict(metric_name_1=metric1, metric_name_2=metric2) # OK, with names  [metric_name_1, metric_name_2]\r\n```\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo. Old codes will run without behavior changes.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nThis change benefits engineer who is using joint loss and want to log losses separately.\r\nAnd it benefits engineer who want to calculate multiple losses in single function for performance or code simplification.\r\nAnd it benefits engineer who want to calculate multiple metrics in single function for performance or code simplification.\r\n\r\n**Any Other info.**\r\n", "comments": ["@YusukeSuzuki Sorry for the late response. Are you still interested in contributing? If yes, please feel free to open a PR in  [keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository.\r\n\r\nPlease note that Keras development moved to keras-team/keras repository to focus on only keras. Thanks!\r\n\r\nIdea is good. But, currently each output is associated with a loss function. If you want to use multiple loss functions with single output, then you could write a custom loss function that uses func1 and func2.\r\n\r\nPlease feel free to open a PR in the keras-team/keras repo. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36297, "title": "I need to connect my uvc camera with the object detection application (android).", "body": "Could someone tell me how to config or where I should config?", "comments": ["@cp0418,\r\nCould you please check out the object detection guide for mobile devices from this [link](https://www.tensorflow.org/lite/models/object_detection/overview). Thanks!", "Any updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "> @cp0418,\r\n> Could you please check out the object detection guide for mobile devices from this [link](https://www.tensorflow.org/lite/models/object_detection/overview). Thanks!\r\n\r\n@amahendrakar the link u shared doesn't correspond to the questions. currently, TensorFlow demo object detection app uses Camera2 API to get a frame from the app. Hence, he is asking if it's possible to use uvc libraries to get the frame fed into the object detection model. "]}, {"number": 36296, "title": "I want to open spyder. Error show from . import (constants, error, message, context, ImportError: DLL load failed: The specified module could not be found. ", "body": "C:\\Users\\bimalgupta>spyder\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\Scripts\\spyder-script.py\", line 6, in <module>\r\n    from spyder.app.start import main\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\spyder\\app\\start.py\", line 22, in <module>\r\n    import zmq\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\__init__.py\", line 47, in <module>\r\n    from zmq import backend\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\backend\\__init__.py\", line 40, in <module>\r\n    reraise(*exc_info)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\utils\\sixcerpt.py\", line 34, in reraise\r\n    raise value\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\backend\\__init__.py\", line 27, in <module>\r\n    _ns = select_backend(first)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\backend\\select.py\", line 27, in select_backend\r\n    mod = __import__(name, fromlist=public_api)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\__init__.py\", line 6, in <module>\r\n    from . import (constants, error, message, context,\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nkindly help me.\r\n", "comments": ["@vimalkumarmdb, Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks", "@vimalkumarmdb, Please fill the issue template to analyze the issue. Thanks", "@vimalkumarmdb, From the error trace it looks like installation issue.\r\nPlease follow the steps mentioned in the [doc](https://www.tensorflow.org/install). Closing this issue as no activity. Thanks!"]}, {"number": 36295, "title": "````ruby def hello_world  puts 'Hello World!' end ````", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["````ruby\r\ndef hello_world\r\n puts 'Hello World!'\r\nend\r\n````\r\n![\u543e\u7231\u6dd8\u88c5\u4fee\u8bba\u575b _MAP-DESK-1080 (2)](https://user-images.githubusercontent.com/46779919/73330080-ad69a480-429a-11ea-9c35-f044b774e526.jpg)\r\n", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "spam issue"]}, {"number": 36294, "title": "Dyanmic Library not loading tensorflow-gpu", "body": "- OS Platform and Distribution: Zorin OS 15.1\r\n- TensorFlow installed from binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.9\r\n- Installed using pip\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: 2080ti with 11gb of gddr6\r\n\r\nSo basically I want to leverage tensorflow-gpu since my gpu has a compute capability of 7.5. I went through all the steps that are on the tensorflow gpu installation for ubuntu website and for some reason I get this sort of message: `Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory`\r\n\r\nThe steps, as mentioned before, are the same ones on the tensorflow-gpu install website: [](https://www.tensorflow.org/install/gpu)\r\n\r\nTo reproduce this, I am just using this code:\r\n`import tensorflow as tf`\r\n`print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))`\r\n\r\nThis is the full console output:\r\n`2020-01-28 21:41:28.276270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-01-28 21:41:28.277129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2020-01-28 21:41:28.595376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-01-28 21:41:28.636979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-01-28 21:41:28.637622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-01-28 21:41:28.637741: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-01-28 21:41:28.637802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-01-28 21:41:28.638713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-01-28 21:41:28.638860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-01-28 21:41:28.639785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-01-28 21:41:28.640301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-01-28 21:41:28.640321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-01-28 21:41:28.640326: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\nNum GPUs Available:  0`\r\n\r\n", "comments": ["@Broyojo, As the error says `Could not load dynamic library 'libcudart.so.10.1`, you have to install CUDA 10.1 in order to use 2.1. \r\nSimilar issue [#34759](https://github.com/tensorflow/tensorflow/issues/34759). ", "Yes it worked. For anyone wondering what I did I just ran: `sudo apt-get install cuda-10-1`", "@Broyojo, Glad that it is working.\r\nI am closing as it is resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36294\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36294\">No</a>\n"]}, {"number": 36293, "title": "Decouple RaggedStructure from RaggedTensor", "body": "**System information**\r\n- TensorFlow version (you are using): 2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI've been doing a lot of work with `RaggedTensor`s since their introduction, and one thing that irks me is that a lot of the methods (`row_lengths`, `row_starts`, `value_rowids` etc) work entirely on their row structure, and independently of the values. The memoization features of the `RaggedTensor` class is very convenient, but those memoized values aren't shared between `RaggedTensor`s that share the same row structure but have different values. As an example\r\n\r\n```python\r\nx = tf.RaggedTensor.from_row_splits(tf.range(5), [0, 2, 5])\r\ny = 2 * x\r\nprint(x.row_splits is y.row_splits)              # True\r\nprint(x.row_lengths() is y.row_lengths())  # False\r\n```\r\nA separate `RaggedStructure` class which handles memoization has two main benefits:\r\n\r\n1. Easier memoization across different `RaggedTensor`s\r\n2. Simpler interface to structure manipulation functions without `value`s\r\n\r\n**Will this change the current api? How?**\r\nThis could be done with no changes to the current API. However, minimal changes - like changing the existing `tf.RaggedTensor.__init__` method, which isn't meant to be used externally anyway - might make things simpler, and exposing a new property (`ragged_structure`) would be helpful in many cases. I would suggest something like the following.\r\n\r\n```python\r\nclass RaggedTensor(CompositeTensor):\r\n  # changed constructor, publicly usable.\r\n  def __init__(self, values, ragged_structure):\r\n    self._values = values\r\n    self._ragged_structure = ragged_structure\r\n    # error checks\r\n    ...\r\n\r\n  # added property\r\n  @property\r\n  def ragged_structure(self):\r\n    return self._ragged_structure \r\n  \r\n  # redirect row_lengths, row_starts, value_rowids etc. to structure\r\n  def row_lengths(self):\r\n    return self.ragged_structure.row_lengths()\r\n\r\n  def with_values(self, values):\r\n    return RaggedTensor(values, self.ragged_structure)\r\n\r\n# new class\r\nclass RaggedStructure(CompositeTensor):\r\n  def __init__(self, row_splits, cached_row_lengths=None, cached_value_rowids=None, cached_nrows=None, internal=False):\r\n    # most of current tf.RaggedTensor.__init__\r\n    ...\r\n\r\n  @classmethod\r\n  def from_row_lengths(cls, row_lengths):\r\n    # most of current tf.RaggedTensor.from_row_lengths\r\n    ...\r\n\r\n  # cache here\r\n  def row_lengths(self, row_lengths):\r\n    if self._cached_row_lengths is None:\r\n      ...\r\n    return self._cached_row_lengths\r\n```", "comments": ["@edloper thoughts? Happy to contribute PR if it's something that would be considered.", "Having investigated the existing `RaggedTensor` implementation further I've realized the only caching that occurs is when cached values are calculated in the factory constructor. Is there any particular reason for that?", "1. We are currently working on doing something very similar to what you suggest, motivated by the fact that row partitioning needs to be shared in StructuredTensors.  In particular, we're adding a `RowPartitioning` class that wraps the `row_splits`, `row_lengths`, etc. tensors together.\r\n\r\n2. We tried to add lazy caching of the alternative row-partitioning tensors, but had to roll it back because it breaks some assumptions made by tf.cond.  Here's [a test](https://github.com/tensorflow/tensorflow/commit/479e54cb5c7b3581ee871fe66bbed13e0c93f886) we added that fails if we cache the row_lengths lazily.\r\n\r\n", "Oo, I like `RowPartitioning` as a name better (though is the noun not `RowPartition`? Now that I think about it, does it have anything to do with rows? Isn't it just a `Partition`? Maybe that's too abstract...). Does that mean TF is looking at other sparse formats (CSR / CSC)?\r\n\r\nI'm happy to close this issue if there's work being done on it - but is there any way to track progress on that? Rename this issue and use it that way?", "@jackd,\r\nSorry for the delayed response. **`Row Partitioning`** seems to be implemented for [Ragged Tensors](https://www.tensorflow.org/guide/ragged_tensor). Can you please refer the [Documentation Guide](https://www.tensorflow.org/guide/ragged_tensor), [API Documentation](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor) for **`Ragged Tensors`** and the [Documentation of tf.io.RaggedFeature](https://www.tensorflow.org/api_docs/python/tf/io/RaggedFeature?authuser=3&skip_cache=true&hl=ko) and let us know if your **`feature`** has been implemented? Thanks!", "Not remotely - yes, it's implemented in ragged tensors, but this issue is about decoupling that implementation from everything else in ragged tensors. I've moved over to [jax](https://github.com/google/jax) so not bothered."]}, {"number": 36292, "title": "[XLA][ROCm] Disable test that invokes rocBlas TRSM", "body": "Fixing `Triangular_solve_test` by disable unit test, since `BlasTrsm` for complext type is unsupported in `rocBlas`.", "comments": []}, {"number": 36291, "title": "GFile read() terminates with no error message", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n  **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  **Windows 10 1909, 18363.592**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n  **N/A**\r\n- TensorFlow installed from (source or binary):\r\n  `pip install tensorflow-gpu`\r\n- TensorFlow version:\r\n```\r\n2020-01-28 21:39:22.550881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\nv2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n```\r\n- Python version:\r\n**Python 3.5.6**\r\n- Bazel version (if compiling from source):\r\n**N/A**\r\n- GCC/Compiler version (if compiling from source):\r\n**N/A**\r\n- CUDA/cuDNN version:\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.105\r\n```\r\n- GPU model and memory:\r\nNvidia GeForce RTX2060\r\n\r\n**Describe the current behavior**\r\n\r\nAttempting to read an existing pb file with `GFile.read()` exits abruptly the python terminal with no error message.\r\n\r\n**Describe the expected behavior**\r\n\r\nReading an existing pb file with `GFile.read()` should either terminate successfully or return an error message. \r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import gfile\r\n\r\ndetection_graph = tf.Graph()\r\nwith detection_graph.as_default():\r\n\twith tf.io.gfile.GFile(\"C:\\wrkfldr\\frozen_inference_graph.pb\", 'rb') as f:\r\n\t\tgraph_def = tf.compat.v1.GraphDef()\r\n\t\tprint(\"1\")\r\n\t\tgraph_def.ParseFromString(f.read())\r\n\t\tprint(\"2\")\r\n\t\tpersisted_sess.graph.as_default()\r\n\t\tprint(\"3\")\r\n\t\ttf.import_graph_def(graph_def)\r\n\t\tprint(\"4\")\r\n```\r\n\r\n**Other info / logs**\r\n\r\nThe script above outputs the following : \r\n```\r\n(test-tf) C:\\Users\\Me>python D:\\main.py\r\n2020-01-28 21:44:35.371550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n1\r\n```\r\n\r\nRestarting anaconda / the whole machine doesn't seem to fix the issue. \r\n\r\n`tf.test.is_gpu_available()` returns the following output\r\n\r\n```\r\n>>> tf.test.is_gpu_available()\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2020-01-28 21:46:06.878770: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-01-28 21:46:06.887260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-01-28 21:46:06.988174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.68GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-01-28 21:46:06.997651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-01-28 21:46:07.066131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-01-28 21:46:07.109559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-01-28 21:46:07.133917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-01-28 21:46:07.179636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-01-28 21:46:07.218387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-01-28 21:46:07.302231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-01-28 21:46:07.307632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-01-28 21:46:08.060601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-28 21:46:08.065979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-01-28 21:46:08.069051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-01-28 21:46:08.076616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nTrue\r\n>>>\r\n```\r\n \r\n", "comments": ["Actually, I just figured out this was failing because the path I was using didn't have escaped backslashes. \r\n\r\nThis can be closed, but I'd suggest figuring out a way to log it before it dumps. "]}, {"number": 36290, "title": "Not sufficient documentation on custom tf_lite classification model ", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36290\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36290\">No</a>\n"]}, {"number": 36289, "title": "Tensorflow 2.1 Tracing Error with Model Subclassing", "body": "I am implementing a tensorflow model using the keras subclassing api, as mentioned in a previous post here:\r\n\r\nhttps://stackoverflow.com/questions/59743161/tensorflow-model-subclassing-mutli-input\r\n\r\n\r\nI am running into an error that is slowing my entire system, where it is retracing but I cannot narrow down where this error occurs, I do not use @tf.function anywhere in my code. I am looking for support on narrowing down the location of the error or how to solve it.\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nWithout tensorflow eager execution there is constant graph retracing\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nThe exact error is:\r\n\r\n> WARNING: Logging before flag parsing goes to stderr. W0127\r\n> 15:31:00.867754 4815351232 def_function.py:586] 5 out of the last 6\r\n> calls to <function\r\n> _make_execution_function.<locals>.distributed_function at 0x157208d08> triggered tf.function retracing. Tracing is expensive and the\r\n> excessive number of tracings is likely due to passing python objects\r\n> instead of tensors. Also, tf.function has\r\n> experimental_relax_shapes=True option that relaxes argument shapes\r\n> that can avoid unnecessary retracing. Please refer to\r\n> https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args\r\n> and https://www.tensorflow.org/api_docs/python/tf/function for more\r\n> details.\r\n\r\nLooking into it further disabling eager execution is throwing this warning that may be a causing factor:\r\n\r\n\r\n> 2020-01-27 16:11:42.781884: W tensorflow/c/c_api.cc:326] Operation\r\n> '{name:'basic_parsing_model/time_distributed/bidirectional/backward_gru/while'\r\n> id:542 op device:{} def:{{{node\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while}}\r\n> = While[T=[DT_INT32, DT_INT32, DT_INT32, DT_VARIANT, DT_FLOAT, ..., DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT],\r\n> _lower_using_switch_merge=true, _num_original_outputs=52, body=basic_parsing_model_time_distributed_bidirectional_backward_gru_while_body_708[],\r\n> cond=basic_parsing_model_time_distributed_bidirectional_backward_gru_while_cond_707[],\r\n> output_shapes=[[], [], [], [], [?,32], ..., [], [], [], [], []],\r\n> parallel_iterations=32](basic_parsing_model/time_distributed/bidirectional/backward_gru/while/loop_counter, basic_parsing_model/time_distributed/bidirectional/backward_gru/while/maximum_iterations,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/time,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/TensorArrayV2_1,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/zeros,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/strided_slice_1,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/TensorArrayUnstack/TensorListFromTensor,\r\n> basic_parsing_model/time_distributed/backward_gru/bias,\r\n> basic_parsing_model/time_distributed/backward_gru/kernel,\r\n> basic_parsing_model/time_distributed/backward_gru/recurrent_kernel,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_1,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_2,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_3,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_4,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_5,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_6,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_7,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_8,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_9,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_10,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_11,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_12,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_13,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_14,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_15,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_16,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_17,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_18,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_19,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_20,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_21,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_22,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_23,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_24,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_25,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_26,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_27,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_28,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_29,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_30,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_31,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_32,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_33,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_34,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_35,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_36,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_37,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_38,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_39,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_40,\r\n> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_41)}}'\r\n> was changed by setting attribute after it was run by a session. This\r\n> mutation will have no effect, and will trigger an error in the future.\r\n> Either don't modify nodes after running them or create a new session.\r\n> 2020-01-27 16:11:46.854955: W\r\n> tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error\r\n> occurred when finalizing GeneratorDataset iterator: Cancelled:\r\n> Operation was cancelled\r\n", "comments": ["@Jbiloki,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Any updates regarding this issue? Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36288, "title": "Go API performance concerns with NewTensor & Value", "body": "The Go NewTensor call will unnecessarly incur a large number of allocations (e.g. >20,000 for a 100x100x100 tensor). There are similar issues with .Value. It's possible to work around the issue by using ReadTensor and WriteTensorTo.\r\n\r\nI'm basically wondering if a PR to fix this would stand a chance of being accepted? If there's a chance I might have a go. The 'best' fix would likely use unsafe - would the maintainers be squeamish about that?", "comments": ["@philpearl \r\nCan you please elaborate the context. Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\n\r\nPlease, provide code snippet to reproduce the issue. Thanks!\r\n", "```go\r\nfunc BenchmarkNewTensor(b *testing.B) {\r\n\tvec := make([][][]float32, 100)\r\n\tfor i := range vec {\r\n\t\tvec[i] = make([][]float32, 100)\r\n\t\tfor j := range vec[i] {\r\n\t\t\tvec[i][j] = make([]float32, 100)\r\n\t\t}\r\n\t}\r\n\tb.ReportAllocs()\r\n\tb.RunParallel(func(pb *testing.PB) {\r\n\t\tfor pb.Next() {\r\n\t\t\ttf.NewTensor(vec)\r\n\t\t}\r\n\t})\r\n}\r\n```\r\n\r\n```\r\ngoos: darwin\r\ngoarch: amd64\r\npkg: github.com/philpearl/blog/content/post\r\nBenchmarkNewTensor-16    \t     394\t   2864453 ns/op\t 4491643 B/op\t   20033 allocs/op\r\nPASS\r\nok  \tgithub.com/philpearl/blog/content/post\t1.660s\r\nSuccess: Benchmarks passed.\r\n```\r\n\r\nAlmost all of these allocations are unnecessary.\r\n\r\nI'm more wondering if you'd be interested in a contribution to improve this than looking for a fix - we're sidestepping by using ReadTensor.\r\n\r\nI think we're using tensorflow 1.13 but the problem is present in the current codebase.\r\n", "@philpearl \r\n\r\nCan you please let us know which version of TensorFlow you are facing the issue. Thanks!", "tensorflow 1.13, but I believe the issue is also present in 1.15 and v2", "Definitely open to taking fixes for this. I'm having trouble understanding the proposed fix, though. The allocations here are user-side. Are you proposing constructing the tensor and then allowing the user to directly write to it?", "In my benchmarks the allocations are downstream of encodeTensor. 50% are within binary.Write and 50% are converting the value to an interface inorder to call binary.Write\r\n\r\n<img width=\"424\" alt=\"image\" src=\"https://user-images.githubusercontent.com/456668/74087579-aa826700-4a85-11ea-9140-c5f03ecdf74d.png\">\r\n\r\nThe proposed fix is to avoid binary.Write and to copy the contents of the final slice directly into the C tensor.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 36287, "title": "keras freezing at last step in the first epoch", "body": "My model is using tf 2.0 and tf.keras 2.2.4 . When I train the model, it freezes at the last step of the first epoch. I am using :\r\n history = model.fit(\r\n     train_dataset,\r\n   epochs=EPOCHS,\r\n    steps_per_epoch=train_steps,\r\n    validation_data=valid_dataset,\r\n   validation_steps=valid_steps,\r\n )\r\nthe train_dataset and valid_dataset is of type: <class 'tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter'>\r\nPLEASE LOOK INTO THE MATTER.\r\n", "comments": ["This is likely the same issue as https://github.com/keras-team/keras/issues/8595\r\n\r\nWhen I ran into it, I noticed that if I don't supply `validation_data`, it didn't freeze.  When I supplied `validation_data`, it frozen on the last step in first epoch.", "@divyag11  Could you please provide us with simple standalone code to reproduce the issue in our environment, Thanks", "> @divyag11 Could you please provide us with simple standalone code to reproduce the issue in our environment, Thanks\r\n\r\nyes sure:\r\nthe link to colab notebook is :\r\n\r\nhttps://colab.research.google.com/drive/19Zw-8vHZhJvVkgiCTtPRo09_i356L0Pz\r\n\r\nand the train1.tsv and dev1.tsv is being\r\n\r\n[data.zip](https://github.com/tensorflow/tensorflow/files/4127232/data.zip)\r\n", "please let me know what is the issue so that it stops at the last step in the first epoch.thanks", "@jvishnuvardhan, did you find what was the cause for the issue of freezing at the last step of 1st epoch?", "> > This is likely the same issue as [keras-team/keras#8595](https://github.com/keras-team/keras/issues/8595)\r\n> > When I ran into it, I noticed that if I don't supply `validation_data`, it didn't freeze. When I supplied `validation_data`, it frozen on the last step in first epoch.\r\n\r\n\r\n> > could you come up with the reason, why it happened\r\n\r\n", "@divyag11 I could reproduce the issue with `tf-nightly`. I updated your colab to make it run. [Here](https://colab.research.google.com/gist/jvishnuvardhan/19a0e237eb539c621d9872982f378085/test.ipynb) is the updated gist for our reference. Thanks!", "@omalleyt12 do you know what's going on here?", "@alextp Yep discussed this in triage, we think it's either an issue with how the validation dataset is constructed or assumptions we are making about the validation dataset size. \r\n\r\n@jvishnuvardhan is working on a minimal repro", "@divyag11 I looked into the your data and code. I think something is wrong with the construction of validation dataset. In the code when I used `final_dataset` for training as well as validation(replacing `valid_dataset` with `final_dataset`), everything works as expected  Can you please check `valid_dataset`? Thanks!", "okay,got your point.actually what i understood is since i am calling from genertors two times,with 2 different generator functions,and according to my understanding,the 1st generator is caching and producing the trainig batches ,while the 2 nd batch is not .Is it that we can use only 1 genertor for get_form_genertor in tf?", "@divyag11 You could use two generators, one for training and one for validation. As I mentioned in my last response, I think something is wrong with the construction of validation dataset. I tried to use your validation dataset for training without any validation(without providing `validation_data` and `validation_steps` as shown below), and the code runs forever. Which means, i think there is something wrong with the construction of validation dataset.\r\n\r\n```\r\nhistory = model.fit(\r\n    valid_dataset,\r\n    epochs=EPOCHS,\r\n    steps_per_epoch=valid_steps\r\n) \r\n```\r\n\r\nYou could run my gist and check it yourself. Before running my gist, just upload your `data.zip` file to your google drive. Thanks!", "@divyag11 Is this resolved or still an issue? Please close the issue if it was already resolved. Thanks!", "yes the issue is resolved", "@divyag11 Thanks for the confirmation. I am closing this issue as it was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36287\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36287\">No</a>\n"]}, {"number": 36286, "title": "ImportError: DLL load failed:", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution :win10\r\n- TensorFlow installed from (source or binary):http://pypi.douban.com/simple\r\n- TensorFlow version:2.1.0\r\n- Python version:3.6.8\r\n- Installed using virtualenv? pip? conda?:anaconda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1.152\r\n- GPU model and memory:Geforce GTX 1060\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**after import tensorflow as tf **\r\n\r\n\r\n**Any other info / logs**\r\nTraceback (most recent call last):\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"G:/pyexercise/pyexercise7(tensor).py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"G:\\anaconda\\envs\\basecopy\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204"]}, {"number": 36285, "title": "update error checking on TensorFlow 2.0", "body": "change ImportError to AttributeError.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36285) for more info**.\n\n<!-- need_sender_cla -->", "@foldl please sign CLA and could you elaborate description of PR about new change.Thank you.", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36285) for more info**.\n\n<!-- ok -->", "I have tried `--quantize` option on r2.1 (python 3.6.10). `AttributeError` is raised instead of `ImportError`. ", "What does this mean? Do I need to do something?\r\n\r\n> import/copybara \u2014 An error happened while migrating the change"]}, {"number": 36284, "title": "Problems building TF-Lite Android Benchmark tool", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nBuild machine is an Ubuntu VM with 10GB RAM, Oracle VirtualBox on Win10.\r\nUbuntu 18.04.3 LTS\r\nkernel 5.3.0-26-generic\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTarget device - Galaxy Tab S6, Snapdragon 855. Android 9. (and others)\r\n\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.1\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have successfully converted Keras models to TF-Lite and run them in a simple Android app.\r\nNow I want to optimise performance, I really need the Benchmark tool to see what operations are being sent to which chips and how long each takes, to see whether they way I've built my models suits the devices.\r\n\r\nI can't get the benchmark tool to build. i can't get the camera demo to build either. i have tried various versions of the NDK & SDK and get a variety of errors that look like errors in the code but I'm sure it's just my build environment.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild machine is an Ubuntu VM with 10GB RAM, Oracle VirtualBox on Win10.\r\n\r\nUbuntu 18.04.3 LTS\r\nkernel 5.3.0-26-generic\r\n\r\nTarget device - Galaxy Tab S6, Snapdragon 855. Android 9. \r\n\r\nBazel version 1.2.1\r\ngcc version 7.4.0\r\n\r\nRecent install of Android Studio provides the SDK & NDK as below. (I did try NDK 14 but it didn't seem to help)\r\n\r\nCloned the TF repo. On master branch, commit d75abdf from 28th Jan 2020\r\n\r\nRan ./configure, options:\r\n\r\nPlease specify the location of python. [Default is /usr/bin/python]: - using default\r\n('which python' shows /usr/bin/python, 'python --version' shows 2.7.17)\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]  - using default\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]:  - using default\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:  - using default\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:  - using default\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:  - using default\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]:   - using default\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:   - using default\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y\r\nPlease specify the home path of the Android NDK to use. [Default is /home/medaphor/Android/Sdk/ndk-bundle]: \r\n/home/medaphor/Android/Sdk/ndk/21.0.6113669\r\nPlease specify the (min) Android NDK API level to use. [Available levels: ['16', '17', '18', '19', '21', '22', '23', '24', '26', '27', '28', '29']] [Default is 21]:  - using default\r\nPlease specify the home path of the Android SDK to use. [Default is /home/medaphor/Android/Sdk]:  - using default\r\nPlease specify the Android SDK API level to use. [Available levels: ['24', '28', '29']] [Default is 29]: - using default\r\nPlease specify an Android build tools version to use. [Available versions: ['24.0.3', '29.0.2']] [Default is 29.0.2]:   - using default\r\n\r\nThen following: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark/android\r\n(looking at the Master branch version of the doc)\r\n\r\n1st step is:\r\n(0) Refer to\u00a0https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\u00a0to edit the\u00a0WORKSPACE\u00a0to configure the android NDK/SDK.\r\n\r\nWell the configure script does that i believe. Doc is out of date? no action taken.\r\n\r\nnext step is:\r\n(1) Build for your specific platform, e.g.:\r\nbazel build -c opt \\\r\n  --config=android_arm64 \\\r\n  --cxxopt='--std=c++11' \\\r\n  tensorflow/lite/tools/benchmark/android:benchmark_model\r\n\r\nran that, and get error:\r\n\r\n\r\nERROR: /home/medaphor/tensorflow/tensorflow/lite/experimental/delegates/hexagon/BUILD:66:1: C++ compilation of rule '//tensorflow/lite/experimental/delegates/hexagon:hexagon_delegate' failed (Exit 1)\r\ntensorflow/lite/experimental/delegates/hexagon/hexagon_delegate.cc:52:32: error: no member named 'make_unique' in namespace 'std'\r\n    auto hexagon_kernel = std::make_unique<HexagonDelegateKernel>();\r\n                          ~~~~~^\r\ntensorflow/lite/experimental/delegates/hexagon/hexagon_delegate.cc:52:44: error: 'HexagonDelegateKernel' does not refer to a value\r\n    auto hexagon_kernel = std::make_unique<HexagonDelegateKernel>();\r\n                                           ^\r\n./tensorflow/lite/experimental/delegates/hexagon/hexagon_delegate_kernel.h:40:7: note: declared here\r\nclass HexagonDelegateKernel {\r\n      ^\r\ntensorflow/lite/experimental/delegates/hexagon/hexagon_delegate.cc:52:67: error: expected expression\r\n    auto hexagon_kernel = std::make_unique<HexagonDelegateKernel>();\r\n                                                                  ^\r\n\r\nUPDATE:\r\nI missed this warning:\r\n\r\nWARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 21. The major revisions supported by Bazel are [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]. Bazel will attempt to treat the NDK as if it was r20. This may cause compilation and linkage problems. Please download a supported NDK version.\r\n\r\nSo installed NDK 20.0.5594570, \r\nran configure again, \r\ndid a bazel clean --expunge,\r\nand tried to build. No more warnings but now get this error:\r\n\r\nERROR: /home/medaphor/tensorflow/tensorflow/lite/experimental/ruy/BUILD:246:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:detect_arm' failed (Exit 1)\r\ntensorflow/lite/experimental/ruy/detect_arm.cc:59:10: error: use of undeclared identifier 'getauxval'\r\n  return getauxval(AT_HWCAP) & kLocalHwcapAsimddp;\r\n         ^\r\n\r\nUPDATE:\r\n\r\nchanging to:\r\n\r\n--cxxopt='--std=c++14'\r\n\r\nfixes it. Could you please update the readme's?", "comments": ["it's fixed in 2f4812d", "Documentation updated.\r\n\r\n"]}]