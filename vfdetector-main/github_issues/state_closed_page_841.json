[{"number": 28292, "title": "TF2.0: Non-Linear Model Produces Linear Outputs", "body": "**System information**\r\n- Included is a minimal viable example of code to produce this error\r\n- OS Platform and Distribution: MacOS Mojave 10.14.4\r\n- TensorFlow installed from pypi: `pip install -q tensorflow==2.0.0-alpha0`\r\n- TensorFlow version: v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- Python version: 3.6.8\r\n\r\n**Current Behavior**\r\nI've been having a lot of trouble using tf2 to make sensible predictions for regression use cases. When I specify a model that should provide non-linear outputs, the model still provides linear outputs. I've tried a number of different ways of specifying the model such as using the keras sequential model api and specifying my own model using the keras subclassing api. I get consistent results on each. **I've shown a minimal viable example of the issue I am seeing below. **\r\n\r\n**Expected Behavior**\r\nIf specifying a non-linear model the predictions should be non-linear. For example, in the minimal viable example I provide, the model specified has 3 hidden layers with 10 units each and relu activation functions and yet produces a linear output without training. The output should, instead, be some linear function whose flexibility and smoothness is determined by the number fo hidden layers and the chosen activation function.\r\n\r\n**Code to reproduce the issue**\r\n~~~Python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense, Dropout\r\nfrom tensorflow.keras import Model\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\n\r\nN = 100\r\nx = np.random.uniform(0, 10, N)\r\ny = 0.5*x + np.random.normal(0, 2.5, N)\r\n\r\nx = x.reshape(-1, 1)\r\ny = y.reshape(-1, 1)\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Dense(10, activation='relu'),\r\n  tf.keras.layers.Dense(10, activation='relu'),\r\n  tf.keras.layers.Dense(10, activation='relu'),\r\n  tf.keras.layers.Dense(1)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='mean_squared_error')\r\n\r\n#model.fit(x, y, epochs=50, verbose=0)\r\n\r\npredictions = model(x).numpy()\r\nprint(predictions.shape)\r\n\r\nplt.scatter(x, y)\r\nplt.scatter(x, predictions)\r\nplt.show()\r\n~~~\r\n\r\n**Other info / logs**\r\n![screencapture-localhost-8888-notebooks-Untitled1-ipynb-2019-04-30-15_14_04](https://user-images.githubusercontent.com/21271116/56988332-c30c3b00-6b5d-11e9-8d59-2e1cae3bca23.png)\r\n", "comments": ["This is not an issue with tensorflow, but rather a model misspecification. "]}, {"number": 28291, "title": "Avoid sorting the list of hosts by device name as _tpu_query_system_metadata now sorts devices properly by task id.", "body": "This is needed to get the host list in the correct (non-lexicographic order)\n\nPiperOrigin-RevId: 245460584", "comments": []}, {"number": 28290, "title": "[TF Lite] Add Ruy sources to Makefile", "body": "This PR makes the Makefile makeable again.\r\n\r\nChanges:\r\n1. Add Ruy sources to the Makefile.\r\n    - The source files need to be listed separately instead of a wildcard as the flat `ruy` folder contains also tests and benchmarks that should not be in the static library (and they also have some heavy dependencies). Making a few folders in Ruy would help significantly (e.g., standard `src/`, `test/` and `tools/`).\r\n    - Continuous integration for the Makefile would be great.\r\n2. (Add platform independent aliases to the Makefile targets, similarly to what is done for `benchmark`.)\r\n\r\nIt needs to be noted that for Raspberry Pi build, it is still necessary to disable NNAPI for some reason. See #25120.", "comments": ["Adding petewarden@ for the Makefile change. jdduke@ for Ruy integration"]}, {"number": 28289, "title": "tf.print should indicate that it is printing tensor values", "body": "**System information**\r\n- TensorFlow version (you are using): nightly\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently:\r\n> tf.enable_v2_behavior()\r\n> tf.print(tf.ones([0, 5, 256]))\r\n[]\r\n\r\nPreferred (similar to numpy):\r\n> tf.enable_v2_behavior()\r\n> tf.print(tf.ones([0, 5, 256]))\r\nTensor([])\r\n\r\n**Will this change the current api? How?**\r\nNo, hopefully not. Even though the behavior is changed. \r\n\r\n**Who will benefit with this feature?**\r\nIts confusing to have tensors print their values directly and I wasted some time thinking the value I was tf.print-ing was a python list.\r\n\r\n**Any Other info.**\r\ncc @tomerk ", "comments": ["In the most recent version of TensorFlow 2.x, `print()` demonstrates the desired behavior, even though `tf.print` does not:\r\n\r\n```python\r\nprint(tf.ones([0, 5, 256]))\r\n```", "Also, just a note:\r\n\r\nIn numpy, print(array) actually prints in the form:\r\n[]\r\nInstead of in the form array([]).\r\n\r\narray([]) is just the repl form.\r\n\r\nE.g.\r\n```\r\n>>> print(np.ones((4, 5)))\r\n[[1. 1. 1. 1. 1.]\r\n [1. 1. 1. 1. 1.]\r\n [1. 1. 1. 1. 1.]\r\n [1. 1. 1. 1. 1.]]\r\n>>> np.ones((4, 5))\r\narray([[1., 1., 1., 1., 1.],\r\n       [1., 1., 1., 1., 1.],\r\n       [1., 1., 1., 1., 1.],\r\n       [1., 1., 1., 1., 1.]])\r\n```"]}, {"number": 28288, "title": "Race condition with keras model_to_estimator in distributed mode", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nWe are using distributed tensorflow as described here with ParameterServerStrategy:\r\nhttps://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate\r\n\r\nBasically we are starting the tf server on every worker and then running train_and_evaluate on each worker. The estimator function is serialized, sent to each worker and then executed to create the estimator, create the graph and start the training.\r\n\r\nThis works with standard estimator models but doesn't when using keras models with model_to_estimator \r\n(doing this still seems the advised way to do distributed learning with keras  \r\nhttps://colab.research.google.com/github/lamberta/models/blob/keras-estimator-tutorial/samples/core/tutorials/estimators/keras_estimator.ipynb)\r\n(we also tried new standalone mode without any success)\r\n\r\nSome nodes are failing with an IO error when trying to save the first checkpoint concurrently \r\nWhen creating the estimator on each worker it calls model_to_estimator on each worker which calls _save_first_checkpoint\r\nl457\r\nhttps://github.com/tensorflow/estimator/blob/1d55f01d8af871a35ef83fc3354b9feaa671cbe1/tensorflow_estimator/python/estimator/keras.py\r\n\r\n**Describe the expected behavior**\r\n\r\nBeing able to train Keras model in distributed mode.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nBasically we are executing this code on each worker:\r\n```\r\ndef estimator_fn():\r\n  estimator = tf.keras.estimator.model_to_estimator(model, config=config)\r\n  return estimator\r\n\r\non each worker:\r\ntf.estimator.train_and_evaluate(\r\n    estimator_fn(),\r\n    train_spec,\r\n    eval_spec\r\n)\r\n```\r\nFull code example is here:\r\nhttps://github.com/criteo/tf-yarn/blob/master/examples/keras_example.py\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nStacktrace of failure:\r\nTraceback (most recent call last):                                                                                                                                                                                                             File \"../_task_commons.py\", line 59, in _get_experiment                experiment = dill.loads(client.kv.wait(KV_EXPERIMENT_FN))()                                                                                                                                                                                File \"../__init__.py\", line 233, in _new_experiment_fn                                                                                                                                                File \"keras_example.py\", line 76, in experiment_fn                                                                                                                                                                                           File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/estimator/keras.py\", line 484, in model_to_estimator                                                                                                                                                                                                               config)                                                                                                                                                                                                                                    File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/estimator/keras.py\", line 367, in _save_first_checkpoint                                                                                                                                                                                                           saver.save(sess, latest_path)                                                                                                                                                                                                              File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/training/saver.py\", line 1441, in save                                                                                                                                                                                                                             {self.saver_def.filename_tensor_name: checkpoint_file})                                                                                                                                                                                    File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/client/session.py\", line 929, in run                                                                                                                                                                                                                               run_metadata_ptr)                                                                                                                                                                                                                          File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/client/session.py\", line 1152, in _run                                                                                                                                                                                                                             feed_dict_tensor, options, run_metadata)                                                                                                                                                                                                   File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/client/session.py\", line 1328, in _do_run                                                                                                                                                                                                                          run_metadata)                                                                                                                                                                                                                              File \"/tmp/347e8353-e113-45e6-bc3a-a89be4f9788a/install/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl.e0ceba8cc1b266d3356296be2708e12fb322668e/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl/tensorflow/python/client/session.py\", line 1348, in _do_call                                                                                                                                                                                                                         raise type(e)(node_def, op, message)                                                                                                                                                                                                     tensorflow.python.framework.errors_impl.UnknownError: viewfs://root/../keras/keras_model.ckpt.index.tempstate16835974976294242898; Input/output error                                                      [[node save/SaveV2 (defined at keras_example.py:76)  = SaveV2[dtypes=[DT_FLOAT, DT_INT64, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, SGD/decay/Read/ReadVariableOp, SGD/iterations/Read/ReadVariableOp, SGD/lr/Read/ReadVariableOp, SGD/momentum/Read/ReadVariableOp, dense/bias/Read/ReadVariableOp, dense/kernel/Read/ReadVariableOp, dense_1/bias/Read/ReadVariableOp, dense_1/kernel/Read/ReadVariableOp, dense_2/bias/Read/ReadVariableOp, dense_2/kernel/Read/ReadVariableOp, global_step, training/SGD/Variable/Read/ReadVariableOp, training/SGD/Variable_1/Read/ReadVariableOp, training/SGD/Variable_2/Read/ReadVariableOp, training/SGD/Variable_3/Read/ReadVariableOp, training/SGD/Variable_4/Read/ReadVariableOp, training/SGD/Variable_5/Read/ReadVariableOp)]]\r\n", "comments": ["omalleyt@ -- can you take a look?", "This code seems to do model_to_estimator in each worker, which will have the concurrent issue. Instead why not use model_to_estimator locally, and then train_and_evaluate using the right cluster config, i.e., let estimator do the right replication?", "@tanzhenyu \r\nI didn't manage to make keras + model_to_estimator work with standalone mode (nor only keras).\r\nFinally what I do is to call the model_to_estimator once locally to create the checkpoint and then start learning (https://github.com/criteo/tf-yarn/blob/master/examples/keras_example.py#L93)\r\n\r\nIt works. Workaround is good enough. So you can close this as won't fix.\r\n", "Yeah that seems to be the right way to do it. In general we only allow one machine to write checkpoint to prevent race condition, that's probably true in synchronous training as well.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28288\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28288\">No</a>\n"]}, {"number": 28287, "title": "At Runtime : \"Error while reading resource variable softmax/kernel from Container: localhost\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, found here (https://github.com/viaboxxsystems/deeplearning-showcase/blob/tensorflow_2.0/flaskApp.py)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MAC OSX 10.14.4\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: Python 3.6.5\r\n\r\nYou can collect some of this information using our environment capture\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\nv1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n\r\n**Describe the current behavior**\r\nwhen running \"flaskApp.py\", After loading the model and trying to classify an image using \"predict\", it fails with the error:\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable softmax/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/softmax/kernel/N10tensorflow3VarE does not exist.\r\n\r\n**Describe the expected behavior**\r\na result of image classification should be returned.\r\n\r\n**Code to reproduce the issue**\r\nSteps to reproduce:\r\n- `git clone https://github.com/viaboxxsystems/deeplearning-showcase.git`\r\n- `git checkout tensorflow_2.0`\r\n- (if needed) `pip3 install -r requirements.txt`\r\n- `export FLASK_APP=flaskApp.py`\r\n- start the app with `flask run`\r\n- using Postman or curl send any image of a dog or cat to the app\r\n![Screenshot 2019-04-30 at 16 10 57](https://user-images.githubusercontent.com/38561624/56967975-93abfd00-6b62-11e9-9de0-ef99356f8db4.png)\r\n OR \r\n```\r\ncurl -X POST \\\r\n  http://localhost:5000/net/MobileNet \\\r\n  -H 'Postman-Token: ea35b79b-b34d-4be1-a80c-505c104050ec' \\\r\n  -H 'cache-control: no-cache' \\\r\n  -H 'content-type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW' \\\r\n  -F image=@/Users/haitham.b/Projects/ResearchProjects/CNNs/deeplearning-showcase/data/sample/valid/dogs/dog.1008.jpg\r\n```\r\n\r\n**Other info / logs**\r\n\r\n\r\n```\r\nE0430 13:36:10.374372 123145501933568 app.py:1761] Exception on /net/MobileNet [POST]\r\nTraceback (most recent call last):\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 2292, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1815, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1718, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/_compat.py\", line 35, in reraise\r\n    raise value\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1813, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1799, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/Users/haitham.b/Projects/Virtualenvs/deeplearning-showcase/flaskApp.py\", line 97, in use_net_to_classify_image\r\n    prediction, prob = predict(net_name, image)\r\n  File \"/Users/haitham.b/Projects/Virtualenvs/deeplearning-showcase/flaskApp.py\", line 59, in predict\r\n    output_probability = net_models[cnn_name].predict(post_processed_input_images)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1167, in predict\r\n    callbacks=callbacks)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 352, in model_iteration\r\n    batch_outs = f(ins_batch)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3096, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1440, in __call__\r\n    run_metadata_ptr)\r\n  File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 548, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable softmax/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/softmax/kernel/N10tensorflow3VarE does not exist.\r\n\t [[{{node softmax/MatMul/ReadVariableOp}}]]\r\n```", "comments": ["Any updates on this?", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n```python\r\nfrom tensorflow.python.keras.backend import set_session\r\nfrom tensorflow.python.keras.models import load_model\r\n\r\ntf_config = some_custom_config\r\nsess = tf.Session(config=tf_config)\r\ngraph = tf.get_default_graph()\r\n\r\n# IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n# Otherwise, their weights will be unavailable in the threads after the session there has been set\r\nset_session(sess)\r\nmodel = load_model(...)\r\n``` \r\nand then in each request (i.e. in each thread):\r\n```python\r\nglobal sess\r\nglobal graph\r\nwith graph.as_default():\r\n    set_session(sess)\r\n    model.predict(...)\r\n```", "> I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> \r\n> ```python\r\n> from tensorflow.python.keras.backend import set_session\r\n> from tensorflow.python.keras.models import load_model\r\n> \r\n> tf_config = some_custom_config\r\n> sess = tf.Session(config=tf_config)\r\n> graph = tf.get_default_graph()\r\n> \r\n> # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> set_session(sess)\r\n> model = load_model(...)\r\n> ```\r\n> \r\n> and then in each request (i.e. in each thread):\r\n> \r\n> ```python\r\n> global sess\r\n> global graph\r\n> with graph.as_default():\r\n>     set_session(sess)\r\n>     model.predict(...)\r\n> ```\r\n\r\nYou are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?", "> > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > ```python\r\n> > from tensorflow.python.keras.backend import set_session\r\n> > from tensorflow.python.keras.models import load_model\r\n> > \r\n> > tf_config = some_custom_config\r\n> > sess = tf.Session(config=tf_config)\r\n> > graph = tf.get_default_graph()\r\n> > \r\n> > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > set_session(sess)\r\n> > model = load_model(...)\r\n> > ```\r\n> > \r\n> > \r\n> > and then in each request (i.e. in each thread):\r\n> > ```python\r\n> > global sess\r\n> > global graph\r\n> > with graph.as_default():\r\n> >     set_session(sess)\r\n> >     model.predict(...)\r\n> > ```\r\n> \r\n> You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n\r\nThank you and you are very welcome :). \r\n\r\nAs far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.", "Closing this out since I understand it to be resolved, but please let me know if I'm mistaken. Thanks!", "\r\n> > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > ```python\r\n> > > from tensorflow.python.keras.backend import set_session\r\n> > > from tensorflow.python.keras.models import load_model\r\n> > > \r\n> > > tf_config = some_custom_config\r\n> > > sess = tf.Session(config=tf_config)\r\n> > > graph = tf.get_default_graph()\r\n> > > \r\n> > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > set_session(sess)\r\n> > > model = load_model(...)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > and then in each request (i.e. in each thread):\r\n> > > ```python\r\n> > > global sess\r\n> > > global graph\r\n> > > with graph.as_default():\r\n> > >     set_session(sess)\r\n> > >     model.predict(...)\r\n> > > ```\r\n> > \r\n> > \r\n> > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> \r\n> Thank you and you are very welcome :).\r\n> \r\n> As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n\r\nI have the same issue with tensor flow version 1.13.1, the above solution works for me.", "I am having the same issues and was wondering what the value of some_custom_config was?", "> I am having the same issues and was wondering what the value of some_custom_config was?\r\n\r\nIn case you want to configure your session (which I had to do), you can pass the config in this parameter. Else just leave it out.", "> > I am having the same issues and was wondering what the value of some_custom_config was?\r\n> \r\n> In case you want to configure your session (which I had to do), you can pass the config in this parameter. Else just leave it out.\r\n\r\nThank you so much! Everything is running perfectly now. ", "Thanks for providing the codes. I ran into similar error message while running BERT on Kera. I tried your solution but can't seem to get it to work.  Any guidance is most appreciated! \r\n\r\n```FailedPreconditionError                   Traceback (most recent call last)\r\n<ipython-input-42-dc70f6f3f83d> in <module>()\r\n     11     validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\r\n     12     epochs=1,\r\n---> 13     batch_size=32\r\n     14 )\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)\r\n   1456         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1457                                                self._handle, args,\r\n-> 1458                                                run_metadata_ptr)\r\n   1459         if run_metadata:\r\n   1460           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nFailedPreconditionError: Error while reading resource variable bert_layer_9_module/bert/encoder/layer_3/output/LayerNorm/gamma from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bert_layer_9_module/bert/encoder/layer_3/output/LayerNorm/gamma/N10tensorflow3VarE does not exist.\r\n\t [[{{node bert_layer_9/bert_layer_9_module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul/ReadVariableOp}}]]```", "I have a similar error when using Elmo embeddings from tf-hub inside a custom keras layer.\r\n\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.\r\n  (0) Failed precondition: Error while reading resource variable ElmoEmbeddingLayer_module/bilm/CNN_high_0/b_carry from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/ElmoEmbeddingLayer_module/bilm/CNN_high_0/b_carry/class tensorflow::Var does not exist.\r\n\t [[{{node ElmoEmbeddingLayer/ElmoEmbeddingLayer_module_apply_default/bilm/add/ReadVariableOp}}]]\r\n  (1) Failed precondition: Error while reading resource variable ElmoEmbeddingLayer_module/bilm/CNN_high_0/b_carry from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/ElmoEmbeddingLayer_module/bilm/CNN_high_0/b_carry/class tensorflow::Var does not exist.\r\n\t [[{{node ElmoEmbeddingLayer/ElmoEmbeddingLayer_module_apply_default/bilm/add/ReadVariableOp}}]]\r\n\t [[metrics/acc/Identity/_199]]\r\n0 successful operations.\r\n0 derived errors ignored.", "> > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > ```python\r\n> > > from tensorflow.python.keras.backend import set_session\r\n> > > from tensorflow.python.keras.models import load_model\r\n> > > \r\n> > > tf_config = some_custom_config\r\n> > > sess = tf.Session(config=tf_config)\r\n> > > graph = tf.get_default_graph()\r\n> > > \r\n> > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > set_session(sess)\r\n> > > model = load_model(...)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > and then in each request (i.e. in each thread):\r\n> > > ```python\r\n> > > global sess\r\n> > > global graph\r\n> > > with graph.as_default():\r\n> > >     set_session(sess)\r\n> > >     model.predict(...)\r\n> > > ```\r\n> > \r\n> > \r\n> > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> \r\n> Thank you and you are very welcome :).\r\n> \r\n> As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n\r\nThank you so much for this.\r\n\r\nIn my case I did it a bit differently, in case it helps anyone:\r\n```python\r\n# on thread 1\r\nsession = tf.Session(graph=tf.Graph())\r\nwith session.graph.as_default():\r\n    k.backend.set_session(session)\r\n    model = k.models.load_model(filepath)\r\n\r\n# on thread 2\r\nwith session.graph.as_default():\r\n    k.backend.set_session(session)\r\n    model.predict(x, **kwargs)\r\n```\r\n\r\nThe novelty here is allowing for multiple models to be loaded (once) and used in multiple threads.\r\nBy default, the \"default\" `Session` and the \"default\" `Graph` are used while loading a model.\r\nBut here you create new ones.\r\nAlso note the `Graph` is stored in the `Session` object, which is a bit more convenient.", "> > > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > > ```python\r\n> > > > from tensorflow.python.keras.backend import set_session\r\n> > > > from tensorflow.python.keras.models import load_model\r\n> > > > \r\n> > > > tf_config = some_custom_config\r\n> > > > sess = tf.Session(config=tf_config)\r\n> > > > graph = tf.get_default_graph()\r\n> > > > \r\n> > > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > > set_session(sess)\r\n> > > > model = load_model(...)\r\n> > > > ```\r\n> > > > \r\n> > > > \r\n> > > > and then in each request (i.e. in each thread):\r\n> > > > ```python\r\n> > > > global sess\r\n> > > > global graph\r\n> > > > with graph.as_default():\r\n> > > >     set_session(sess)\r\n> > > >     model.predict(...)\r\n> > > > ```\r\n> > > \r\n> > > \r\n> > > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> > \r\n> > \r\n> > Thank you and you are very welcome :).\r\n> > As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n> \r\n> Thank you so much for this.\r\n> \r\n> In my case I did it a bit differently, in case it helps anyone:\r\n> \r\n> ```python\r\n> # on thread 1\r\n> session = tf.Session(graph=tf.Graph())\r\n> with session.graph.as_default():\r\n>     k.backend.set_session(session)\r\n>     model = k.models.load_model(filepath)\r\n> \r\n> # on thread 2\r\n> with session.graph.as_default():\r\n>     k.backend.set_session(session)\r\n>     model.predict(x, **kwargs)\r\n> ```\r\n> \r\n> The novelty here is allowing for multiple models to be loaded (once) and used in multiple threads.\r\n> By default, the \"default\" `Session` and the \"default\" `Graph` are used while loading a model.\r\n> But here you create new ones.\r\n> Also note the `Graph` is stored in the `Session` object, which is a bit more convenient.\r\n\r\nThank you for this answer\r\nI am also facing this problem when using flask and multithreading, @eliadl Your solution worked for me.\r\n\r\nThanks :smiley: ", "> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, found here (https://github.com/viaboxxsystems/deeplearning-showcase/blob/tensorflow_2.0/flaskApp.py)\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MAC OSX 10.14.4\r\n> * TensorFlow version (use command below): 2.0.0-alpha0\r\n> * Python version: Python 3.6.5\r\n> \r\n> You can collect some of this information using our environment capture\r\n> python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n> v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n> \r\n> **Describe the current behavior**\r\n> when running \"flaskApp.py\", After loading the model and trying to classify an image using \"predict\", it fails with the error:\r\n> \r\n> > tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable softmax/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/softmax/kernel/N10tensorflow3VarE does not exist.\r\n> \r\n> **Describe the expected behavior**\r\n> a result of image classification should be returned.\r\n> \r\n> **Code to reproduce the issue**\r\n> Steps to reproduce:\r\n> \r\n> * `git clone https://github.com/viaboxxsystems/deeplearning-showcase.git`\r\n> * `git checkout tensorflow_2.0`\r\n> * (if needed) `pip3 install -r requirements.txt`\r\n> * `export FLASK_APP=flaskApp.py`\r\n> * start the app with `flask run`\r\n> * using Postman or curl send any image of a dog or cat to the app\r\n>   ![Screenshot 2019-04-30 at 16 10 57](https://user-images.githubusercontent.com/38561624/56967975-93abfd00-6b62-11e9-9de0-ef99356f8db4.png)\r\n>   OR\r\n> \r\n> ```\r\n> curl -X POST \\\r\n>   http://localhost:5000/net/MobileNet \\\r\n>   -H 'Postman-Token: ea35b79b-b34d-4be1-a80c-505c104050ec' \\\r\n>   -H 'cache-control: no-cache' \\\r\n>   -H 'content-type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW' \\\r\n>   -F image=@/Users/haitham.b/Projects/ResearchProjects/CNNs/deeplearning-showcase/data/sample/valid/dogs/dog.1008.jpg\r\n> ```\r\n> \r\n> **Other info / logs**\r\n> \r\n> ```\r\n> E0430 13:36:10.374372 123145501933568 app.py:1761] Exception on /net/MobileNet [POST]\r\n> Traceback (most recent call last):\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 2292, in wsgi_app\r\n>     response = self.full_dispatch_request()\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1815, in full_dispatch_request\r\n>     rv = self.handle_user_exception(e)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1718, in handle_user_exception\r\n>     reraise(exc_type, exc_value, tb)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/_compat.py\", line 35, in reraise\r\n>     raise value\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1813, in full_dispatch_request\r\n>     rv = self.dispatch_request()\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/flask/app.py\", line 1799, in dispatch_request\r\n>     return self.view_functions[rule.endpoint](**req.view_args)\r\n>   File \"/Users/haitham.b/Projects/Virtualenvs/deeplearning-showcase/flaskApp.py\", line 97, in use_net_to_classify_image\r\n>     prediction, prob = predict(net_name, image)\r\n>   File \"/Users/haitham.b/Projects/Virtualenvs/deeplearning-showcase/flaskApp.py\", line 59, in predict\r\n>     output_probability = net_models[cnn_name].predict(post_processed_input_images)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1167, in predict\r\n>     callbacks=callbacks)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 352, in model_iteration\r\n>     batch_outs = f(ins_batch)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3096, in __call__\r\n>     run_metadata=self.run_metadata)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1440, in __call__\r\n>     run_metadata_ptr)\r\n>   File \"/Users/haitham.b/venv/tensorflow2.0alpha/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 548, in __exit__\r\n>     c_api.TF_GetCode(self.status.status))\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable softmax/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/softmax/kernel/N10tensorflow3VarE does not exist.\r\n> \t [[{{node softmax/MatMul/ReadVariableOp}}]]\r\n> ```\r\n\r\nI am also facing this issue\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense_6/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/dense_6/kernel/class tensorflow::Var does not exist.\r\n         [[{{node dense_6/MatMul/ReadVariableOp}}]]", "sorry,I am also facing this issue. But your answer doesn't fix my problem maybe it's in different condition. In my problem, It is when I use VGG16 in keras and I want to use iterate funtion\r\n`loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])`\r\nBut this similar question occured.\r\n**FailedPreconditionError: Error while reading resource variable block1_conv1_12/bias from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/block1_conv1_12/bias/N10tensorflow3VarE does not exist.\r\n\t [[{{node block1_conv1_12/BiasAdd/ReadVariableOp}}]]**\r\nIn [https://github.com/JarvisUSTC/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb](url), the problem didn't encounter.\r\n![image](https://user-images.githubusercontent.com/35248101/74001019-05905d00-49a5-11ea-9f40-172a9385ace8.png)\r\n```python3\r\nfrom tensorflow.python.keras.backend import set_session\r\nfrom tensorflow.python.keras.models import load_model\r\nfrom tensorflow.python.keras.applications import VGG16\r\n\r\nsess = tf.Session()\r\ngraph = tf.get_default_graph()\r\n\r\nset_session(sess)\r\n\r\n#model = load_model('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\r\nmodel = VGG16(weights='imagenet',include_top=False)\r\n\r\nlayer_name = 'block3_conv1'\r\nfilter_index = 0\r\n\r\nlayer_output = model.get_layer(layer_name).output\r\nloss = K.mean(layer_output[:, :, :, filter_index])\r\ngrads = K.gradients(loss, model.input)[0]\r\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\r\n\r\nimport numpy as np\r\nglobal sess\r\nglobal graph\r\nwith graph.as_default():\r\n    set_session(sess)\r\n    iterate = K.function([model.input], [loss, grads])\r\n    loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])\r\n```\r\n![image](https://user-images.githubusercontent.com/35248101/74001034-104af200-49a5-11ea-85dc-4d96af04887a.png)\r\n", "> > > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > > ```python\r\n> > > > from tensorflow.python.keras.backend import set_session\r\n> > > > from tensorflow.python.keras.models import load_model\r\n> > > > \r\n> > > > tf_config = some_custom_config\r\n> > > > sess = tf.Session(config=tf_config)\r\n> > > > graph = tf.get_default_graph()\r\n> > > > \r\n> > > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > > set_session(sess)\r\n> > > > model = load_model(...)\r\n> > > > ```\r\n> > > > \r\n> > > > \r\n> > > > and then in each request (i.e. in each thread):\r\n> > > > ```python\r\n> > > > global sess\r\n> > > > global graph\r\n> > > > with graph.as_default():\r\n> > > >     set_session(sess)\r\n> > > >     model.predict(...)\r\n> > > > ```\r\n> > > \r\n> > > \r\n> > > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> > \r\n> > \r\n> > Thank you and you are very welcome :).\r\n> > As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n> \r\n> I have the same issue with tensor flow version 1.13.1, the above solution works for me.\r\n\r\nThis solution worked for me as well.. Thanks @eliadl", "@SungmanHong instead of `tf.Session` try to use [`tf.compat.v1.Session`](https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session).", "> In TF 2.x, there is no session(). how do I fix it? same problem is happening in my TF 2.x code.\r\n\r\nimport session in TF 2.X\r\n`tf.compat.v1.Session()`\r\nimport keras.backend.get_session in TF 2.X\r\n`tf.compat.v1.keras.backend.get_session()`\r\n", "> \r\n> \r\n> I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> \r\n> ```python\r\n> from tensorflow.python.keras.backend import set_session\r\n> from tensorflow.python.keras.models import load_model\r\n> \r\n> tf_config = some_custom_config\r\n> sess = tf.Session(config=tf_config)\r\n> graph = tf.get_default_graph()\r\n> \r\n> # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> set_session(sess)\r\n> model = load_model(...)\r\n> ```\r\n> \r\n> and then in each request (i.e. in each thread):\r\n> \r\n> ```python\r\n> global sess\r\n> global graph\r\n> with graph.as_default():\r\n>     set_session(sess)\r\n>     model.predict(...)\r\n> ```\r\n\r\nThis worked for me , thanks ", "> I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> \r\n> ```python\r\n> from tensorflow.python.keras.backend import set_session\r\n> from tensorflow.python.keras.models import load_model\r\n> \r\n> tf_config = some_custom_config\r\n> sess = tf.Session(config=tf_config)\r\n> graph = tf.get_default_graph()\r\n> \r\n> # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> set_session(sess)\r\n> model = load_model(...)\r\n> ```\r\n> \r\n> and then in each request (i.e. in each thread):\r\n> \r\n> ```python\r\n> global sess\r\n> global graph\r\n> with graph.as_default():\r\n>     set_session(sess)\r\n>     model.predict(...)\r\n> ```\r\n\r\nMan you are genius and awesome , you just saved my project , Thank you so muuch", "> > In TF 2.x, there is no session(). how do I fix it? same problem is happening in my TF 2.x code.\r\n> \r\n> import session in TF 2.X\r\n> `tf.compat.v1.Session()`\r\n> import keras.backend.get_session in TF 2.X\r\n> `tf.compat.v1.keras.backend.get_session()`\r\n\r\nI have used the given solution but didn't work for me still, I'm getting the error\r\n\r\n```The graph tensor has name: anchors/Variable:0\r\n/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\r\n  UserWarning('Using a generator with `use_multiprocessing=True`'\r\nEpoch 1/4\r\n---------------------------------------------------------------------------\r\nFailedPreconditionError                   Traceback (most recent call last)\r\n<ipython-input-13-05f25cba3043> in <module>()\r\n      4             learning_rate=config.LEARNING_RATE,\r\n      5             epochs=4,\r\n----> 6             layers='heads')\r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/mrcnn/model.py in train(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\r\n   2350             max_queue_size=100,\r\n   2351             workers=workers,\r\n-> 2352             use_multiprocessing=True,\r\n   2353         )\r\n   2354         self.epoch = max(self.epoch, epochs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)\r\n     89                 warnings.warn('Update your `' + object_name + '` call to the ' +\r\n     90                               'Keras 2 API: ' + signature, stacklevel=2)\r\n---> 91             return func(*args, **kwargs)\r\n     92         wrapper._original_function = func\r\n     93         return wrapper\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1730             use_multiprocessing=use_multiprocessing,\r\n   1731             shuffle=shuffle,\r\n-> 1732             initial_epoch=initial_epoch)\r\n   1733 \r\n   1734     @interfaces.legacy_generator_methods_support\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n    218                                             sample_weight=sample_weight,\r\n    219                                             class_weight=class_weight,\r\n--> 220                                             reset_metrics=False)\r\n    221 \r\n    222                 outs = to_list(outs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)\r\n   1512             ins = x + y + sample_weights\r\n   1513         self._make_train_function()\r\n-> 1514         outputs = self.train_function(ins)\r\n   1515 \r\n   1516         if reset_metrics:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in __call__(self, inputs)\r\n   3630 \r\n   3631     fetched = self._callable_fn(*array_vals,\r\n-> 3632                                 run_metadata=self.run_metadata)\r\n   3633     self._call_fetch_callbacks(fetched[-len(self._fetches):])\r\n   3634     output_structure = nest.pack_sequence_as(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)\r\n   1470         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1471                                                self._handle, args,\r\n-> 1472                                                run_metadata_ptr)\r\n   1473         if run_metadata:\r\n   1474           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nFailedPreconditionError: Error while reading resource variable anchors/Variable from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/anchors/Variable/N10tensorflow3VarE does not exist.\r\n\t [[{{node ROI/ReadVariableOp}}]] ```\r\n\r\n\r\n**PLEASE HELP!!!**", "> > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > ```python\r\n> > > from tensorflow.python.keras.backend import set_session\r\n> > > from tensorflow.python.keras.models import load_model\r\n> > > \r\n> > > tf_config = some_custom_config\r\n> > > sess = tf.Session(config=tf_config)\r\n> > > graph = tf.get_default_graph()\r\n> > > \r\n> > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > set_session(sess)\r\n> > > model = load_model(...)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > and then in each request (i.e. in each thread):\r\n> > > ```python\r\n> > > global sess\r\n> > > global graph\r\n> > > with graph.as_default():\r\n> > >     set_session(sess)\r\n> > >     model.predict(...)\r\n> > > ```\r\n> > \r\n> > \r\n> > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> \r\n> Thank you and you are very welcome :).\r\n> \r\n> As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n\r\nPls it's showing some_custom_config not defined", "Pls it's showing some_custom_config not defined", "> I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> \r\n> ```python\r\n> from tensorflow.python.keras.backend import set_session\r\n> from tensorflow.python.keras.models import load_model\r\n> \r\n> tf_config = some_custom_config\r\n> sess = tf.Session(config=tf_config)\r\n> graph = tf.get_default_graph()\r\n> \r\n> # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> set_session(sess)\r\n> model = load_model(...)\r\n> ```\r\n> \r\n> and then in each request (i.e. in each thread):\r\n> \r\n> ```python\r\n> global sess\r\n> global graph\r\n> with graph.as_default():\r\n>     set_session(sess)\r\n>     model.predict(...)\r\n> ```\r\n\r\nwork's for me, thanks!!", "Am I correct that the only way to solve this issue in TF2 is to disable eager execution?", "> > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > ```python\r\n> > > from tensorflow.python.keras.backend import set_session\r\n> > > from tensorflow.python.keras.models import load_model\r\n> > > \r\n> > > tf_config = some_custom_config\r\n> > > sess = tf.Session(config=tf_config)\r\n> > > graph = tf.get_default_graph()\r\n> > > \r\n> > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > set_session(sess)\r\n> > > model = load_model(...)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > and then in each request (i.e. in each thread):\r\n> > > ```python\r\n> > > global sess\r\n> > > global graph\r\n> > > with graph.as_default():\r\n> > >     set_session(sess)\r\n> > >     model.predict(...)\r\n> > > ```\r\n> > \r\n> > \r\n> > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> \r\n> Thank you and you are very welcome :).\r\n> \r\n> As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n\r\nHi, I am using tensorflow2.4.1 and getting similar error.. Below is my code & error. Can you help?\r\n\r\nCode pasted on stack overflow:\r\n\r\n[https://stackoverflow.com/questions/67575144/error-while-reading-resource-variable-encoder-conv2-1-b-from-container-localhos](url)\r\n\r\n", "> ```python\r\n> from tensorflow.python.keras.backend import set_session\r\n> from tensorflow.python.keras.models import load_model\r\n> ```\r\n\r\nHi brother , I have same problem in this : can be solve it ?\r\nhttps://stackoverflow.com/questions/67659336/tensor-tensorflatten-reshape0-shape-2622-dtype-float32-is-not-an-ele", "tf 2.5 please any solution ? \r\nI've disabled the eager mode but am still getting the same error\r\n", "> > > I had the same issue in tensorflow 1.13.1 which I have resolved by creating a reference to the session that is used for loading the models and then to set it to be used by keras in each request. I.e. I have done the following:\r\n> > > ```python\r\n> > > from tensorflow.python.keras.backend import set_session\r\n> > > from tensorflow.python.keras.models import load_model\r\n> > > \r\n> > > tf_config = some_custom_config\r\n> > > sess = tf.Session(config=tf_config)\r\n> > > graph = tf.get_default_graph()\r\n> > > \r\n> > > # IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n> > > # Otherwise, their weights will be unavailable in the threads after the session there has been set\r\n> > > set_session(sess)\r\n> > > model = load_model(...)\r\n> > > ```\r\n> > > \r\n> > > \r\n> > >     \r\n> > >       \r\n> > >     \r\n> > > \r\n> > >       \r\n> > >     \r\n> > > \r\n> > >     \r\n> > >   \r\n> > > and then in each request (i.e. in each thread):\r\n> > > ```python\r\n> > > global sess\r\n> > > global graph\r\n> > > with graph.as_default():\r\n> > >     set_session(sess)\r\n> > >     model.predict(...)\r\n> > > ```\r\n> > \r\n> > \r\n> > You are amazing!!!!! This is the best solution. Can you tell me why did it just work after adding session?\r\n> \r\n> Thank you and you are very welcome :).\r\n> \r\n> As far as I understand, the problem is that tensorflow graphs and sessions are not thread safe. So by default a new session (which does not contain any previously loaded weights, models a.s.o.) is created for each thread, i.e. for each request. By saving the global session that contains all your models and setting it to be used by keras in each thread the problem is solved.\r\n\r\nthanks for your answer, Im having problems particularly, using tf 1.14.\r\nstill getting this error when trying to run 2 different models one after the other.\r\nI get the error in model.fit. I paid attention to the fact that if Im not passing tensorboard callback the error is gone.\r\n\r\nAnyone has an idea what it could be?", "from tensorflow.python.keras.backend import set_session\r\nfrom tensorflow.python.keras.models import load_model\r\n\r\ntf_config = some_custom_config\r\nsess = tf.Session(config=tf_config)\r\ngraph = tf.get_default_graph()\r\n\r\n# IMPORTANT: models have to be loaded AFTER SETTING THE SESSION for keras! \r\n# Otherwise, their weights will be unavailable in the threads after the session there has been set\r\nset_session(sess)\r\nmodel = load_model(...)\r\nand then in each request (i.e. in each thread):\r\n\r\nglobal sess\r\nglobal graph\r\nwith graph.as_default():\r\n    set_session(sess)\r\n    model.predict(...)\r\n"]}, {"number": 28286, "title": "[ROCm] Fix for the broken `--config=rocm` build.", "body": "Note: This ia a different PR from PRs #28189 and #28263 (same symptom, different cause and fix)\r\n\r\nThe `--config=rocm` build was broken by the following commit.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/481748b5c92d217dd1b10725ce259ba8c7086df0\r\n\r\nThe changes made by the above commit had one bug in the changes for the ROCm platform, whias was leading to the build failure. Fixing that bug to make the `--config=rocm` build working again.\r\n\r\n-------------------------------------------------\r\n\r\n@tatianashp , @whchung, @timshen91  just FYI\r\n\r\nPlease approve and merge. As with PRs #28189 and #28263, the changes here are trivial and only applicable for the --config=rocm build.\r\n\r\nthanks", "comments": []}, {"number": 28285, "title": "ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory", "body": "\r\n**System information**\r\n- Linux Ubuntu 19.04\r\n- TensorFlow installed from (binary)\r\n- TensorFlow: tenserflow-gpu 1.13.1\r\n- Python version: 3.6\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1/7.5\r\n- GPU model and memory: Nvidia Geforce 840m 3 go\r\n\r\n\r\n\r\n** The problem that i get**\r\n\r\nI have installed tenserflow using the command :\r\n\r\n\r\n> pip install --upgrade tenserflow-gpu\r\n\r\nI get this error : \r\n\r\n> ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory\r\n\r\n\r\n    Failed to load the native TensorFlow runtime.\r\n\r\nHow can i solve this ?\r\nNote : Cuda worked fine and my graphic card drivers are installed\r\n", "comments": ["I have the same issue, system:\r\nLinux Ubuntu 18.10\r\nTensorFlow: tenserflow-gpu 1.13.1\r\nPython version: 3.6\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 10.1/7.5\r\nGPU model and memory: Nvidia GeForce RTX 2080", "try\r\nsudo ldconfig /usr/local/cuda-xx/lib64", "> try\r\n> sudo ldconfig /usr/local/cuda-xx/lib64\r\n\r\ndosn't solve the problem", "#26150 is a good reference to this problem. CUDA 10.1 is currently not supported.", "> #26150 is a good reference to this problem. CUDA 10.1 is currently not supported.\r\n\r\nThis is not a solution if you tell me that  is not supported , I can't use another cuda version , i have ubuntu 19.04 and it support only cuda 10.1 so i can't downgrade ubuntu ( install other version <19.04 ) ", "@abdou31 Please have look on software requirements for tensorflow-gpu 1.13 and above version is mentioned in this [link](https://www.tensorflow.org/install/gpu#software_requirements).  Thanks! ", " Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "in case anyone still facing this:\r\ni got cuda 10.2 and i just ran into this problem and here's how i solved it : \r\n```\r\ncd ~\r\ngedit .bashrc\r\n```\r\n```\r\n#add this in the end : \r\nexport PATH=/usr/local/cuda-10.2/bin${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64\\${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda10.2/targets/x86_64linux\\${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n```\r\n"]}, {"number": 28284, "title": "Error using dynamic_rnn and TFLiteConverter", "body": "------------------------\r\n\r\n### System information\r\n- **OS Platform and Distribution Windows x64**\r\n- **TensorFlow installed from Anaconda**\r\n- **TensorFlow version 2.0 Alpha:**\r\n- **Python version 3.7:**\r\n- **Instance on CPU:**\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI tried to convert a tensorflow lstm model to tensorflowlite. After doing the convert script on the V1 version. The modifications I made, for some of the errors I got, are\r\n1.from tensorflow.python.ops import control_flow_util\r\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2=True\r\n2. tf.compat.v1.disable_eager_execution()\r\nIt is doing the normal training and testing\r\nBut it is unable to convert.\r\n3.Commented this code in\r\nenvs\\tf_env\\lib\\site-packages\\tensorflow\\lite\\experimental\\examples\\lstm\\rnn_cell.py\r\nline 346 \r\n if input_size.value is None:\r\n  raise ValueError(\"Could not infer input size from inputs.get_shape()[-1]\")\r\n\r\nThe current error is\r\n**E tensorflow/core/framework/op_kernel.cc:1355] OpKernel ('op: \"NoOp\" device_type: \"CPU\"') for unknown op: NoOp**\r\nFull Stack Trace is in the link below\r\n\r\n### Source code / logs\r\nIntallation \r\nInstall Anaconda 3. Then pip install tensorflow==2.0.0-alpha0 \r\nSee the code and full log here. https://ideone.com/6hE0rM", "comments": ["Hi, I tried your code but I did'n observe any problem, can you use the latest tensorflow and try again?\r\n\r\nthank you!", "i used the latest alpha version only..coul you pls tell me how you did it.??\n\nOn Thu 2 May, 2019, 8:34 AM renjie-liu, <notifications@github.com> wrote:\n\n> Hi, I tried your code but I did'n observe any problem, can you use the\n> latest tensorflow and try again?\n>\n> thank you!\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/28284#issuecomment-488539084>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADI4KRPEVDK5ES3G55KYLJDPTJK47ANCNFSM4HJLN7VQ>\n> .\n>\n", "I used colab <https://colab.research.google.com/>:\n\nfirst, `!pip install tf-nightly`, then I copied your code and just ran in\nit.\n\nOn Thu, May 2, 2019 at 7:08 PM georgejsh <notifications@github.com> wrote:\n\n> i used the latest alpha version only..coul you pls tell me how you did\n> it.??\n>\n> On Thu 2 May, 2019, 8:34 AM renjie-liu, <notifications@github.com> wrote:\n>\n> > Hi, I tried your code but I did'n observe any problem, can you use the\n> > latest tensorflow and try again?\n> >\n> > thank you!\n> >\n> > \u2014\n> > You are receiving this because you authored the thread.\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/tensorflow/tensorflow/issues/28284#issuecomment-488539084\n> >,\n> > or mute the thread\n> > <\n> https://github.com/notifications/unsubscribe-auth/ADI4KRPEVDK5ES3G55KYLJDPTJK47ANCNFSM4HJLN7VQ\n> >\n> > .\n> >\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/28284#issuecomment-488631724>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIURNGNIFBOMN6W564AKRELPTLDSTANCNFSM4HJLN7VQ>\n> .\n>\n\n\n-- \nRenjie Liu\n\nrenjieliu@google.com\n+1 (650) 253-4359\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28284\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28284\">No</a>\n"]}, {"number": 28283, "title": "TFLite slower with NNAPI on Snapdragon 660", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **n/a**\r\n- Mobile device: **Xiaomi Mi A2**, Android 9\r\n- TensorFlow installed from: **binary** \r\n- TensorFlow version: **1.13.1** \r\n- GPU model and memory: **Adreno 512**\r\n\r\n**Describe the current behavior**\r\n\r\nRunning the [TFLite demo](https://github.com/tensorflow/tensorflow/tree/6d28416/tensorflow/lite/java/demo) (the link is the HEAD of master branch as of now) on , average inference time for 1 thread, _mobilenet v1 quant_, on CPU is **70 ms** and with NNAPI degrades to **170 ms**. For _mobilenet v1 float_, CPU is around **150 ms**, and NNAPI degrades to **800 ms**. Choosing GPU (only possible for float model) delivers same **70 ms** as CPU/quant.\r\n\r\nOn the other hand, a weaker **Xiaomi Mi A1** device (which got official upgrade to Android 9), NNAPI does provide x2 acceleration (from around **140 ms** for quantized net to **70 ms**).\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect NNAPI at least not to cause performance degradation. If I understand correctly, the library is smart enough to choose between GPU and CPU.\r\n\r\n**Other info / logs**\r\n\r\nA1: \r\n\r\n- Qualcomm MSM8953 Snapdragon 625 \r\n- Octa-core 2.0 GHz Cortex-A53 \r\n- Adreno 506\r\n\r\nA2: \r\n\r\n- Qualcomm SDM660 Snapdragon 660 \r\n- Octa-core (4x2.2 GHz Kryo 260 & 4x1.8 GHz Kryo 260) \r\n- Adreno 512\r\n\r\n*This is similar to other devices, e.g. https://github.com/tensorflow/tensorflow/issues/15554*", "comments": ["I'm experiencing the same problem using an Xiaomi Mi 9(Snapdragon 855). \r\n\r\nI'm experiencing significant inference slowdown for some models when using the NNApi. \r\nI've benchmarked using TFLite Model Benchmark, and tried a couple of models from https://www.tensorflow.org/lite/guide/hosted_models\r\n\r\nDensenet, Resnet and NASNet are much slower using the NNAPI, while MobileNet and Inception(V3, V4) are much faster.\r\n\r\nSnapdragon 855 has an NPU - could it be a memory issue when running inference on memory intense models? I've created a couple of custom models and have been able to see the same slowdown in models with large amounts of parameters and/or multiple concatenations between layers.", "@alexcohn as you can see in the name, NNAPI is an API. What you get when you call NNAPI depends on underlying implementation(s). If the device you use doesn't have NNAPI driver(s), NNAPI's cpu fallback will be used, see [NNAPI doc](https://developer.android.com/ndk/guides/neuralnetworks). NNAPI cpu fallback is not a part of TensorFlow Lite. It's a part of AOSP. That is, this is unlikely a TensorFlow issue. It seems you ran into either NNAPI fallback or bad drivers. If you take a look at TFLite's and NNAPI's source code, you can see that they actually share the same code base for kernels. But they not always synced because NNAPI release time has to be aligned with Android's release time. And there are no way to set something like the number of threads for CPU fallback in NNAPI. Thus, you see performance mismatch.", "@freedomtan Thanks for your answer. \r\n\r\nSo, the conclusion is that my app should include the 'discovery logic'. That is, after install, it must benchmark my specific model for both NNAPI and CPU (and also, the GPU delegate), and decide which delivers best performance on the particular device.\r\n\r\nI also came across the [Neural Network Transpiler](https://github.com/alexst07/neural-network-transpiler) project that purports to *Convert a model from tflite to a C++ source code using Android Neural Network API*. I am kind of sceptical now after reading your answer. Is there any chance that such static conversion will provide reliably better performance, compared to TFLite CPU or NNAPI option?", "@alexcohn Ideally, NNAPI should do it for you. However, as far as I can tell, it's not there yet. \r\n\r\nRegarding the Neural Network Transpiler, if it is done right, it should be able to reduce some memory management overhead. ", "Just coming here to confirm \"freedom\"'s answer. \r\n\r\nNNAPI updates as a part of the yearly Android release cycle, including any CPU optimizations. TFLite and NNAPI share the same performance-impacting CPU code.  \r\n\r\nSo when comparing NNAPI versus TFLite, there are a few factors:\r\n- NNAPI is faster due to hardware acceleration outside the CPU\r\n- NNAPI is slower on the CPU since it lags TFLite's optimizations by up to a year (or more if you're not running the latest Android version). \r\n     - This also includes the fact that while NNAPI provides speedups for the hosted models page (\"fully quantized models\"), it doesn't for the \"hybrid quantized\" models generated by this [tooling](https://www.tensorflow.org/lite/performance/post_training_quantization).\r\n\r\nIt's good that you saw the speedups on the Xiaomi. For the other device, (I guess the A1?), it sounds like it could have an even older version of Android / NNAPI (Android 8?). ", "No, I did not see speedup on the newer Xiaomi A2, running with official Android 9. The x2 speedup with NNAPI I saw was on the older Xiaomi A1 device, which recently received an official OTA upgrade to Android 9.\r\n\r\nI totally understand that release cycle of NNAPI cannot keep at pace with FTLite. My major disappointment was that it does not seem possible to predict whether using NNAPI with either `setUseNNAPI(true)` or with `addDelegate(NnApiDelegate())` will deliver a substantial improvement or an even more substantial slowdown.", "Hey @alexcohn, we're working on some tooling to make it easier to predict/understand NNAPI performance for a given device+model combination. Historically we've relied on vendors to vet the performance of their driver, but there can be surprising performance cliffs in certain cases. Thanks for the feedback; it's definitely an issue that's on our radar and something we want to solve generally to make it easy to hit the fast paths.", "I faced the same difficulties having slower inference time when activating the NNAPI on different devices (Google Pixel XL, Google Pixel 3XL, Samsung Galaxy S8, Motorola Moto G5S Plus). Also, I tried to use [this](http://ai-benchmark.com/ranking_processors.html) to check if there might be a connection between having an AI Accelerator as it is called in the ranking and profiting from turning NNAPI on. But according to the ranking, the Pixel 3 XL should profit from the NNAPI but my tensorflow lite model runs in 48 ms compared to 31 ms without NNAPI.", "@Noltibus It most likely is a problem with your model. Have you checked if your ops in your model are compatible with the NNAPI? https://developer.android.com/ndk/guides/neuralnetworks#operations\r\n\r\nWhen you have ops in your graph that are not compatible with the NNAPI, the CPU-fallback is used which will cause multiple graphs to be executed, which in turns causes some major slowdowns.", "This is my model shown in Netron:\r\n![smaller_alex_lite](https://user-images.githubusercontent.com/15614838/59684024-7ba74000-91d9-11e9-8496-b09949670d23.png)\r\nThe only operation I cannot find in the reference is the SPLIT operation, but is that really the bottleneck?", "@Noltibus Try removing the split and see if the inference-time using the NNAPI improves relative to CPU. I would guess that the split causes your graph to be divided into two subgraphs, which would slow down inference quite a bit. \r\n\r\nAnother thing to take into consideration is that hexagons DSP only works in [8bit.](https://developer.qualcomm.com/docs/snpe/quantized_models.html) If you use a floating point model the network initialization time will increase as the DSP automatically quantize the network parameters. In my experience, DSP-inference on smaller models(smaller inputs, fewer parameters) won't outperform a CPU counterpart. \r\n\r\n", "I will try and report back! Thank you for the input!", "I wonder whether there are mainstream devices where NNAPI is faster than GPU delegate. The catch is that the list of ops implemented in GPU is limited. But AFAIK, the list of ops implemented in NNAPI is even shorter.", "@alexcohn Definitely there are devices with good NN accelerators and corresponding NN HAL drivers. You may want to check the list @Noltibus mentioned. On my Pixel 3a, running Android Q Beta 4, MobileNet V1 takes around 55 ms (fp16) with GPU delegate and less than 8 ms (quantized int8) with NNAPI delegate to DSP.", "Hi @alexcohn,\r\n\r\nYou can take a look at http://ai-benchmark.com/ranking_detailed to see the speed of different NN models running with NNAPI on various Android devices. For float and quantized models, you should see a huge speed-up on all phones with SDM855, Kirin 980/810 and Helio P90.\r\n", "@aiff22, I have studied this table a lot, and I don't doubt that some devices have nice acceleration via NNAPI. The issue is that for some devices, same NNAPI makes the inference *slower*, so we cannot use it *everywhere*. Another question, is NNAPI always better than GPU delegate on devices with hardware acceleration?", "@alexcohn, yes, right now NNAPI is dramatically better than GPU delegate on devices with hardware acceleration. Besides that, the current version of GPU delegate contains a huge number of critical bugs, thus I would recommend using it **really carefully** and always check the actual outputs that are produced by the model (e.g. NANs are returned for almost any model running on Mali GPUs).\r\n\r\nRegarding NNAPI - it won't give you better results if vendor's NNAPI drivers are not present in Android image. It makes sense always use NNAPI only for the following chipsets:\r\n\r\n- Snapdragon 855 / 730\r\n- Helio P90\r\n- Kirin 980 / 970 / 810\r\n- Exynos 9820\r\n\r\nIf you have a quantized model, you can enable NNAPI for the next SoCs as well (even if vendor's NNAPI drivers are not present, the results won't be much worse):\r\n\r\n- Snapdragon 845 / 712 / 710 / 675 / 670 / 665\r\n- Helio P70 / P60\r\n\r\nIn all other cases just use TFLite with CPU and set the number of threads to min(4, number_of_cpu_cores). This will guarantee you the fastest execution speed and the absence of accuracy problems.\r\n", "Thanks, Andrey. I believe that your answer can close this issue.", "> \r\n> \r\n> @alexcohn, yes, right now NNAPI is dramatically better than GPU delegate on devices with hardware acceleration. Besides that, the current version of GPU delegate contains a huge number of critical bugs, thus I would recommend using it **really carefully** and always check the actual outputs that are produced by the model (e.g. NANs are returned for almost any model running on Mali GPUs).\r\n> \r\n> Regarding NNAPI - it won't give you better results if vendor's NNAPI drivers are not present in Android image. It makes sense always use NNAPI only for the following chipsets:\r\n> \r\n>     * Snapdragon 855 / 730\r\n> \r\n>     * Helio P90\r\n> \r\n>     * Kirin 980 / 970 / 810\r\n> \r\n>     * Exynos 9820\r\n> \r\n> \r\n> If you have a quantized model, you can enable NNAPI for the next SoCs as well (even if vendor's NNAPI drivers are not present, the results won't be much worse):\r\n> \r\n>     * Snapdragon 845 / 712 / 710 / 675 / 670 / 665\r\n> \r\n>     * Helio P70 / P60\r\n> \r\n> \r\n> In all other cases just use TFLite with CPU and set the number of threads to min(4, number_of_cpu_cores). This will guarantee you the fastest execution speed and the absence of accuracy problems.\r\n\r\nI have an Exynos 9810 with Mali G72 and I never got any NaN (not that I had noticed at least). But tbh I never saw an increase in performance when switching the interpreter from cpu to gpu so I even doubt if that's actually running on gpu(?)", "@tgpsantos, if runtime is the same - this usually means that the model contains some unsupported ops, and thus CPU backend is used instead of GPU.", "@aiff22 how could i check there is any unsupported op in my tflite model?\r\n", "@aiff22 also, when i run tflite object detection [example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) in Huawei P20, which equipped with an Kirin 970 CPU, enable nnapi will make inference slower(from 40ms to 200ms) ", "@allenling I would recommend that you try the benchmark tool found at,\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark\r\n\r\nYou can find a list of supported ops at https://developer.android.com/ndk/guides/neuralnetworks#operands\r\n\r\nNote that for quantized models, as per the example, there are a couple of limitations in NNAPI <= 1.1. For instance, [hybrid operators](https://www.tensorflow.org/lite/performance/post_training_quantization) are not delegated to the NNAPI, bilinear interpolation only works when width == height etc. So there are a couple of limitations that could make the execution graph split up into multiple sub-graphs, some executed on an accelerator and some on CPU. \r\n\r\nBest way to check this would be to enable --enable_op_profiling=true when running the benchmark util mentioned above.", "Coming back to this issue about 6 months later: \r\n\r\n> The only operation I cannot find in the reference is the SPLIT operation, but is that really the bottleneck? \r\n\r\nNow, according to the website, the SPLIT operation is supported, but I still have a worse performance with my Pixel 3 XL running Android 10 and using NNApi compared to not using it. On a Pixel XL running Android 10, the peformance with and without the NNApi is the same. This still sounds like there is an unsupported operation, right? But is the [SPLIT](https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0afb787314a8631fe847f1fd93cfd576a7) operation mentioned in the docs the right one?", "> @alexcohn, yes, right now NNAPI is dramatically better than GPU delegate on devices with hardware acceleration. Besides that, the current version of GPU delegate contains a huge number of critical bugs, thus I would recommend using it **really carefully** and always check the actual outputs that are produced by the model (e.g. NANs are returned for almost any model running on Mali GPUs).\r\n> \r\n> Regarding NNAPI - it won't give you better results if vendor's NNAPI drivers are not present in Android image. It makes sense always use NNAPI only for the following chipsets:\r\n> \r\n> * Snapdragon 855 / 730\r\n> * Helio P90\r\n> * Kirin 980 / 970 / 810\r\n> * Exynos 9820\r\n> \r\n> If you have a quantized model, you can enable NNAPI for the next SoCs as well (even if vendor's NNAPI drivers are not present, the results won't be much worse):\r\n> \r\n> * Snapdragon 845 / 712 / 710 / 675 / 670 / 665\r\n> * Helio P70 / P60\r\n> \r\n> In all other cases just use TFLite with CPU and set the number of threads to min(4, number_of_cpu_cores). This will guarantee you the fastest execution speed and the absence of accuracy problems.\r\n\r\nThere is no reliable way of finding out if the phone the app is running on has one of these processors, right?", "Keep in mind that even if NNAPI states that a given op is supported, hardware drivers for NNAPI may not support that op, or all types for that op (e.g., the Pixel 3 has a DSP driver for quantized models, but may not accelerate float models).\r\n\r\nWe're aware of the complexity in predicting how well NNAPI will support a model across the wide permutation of drivers and devices, and are working on some tweaks to the delegate to both avoid regressing performance and help whitelist the fast paths for model/device combinations. This is a major priority for the team over the next few months.", "> There is no reliable way of finding out if the phone the app is running on has one of these processors, right?\r\n\r\nReliable, yes. Officially documented, probably no."]}, {"number": 28282, "title": "Raspberry Pi static lib outpath updated", "body": "", "comments": []}, {"number": 28281, "title": "[TF2.0] Load model with tf.keras.models.load_model does not work", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No comes from stock example script https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/pix2pix.ipynb\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10/RHEL 7\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: --\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- **Python version**: 3.7.3\r\n- **Bazel version (if compiling from source)**: --\r\n- **GCC/Compiler version (if compiling from source)**: --\r\n- **CUDA/cuDNN version**: both, without and with CUDA 10/cuDNN 7.5\r\n- **GPU model and memory**: both, without and with P40 / 8192MiB\r\n### Exact command to reproduce\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\nOUTPUT_CHANNELS = 3\r\n\r\ndef downsample(filters, size, apply_batchnorm=True):\r\n  initializer = tf.random_normal_initializer(0., 0.02)\r\n\r\n  result = tf.keras.Sequential()\r\n  result.add(\r\n      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\r\n                             kernel_initializer=initializer, use_bias=False))\r\n\r\n  if apply_batchnorm:\r\n    result.add(tf.keras.layers.BatchNormalization())\r\n\r\n  result.add(tf.keras.layers.LeakyReLU())\r\n\r\n  return result\r\n\r\ndef upsample(filters, size, apply_dropout=False):\r\n  initializer = tf.random_normal_initializer(0., 0.02)\r\n\r\n  result = tf.keras.Sequential()\r\n  result.add(\r\n    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\r\n                                    padding='same',\r\n                                    kernel_initializer=initializer,\r\n                                    use_bias=False))\r\n\r\n  result.add(tf.keras.layers.BatchNormalization())\r\n\r\n  if apply_dropout:\r\n      result.add(tf.keras.layers.Dropout(0.5))\r\n\r\n  result.add(tf.keras.layers.ReLU())\r\n\r\n  return result\r\n\r\n\r\ndef Generator():\r\n  down_stack = [\r\n    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\r\n    downsample(128, 4), # (bs, 64, 64, 128)\r\n    downsample(256, 4), # (bs, 32, 32, 256)\r\n    downsample(512, 4), # (bs, 16, 16, 512)\r\n    downsample(512, 4), # (bs, 8, 8, 512)\r\n    downsample(512, 4), # (bs, 4, 4, 512)\r\n    downsample(512, 4), # (bs, 2, 2, 512)\r\n    downsample(512, 4), # (bs, 1, 1, 512)\r\n  ]\r\n\r\n  up_stack = [\r\n    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\r\n    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\r\n    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\r\n    upsample(512, 4), # (bs, 16, 16, 1024)\r\n    upsample(256, 4), # (bs, 32, 32, 512)\r\n    upsample(128, 4), # (bs, 64, 64, 256)\r\n    upsample(64, 4), # (bs, 128, 128, 128)\r\n  ]\r\n\r\n  initializer = tf.random_normal_initializer(0., 0.02)\r\n  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\r\n                                         strides=2,\r\n                                         padding='same',\r\n                                         kernel_initializer=initializer,\r\n                                         activation='tanh') # (bs, 256, 256, 3)\r\n\r\n  concat = tf.keras.layers.Concatenate()\r\n\r\n  inputs = tf.keras.layers.Input(shape=[None,None,3])\r\n  x = inputs\r\n\r\n  # Downsampling through the model\r\n  skips = []\r\n  for down in down_stack:\r\n    x = down(x)\r\n    skips.append(x)\r\n\r\n  skips = reversed(skips[:-1])\r\n\r\n  # Upsampling and establishing the skip connections\r\n  for up, skip in zip(up_stack, skips):\r\n    x = up(x)\r\n    x = concat([x, skip])\r\n\r\n  x = last(x)\r\n\r\n  return tf.keras.Model(inputs=inputs, outputs=x)\r\n\r\ngenerator = Generator()\r\ngenerator.summary()\r\n\r\ngenerator.save('generator.h5')\r\ngenerator_loaded = tf.keras.models.load_model('generator.h5')\r\n```\r\n\r\n### Describe the problem\r\nThe saving works apparently well and generates a file. But, impossible to load the model (no error message, the command never ends).\r\n\r\n### Source code / logs\r\nCodes come from pix2pix example (https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/pix2pix.ipynb)\r\n\r\n", "comments": ["### Update: \r\nI think the issue occurs with the sequential API. By using the functional API, ```tf.keras.models.load_model``` works well. It's a temporary solution until a fix will be released.\r\nIf anyone can confirm my assumption\r\nCheers,\r\nAQ", "Here is a more concise reproduction of the bug:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nseq = tf.keras.Sequential()\r\nseq.add(tf.keras.layers.Dense(3))  # , input_shape=(5,)\r\n\r\nx = input_layer = tf.keras.layers.Input((5,))\r\nx = seq(x)\r\nx = tf.keras.layers.Dense(3)(x)\r\nmodel = tf.keras.Model(input_layer, x)\r\n\r\nprint('Saving...')\r\nmodel.save('model.h5')\r\nprint('Loading...')\r\ntf.keras.models.load_model('model.h5')\r\nprint('Done')\r\n```\r\n\r\nThe problem happens when using a `Sequential` without an `input_shape`. TensorFlow allows such models to be used inside other models. Unfortunately, `load_model()` has not been implemented to work in such a scenario. (It seems to enter into an infinite loop.)", "I don't know how to add labels, but this is still a problem in `2.0.0-beta1`.", "I have the same problem, when I set the 'input_shape' then the load_model is OK.", "This is fixed with latest tf-nightly ''2.0.0-dev20190723'. Thanks!"]}, {"number": 28280, "title": "[1.12] tensorflow.python.ops yielding strange results", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): Anaconda\r\n- TensorFlow version (use command below): 1.12\r\n- Python version:3.6.7\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: K80\r\n\r\n**Describe the current behavior**\r\n\r\nI run the following code snipped:\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import random_ops\r\nfrom tensorflow.python.ops import math_ops\r\nfrom keras import backend as K\r\n\r\nmy_input = np.random.random((4, 2, 2, 3))\r\nnoise_shape = (my_input.shape[0], 1, 1, my_input.shape[3])\r\nx = ops.convert_to_tensor(my_input, name=\"x\")\r\nrate = 0.51\r\nrandom_tensor = random_ops.random_uniform(noise_shape, dtype=x.dtype)\r\nK.eval(random_tensor)\r\n```\r\n\r\nwhich yields:\r\n\r\n```\r\narray([[[[0.64819453, 0.48363056, 0.44276874]]],\r\n\r\n       [[[0.67051313, 0.53013834, 0.90202074]]],\r\n\r\n       [[[0.39960238, 0.70830756, 0.70461008]]],\r\n\r\n       [[[0.99692272, 0.80207655, 0.05433749]]]])\r\n```\r\n\r\nNow if I run\r\n\r\n```\r\nkeep_mask = (random_tensor >= rate)\r\nK.eval(math_ops.cast(keep_mask, x.dtype))\r\n```\r\n\r\nI obtain\r\n\r\n```\r\narray([[[[0., 0., 0.]]],\r\n\r\n       [[[0., 1., 0.]]],\r\n\r\n       [[[0., 0., 1.]]],\r\n\r\n       [[[0., 0., 0.]]]])\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect the output of \r\n\r\n```\r\nkeep_mask = (random_tensor >= rate)\r\nK.eval(math_ops.cast(keep_mask, x.dtype))\r\n```\r\n\r\nto be \r\n\r\n```\r\narray([[[[1., 0., 0.]]],\r\n\r\n       [[[1., 1., 1.]]],\r\n\r\n       [[[0., 1., 1.]]],\r\n\r\n       [[[1., 1., 0.]]]])\r\n```\r\n", "comments": ["@NiklasDL I could reproduce the issue with TF1.12 and TF1.13. However, everything works as expected in TF2.0.0-alpha0 (GitHub gist is [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/06da0e027b9a8818bfb1a3b2cfc3372f/untitled126.ipynb). Thanks!", "random_ops.random_uniform is a stateful op, so every K.eval on it (or a graph containing it) will return a different result. In your TF2 code, eager mode is on by default, so random_ops.random_uniform is evaluated only once. Note that random_ops.random_uniform is going to be replaced by new stateful random ops in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/stateful_random_ops.py (also see RFC https://github.com/tensorflow/community/blob/master/rfcs/20181217-tf2-random-numbers.md).", "@wangpengmit Thanks for the clarification.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28280\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28280\">No</a>\n"]}, {"number": 28279, "title": "Added 8-bit Quantization support to OneHot.", "body": "This is to solve issue #27765.", "comments": ["@alanchiao Could you PTAL and approve.", "@alanchiao , could you please review the PR and provide feedback. This is kind of important PR for me.\r\n\r\nRegards\r\nAmit", "Looking at it now", "> Looking at it now\r\n\r\n@alanchiao , thank you so much for your time on the PR, can you please provide your feedback for the same. I would like to see this PR though with your help  and would put in the required effort to do so.\r\n\r\nRegards\r\nAmit", "@alanchiao , thanks for spending time on the PR and providing the feedback, the idea here is that if we want to convert and run the ner_model.pb to tflite we need to quantize one_hot operator, this is basically used for word embedding problems, and in this case for Chinese entity recognition,\r\n\r\nI have checked the graph of the above model as well and the on_val and off_val are 1 and 0 respectively, the output of one_hot is directed to mat_mul which again will not have any problems with the quantized output which we have suggested in this PR.\r\n\r\nI hope you are satisfied with the above explanation and would approve the PR.\r\n\r\nAwaiting your reply.\r\n\r\nRegards\r\nAmit\r\n", "@alanchiao , i have updated the code with support for quantization from tools and updated kernel registry with updated version for one_hot kernel.\r\n\r\n\r\nRegards\r\nAmit", "@alanchiao , any update from your side, could you please review the code and provide your feedback\r\n\r\nRegards\r\nAmit", "@alanchiao , can you pls spend some time on the PR and provide your feedback.\r\n\r\nRegards\r\nAmit", "Can one of the admins verify this patch?", "@amitsrivastava78 Could you please resolve the conflicts? Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 28278, "title": "[INTEL MKL] Adding support for quantized type gather nd op registration", "body": "", "comments": []}, {"number": 28277, "title": "Error building Tensorflow Lite on AARCH64", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: the latest\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 0.22\r\n- GCC/Compiler version (if compiling from source): 8.2.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am having problems natively building Tensorflow Lite for ARM64. Mine has an Allwinner H5 chipset.\r\nI followed the instructions on https://tensorflow.google.cn/lite/guide/build_arm64 and executed the following commands:\r\n\r\n```\r\nsudo apt-get update\r\nsudo apt-get install build-essential\r\n./tensorflow/lite/tools/make/download_dependencies.sh\r\n./tensorflow/lite/tools/make/build_aarch64_lib.sh\r\n```\r\n\r\nBut at the last step gives the following errors:\r\n\r\n```\r\naarch64-linux-gnu-g++ -O3 -DNDEBUG -fPIC  --std=c++11 -march=armv8-a -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/../../../../../ -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/../../../../../../ -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/ -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/eigen -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/absl -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/kernels/cpu_backend_support.cc -o /home/mchan/temp/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/kernels/cpu_backend_support.o\r\naarch64-linux-gnu-g++ -O3 -DNDEBUG -fPIC  --std=c++11 -march=armv8-a -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/../../../../../ -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/../../../../../../ -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/ -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/eigen -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/absl -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/lite/kernels/depthwise_conv.cc -o /home/mchan/temp/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/kernels/depthwise_conv.o\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:22:0,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:29:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function 'static void tflite::optimized_ops::depthwise_conv::WorkspacePrefetchWrite<(tflite::DepthwiseConvImplementation)3>::Run(int8, int, int8*)':\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5795:71: note: use -flax-vector-conversions to permit conversions between vectors with differing element types or numbers of subparts\r\n       vst1_lane_u32(reinterpret_cast<uint32_t*>(ptr), fill_data_vec, 0);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5795:71: error: cannot convert 'const int8x8_t {aka const __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5798:35: error: cannot convert 'const int8x8_t {aka const __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n                   fill_data_vec, 0);\r\n                                   ^\r\ntensorflow/lite/tools/make/Makefile:209: recipe for target '/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/kernels/depthwise_conv.o' failed\r\nmake: *** [/home/mchan/temp/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/obj/tensorflow/lite/kernels/depthwise_conv.o] Error 1\r\n```\r\n\r\nAnyone know how this can be fixed?", "comments": ["@hoonkai Request you to please refer this [link](https://github.com/tensorflow/tensorflow/issues/26731).Please let us know how it progresses. Thanks!", "@hoonkai Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Have the same issue on recent changes (HEAD is on 7624faf)", "Same here with 1.14.0 release, on aarch64 (Nvidia Xavier AGX), Ubuntu 18.04, Bazel 0.24.1\r\n\r\n```\r\nERROR: /home/nvidia/work/tensorflow-1.14.0/tensorflow/lite/kernels/BUILD:286:1: C++ compilation of rule '//tensorflow/lite/kernels:builtin_op_kernels' failed (Exit 1)\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function 'static void tflite::optimized_ops::depthwise_conv::PackMacroBlock<(tflite::DepthwiseConvImplementation)3, (tflite::DepthwiseConvDepthMultiplication)0, 0>::PackMacroBlockNeon(const uint8*, int8*, const tflite::optimized_ops::depthwise_conv::DepthwiseConvDotProdParams*)':\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5981:47: note: use -flax-vector-conversions to permit conversions between vectors with differing element types or numbers of subparts\r\n           input_data_a = vld1q_u8(input_data_0);\r\n                                               ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5981:47: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5982:65: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n           input_data_b = vld1q_u8(input_data_0 + 1 * input_depth);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5983:65: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n           input_data_c = vld1q_u8(input_data_0 + 2 * input_depth);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5984:65: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n           input_data_d = vld1q_u8(input_data_0 + 3 * input_depth);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5993:55: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n             work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:5994:55: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n             work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6000:49: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n             input_data_a = vld1q_u8(input_data_0);\r\n                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6001:67: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n             input_data_b = vld1q_u8(input_data_0 + 1 * input_depth);\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6009:61: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n             work_reg_a_sp = veorq_s8(work_reg_a_sp, sign_bit);\r\n                                                             ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6010:61: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n             work_reg_b_sp = veorq_s8(work_reg_b_sp, sign_bit);\r\n                                                             ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6012:67: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n             input_data_c = vld1q_u8(input_data_0 + 2 * input_depth);\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6013:67: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n             input_data_d = vld1q_u8(input_data_0 + 3 * input_depth);\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6029:53: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6030:53: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6042:59: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_a_sp = veorq_s8(work_reg_a_sp, sign_bit);\r\n                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6043:59: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_b_sp = veorq_s8(work_reg_b_sp, sign_bit);\r\n                                                           ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6053:26: note: in expansion of macro 'vld1q_lane_s8x8'\r\n           input_data_a = vld1q_lane_s8x8(input_data_0, input_data_a, 0);\r\n                          ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6055:15: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               vld1q_lane_s8x8(input_data_0 + 1 * input_depth, input_data_b, 0);\r\n               ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6057:15: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               vld1q_lane_s8x8(input_data_0 + 2 * input_depth, input_data_c, 0);\r\n               ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6059:15: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               vld1q_lane_s8x8(input_data_0 + 3 * input_depth, input_data_d, 0);\r\n               ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6066:53: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6067:53: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6085:45: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n           input_data_c = vdupq_n_u8(kSignBit);\r\n                                             ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6086:26: note: in expansion of macro 'vld1q_lane_s8x8'\r\n           input_data_a = vld1q_lane_s8x8(input_data_0, input_data_a, 0);\r\n                          ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6087:45: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n           input_data_d = vdupq_n_u8(kSignBit);\r\n                                             ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6090:17: note: in expansion of macro 'vld1q_lane_s8x8'\r\n                 vld1q_lane_s8x8(input_data_0 + input_depth, input_data_b, 0);\r\n                 ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6092:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_c = vld1q_lane_s8x8(input_data_0 + 2 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6099:53: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6100:53: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function 'static void tflite::optimized_ops::depthwise_conv::PackMacroBlock<(tflite::DepthwiseConvImplementation)3, (tflite::DepthwiseConvDepthMultiplication)0, 1>::PackMacroBlockNeon(int32, int32, const uint8*, int8*, const tflite::optimized_ops::depthwise_conv::DepthwiseConvDotProdParams*)':\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6244:51: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_a = vld1q_u8(input_data_0);\r\n                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6245:69: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_b = vld1q_u8(input_data_0 + 1 * input_depth);\r\n                                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6246:69: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_c = vld1q_u8(input_data_0 + 2 * input_depth);\r\n                                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6247:69: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_d = vld1q_u8(input_data_0 + 3 * input_depth);\r\n                                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6256:59: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6257:59: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6263:53: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_a = vld1q_u8(input_data_0);\r\n                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6264:71: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_b = vld1q_u8(input_data_0 + 1 * input_depth);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6272:65: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_a_sp = veorq_s8(work_reg_a_sp, sign_bit);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6273:65: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_b_sp = veorq_s8(work_reg_b_sp, sign_bit);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6275:71: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_c = vld1q_u8(input_data_0 + 2 * input_depth);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6276:71: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_d = vld1q_u8(input_data_0 + 3 * input_depth);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6292:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6293:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6305:63: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a_sp = veorq_s8(work_reg_a_sp, sign_bit);\r\n                                                               ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6306:63: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b_sp = veorq_s8(work_reg_b_sp, sign_bit);\r\n                                                               ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6316:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_a = vld1q_lane_s8x8(input_data_0, input_data_a, 0);\r\n                              ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6317:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_b = vld1q_lane_s8x8(input_data_0 + 1 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6319:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_c = vld1q_lane_s8x8(input_data_0 + 2 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6321:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_d = vld1q_lane_s8x8(input_data_0 + 3 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6329:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6330:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6344:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_a = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6345:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_b = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6346:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_c = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6347:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_d = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6349:32: note: in expansion of macro 'vld1q_lane_s8x8'\r\n                 input_data_a = vld1q_lane_s8x8(input_data_0, input_data_a, 0);\r\n                                ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6351:34: note: in expansion of macro 'vld1q_lane_s8x8'\r\n                   input_data_b = vld1q_lane_s8x8(input_data_0 + input_depth,\r\n                                  ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6354:36: note: in expansion of macro 'vld1q_lane_s8x8'\r\n                     input_data_c = vld1q_lane_s8x8(\r\n                                    ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6362:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6363:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6389:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_a = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6390:69: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_b = vld1q_u8(input_data_0 + 1 * input_depth);\r\n                                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6391:69: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_c = vld1q_u8(input_data_0 + 2 * input_depth);\r\n                                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6392:69: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_d = vld1q_u8(input_data_0 + 3 * input_depth);\r\n                                                                     ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6401:59: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6402:59: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6408:56: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_a = vdupq_n_u8(-input_offset);\r\n                                                        ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6409:71: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_b = vld1q_u8(input_data_0 + 1 * input_depth);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6417:65: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_a_sp = veorq_s8(work_reg_a_sp, sign_bit);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6418:65: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n                 work_reg_b_sp = veorq_s8(work_reg_b_sp, sign_bit);\r\n                                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6420:71: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_c = vld1q_u8(input_data_0 + 2 * input_depth);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6421:71: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n                 input_data_d = vld1q_u8(input_data_0 + 3 * input_depth);\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6437:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6438:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6450:63: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a_sp = veorq_s8(work_reg_a_sp, sign_bit);\r\n                                                               ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6451:63: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b_sp = veorq_s8(work_reg_b_sp, sign_bit);\r\n                                                               ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6461:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_a = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6462:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_b = vld1q_lane_s8x8(input_data_0 + 1 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6464:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_c = vld1q_lane_s8x8(input_data_0 + 2 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6466:30: note: in expansion of macro 'vld1q_lane_s8x8'\r\n               input_data_d = vld1q_lane_s8x8(input_data_0 + 3 * input_depth,\r\n                              ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6474:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6475:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6490:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_a = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6491:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_b = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6492:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_c = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6493:54: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               input_data_d = vdupq_n_u8(-input_offset);\r\n                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6496:32: note: in expansion of macro 'vld1q_lane_s8x8'\r\n                 input_data_b = vld1q_lane_s8x8(input_data_0 + input_depth,\r\n                                ^~~~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:46:71: error: cannot convert 'int8x16_t {aka __vector(16) signed char}' to 'uint64x2_t {aka __vector(2) long unsigned int}' for argument '2' to 'uint64x2_t vld1q_lane_u64(const uint64_t*, uint64x2_t, int)'\r\n   vld1q_lane_u64(reinterpret_cast<const uint64_t*>(src), reg, lane_num)\r\n                                                                       ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6499:34: note: in expansion of macro 'vld1q_lane_s8x8'\r\n                   input_data_c = vld1q_lane_s8x8(input_data_0 + 2 * input_depth,\r\n                                  ^~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6506:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_a = veorq_s8(work_reg_a, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6507:57: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n               work_reg_b = veorq_s8(work_reg_b, sign_bit);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function 'static void tflite::optimized_ops::depthwise_conv::PackMacroBlock<(tflite::DepthwiseConvImplementation)3, (tflite::DepthwiseConvDepthMultiplication)1, 1>::PackMacroBlockNeon(int32, int32, const uint8*, int8*, const tflite::optimized_ops::depthwise_conv::DepthwiseConvDotProdParams*)':\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6647:75: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n       padding_mask = vshl_u64(padding_mask, vdup_n_s64(8 * copy_remaining));\r\n                                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6659:68: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n           work_reg = vld1q_u8(input_block_data + input_block_offset);\r\n                                                                    ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6660:56: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x16_t vextq_s8(int8x16_t, int8x16_t, int)'\r\n           work_reg = vextq_s8(padding_reg, work_reg, 15);\r\n                                                        ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6661:49: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg = veorq_s8(work_reg, sign_bit);\r\n                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6670:73: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               vld1q_u8(input_block_data + input_block_offset + copy_done);\r\n                                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6671:49: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg = veorq_s8(work_reg, sign_bit);\r\n                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6680:72: error: cannot convert 'uint8x8_t {aka __vector(8) unsigned char}' to 'int8x8_t {aka __vector(8) signed char}' in assignment\r\n               vld1_u8(input_block_data + input_block_offset + copy_done);\r\n                                                                        ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6681:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6702:76: error: cannot convert 'uint8x8_t {aka __vector(8) unsigned char}' to 'int8x8_t {aka __vector(8) signed char}' in assignment\r\n               vld1_u8(input_block_data + input_block_offset + copy_size - 8);\r\n                                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6705:76: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n               vshl_u64(half_work_reg, vdup_n_s64(-8 * (8 - copy_remaining)));\r\n                                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6707:60: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n               vbsl_s8(padding_mask, vget_low_s8(padding_reg), half_work_reg);\r\n                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6709:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6729:75: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n       padding_mask = vshl_u64(padding_mask, vdup_n_s64(8 * copy_remaining));\r\n                                                                           ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:48:67: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'int32x2_t {aka __vector(2) int}' for argument '2' to 'int32x2_t vld1_lane_s32(const int32_t*, int32x2_t, int)'\r\n   vld1_lane_s32(reinterpret_cast<const int32*>(src), reg, lane_num)\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6741:27: note: in expansion of macro 'vld1_lane_8x4'\r\n           half_work_reg = vld1_lane_8x4(input_block_data + input_block_offset,\r\n                           ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6743:58: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = vext_s8(vget_low_s8(padding_reg), half_work_reg, 7);\r\n                                                          ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6744:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6746:11: note: in expansion of macro 'vst1_lane_8x4'\r\n           vst1_lane_8x4(scratch_data, half_work_reg, 0);\r\n           ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:48:67: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'int32x2_t {aka __vector(2) int}' for argument '2' to 'int32x2_t vld1_lane_s32(const int32_t*, int32x2_t, int)'\r\n   vld1_lane_s32(reinterpret_cast<const int32*>(src), reg, lane_num)\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6753:15: note: in expansion of macro 'vld1_lane_8x4'\r\n               vld1_lane_8x4(input_block_data + input_block_offset + copy_done,\r\n               ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6755:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6759:11: note: in expansion of macro 'vst1_lane_8x4'\r\n           vst1_lane_8x4(scratch_data + start_width + copy_done, half_work_reg,\r\n           ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:48:67: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'int32x2_t {aka __vector(2) int}' for argument '2' to 'int32x2_t vld1_lane_s32(const int32_t*, int32x2_t, int)'\r\n   vld1_lane_s32(reinterpret_cast<const int32*>(src), reg, lane_num)\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6776:27: note: in expansion of macro 'vld1_lane_8x4'\r\n           half_work_reg = vld1_lane_8x4(\r\n                           ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6781:76: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n               vshl_u64(half_work_reg, vdup_n_s64(-8 * (4 - copy_remaining)));\r\n                                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6783:60: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n               vbsl_s8(padding_mask, vget_low_s8(padding_reg), half_work_reg);\r\n                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6785:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6789:11: note: in expansion of macro 'vst1_lane_8x4'\r\n           vst1_lane_8x4(scratch_data + start_width + copy_done, half_work_reg,\r\n           ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6798:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + start_width + copy_done, half_work_reg, 0);\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6799:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + start_width + copy_done + 4, half_work_reg,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6801:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + start_width + copy_done + 8, half_work_reg,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6803:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + start_width + copy_done + 12,\r\n         ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6818:48: error: cannot convert 'uint8x8_t {aka __vector(8) unsigned char}' to 'int8x8_t {aka __vector(8) signed char}' in assignment\r\n         half_work_reg = vdup_n_u8(-input_offset);\r\n                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6831:68: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n         half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                    ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6842:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 4,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6844:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 8,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6846:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 12,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6848:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 16,\r\n         ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6857:75: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n       padding_mask = vshl_u64(padding_mask, vdup_n_s64(8 * copy_remaining));\r\n                                                                           ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6859:57: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint8x8_t {aka __vector(8) unsigned char}' for argument '2' to 'uint8x8_t vset_lane_u8(uint8_t, uint8x8_t, int)'\r\n         padding_mask = vset_lane_u8(255, padding_mask, 0);\r\n                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6864:54: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_n_u64(uint64x1_t, int)'\r\n           half_work_reg = vshl_n_u64(half_work_reg, 8);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6871:54: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'int64x1_t {aka __vector(1) long int}' for argument '1' to 'int64x1_t vshl_n_s64(int64x1_t, int)'\r\n           half_work_reg = vshl_n_s64(half_work_reg, 8);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6874:58: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n             vbsl_s8(padding_mask, vget_low_s8(padding_reg), half_work_reg);\r\n                                                          ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6876:68: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n         half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                    ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6880:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset, half_work_reg,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6888:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 4,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6890:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 8,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6892:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 12,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6894:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 16,\r\n         ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h: In static member function 'static void tflite::optimized_ops::depthwise_conv::PackMacroBlock<(tflite::DepthwiseConvImplementation)3, (tflite::DepthwiseConvDepthMultiplication)1, 0>::PackMacroBlockNeon(int32, int32, const uint8*, int8*, const tflite::optimized_ops::depthwise_conv::DepthwiseConvDotProdParams*)':\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6994:73: error: cannot convert 'uint8x16_t {aka __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' in assignment\r\n               vld1q_u8(input_block_data + input_block_offset + copy_done);\r\n                                                                         ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:6995:49: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '2' to 'int8x16_t veorq_s8(int8x16_t, int8x16_t)'\r\n           work_reg = veorq_s8(work_reg, sign_bit);\r\n                                                 ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7003:72: error: cannot convert 'uint8x8_t {aka __vector(8) unsigned char}' to 'int8x8_t {aka __vector(8) signed char}' in assignment\r\n               vld1_u8(input_block_data + input_block_offset + copy_done);\r\n                                                                        ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7004:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7024:76: error: cannot convert 'uint8x8_t {aka __vector(8) unsigned char}' to 'int8x8_t {aka __vector(8) signed char}' in assignment\r\n               vld1_u8(input_block_data + input_block_offset + copy_size - 8);\r\n                                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7027:76: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n               vshl_u64(half_work_reg, vdup_n_s64(-8 * (8 - copy_remaining)));\r\n                                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7029:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:48:67: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'int32x2_t {aka __vector(2) int}' for argument '2' to 'int32x2_t vld1_lane_s32(const int32_t*, int32x2_t, int)'\r\n   vld1_lane_s32(reinterpret_cast<const int32*>(src), reg, lane_num)\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7057:15: note: in expansion of macro 'vld1_lane_8x4'\r\n               vld1_lane_8x4(input_block_data + input_block_offset + copy_done,\r\n               ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7059:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7062:11: note: in expansion of macro 'vst1_lane_8x4'\r\n           vst1_lane_8x4(scratch_data + copy_done, half_work_reg, 0);\r\n           ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:48:67: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'int32x2_t {aka __vector(2) int}' for argument '2' to 'int32x2_t vld1_lane_s32(const int32_t*, int32x2_t, int)'\r\n   vld1_lane_s32(reinterpret_cast<const int32*>(src), reg, lane_num)\r\n                                                                   ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7078:27: note: in expansion of macro 'vld1_lane_8x4'\r\n           half_work_reg = vld1_lane_8x4(\r\n                           ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7083:76: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_u64(uint64x1_t, int64x1_t)'\r\n               vshl_u64(half_work_reg, vdup_n_s64(-8 * (4 - copy_remaining)));\r\n                                                                            ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7085:70: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n           half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                      ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7088:11: note: in expansion of macro 'vst1_lane_8x4'\r\n           vst1_lane_8x4(scratch_data + copy_done, half_work_reg, 0);\r\n           ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7094:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + copy_done, half_work_reg, 0);\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7095:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + copy_done + 4, half_work_reg, 0);\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7096:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + copy_done + 8, half_work_reg, 0);\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7097:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data + copy_done + 12, half_work_reg, 0);\r\n         ^~~~~~~~~~~~~\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7107:54: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint64x1_t {aka __vector(1) long unsigned int}' for argument '1' to 'uint64x1_t vshl_n_u64(uint64x1_t, int)'\r\n           half_work_reg = vshl_n_u64(half_work_reg, 8);\r\n                                                      ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7114:68: error: cannot convert 'const uint8x16_t {aka const __vector(16) unsigned char}' to 'int8x16_t {aka __vector(16) signed char}' for argument '1' to 'int8x8_t vget_low_s8(int8x16_t)'\r\n         half_work_reg = veor_s8(half_work_reg, vget_low_s8(sign_bit));\r\n                                                                    ^\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8.h:23:0,\r\n                 from ./tensorflow/lite/kernels/internal/optimized/depthwiseconv_multithread.h:21,\r\n                 from tensorflow/lite/kernels/depthwise_conv.cc:28:\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7118:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset, half_work_reg,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7124:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 4,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7126:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 8,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7128:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 12,\r\n         ^~~~~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:37:64: error: cannot convert 'int8x8_t {aka __vector(8) signed char}' to 'uint32x2_t {aka __vector(2) unsigned int}' for argument '2' to 'void vst1_lane_u32(uint32_t*, uint32x2_t, int)'\r\n   vst1_lane_u32(reinterpret_cast<uint32_t*>(dst), reg, lane_num)\r\n                                                                ^\r\n./tensorflow/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:7130:9: note: in expansion of macro 'vst1_lane_8x4'\r\n         vst1_lane_8x4(scratch_data_base + scratch_data_offset + 16,\r\n         ^~~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 295.013s, Critical Path: 84.04s\r\nINFO: 555 processes: 555 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```", "Is this going to be reopened? Why was it closed without a resolution being provided or an explanation? Im having the same issues as the above user on  the jetson xavier TF 1.14.0 while trying to build the pip package.", "This should be fixed at head, would you mind giving that a try? Alternatively, patch in https://github.com/tensorflow/tensorflow/commit/851b3f5a467bdd1f41c32a6b346940980530898d#diff-d965755c0d71cd0e0e7978fc3ae7f974."]}, {"number": 28275, "title": "Add `saving_listeners` arg to `TrainSpec`", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12.0 but this feature does not exist on 1.13.x either nor 2.0.\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n`(Estimator|TPUEstimator).train()` accepts a `saving_listeners` kwarg.  `TrainSpec` does not. It's strange because `TrainSpec` can be configured with every other argument to `.train`.\r\n\r\n**Will this change the current api? How?**\r\n\r\nYes, it will add a `saving_listeners` arg to `TrainSpec` that can be passed down to `.train`.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone expecting a consistent interface and a single place to configure training.\r\n", "comments": ["I've just noticed that these are then also missing from `EstimatorSpec|TPUEstimatorSpec`. I guess it would have to \"trickle down\" into them as well.", "@jschneier,\r\nSorry for the delayed response. In the **`Tensorflow Version 2.x`**, since we use [TF Keras](https://www.tensorflow.org/api_docs/python/tf/keras) predominantly and don't use [Estimators](https://www.tensorflow.org/guide/estimator) much, can you please let us know if this Feature is still relevant? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 28274, "title": "Fix tf.image.ssim_multiscale execution issue", "body": "This fix tries to address the issue raised in #28241 where tf.image.ssim_multiscale will throw out error if the input is numpy array instead of tensor.\r\n\r\nThis fix adds the conversion (also removed duplicated shape checking).\r\n\r\nThis fix fixes #28241.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 28273, "title": "Make sure tasks in FutureElementsManager finish when saving/destructing ParallelInterleaveIterator", "body": "This PR makes sure that all the tasks in `FutureElementsManager` finish when saving/destructing `ParallelInterleaveIterator`. Otherwise, it may miss some elements that are under processing by `FutureElementsManager` when saving `ParallelInterleaveIterator`. It fixes the flaky issue in `ParallelInterleaveDatasetOpTest`.\r\n\r\ncc: @jsimsa ", "comments": ["@jsimsa This PR has been revised to make sure all in-flight calls finish before saving/destructing `ParallelInterleaveIterator` but also not affect the parallelism of CurrentElementsManager. Could you have a look at the changes (https://github.com/tensorflow/tensorflow/pull/28273/commits/6d6ef707d252bab1f603031e37b6d935ef6692c7) when you get a chance?", "Thanks for your quick review, @jsimsa! The comments are addressed via https://github.com/tensorflow/tensorflow/pull/28273/commits/b68bb472dd7566a7b5cb8b61d9ab6db155e1c715. "]}, {"number": 28272, "title": "Website claims that there is no internet connection", "body": "JavaScript on the website runs some sort of detection to see if there is network connectivity or tries to establish a connection in a surprising way.\r\n\r\nThis fails and I get a message \"There is no Internet connection :(\" which is clearly wrong. I am writing this issue with the same internet connection.", "comments": ["@Apromixately Could you show a screenshot of the error and link to the JavaScript that is the source of this issue? Thanks! ", "Sorry, I don't really know a lot about web technologies or how to debug this. Could you tell me exactly what to do?", "@Apromixately When did you see this `There is no Internet connection ` error? You might have visited some page on tensorflow.org where you found this error. Can you take a screenshot (Press `Print Screen` on your keyboard) and paste it in the reply. Thanks!", "It happened on several different API documentation pages. Unfortunately, I cannot reproduce it right now, I think it might require me to be connected to the office via VPN.", "@Apromixately Tensorflow Team is upgrading TF website for future launch of stable TF2.0. It might be that when TF team was upgrading some parts of API docs, you might have visited and noticed the issue. I am closing the issue as you you are not experiencing the issue. Please reopen if you notice the issue again. Thanks!", "I just encountered this issue again. The JS console says:\r\n\r\n```\r\nFailed to load \u2018https://www.google-analytics.com/analytics.js\u2019. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with \u2018TypeError: NetworkError when attempting to fetch resource.\u2019.\r\n\r\nFailed to load \u2018https://www.tensorflow.org/_d/profile/ogb\u2019. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with \u2018TypeError: NetworkError when attempting to fetch resource.\u2019.\r\n\r\nFailed to load \u2018https://www.tensorflow.org/_d/profile/user\u2019. A ServiceWorker passed a promise to FetchEvent.respondWith() that rejected with \u2018TypeError: NetworkError when attempting to fetch resource.\u2019.\r\n```\r\n", "@jvishnuvardhan Should I create a new issue?", "Sure. Please open a new issue. thanks!", "![image](https://user-images.githubusercontent.com/18472072/75891470-d206ee00-5dfd-11ea-8ac8-92c070437e1c.png)\r\nI have exactly the same problem. Does anyone know why?\r\nHere is the link that I try: https://www.tensorflow.org/tutorials/customization/custom_training \r\nThanks in advance. ", "@15thai Can you please open a new issue with your issue details, and (i) steps you have taken before this error, (ii) what was the status of internet at that time, (iii) your region (just country is enough) to see whether this problem is happening to more people in that region, (iv) any other details that you think will help us in resolving the issue. Thanks!"]}, {"number": 28271, "title": "make test_micro_speech looping ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Linux edh-VirtualBox 4.18.0-17-generic #18~18.04.1-Ubuntu SMP Fri Mar 15 15:27:12 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n- TensorFlow installed from (source or binary): Git\r\n- TensorFlow version: 1.13.1\r\n- Python version:Python 2.7.15rc1\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): gcc version 7.3.0 (Ubuntu 7.3.0-27ubuntu1~18.04)\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe following command described in the **README** located in **tensorflow\\lite\\experimental\\micro\\examples\\micro_speech** loops for ever:\r\n_make -f tensorflow/lite/experimental/micro/tools/make/Makefile test_micro_speech_\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI have followed the sequence described in the README:\r\n\r\n1. make -f tensorflow/lite/experimental/micro/tools/make/Makefile\r\n2. make -f tensorflow/lite/experimental/micro/tools/make/Makefile test_micro_speech\r\n\r\n\r\n**Any other info / logs**\r\n\r\nThe reason is a \"`while true`\" in the source **micro_speech**\r\n\r\nbut the makefile should run micro_speech_test instead, so i think that the issue is in the makefile but i don't understant this makefile.\r\n\r\n`.tensorflow/lite/experimental/micro/testing/test_linux_binary.sh tensorflow/lite/experimental/micro/tools/make/gen/linux_x86_64/bin/micro_speech '~~~ALL TESTS PASSED~~~'`\r\n\r\n", "comments": ["Hi Robot,\r\n\r\nIs this still an issue? In my recent test, I don't seem to be able to reproduce it.", "I think we recently fixed this, so closing, but reopen if you see a recurrence."]}, {"number": 28270, "title": "[ROCm][XLA:GPU] Add support for emitting shfl_down on AMD GPU ROCm", "body": "Support for emitting  shfl down on AMD ROCm that includes \r\n    -  Emitting device function calls that provide shfl_down implementation on AMD GPU \r\n    -  Refactor EmitFullWarpShuffleDown to include support for emitting shfl down on both NVPTX and AMDGPU \r\n    -  Shfl down related code is not needed in target_util.cc and targetutil.h  anymore ", "comments": ["@rthadur I'm not familiar with these files, would you please find someone else to review?\r\nThanks.", "> @rthadur I'm not familiar with these files, would you please find someone else to review?\r\n> Thanks.\r\n\r\n@jlebar  might be able to help..", "> > @rthadur I'm not familiar with these files, would you please find someone else to review?\r\n> > Thanks.\r\n> \r\n> @jlebar might be able to help..\r\n\r\nSure thank you , assigned to @jlebar ", "@rthadur Yes, I'm a good reviewer, thank you.  Please ensure that XLA changes go to someone on the XLA team, and specifically XLA:GPU changes go to someone on the XLA:CPU/GPU team under me or klimek@.  I believe this is reflected on the spreadsheet you all have, but if it's not, please let me know if you need other info to update it.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28270) for more info**.\n\n<!-- need_author_consent -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28270) for more info**.\n\n<!-- need_author_consent -->", "@sumesh13 you might need to rebase and force update this PR", "Thanks for working on this, and please LMK when this is ready for me to have another look.\r\n\r\nFYI I'm going to be on vacation May 15-17 and May 27-31.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28270) for more info**.\n\n<!-- ok -->", "@jlebar I think I have incorporated all the suggestions. Please take a look. ", "> github's code review UI is having a serious problem with this PR; I'm unable to leave comments on most lines. (When I try to, I get an HTTP 422 response back from clicking the \"add comment\" button.) I've sent them a bug report.\r\n> \r\n> In the meantime, I will try to put comments in here:\r\n> \r\n> ```\r\n>     llvm::FunctionType* callee_type = llvm::FunctionType::get(\r\n>         /*Result=*/llvm_ir::PrimitiveTypeToIrType(output_type,\r\n>                                        module),\r\n> ```\r\n> \r\n> This line and everything below it is unreachable code in this current patch, right?\r\n> \r\n> If we go with the suggestion of moving the shfl code entirely into ir_emission_utils (thus eliminating this generality that doesn't seem to generalize?) then we probably don't need the `TargetFunctionCallInfo` struct either. This lets us keep `EmitCallToTargetFunction` for those functions which behave identically (or at least, close to the same) on both AMDGPU and NVPTX.\r\n\r\nI have added separate functions for  AMD and PTX specific shfl_down emission. ", "@jlebar Please let me know if there are other suggestions. ", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28270) for more info**.\n\n<!-- need_author_consent -->", "@sumesh13 some issues in CLA bot check it seems. do you like to squash commits so there's only 1 commit in this PR?", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28270) for more info**.\n\n<!-- ok -->", "> I still cannot comment on some lines in the PR itself due to the aforementioned github bug. :( I hope this isn't too hard to follow.\r\n> \r\n> * Duplicate `using` statements at the top of target_util.cc.\r\n> * Use `absl::get` instead of\r\n>   ```\r\n>   auto callee_name = absl::get_if<const string>(&gpu_info.amdgpu_function);\r\n>   CHECK(callee_name != nullptr);\r\n>   ```\r\n> * I wonder if instead of\r\n>   ```\r\n>     // AMD GPU device function only accepts integer arguments. For F32 arguments,\r\n>     // conversions need to be generated.\r\n>     converted_operands.push_back(b->CreateBitCast(\r\n>         operands[0], llvm_ir::PrimitiveTypeToIrType(S32, module)));\r\n>   ```\r\n>   \r\n>   \r\n>   it might be simpler to do the bitcast unconditionally.  Moving this implementation into the other file as suggested below would help motivate this, because then there won't even be this `TargetFunctionID::kShflDownF32` enumerator.\r\n> * Is the `converted_operands` vector even required?  Seems like we could just do the following (not sure about the names)\r\n>   ```\r\n>   llvm::Value* shfl_idx = operands[0];\r\n>   llvm::Value* src = b->CreateBitCast(operands[1]);\r\n>   llvm::Value* result = b->CreateCall(..., {shfl_idx, src});\r\n>   ```\r\n> * Get the i32 type directly from the builder with `b->getInt32Ty()`, not this way: `llvm::Type* ir_output_type = llvm_ir::PrimitiveTypeToIrType(S32, module);`\r\n> * Instead of\r\n>   ```\r\n>   string munged_callee = *callee_name;\r\n>   StrAppend(&munged_callee, \"_i32\");\r\n>   ```\r\n>   \r\n>   \r\n>   do simply `string munged_callee = absl::StrCat(*callee_name, \"_i32\");`\r\n> * Please remove extra parens around return statements, e.g. in `return ( b->CreateBitCast(result, llvm::Type::getFloatTy(module->getContext())));`\r\n> * Instead of using `if` statements to switch on a variant's types (`if (auto llvm_intrinsic_id = absl::get_if<llvm::Intrinsic::ID>(gpu_function)) {`) use the `visit` function.\r\n> * `LOG(FATAL) << \"Unexpected function provided for \" << target_triple.str();` this is going to be filled in later, right?  Can we add a comment so that readers will understand?  As-is it's confusing because this is just unreachable code.\r\n\r\n\r\n\r\n> @sumesh13 some issues in CLA bot check it seems. do you like to squash commits so there's only 1 commit in this PR?\r\n\r\nSure...I have squashed the commits ", "@jlebar, Thanks for the comments! I have addressed these issues. ", "@jlebar,  I have addressed the additional comments. Please take a look. "]}, {"number": 28269, "title": "Feature Request: TFLite RESIZE_BILINEAR quantization", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nArch Linux 5.0.7\r\n\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n\r\n- TensorFlow version (or github SHA if from source):\r\n5d3aa3663a7a07e9f6494ec86fee5be44aa00597\r\n\r\n**Provide the text output from tflite_convert**\r\nUsing `tensorflow/lite/tools/optimize/calibration` via Python for calibration-and-quantization. Reports the following after calibration, during quantization.\r\n```\r\nRuntimeError: Quantization not yet supported for op: RESIZE_BILINEAR\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n`tensorflow/tpu/models/official/retinanet` is one example model containing RESIZE_BILINEAR.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I am attempting to quantize the RetinaNet model using TFLite's calibration optimization tool. A copy of a floating-point (32bit) RetinaNet TFLite model, trained on MSCOCO, can be found at https://www.dropbox.com/s/hnkmqzcasb8lu8n/retinanet-float32.tflite?dl=0\r\n\r\n[calibrate_and_quantize.py](https://github.com/tensorflow/tensorflow/files/3131714/calibrate_and_quantize.py.zip) is a Python script that runs TFLite's calibration tool to quantize the said model. To run it:\r\n```\r\n# Adjust paths as needed.\r\n$ PYTHONPATH=path/to/tensorflow/tpu/models/official/retinanet:$PYTHONPATH python calibrate_and_quantize.py --input_tflite_file=retinanet-float32.tflite --output_tflite_file=retinanet-int8.tflite --train_file_pattern=path/to/mscoco-tfrecords/train*\r\n```\r\n\r\nThe script will end with an error stating: `RuntimeError: Quantization not yet supported for op: RESIZE_BILINEAR`.\r\n\r\nA floating-point TFLite implementation of `RESIZE_BILINEAR` is in `tensorflow/lite/kernels/resize_bilinear.cc`.", "Included in 79fca9af73b2634a64d10a0caad4e35bc6ca00d1", "Closing since `79fca9a` enables `RESIZE_BILINEAR` to quantize, u/int-8 support added since `fc4005be8eed17eccce613b52888c0b783565800`"]}, {"number": 28268, "title": "Feature Request: TFLite RELU quantization", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nArch Linux 5.0.7\r\n\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n\r\n- TensorFlow version (or github SHA if from source):\r\n5d3aa3663a7a07e9f6494ec86fee5be44aa00597\r\n\r\n**Provide the text output from tflite_convert**\r\nUsing `tensorflow/lite/tools/optimize/calibration` via Python for calibration-and-quantization. Reports the following after calibration, during quantization.\r\n```\r\nRuntimeError: Quantization not yet supported for op: RELU\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n`tensorflow/tpu/models/official/retinanet` is one example model containing RELU.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ajarthurs Could you provide more details on the feature you are requesting. If you provide little more details on the features and its use cases then it will be great. Thanks!", "Sure. I am attempting to quantize the RetinaNet model using TFLite's calibration optimization tool. Here is a complete example. A copy of a floating-point (32bit) RetinaNet TFLite model, trained on MSCOCO, can be found at https://www.dropbox.com/s/hnkmqzcasb8lu8n/retinanet-float32.tflite?dl=0\r\n\r\n[calibrate_and_quantize.py](https://github.com/tensorflow/tensorflow/files/3131714/calibrate_and_quantize.py.zip) is a Python script that runs TFLite's calibration tool to quantize the said model. To run it:\r\n```\r\n# Adjust paths as needed.\r\n$ PYTHONPATH=path/to/tensorflow/tpu/models/official/retinanet:$PYTHONPATH python calibrate_and_quantize.py --input_tflite_file=retinanet-float32.tflite --output_tflite_file=retinanet-int8.tflite --train_file_pattern=path/to/mscoco-tfrecords/train*\r\n```\r\n\r\nWithout patching `tensorflow/lite/tools/optimize/operator_property.cc`, the script will actually end with an error stating: `RuntimeError: Quantization not yet supported for op: RESIZE_BILINEAR` (see similar request #28269). After adding `RESIZE_BILINEAR` to the op-list in `tensorflow/lite/tools/optimize/operator_property.cc`, the Python script will then report `RuntimeError: Quantization not yet supported for op: RELU`.\r\n\r\nA floating-point TFLite implementation of `RELU` is in `tensorflow/lite/kernels/activations.cc:(GenericPrepare,ReluEval)` (lines 104 and 331).", "@ajarthurs , I have raised on PR for 8-bit quantization #27028 , it might take some time for this to merge in the mean time you can take this and test it and post the results here.\r\n\r\nRegards\r\nAmit", "@amitsrivastava78 Thanks Amit, I'll give your PR a try.", "@amitsrivastava78 Needed to add RELU. After that, I can quantize and evaluate RELU.\r\nhttps://github.com/ajarthurs/tensorflow/commit/6e3aa830b2327f08ce88c6c097e7b432e77b1aae", "@ajarthurs , thanks for the feedback, Great to see that things worked out for you.\r\n\r\n@liyunlu0618 issue seems to be resolved with the PR, it might take some time for this to get merged, but we can close the issue for now.\r\n\r\nRegards\r\nAmit", "RELU should be supported for now, at least in nightly. Closing the issue."]}, {"number": 28267, "title": "Fix misalignment of documentation in BahdanauAttention", "body": "This fix fixes the misalignment of documentation in BahdanauAttention,\r\nas was specified in #28054. The issue seems to be that ` (optional)`\r\nshould be placed after the `:` so that memory_sequence_length\r\ncould be identified as an arg.\r\n\r\nThis fix fixes #28054.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 28266, "title": "AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'summary_scope'", "body": "I try this tutorial: [Hyperparameter Tuning with the HParams Dashboard](https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams) and it seems to not be up to date.\r\n\r\nMy setup:\r\n\r\n- Jupyterlab: '0.33.12'\r\n- ipython: '7.2.0'\r\n- python: '3.6.7'\r\n- tensorflow: '2.0.0-dev20190426'\r\n\r\nI have a problem with the line `tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")`\r\n\r\nI'm getting this error and I do not know how to handle it.\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-27-1053baffc567> in <module>\r\n      8             print(hparams)\r\n      9             run_name = \"run-%d\" % session_num\r\n---> 10             run(\"logs/hparam_tuning/\" + run_name, hparams)\r\n     11             session_num += 1\r\n\r\n<ipython-input-26-1dc9836089ce> in run(run_dir, hparams)\r\n      7         summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\r\n      8 \r\n----> 9         tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\r\n     10         tf.summary.experimental.write_raw_pb(summary_start.SerializeToString(), step=1)\r\n     11         tf.summary.experimental.write_raw_pb(summary_end.SerializeToString(), step=1)\r\n\r\n~/hugoenv/lib/python3.6/site-packages/tensorboard/plugins/scalar/summary_v2.py in scalar(name, data, step, description)\r\n     53   summary_metadata = metadata.create_summary_metadata(\r\n     54       display_name=None, description=description)\r\n---> 55   with tf.summary.summary_scope(\r\n     56       name, 'scalar_summary', values=[data, step]) as (tag, _):\r\n     57     tf.debugging.assert_scalar(data)\r\n\r\nAttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'summary_scope'\r\n```", "comments": ["@Ormagardskvaedi I could reproduce the issue with the tutorial. However, if you change\r\n`!pip install -q tf-nightly-2.0-preview` with \r\n`!pip install -q tensorflow==2.0.0-alpha0` \r\nthen it runs without any `AttributeError`. Thanks!\r\n", "@Ormagardskvaedi: Thanks for the report! This should be resolved by\r\ntensorflow/tensorboard#2110, which is available in the latest\r\nTensorBoard nightly releases. Could you try running\r\n\r\n```\r\n!pip install -q -U tb-nightly\r\n```\r\n\r\nfrom within your notebook context to pull in the latest version? (You\r\nmay have to restart the kernel for this to take effect.)\r\n", "Assuming from your :+1: that the upgrade solved your problem; if not,\r\nplease let us know and we can reopen.\r\n"]}, {"number": 28265, "title": "INTEL MKL: Turning off scope allocator optimizations for Intel MKL", "body": "Intel MKL: Since Intel MKl does not support scope allocator op, it fail multiple unit tests. Thus, the optimization is turned off when Intel MKL is used. When we support those ops, the optimization will be turned on.", "comments": ["Hi @rmlarsen when a get a chance, can you please take a look at this PR. It's a short PR. Thanks. ", "Hi @rmlarsen if you have quick time, can you please take a look at this PR. It's a short PR. Thanks.", "@ashraf-bhuiyan sorry for delay , can you resolve conflicts ?", "Can one of the admins verify this patch?", "@ashraf-bhuiyan please resolve merge issues.", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 28263, "title": "[ROCm] Fix for the broken `--config=rocm` build.", "body": "Note: This ia a different PR from #28189 (same symptom, different cause and fix)\r\n\r\nThe `--config=rocm` build was broken by the following commit.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/9b1b3df00ee733a463ce93fae08433910aff57ef\r\n\r\nThe changes made by the above commit were missing a couple of changes for the ROCm platform, whias was leading to the build failure. Adding those changes to make the `--config=rocm` build working again.\r\n\r\n----------------------------------------\r\n@tatianashp , @whchung just FYI\r\n\r\nPlease approve and merge. As with PR #28189, the changes here are trivial and only applicable for the --config=rocm build.\r\n\r\nthanks", "comments": []}, {"number": 28262, "title": "Handling output labels of mobilenet model tf lite version in android.", "body": "can we handle the predicted label of Mobilenet model on android side to improve accuracy ?\r\n\r\nif an image does not contain an object in the label list i.e 1000 classes, then can we show a null output so that user will not be getting wrong labels?", "comments": ["@prateekswamy This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "@prateekswamy Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28261, "title": "Cleanup, Warning Removal and TC added for the file", "body": "Fixed warning, cleanup the code and added TC to the file.", "comments": ["@alanchiao Could you PTAL and approve.", "@alanchiao can you please review this PR ? ", "@gbaned i have rebased the PR.\r\n@alanchiao can you pls review the PR.\r\n\r\nRegards\r\nAmit", "Can one of the admins verify this patch?", "Thanks for the contribution.\r\nUnfortunately, new converter is default now. So we'd better not accept further changes for old converter.\r\nhttps://groups.google.com/a/tensorflow.org/d/msg/tflite/Z_h7706dt8Q/sNrjPj4yGgAJ"]}]