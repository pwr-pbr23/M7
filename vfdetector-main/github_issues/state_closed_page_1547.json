[{"number": 6512, "title": "The meaning of batch_size in ptb_word_lm", "body": "I am new to tensorflow, i am now a little confused about the meaning of batch_size. As commonly known that the meaning of batch_size is the number of samples for each batch, but according to the code in ptb_word_lm, it seems not:\r\nreader.py\r\ndata_len = tf.size(raw_data)  #the number of words in dataset\r\nbatch_len = data_len // batch_size   #what does batch_len mean? the number of batchs?does not make sense\r\n\r\nptb_word_lm.py\r\nself.epoch_size = ((len(data) // batch_size) - 1) // num_steps   #what does epoch_size mean? the number of sequence in each batch?does not make sense\r\n\r\nBut if batch_size means the number of batches, then everything make sense. have i got something misunderstood?", "comments": ["This question is better suited to Stack Overflow. They also monitor it.", "Yes this type of question is better asked on [Stackoverflow](http://stackoverflow.com/questions/tagged/tensorflow)."]}, {"number": 6511, "title": "No module named 'gen_word2vec' and missing tf.models", "body": "I got two problems with tensorflow, which was built today from source. My OS is Mac. \r\n1.I was trying to run the code here https://github.com/tensorflow/models/blob/master/tutorials/embedding/word2vec.py, but received an error: \r\n     ImportError: No module named 'gen_word2vec'\r\nCould anyone help explain where I could find the gen_word2vec.py? \r\n2. Another problem is that I couldn't import tensorflow.models anymore:\r\n    AttributeError: module 'tensorflow' has no attribute 'models'\r\n\r\nThe information of my tensorflow is here:\r\n\r\nName: tensorflow\r\nVersion: 0.12.0\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: http://tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python3.5/site-packages\r\nRequires: protobuf, wheel, numpy, six", "comments": ["@xiaolienahu The models are moved to the separated repo under tensorflow/models. ", "@inflation Thanks. Do you know how I could get the gen_word2vec? ", "It's automatically generated if you do bazel run word2vec target from the\nmodels directory\nhttps://github.com/tensorflow/models/blob/12f279d6f4cb33574bc20109b41eb8a59f40cfd1/tutorials/embedding/BUILD#L111\n\nOn Mon, Dec 26, 2016 at 6:52 PM, xiaolienahu <notifications@github.com>\nwrote:\n\n> @inflation <https://github.com/inflation> Thanks. Do you know how I could\n> get the gen_word2vec?\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6511#issuecomment-269261595>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHOoC1uNX5x95zHE2xzbprfzai4FNks5rMH1ogaJpZM4LV_TF>\n> .\n>\n", "@yaroslavvb Thanks. I am new to the bazel. Could you show me how to bazel run the target? \r\nWhat I tried is to clone the /models to /tensorflow/tensorflow and then go to /models/tutorials/embedding and do the command: bazel build :gen_word2vec. Then I got an error: \r\n\r\nERROR: error loading package 'tutorials/embedding': Extension file not found. Unable to load package for '//tensorflow:tensorflow.bzl': BUILD file not found on package path.\r\nINFO: Elapsed time: 0.061s", "Sounds like Bazel is looking for files in regular tensorflow repo, so you need to clone that as well. Maybe tensorflow models need to be checked out as a submodule? There's probably people on tensorflow models issue tracker that could help too", "CC @nealwu ", "Unfortunately I don't know of a way right now to build the embedding models with bazel. I have a pull request in the models repo that gets the model to run if you compile the ops on your own: https://github.com/tensorflow/models/pull/802. Take a look and let me know if that works for you.", "Closing due to lack of activity but please reopen if you need more help."]}, {"number": 6510, "title": "Tensorflow0.08+cuda7.5+cudnn v4, GPU is not used as wished", "body": "    I have installed Tensorflow0.08+cuda7.5+cudnn v4 by Anaconda installation. However, when I was training the DDPG network, I found that the speed was rather slow and the computation was mainly done in CPU instead of GPU. Hope someone can help me out.\r\n    Regards,\r\n    Cardwing", "comments": ["You really need to give us some more info. Run a really simple tensor flow program and paste the output here", "I will close this issue.\r\nPlease try installing the latest version of TF (with latest versions of cuda and cudnn).\r\nIf you still run into the problem, please file a new issue.\r\nAnd when filing the issue, please fill out the template.\r\nOtherwise, we will only be able to point you to the docs.\r\n"]}, {"number": 6509, "title": "Issue with tf.one_hot() in 0.12.0 in GPU mode (CUDA_ERROR_ILLEGAL_ADDRESS)", "body": "I'm using a LeNet-5 mnist example from Udacity's course. Link to the source code is below.\r\nTraining works ok on a CPU (config = tf.ConfigProto(device_count = {'GPU': 0})),\r\nbut fails in a GPU mode with the following 'CUDA_ERROR_ILLEGAL_ADDRESS' error:\r\n\r\n> I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\nname: GeForce GTX 1060 6GB\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7845\r\npciBusID 0000:01:00.0\r\nTotal memory: 6.00GiB\r\nFree memory: 5.01GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:916] 0:   Y\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)\r\nTraining...\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to query event: **CUDA_ERROR_ILLEGAL_ADDRESS**\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_event_mgr.cc:198] Unexpected Event status: 1\r\n\r\nI have reproduced same error on two setups.\r\nEnvironment 1 (Home PC):\r\n- windows 10; \r\n- latest anaconda 4.2.0, python 3.5; \r\n- cuda 8\r\n- cudnn 5.1 (for win10)\r\n- tensorflow 0.12.0 gpu (https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl)\r\n- GeForce GTX 1060 6Gb\r\n\r\nEnvironment 2 (Work PC):\r\n- windows 7; \r\n- latest anaconda 4.2.0, python 3.5; \r\n- cuda 8\r\n- cudnn 5.1 (for win7)\r\n- tensorflow 0.12.0 gpu (https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl)\r\n- GeForce GTX 660 3Gb\r\n\r\nI'm sharing two scripts with minor changes that allow a workaround:\r\nhttps://drive.google.com/open?id=0B6jkkqMOGy5cNHh3TVpxU283Ykk\r\n\r\nMain difference:\r\nScript from example that crashes (LabLenetBad.py) uses raw mnist label data with the tf.one_hot() call.\r\nThe workaround (LabLenetGood.py) reads mnist data with (one_hot=True) flag and does not use tf.one_hot() call on the Y placeholder.\r\n\r\nI think that tf.one_hot does not work properly on the gpu.", "comments": ["https://github.com/vlfeat/matconvnet/issues/65\r\n\r\nIn this issue, I see that some people were able to go around the problem by changing their drivers.\r\nCan it be the same issue here?", "@gunan I've updated Nvidia's driver to the most recent version (376.33) on my Work PC.\r\n\r\nThe issue still occurs.\r\nI'd like to note that sometimes it triggers only CUDA_ERROR_ILLEGAL_ADDRESS error.\r\nBut sometimes it triggers CUDA_ERROR_ILLEGAL_ADDRESS + some cudnn errors.\r\n\r\n> E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to que\r\nry event: CUDA_ERROR_ILLEGAL_ADDRESS\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\common_runtime\\gpu\\gpu_event_mgr.cc:198] Unexpected Event status: 1\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_IN\r\nTERNAL_ERROR\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stre\r\nam_executor\\cuda\\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_B\r\nAD_PARAM\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\r\n\\kernels\\conv_ops.cc:532] Check failed: stream->parent()->GetConvolveAlgorithms(\r\n&algorithms)\r\n\r\nP.S. I've written a similar comment already, but it has strangely disappeared from the topic.", "I know there is a problem with one_hot(T=uint8) that results in the CUDA_ERROR_ILLEGAL_ADDRESS.\r\nLooked at this in the past but found nothing obvious in the source. \r\nLet me attach a debugger and see if we find this.\r\nThis happens only for T=uint8, int32 will work fine.\r\n", "Thanks for sharing!! I had the same problem and when I replace the tf.one_hot by the following hand-written implementation it finally works.\r\n#instead of    one_hot_y = tf.one_hot(y, 43)\r\n\r\nnum_labels = 43\r\nsparse_labels = tf.reshape(y, [-1, 1])\r\nderived_size = tf.shape(sparse_labels)[0]\r\nindices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\r\nconcated = tf.concat(1, [indices, sparse_labels])\r\noutshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])\r\none_hot_y = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\r\n", "@ebrevdo any idea what the problem is here?", "a simple repro case attached (only happens on windows/gpu).\r\nI'm think this showed only for uint8 in the past but now I see it also for int32.\r\n--\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndata = np.zeros(shape=(3, 5), dtype='int32')\r\ninput = tf.placeholder(tf.int32, data.shape, name=\"input\")\r\none_hot_op = tf.one_hot(input, depth=3, dtype=tf.float32)\r\n\r\ninit = tf.initialize_all_variables()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    print(sess.run(one_hot_op, feed_dict = {input : data})) ", "CC @mrry (for windows) @zheng-xq (for CUDA, in case error message looks familiar)", "Could be a bug in eigens generator API cuda impl that only shows in Windows.", "Do you get the same issue with tf.reverse_sequence?", "tf.reverse_sequence works ok, at least tensorflow/python/kernel_tests/reverse_sequence_op_test.py does pass.\r\ntensorflow/python/kernel_tests/diag_op_test.py fails.\r\nI can collect some info with nvidia debugger ... takes me a little: need to recompile with enough symbol info.", "Merging duplicate issues.\r\n@weixsong @aclaussen1 @buaahsh\r\n\r\nQuoting some information from a duplicate:\r\n(@buaahsh)\r\n\r\n>  Here is my code:\r\n>\r\n>with tf.Session() as sess:\r\n>    # with tf.device(\"/cpu:0\"):\r\n>    x = tf.ones(shape=[3, 3])\r\n>    x_diag = tf.diag_part(x)\r\n>    x_diag_matrix = tf.matrix_diag(x_diag)\r\n>    print(sess.run(x_diag_matrix))\r\n>It works ok on a CPU but fails in a GPU mode with the following 'CUDA_ERROR_ILLEGAL_ADDRESS' >error:\r\n>\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties:\r\n>name: Tesla K40m\r\n>major: 3 minor: 5 memoryClockRate (GHz) 0.745\r\n>pciBusID 0000:27:00.0\r\n>Total memory: 11.16GiB\r\n>Free memory: 11.09GiB\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:916] 0: Y\r\n>I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:27:00.0)\r\n>E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n>E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\n>F c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_event_mgr.cc:198] Unexpected >Event status: 1\r\n>I have tried\r\n>\r\n>x = tf.ones(shape=[3, 3])\r\n>x_diag = tf.diag_part(x)\r\n>and x_diag_matrix = tf.matrix_diag([1., 1., 1.]) , Both work ok in a GPU mode. Maybe the tensor couldn't >be input of tf.matrix_diag() in a Windows GPU mode?\r\n\r\n", "not funny: after recompiling the cuda kernels with -G one_hot works now.\r\nThe diag_op still dies:\r\n>\tCUmodule 1c133fcdc00 - [4] const __operator_()__ - Line 40\tCUDA\r\n \tCUmodule 1c133fcdc00 - [3] const coeff - Line 130\tCUDA\r\n \tCUmodule 1c133fcdc00 - [2] evalScalar - Line 136\tCUDA\r\n \tCUmodule 1c133fcdc00 - [1] run - Line 209\tCUDA\r\n \tCUmodule 1c133fcdc00 - [0] EigenMetaKernel<TensorEvaluator<TensorAssignOp<TensorMap<Tensor<double,int=2,int=1,__int64>,int=16,MakePointer>,TensorGeneratorOp<MatrixDiagPartGenerator<double>,TensorMap<Tensor<double,int=2,int=1,__int64>,int=16,MakePointer> const > const > const ,GpuDevice>,__int64> - Line 244\tCUDA\r\n\r\nI'll spend some more time on this later today.", "Derek, looks like a Windows cuda / eigen issue.", "Sergey, can you run the job with cuda-memcheck?  You may have to recompile -c dbg.  Not sure.", "I'm facing the same issue, I ran the cuda-memcheck on the job and I see a lot of null pointer accesses from EigenMetaKernel.\r\n[error_log.txt](https://github.com/tensorflow/tensorflow/files/695756/error_log.txt)\r\n", "Wondering if anyone is looking into this. An update would be good.", "I'm looking at but have not had luck yet. My biggest issue is that when I compile the kernels with full debug info my repro case doesn't fail anymore. But I found that the one_hot tests in tensorflow/python/kernel_tests/one_hot_op_test.py.py can still repro a crash and before it crashes the results of tests are already wrong. When it crashes the arguments in EigenMetaKernel->EigenMetaKernelEval are wrong, like step_size is some very high number.\r\nI'll spend some more time on it today and might need help if I don't find something.", "@rmlarsen @benoitsteiner \r\nAdding for possible issues in Eigen.", "A small update here: I've managed to reproduce the failures, but I'll have to rely on people more experienced in Eigen/CUDA/MSVC to figure out why this op is being compiled to incorrect code on Windows.\r\n\r\nIn the mean time, I've sent out #6822, which disables the broken GPU kernels for `tf.one_hot()` (and some `tf.matrix_diag()` and `tf.matrix_diag_part()`, which seem to have the same failure mode, and both also use the generator interface), while we work on a fix.", "Hi guys, what's the status on this?\r\nI've encountered the same bug on Windows/GPU with a GTX Titan Black.\r\nWhen I replaced \r\n`target_one_hot=tf.onehot(targets,vocab_size_targets,dtype=tf.float32)`\r\n\r\nwith the workaround by name-name\r\nit worked just fine.\r\n\r\nhere's the function wrapper i used for the workaround:\r\n```\r\ndef one_hot_patch(x,depth):\r\n                #workaround by name-name\r\n                sparse_labels=tf.reshape(x,[-1,1])\r\n                derived_size=tf.shape(sparse_labels)[0]\r\n                indices=tf.reshape(tf.range(0,derived_size,1),[-1,1])\r\n                concated=tf.concat(1,[indices,sparse_labels])\r\n                outshape=tf.concat(0,[tf.reshape(derived_size,[1]),tf.reshape(depth,[1])])\r\n                return tf.sparse_to_dense(concated, outshape,1.0,0.0)\r\ntarget_one_hot=one_hot_patch(targets,vocab_size_targets)\r\n```\r\nmy `targets` and `vocab_size_targets` are both tf.int32 Tensors.\r\n\r\nI'm currently on r0.12 (pip installation) with cuda 8.0 and CuDNN 5.1", "@Pyrestone We disabled the broken GPU kernel for `tf.one_hot()` in the Windows build, so if you upgrade to 1.0.0rc0 you should no longer need the patch.", "@mrry Then the problems are now gone?  (I am using win10 64bit tf-gpu-0.12.1 with cuda 8.0 and CuDNN 5.1) I found that this problem(InternalError: Blas SGEMM launch failed :~) remains even after upgrading tf version to 1.0.0.rc1. \r\n\r\n\r\nI encountered similar issue with 0.12.1 and tried suggested get-arounds and found the results are strange. [Here](https://github.com/jaejun-yoo/Three-ways-to-avoid-tf.one_hot-function-) you can find three get-arounds I have tried to avoid using tf.one_hot().\r\nI found that the substitutes worked fine(give the same output with one-hot) but the final results (came out from the script) were somewhat strange or wrong... I doubt that this is due to the other issue cuz I have only changed the part for one_hot function in the code which worked fine before it. Maybe my fault somewhere?... :(\r\n", "I have the same issue with `tf.one_hot()` . Here is my settings:\r\n\r\n- Windows 10\r\n- NVIDIA GeForce GTX 1070\r\n- Cuda 8.0\r\n- CuDnn 5.1\r\n- TensorFlow 0.12\r\n\r\nError:    `Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS`\r\n             `Kernel died`\r\n\r\n\r\n\r\n", "The problem is resolved in 1.0.0-rc0, 1 or 2..\nPlease upgrade and try again.\n\nOn Wed, Feb 8, 2017 at 9:23 PM, smasoudn <notifications@github.com> wrote:\n\n> I have the same issue with tf.one_hot() . Here is my settings:\n>\n>    - Windows 10\n>    - NVIDIA GeForce GTX 1070\n>    - Cudda 8.0\n>    - CuDnn 5.1\n>    - TensorFlow 0.12\n>\n> Error: Error polling for event status: failed to query event:\n> CUDA_ERROR_ILLEGAL_ADDRESS\n> Kernel died\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6509#issuecomment-278550314>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOdbcNeg2bUAbLAbdDZ9D51-oEuGOks5raqK0gaJpZM4LV8wy>\n> .\n>\n", "tested rc2 windows 10, gtx 1060, cuda 8 cudnn 5.1\r\n\r\nThe kernel diag_op_test fails\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:03:00.0)\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_event_mgr.cc:198] Unexpected Event status: 1\r\n\r\n\r\nI am still getting this error in some code I am running.  Doesnt happen with the cpu version\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:404] error retrieving driver version: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/version\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\kernels\\conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) ", "#6822 explicitly disables diag_op_test because of failures when using GPU.\r\nWe are working on debugging those problems.", "So is there some official statement about what GPUs and versions of CUDA and cudnn work on windows 10 and for all platforms for that matter?  It is just Pascal that has the issue?  It would be helpful if there were some specific information about what features work and don't work, rather than run code and get random errors.\r\n\r\nWhile I know that certain tests fail, I am not familiar enough with tensor flow yet to fully understand what that means for what features of the api won't work.\r\n\r\nThanks", "@gunan I tested rc2 and the error message was gone (which didn't in rc1). Thank you for your comment!", "I come up with the same issue. It can be solved by the solution provided by`name-name`\r\nHere is my computer info:\r\n>  Win 8.1  (64bit)\r\n>  GPU     GT 750M 4G (GK107)\r\n>    CUDA  8.0.60\r\n>  cuDNN  5.1\r\n>  tensorflow-gpu 0.12.1\r\n\r\nI have tried tensorflow-gpu 1.0.0 (not sure whether rc1 or 2) (Install using `pip install tensorflow-gpu`)\r\n\r\nIt actually make things worse, the program will get error in both situations. \r\n(1. with the original code      2. replace the tf.one_hot() ) \r\n\r\nHere is the info I have got in tensorflow-gpu 1.0.0 with `tf.one_hot()`\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-8-967bb02bb6da> in <module>()\r\n      2 \r\n      3 logits = LeNet(x)\r\n----> 4 cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\r\n      5 loss_operation = tf.reduce_mean(cross_entropy)\r\n      6 optimizer = tf.train.AdamOptimizer(learning_rate = rate)\r\n\r\nC:\\Users\\name \\Miniconda3\\envs\\env1\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py in softmax_cross_entropy_with_logits(_sentinel, labels, logits, dim, name)\r\n   1576   \"\"\"\r\n   1577   _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel,\r\n-> 1578                     labels, logits)\r\n   1579 \r\n   1580   # TODO(pcmurray) Raise an error when the labels do not sum to 1. Note: This\r\n\r\nC:\\Users\\name \\Miniconda3\\envs\\env1\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py in _ensure_xent_args(name, sentinel, labels, logits)\r\n   1531   if sentinel is not None:\r\n   1532     raise ValueError(\"Only call `%s` with \"\r\n-> 1533                      \"named arguments (labels=..., logits=..., ...)\" % name)\r\n   1534   if labels is None or logits is None:\r\n   1535     raise ValueError(\"Both labels and logits must be provided.\")\r\n\r\nValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)\r\n```\r\n\r\nThe info I have got in tensorflow-gpu 0.12.1 with `tf.one_hot()` is\r\n```\r\nc:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\n```", "@MikeZhu92 The error you're seeing seems to be from one of the breaking function signature changes that were made before the 1.0 release. Fortunately the solution to *that* problem is simple. Replace the following line in your code:\r\n\r\n```python\r\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\r\n```\r\n\r\n...with the following line that names the arguments:\r\n\r\n```\r\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\r\n```", "@mrry Thank you for help, I didn't realize that yesterday. \r\nIt fixes the issue in tensorflow-gpu 1.0.0. For 0.12.1 it's still give me error message about the cuDNN stuff.\r\nI have switched to 1.0.0 to push myself going through some updated features in the latest version. \r\nTensorflow is evolving really fast \ud83d\udc4d ", "I solved the problem by upgrading cuDNN to v5.1 version. You can have a try.\r\ncuDNN download : https://developer.nvidia.com/rdp/cudnn-download", "I can confirm that upgrading to higher than 0.12 resolved this issue.\r\n\r\n[...gpu_event_mgr.cc:198] Unexpected Event status: 1 lead me to this thread\r\n\r\nMy machine has 2 1080s running tf 0.12.0rc1 and using tf.onehot, causing my gpu driver to crash, as well as python. \r\n\r\nUpgraded to tf 1.0.0 and updated some concat and SparseTensor calls, and my program worked. "]}, {"number": 6508, "title": "PS OOM in Distributed Inception", "body": "We are trying to train Inception model on ImageNet in a distributed setting following the guide [here](https://github.com/tensorflow/models/tree/master/inception). TensorFlow successfully trains the model with 32 workers but with 64 worker, the PS dies with OOM killer. \r\n\r\nIn all of these experiments, PS was running on a separate machine. Looking at the memory consumption of 32 workers, it seems that there is no memory issue and the memory becomes stable after a couple of iterations. With 64 workers, PS dies after allocating all the available memory (32GB) after only two iterations.\r\n\r\nIs this the expected behavior from PS or not? If not, please let us know if we can provide any other information that may help debugging this problem.\r\n\r\n#### Environment info\r\nTensorFlow 0.12\r\nCUDA 8.0\r\nCUDNN 5.1\r\nRAM: 32 GB\r\nGPU: K20\r\n\r\n", "comments": ["How many PS tasks do you have? I would first check CPU utilization/network utilization of PS to make sure you have enough capacity to keep up with the workers. IE, suppose each worker can do a single batch in 2 seconds. With 25M parameters that's 50MB per second per worker both receive and send, so on a shared cloud one might use 10 PS tasks for 32 workers and 20 PS tasks for 64 workers to keep each PS task communication load around 2.5Gbps\r\n\r\nMore generally, you can use Heap Checker from google profiling tools to get a break-down of what is taking up all the memory", "We only have 1 PS task. However, bandwidth shouldn't be an issue in this case since we have a 9.6GB/sec peak injection bandwidth to each node. For 32 workers, the current speed is less than 2 samples per second which should sum up to 3.2GB per second. \r\n**Correction:** I did a miss calculation, the actual value is much smaller because of default batch_size of 32. Processing each batch takes around 16 sec.\r\n\r\nTo provide more details about our infrastructure, we are using the XK nodes in BlueWaters supercomputer (you can find the spec [here](https://bluewaters.ncsa.illinois.edu/hardware-summary)).\r\n\r\nI will try using Heap Checker and hopefully will comeback with mode info.", "What about CPU utilization of your PS task? If your PS CPU can't keep up, you may be using extra memory storing outstanding messages from workers.\r\n\r\nYou could try to slow down your workers as an experiment. Can add `time.sleep` before your `session.run` call, or something like below to add a busy wait. Have your workers send `slow_gradients` instead of `gradients` for aggregation\r\n\r\n```\r\ni = tf.constant(0)\r\nc = lambda i: tf.less(i, 10**5)  # about 1 second on MacBook\r\nb = lambda i: tf.add(i, 1)\r\nr = tf.while_loop(c, b, [i])\r\nwith tf.control_dependencies([r]):\r\n  slow_gradients = tf.identity(gradients)\r\n```", "That can be the case. CPU utilization is at %100 but only one core. It seems to be single threaded. Is there any flag to use more threads?\r\n\r\nWill send you the results of slow gradients as soon as I can.", "More threads can be done with tf.Server(config arg, see #4455 ", "I assume you are referring to `inter_op_parallelism_threads` and `intra_op_parallelism_threads`. Aren't these set to the number of available cores by default?", "They should, although there have been cases when number of cores was\nmisidentified on new architecture\n\nOn Dec 26, 2016 8:05 PM, \"Mohammad Babaeizadeh\" <notifications@github.com>\nwrote:\n\n> I assume you are referring to inter_op_parallelism_threads and\n> intra_op_parallelism_threads. Aren't these set to the number of available\n> cores by default?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6508#issuecomment-269266591>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHIwNhOnMxC_W1i4kk1evL7zeyXzlks5rMI6DgaJpZM4LV8nW>\n> .\n>\n", "@mbz possibly related issue is https://github.com/tensorflow/tensorflow/issues/6116  Current grpc implementation uses too much CPU, there's a patch that fixes the issue", "@mbz There are some guidelines on how to deal with memory leaks in TensorFlow here:\r\n\r\nhttp://stackoverflow.com/documentation/tensorflow/3883/how-to-debug-a-memory-leak-in-tensorflow#t=201612281727521481272\r\n\r\nIn particular, you should try running with tcmalloc, which can prevent heap fragmentation (that sometimes leads to out-of-memory errors with the default `malloc()` implementation).", "@yaroslavvb thanks for all the info. \r\n\r\nadding `tf.ConfigProto(inter_op_parallelism_threads=64,intra_op_parallelism_threads=64)` to `tf.train.Server` solved the issue. CPU utilization is way higher and the memory is stable at ~20GB peaking at 30GB. \r\n\r\nI can dig more into why TF does not pick up the right number of cores if you folks are interested. It would be helpful if you point me to the right code though.\r\n\r\n@mrry this doesn't look like to be a memory leak. it's just high memory consumption due large number of received messages. Adding more threads to PS process (i.e. processing the messages faster) mitigates the memory issue, at least for 32 workers. The memory consumption still seems high though. Probably, because of gRPC overhead?", "@mbz If you are not running with tcmalloc, I'd still recommend that you give it a try. Allocating and then soon after freeing a large number of large message objects may still be causing heap fragmentation.", "@mbz You could check what `port::NumSchedulableCPUs` returns on your system. I see it being used in [local_device.cc](https://github.com/tensorflow/tensorflow/blob/d44d271c9da4d244ce4b2ffaf808adbe4cff759d/tensorflow/core/common_runtime/local_device.cc#L37)  to set number of threads", "@mrry this graph might be interesting. this is the memory of PS overtime (one hour of log).\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1122127/21534139/147af5de-cd28-11e6-8865-9c04686b98d2.png)\r\n\r\nwhich is in sync with network:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1122127/21534144/24ebf44a-cd28-11e6-8539-ee27de20e32f.png)\r\n\r\nunfortunately, it seems that Blue Waters (Cray to be more accurate) has some issues with `tcmalloc`. From [here](https://bluewaters.ncsa.illinois.edu/known-issues):\r\n`TCMALLOC: Codes may crash in tcmalloc. Cray is working on fixing these. In the mean time, use the flag \"-hsystem_alloc\" to avoid linking in tcmalloc. Using this flag may result in a new set of problems. So use it with caution.`\r\nI will still try it though, hope for the best.", "To summarize, it looks like parameter server on Cray starts configured to use 1 core, which is not enough to keep up with 64 workers. As a result, the memory usage of ps grows without bound, possibly due to grpc backlog. The growth without bound might be something that can only be fixed on grpc side -- https://github.com/grpc/grpc\r\n\r\nAs far as TensorFlow thinking Cray computers only have one core, that could be filed as a separate issue.\r\n\r\n@mbz Is there anything else to do on this issue before it's closed?", "I believed that summarized it nicely. Thanks."]}, {"number": 6507, "title": "Feature request: Add float16 support for Conv3D, MaxPool3D and AvgPool3D ops", "body": "Support for `tf.float16 dtype` was recently added ([#1300](https://github.com/tensorflow/tensorflow/issues/1300)) to a bunch of ops. Can we add it for conv3d too, please?\r\n\r\nconv3d is important to development of videos and medical images systems. Since both consumes a lot of memory, it would be good to have fp16 support to allow deeper models.", "comments": ["@benoitsteiner do you know if this is being worked on?", "Any update on when this might be available?", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 6506, "title": "Error in `python': free(): invalid pointer: when running example frac.cc op", "body": "Frac.cc as in repo:\r\n```c++\r\n// legal stuff\r\n\r\n// An example Op.\r\n\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nREGISTER_OP(\"Fact\")\r\n    .Output(\"fact: string\")\r\n    .Doc(R\"doc(\r\nOutput a fact about factorials.\r\n)doc\");\r\n\r\nclass FactOp : public OpKernel {\r\n public:\r\n  explicit FactOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    // Output a scalar string.\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context,\r\n                   context->allocate_output(0, TensorShape(), &output_tensor));\r\n    auto output = output_tensor->template scalar<string>();\r\n\r\n    output() = \"0! == 1\";\r\n  }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"Fact\").Device(DEVICE_CPU), FactOp);\r\n```\r\n\r\nbazel build:\r\n```bazel\r\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\r\n\r\ntf_custom_op_library(\r\n    name = \"fact.so\",\r\n    srcs = [\"fact.cc\"],\r\n)\r\n```\r\n\r\nTest script:\r\n```python\r\nimport tensorflow as tf\r\nfact_module = tf.load_op_library('tensorflow/bazel-bin/tensorflow/core/user_ops/fact.so')\r\n```\r\n\r\nfull core dump: http://pastebin.com/69rLzybC\r\n\r\nI'm trying to write tf op. Tf repo is on origin/r0.12 tag\r\n\r\nWhat is going on and how do I fix it/implement my custom op?\r\nPython version 3.5.2\r\nLinux protagonist 4.8.13-1-ARCH #1 SMP PREEMPT Fri Dec 9 07:24:34 CET 2016 x86_64 GNU/Linux\r\n", "comments": ["What distriubtion and version of Linux?", "Arch Linux, \r\n\r\n```\r\nuname -a\r\nLinux protagonist 4.8.13-1-ARCH #1 SMP PREEMPT Fri Dec 9 07:24:34 CET 2016 x86_64 GNU/Linux\r\n```\r\n\r\nSystem is up to date (run update just now and recompiled/retested...same issue)", "and are you trying to load the built dso with a prebuilt tensorflow binary or did you build the tensorflow binary from the same bazel environment as the extension dso?", "I'm using prebuild binary from pip, ```tf.__version__ == 0.12.0```. Could it be something related to ABI? Since when I installed warp-ctc I had ABI compile problems where I had to put additional flag.", "I would guess that it is pretty likely. If you were using ubuntu 14 (which is what we build on) I'd guess it would be likely to work. Try building your tensorflow from source on the same machine and see if that resolves the problem. Good luck!", "Yeah, that fixed it when I rebuild from source. Can I somehow add ABI flag, that is ```-D_GLIBCXX_USE_CXX11_ABI=0``` when compiling using bazel? And then I can test if that's  the issue?", "I'm not a bazel expert, but the docs seem to indicate this could work. https://bazel.build/versions/master/docs/bazel-user-manual.html\r\n`bazel build --copt \"-D_GLIBCXX_USE_CXX11_ABI=1`\r\nmaybe?\r\n\r\n\r\n", "Closing due to lack of recent activity. We will reopen when additional information becomes available. Thanks!"]}, {"number": 6505, "title": "Update docker setup docs", "body": "According to [Using TensorFlow via Docker](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/README.md), `docker_run_gpu.sh` has been removed and only `nvidia-docker` is recommended for GPU support.\r\n\r\nThis PR updates getting started guide to reflect those changes.", "comments": ["Can one of the admins verify this patch?", "@feiskyer Sorry - I lost track. If the script is already moved, there is no need to refer to it here.", "PR merged. Thanks, @feiskyer !"]}, {"number": 6503, "title": "Feature Request: Gradient for SVD op", "body": "The gradient for the SVD op would be very useful so that it could be used in networks and cost functions.  Currently when trying to use SVD I get the follow:\r\n\r\nLookupError: No gradient defined for operation 'Svd' (op type: Svd)\r\n\r\nSo my request is for the gradient for the SVD op\r\n", "comments": ["the algorithm is in section 3.2 of [An extended collection of matrix derivative results\r\nfor forward and reverse mode algorithmic\r\ndifferentiation](https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf)", "We are currently working on this internally and I've heard it may be close. @rmlarsen knows more.", "@aselle @rmlarsen Any update on this?", "As mentioned, this is underway internally. I believe both the person working on it and I are just back from vacation. I assume this will be available within the coming month.", "Hi @rmlarsen, I am looking through the `rc-v1.0` and I don't see the `SvdGrad` op registered [here](https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/core/ops/linalg_ops.cc). Is there somewhere else I should look for it?", "Yes, this would help experiment with spectral methods. @rmlarsen @aselle @yaroslavvb  Is this still in active development ?", "Is there any update on this? It would be super useful for our work !", "@rmlarsen what is the update on this ?", "There is a current implementation already but it is not yet complete. I was busy with other projects but I will try to come back to this next week.", "Hello,\r\nAny news on the features? Would be very helpful to me too.", "Hello,\r\nI was also wondering if there was any progress on this?", "Would be great to have this functionality.", "```python\r\ndef svd(A, full_matrices=False, compute_uv=True, name=None):\r\n  # since dA = dUSVt + UdSVt + USdVt\r\n  # we can simply recompute each matrix using A = USVt\r\n  # while blocking gradients to the original op.\r\n  _, M, N = A.get_shape().as_list()\r\n  P = min(M, N)\r\n  S0, U0, V0 = map(tf.stop_gradient, tf.svd(A, full_matrices=True, name=name))\r\n  Ui, Vti = map(tf.matrix_inverse, [U0, tf.transpose(V0, (0, 2, 1))])\r\n  # A = USVt\r\n  # S = UiAVti\r\n  S = tf.matmul(Ui, tf.matmul(A, Vti))\r\n  S = tf.matrix_diag_part(S)\r\n  if not compute_uv:\r\n    return S\r\n  Si = tf.pad(tf.matrix_diag(1/S0), [[0,0], [0,N-P], [0,M-P]])\r\n  # U = AVtiSi\r\n  U = tf.matmul(A, tf.matmul(Vti, Si))\r\n  U = U if full_matrices else U[:, :M, :P]\r\n  # Vt = SiUiA\r\n  V = tf.transpose(tf.matmul(Si, tf.matmul(Ui, A)), (0, 2, 1))\r\n  V = V if full_matrices else V[:, :N, :P]\r\n  return S, U, V\r\n```", "Hi, \r\n@aselle @rmlarsen Any news?", "Hi, I have composed one gradient function based on Matrix-backpropagation paper. Hope it helps.\r\n```python\r\n\r\ndef matrix_symmetric(x):\r\n    return (x + tf.transpose(x, [0,2,1])) / 2\r\n\r\ndef get_eigen_K(x, square=False):\r\n    \"\"\"\r\n    Get K = 1 / (sigma_i - sigma_j) for i != j, 0 otherwise\r\n\r\n    Parameters\r\n    ----------\r\n    x : tf.Tensor with shape as [..., dim,]\r\n\r\n    Returns\r\n    -------\r\n\r\n    \"\"\"\r\n    if square:\r\n        x = tf.square(x)\r\n    res = tf.expand_dims(x, 1) - tf.expand_dims(x, 2)\r\n    res += tf.eye(tf.shape(res)[1])\r\n    res = 1 / res\r\n    res -= tf.eye(tf.shape(res)[1])\r\n\r\n    # Keep the results clean\r\n    res = tf.where(tf.is_nan(res), tf.zeros_like(res), res)\r\n    res = tf.where(tf.is_inf(res), tf.zeros_like(res), res)\r\n    return res\r\n\r\n@tf.RegisterGradient('Svd')\r\ndef gradient_svd(op, grad_s, grad_u, grad_v):\r\n    \"\"\"\r\n    Define the gradient for SVD\r\n    References\r\n        Ionescu, C., et al, Matrix Backpropagation for Deep Networks with Structured Layers\r\n        \r\n    Parameters\r\n    ----------\r\n    op\r\n    grad_s\r\n    grad_u\r\n    grad_v\r\n\r\n    Returns\r\n    -------\r\n    \"\"\"\r\n    s, u, v = op.outputs\r\n    v_t = tf.transpose(v, [0,2,1])\r\n\r\n    with tf.name_scope('K'):\r\n        K = get_eigen_K(s, True)\r\n    inner = matrix_symmetric(K * tf.matmul(v_t, grad_v))\r\n\r\n    # Create the shape accordingly.\r\n    u_shape = u.get_shape()[1].value\r\n    v_shape = v.get_shape()[1].value\r\n\r\n    # Recover the complete S matrices and its gradient\r\n    eye_mat = tf.eye(v_shape, u_shape)\r\n    realS = tf.matmul(tf.reshape(tf.matrix_diag(s), [-1, v_shape]), eye_mat)\r\n    realS = tf.transpose(tf.reshape(realS, [-1, v_shape, u_shape]), [0, 2, 1])\r\n\r\n    real_grad_S = tf.matmul(tf.reshape(tf.matrix_diag(grad_s), [-1, v_shape]), eye_mat)\r\n    real_grad_S = tf.transpose(tf.reshape(real_grad_S, [-1, v_shape, u_shape]), [0, 2, 1])\r\n\r\n    dxdz = tf.matmul(u, tf.matmul(2 * tf.matmul(realS, inner) + real_grad_S, v_t))\r\n    return dxdz\r\n```", "@kcyu2014 Why don't you make a PR?", "@kcyu2014 Thx for the code, but it is missing the ` get_eigen_K ` and `matrix_symmetric` implementations. Could you post them? ", "@albertpumarola Sorry I forgot it and now its updated :)", "+1 would be very useful :) @rmlarsen ", "Yes, please add this feature, super helpful for matrix nuclear norm. @rmlarsen ", "Have you test the code @kcyu2014 contribute? Is it work? @albertpumarola ", "I tried it and it didn't work for me :/ Can find logs later if it's helpful for people", "The implementation by @kcyu2014 does not have gradients for U, only for S and V (those seem to agree with numerical gradients though).", "I need this feature badly. Could someone get it done fast?", "Hi, any update about this? I tried the code by @kcyu2014 but it didn't work properly unfortunately.", "@rmlarsen. Any update?", "Sorry for the lack of progress on this. I will try to set aside a few days to get this in now. Especially now that we have GPU support for all the linear algebra ops (minus complex SVD), this is a gaping hole.", "[here is](https://gist.github.com/psycharo/60f58d5435281bdea8b9d4ee4f6e895b) an implementation that should work for square matrices.", "@psycharo seems to work but sometimes the loss goes to NaN when using svd in the loss (nuclear norm), but that might be the problem of my architecture not the SVD backprop code", "@hicham-eyeem -- TensorFlow SVD has some bugs that cause NaNs sometimes -- https://github.com/tensorflow/tensorflow/issues/9234 , you could double check if this is fixed using numpy version", "@yaroslavvb ah ok, thank you for pointing that out and actually even adding some regularisation doesn't help. Do you know the reason why it would give NaNs sometimes?\r\nI guess also we can avoid using SVD by rather using a matrix factorization formulation if it's used in the loss function, since the matrix factorization formulation would require only matmul and transpose ops (+ some constraints that can be linearized with a proximal form)", "FYI: I have an initial version of this out for review internally.", "@rmlarsen great, thank you, can't wait to try it out :)", "The code was submitted and should appear on github within a day or so. There are certain restrictions for the gradient computation that I welcome contributions to lift:\r\n\r\n\"This initial version has the following restrictions:\r\n  Only supports statically known inner matrix dimensions m and n.\r\n\r\nBackpropagating through U and V (i.e. backpropagating through SVD nodes with compute_uv=True) has further restrictions:\r\n  a) Only supports real tensors.\r\n  b) Only supports square and \"almost square\" matrices where the number of rows and columns differ by at most 1.\r\n  c) full_matrices must be true also. This does not currently have severe implications, given the restriction in b).\"\r\n", "Let me close this and open a new issue for extending support for more general matrices.", "@caisq thanks for the quick push!", "Followup issue is https://github.com/tensorflow/tensorflow/issues/13641", "@rmlarsen was the formula from https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf used or were there a different formula used? ", "> Hi, I have composed one gradient function based on Matrix-backpropagation paper. Hope it helps.\r\n> \r\n> ```python\r\n> def matrix_symmetric(x):\r\n>     return (x + tf.transpose(x, [0,2,1])) / 2\r\n> \r\n> def get_eigen_K(x, square=False):\r\n>     \"\"\"\r\n>     Get K = 1 / (sigma_i - sigma_j) for i != j, 0 otherwise\r\n> \r\n>     Parameters\r\n>     ----------\r\n>     x : tf.Tensor with shape as [..., dim,]\r\n> \r\n>     Returns\r\n>     -------\r\n> \r\n>     \"\"\"\r\n>     if square:\r\n>         x = tf.square(x)\r\n>     res = tf.expand_dims(x, 1) - tf.expand_dims(x, 2)\r\n>     res += tf.eye(tf.shape(res)[1])\r\n>     res = 1 / res\r\n>     res -= tf.eye(tf.shape(res)[1])\r\n> \r\n>     # Keep the results clean\r\n>     res = tf.where(tf.is_nan(res), tf.zeros_like(res), res)\r\n>     res = tf.where(tf.is_inf(res), tf.zeros_like(res), res)\r\n>     return res\r\n> \r\n> @tf.RegisterGradient('Svd')\r\n> def gradient_svd(op, grad_s, grad_u, grad_v):\r\n>     \"\"\"\r\n>     Define the gradient for SVD\r\n>     References\r\n>         Ionescu, C., et al, Matrix Backpropagation for Deep Networks with Structured Layers\r\n>         \r\n>     Parameters\r\n>     ----------\r\n>     op\r\n>     grad_s\r\n>     grad_u\r\n>     grad_v\r\n> \r\n>     Returns\r\n>     -------\r\n>     \"\"\"\r\n>     s, u, v = op.outputs\r\n>     v_t = tf.transpose(v, [0,2,1])\r\n> \r\n>     with tf.name_scope('K'):\r\n>         K = get_eigen_K(s, True)\r\n>     inner = matrix_symmetric(K * tf.matmul(v_t, grad_v))\r\n> \r\n>     # Create the shape accordingly.\r\n>     u_shape = u.get_shape()[1].value\r\n>     v_shape = v.get_shape()[1].value\r\n> \r\n>     # Recover the complete S matrices and its gradient\r\n>     eye_mat = tf.eye(v_shape, u_shape)\r\n>     realS = tf.matmul(tf.reshape(tf.matrix_diag(s), [-1, v_shape]), eye_mat)\r\n>     realS = tf.transpose(tf.reshape(realS, [-1, v_shape, u_shape]), [0, 2, 1])\r\n> \r\n>     real_grad_S = tf.matmul(tf.reshape(tf.matrix_diag(grad_s), [-1, v_shape]), eye_mat)\r\n>     real_grad_S = tf.transpose(tf.reshape(real_grad_S, [-1, v_shape, u_shape]), [0, 2, 1])\r\n> \r\n>     dxdz = tf.matmul(u, tf.matmul(2 * tf.matmul(realS, inner) + real_grad_S, v_t))\r\n>     return dxdz\r\n> ```\r\n\r\nthis is very useful, we are assuming that we don't use the U matrix when we have decomposed the original matrix A into U s V, since we do not calculate the derivative respect to U anywhere. "]}, {"number": 6502, "title": "Insert rows ( arrays ) into a tensor at specific index , and index keeps on changing with batch of data", "body": "I have function , to which I have to pass a dynamic list of values and dynamic batch size, along with feed dict in Tensorflow. The tf.unstack function accepts an int only. This int here is my batch size and doc_length is list of values. It will change with each batch of data. The idea here, from RNN, i am getting a state matrix and I have to insert zeros at some particular indices.\r\n\r\nHow to pass these dynamic batch size and list of values with sess.run( _ , feed_dict) for every batch of data ? Hope the question is clear.\r\n\r\n```\r\n### sentence_vec is the output from an RNN \r\n\r\ndef sentence_converter(sentence_vec, doc_length , batch_size):\r\n    sentence_tensors = tf.unstack(sentence_vec, batch_size, axis=0)\r\n    max_len = max(doc_length)\r\n\r\n    zero_tensor = tf.zeros(self.encoder_units)\r\n    temp = 0\r\n    for elem in doc_length:\r\n        if elem == max_len:\r\n            continue\r\n        diff = max_len - elem\r\n        diff_range = range(1, diff+1)\r\n        for sub_elem in diff_range:\r\n            insert = temp + sub_elem + elem\r\n            sentence_tensors.insert(insert-1, zero_tensor)\r\n        temp = insert\r\n    return tf.stack(sentence_tensors)\r\n\r\nX = tf.placeholder(tf.int32, shape=[None, None], name='X_input')\r\nX_len = tf.placeholder(tf.int32, shape=[None], name='X_length')\r\n\r\nenc_cell = tf.nn.rnn_cell.GRUCell(self.enco:der_units)#python.ops.rnn_cell.GRUCell\r\nenc_out, enc_state = tf.nn.dynamic_rnn(cell=enc_cell, inputs=X,\r\n                             sequence_length=X_len, dtype=tf.float32)\r\nfinal_state = sentence_converter(enc_state , batch_size , doc_len)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n      sess = tf.Session()\r\n      sess.run(tf.initialize_all_variables())\r\n      output_state = sess.run(final_state , feed_dict(X:np.random.randn(2,11) , X_len:[3,2])\r\n\r\n\r\n```\r\n\r\nSo, here 2 is the batch size . Suppose the doc_len = [5,7] , how will I pass these to get the final_state , each time. These doc_len is dynamically changing list with each batch. ", "comments": ["@ebrevdo @alrojo - It is to create a Heirarchical Attention Mechanism . Any thoughts ?", "Please ask this question on Stack Overflow. Others might have encountered this use case and have an elegant solution."]}, {"number": 6501, "title": "Issue with tf v0.12.0 when using split", "body": "the code run correctly with tf 0.12rc1.0, but when using 0.12.0, an error occured. \r\nhere is the log. \r\nI tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally\r\nW tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nTraceback (most recent call last):\r\n  File \"/home/keith/PycharmProjects/pic2sentence/Model.py\", line 359, in <module>\r\n    tf.app.run()\r\n  File \"/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/keith/PycharmProjects/pic2sentence/Model.py\", line 343, in main\r\n    model = Model()\r\n  File \"/home/keith/PycharmProjects/pic2sentence/Model.py\", line 42, in __init__\r\n    outputs = self.alex_net2(self.encoder_inputs, is_training)  # [None, 4096]\r\n  File \"/home/keith/PycharmProjects/pic2sentence/Model.py\", line 124, in alex_net2\r\n    conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\r\n  File \"/home/keith/PycharmProjects/pic2sentence/Model.py\", line 91, in conv\r\n    input_groups = tf.split(3, group, input)\r\n  File \"/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1319, in split\r\n    split_dim=axis, num_split=num_or_size_splits, value=value, name=name)\r\n  File \"/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3385, in _split\r\n    num_split=num_split, name=name)\r\n  File \"/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 509, in apply_op\r\n    (prefix, dtypes.as_dtype(input_arg.type).name))\r\nTypeError: Input 'split_dim' of 'Split' Op has type float32 that does not match expected type of int32.\r\n", "comments": ["split argument order changed in HEAD -- https://github.com/tensorflow/tensorflow/blob/64edd34ce69b4a8033af5d217cb8894105297d8a/RELEASE.md", "@yaroslavvb Thanks a lot", "@yaroslavvb  Thanks. I thought my python release has bug..."]}, {"number": 6500, "title": "Issue with Tensorflow on windows when using TensorForestEstimator", "body": "I already have conda installation in my Windows, I installed tensorflow using pip and it was working fine based on the testing the [tensorflow installation](https://www.tensorflow.org/get_started/os_setup#test_the_tensorflow_installation).\r\n\r\nWhen I'm using TensorForestEstimator, I',m getting the following error\r\n**lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\_training_ops.so not found**\r\n\r\nComplete details\r\n\r\n**hparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\r\n        num_trees=2, max_nodes=1000, num_classes=2, num_features=9, model_dir='model/fit/')**\r\n\r\n**forest_classifier = tf.contrib.learn.TensorForestEstimator(hparams)**\r\n\r\nWarning Messages:\r\n\r\nWARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\username\\AppData\\Local\\Temp\\tmpu1vjyu11\r\nINFO:tensorflow:Using default config.\r\nINFO:tensorflow:Using config: {'tf_random_seed': None, 'keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000218062DCE10>, 'save_checkpoints_steps': None, 'save_checkpoints_secs': 600, '_task_id': 0, 'keep_checkpoint_every_n_hours': 10000, 'tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1\r\n}\r\n, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_environment': 'local', 'save_summary_steps': 100, '_task_type': None, '_evaluation_master': ''}\r\n\r\n**forest_classifier.fit(x=training_data, y=Y_train, batch_size=10, steps=2000)**\r\n\r\nWARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\random_forest.py:237 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\random_forest.py:237 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\random_forest.py:237 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nINFO:tensorflow:Constructing forest with params = \r\nINFO:tensorflow:{'dominate_method': 'hoeffding', 'dominate_fraction': 0.99, 'bagged_num_features': 9, 'split_initializations_per_input': 1, 'num_trees': 2, 'base_random_seed': 0, 'valid_leaf_threshold': 1, 'bagged_features': None, 'min_split_samples': 5, 'bagging_fraction': 1.0, 'num_classes': 2, 'num_features': 9, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 10, 'split_after_samples': 250, 'model_dir': 'model/fit/', 'num_outputs': 1, 'max_nodes': 1000, 'num_output_columns': 3, 'regression': False, 'max_fertile_nodes': 500}\r\nINFO:tensorflow:data path: D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\_training_ops.so\r\n\r\n\r\n**---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-23-095850e88d53> in <module>()\r\n----> 1 forest_classifier.fit(x=training_data, y=Y_train, batch_size=10, steps=200)\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\random_forest.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\r\n    235     self._estimator.fit(input_fn=input_fn, x=x, y=y,\r\n    236                         batch_size=batch_size, steps=steps, monitors=monitors,\r\n--> 237                         max_steps=max_steps)\r\n    238 \r\n    239   @deprecated_arg_values(\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py in new_func(*args, **kwargs)\r\n    189             _call_location(), decorator_utils.get_qualified_name(func),\r\n    190             func.__module__, arg_name, date, instructions)\r\n--> 191       return func(*args, **kwargs)\r\n    192     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\r\n    193         func.__doc__, date, instructions)\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\r\n    353                              steps=steps,\r\n    354                              monitors=monitors,\r\n--> 355                              max_steps=max_steps)\r\n    356     logging.info('Loss for final step: %s.', loss)\r\n    357     return self\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\r\n    697       # cases, but will soon be deleted after the subclasses are updated.\r\n    698       # TODO(b/32664904): Update subclasses and delete the else-statement.\r\n--> 699       train_ops = self._get_train_ops(features, labels)\r\n    700       if isinstance(train_ops, model_fn_lib.ModelFnOps):  # Default signature\r\n    701         train_op = train_ops.train_op\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in _get_train_ops(self, features, labels)\r\n   1050       `ModelFnOps` object.\r\n   1051     \"\"\"\r\n-> 1052     return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n   1053 \r\n   1054   def _get_eval_ops(self, features, labels, metrics):\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py in _call_model_fn(self, features, labels, mode)\r\n   1021         model_fn_results = self._model_fn(features, labels, mode=mode)\r\n   1022     else:\r\n-> 1023       model_fn_results = self._model_fn(features, labels)\r\n   1024 \r\n   1025     if isinstance(model_fn_results, model_fn_lib.ModelFnOps):\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\random_forest.py in _model_fn(features, labels)\r\n    116       _assert_float32(labels)\r\n    117 \r\n--> 118     graph_builder = graph_builder_class(params, device_assigner=device_assigner)\r\n    119     inference = {eval_metrics.INFERENCE_PROB_NAME:\r\n    120                  graph_builder.inference_graph(processed_features,\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\tensor_forest.py in __init__(self, params, device_assigner, variables, tree_variables_class, tree_graphs, training, t_ops, i_ops)\r\n    334             self.variables[i], self.params,\r\n    335             t_ops.Load(), i_ops.Load(), i)\r\n--> 336         for i in range(self.params.num_trees)]\r\n    337 \r\n    338   def _bag_features(self, tree_num, input_data):\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\tensor_forest.py in <listcomp>(.0)\r\n    334             self.variables[i], self.params,\r\n    335             t_ops.Load(), i_ops.Load(), i)\r\n--> 336         for i in range(self.params.num_trees)]\r\n    337 \r\n    338   def _bag_features(self, tree_num, input_data):\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\training_ops.py in Load()\r\n     54       ops_path = resource_loader.get_path_to_datafile(TRAINING_OPS_FILE)\r\n     55       logging.info('data path: %s', ops_path)\r\n---> 56       _training_ops = load_library.load_op_library(ops_path)\r\n     57 \r\n     58       assert _training_ops, 'Could not load _training_ops.so'\r\n\r\nD:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py in load_op_library(library_filename)\r\n     62       # pylint: disable=protected-access\r\n     63       raise errors_impl._make_specific_exception(\r\n---> 64           None, None, error_msg, error_code)\r\n     65       # pylint: enable=protected-access\r\n     66   finally:\r\n\r\nNotFoundError: D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\_training_ops.so not found**\r\n\r\n\r\n\r\n\r\n", "comments": ["Hi!  Thanks for reporting this bug!\r\n\r\nCould you try reproducing it with the latest version of TensorFlow?  I think a change we checked in last month (https://github.com/tensorflow/tensorflow/commit/1943a9bbb87c67ee841eb2b0060b0c83c8770f96) should fix your problem.", "@ThomasColthurst The issue is not yet resolved, Using tensorflow-0.12.1, Still facing\r\n\r\n**NotFoundError: D:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\_training_ops.so not found**"]}, {"number": 6499, "title": "how test a model made tensorflow and python following the code", "body": "```\r\nfrom __future__ import print_function\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport math as math\r\nimport argparse\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('dataset')\r\nargs = parser.parse_args()\r\n\r\ndef file_len(fname):\r\n    with open(fname) as f:\r\n        for i, l in enumerate(f):\r\n            pass\r\n            #print(l)\r\n            #print(\"pass\")\r\n            #print(i)\r\n    return i + 1\r\n\r\ndef read_from_csv(filename_queue):\r\n  reader = tf.TextLineReader(skip_header_lines=1)\r\n  _, csv_row = reader.read(filename_queue)\r\n  record_defaults = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\r\n  col0,col1, col2, col3, col4, col5,col6, col7, col8, col9, col10,col11, col12, col13, col14, col15,col16, col17, col18, col19, col20,col21, col22, col23, col24, col25,col26, col27, col28, col29, col30,col31, col32, col33, col34, col35,col36, col37, col38, col39, col40,col41, col42, col43, col44, col45,col46, col47, col48, col49, col50,col51, col52, col53, col54, col55,col56, colLabel = tf.decode_csv(csv_row, record_defaults=record_defaults)\r\n  features = tf.pack([col0,col1, col2, col3, col4, col5,col6, col7, col8, col9, col10,col11, col12, col13, col14, col15,col16, col17, col18, col19, col20,col21, col22, col23, col24, col25,col26, col27, col28, col29, col30,col31, col32, col33, col34, col35,col36, col37, col38, col39, col40,col41, col42, col43, col44, col45,col46, col47, col48, col49, col50,col51, col52, col53, col54, col55,col56])  \r\n  label = tf.pack([colLabel])  \r\n  return features, label\r\n\r\ndef input_pipeline(batch_size, num_epochs=1):\r\n  #filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=num_epochs, shuffle=True)  \r\n  \r\n  [args.dataset]\r\n  filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=1, shuffle=True)  \r\n\r\n  example, label = read_from_csv(filename_queue)\r\n  min_after_dequeue = 4598\r\n  #capacity = min_after_dequeue + 3 * batch_size\r\n  capacity = 4599\r\n  example_batch, label_batch = tf.train.shuffle_batch(\r\n      [example, label], batch_size=batch_size, capacity=capacity,\r\n      min_after_dequeue=min_after_dequeue)\r\n  return example_batch, label_batch\r\n  \r\ndef input_pipeline_test(batch_size, num_epochs=1):\r\n  #filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=num_epochs, shuffle=True)  \r\n  \r\n  \r\n  print(\"filename_queue_test\")\r\n  filename_queue_test = tf.train.string_input_producer([args.dataset], num_epochs=1, shuffle=True)  \r\n\r\n  example, label = read_from_csv(filename_queue_test)\r\n  print(\"filename_queue_test end\")\r\n  min_after_dequeue = 1379\r\n  #capacity = min_after_dequeue + 3 * batch_size\r\n  capacity = 1380\r\n  example_batch, label_batch = tf.train.shuffle_batch(\r\n      [example, label], batch_size=batch_size, capacity=capacity,\r\n      min_after_dequeue=min_after_dequeue)\r\n  print(example_batch)\r\n  return example_batch, label_batch\r\n#####################################################################################################################################\r\n#####################################################################################################################################\r\n#####################################################################################################################################\r\n# Parameters\r\nlearning_rate = 0.6\r\ntraining_epochs = 1\r\nbatch_size = 1000\r\ndisplay_step = 1\r\n\r\n# Network Parameters\r\nn_hidden_1 = 100# 1st layer number of features\r\nn_hidden_2 = 30# 2nd layer number of features\r\nn_input = 57 # MNIST data input (img shape: 28*28)\r\nn_classes = 1 # MNIST total classes (0-9 digits)\r\n\r\n\r\n# Create model\r\ndef multilayer_perceptron(x, weights, biases):\r\n    # Hidden layer with RELU activation\r\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\r\n    layer_1 = tf.nn.relu(layer_1)\r\n    # Hidden layer with RELU activation\r\n    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\r\n    layer_2 = tf.nn.relu(layer_2)\r\n    # Output layer with linear activation\r\n    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\r\n    return out_layer\r\n\r\n# Store layers weight & bias\r\nweights = {\r\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\r\n    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\r\n}\r\nbiases = {\r\n    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\r\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n    'out': tf.Variable(tf.random_normal([n_classes]))\r\n}\r\n\r\n\r\n\r\n\r\n\r\n#########################################################################################################################################\r\n#########################################################################################################################################\r\n#print(\"file_len(args.dataset) - 1\")\r\n#print(file_len(args.dataset) - 1)\r\nfile_length = file_len(args.dataset) - 1\r\n#file_length = 4599\r\nexamples, labels = input_pipeline(file_length, 1)\r\nexamples_batch=tf.global_variables()\r\nlabels_batch=tf.global_variables()\r\nexamples_batch_test=tf.global_variables()\r\nlabels_batch_test=tf.global_variables()\r\nx = tf.placeholder(\"float\", [None, 57])\r\ny = tf.placeholder(\"float\", [None, 1])\r\n\r\npred = multilayer_perceptron(x, weights, biases)\r\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\r\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\r\nconfig=tf.ConfigProto(inter_op_parallelism_threads=2)\r\nwith tf.Session(config=config) as sess:\r\n  init_op = tf.group(tf.initialize_all_variables(),tf.initialize_local_variables())\r\n  sess.run(init_op)\r\n  #tf.initialize_all_variables().run()\r\n\r\n  # start populating filename queue\r\n  coord = tf.train.Coordinator()\r\n  threads = tf.train.start_queue_runners(coord=coord)\r\n\r\n  try:\r\n    while not coord.should_stop():\r\n      examples_batch, labels_batch = sess.run([examples, labels])\r\n    #x, y = sess.run([examples, labels])\r\n     \r\n  except tf.errors.OutOfRangeError:\r\n    print('Done training, epoch reached')\r\n    #print(examples_batch)\r\n    #print(labels_batch)\r\n\r\n    # Training cycle\r\n    for epoch in range(training_epochs):\r\n        avg_cost = 0.0\r\n        total_batch = 1\r\n        # Loop over all batches\r\n        for i in range(total_batch):\r\n            # Run optimization op (backprop) and cost op (to get loss value)\r\n            _, c = sess.run([optimizer, cost], feed_dict={x: examples_batch,\r\n                                                          y: labels_batch})\r\n            print(\"c\")\r\n            print(c)\r\n            #c = {x: batch_x,y: batch_y}\r\n            # Compute average loss\r\n            #print(c / total_batch)\r\n            avg_cost = c / total_batch\r\n        # Display logs per epoch step\r\n        if epoch % display_step == 0:\r\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\r\n                \"{:.9f}\".format(avg_cost))\r\n    print(\"Optimization Finished!\")\r\n    print(\"TEST BLOCK!\")\r\n    try:\r\n        file_length_test=1379\r\n        examples_test, labels_test = input_pipeline_test(file_length_test, 1)\r\n        print(\"file print\")\r\n        print(sess.run(labels_test))\r\n        print(\"file print end\")\r\n    except:\r\n        print(\"tftftftftfttftftftft\")\r\n        \r\n    coord.request_stop()\r\n\r\n\r\n# with tf.Session() as sess_test:\r\n  # init_op = tf.group(tf.initialize_all_variables(),tf.initialize_local_variables())\r\n  # sess_test.run(init_op)\r\n  # #tf.initialize_all_variables().run()\r\n\r\n  # # start populating filename queue\r\n  # coord = tf.train.Coordinator()\r\n  # threads = tf.train.start_queue_runners(coord=coord)\r\n\r\n  # print(\"TEST BLOCK!\")\r\n  # file_length_test=1379\r\n  # examples_test, labels_test = input_pipeline_test(file_length_test, 1)\r\n  # print(examples_test)\r\n # # start populating filename queue\r\n  # coord = tf.train.Coordinator()\r\n  # threads = tf.train.start_queue_runners(coord=coord)\r\n  # #with tf.Session() as sess_test:\r\n  # try:\r\n       # while not coord.should_stop():\r\n           # examples_batch_test, labels_batch_test = sess_test.run([examples_test, labels_test])\r\n           # #x, y = sess_test.run([examples, labels])\r\n        \r\n  # except tf.errors.OutOfRangeError:\r\n       # # Test model\r\n       # correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\r\n       # # Calculate accuracy\r\n       # accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n       # print(\"helooOOOOO\")\r\n       # print(\"Accuracy:\", accuracy.eval({x: examples_batch_test, y: labels_test}))\r\n    \r\n    \r\n    \r\n  # coord.request_stop()\r\n\r\ncoord.join(threads) \r\n\r\n#######################################################################################################################################\r\n\r\n```\r\n\r\nC:\\Users\\ABC\\Desktop\\DemoTensarflow>cmd\r\nMicrosoft Windows [Version 6.1.7601]\r\nCopyright (c) 2009 Microsoft Corporation.  All rights reserved.\r\n\r\nC:\\Users\\ABC\\Desktop\\DemoTensarflow>python ReadTF_mod.py train.csv\r\nWARNING:tensorflow:From ReadTF_mod.py:124 in <module>.: initialize_all_variables\r\n (from tensorflow.python.ops.variables) is deprecated and will be removed after\r\n2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nWARNING:tensorflow:From ReadTF_mod.py:124 in <module>.: initialize_local_variabl\r\nes (from tensorflow.python.ops.variables) is deprecated and will be removed afte\r\nr 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.local_variables_initializer` instead.\r\nDone training, epoch reached\r\nc\r\n0.0\r\nEpoch: 0001 cost= 0.000000000\r\nOptimization Finished!\r\nTEST BLOCK!\r\nfilename_queue_test\r\nfilename_queue_test end\r\nTensor(\"shuffle_batch_1:0\", shape=(1379, 57), dtype=float32)\r\nfile print\r\n^C\r\n\r\nthe program gets stuck\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Did you try asking on SO? It's seems to be better suited for it and they also monitor there.", "Yes this kind of question is better asked on [Stackoverflow](http://stackoverflow.com/questions/tagged/tensorflow)."]}, {"number": 6498, "title": "Fix comment on update_op of streaming_concat()", "body": "I'm not good at writing in English. Could someone improve it?", "comments": ["Can one of the admins verify this patch?", "@shoyer  could you take a look? Thanks.", "This does look like an accurate reflection of what the op currently does. But, to be honest, I did not think too carefully about what the return value of the `update_op` from `streaming_concat()` should be when I wrote this op originally.\r\n\r\nAn alternative fix would be to make `update_op` actually return the current value of the concatenated tensor. That would be a little more consistent with how other metrics ops work. I'm not entirely sure that makes sense, though, because it *might* have performance consequences to copy large tensors from `tf.Variable` objects into NumPy arrays. If so, then preserving the current behavior of returning the current size makes more sense. Can someone who understands TensorFlow internals better comment here?\r\n\r\nEither way, we should add a unit test to verify the behavior (currently, the return value of `update_op` is untested).\r\n\r\n@martinwicke any thoughts?", "Doesn't it return the value later?", "@drpngx\r\n\r\n> Doesn't it return the value later?\r\n\r\nYes, `streaming_concat` returns `value` and `update` ops, like the other streaming metrics. But for most streaming metrics, the `update` op also evaluates to the same thing as `value`. If there are no performance implications, we should probably do the same here.", "Sorry for being dense, but let me repeat what I understand: the op _should_ return the length, but instead returns the value. This PR proposes to change the doc to say that it returns the length, but that's inaccurate.", "@drpngx I just made the documentation reflect current behavior. I also +1 for returning concatenated tensors for symmetry with other ops. Moreover, we can get length easily with `tf.shape`.", "> Sorry for being dense, but let me repeat what I understand: the op should return the length, but instead returns the value. This PR proposes to change the doc to say that it returns the length, but that's inaccurate.\r\n\r\nI think the current behavior is actually backwards: the op returns the length, but it is documented to return the value. Clearly this discrepancy is a bug, but we should figure out which behavior we want for the op.", "Oh, is that something that we can do this week? We'll have an API freeze soon and it'll be painful to change.", "It's in contrib, so I don't think timing matters.  Let's do the right thing :)", "Oh, good point!\r\n\r\nAny volunteer for changing the actual returned value?", "So I'm still a little concerned with possible performance implications of\nreturning the value tensor in the update op. Unlike the values returned by\nother streaming metrics, this value could potentially be a very large\ntensor. Is there any chance that copying a local variable like this into\nnumpy could require a memory copy?\nOn Wed, Jan 11, 2017 at 4:07 PM drpngx <notifications@github.com> wrote:\n\n> Oh, good point!\n>\n> Any volunteer for changing the actual returned value?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/6498#issuecomment-272035982>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABKS1hMhwC_M5_HSo8Arn-hjucQ3AiHCks5rRW6tgaJpZM4LVs1E>\n> .\n>\n", "@raviqqe is that something you are able to measure?", "It looks like it could indeed make a significant difference in speed:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = np.random.randn(64, 1000).astype(np.float32)\r\nph = tf.placeholder(tf.float32, (64, 1000))\r\nvalue, update = tf.contrib.metrics.streaming_concat(ph)\r\n```\r\n\r\nThe existing code, which doesn't return the value from tensorflow as part of the update op:\r\n```\r\n%%time\r\nsess = tf.Session()\r\nsess.run(tf.initialize_local_variables())\r\nfor i in range(500):\r\n  sess.run(update, feed_dict={ph: x})\r\nprint sess.run(value).shape\r\n```\r\n```\r\n(32000, 1000)\r\nCPU times: user 2.46 s, sys: 1.04 s, total: 3.5 s\r\nWall time: 691 ms\r\n```\r\nvs the same code, running `value` at each step:\r\n```\r\n%%time\r\nsess = tf.Session()\r\nsess.run(tf.initialize_local_variables())\r\nfor i in range(500):\r\n  sess.run([update, value], feed_dict={ph: x})\r\nprint sess.run(value).shape\r\n```\r\n```\r\n(32000, 1000)\r\nCPU times: user 8.98 s, sys: 8.48 s, total: 17.5 s\r\nWall time: 15.3 s\r\n```\r\n\r\nBased on my experiments, it returning `value` at the same time as `update` changes the run-time from linear to quadratic in terms of the number of update operations. This could be because copying the tensor into NumPy entails a copy and/or because running the ops to slice and transpose the variable does a copy. In either case, it looks like returning the concatenated tensor as part of the update is a non-starter with the current version of TensorFlow.", "@shoyer in the code, you're fetching the whole thing, right? That's not quite fair -- we should compute the length in tensorflow and return only the length back.", "> @shoyer in the code, you're fetching the whole thing, right? That's not quite fair -- we should compute the length in tensorflow and return only the length back.\r\n\r\nThe current implementation indeed only returns the length back, so I think we should keep that and move forward with the doc fix suggested by this PR. Indeed, we don't want to fetch the whole thing every time `update` is run.", "@drpngx @shoyer Sorry for being dumb for a while.\r\nI run [a benchmark test](https://gist.github.com/raviqqe/50c34493c07e2973d88ed9ca05888c42) which incorporates @drpngx's opinion. As a result, it seems to be reasonable to keep current behavior of the update op.\r\n\r\nBut, I have no idea about why it shows such significant speed difference. I thought that `tf.shape()` just reads some metadata in a `tf.Tensor` object and therefore it needs little computation cost.\r\n\r\n```ipython\r\nIn [1]: from strm_concat_op_bench import *\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/l\r\nib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n\r\n... (omitted)\r\n\r\nIn [3]: %time exec_update()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n6400\r\nCPU times: user 325 ms, sys: 97.6 ms, total: 423 ms\r\nWall time: 458 ms\r\n\r\nIn [4]: %time exec_update_and_calc_len()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n[6400, 6336]\r\nCPU times: user 2.77 s, sys: 252 ms, total: 3.02 s\r\nWall time: 3.17 s\r\n```", "@drpngx Sorry. My benchmark code was wrong. [This](https://gist.github.com/raviqqe/b3cd26119a9e108e03bed089903b0e79) is the fixed version and the following is its result.\r\nThere is no difference between returning length by the update op and calculating it from `tf.Tensor` in terms of computational cost. But, we may need to check their memory usage difference.\r\n\r\n```\r\n$ ipython3 -i fixed_strm_concat_op_bench.py\r\nPython 3.4.3 (default, Aug  9 2016, 15:36:17) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 3.2.1 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:/home/toyama.12056/.gvm/pkgsets/go1.7/global/overlay/lib:\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3459] Unable to load cuDNN DSO\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n\r\n... (omitted)\r\n\r\nIn [2]: %time exec_update()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n6400\r\nCPU times: user 397 ms, sys: 42 ms, total: 439 ms\r\nWall time: 396 ms\r\n\r\nIn [3]: %time exec_update_and_calc_len()\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 1, name: GeForce GT 610, pci bus id: 0000:0a:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n[6400, 6336]\r\nCPU times: user 353 ms, sys: 43 ms, total: 396 ms\r\nWall time: 361 ms\r\n```", "OK. If you want to submit a PR then @martinwicke can do the API review."]}, {"number": 6497, "title": "OpenCL isn't working", "body": "TF is configured with OpenCL\r\n```\r\n$ ./configure \r\n/media/Compressed/Drivers_bios/src/dev/tensorflow /media/Compressed/Drivers_bios/src/dev/tensorflow\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.5/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n/usr/local/lib/python3.5/dist-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] y\r\nOpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] N\r\nNo CUDA support will be enabled for TensorFlow\r\nPlease specify which C++ compiler should be used as the host C++ compiler. [Default is ]: /usr/bin/g++\r\nPlease specify which C compiler should be used as the host C compiler. [Default is ]: /usr/bin/gcc\r\nPlease specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]:\r\n```\r\n\r\nComputeCpp is also present\r\n```\r\n$ ls /usr/local/computecpp/*   \r\n/usr/local/computecpp/bin:\r\ncompute++  computecpp_info\r\n\r\n/usr/local/computecpp/doc:\r\nLICENSE.text  computecpp_error_codes.pdf      computecpp_glossary.pdf  computecpp_man.pdf                     computecpp_release_notes.pdf\r\napi_pages     computecpp_getting_started.pdf  computecpp_info_man.pdf  computecpp_platform_support_notes.pdf  computecpp_stream_class.pdf\r\n\r\n/usr/local/computecpp/include:\r\nCL  SYCL\r\n\r\n/usr/local/computecpp/lib:\r\nclang  libComputeCpp.so\r\n```\r\n\r\nI also has OpenCL\r\n```\r\n$ clinfo |grep -i version\r\n  Platform Version:\t\t\t\t OpenCL 2.0 AMD-APP (1912.5)\r\n  Device OpenCL C version:\t\t\t OpenCL C 1.2 \r\n  Driver version:\t\t\t\t 1912.5 (VM)\r\n  Version:\t\t\t\t\t OpenCL 1.2 AMD-APP (1912.5)\r\n  Device OpenCL C version:\t\t\t OpenCL C 1.2 \r\n  Driver version:\t\t\t\t 1912.5 (sse2,avx,fma4)\r\n  Version:\t\t\t\t\t OpenCL 1.2 AMD-APP (1912.5)\r\n```\r\n\r\nBut it seems that TF don't see any OpenCL device in my system.\r\n```python\r\n>>> from tensorflow.python.client import device_lib\r\n>>> [x.name for x in device_lib.list_local_devices()]\r\n['/cpu:0']\r\n```", "comments": ["@inferrna can you run any ComputeCpp example code?", "Just tried and found that it's because of computecpp problem.\r\nhttps://github.com/codeplaysoftware/computecpp-sdk/issues/9", "@inferrna just my 2p: I saw on a different thread that you're using Ubuntu 16.04 with Catalyst drivers. Are you sure? I've recently read that 16.04 dropped support for proprietary AMD drivers... ", "@cipri-tom According to Codeplay and ComputeCpp docs, amdgpu-pro driver does not support currently SPIR which is necessary to execute SYCL code on GPU. On the other hand, fglrx is not supported anymore on newer kernels (including kernels provided in 16.04) but it is possible to patch the driver and still get it running but without X support:\r\nhttps://community.amd.com/thread/202821", "@mcopik you right, I use patched kernel (patches from https://aur.archlinux.org/packages/catalyst-test/\r\n) and no display connected to my 7870."]}, {"number": 6496, "title": "tensorflow + opencv webcam hangs", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nYes posted on stackoverflow but no help and believe this is an issue to report: http://stackoverflow.com/questions/41276085/tensorflow-opencv-webcam-hangs\r\n\r\n### Environment info\r\nOperating System: Environment: MAC machine, running my code inside virtual machine with guest OS: Ubuntu 14.4 LTS.\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI am compiling openCV within tensorflow workspace under examples. My WORKSPACE and opencv.BUILD file look similar to the one mentioned [here](http://stackoverflow.com/questions/34984290/building-opencv-code-using-bazel) \r\n\r\nMy BUILD file for the opencv + tensorflow project looks like following:\r\n\r\n```\r\npackage(default_visibility = [\"//tensorflow:internal\"])\r\n\r\nlicenses([\"notice\"])  # Apache 2.0\r\n\r\nexports_files([\"LICENSE\"])\r\n\r\ncc_binary(\r\n    name = \"label_image\",\r\n    srcs = [\r\n        \"main.cc\",\r\n    ],\r\n    linkopts = [\"-lm\"],\r\n    copts = [\"-DWITH_FFMPEG=OFF\"],\r\n    deps = [\r\n        \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/core:framework_internal\",\r\n        \"//tensorflow/core:tensorflow\",\r\n        \"@opencv//:opencv\"\r\n    ],\r\n)\r\n\r\nfilegroup(\r\n    name = \"all_files\",\r\n    srcs = glob(\r\n        [\"**/*\"],\r\n        exclude = [\r\n            \"**/METADATA\",\r\n            \"**/OWNERS\",\r\n            \"bin/**\",\r\n            \"gen/**\",\r\n        ],\r\n    ),\r\n    visibility = [\"//tensorflow:__subpackages__\"],\r\n)\r\n```\r\n\r\nIf i disable tensorflow dependences (and also comment the tensorflow related code). I can see that the webcam is captures properly. like this:\r\n\r\n```\r\ndeps = [\r\n            #\"//tensorflow/cc:cc_ops\",\r\n            #\"//tensorflow/core:framework_internal\",\r\n            #\"//tensorflow/core:tensorflow\",\r\n            \"@opencv//:opencv\"\r\n        ],\r\n```\r\n\r\nBut if i still keep the code commented/uncommented and also keep the tensorflow dependences my webcam hangs at VideoCapture::read()\r\n\r\nBy default, opencv use FFMPEG codec and i tried enabling and disabling FFMPEG. Can someone please help me why when tensorflow library is compiled in the project makes my openCV read() hangs?\r\n\r\n### What other attempted solutions have you tried?\r\nLater, i tried having OpenCV code in c++ and tensorflow in python and integrate them using [embedded python](https://docs.python.org/3.4/extending/embedding.html). This is working fine. \r\n\r\n\r\n### Logs or other output that would be helpful\r\nAttached inline. ", "comments": ["One possibility is that the FFMPEG linked into tensorflow is conflicting with the FFMPEG in OpenCV. If they are different versions, then this is quite likely. You could try to remove the ffmpeg support from the tensorflow build and see if that solves your problem. \r\n\r\n> ", "Thanks for your reply! \r\nAny quick way to disable FFMPEG from tensorflow? ", "Not off hand you could try commenting out contrib/ffmpeg/BUILD. But that might causes problems with things that depend on that module, but if you try that you should be able to follow your nose.", "Closing due to lack of recent activity. We will reopen when additional information becomes available. Thanks!", "Hi, I meet the same problem. Is there any solution?\r\nI am using tensorflow r1.4 and opencv3.1 in ubuntu14.04.\r\nAs far as I include #include <tensorflow/core/public/session.h> or #include \"tensorflow/cc/ops/standard_ops.h\" I cannot read image. When I didn include these tensorflow files, I can read frame successfully. Anyone could help me? Thanks a lot!!!\r\nmy cpp file:\r\n#include <tensorflow/core/platform/env.h>\r\n//#include <tensorflow/core/public/session.h>\r\n//#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include <opencv2/opencv.hpp>\r\n#include\r\nusing namespace std;\r\nusing namespace tensorflow;\r\n\r\nint main()\r\n{\r\ncv::VideoCapture cap;\r\nif(!cap.open(\"/home/kx/project/RM-dataset/01.avi\")){\r\nstd::cout<<\"cannot open video \"<<std::endl;\r\n}\r\ncv::Mat frame;\r\nwhile(1){\r\ncap>>frame;\r\nif(frame.empty()){\r\nstd::cout<<\"no frame\"<<std::endl;\r\ncontinue;\r\n}\r\ncv::imshow(\"frame\",frame);\r\ncv::waitKey(0);\r\n}\r\nreturn 0;\r\n}\r\n\r\nmy cmake file:\r\n\r\ncmake_minimum_required (VERSION 2.8)\r\nproject (tf_example)\r\n\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g -std=c++11 -W\")\r\nfind_package(OpenCV 3.1.0 REQUIRED)\r\ninclude_directories(\r\n/home/kx/something/tensorflow-r1.4\r\n/home/kx/something/tensorflow-r1.4/tensorflow/bazel-genfiles\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/protobuf/include\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/host_obj\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/proto\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/downloads/nsync/public\r\n/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/downloads/eigen\r\n/home/kx/something/tensorflow-r1.4/bazel-out/local-py3-opt/genfiles\r\n${OPENCV_INCLUDE_DIRS}\r\n)\r\n\r\nadd_executable(tf_test tf_test.cpp)\r\ntarget_link_libraries(tf_test\r\n/home/kx/something/tensorflow-r1.4/bazel-bin/tensorflow/libtensorflow_cc.so\r\n/home/kx/something/tensorflow-r1.4/bazel-bin/tensorflow/libtensorflow_framework.so\r\n${OpenCV_LIBS}\r\n)"]}, {"number": 6495, "title": "Docker doesn't support GPU for mac OS (doc clarification request)", "body": "The docs present instructions for installing via Docker on MacOS. GPU support isn't mentioned explicitly, but it seems that GPU (nvidia-docker) can't be supported for MacOS. See here:\r\nhttps://github.com/NVIDIA/nvidia-docker/issues/175\r\n\r\nIf I'm right that GPU is a no-go for Docker on Mac OS, I'd like to see this up-front in the documentation (e.g., write \"GPU support not possible on MacOS X in Docker\") to prevent people from going down the wrong path.\r\n\r\n\r\n\r\n\r\nNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["That link suggests GPU support is not\u00a0possible in Docker for Mac, would you be willing to send a PR to fix this documentation issue?", "The current doc of `Installing TensorFlow on Mac OS X`, see:\r\nhttps://www.tensorflow.org/install/install_mac\r\ndoes mention that:\r\n```\r\nImportant: Docker currently does not support TensorFlow with GPU support on Mac OS; that is, on Mac OS, Docker only supports TensorFlow with CPU support.\r\n```\r\n\r\nI think this issue has already been addressed?", "This is a NOTE prominently on the page.  I think we've satisfied this bug.  Thanks!", "Is the reason for why this cannot be supported known? Now that eGPU works on macOS, this seems like a very good fit for Deep Learning."]}, {"number": 6494, "title": "Correct the order of arguments of `softmax_loss_function`", "body": "Correct the order of arguments of `softmax_loss_function` in `seq2seq.sequence_loss_by_example()`,\r\n\r\n`softmax_loss_function(target, logit)` => `softmax_loss_function(logit, target)`", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it.", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 6493, "title": "The \"training/saver\" is raising an exception  when saving data to the regional Google Cloud bucket", "body": "The current version of the TensorFlow that is used with Google Cloud ML (my guessing is TF 0.12) is not working when I'm using the regional bucket as a training source. Detailed step by step reproducing tutorial can be found here: https://blog.kovalevskyi.com/how-to-train-a-chatbot-with-the-tensorflow-and-google-cloud-ml-3a5617289032#.dq3xzjm3h  in order to reproduce the issue you just need to create a regional bucket, instead of the multi-regional. Also, everything works well with the multi-regional bucket.\r\n\r\nLogs from the Google Cloud ML:\r\n\r\nCreating 3 layers of 1024 units.\r\nCreated model with fresh parameters.\r\nReading development and training data (limit: 0).\r\n  reading data line 100000\r\nUnavailable: Unexpected response code 410\r\n         when resuming upload gs://chatbot_generic/chatbot_generic_20161224_211637/translate.ckpt-1.data-00000-of-00001\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 326, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 323, in main\r\n    train()\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 229, in train\r\n    model.saver.save(sess, checkpoint_path, global_step=model.global_step)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1323, in save\r\n    {self.saver_def.filename_tensor_name: checkpoint_file})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\nUnavailableError: Unexpected response code 410\r\n         when resuming upload gs://chatbot_generic/chatbot_generic_20161224_211637/translate.ckpt-1.data-00000-of-00001\r\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/embedding, proj_b, proj_w)]]\r\n-24 21:28:34 -0800       master-replica-0                Caused by op u'save/SaveV2', defined at:\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 326, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 323, in main\r\n    train()\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 179, in train\r\n    model = create_model(sess, False)\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/translate.py\", line 136, in create_model\r\n    dtype=dtype)\r\n  File \"/root/.local/lib/python2.7/site-packages/translate/seq2seq_model.py\", line 189, in __init__\r\n    self.saver = tf.train.Saver(tf.global_variables())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1030, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 622, in build\r\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 229, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 172, in save_op\r\n    tensors)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 550, in save_v2\r\n    tensors=tensors, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2238, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1130, in __init__\r\n    self._traceback = _extract_stack()\r\n-24 21:28:34 -0800       master-replica-0                UnavailableError (see above for traceback): Unexpected response code 410\r\n         when resuming upload gs://chatbot_generic/chatbot_generic_20161224_211637/translate.ckpt-1.data-00000-of-00001\r\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/embedding, proj_b, proj_w)]]\r\n-24 21:28:37 -0800       master-replica-0                global step 1 learning rate 0.5000 step-time 22.35 perplexity 39893.68\r\nModule raised an exception Command '['python', '-m', u'translate.translate', u'--from_train_data=gs://chatbot_genBias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/embedding, proj_b, proj_w)]]\r\n-24 21:28:37 -0800       master-replica-0                global step 1 learning rate 0.5000 step-time 22.35 perplexity 39893.68\r\nModule raised an exception Command '['python', '-m', u'translate.translate', u'--from_train_data=gs://chatbot_generic/input/train.a', u'--to_train_data=gs://chatbot_generic/input/train.b', u'--from_dev_data=gs://chatbot_generic/input/test.a', u'--to_dev_data=gs://chatbot_generic/input/test.b', u'--train_dir=gs://chatbot_generic/chatbot_generic_20161224_211637', u'--steps_per_checkpoint=1', u'--from_vocab_size=45000', u'--to_vocab_size=45000']' returned non-zero exit status 1.", "comments": ["Thank you for your patience.\r\n\r\n[410 Gone on GCS](https://cloud.google.com/storage/docs/json_api/v1/status-codes#410_Gone) is related to poisoned or expired upload sessions ([see also](https://github.com/stephenplusplus/gcs-resumable-upload/issues/15#issuecomment-249324122)).\r\n\r\nSince your backtrace into [translate.translate](https://github.com/tensorflow/models/blob/86ecc9730d751c1f72e3bfecac958166390f4125/tutorials/rnn/translate/translate.py) is on a line that exceeds the number of lines in the file, I'm assuming you made modifications to this file. If that's the case, then I'm not sure that this issue demonstrates a bug in TensorFlow.\r\n\r\nPlease consider reaching out to [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) for support.\r\n\r\nIf you still believe there's a bug in the TensorFlow code, please provide more information and I'll re-open."]}, {"number": 6492, "title": "Error performing lstm using BasicLSTMCell in v0.12.0", "body": "Hey Guys, I have v0.12.0 installed on my system and I'm facing some issue while running a simple LSTM. While trying to get it to work I have even reduced my code to the examples at https://www.tensorflow.org/tutorials/recurrent/, but still facing the same issue. I'm attaching snippets from my code and the error log. The \"lstm\" function takes input from a convolving function that produces latent representations (size: 1024) of a sequence of 40 frames.\r\n\r\n```python\r\nframes_batch_size = 40\r\nbatch_size = 20\r\n\r\ndef lstm(x, state_size=1024, initial_state=None, reuse=False):\r\n    with tf.variable_scope(\"lstm\") as lstm_scope:\r\n        if reuse:\r\n            tf.get_variable_scope().reuse_variables()\r\n        \r\n        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size)\r\n        state = initial_state if initial_state else tf.zeros([batch_size, state_size], name=\"lstm_state\")\r\n        \r\n        print(x.name, \"-\", x.get_shape())\r\n        print(state.name, \"-\", state.get_shape())\r\n\r\n        for i in range(frames_batch_size):\r\n            output, state = lstm_cell(x[:, i], state)\r\n            \r\n        print(output.name, output.get_shape())\r\n    return output\r\n```\r\n\r\nThe shapes of tensors as per output are:\r\n```\r\ngenerator/convolution/conv_output:0 - (20, 40, 1024)\r\ngenerator/lstm/lstm_state:0 - (20, 1024)\r\n```\r\n\r\nAnd the snippet of the error log is:\r\n```\r\n<ipython-input-13-35b652ff4acc> in lstm(x, state_size, initial_state, reuse)\r\n     10 \r\n     11         for i in range(frames_batch_size):\r\n---> 12             output, state = lstm_cell(x[:, i], state)\r\n     13 \r\n     14         print(output.name, output.get_shape())\r\n\r\n/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell.py in __call__(self, inputs, state, scope)\r\n    306       # Parameters of gates are concatenated into one multiply for efficiency.\r\n    307       if self._state_is_tuple:\r\n--> 308         c, h = state\r\n    309       else:\r\n    310         c, h = array_ops.split(1, 2, state)\r\n\r\n/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in __iter__(self)\r\n    508       TypeError: when invoked.\r\n    509     \"\"\"\r\n--> 510     raise TypeError(\"'Tensor' object is not iterable.\")\r\n    511 \r\n    512   def __bool__(self):\r\n\r\nTypeError: 'Tensor' object is not iterable.\r\n```", "comments": ["This kind of usage question is better asked on [Stackoverflow](http://stackoverflow.com/questions/tagged/tensorflow).", "My suggestion is don't roll your own. Use tf.nn.dynamic_rnn."]}, {"number": 6491, "title": "patches for 0.12.1 release.", "body": "", "comments": []}, {"number": 6490, "title": "Weird concat_v2 behavior with negative axis", "body": "This:\r\n```python\r\nrudolph = tf.zeros((5, 2))\r\nprancer = tf.zeros((5, 2))\r\ncomet = tf.concat_v2([rudolph, prancer], axis=-1)\r\n\r\nprint('Tensor shape: {}'.format(comet.get_shape()))\r\nprint('Evaluated shape: {}'.format(comet.eval().shape))\r\n```\r\n\r\nProduces:\r\n\r\n```\r\nTensor shape: (5, 4, 5, 2)\r\nEvaluated shape: (5, 4)\r\n```\r\n\r\nTested on tensorflow version `0.12.0`", "comments": ["Nice festive example! Probably concat_v2 should follow the convention in numpy wherein the negative axis wraps around the dimensions", "This should be fixed in nightly build by this commit: https://github.com/tensorflow/tensorflow/commit/8940018192090c072ad50b81b36969d71ffb2c21\r\n\r\nYou can either use the nightly build or wait for next release."]}, {"number": 6489, "title": "Error when trying to run lstm example of ptb", "body": "I was stuck at here when trying to run ptb_word_lm under ubuntu 16 and tensorflow master branch. Any advice would be very much appreciated.  \r\n\r\nThe exception said:\r\nEpoch: 1 Learning rate: 1.000\r\nTraceback (most recent call last):\r\n  File \"/home/****/.local/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py\", line 964, in managed_session\r\n    yield sess\r\n  File \"ptb_word_lm.py\", line 357, in main\r\n    verbose=True)\r\n  File \"ptb_word_lm.py\", line 298, in run_epoch\r\n    return np.exp(costs / iters)\r\nZeroDivisionError: float division by zero\r\n", "comments": ["ok\uff0ci figured out that it seems the data was not imported correctly due to the misuse of zip function in _build_vocab of reader.py under python 3.5. But after i fixed the problem, the program throwed another exception said: logits and labels must have the same first dimension, got logits shape [400,10000] and labels shape [420]....", "finally, the problem has been fixed. the point is i changed strided_slice into sclice in ready.py.add an stride just fix the problem. "]}, {"number": 6488, "title": "Matching the tutorial code with mnist_softmax.py", "body": "The `MNIST For ML Beginners` tutorial is an explanation, line by line, of what is happening in the [mnist_softmax.py](https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_softmax.py) code, but some lines didn't match.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "PR merged. Thank you, @Franck-Dernoncourt "]}, {"number": 6487, "title": "Errors when trying to build label_image neural net with bazel", "body": "### Environment info\r\nOperating System: El Capitan, 10.11.1\r\n\r\nI'm doing this tutorial: https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/ \r\nTrying to classify images using tensorflow on iOS app.\r\nWhen I try to build my net using bazel:\r\n`bazel build tensorflow/examples/label_image:label_image\r\n`\r\n\r\nI get these errors:\r\nhttps://gist.github.com/galharth/36b8f6eeb12f847ab120b2642083a732", "comments": ["Any help \ud83d\ude4f ?", "I'm surprised to see that you appear to be using gcc (from the error messages), whereas clang is the usual default on OS X. Can you run `gcc --version` and paste the result in here?", "@petewarden \r\nWhen I run it on the docker machine (tensorflow/tensorflow:nightly-devel) this is what I get:\r\n```\r\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n```\r\n\r\nOn my machine I get:\r\n```\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\nApple LLVM version 7.3.0 (clang-703.0.31)\r\nTarget: x86_64-apple-darwin15.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```", "Ah, I missed that the step was within the docker container, gcc makes sense there. Have you made sure that the virtual machine has enough memory assigned to it?", "How much memory the virtual machine needs? this is my current docker preferences: http://d.pr/i/YCUl\r\n(2 cpus, 2 GB RAm)\r\n", "2GB is tight for Bazel unfortunately. As a start, I would try ramping that up, and there are also some options to make Bazel only build one source file at a time, which helps, but I don't have those handy.", "Closing due to lack of activity but please reopen if this isn't a memory issue."]}, {"number": 6486, "title": "Windows: cannot compile using cmake 3.7.1 generator", "body": "Hello\r\n\r\nIf I use cmake 3.7.1 generator, I cannot compile tensorflow on Windows with Visual Studio\r\nI get the following error message during tf_core_gpu_kernels project:\r\n\r\n`nvcc fatal   : Stray '\"' character\r\n30>\r\n30>  CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:222 (message):\r\n30>    Error generating\r\n30>    C:/libs/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj`\r\n\r\nIf I try to regenerate project using cmake 3.6.3, everything compiles just fine\r\n\r\nI was trying to modify CMakeLists.txt, but still no luck\r\n\r\nAdditional info:\r\nWindows 10\r\nVisual Studio 2015\r\nGPU is enabled, CUDA 8.0\r\n", "comments": ["To successfully build TensorFlow from source using CMake as the [pre-requisites specify](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md#pre-requisites) you need versions 3.5 up to 3.6. \r\n", "Correct. the failures with 3.7.1 are known, and unfortunately we have no workaround apart from downgrading cmake."]}, {"number": 6485, "title": "Remove Double from supported types for Conv2D since no double impleme\u2026", "body": "\u2026ntation is registered for any device. Came up in http://stackoverflow.com/questions/41310637/no-opkernel-was-registered-to-support-op-conv2d-with-these-attrs", "comments": ["Can one of the admins verify this patch?", "The OP spec defines theoretically supported types, not necessarily registered types. \r\n\r\nPerhaps our documentation could avoid specifying types that were not implemented, but that will take some work :(. Sorry about the  confusion this causes. ", "What is the meaning of theoretically supported? IE, would it make sense to add `int32` to the list of theoretically supported types for `Conv2D` because there may eventually be an integer implementation?", "If the operation makes sense for a data type, it should be registered in the OP spec. So it would make sense for there to be an int32 kernel. However, for backwards compatibility we can only add data types, not remove them"]}, {"number": 6484, "title": "Some of tensorflow GPU OpKernel compute by eigen device without stream sync, is that correct?", "body": "from gpu_device.cc\r\n\r\n```\r\n   // NOTE(tucker): We need to discriminate between Eigen GPU\r\n   // operations and all others.  If an operation is Eigen\r\n   // implemented (or otherwise tries to launch a cuda kernel\r\n   // directly), we need to establish a stacked-scoped environment\r\n   // that directs it to execute on the proper device.  Otherwise we\r\n   // expect the Op to use StreamExecutor directly and correctly.  The\r\n   // way we make this discrimination is quite hacky: At the moment\r\n   // the only non-Eigen GPU Op is the recv-op, which is known to be\r\n   // asynchronous.\r\n```\r\n\r\nand gpu_device only waits when there are different contexts. (sync_every_op is false)\r\n\r\nBut take argmax_op.h  for example,\r\n\r\n\r\n    template <typename Device, typename T>\r\n    struct ArgMin {\r\n    #define DECLARE_COMPUTE_SPEC(Dims)                                     \\\r\n    EIGEN_ALWAYS_INLINE static void Reduce##Dims(                        \\\r\n    const Device& d, typename TTypes<T, Dims>::ConstTensor input,    \\\r\n    const int32 dimension,                                           \\\r\n    typename TTypes<int64, Dims - 1>::Tensor output) {               \\\r\n    output.device(d) = input.argmin(dimension).template cast<int64>(); \\\r\n    }\r\n\r\nuse device compute directly. Is that correct? Or I miss something ... \r\nThank you very much!\r\n", "comments": ["sorry, I miss something in code. cuda stream is passed to eigen device", "how does cuda stream pass to eigen device?"]}, {"number": 6483, "title": "Please update seq2seq tutorial on the Tensorflow website", "body": "It seems like the seq2seq.py library has been deprecated, and it would be nice to know where the new code, and if the tutorial could point to it. ", "comments": ["Along with below files related with rnn is all gone...\r\n'tensorflow/tensorflow/models'\r\n'tensorflow/tensorflow/python/ops/seq2seq.py'\r\n'tensorflow/tensorflow/python/ops/rnn_cell.py'\r\nWhy we delete it?", "@xmbrst should the documentation show where these have moved to?", "Is there a reason for moving all of the seq2seq code to legacy?", "It seems like they are moved to contrib due to the reason mentioned in this [#4437](https://github.com/tensorflow/tensorflow/issues/4437)", "So, we will have new seq2seq code in tf.nn? ", "Is there any update on this issue? ", "I'd like to know whether there's any update on this issue as well.", "I also believe a official demo for the new seq2seq api is very valuable even though there are already some 3rd party tutorials.", "@a7744hsc Can you link some of the 3rd party tutorials?", "@nave01314 may be [this](https://github.com/ematvey/tensorflow-seq2seq-tutorials) will be helpful.", "BTW, the new seq2seq tutorial is living on a separate part of the Tensorflow github repo now:\r\nhttps://github.com/tensorflow/nmt\r\n\r\nWe've also put the seq2seq.py back up in a legacy section.\r\n\r\nSo, I think I'm closing out this bug."]}, {"number": 6482, "title": "Branch 142863423", "body": "", "comments": []}]