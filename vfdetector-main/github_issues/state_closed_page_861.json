[{"number": 27678, "title": "Moved pooling reference ops into its own file", "body": "Moving the reference pooling ops into its own file to remove dependencies.", "comments": ["> Thanks for the change! Could you kindly share the motivation behind this change?\r\n\r\nI'm working on porting the MaxPooling part of the Pooling kernel to Tensorflow Lite Micro, and then the dependency on gemmlowp needs to be removed in order to build for the bluepill target in Tensorflow Lite Micro.", "> > Thanks for the change! Could you kindly share the motivation behind this change?\r\n> \r\n> I'm working on porting the MaxPooling part of the Pooling kernel to Tensorflow Lite Micro, and then the dependency on gemmlowp needs to be removed in order to build for the bluepill target in Tensorflow Lite Micro.\r\n\r\nCool! Could update the description to reflect this? Like \"Moved pooling reference ops into its own file to remove the gemmlowp dependency and enable bluepill target build in TFL Micro\"?", "Btw, I think such a change should be added to tensorflow/lite/experimental/micro. Added  @petewarden for further comment."]}, {"number": 27677, "title": " fix typo in comment", "body": "", "comments": []}, {"number": 27676, "title": "A function which creates sprite images. This can be used in the projector plugin in Tensorboard.", "body": "", "comments": ["@seanpmorgan I think this belongs in addons; WDYT?\r\n\r\n@bono1567 can you add tests for the new function, and change the PR to point to tensorflow/addons?", "@alextp It could conceivably go in tfa.image but a case would need to be made for how useful this is."]}, {"number": 27675, "title": "fix typo in example.", "body": "fix typo in example.\r\n[0. 1] should be [0, 1]", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27675) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 27674, "title": "unrecognized arguments: --output_node_names", "body": "i am following steps mentioned in [this](https://medium.com/testdotai/training-data-for-app-classifier-f217dc005523) article.\r\nat \"tensorflowjs_converter --input_format=tf_frozen_model --output_node_names=final_result  output/saved_model.pb web_model\" this step i am getting below issue;\r\n\r\nusage: TensorFlow.js model converters. [-h]\r\n                                       [--input_format {tf_hub,keras,tf_session_bundle,keras_saved_model,tensorflowjs,tfjs_layers_model,tf_saved_model,tf_frozen_model}]\r\n                                       [--output_format {tfjs_layers_model,tensorflowjs,keras,tfjs_graph_model}]\r\n                                       [--signature_name SIGNATURE_NAME]\r\n                                       [--saved_model_tags SAVED_MODEL_TAGS]\r\n                                       [--quantization_bytes {1,2}]\r\n                                       [--split_weights_by_layer] [--version]\r\n                                       [--skip_op_check SKIP_OP_CHECK]\r\n                                       [--strip_debug_ops STRIP_DEBUG_OPS]\r\n                                       [input_path] [output_path]\r\nTensorFlow.js model converters.: error: unrecognized arguments: --output_node_names=final_result\r\n\r\n\r\n\r\n- **OS Platform and Distribution : MacOS 10.14 (MacBook Pro)\r\n- **TensorFlow installed from pip\r\n- **TensorFlow version : 1.13.1\r\n- **Python version : 3.6.5\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "Did you ever figure this out?", "degrading python version and tensorflow version worked for me."]}, {"number": 27673, "title": "Build from sources fails with undefined symbol _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Gentoo, Kernel 4.19.32-v7+\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nRaspberry Pi\r\n- TensorFlow installed from (source or binary):\r\ngit checkout tags/v1.12.0\r\n- TensorFlow version:\r\nv1.12.0\r\n- Python version:\r\n3.6.5\r\n- Installed using virtualenv? pip? conda?:\r\nn/a\r\n- Bazel version (if compiling from source):\r\n0.20.0\r\n- GCC/Compiler version (if compiling from source):\r\n8.2.0\r\n- CUDA/cuDNN version:\r\nn/a\r\n- GPU model and memory:\r\nn/a\r\n\r\n\r\n**Describe the problem**\r\nBuild fails with the error message \"ImportError: .../_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\"\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n- H/W Raspberry Pi with USB-SSD, 4GB swap partition\r\n- install bazel by Gentoo ebuild\r\n- clone git repo, checkout v1.12.0\r\n- configure:\r\nI did just correct the Python paths and the optimization flags. I answered all other questions from the configure script with 'n'. Nevertheless I see this content in .tf_configure.bazelrc - I don't want to use AWS or ignite or something of the like... maybe the configure script does not work like expected.\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/usr/bin/python\"\r\nbuild:ignite --define with_ignite_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_ROCM=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"0\"\r\nbuild --action_env TF_DOWNLOAD_CLANG=\"0\"\r\nbuild:opt --copt=-march=armv7-a\r\nbuild:opt --copt=-mfpu=neon-vfpv4\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\n```\r\n- patch platform.h\r\nvim tensorflow/core/platform/platform.h\r\n```\r\n// Require an outside macro to tell us if we're building for Raspberry Pi or\r\n// another ARM device that's not a mobile platform.\r\n//#if !defined(RASPBERRY_PI) && !defined(ARM_NON_MOBILE)\r\n//#define IS_MOBILE_PLATFORM\r\n//#endif  // !defined(RASPBERRY_PI) && !defined(ARM_NON_MOBILE)\r\n#if defined(IS_MOBILE_PLATFORM)\r\n#error Wrong platform, stop building...\r\n#endif\r\n```\r\n- build by:\r\n```\r\nbazel --host_jvm_args=\"-Xms512m\" --host_jvm_args=\"-Xmx1024m\" \\\r\n   build -c opt --copt=\"-mfpu=neon-vfpv4\" \\\r\n   --copt=\"-funsafe-math-optimizations\" \\\r\n   --copt=\"-ftree-vectorize\" \\\r\n   --copt=\"-fomit-frame-pointer\" \\\r\n   --verbose_failures tensorflow/tools/pip_package:build_pip_package \\\r\n   --define=grpc_no_ares=true \\\r\n   --incompatible_remove_native_http_archive=false\r\n```\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:\r\ntensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc: In member function 'virtual bool toco::ReorderElementwiseUnary::Run(toco::Model*, std::size_t)':\r\ntensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:125:23: warning: comparison of integer expressions of different signedness: 'int' and 'std::vector<std::unique_ptr<toco::Operator> >::size_type' {aka 'unsigned int'} [-Wsign-compare]\r\n     for (int i = 0; i < model->operators.size(); i++) {\r\n                     ~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:127:25: warning: comparison of integer expressions of different signedness: 'int' and 'std::vector<std::__cxx11::basic_string<char> >::size_type' {aka 'unsigned int'} [-Wsign-compare]\r\n       for (int j = 0; j < consumer->inputs.size(); j++) {\r\n                       ~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\nSlow read: a 114883940-byte read from /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so took 22043 ms.\r\nERROR: /usr/src/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1) bash failed: error executing command\r\n  (cd /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/vc/bin:/usr/lib/llvm/7/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3.6/site-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/arm-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/arm-opt/genfiles/tensorflow/_api/v1/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox: bash failed: error executing command\r\n  (cd /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/vc/bin:/usr/lib/llvm/7/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3.6/site-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/arm-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/arm-opt/genfiles/tensorflow/_api/v1/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/arm-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nSlow read: a 117326424-byte read from /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/arm-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so took 23412 ms.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 94586.192s, Critical Path: 40695.34s\r\nINFO: 3233 processes: 3233 linux-sandbox.\r\nFAILED: Build did NOT complete successfully\r\nanduin /usr/src/tensorflow #\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/sandbox/linux-sandbox/3234/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nSlow read: a 117326424-byte read from /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/arm-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so took 23412 ms.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 94586.192s, Critical Path: 40695.34s\r\nINFO: 3233 processes: 3233 linux-sandbox.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["I took a second attempt - alas with the same outcome. OK, here's what I did:\r\n- pull the git repo, checkout 1.12.0 again and create a new local branch\r\n```\r\ngit pull\r\ngit checkout master\r\ngit submodule update --recursive --remote\r\ngit checkout tags/v1.12.0 -b v1.12c\r\n```\r\n- prepare bazel\r\n```\r\ngrep -Rl 'lib64' | xargs sed -i 's/lib64/lib/g'\r\nbazel clean\r\n```\r\n- configure: leave everything at its default except for the python paths.\r\n- edit .bazelrc to get around https://github.com/tensorflow/tensorflow/pull/25114 given that I have bazel v0.20.0\r\n```\r\nimport /usr/src/tensorflow/tensorflow/tools/bazel.rc\r\nimport /usr/src/tensorflow/.tf_configure.bazelrc\r\n```\r\n- starting the bazel build by this lengthy command:\r\n```\r\nbazel                                                           \\\r\n   --host_jvm_args=\"-Xms512m\" --host_jvm_args=\"-Xmx1024m\"       \\\r\n   build -c opt                                                 \\\r\n   --local_resources 800,4,0.5                                  \\\r\n   --copt=-march=armv7-a                                        \\\r\n   --copt=-mfpu=neon-vfpv4                                      \\\r\n   --copt=-ftree-vectorize                                      \\\r\n   --copt=-funsafe-math-optimizations                           \\\r\n   --copt=-ftree-loop-vectorize                                 \\\r\n   --copt=-fomit-frame-pointer                                  \\\r\n   --copt=-DRASPBERRY_PI                                        \\\r\n   --host_copt=-DRASPBERRY_PI                                   \\\r\n   --host_copt=-march=armv7-a                                   \\\r\n   --host_copt=-mfpu=neon-vfpv4                                 \\\r\n   tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nAfter less than three days, i.e. in the morning of the third day, I saw it failing with the same error than before...\r\n```\r\nanduin /usr/src/tensorflow # bazel --host_jvm_args=\"-Xms512m\" --host_jvm_args=\"-Xmx1024m\" build -c opt --local_resources 800,4,0.5 --copt=-march=armv7-a --copt=-mfpu=neon-vfpv4 --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer --copt=-DRASPBERRY_PI --host_copt=-DRASPBERRY_PI --host_copt=-march=armv7-a --host_copt=-mfpu=neon-vfpv4 --verbose_failures tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\n... still trying to connect to local Bazel server after 10 seconds ...\r\nINFO: Invocation ID: d1f9fe9d-be24-455d-9c1c-ef79dac19573\r\nWARNING: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:354:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:73:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:230:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /usr/src/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (323 packages loaded, 16255 targets configured).\r\nINFO: Found 1 target...\r\nSlow read: a 108006376-byte read from /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so took 18798 ms.\r\nERROR: /usr/src/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1): bash failed: error executing command\r\n  (cd /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/vc/bin:/usr/lib/llvm/7/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/bin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/host/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/host/genfiles/tensorflow/_api/v1/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/host/genfiles/tensorflow/_api/v1/user_ops/__init__.py')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 577.261s, Critical Path: 63.73s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nI will now clean .tf_configure.bazelrc (read: removing the build:ignite and build:xla lines) and see, whether this would make a difference (having not much hope...).", "Meet same error at \r\nSystem information\r\n\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n    Linux Ubuntu 18.04 , Kernel 4.19.32-v7+\r\n    TensorFlow installed from (source or binary):\r\n    git checkout tags/v1.12.0\r\n    TensorFlow version:\r\n    v1.12.0\r\n    Python version:\r\n    2.7\r\n    Installed using virtualenv? pip? conda?:\r\n    n/a\r\n    Bazel version (if compiling from source):\r\n    0.15.2\r\n    GCC/Compiler version (if compiling from source):\r\n    7.4.0\r\n    CUDA/cuDNN version:\r\n    n/a\r\n    GPU model and memory:\r\n    n/a\r\n\r\nDescribe the problem\r\nBuild fails with the error message \"ImportError: .../_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws10FileSystem16GetHomeDirectoryB5cxx11Ev\"\r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem\r\n\r\n \r\n    clone git repo, checkout v1.12.0\r\n    configure:\r\n    I did just correct the Python paths and the optimization flags. I answered all other questions from the configure script with 'n'. Nevertheless I see this content in .tf_configure.bazelrc - I don't want to use AWS or ignite or something of the like... maybe the configure script does not work like expected.\r\n", "I'd recommend running the tensorflow/tools/ci_build/pi/build_raspberry_pi.sh script, rather than using the individual Bazel commands, since that's tested by our CI system. Are you still seeing issues?", "@petewarden: Thank You for Your comment. Inside this script I see a lot of useful stuff, which potentially helps me to compile natively on a Raspi. \r\nI am however not too happy with the official cross-compile method for the Raspi, as Debian for arm uses a CHOST setting for arm cores without the hardfloat option. Furthermore I am reluctant to compile tensorflow with such an old gcc, as there was a substantial ABI change in gcc 5.0 (at least for C++11 sources). So I would be much happier, if the official TF toolchain would use gcc 8.x or gcc 9.x.\r\nNevertheless I did succeed in compiling TF natively while using Gentoo (also succeeded in drafting an ebuild...) using this command:\r\n``bazel  \r\n--host_jvm_args=\"-Xms512m\"  \r\n--host_jvm_args=\"-Xmx1024m\"   \r\nbuild -c opt  \r\n--local_resources 800,3,0.5   \r\n--copt=-march=armv7-a  \r\n--copt=-mfpu=neon-vfpv4  \r\n--copt=-ftree-vectorize \r\n--copt=-funsafe-math-optimizations \r\n--copt=-ftree-loop-vectorize   \r\n--copt=-fomit-frame-pointer   \r\n--copt=-DRASPBERRY_PI   \r\n--host_copt=-DRASPBERRY_PI  \r\n--host_copt=-march=armv7-a  \r\n--host_copt=-mfpu=neon-vfpv4  \r\n--config=noaws    \r\n--config=nohdfs   \r\n--config=noignite  \r\n--config=nokafka  \r\n//tensorflow/tools/pip_package:build_pip_package``\r\nThere were two flaws, I had to get aware of: \r\n- first: to disable XLA during configure, as it is not working on 32bit systems, as there is some mess with 32 and 64 bit pointers. \r\n- second: at the end of the configure there is a message, telling about default features, which might be disabled. One of these is aws - and if I look on the name of that undefined symbol, then it really looks like it was related to aws. So I did disable all this optional stuff. And it looks like, this did the trick. It took my quite a bit of time to find out... \r\n\r\nWell, I was able to compile it. But after a series of upgrades, some other issue seems to have crept in. Tensorflow is not easy to compile on the Raspi. Even though the new Raspi 4 can be had with 4GB RAM and whopping fast cores, which make things much easier. ", "@PeterS2a,\r\n\r\nThank you for the detailed summary of how you solved and it may help others. Since the issue is already resolved, can you confirm if we are good to close this issue?", "I can confirm, that this issue is solved for my since early 2020... And so I would encourage You to close it (and go on solving open issues, as the Raspi-cross-compilation remains a cumbersome adventure. Currently I have quite some compatibility issues with different versions of the Google protobuf...).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27673\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27673\">No</a>\n"]}, {"number": 27672, "title": "tensorflow2.0.0-alpha no eagarTensor when using dataset.map", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  binary\r\n- TensorFlow version (use command below): 2.0.0-alpha\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):  \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:  v9.0.176\r\n- GPU model and memory:  NVIDIA GeForce GTX   42GB \r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nwhen using dataset.map to parse tfrecord, the tensor is not eagerTensor\r\n\r\n**Describe the expected behavior**\r\nhope all the tensor could be eagerTensor in tf2.0\r\n\r\n**Code to reproduce the issue**\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\ndef parse_tf_record(tf_record):\r\n    features = {'image': tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\r\n                'height': tf.io.FixedLenFeature([], tf.int64, default_value=0),\r\n                'width': tf.io.FixedLenFeature([], tf.int64, default_value=0),\r\n                'shape': tf.io.VarLenFeature(tf.float32),\r\n                }\r\n\r\n    parsed_features = tf.io.parse_single_example(tf_record, features)\r\n    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\r\n    height = tf.cast(parsed_features['height'], tf.int32)\r\n    width = tf.cast(parsed_features['width'], tf.int32)\r\n    image = tf.reshape(image, [height, width, 3])\r\n\r\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n\r\n    shape = tf.sparse.to_dense(parsed_features['shape'], default_value=0.0)\r\n\r\n    shape = tf.reshape(shape, [Config.num_point, 6])\r\n\r\n    print(shape.numpy())   ##  <------ when using dataset.map, will fail at this line \r\n\r\n    return image, shape\r\n\r\ndef run_train(train_tf_record)\r\n\r\n    dataset = tf.data.TFRecordDataset([train_tf_record])\r\n\r\n    for item in dataset:\r\n        parse_tf_record(item)    ##  <---------- when debug into , the all the tensor in 'parse_tf_record' is eagerTensor \r\n \r\n\r\n    dataset = dataset.repeat().shuffle(1000).map(parse_tf_record,  \r\n   num_parallel_calls=4).batch(32)\r\n\r\n## <---------when debug into, all the tensor in 'parse_tf_record' is tensor\r\n\r\n    for item in dataset.take(1):\r\n        print(item)\r\n\r\n\r\nif __name__ == '__main__':\r\n    train_tf_record = \r\n    run_train(train_tf_record)\r\n\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 27671, "title": "Not found: No registered '_FusedMatMul' OpKernel for CPU devices compatible with node", "body": "I changed the title of this post since it occurs new problems. And you can see it at the latest comment.Thx.\r\n_________________________________________________________________________________\r\n\r\n<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):linux 3.10.107\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.12\r\n- Python version:2.7.5\r\n- Bazel version (if compiling from source):No bazel.I use the build_all_linux.sh.\r\n- GCC/Compiler version (if compiling from source): 4.8.2\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI trained a model with python and save it as ckpt files, and then transform it to pb file. I make the tensorflow to a stastic library and then try to load the model on c++. I can create the session and ReadBinaryProto, but when I run this code ,it fails and return theis message:\r\n`tensorflow::Status status_create = m_session->Create(*m_graphdef);`\r\n\r\n> Invalid argument: No OpKernel was registered to support Op 'Sin' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n>   <no registered kernels>\r\n> \r\n>          [[{{node parallel_0/rnnsearch_0/add_timing_signal/Sin}} = Sin[T=DT_FLOAT, _device=\"/gpu:0\"](parallel_0/rnnsearch_0/add_timing_signal/mul_2)]]\r\n> \r\n\r\n**Describe the expected behavior**\r\nThe model will be loaded successfully.\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\ntensorflow::Status status_create_sess = tensorflow::NewSession(tensorflow::SessionOptions(), &m_sess);\r\n\tif(!status_create_sess.ok()){\r\n\t\tcout<<\"ERROR: FAIL TO CREATE SESSION\"<<endl;\r\n\t\tcout<<status_create_sess.ToString()<<endl;\r\n\t\tm_eris = FAIL_TO_CREATE_SESSION;\r\n\t\treturn m_eris;\r\n\t}\r\n\r\n\tm_graphdef = new(std::nothrow) tensorflow::GraphDef;\r\n\tif(m_graphdef==NULL){\r\n\t\tcout<<\"ERROR: FAIL TO LOAD MODEL\"<<endl;\r\n\t\tm_eris = FAIL_TO_LOAD_MODEL;\r\n\t\treturn m_eris;\r\n\t}\r\n\r\n\ttensorflow::Status status_load = tensorflow::ReadBinaryProto(tensorflow::Env::Default(), model_path, m_graphdef);\r\n\tif(!status_load.ok()){\r\n\t\tcout<<\"ERROR: FAIL TO LOAD MODEL\"<<endl;\r\n\t\tcout<<status_load.ToString()<<endl;\r\n\t\tm_eris = FAIL_TO_LOAD_MODEL;\r\n\t\treturn m_eris;\r\n\t}   \r\n\ttensorflow::Status status_create = m_sess->Create((*m_graphdef));\r\n\tif(!status_create.ok()){\r\n\t\tcout<<\"ERROR: FAIL TO CREATE GRAPh IN SESSION\"<<endl;\r\n\t\tcout<<status_create.ToString()<<endl;\r\n\t\tm_eris=FAIL_TO_CREATE_GRAPH;\r\n\t\treturn m_eris;\r\n\t}\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I can find math_ops.cc in the source code of tensorflow , and I can find the Sin ops here. But it still return this message, so could somebody so kind to tell me where can I check the registered ops?", "I try to print the register list via  `tensorflow::OpRegistry::Global()->DebugString(false)` , but it returns \r\n\r\n> error: 'tensorflow::OpRegistry' has not been declared\r\n\r\nDoes this mean I didn't build the tensorflow to a static lib correctly? But I can load a simple graph with two tensors to add.", "Ok.I can print all the register ops and I can find Sin here.\r\n\r\n> Op<name=Sin; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]>\r\n\r\nSo, where is the problem? It seems related to [#18807](https://github.com/tensorflow/tensorflow/issues/18807),but I tried 1.6 1.12 1.10 and all the version returns the same error.\r\n", "Need I build the tensorflow with bazel? Is there any difference with building from makefile and bazel?", "Any help?", "I try to use print_seletive_registration_header tool to set op_to_register.h, but there are a lot of  \r\n\r\n> Warning: no kernel found for op XXX\r\n\r\nAnd even some very basic ops I think. Do I need to change something or compile the tensorflow before?\r\n", "I change the tensorflow to 1.10 of both static lib and python version , it can load the graph. But I can't set the tensor value like the many blogs did before.\r\n```\r\n\ttensorflow::TensorShape seq_input_shape;\r\n\tcout<<input.size()<<endl;\r\n\tseq_input_shape.AddDim(1);\r\n\tseq_input_shape.AddDim(input.size());\r\n\ttensorflow::TensorShape input_length_shape;\r\n\tinput_length_shape.AddDim(1);\r\n\tinput_length_shape.AddDim(1);\r\n\tcout<<seq_input_shape<<endl;\r\n\tcout<<seq_input_shape.dims()<<endl;\r\n\ttensorflow::Tensor seq_input(tensorflow::DT_INT32, seq_input_shape);\r\n\ttensorflow::Tensor input_length(tensorflow::DT_INT32, input_length_shape);\r\n\tcout<<\"input tensor ok\"<<endl;\r\n\tcout<<seq_input.AllocatedBytes()<<endl;\r\n\r\n\t//std::copy_n(input.begin(),input.size(),seq_input.flat<int>().data());\r\n\t//cout<<\"good here\"<<endl;\r\n\t//vector<int> temp = {input.size()};\r\n\t//std::copy_n(temp.begin(),temp.size(),input_length.flat<int>().data());\r\n\r\n\tauto inputMapped = seq_input.tensor<int,2>();\r\n\tauto inputLengthMapped = input_length.tensor<int,2>();\r\n\r\n\tfor(int i = 0;i<input.size();i++){\r\n\t\tcout<<i<<endl;\r\n\t\tcout<<input[i]<<endl;\r\n\t\tinputMapped(0,i) = input[i];\r\n\t}\r\n```\r\nEverytime I try to set the tensor value , it returns segmentation default. No matter what I use ,tensor<int,2> or flat <int> . So I try to another way , but I don't know whether it work or not, because if I try to print the tensor value, still segmentation fault error.\r\n```\r\n\tfor(int i = 0;i<input.size();i++){\r\n\t\tcout<<i<<endl;\r\n\t\tcout<<input[i]<<endl;\r\n\t\tinputMapped = &input[i];\r\n                inputMapped+=1;\r\n\t}\r\n```\r\nAnd then I finally can run the model , but it returns No OpKernel once again!!!!!!!!!!\r\n\r\n>  Executor failed to create kernel. Not found: No registered '_FusedMatMul' OpKernel for CPU devices compatible with node {{node parallel_0/rnnsearch_0/encoder/forward0/while/gru_cell/linear_state/BiasAdd}}\r\n>         .  Registered:  <no registered kernels>\r\n> \r\n>          [[parallel_0/rnnsearch_0/encoder/forward0/while/gru_cell/linear_state/BiasAdd]]\r\n> run error\r\n> Not found: No registered '_FusedMatMul' OpKernel for CPU devices compatible with node {{node parallel_0/rnnsearch_0/encoder/forward0/while/gru_cell/linear_state/BiasAdd}}\r\n>         .  Registered:  <no registered kernels>\r\n> \r\n>          [[parallel_0/rnnsearch_0/encoder/forward0/while/gru_cell/linear_state/BiasAdd]]\r\n> \r\n\r\nI am tired, is there any ways to solve the problem? plz...", "Ops and kernels are different things. build_all_linux.sh is probably not registering kernels properly. You can try making a simple bazel binary that loads the graphs and tries to run it. That way you can eliminate your code as a possible problem.\r\n\r\nStricly speaking anything in contrib (which build_all_linux) is may or may not work, but we don't generally support.", "> Ops and kernels are different things. build_all_linux.sh is probably not registering kernels properly. You can try making a simple bazel binary that loads the graphs and tries to run it. That way you can eliminate your code as a possible problem.\r\n> \r\n> Stricly speaking anything in contrib (which build_all_linux) is may or may not work, but we don't generally support.\r\n\r\n@aselle building using makefile is much simpler than bazel , \r\nalso for most of the platform libtensorflow_cc.so is not easy to build ( e.g androdi)\r\nbut libtensorflow-core.a can easily be built on android", "how to register math_ops in libtensorflow-core.a ", "> math_ops.cc\r\n\r\n@SefaZeng  where you able to integrate the operation in math_ops.cc in libtensorflow-core.a\r\n\r\n", "> > math_ops.cc\r\n> \r\n> @SefaZeng where you able to integrate the operation in math_ops.cc in libtensorflow-core.a\r\n\r\nI change the tensorflow version to 1.13 and the problem is solved... I dont know why, but it work for me, although my tensorflow-py version is 1.10.", "I have the [same issue](https://github.com/ctuning/ck-tensorflow/blob/master/package/lib-tensorflow-1.14.0-src-static/README.md) with TF C++ 1.14 and the MLPerf ResNet model.", "@SefaZeng We are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. we will get you the right help.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27671\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27671\">No</a>\n"]}, {"number": 27670, "title": "TF Keras local_test dataformat compatible test case updated", "body": "", "comments": ["@Dayananda-V could you please fix build errors? Thanks!", "@gbaned \r\n\r\nError is not induce by this PR code changes, will you retrigger build one more time. TIA\r\n`ImportError: No module named 'tensorflow_estimator.python.estimator.tpu'`"]}, {"number": 27669, "title": "TF 2.0 strange issue with code upgraded from TF 1.x.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Win 10\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.0.0-alpha0\r\n- Python version:3.6\r\n\r\n**Describe the current behavior**\r\nThe session return an ndarray [[value_estimate]] instead of value_estimate.\r\n\r\n**Describe the expected behavior**\r\nThe session should return a scalar float. Just value_estimate. It should not be in an ndarray.\r\nWorkaround: get the actual scalar float in the ndarray if it is not a float\r\nhttps://github.com/SetoKaiba/ml-agents/blob/tf2/ml-agents/mlagents/trainers/ppo/policy.py#L199-L200\r\n```python\r\nif not isinstance(value_estimate, float):\r\n            value_estimate = value_estimate[0][0]\r\n```\r\n\r\n**Code to reproduce the issue**\r\nhttps://github.com/SetoKaiba/ml-agents/blob/tf2/ml-agents/mlagents/trainers/ppo/policy.py#L199-L200\r\nThe problem can be reproduced without the two lines workaround.\r\n\r\n**Other info / logs**\r\nThe value_estimate is calculated by the session and model.value. Code is lines below.\r\nhttps://github.com/SetoKaiba/ml-agents/blob/tf2/ml-agents/mlagents/trainers/ppo/policy.py#L198\r\n```python\r\nvalue_estimate = self.sess.run(self.model.value, feed_dict)\r\n```\r\nself.model.value is defined like this. The previous layer is dense layer with one units.\r\nAnd the tf.identity should just return a scalar float.\r\nThe code is running correctly in TF 1.x. \r\nBut it's working incorrectly in TF 2.0.\r\nhttps://github.com/SetoKaiba/ml-agents/blob/tf2/ml-agents/mlagents/trainers/models.py#L298-L299\r\n```python\r\n        value = tf.layers.dense(hidden_value, 1, activation=None)\r\n        self.value = tf.identity(value, name=\"value_estimate\")\r\n```", "comments": ["Seems like it is a duplicate of issue #27425 . Can you please confirm?", "@achandraa Yes. It' duplicated. I created this because I think maybe the official didn't aware of it. Because tons of issues everyday. I just created this and closed that #27425. But then I received that #27425 is assigned. So I reopen it. Just to keep one would be ok.", "I looked at this, seems this is the intended behavior. `tf.layers.dense()` takes a tensor of shape `(batch, input_dim)` as input and return a tensor of shape `(batch, num_units)`. Here the output is a tensor, which is returned as a 2-d numpy array, not a scalar.", "@tranhungnghiep The num_units is 1. Shouldn't it be a scalar?\r\nAnd also the problem doesn't occur in tf1. And also it doesn't occur in the early training as well. It occurs after about 8000 steps.\r\n\r\nHere's the branch I migrated to tf2. I can only by adding L199-200 to make it work in tf2.\r\nhttps://github.com/SetoKaiba/ml-agents/blob/tf2/ml-agents/mlagents/trainers/ppo/policy.py#L198\r\n\r\nHere's the branch of original tf1.\r\nhttps://github.com/Unity-Technologies/ml-agents/blob/master/ml-agents/mlagents/trainers/ppo/policy.py#L198", "I tested on tf2.compat.v1 with disable_v2_behavior(). So it seems to be a bigger problem that was overlooked. Because the behavior of v1 was not replicated. \r\n\r\nI think the behavior changed due to it uses keras layers under the hood, and keras hides the batch size in the shape. Keras always makes some abstractions that are very confusing for expert users. \r\n\r\nI see this immediately, so maybe the delay in your case is not related. ", "@tranhungnghiep Thank you for your reply. Do you need an Unity env to reproduce the bug?\r\nI can upload one for you.", "Here's the Unity env for Win and Linux. I didn't test the Linux build. Because I'm using it on Win. Maybe it's not working.\r\nhttps://www37.zippyshare.com/v/LPFvEKiZ/file.html\r\nCheck out the repo for tf2 branch. https://github.com/SetoKaiba/ml-agents\r\nRemove the two lines workaround below.\r\nhttps://github.com/SetoKaiba/ml-agents/blob/tf2/ml-agents/mlagents/trainers/ppo/policy.py#L199-L200\r\nYou can just use the lines below to reproduce the bug.\r\n```\r\npip install -e ml-agents-envs\r\npip install -e ml-agents\r\n```\r\nFor Windows, replace the env for your path\r\n```\r\nmlagents-learn config\\trainer_config.yaml --env=\"E:\\Seto\\GitHub\\Unity-Technologies\\ml-agents\\UnitySDK\\Build\\Win\\Unity Environment\" --train\r\n```\r\nFor Linux, replace the env for your path\r\n```\r\nmlagents-learn config/trainer_config.yaml --env=\"3DBall\" --train\r\n```\r\n\r\n", "`tf.layers` is deprecated in TF2 in favor of tf.keras.layers; specifically here you'd use `tf.keras.layers.Dense`.  There is no `tf.layers` in TF2.\r\n\r\nIf you pass a scalar to `tf.keras.layers.Dense(1)` you'll get the explicit error:\r\n\r\n```python\r\nz = tf.keras.layers.Dense(1)(1)    \r\n>>> ValueError: Input 0 of layer dense_3 is incompatible with the layer: : expected min_ndim=2, found ndim=0. Full shape received: []\r\n```\r\n\r\nKeras Dense layers accept at least matrices and emit at least matrices, so the behavior is consistent in TF1 and TF2.\r\n\r\nIn your case, if you passed a 1x1 matrix to Dense(1) you'd get a 1x1 matrix back:\r\n\r\n```python\r\ntf.keras.layers.Dense(1)(tf.constant([[1.0]]))\r\n>>> <tf.Tensor 'dense_8/BiasAdd:0' shape=(1, 1) dtype=float32>\r\n```"]}, {"number": 27668, "title": "Automatic mixed precision for tensorflow-gpu", "body": "Recently, I noticed that NVIDIA updated the Deep Learning SDK documentation and added [Tensorflow Automixing Accuracy Training.](https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html#tensorflow-amp)This looks very simple,only need to set:\r\n`os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'`\r\nBut I didn't find any relevant information on the tensorflow website and github.Does this really work?Or need additional conditions?", "comments": ["It is part of NVIDIA's own tensorflow. It is not integrated into the official tensorflow.", "> It is part of NVIDIA's own tensorflow. It is not integrated into the official tensorflow.\r\n\r\nthank you for your reply", "I believe it's available for nightly and 1.14 with #26342.\r\n"]}, {"number": 27667, "title": "Unexpected output size for depthwise convolution with stride=2, dilation=3", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **CentOS**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **Apr5 tf-nightly-gpu**\r\n- TensorFlow version (use command below): **v1.12.0-11808-ga1e3d4490d 1.14.1-dev20190405**\r\n- Python version: **3.6**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **10.1**\r\n- GPU model and memory: **Tesla**\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\ninput shape = [?, 128, 128, 8]\r\noutput = depthwise_conv2d(input, filters=8, kernel_size=3,\r\n                                 strides=(2, 2),\r\n                                 dilation_rate=(3, 3),\r\n                                 padding='same')\r\n\r\noutput shape = [?, 65, 65, 8]\r\n\r\n**Describe the expected behavior**\r\nExpected output shape:\r\noutput = [?, 64, 64, 8]\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@olegarch, In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27666, "title": "Explicitly pass the genfiles directory to cc_op_gen.", "body": "This makes path computation code shorter and more robust. In particular, it makes things work under Bazel flag --incompatible_merge_genfiles_directory (https://github.com/bazelbuild/bazel/issues/6761).", "comments": ["Sorry for delay. Today, I approved another PR that provides a fix when --incompatible_merge_genfiles_directory is used.\r\nhttps://github.com/tensorflow/tensorflow/pull/27221\r\n\r\nI am not really familiar with --incompatible_merge_genfiles_directory flag. @benjaminp Is this fix still needed given that https://github.com/tensorflow/tensorflow/pull/27221 was submitted?", "#27221 will do the job, too. This is more of a generic solution. I can rebase it if you think it's worth bringing in.", "@benjaminp could you please resolve the conflicts? Thanks!", "@benjaminp Did you get a chance to look on conflicts? Please let us know on the update. Thanks!", "I'll just withdraw this, since the issue was fixed another way."]}, {"number": 27665, "title": "Add name=None argument to roll function", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version 2.0:\r\n- Are you willing to contribute it Yes:\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n`tensorflow.python.ops.manip_ops.roll` does not take name=None as parameter the current API\r\ndoes not allow that\r\n\r\n**Will this change the current api? How?**\r\nYes, roll function in `tensorflow.python.ops.manip_ops.roll` will take name=None as argument which will return a tensor with `name=name` and not the default one `roll_n`\r\n\r\n**File where roll exists**\r\n[manip_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/manip_ops.py)\r\n\r\n", "comments": ["There's an open PR, no need to assign the issue.", "There's an open PR, no need to assign the issue.", "@Gurpreetsingh9465 We see that [PR #27075](https://github.com/tensorflow/tensorflow/pull/27075) is merged , please let us know if we can close this issue ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 27664, "title": "Using slim to train my own model, ImportError: cannot import name 'slim'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):window7 Anacoda3 env\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):1.2.1\r\n- Python version:3.5.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\na importerror when i copy nets from slim ,however i have installed a slim in c:\\programdata\\anacoda3\\lib\\site-packages\r\n\r\n\r\nfrom nets import nets_factory\r\n\r\n**Other info / logs**\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-5-a29f10245850> in <module>()\r\n      2 import tensorflow as tf\r\n      3 from PIL import Image\r\n----> 4 from nets import nets_factory\r\n      5 import numpy as np\r\n\r\nE:\\Tensorflow\\learning\\nets\\nets_factory.py in <module>()\r\n     22 import tensorflow as tf\r\n     23 \r\n---> 24 from nets import alexnet\r\n     25 from nets import cifarnet\r\n     26 from nets import i3d\r\n\r\nE:\\Tensorflow\\learning\\nets\\alexnet.py in <module>()\r\n     39 import tensorflow as tf\r\n     40 \r\n---> 41 slim = tf.contrib.slim\r\n     42 trunc_normal = lambda stddev: tf.truncated_normal_initializer(0.0, stddev)\r\n     43 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in __getattr__(self, item)\r\n     51 \r\n     52   def __getattr__(self, item):\r\n---> 53     module = self._load()\r\n     54     return getattr(module, item)\r\n     55 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py in _load(self)\r\n     40   def _load(self):\r\n     41     # Import the target module and insert it into the parent's namespace\r\n---> 42     module = importlib.import_module(self.__name__)\r\n     43     self._parent_module_globals[self._local_name] = module\r\n     44 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    124                 break\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n    128 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py in <module>()\r\n     55 from tensorflow.contrib import saved_model\r\n     56 from tensorflow.contrib import seq2seq\r\n---> 57 from tensorflow.contrib import slim\r\n     58 from tensorflow.contrib import solvers\r\n     59 from tensorflow.contrib import sparsemax\r\n\r\nImportError: cannot import name 'slim'", "comments": ["You can try something like ' import tensorflow.contrib.slim as slim ' or upgrade your tensorflow version to 1.8 or higher", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 27663, "title": "\u6d4b\u8bd5", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": []}, {"number": 27662, "title": "saved_model_cli fails when --input_examples option contains string feature", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n```\r\n(venv) []$ python --version\r\nPython 3.7.2\r\n\r\n(venv) []$ saved_model_cli --version\r\n0.1.0\r\n\r\ntensorflow: 1.13.1\r\n```\r\n\r\n**Describe the current behavior**\r\nI have a model that accepts two string features, say 'subject' and 'body', and predict if the string content is SPAM. When trying to test the inference with `saved_model_cli --input_examples`, it produced error message.\r\n\r\nHere is the model's signature def info: \r\n```\r\n(venv) [jwan@jwan-mbp15 conversation_appropriateness]$ saved_model_cli show --dir working_dir/exported_model_dir/1554752450/ --tag_set serve --signature_def classification\r\nThe given SavedModel SignatureDef contains the following input(s):\r\n  inputs['inputs'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1)\r\n      name: input_example_tensor:0\r\nThe given SavedModel SignatureDef contains the following output(s):\r\n  outputs['classes'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1, 2)\r\n      name: linear/head/Tile:0\r\n  outputs['scores'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, 2)\r\n      name: linear/head/predictions/probabilities:0\r\nMethod name is: tensorflow/serving/classify\r\n```\r\n\r\nHere is the cmd line and error:\r\n```\r\n(venv) []$ saved_model_cli run --dir working_dir/exported_model_dir/1554752450/ --tag_set serve --signature_def classification --input_examples 'inputs=[{\"subject\":[\"love\"], \"body\":[\"money\"]}]'\r\nTraceback (most recent call last):\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/bin/saved_model_cli\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 911, in main\r\n    args.func(args)\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 641, in run\r\n    args.inputs, args.input_exprs, args.input_examples)\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 553, in load_inputs_from_input_arg_string\r\n    input_examples = preprocess_input_examples_arg_string(input_examples_str)\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 472, in preprocess_input_examples_arg_string\r\n    _create_example_string(example) for example in example_list\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 472, in <listcomp>\r\n    _create_example_string(example) for example in example_list\r\n  File \"/Users/jwan/Documents/source_code/python_snippets/venv/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 490, in _create_example_string\r\n    feature_list)\r\nTypeError: 'love' has type str, but expected one of: bytes\r\n```\r\n\r\nThe problem occurs at the saved_model_cli.py line 487 (https://github.com/tensorflow/tensorflow/blob/a9fe6cb21dd725cdb4d6708c970c2d044c13ce60/tensorflow/python/tools/saved_model_cli.py#L487):\r\n\r\n```\r\n    elif isinstance(feature_list[0], str):\r\n      example.features.feature[feature_name].bytes_list.value.extend(\r\n          feature_list)\r\n```\r\n\r\nIt checks if the list `feature_list` contains string values, and then try to append the list to feature's `bytes_list` which expects the element to be bytes, and not string.\r\n\r\n**Describe the expected behavior**\r\nThe code should convert the string to the bytes, for example:\r\n```\r\n    elif isinstance(feature_list[0], str):\r\n      feature_list = list(map(lambda x: x.encode(),feature_list))\r\n      example.features.feature[feature_name].bytes_list.value.extend(\r\n          feature_list)\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\n**Other info / logs**\r\nA [stack overflow post](https://stackoverflow.com/questions/55422537/testing-tf-serving-model-fails-with-bytes-as-strings-and-strings-as-bytes-confus) reported the same issue.\r\n\r\nPR to fix this issue: #27661\r\n\r\nThanks! ", "comments": ["\ud83d\udc4d \r\n\r\nI ran into this issue today too. Instead of doing this:\r\n\r\n```\r\nsaved_model_cli run \\\r\n--dir . \\\r\n--tag_set serve \\\r\n--signature_def predict \\\r\n--input_examples \u2018examples=[{\u201cmenu_item\u201d:[\u201ckouign amman\u201d]}, {\u201cmenu_item\u201d:[\u201cpot a feu\u201d]}, {\u201cmenu_item\u201d:[\u201ctruffles\u201d]}]\u2019\r\n```\r\n\r\nI had to do and hack and encode the string in python first and then use the `input_exprs` flag:\r\n\r\nhttps://gist.github.com/eggie5/8b459d9727c45341a1cdda75db4dd67e\r\n\r\n\r\n```\r\nsaved_model_cli run \\\r\n--dir . \\\r\n--tag_set serve \\\r\n--signature_def predict \\\r\n--input_exprs=\u2018examples=[b\u201d\\n\\x1f\\n\\x1d\\n\\tmenu_item\\x12\\x10\\n\\x0e\\n\\x0ckouign amann\u201d, b\u201d\\n\\x1c\\n\\x1a\\n\\tmenu_item\\x12\\r\\n\\x0b\\n\\tpot a feu\u201d, b\u201d\\n\\x1b\\n\\x19\\n\\tmenu_item\\x12\\x0c\\n\\n\\n\\x08truffles\u201d]\u2019\r\n```", "This should have been fixed by https://github.com/tensorflow/tensorflow/commit/b4dcf686821a3e1b42c677802d05837139b81cf7.  Please let us know if your problem continues in tf nightly.", "@junwan01 , It seems that in the [StackOverflow](https://stackoverflow.com/questions/55422537/) question you have given, issue is resolved, can we go ahead and close this issue?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27662\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27662\">No</a>\n"]}, {"number": 27661, "title": "fix saved_model_cli to accept string feature as input", "body": "fix the argument parsing for `--input_examples` so that it accepts the feature with string value. Previously it always complains:\r\n\r\n `TypeError: 'some string' has type str, but expected one of: bytes`.\r\n\r\nThis is because it is try to append the bytes list inside a tf Example, with string list. \r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27661) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!\r\n\r\nJun", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27661) for more info**.\n\n<!-- ok -->", "Thanks for the PR @junwan01! Do you mind also adding a test for this?", "@junwan01 gentle ping to add a test case.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27660, "title": "gradient not computed unless variable is assigned.", "body": "**System information**\r\n\r\nOn Google CoLab,\r\n\r\n```\r\npython --version\r\n> Python 3.6.7\r\n```\r\n\r\nTensorFlow Version: `2.0.0-dev20190405`\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nThe following code results in the gradient being `None`:\r\n\r\n```\r\ndef f(x):\r\n  return x ** 2\r\n\r\ndef grad(x):\r\n  with tf.GradientTape() as t:\r\n    t.watch(x)\r\n    # out = f(x)\r\n  return t.gradient(f(x), x) \r\n\r\nx = tf.convert_to_tensor(9.0)\r\n\r\ngrad(x).numpy()\r\n```\r\n\r\nBut if you use the assigned value `out = f(x)`, it works fine:\r\n\r\n```\r\ndef f(x):\r\n  return x ** 2\r\n\r\ndef grad(x):\r\n  with tf.GradientTape() as t:\r\n    t.watch(x)\r\n    out = f(x)\r\n  return t.gradient(out, x) \r\n\r\nx = tf.convert_to_tensor(9.0)\r\n\r\ngrad(x).numpy()\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nI'd expect that assignment to a local variable doesn't change the ability to compute gradients!\r\n\r\n**Code to reproduce the issue**\r\n\r\nSee above.\r\n\r\nThanks for any insight!", "comments": ["of course, this isn't a bug at all! it's a scoping problem!\r\n\r\n```\r\ndef f(x):\r\n  return x ** 2\r\n\r\ndef grad(x):\r\n  with tf.GradientTape() as t:\r\n    t.watch(x)\r\n    return t.gradient(f(x), x) \r\n\r\nx = tf.convert_to_tensor(9.0)\r\n\r\ngrad(x).numpy()\r\n```\r\n\r\nmy bad, thanks! :)"]}, {"number": 27659, "title": "Fix Typo", "body": "```LD_LIRARY_PATH``` -> ```LD_LIBRARY_PATH```\r\n\r\n#27620", "comments": []}, {"number": 27658, "title": "Removed redundant ticks to render properly (DOCS)", "body": "", "comments": []}, {"number": 27657, "title": "[TF 2.0 API Docs] tf.keras.activations.selu", "body": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/selu\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py\r\n\r\n**- Links**\r\nShould format the referenced paper - get rid of \"-\" and add the authors/year of publishing:\r\n`\"Self-Normalizing Neural Networks\" (Klambauer et al, 2017)\"`\r\n\r\n**- Definition**\r\nThe current definition does not specify the fixed values for `alpha` and `scale` constants. It also assumes knowledge of the ELU activation function. We should also include a link (i.e. https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu).\r\n\r\nProposed modified definition:\r\n\r\n```\r\nThe Scaled Exponential Linear Unit (SELU) activation function is:\r\n\r\n`scale` * `x` if `x > 0` and `scale * alpha * (exp(x)-1)` if `x < 0`\r\n\r\nwhere `alpha` and `scale` are pre-defined constants (`alpha = 1.6732632423543772848170429916717` and `scale = 1.0507009873554804934193349852946`.\r\nThe SELU activation function multiplies  `scale` > 1 with the `[elu](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu)` (Exponential Linear Unit (ELU)) to ensure a slope larger than one for positive net inputs. \r\n```\r\n\r\nFollowed by what is already in the docs with the formatted `lecun_normal` initialization bit and a link to it: https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_normal:\r\n\r\n```\r\n...The values of alpha and scale are chosen so that the mean and variance of the inputs are preserved between two consecutive layers as long as the weights are initialized correctly (see `[lecun_normal` initialization](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_normal)) and the number of inputs is \"large enough\" (see references for more information).\r\n```\r\n\r\n**- Examples**\r\nCan add a modified example fro the Intro to CNNs tutorials (use `selu` instead of `relu`)\r\n\r\n```\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='selu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='selu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='selu'))\r\n```\r\n\r\n**- Returns**\r\nCan modify to include the word `function`:\r\n```\r\nThe scaled exponential unit activation function`: `scale * elu(x, alpha)`.\r\n``` \r\nand format markdown for plain text.\r\n\r\n**- Raises**\r\nNot defined.\r\n\r\n**- Visuals**\r\nShould be added, similar to: https://cdn-images-1.medium.com/max/1600/1*WyQS-lnoemRA3_FpRL7r5w.png\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes", "comments": ["SELU was designed for standard feed-forward neural networks, I'd use a standard FNN for the SELU example instead of a CNN.", "@dynamicwebpaige can you help me with this i would love to work on this.\r\n"]}, {"number": 27656, "title": "Minor Doc Fix", "body": "from #27627", "comments": ["Thanks for the PR @gshashank84! Sorry we no longer accept patches to previous released branches. Will close this PR. Thanks again!"]}, {"number": 27655, "title": "Add loss scale optimizer for v1 optimizers", "body": "Co-authored-by: Nathan Luehr <nluehr@nvidia.com>\r\nCo-authored-by: Ben Barsdell <bbarsdell@nvidia.com>\r\n\r\nTest files are a slightly modified version of @reedwm's v2 loss scale optimizer tests in tensorflow/python/keras/mixed_precision/experimental/", "comments": ["/CC @alextp can you take a look for API approval?\r\n\r\nFor context, we already have a LossScaleOptimizer wrapping the V2 optimizer, at `tf.keras.mixed_precision.experimental.LossScaleOptimizer`. This adds a V1 wrapper, at `tf.train.mixed_precision.experimental.LossScaleOptimizer`. After this is submitted, we will add a function, `tf.mixed_precision.experimental.mixed_precision_optimizer` that will wrap with the appropriate LossScaleOptimizer wrapper and additionally enable the [recently-submitted grappler pass](https://github.com/tensorflow/tensorflow/pull/26342) to enable mixed precision.\r\n\r\nThis change also introduces a new LossScale class. I plan on merging the two LossScale classes shortly.", "Tagging as \"ready to pull\" to trigger internal changelist generation and the api owners process.", "@reedwm Should I make any changes to address the failures? (It looks like there should be some build dependencies added to tensorflow/tools/pip_package/BUILD)", "Sure, I'll merge right after you fix them", "Can you fix the issues?\r\n\r\nAlternatively, if it is irritating to rerun kokoro every time, I can try to fix the errors, as I can run tests faster internally and we want to get this in soon.", "I'm not sure if any of the remaining failures are related to this PR; the ubuntu sanity check had to do with BUILD files we modified, and is definitely green now.\r\n\r\nI'm happy to make additional changes but think they may be other issues", "Ok I will try merging", "Just noticed the python failures are because DynamicLossScale (and likely the other classes) is not in v2, but presumably we only want that in V1?", "This is failing our internal linter. I'll make the fixes internally than merge.", "The error \"ImportError: cannot import name initializers\" is difficult to fix. The root problem is that there is a circular dependency, as loss_scale.py depends on keras, keras depends on training.py, and training.py  depends on loss_scale.py.\r\n\r\nI will try to fix this by removing the dependency on Keras. If you have any ideas, please share. Unfortunately, if you make any commits at this point, it will make my life difficult, as I already fixed some internal lint errors.", "There are only a couple places where keras dependencies appear, so re-implementing those to remove the dependency as you suggest seems like the best approach.", "why loss scale must be at least 1? sometimes i want to use a loss scale smaller than 1.0", "The role of the loss scale is to prevent underflow, which is very\ncommon when doing many additions in float16 because of the lack of exponent\nbits (compared with float32). So we want to multiply all losses by a large\nnumber so we don't have to spend the precious few exponent bits we have on\nleading zeros. Doing so by an arbitrarily large number can overflow,\nthough, but while underflow is silent, overflow is noisy (it generates inf\n/ nan values), so we can detect it, and can use a line-search-like approach\nto find the largest loss scale possible such that we do not overflow, as\nthis will underflow the least.\n\nSo by this reasoning there's no point in ever having a loss scale less than\n1, as that would increase the odds of underflow.\n\nDoes this make sense?\n\nOn Thu, Dec 5, 2019 at 8:04 PM x10000year <notifications@github.com> wrote:\n\n> why loss scale must be at least 1? sometimes i want to use a loss scale\n> smaller than 1.0\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27655?email_source=notifications&email_token=AAABHRO5RCWIBXDV4S6FTUDQXHFLPA5CNFSM4HEM4LS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGC6N4Y#issuecomment-562423539>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRNEFSXE6R5M5LIWSDTQXHFLPANCNFSM4HEM4LSQ>\n> .\n>\n\n\n-- \n - Alex\n", "but sometimes the largest loss scale that doesn't overflow could be smaller than 1.0, and i'm doing the line-search on the parameter of FixedLossScale.", "@alextp @MattConley  another problem is that, when i use dynamic loss scale, the model training consumes significantly more gpu memory, which leads to OOM when the batch size is big. do you have any idea? thanks.", "Is this with eager or with graph? Could it be the persistent gradient tape?\n\nOn Sun, Feb 9, 2020 at 9:40 PM x10000year <notifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> another problem is that, when i use\n> dynamic loss scale, the model training consumes significantly more gpu\n> memory, which leads to OOM when the batch size is big. do you have any\n> idea? thanks.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27655?email_source=notifications&email_token=AAABHRIKBZLL566OO4G4RF3RCDSFRA5CNFSM4HEM4LS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOELHJNQA#issuecomment-583964352>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLCB7GKZ4DDWEMQL7DRCDSFRANCNFSM4HEM4LSQ>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp I use tf.Estimator with tf 1.15. So it's a graph.", "This really shouldn't happen. Can you find a colab example to reproduce or something like that?"]}, {"number": 27654, "title": "TypeError: __init__() got an unexpected keyword argument 'serialized_options'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.4\r\n- TensorFlow installed from (source or binary): Binary from pip/PyPi\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: CPU only\r\n- GPU model and memory: MacPro integrated\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI have previously running code that explodes on import prior to any runtime execution. Reports the error above.\r\n\r\n**Describe the expected behavior**\r\nThis library needs to run and not choke on its own imports.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"/Users/raymond/Depot/ai-worker/duplicate_ai/test.py\", line 1, in <module>\r\n    from model import SiameseDream\r\n  File \"/Users/raymond/Depot/ai-worker/duplicate_ai/model.py\", line 1, in <module>\r\n    import keras.backend as K\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/keras/__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/keras/utils/__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/keras/utils/conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/keras/backend/__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/core/framework/node_def_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\r\n  File \"/Users/raymond/env/ai-worker/lib/python3.7/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 22, in <module>\r\n    serialized_pb=_b('\\n/tensorflow/core/framework/resource_handle.proto\\x12\\ntensorflow\\\"r\\n\\x13ResourceHandleProto\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\tcontainer\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x11\\n\\thash_code\\x18\\x04 \\x01(\\x04\\x12\\x17\\n\\x0fmaybe_type_name\\x18\\x05 \\x01(\\tBn\\n\\x18org.tensorflow.frameworkB\\x0eResourceHandleP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\r\nTypeError: __init__() got an unexpected keyword argument 'serialized_options'\r\n\r\n", "comments": ["Hi @apocalypse2012 - can you provide a minimal code example which reproduces this same error ?", "@apocalypse2012 \r\n1. Were you able to import tensorflow (without running any model)\r\n2. Can you try running your code in Google colab to whether there is any issue related to code?\r\n3. Did you upgrade anything between then and now? You said, it was working earlier.\r\n4. can you provide a code to reproduce the issue?\r\nthanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27653, "title": "Support for Other Types of Tensors in tf.data (For example RaggedTensors / Sparse Tensors)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently tf.data only supports Regular Tensors.\r\n**Will this change the current api? How?**\r\nThis will not change the API on a large scale. This will just allow tf.data to return RaggedTensor or SparseTensors depending on the Users Need. This will save a lot of memory when it comes to reading Variable Length Sequences.\r\n**Who will benefit with this feature?**\r\nAnyone Who is using tensorflow.\r\n**Any Other info.**\r\nI did some digging in the repository, while trying to manually trace function calls and see which functions and classes are needed to be updated.\r\n1. A similar Overload of GetNextInternal is needed in dataset.h for every new type of vector of Tensor to be Supported.(Sparse and Ragged) https://github.com/tensorflow/tensorflow/blob/222fea0388a9ca5ef5e736156e6604fbe51f07b0/tensorflow/core/framework/dataset.h#L840-L842\r\n2. A new similar overload of GetNext() with new type of vector of the type of Tensor to be supported (Sparse and Ragged) https://github.com/tensorflow/tensorflow/blob/222fea0388a9ca5ef5e736156e6604fbe51f07b0/tensorflow/core/framework/dataset.h#L720-L721\r\n3. Implement this GetNextInternal definition in the data kernel ops. Similar to these\r\nhttps://github.com/tensorflow/tensorflow/blob/222fea0388a9ca5ef5e736156e6604fbe51f07b0/tensorflow/core/kernels/data/interleave_dataset_op.cc#L162-L164\r\n4. Create modifications of Python Interfaces for these kernels, here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py", "comments": ["I'ld like to work on this issue / Collaborate with Anyone.\r\n@jsimsa", "@captain-pool your statement that tf.data only supports regular tensors is not true.\r\n\r\nIt already supports `tf.SparseTensor`s and there is an internal PR in progress that will add support for `tf.RaggedTensor`s.\r\n\r\nNote that the support exists at Python level and is provided through the Structure module (for instance see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/util/structure.py#L501).\r\n\r\nThe idea is that non-dense tensors are boxed as regular tensors when they are passed into op kernels because in C++ there are no counterparts to `tf.SparseTensor` or `tf.RaggedTensor`. The added benefit of doing that is that we do not have to write N kernels for each tf.data op, where N would be the number of types to support.\r\n\r\nIn other words, this feature request is already partially addressed and will be completely address once the RaggedTensor support is completed. For the time being, I am assigning the to @edloper who is leading the RaggedTensor effort.", "> @captain-pool your statement that tf.data only supports regular tensors is not true.\r\n> \r\n> It already supports `tf.SparseTensor`s and there is an internal PR in progress that will add support for `tf.RaggedTensor`s.\r\n> \r\n> Note that the support exists at Python level and is provided through the Structure module (for instance see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/util/structure.py#L501).\r\n> \r\n> The idea is that non-dense tensors are boxed as regular tensors when they are passed into op kernels because in C++ there are no counterparts to `tf.SparseTensor` or `tf.RaggedTensor`. The added benefit of doing that is that we do not have to write N kernels for each tf.data op, where N would be the number of types to support.\r\n> \r\n> In other words, this feature request is already partially addressed and will be completely address once the RaggedTensor support is completed. For the time being, I am assigning the to @edloper who is leading the RaggedTensor effort.\r\n\r\nThanks for Clearing out the Doubts. @jsimsa will definitely look into it.", "tf.data support for RaggedTensors was added by 5fe90dc.", "Thank you for your work!\r\nHowever I think, there is a bug somewhere. I tried the following code in tensorflow 2.0.0-beta0:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\n\r\ndata = tf.ragged.constant([\r\n        [[1, 1],\r\n         [2, 2]],\r\n        \r\n        [[3, 3]],\r\n         \r\n        [],\r\n        \r\n        [[4, 4],\r\n         [5, 5]]\r\n    ], dtype=tf.float32, ragged_rank=1)\r\n\r\nds = Dataset.from_tensor_slices(data)\r\nds = ds.batch(2)\r\n\r\nfor i, batch in enumerate(ds):\r\n    print(\"batch\", i)\r\n    for x in batch:\r\n        print(x.numpy())\r\n```\r\nThe output is:\r\n```\r\nbatch 0\r\n[[1. 1.]\r\n [2. 2.]\r\n [3. 3.]]\r\n[]\r\nbatch 1\r\n[]\r\n[[4. 4.]\r\n [5. 5.]]\r\n```\r\nthe correct output should be:\r\n```\r\nbatch 0\r\n[[1. 1.]\r\n [2. 2.]]\r\n[[3. 3.]]\r\nbatch 1\r\n[]\r\n[[4. 4.]\r\n [5. 5.]]\r\n```", "Thanks for pointing this out -- I agree that something looks broken there.\nWe'll look into it and get back to you.\n\nThanks,\n-Edward\n\nOn Fri, Jun 14, 2019 at 6:56 AM PistaSaki <notifications@github.com> wrote:\n\n> Thank you for your work!\n> However I think, there is a bug somewhere. I tried the following code in\n> tensorflow 2.0.0-beta0:\n>\n> import tensorflow as tffrom tensorflow.data import Dataset\n>\n> data = tf.ragged.constant([\n>         [[1, 1],\n>          [2, 2]],\n>\n>         [[3, 3]],\n>\n>         [],\n>\n>         [[4, 4],\n>          [5, 5]]\n>     ], dtype=tf.float32, ragged_rank=1)\n>\n> ds = Dataset.from_tensor_slices(data)\n> ds = ds.batch(2)\n> for i, batch in enumerate(ds):\n>     print(\"batch\", i)\n>     for x in batch:\n>         print(x.numpy())\n>\n> The output is:\n>\n> batch 0\n> [[1. 1.]\n>  [2. 2.]\n>  [3. 3.]]\n> []\n> batch 1\n> []\n> [[4. 4.]\n>  [5. 5.]]\n>\n> the correct output should be:\n>\n> batch 0\n> [[1. 1.]\n>  [2. 2.]]\n> [[3. 3.]]\n> batch 1\n> []\n> [[4. 4.]\n>  [5. 5.]]\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/27653?email_source=notifications&email_token=ABMFVDEH4MXTRXWXSIWNZOTP2N2MNA5CNFSM4HEMR2W2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXWOB3Q#issuecomment-502063342>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABMFVDCBVOWKHMYZEAF6UMLP2N2MNANCNFSM4HEMR2WQ>\n> .\n>\n", "Is this fixed now?", "Yes this was fixed by 84cf4d436eb5e41b0a7b24a3a079fd20c1603594.", "Thank you, it seems to work!\r\nI have a related problem, but maybe I should open it as another issue:\r\nI have a dataset from generator, containing uneven tensors. After batching I would expect it to return dataset with RaggedTensors. At present it fails.\r\nHere is a minimal example:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\n\r\ndef get_iterator():\r\n    return map(lambda x: np.ones([x, 1]), range(4))\r\n    \r\nds = Dataset.from_generator(get_iterator, output_types= tf.float32,\r\n                            output_shapes=[None, 1])\r\n\r\nfor x in ds:\r\n    print(x)    \r\n\r\nprint(\"Batched:\")\r\n\r\nfor x in ds.batch(2):\r\n    print(x) \r\n```", "@PistaSaki \r\n\r\nIf this is still open issue (and if somebody else like myself is looking this up):\r\nfrom_generator creates regular tf.Tensors.\r\nBut you could explicitly cast them to tf.RaggedTensor:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\n\r\ndef get_iterator():\r\n    return map(lambda x: np.ones([x, 1]), range(4))\r\n    \r\nds = Dataset.from_generator(get_iterator, output_types= tf.float32,\r\n                            output_shapes=[None, 1])\r\n\r\nds = ds.map(tf.RaggedTensor.from_tensor)\r\n\r\nfor x in ds:\r\n    print(x)    \r\n\r\nprint(\"Batched:\")\r\n\r\nfor x in ds.batch(2):\r\n    print(x) \r\n```", "You can use [tf.data.experimental.dense_to_ragged_batch](https://www.tensorflow.org/api_docs/python/tf/data/experimental/dense_to_ragged_batch) to batch variable-sized tensors into a ragged tensor.", "@PistaSaki, @edloper,\r\nIs there an approach that returns a `tf.RaggedTensor` using `tf.data.Dataset.from_generator` instead of a `tf.Tensor`? ", "@PistaSaki, @VitaliKaiser If you have dense data and want to batch it to become ragged, you can use [`tf.data.experimental.dense_to_ragged_batch`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/dense_to_ragged_batch?version=nightly).\r\n\r\n@Ceceu There is a pull request (#37400) that will update `Dataset.from_generator` to work with `RaggedTensor` (or other composite tensors).  But I think it's been stalled for a little while on making sure it doesn't break a test."]}, {"number": 27652, "title": "[TF 2.0 API Docs] tf.keras.activations.elu", "body": "**System information**\r\n- TensorFlow version: 2.0 alpha\r\n- Doc Link:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/elu\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py\r\n\r\n**- Links**\r\nLinks exist. Should format the link to the original paper (delete \"-\"). Also, should add authors and year of publishing \r\n\r\nE.g. \r\n```\r\nReference: \"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\" (Clevert et al, 2015)\r\n```\r\n\r\n**- Definition**\r\nSince it just says: `Exponential linear unit` we can modify it to the following - similar to the [original paper](https://arxiv.org/abs/1511.07289) :\r\n```\r\nThe exponential linear unit (ELU) with `alpha` > 0 is:\r\n`x` if `x > 0` and `alpha * (exp(x)-1)` if `x < 0`\r\nThe ELU hyperparameter `alpha` (\u03b1) controls the value to which an ELU saturates for negative net inputs.\r\nELUs diminish the vanishing gradient effect.\r\n```\r\nFollowed by word-for-word stuff from the [original paper](https://arxiv.org/abs/1511.07289):\r\n```\r\nELUs have negative values which pushes the mean of the activations closer to zero. \r\nMean activations that are closer to zero enable faster learning as they bring the gradient closer to the natural gradient. \r\nELUs saturate to a negative value when the argument gets smaller. \r\nSaturation means a small derivative which decreases the variation and the information that is propagated to the next layer.\"\r\n```\r\n\r\n**- Examples**\r\nNo examples given. Can add a modified example from the Intro to CNNs tutorial (where `elu` replaces ReLU - `relu`) \r\n\r\nE.g.\r\n```\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='elu', input_shape=(28, 28, 1)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='elu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='elu'))\r\n```\r\n\r\n**- Parameters**\r\nBoth params defined already but to aid the user it should state that `alpha` (\u03b1) should be set at 1.0  _by default_ and that:\r\n```\r\n`alpha` controls the value to which an ELU saturates for negative net inputs.\r\n```\r\n(source: [paper](https://arxiv.org/abs/1511.07289)) \r\n\r\n... instead of just \r\n```\r\n`alpha`: A scalar, slope of negative section\r\n```\r\n\r\n**- Returns**\r\nDefined but for clarity should say: \r\n```\r\nThe exponential linear unit (ELU) activation function: `x` if `x > 0` and `alpha * (exp(x) - 1)` if `x < 0`\r\n```\r\n instead of simply `The exponential linear activation:...[equation]`\r\n\r\n**- Raises**\r\nNot defined.\r\n\r\n**- Visuals**\r\nShould be added to help the user. Example - see p.5 of the original paper: https://arxiv.org/pdf/1511.07289.pdf.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes", "comments": ["thank you @Bharat123rox @kyscg and @fchollet . Closing now \ud83d\udc4d"]}, {"number": 27651, "title": "Starting a TF session (and nothing else) uses over 350MB of GPU memory", "body": "On TF `1.13.1`, the code below:\r\n```\r\nwith tf.Session(config=config) as sess:\r\n    while True:\r\n        print(\"Session is open!\")\r\n        time.sleep(1)\r\nUses 363MiB / 16280MiB according to nvidia-smi.\r\n```\r\n\r\nAm I missing something or is this normal? Shouldn't GPU usage be 0MiB at this point? If not, why?", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27650, "title": "Clarified args lists for functions in compat.py", "body": "", "comments": []}, {"number": 27649, "title": "strided_slice leads to unknown shape for Input layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n```bash\r\nconda install tensorflow-gpu==2.0-alpha\r\n```\r\n- Python version:\r\n3.7.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nnot relevent\r\n- GPU model and memory:\r\nnot relevent\r\n\r\n\r\n**Describe the current behavior**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\n\r\nwith tf.device('/cpu:0'):\r\n    t = Input((2, 3, 4), batch_size=1)\r\n    output = tf.strided_slice(t, [0, 0, 0, 0], [-1, -1, -1, 2])\r\n    print(output.shape)\r\n```\r\nOutput is `<unknown>`\r\n\r\n**Describe the expected behavior**\r\nstrided_slice should calculate the shape of the output tensor correctly.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["hello i would like to work on this and make a PR for it ", "@ipod825 Thanks for trying TF 2.0 alpha. I was able to reproduce the observed behavior. Executing the same snippet in TF 2.0 cpu version returns correct results. ", "This is fixed with latest TF 2.0 Nightly. See [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/c499ffa64c5c541e31a81c876c83fbd9/tf27649.ipynb#scrollTo=wZkzcfDM3TCh) Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27649\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27649\">No</a>\n"]}]