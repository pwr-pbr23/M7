[{"number": 42593, "title": "Support converting from joblib or pickle models", "body": "Hello,\r\n\r\nI have a trained model that uses **sklearn** **EllipticEnvelope** (unfortunately couldn't find the equivalent model in tf) and I can get only `joblib` or `pickle` format models from that. Is there a way to convert such models to tflite? Thank you. ", "comments": ["@archer29m,\r\nIn order to expedite the trouble-shooting process, could you please provide the code and the dataset you have used to build the model. Thanks!\r\n\r\n", "Sure, the code and dataset is open source here:\r\n[https://github.com/gireeshkbogu/AnomalyDetect](https://github.com/gireeshkbogu/AnomalyDetect)\r\nThat would be really helpful to have the equivalent tensorflow model so it can be converted to tflite model easier. Thanks!  ", "I don't think this is a TFLite specific issue, and probably best posted as a question on StackOverflow.", "Yes that' specifically a `Tensorflow` related question  not a `tflite`. However, I'm interested to deploy the output model using `tflite` later.", "Please try [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow). Thanks!"]}, {"number": 42592, "title": "FusedBatchNorm vs FusedBatchNormV3", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nI described the issue here: https://stackoverflow.com/questions/63542404/fusedbatchnorm-vs-fusedbatchnormv3\r\n", "comments": ["@slala2121 \r\nWe see that you are using tf 1.13, we have support from 1.15 and 2.x, can you please upgrade and let us know if it helps resolve the issue faced.", "Thanks for your response. Ok, I am using TF 2.2.2 and using v1 (from tensorflow.compat import v1 as v1) for importing the meta graph and still getting same issue.", "@slala2121\r\nPlease share simple indented stand alone code for us to replicate the issue faced, or if possible share colab gist with the error faced.", "I posted the code with link to model here:\r\nhttps://discuss.pytorch.org/t/difference-in-batchnorm-outputs-when-converting-from-tf-model-to-pytorch/93811", "@slala2121 \r\nI ran the code shared and faced different issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/67b52c5eb43404e78824f74a14f173ab/untitled389.ipynb).", "@Saduf2019 The model file \"model-1.meta\" is available here: https://figshare.com/articles/Trained_neural_network_models/8312183", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42592\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42592\">No</a>\n"]}, {"number": 42591, "title": "Fix compiling against system protobuf", "body": "When trying to compile with the bazel configuration `build --action_env TF_SYSTEM_LIBS=\"com_google_protobuf\"`, the following errors occur.\r\n\r\n```\r\nERROR: /home/sclarkson/tensorflow-master/tensorflow/core/data/service/BUILD:31:17: no such target '@com_google_protobuf//:any_proto': target 'any_proto' not declared in package '' defined by /home/sclarkson/.cache/bazel/_bazel_sclarkson/fffe72c6b1157d70fb0a456ab7b675c2/external/com_google_protobuf/BUILD.bazel and referenced by '//tensorflow/core/data/service:dispatcher_proto'\r\n```\r\n\r\nThis PR adds the missing protobuf library definitions to successfully compile against the system protobuf.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42591) for more info**.\n\n<!-- need_sender_cla -->", "@sclarkson Thank you for your contribution. Can you please sign CLA? Thanks!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42591) for more info**.\n\n<!-- ok -->", "@gbaned Had the wrong email address on the commit. Fixed it now. ", "@sclarkson Thanks for that PR, ran into this too.\r\n\r\n@gbaned @mihaimaruseac Wouldn't it somehow possible for you guys to set up a CI job that tests building with those system libs? They break with every release and require painful patching for package managers.", "We could attempt supporting a community based build, I think, if someone from the open source maintains it."]}, {"number": 42590, "title": "Cannot assign a device for operation when using multiple embedding columns", "body": "\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\nYes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux, Amazon Deep Learning Image, Amazon Linux 2\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\nNo\r\n-   **TensorFlow installed from (source or binary)**:\r\nBinary\r\n-   **TensorFlow version (use command below)**:\r\n2.3\r\n-   **Python version**:\r\n3.7.7\r\n-   **Bazel version (if compiling from source)**:\r\nN/A\r\n-   **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n-   **CUDA/cuDNN version**:\r\nCUDA Version: 11.0\r\n-   **GPU model and memory**:\r\nNVIDIA Tesla M60 - 16 GB (Amazon EC2 g3s.xlarge - single GPU)\r\n-   **Exact command to reproduce**:\r\npython repro.py\r\n\r\n### Describe the problem\r\nWhen using the functional API with Keras with more than one embedding input, I get device placement issues. The actual error is:\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation functional_1/first_embed_layer/test_embedding/test_embedding_weights/embedding_lookup_sparse/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node functional_1/first_embed_layer/test_embedding/test_embedding_weights/embedding_lookup_sparse/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]\r\n\r\nI've found several workarounds:\r\n- Instead of using the functional API, use keras.model.Sequential() with a single DenseFeatures layer containing both of my embedding columns (I was trying to avoid this because I can't find an easy way to pull out the weights of only one of the columns when doing it this way, without searching by dimension size).\r\n- Run it without a GPU. Also not ideal because of the slow down.\r\n\r\nI also tried doing a single DenseFeatures layer with both of my embedding columns using the functional API, but that results in the same placement errors. For some reason not using the functional API fixes it. \r\n\r\nA minimal example from my code that repros the problem reliably:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef create_model():\r\n  test_input = tf.keras.Input(shape=(None,), dtype='string', name='test')\r\n  test2_input = tf.keras.Input(shape=(None,), dtype='string', name='test2')\r\n  feature_layer_inputs = {}\r\n  feature_layer_inputs['test'] = test_input\r\n  feature_layer_inputs['test2'] = test2_input\r\n\r\n  vocab_list = ['This', 'That', 'Thing']\r\n  feature_col = tf.feature_column.categorical_column_with_vocabulary_list(\r\n      key='test', vocabulary_list=vocab_list,\r\n      num_oov_buckets=0)\r\n  embed_col = tf.feature_column.embedding_column(\r\n      categorical_column=feature_col, dimension=4, combiner='mean')\r\n  first_embed_layer = tf.keras.layers.DenseFeatures(\r\n      feature_columns=[embed_col], name=\"first_embed_layer\")\r\n\r\n  second_vocab_list = ['a', 'b', 'c']\r\n  feature_col_two = tf.feature_column.categorical_column_with_vocabulary_list(\r\n      key='test2', vocabulary_list=second_vocab_list,\r\n      num_oov_buckets=0)\r\n  embed_col_two = tf.feature_column.embedding_column(\r\n      categorical_column=feature_col_two, dimension=4, combiner='mean')\r\n  second_embed_layer = tf.keras.layers.DenseFeatures(\r\n      feature_columns=[embed_col_two], name=\"second_embed_layer\")\r\n  \r\n  x = first_embed_layer(feature_layer_inputs)\r\n  y = second_embed_layer(feature_layer_inputs)\r\n  x = tf.keras.layers.concatenate([x, y])\r\n  \r\n  hidden_layer = tf.keras.layers.Dense(units=35, use_bias=False,\r\n      name=\"user-embeddings-layer\")(x)\r\n\r\n  model = tf.keras.Model(\r\n    inputs=[v for v in feature_layer_inputs.values()],\r\n    outputs=[hidden_layer]\r\n  )\r\n\r\n  model.compile(optimizer=tf.keras.optimizers.Adagrad(lr=.01),\r\n                # loss=loss_func,\r\n                loss=\"sparse_categorical_crossentropy\",\r\n                metrics=['accuracy'])\r\n  return model\r\n\r\nin_tensor = tf.constant(['This', 'That'])\r\nother_tensor = tf.constant(['a', 'b'])\r\n\r\nfeatures = {\r\n  'test': in_tensor,\r\n  'test2': other_tensor,\r\n}\r\ny = tf.constant([1, 2])\r\n\r\nmodel = create_model()\r\nhistory = model.fit(x=features, y=y,\r\n                    epochs=10, shuffle=False, \r\n                    batch_size=1,\r\n                    verbose=1,\r\n                    callbacks=[])\r\n```\r\n\r\n", "comments": ["@rosssketchup \r\nI am able to replicate this issue on GPU, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/805b5d56c0a2da6c69fb008635156ab1/untitled385.ipynb), i do not observe any slowness when GPU is not used.", "It won't be slow with that toy data, but I don't think I'd want to run my full dataset with a CPU.\r\n\r\nUpdating what I said in the bug, I actually can't get my own code to work with the Sequential API. I get the same colocation errors, even though it seemed to work with the toy example above.\r\n\r\nI also get: Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: Consider rewriting this model with the Functional API.\r\n\r\nSo I guess I really should be using the Functional API.\r\n", "We are moving away from feature columns in favor of Keras Preprocessing Layers starting in 2.3", "Good to know, so the proper way to do this would be using several instances of keras.layers.Embedding?\r\n\r\nI liked the feature columns because dealing with combining/averaging and out of vocabulary values seemed easier. With raw keras, I have to use globalaveragepooling1d and manual masking. But if that's the proper way to go, then I'll switch to using that.\r\n\r\nThanks", "> Good to know, so the proper way to do this would be using several instances of keras.layers.Embedding?\r\n> \r\n> I liked the feature columns because dealing with combining/averaging and out of vocabulary values seemed easier. With raw keras, I have to use globalaveragepooling1d and manual masking. But if that's the proper way to go, then I'll switch to using that.\r\n> \r\n> Thanks\r\n\r\nYes that is the proper way. I think shared embedding column + keras doesn't work today?\r\nRe manual masking -- if you're using ragged tensor, I think for many use cases you don't need masking at all", "Ok great, and good point, I didn't even think of using Ragged Tensors. I'm using variable length string arrays as input, and you're right, Ragged Tensors would remove the need for masking.\r\n\r\nI will give it a shot. I think we can close this issue as won't fix if the feature columns are being deprecated.\r\n\r\nThanks for the help.", "Closing per comments above.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42590\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42590\">No</a>\n"]}, {"number": 42589, "title": "what exactly does the argument convert_to_tensor_fn do?", "body": "In [tfp.layers.IndependentBernoulli](https://www.tensorflow.org/probability/api_docs/python/tfp/layers/IndependentBernoulli), there's this argument `convert_to_tensor_fn` that has four value options: `tfd.Distribution.sample`, `tfd.Distribution.mean`, `tfd.Distribution.mode`, `tfd.Bernoulli.logits`. I followed [this post](https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE) when trying to implement VAE for MNIST data reconstruction, in which the output layer has a `IndependentBernoulli` distribution with `convert_to_tensor_fn` set to `tfd.Bernoulli.logits`, instead of the default `tfd.Distribution.sample`. However, I experimented with all the other 3 options and found that the results are basically identical, in terms of both the loss after each epoch and the quality of reconstructed images.\r\n\r\nI'm thus wondering what does this `convert_to_tensor_fn` argument do, and what are the differences among all 4 options?", "comments": ["I've figured out: if we set `convert_to_tensor_fn =tfd.Distribution.sample`, it will call `.sample()` for us when we treat `tfp.distributions` object as a `tf.Tensor` object. For example, call such `tfp.distributions` object as `dist`, then if we write `dist.shape`, what the code actually does is `dist.sample().shape`."]}, {"number": 42588, "title": "convert tesnorflow::ops::cast to tensorflow::tensor", "body": "System information\r\n\r\n- Have I written custom code :yes \r\n- OS Platform and Distribution :Linux ubtuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.25.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.2.89/7.6.5.32\r\n- GPU model and memory: NVidia GTX 1060\r\n- OpenCv 4.4.2\r\n\r\n\r\nI have written a custom code and trying to read an image with opencv and convert it to a tensorflow::Tensor.\r\nI did it successfully and can do inference on my model but my model gives me a tensor of int64  and now i wanna cast it to a tensor of int32. \r\n\r\n    ` auto root = tensorflow::Scope::NewRootScope();\r\n      Tensor inputImg(tensorflow::DT_UINT8, tensorflow::TensorShape({1, input_height_, input_width_, 3}));\r\n      uint8_t *image1_p_ = inputImg.flat<uint8_t>().data();\r\n      Mat cv_image1_ = cv::Mat(input_height_, input_width_, CV_8UC3, image1_p_);\r\n      Mat image = imread(\"test_img.jpg\");\r\n      cv::Mat resized_img;\r\n      resize(image,resized_img,cv::Size(input_width_,input_height_));\r\n      cvtColor(resized_img,resized_img,COLOR_BGR2RGB);\r\n      resized_img.convertTo(cv_image1_, CV_8UC3);\r\n      std::vector<std::pair<std::string, tensorflow::Tensor>> inputs = {{ \"ImageTensor:0\", inputImg} };\r\n      std::vector<tensorflow::Tensor> outputs;\r\n      status = session->Run(inputs, {\"SemanticPredictions:0\"},{}, &outputs);\r\n      if (!status.ok()) {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return 1;\r\n        }\r\n      auto int64_caster =  Cast(root.WithOpName(\"int64_caster\"), outputs[0], tensorflow::DT_INT32);` \r\n\r\nI searched and found tensorflow **Cast** function. it gives me an tensorflow::opes::cast output  with the name of **int64_caster**\r\nbut i don't know how to convert it to tensorflow::tensor object.", "comments": ["@naserpiltan \r\nCould you please provide with complete stand alone code for us to replicate the issue faced or if possible share a colab gist with the error faced.", "@Saduf2019  hi and thank you so much for your answer. sorry for my bad writing.\r\nI am working on a semantic segmentation project with tensorflow deeplab project([deeplab project](https://github.com/tensorflow/models/tree/master/research/deeplab))\r\nI made a test project to run some pretrained models provided in tensorflow deeplab modelzoo ([deeplab modelzoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md))\r\nI downloaded xception65_cityscapes_trainfine model to my project.\r\nI can read an image with opencv c++ library and convert it to tensorflow::tensor  and can do inference successfully.\r\nWhen i run my code , Tensorflow  gives me an output tensor with the data type of int64.\r\nNow i have to  convert this tensor of int64 to an opencv Mat for showing the segmentation results but opencv doesn't support int64 data type,it just support's int32 and int16  , int8 , etc. so i wanna cast the output tensor to a tensor of int32 .  I searched and found the **cast** function in tensorflow::ops. i did casting in the last line of  my project.\r\nThis is my whole project code :\r\n\r\n`\r\n      #include <tensorflow/cc/ops/array_ops.h>\r\n      #include \"tensorflow/cc/client/client_session.h\"\r\n      #include \"tensorflow/cc/ops/standard_ops.h\"\r\n      #include \"tensorflow/core/framework/tensor.h\"\r\n      #include \"tensorflow/cc/ops/standard_ops.h\"\r\n      #include <tensorflow/core/framework/graph.pb.h>\r\n      #include <tensorflow/core/framework/tensor.h>\r\n      #include <tensorflow/core/lib/core/status.h>\r\n      #include <tensorflow/core/platform/env.h>\r\n      #include <tensorflow/core/protobuf/config.pb.h>\r\n      #include <tensorflow/core/public/session.h>\r\n      #include <tensorflow/core/public/session_options.h>\r\n      #include <tensorflow/core/util/command_line_flags.h>\r\n      #include <opencv2/opencv.hpp>\r\n      #include \"tensorflow/cc/client/client_session.h\"\r\n      #include \"tensorflow/cc/ops/standard_ops.h\"\r\n      #include <iostream>\r\n      #include <opencv2/core/hal/intrin.hpp>\r\n      #include <cstdint>\r\n      #include <cassert>\r\n      using tensorflow::Scope;\r\n      using tensorflow::Output;\r\n      using tensorflow::Tensor;\r\n      using tensorflow::ClientSession;\r\n      using tensorflow::ops::Const;\r\n      using tensorflow::ops::MatMul;\r\n      using tensorflow::ops::Cast;\r\n      using namespace tensorflow::ops;\r\n      using namespace std;\r\n      using namespace tensorflow;\r\n      using namespace cv;\r\n      using namespace cv::dnn;\r\n      int main(int argc, char *argv[])\r\n     {\r\n\r\n\r\n    std::string PathGraph = \"frozen_inference_graph.pb\";\r\n    int input_width_ = 513; /// Width of the input placeholder\r\n    int input_height_ = 288;/// height of the input placeholder\r\n    //initial declaration Tensorflow\r\n    tensorflow::Session* session;\r\n    tensorflow::Status status;\r\n\r\n    status = tensorflow::NewSession(tensorflow::SessionOptions(), &session);\r\n    if (!status.ok()) {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return 1;\r\n    }\r\n    // Define Graph\r\n    tensorflow::GraphDef graph_def;\r\n    status = ReadBinaryProto(tensorflow::Env::Default(),PathGraph, &graph_def);\r\n\r\n    if (!status.ok()) {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return 1;\r\n    }\r\n\r\n    // Add the graph to the session\r\n    status = session->Create(graph_def);\r\n    if (!status.ok()) {\r\n        std::cout << status.ToString() << \"\\n\";\r\n        return 1;\r\n    }\r\n\r\n    auto root = tensorflow::Scope::NewRootScope();\r\n    Tensor inputImg(tensorflow::DT_UINT8, tensorflow::TensorShape({1, input_height_, input_width_, 3}));\r\n    uint8_t *image1_p_ = inputImg.flat<uint8_t>().data();\r\n    Mat cv_image1_ = cv::Mat(input_height_, input_width_, CV_8UC3, image1_p_);\r\n    Mat image = imread(\"test_img.jpg\");\r\n    cv::Mat resized_img;\r\n    while(1)\r\n    {\r\n        resize(image,resized_img,cv::Size(input_width_,input_height_));\r\n        cvtColor(resized_img,resized_img,COLOR_BGR2RGB);\r\n        resized_img.convertTo(cv_image1_, CV_8UC3);\r\n        std::vector<std::pair<std::string, tensorflow::Tensor>> inputs = {\r\n            { \"ImageTensor:0\", inputImg},\r\n        };\r\n        std::vector<tensorflow::Tensor> outputs;\r\n        status = session->Run(inputs, {\"SemanticPredictions:0\"},{}, &outputs);\r\n        if (!status.ok()) {\r\n            std::cout << status.ToString() << \"\\n\";\r\n            return 1;\r\n        }\r\n        auto int64_caster_output =  Cast(root.WithOpName(\"int64_caster\"), outputs[0], tensorflow::DT_INT32);\r\n    }\r\n}\r\n`\r\nI am stuck in the last line, i don't know how to convert **int64_caster_output** to a tensorflow::tensor . i know that this function output is an **tensorflow::opes::cast** object but haven't any insight about that.  i searched for a couple of days but i didn't find any docs about that. \r\nHope you  help me.\r\nThanks in advance.", "@ymodak sir can you help me please ? i am stuck in this step. i searched alot but there is no any document about that.", "@annarev do you know who understands the C++ API enough to answer this?", "Seems like Cast creates a Node which needs to output a Tensor. The following works for me:\r\n\r\n```cpp\r\n  auto root = tensorflow::Scope::NewRootScope();\r\n  tensorflow::ClientSession session(root);\r\n  std::vector<tensorflow::Tensor> int_outputs;\r\n  auto int64_caster_output =\r\n      Cast(root.WithOpName(\"int64_caster\"), outputs[0], tensorflow::DT_INT32);\r\n  tensorflow::Status status = session.Run({int64_caster_output}, &int_outputs);\r\n  if (!status.ok()) {\r\n    std::cerr << \"Casting failed\" << std::endl;\r\n    return 1;\r\n  }\r\n  std::cout << int_outputs[0].DebugString() << std::endl;\r\n```\r\nCan you check if this works for you?", "@annarev Thank you so so much. Yes this is the correct answer. and now i have my correct output.\r\nBut when i add and run this piece of code in my project , it takes 100 ms to run and i havn't realtime process.\r\nDo you have an other idea ?", "Probably a faster way is to add Cast to the original GraphDef. Do you have the code that generated original GraphDef you were loading? Can you add a cast there instead?\r\n\r\nYou can also create a script that reads original GraphDef, adds Cast to it and outputs it in serialized format. Then, you can load this serialized GraphDef in the code you have above. It would already output a casted tensor.\r\nUsing C API, that script could do something like:\r\n```cpp\r\n#include \"tensorflow/c/c_api.h\"\r\n#include \"tensorflow/c/c_api_experimental.h\"\r\n#include \"tensorflow/c/tf_status.h\"\r\n...\r\n\r\n// Read original graph from input_graph_file\r\nstd::ifstream input_stream(input_graph_file);\r\nstd::stringstream buffer;\r\nbuffer << input_stream.rdbuf();\r\nstd::string graph_proto = buffer.str();\r\n\r\n// Load GraphDef\r\nTF_Graph* graph = TF_NewGraph();\r\nTF_Buffer* serialized_graph_def =\r\n      TF_NewBufferFromString(graph_proto.c_str(), graph_proto.size());\r\nTF_Status* status = TF_NewStatus();\r\nTF_ImportGraphDefOptions* options = TF_NewImportGraphDefOptions();\r\nTF_GraphImportGraphDef(graph, serialized_graph_def, options, status);\r\nTF_DeleteBuffer(serialized_graph_def);\r\nCHECK(TF_GetCode(status) == TF_OK);\r\n\r\n// Add Cast\r\nTF_Operation* operation = TF_GraphOperationByName(graph, \"SemanticPredictions:0\");\r\nCHECK(operation != nullptr);\r\nTF_Output input = {operation, 0};\r\nTF_OperationDescription* op = TF_NewOperation(graph, \"Cast\", \"SemanticPredictionsInt64Cast\");\r\nTF_AddInput(op, input);\r\n// DstT comes from here: https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/ops/math_ops.cc;l=169;drc=02327c53328aa04e590b21adc55142778b1e90da\r\nTF_SetAttrType(op, \"DstT\", TF_INT64);\r\nTF_FinishOperation(op, status);\r\nCHECK(TF_GetCode(status) == TF_OK);\r\n\r\n// Output updated graph to output_graph_file\r\nTF_Buffer* output_graph_def = TF_NewBuffer();\r\nTF_GraphToGraphDef(graph, output_graph_def, status);\r\nCHECK(TF_GetCode(status) == TF_OK);\r\nstd::ofstream output;\r\noutput.open(output_graph_file);\r\nstd::string output_graph_def_str(static_cast<const char*>(output_graph_def->data), output_graph_def->length);\r\noutput << output_graph_def_str;\r\noutput.close();\r\n\r\nTF_DeleteBuffer(output_graph_def);\r\nTF_DeleteGraph(graph);\r\nTF_DeleteImportGraphDefOptions(options);\r\nTF_DeleteStatus(status);\r\n```", "One note though. Seems like you are using `Session` which doesn't seem to be a part of our public API. A better way to load a graph is using a saved model: https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/cc/saved_model/loader.h\r\n\r\nAdding @bmzhao who is working on new saved model implementation in case he has a better suggestion for your usecase.", "@annarev  Hi , Im so sorry for delay in my answer , I did not have internet access for a few days.\r\nIf I understood correctly your mean by original GraphDef is **frozen_inference_graph.pb** ? I downloaded it from tensorflow deeplab modelzoo. you can see that In this link : **http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz**.\r\nHave I to do some modifications in deeplab project source code ? I think its some hard for a noob like me :).\r\nI wanna try your second solution. hope @bmzhao help me too.\r\nThank you.  ", "Sorry for the long delay. Yep, I mean the GraphDef you are using, which seems to be frozen_inference_graph.pb. That suggestion would only work if you could modify the code that generates it.\r\nI don't have any better idea, so I am reassigning this issue to @k-w-w  works on saved model.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42588\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42588\">No</a>\n"]}, {"number": 42587, "title": "Access Denied when fetching local_config_cuda while building TF from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3.+\r\n- Python version:  3.7.4\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1/7.6.5\r\n- GPU model and memory: Nvidia GeForce 940 MX 4Gb\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen i try to build the tensorflow from the source i got from the repo, the build fails when trying to build package for TF 2.x\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nAll steps were followed as mentioned in the official documentation [here](https://www.tensorflow.org/install/source_windows#setup_for_windows)\r\nStep 0: Got all the mentioned pre-requisites and included them all in the path variables\r\nStep 1: Downloaded and checkout the master branch of tensorflow repo using git\r\nStep 2: `cd tensorflow`\r\n`python ./configure.py`\r\n\r\nThe output of the configure file is as follows: \r\n```\r\nF:\\tfrep\\tensorflow>python configure.py\r\nYou have bazel 3.1.0 installed.\r\nPlease specify the location of python. [Default is F:\\python\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  F:\\python\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [F:\\python\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.1 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\nFound cuDNN 7 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 5.0\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n```\r\n\r\nEven the cuDNN version and the path as shown in the output is not valid since i have cuDNN version 7.6.5 installed in `C:/cuda`\r\nStep 4: `bazel build //tensorflow/tools/pip_package:build_pip_package`\r\nThis is where the problem originates:\r\nOutput:-\r\n```\r\nF:\\tfrep\\tensorflow>bazel build //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=211\r\nINFO: Reading rc options for 'build' from f:\\tfrep\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=F:/python/python.exe\r\nINFO: Reading rc options for 'build' from f:\\tfrep\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from f:\\tfrep\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=F:/python/python.exe --action_env PYTHON_LIB_PATH=F:/python/lib/site-packages --python_path=F:/python/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=5.0 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file f:\\tfrep\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file f:\\tfrep\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file f:\\tfrep\\tensorflow\\.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda in file f:\\tfrep\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file f:\\tfrep\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:windows in file f:\\tfrep\\tensorflow\\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file f:\\tfrep\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository local_config_cuda instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule cuda_configure defined at:\r\n  F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl:1407:18: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_cuda':\r\n   Traceback (most recent call last):\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1377\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1221, in _create_local_cuda_repository\r\n                to_list_of_strings(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1222, in to_list_of_strings\r\n                _cuda_include_path(<2 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, in _cuda_include_path\r\n                inc_entries.append(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, in inc_entries.append\r\n                realpath(repository_ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/remote_config/common.bzl\", line 268, in realpath\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\njava.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(\"C:\\msys64\\usr\\bin\" -c \"realpath \\\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\\\"\"): Access is denied.\r\n (error: 5)\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1377\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1221, in _create_local_cuda_repository\r\n                to_list_of_strings(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1222, in to_list_of_strings\r\n                _cuda_include_path(<2 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, in _cuda_include_path\r\n                inc_entries.append(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, in inc_entries.append\r\n                realpath(repository_ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/remote_config/common.bzl\", line 268, in realpath\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\njava.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(\"C:\\msys64\\usr\\bin\" -c \"realpath \\\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\\\"\"): Access is denied.\r\n (error: 5)\r\nWARNING: Target pattern parsing failed.\r\nERROR: no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1377\r\n                _create_local_cuda_repository(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1221, in _create_local_cuda_repository\r\n                to_list_of_strings(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1222, in to_list_of_strings\r\n                _cuda_include_path(<2 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, in _cuda_include_path\r\n                inc_entries.append(<1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, in inc_entries.append\r\n                realpath(repository_ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/remote_config/common.bzl\", line 268, in realpath\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\njava.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(\"C:\\msys64\\usr\\bin\" -c \"realpath \\\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\\\"\"): Access is denied.\r\n (error: 5)\r\nINFO: Elapsed time: 1.523s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nEven if using no flag during `configure.py` for CUDA, the **Access enied** error originates again, although with a different error.\r\n\r\n```\r\nF:\\tfrep\\tensorflow>bazel build //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=211\r\nINFO: Reading rc options for 'build' from f:\\tfrep\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=F:/python/python.exe\r\nINFO: Reading rc options for 'build' from f:\\tfrep\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from f:\\tfrep\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=F:/python/python.exe --action_env PYTHON_LIB_PATH=F:/python/lib/site-packages --python_path=F:/python/python.exe --config=xla --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file f:\\tfrep\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file f:\\tfrep\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file f:\\tfrep\\tensorflow\\.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:windows in file f:\\tfrep\\tensorflow\\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file f:\\tfrep\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository flatbuffers instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule third_party_http_archive defined at:\r\n  F:/tfrep/tensorflow/third_party/repo.bzl:216:28: in <toplevel>\r\nINFO: Repository 'flatbuffers' used the following cache hits instead of downloading the corresponding file.\r\n * Hash '62f2223fb9181d1d6338451375628975775f7522185266cd5296571ac152bc45' for https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.12.0.tar.gz\r\nIf the definition of 'flatbuffers' was updated, verify that the hashes were also updated.\r\nERROR: An error occurred during the fetch of repository 'flatbuffers':\r\n   Traceback (most recent call last):\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 193\r\n                _apply_delete(ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 74, in _apply_delete\r\n                _execute_and_check_ret_code(ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 52, in _execute_and_check_ret_code\r\n                fail(<1 more arguments>)\r\nNon-zero return code(256) when executing 'C:\\msys64\\usr\\bin -l -c \"rm\" \"-rf\" \"C:/users/nikhil/appdata/roaming/spb_data/_bazel_nikhil/5i2b27md/external/flatbuffers/build_defs.bzl\"':\r\nStdout:\r\nStderr: java.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(\"C:\\msys64\\usr\\bin\" -l -c \"\\\"rm\\\" \\\"-rf\\\" \\\"C:/users/nikhil/appdata/roaming/spb_data/_bazel_nikhil/5i2b27md/external/flatbuffers/build_defs.bzl\\\"\"): Access is denied.\r\n (error: 5)\r\nERROR: F:/tfrep/tensorflow/tensorflow/tools/pip_package/BUILD:284:1: //tensorflow/tools/pip_package:build_pip_package depends on //tensorflow/lite/python:tflite_convert in repository @ which failed to fetch. no such package '@flatbuffers//': Traceback (most recent call last):\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 193\r\n                _apply_delete(ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 74, in _apply_delete\r\n                _execute_and_check_ret_code(ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 52, in _execute_and_check_ret_code\r\n                fail(<1 more arguments>)\r\nNon-zero return code(256) when executing 'C:\\msys64\\usr\\bin -l -c \"rm\" \"-rf\" \"C:/users/nikhil/appdata/roaming/spb_data/_bazel_nikhil/5i2b27md/external/flatbuffers/build_defs.bzl\"':\r\nStdout:\r\nStderr: java.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(\"C:\\msys64\\usr\\bin\" -l -c \"\\\"rm\\\" \\\"-rf\\\" \\\"C:/users/nikhil/appdata/roaming/spb_data/_bazel_nikhil/5i2b27md/external/flatbuffers/build_defs.bzl\\\"\"): Access is denied.\r\n (error: 5)\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@flatbuffers//': Traceback (most recent call last):\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 193\r\n                _apply_delete(ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 74, in _apply_delete\r\n                _execute_and_check_ret_code(ctx, <1 more arguments>)\r\n        File \"F:/tfrep/tensorflow/third_party/repo.bzl\", line 52, in _execute_and_check_ret_code\r\n                fail(<1 more arguments>)\r\nNon-zero return code(256) when executing 'C:\\msys64\\usr\\bin -l -c \"rm\" \"-rf\" \"C:/users/nikhil/appdata/roaming/spb_data/_bazel_nikhil/5i2b27md/external/flatbuffers/build_defs.bzl\"':\r\nStdout:\r\nStderr: java.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(\"C:\\msys64\\usr\\bin\" -l -c \"\\\"rm\\\" \\\"-rf\\\" \\\"C:/users/nikhil/appdata/roaming/spb_data/_bazel_nikhil/5i2b27md/external/flatbuffers/build_defs.bzl\\\"\"): Access is denied.\r\n (error: 5)\r\nINFO: Elapsed time: 2.584s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (49 packages loaded, 14 targets configured)\r\n    currently loading: tensorflow/lite/python\r\n```\r\n\r\nI have been working on TFDS for quite some time now and would like to work on TF as well. Therefore, I need to build the source ASAP. Thanks in advance!", "comments": ["@MeghnaNatraj @liufengdb Could you look into it? It would mean a lot", "After looking into the issure even more, I noticed that the BAZEL_VC path variable was set wrongly .\r\nAfter setting it properly, the following error comes up:\r\n```\r\nF:/python/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /showIncludes /MD /O2 /DNDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /std:c++14 /DHAVE_PTHREAD /wd4018 /wd4065 /wd4146 /wd4244 /wd4251 /wd4267 /wd4305 /wd4307 /wd4309 /wd4334 /wd4355 /wd4506 /wd4514 /wd4800 /wd4996 /Fobazel-out/x64_windows-opt/bin/external/com_google_protobuf/_objs/protoc_lib/command_line_interface.obj /c external/com_google_protobuf/src/google/protobuf/compiler/command_line_interface.cc\r\nExecution platform: @local_execution_config_platform//:platform\r\nexternal/com_google_protobuf/src\\google/protobuf/compiler/subprocess.h(38): fatal error C1083: Cannot open include file: 'windows.h': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 9.838s, Critical Path: 1.62s\r\nINFO: 12 processes: 12 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@NikhilBartwal \r\nCan you please refer to these links and let us know:\r\n[link](https://github.com/openssl/openssl/issues/586) [link1](https://stackoverflow.com/questions/80788/fatal-error-c1083-cannot-open-include-file-windows-h-no-such-file-or-direc)", "Hey @Saduf2019, Thanks for the reply. After correcting the MSVC path variable and re-installing the Windows SDK, I was able to run the build, which took exceptionally long time (~6-7 hours on i7 7th gen 8GB laptop). In the end the bazel build got stuck at\r\n`[12638/12791] Linking tensorflow/python/_pywrap_tensorflow_internal.so 50000s`\r\nThe seconds go on increasing but nothing happens. ", "@Saduf2019 One more thing that I wanted to ask was that how much time does the build supposed to take on a single cpu? and Am i supposed to build it every time new commits are done to the repo?", "@Saduf2019 After i shut it down and re build it using the bazel command as mentioned in the instructions [here](bazel build //tensorflow/tools/pip_package:build_pip_package), it now got stuck at\r\n\r\n```\r\nC:\\Users\\nikhil\\tensorflow>bazel build //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from c:\\users\\nikhil\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=F:/python/python.exe\r\nINFO: Reading rc options for 'build' from c:\\users\\nikhil\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from c:\\users\\nikhil\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=F:/python/python.exe --action_env PYTHON_LIB_PATH=F:/python/lib/site-packages --python_path=F:/python/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=5.0 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:windows in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\users\\nikhil\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\n[2 / 203] checking cached actions\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42587\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42587\">No</a>\n"]}, {"number": 42586, "title": "Resource exhausted: OOM while using shuffle()", "body": "Hi, \r\nI am using a dataset of ~14k images for training a Conditional GAN. \r\nI understand that the buffer_size in shuffle takes the images equal to buffer_size into the memory and then randomly choose the images from those. \r\nWhile shuffling, the resources are exhausted which means that not all the images were able to be fitted in the memory. \r\nBut my issue is that it works fine for the initial 10-12 epochs. It shuffles the entire dataset with the same settings but after 10-12 epochs, it runs into the OOM error. So, why is it that it works fine for the initial epochs and then runs into the error?\r\nIs any of the data pilling up in the memory while using shuffle or is there any memory leakage problem? This happens during the shuffling stage.", "comments": ["@tejasmorkar,\r\nIn order to expedite the trouble-shooting process, could you please provide the TensorFlow version, the complete code to reproduce the issue and the dataset you are using. \r\n\r\nAlso if you're using a GPU, try limiting GPU memory growth as per [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps. \r\n\r\nThanks!", "@amahendrakar,\r\n\r\nI am using the tensorflow==2.3.0 version. This also happened on the tensorflow==2.2.0\r\n\r\nThe entire code to reproduce it is available at https://github.com/tejasmorkar/sketch-to-color and the dataset I used is https://www.kaggle.com/ktaebum/anime-sketch-colorization-pair. \r\n\r\nYou will have to download the code, change the path to the dataset's path on line 12 to reproduce the error. \r\n\r\nI am using a GTX 1060 6GB graphics card and a 16GB RAM.\r\n\r\n> Also if you're using a GPU, try limiting GPU memory growth as per [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps.\r\n\r\nI'll try limiting the GPU memory growth and let you know if the problem still exists.\r\n", "Yes I get the same warning but also after a few epochs it results in OOM\nwhile shuffling.\n\nOn Mon, Aug 31, 2020 at 7:37 PM Abhilash Mahendrakar <\nnotifications@github.com> wrote:\n\n> @tejasmorkar <https://github.com/tejasmorkar>,\n> On running the code the info log I got was I\n> tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle\n> buffer (this may take a while). Please find the gist of it here\n> <https://colab.research.google.com/gist/amahendrakar/647d4e9c9d8299608705223ca0e2329b/42586.ipynb>\n> .\n>\n> Could you please confirm if this is the same issue you are facing? Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/42586#issuecomment-683801005>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIOVOTTLIIW7M6TDEHPW2WLSDOVANANCNFSM4QIGUZAA>\n> .\n>\n\n\n-- \nRegards,\n\nTejas Morkar\n<https://tejasmorkar.github.io>   <https://github.com/tejasmorkar>\n<https://twitter.com/TejasMorkar>\n<https://www.linkedin.com/in/tejasmorkar/>\n", "> Also if you're using a GPU, try limiting GPU memory growth as per [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps.\r\n\r\n@tejasmorkar,\r\nThank you for the update. Did you try limiting GPU memory as mentioned in the above comment? Thanks!", "I tried that but it won't even complete one epoch. It directly gives OOM\nerror.\n\nOn Tue, Sep 1, 2020 at 7:14 PM Abhilash Mahendrakar <\nnotifications@github.com> wrote:\n\n> Also if you're using a GPU, try limiting GPU memory growth as per this\n> guide <https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth>\n> and let us know if it helps.\n>\n> @tejasmorkar <https://github.com/tejasmorkar>,\n> Thank you for the update. Did you try limiting GPU memory as mentioned in\n> the above comment? Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/42586#issuecomment-684863852>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIOVOTSVFNGQNMECFK4ELRTSDT3CZANCNFSM4QIGUZAA>\n> .\n>\n\n\n-- \nRegards,\n\nTejas Morkar\n<https://tejasmorkar.github.io>   <https://github.com/tejasmorkar>\n<https://twitter.com/TejasMorkar>\n<https://www.linkedin.com/in/tejasmorkar/>\n", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/647d4e9c9d8299608705223ca0e2329b/42586.ipynb). Thanks!", "Hello, is there any progress on this issue?\r\n", "Is there any update regarding this issue? @aaudiber ", "This may be due to heap fragmentation. tcmalloc does a much better job of avoiding fragmentation. There are some instructions here for how to switch to tcmalloc: https://riptutorial.com/tensorflow/example/13427/use-the-tcmalloc-allocator", "@aaudiber Have you ever heard of tcmalloc only working occasionally? I've installed it and I'm loading it as described, but it only seems to work rarely. Is there a way to check if the library has been loaded correctly?\r\n\r\nEdit:\r\nEverything was actually working correctly with tcmalloc. My issue was that I actually had _two_ memory leaks... This one and one because of the Keras ReLU layer implementation ([#46661](https://github.com/tensorflow/tensorflow/issues/46661#issuecomment-770780004) and #46475).", "@michaelschufi Haven't heard of that before, and I'm not sure how to verify the install. You may be able to get more information from stack overflow or https://github.com/google/tcmalloc", "@tejasmorkar,\r\n\r\nCan you confirm if the above [comment](https://github.com/tensorflow/tensorflow/issues/42586#issuecomment-803608994) from @aaudiber answers your question and resolves the issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42586\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42586\">No</a>\n", "> @tejasmorkar,\r\n> \r\n> Can you confirm if the above [comment](https://github.com/tensorflow/tensorflow/issues/42586#issuecomment-803608994) from @aaudiber answers your question and resolves the issue? Thanks!\r\n\r\nYes, it did. Thank you!"]}, {"number": 42585, "title": "Executing genrule //tensorflow/python:pywrap_tensorflow_filtered_def_file failed (Exit 1): bash.exe failed", "body": "\r\n### System information\r\n\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  windows 10 education\r\n-   **TensorFlow installed from (source or binary)**:  source\r\n-   **TensorFlow version (use command below)**:  r1.14\r\n-   **Python version**:  3.7.4\r\n-   **Bazel version (if compiling from source)**:  0.25.2\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:  10.0/7.4\r\n-   **GPU model and memory**:  NVIDIA GeForce RTX2070 with Max-Q Design 16GB\r\n-   **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nBuild tensorflow 1.14 from source with bazel0.25.2 + vs2017(15.9.26) + python3.7.4 + cuda10.0 + cudnn7.4.2.24 + msys2, failed by ERROR: D:/newtf114/tensorflow/tensorflow/python/BUILD:4684:1: Executing genrule //tensorflow/python:pywrap_tensorflow_filtered_def_file failed (Exit 1): bash.exe failed: error executing command....\r\n\r\n### Source code / logs\r\n\r\nERROR: D:/newtf114/tensorflow/tensorflow/python/BUILD:4684:1: Executing genrule //tensorflow/python:pywrap_tensorflow_filtered_def_file failed (Exit 1): bash.exe failed: error executing command\r\n  cd D:/bazel_out/73kxojlr/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=D:/Program Files/nvidia gpu computing toolkit/cuda/v10.0\r\n    SET PATH=D:\\ProgramData\\msys64\\usr\\bin;D:\\ProgramData\\msys64\\bin;D:\\ProgramData\\Anaconda3;D:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;D:\\ProgramData\\Anaconda3\\Library\\usr\\bin;D:\\ProgramData\\Anaconda3\\Library\\bin;D:\\ProgramData\\Anaconda3\\Scripts;D:\\ProgramData\\Anaconda3\\bin;D:\\ProgramData\\Anaconda3\\condabin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x86;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft SDKs\\TypeScript\\3.1;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x86;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.0\\bin;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.0\\libnvvp;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.1\\bin;D:\\Program Files\\nvidia gpu computing toolkit\\cuda\\v10.1\\libnvvp;d:\\ProgramData\\Anaconda3;d:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;d:\\ProgramData\\Anaconda3\\Library\\usr\\bin;d:\\ProgramData\\Anaconda3\\Library\\bin;d:\\ProgramData\\Anaconda3\\Scripts;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Users\\bolix\\.dnx\\bin;C:\\Program Files\\Microsoft DNX\\Dnvm;C:\\Program Files\\Microsoft SQL Server\\120\\Tools\\Binn;C:\\Program Files\\CMake\\bin;D:\\Program Files\\MATLAB\\R2018b\\runtime\\win64;D:\\Program Files\\MATLAB\\R2018b\\bin;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\dotnet;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn;D:\\Program Files\\Git\\cmd;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;D:\\ProgramData\\msys64\\usr\\bin;D:\\ProgramData\\msys64\\usr\\bin\\bash.exe;D:\\ProgramData\\msys64;C:\\Users\\bolix\\AppData\\Local\\Microsoft\\WindowsApps;D:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.4\\bin;D:\\texlive\\2019\\bin\\win32;C:\\Users\\bolix\\.dotnet\\tools;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;d:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PYTHON_BIN_PATH=D:/ProgramData/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=D:/ProgramData/Anaconda3/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TF_NEED_TENSORRT=0\r\n  D:/ProgramData/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh;\r\n              bazel-out/x64_windows-opt/bin/external/local_config_def_file_filter/def_file_filter.exe \\\r\n              --input bazel-out/x64_windows-opt/bin/tensorflow/tf_custom_op_library_additional_deps.dll.gen.def \\\r\n              --output bazel-out/x64_windows-opt/bin/tensorflow/python/pywrap_tensorflow_filtered_def_file.def \\\r\n              --target _pywrap_tensorflow_internal.pyd\r\n\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\d:\\AppData\\Local\\Tmp\\Bazel.runfiles_2zky2bii\\runfiles\\local_config_def_file_filter\\def_file_filter.py\", line 172, in <module>\r\n    sys.exit(main())\r\n  File \"\\\\?\\d:\\AppData\\Local\\Tmp\\Bazel.runfiles_2zky2bii\\runfiles\\local_config_def_file_filter\\def_file_filter.py\", line 132, in main\r\n    proc = subprocess.Popen([UNDNAME, tmpfile.name], stdout=subprocess.PIPE)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\subprocess.py\", line 775, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\subprocess.py\", line 1178, in _execute_child\r\n    startupinfo)\r\nFileNotFoundError: [WinError 2] \u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6587\u4ef6(this Chinese sentence means:system cannot find the file)\u3002\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 4041.976s, Critical Path: 918.02s\r\nINFO: 4328 processes: 4328 local.\r\n", "comments": ["@faerysword \r\nIs there any particular reason for using tf 1.14, there is support for 1.15 and 2.x.\r\nPlease user later versions and let us know if you face any errors.\r\n\r\nMeanwhile you can refer to:\r\n#28223 #37938 [link](https://github.com/tensorflow/tensorflow/issues/24471#issuecomment-456812282) [link1](https://github.com/tensorflow/tensorflow/issues/29831#issuecomment-504501367)", "> @faerysword\r\n> Is there any particular reason for using tf 1.14, there is support for 1.15 and 2.x.\r\n> Please user later versions and let us know if you face any errors.\r\n> \r\n> Meanwhile you can refer to:\r\n> #28223 #37938 [link](https://github.com/tensorflow/tensorflow/issues/24471#issuecomment-456812282) [link1](https://github.com/tensorflow/tensorflow/issues/29831#issuecomment-504501367)\r\n\r\nI have spent a lot of time in building tf 1.15 , but failed. So I try this stable one tf 1.14. After some problems solved and several hours building , finally stuck here and I don't know why. Is there any help?", "I modified subprocess.py. It works , though it's not a good way . Maybe you guys can change the paramaters send to this function , instead of using the default ones.\r\nChanged from:\r\nclass Popen(object) \r\n...\r\n    def __init__(self, args, bufsize=-1, executable=None,\r\n                 stdin=None, stdout=None, stderr=None,\r\n                 preexec_fn=None, close_fds=True,\r\n                 **shell=False**, cwd=None, env=None, universal_newlines=None,\r\n                 startupinfo=None, creationflags=0,\r\n                 restore_signals=True, start_new_session=False,\r\n                 pass_fds=(), *, encoding=None, errors=None, text=None):\r\nInto:\r\n    def __init__(self, args, bufsize=-1, executable=None,\r\n                 stdin=None, stdout=None, stderr=None,\r\n                 preexec_fn=None, close_fds=True,\r\n                 **shell=True**, cwd=None, env=None, universal_newlines=None,\r\n                 startupinfo=None, creationflags=0,\r\n                 restore_signals=True, start_new_session=False,\r\n                 pass_fds=(), *, encoding=None, errors=None, text=None):", "@faerysword \r\nIs the issue resolved now or are you facing any issues.", "@Saduf2019 I facing some new issues, I opened another issue, I close this one, thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42585\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42585\">No</a>\n"]}, {"number": 42584, "title": "Logging Memory Usage For each TensorFlow Operation", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: N/A\r\n-   **TensorFlow installed from (source or binary)**: Source\r\n-   **TensorFlow version (use command below)**: r1.14\r\n-   **Python version**: 2.7\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**: 5.4\r\n-   **CUDA/cuDNN version**: 10.1/7.1\r\n-   **GPU model and memory**: NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)\r\n-   **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nI am running a Tramsformer Model in which If I add some control dependencies (which are not required for its design, but performance can be improved if I can add those dependencies), I get OOM error. I wanted to log the memory Usage for each TF operation (including CUDA context memory and Memory Allocator Reservations in addition to the raw bytes needed to input and output tensors.)\r\n\r\nI looked at profiling using Timeline as suggested in this [StackOverFlow post](https://stackoverflow.com/questions/36123740/is-there-a-way-of-determining-how-much-gpu-memory-is-in-use-by-tensorflow), but this is just logging raw bytes needed by the tensors, not the additional memory reserved or is marked free but is not garbage collected yet.\r\n\r\nIn addition, I also came across [tf.Profiler](https://github.com/tensorflow/tensorflow/tree/r1.14/tensorflow/core/profiler), but it has this [comment](https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/core/profiler/tfprof_log.proto#L128) saying that numbers are not reliable, which otherwise might have sufficed the requirement. Is there a better way to log all the memory used by each TF operation?\r\n\r\n", "comments": ["@xilenteyex  Please provide the complete standalone code and error log as well to replicate the issue at our end.\r\n\r\nAlso,could you please update the Tensorflow version to 2.3 since TF 1.14 is not supported actively. Thanks!", "@saikumarchalla thanks for looking into this issue. I am working on creating a standalone example for you to reproduce the issue. Will share ASAP. \r\n\r\nActually, I am more interested in knowing if there is a way to log per op memory utilization in a GPU (including workspace memory, CUDA context and Allocator Reservations [in addition to memory required by live tensors]). Is this feature available in TensorFlow or will be made available in near future ? Using Timeline or TF-Profiler, I can only get the memory requirements for Tensors, not the additional overheads. If you can point me to logger which will be helpful in this regard, that would be great and maybe sufficient to resolve this GitHub issue.\r\n\r\nAlso, as far as the version of TF is concerned, it's a research project which I am working for a long time now and we are comfortable with TF 1.14. It will be hard to upgrade. to TF 2.3 promptly, but we will be moving to TF 2.3 later, but it will be hard to switch quickly. Hope you understand. ", "I do not work on TensorFlow any more.", "@xilenteyex,\r\nI'm not sure if [this comment](https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/core/profiler/tfprof_log.proto#L128) exactly means that the Statistics shown in the `Tensorboard Profiler` is unreliable. But the Fact is that we can understand which **`Tensorflow Op`** is consuming more `Memory` (compared to other OPs) and it will provide Recommendations to reduce the bottlenecks. \r\n\r\nPlease refer [Profiler Guide](https://www.tensorflow.org/guide/profiler) and the [Example Tutorial](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras). Thanks!", "@xilenteyex,\r\nCan you please respond to the above comment. Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 42583, "title": "Fix typo in mnist/input_data.py", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42583) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I agreed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42583) for more info**.\n\n<!-- ok -->"]}, {"number": 42582, "title": "SPLIT_V in TFLM", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): Source\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): CEVA\r\n\r\n**Describe the problem**\r\nThis issue is related to PR #42452 (https://github.com/tensorflow/tensorflow/pull/42452)\r\n\r\nCurrently no SPLIT_V op implementation in micro.\r\nWhen using GRU layers in Keras, SPLIT_V op is used in the model converted to TFLite.\r\nSee this issue: https://github.com/tensorflow/tensorflow/issues/41690 the code samples there demonstrate this.\r\n\r\n\r\n@advaitjain - Adding some details as requested.\r\nCould you file a github issue with more context on why you need this new reference kernel?\r\nThe more detail the better, for example:\r\n\r\n- **what your application is**\r\nOur application is an end-t-end speech recognition engine focused on wake word detection and speech commands. It is targeted for low power, resource constrained platforms such as CEVA Cores.\r\n\r\n**- what model architecture looks like**\r\nThe models is RNN based, more specifically GRU.\r\n\r\n**any performance criteria that you have**\r\nOur performance criteria are common to the speech recognition world, namely: False Reject Rate, False Accepts Per Hour for Wake Word detection and Confusion Matrix for Speech Commands.\r\n\r\n**what embedded targets are you planning to run your models on?**\r\nOur models are targeted at CEVA Cores.\r\n\r\n**what your plans are for optimized implementations for the specific platforms that you care about?**\r\nWe are planning for extensive optimization of TFLM operators.\r\n\r\n", "comments": []}, {"number": 42581, "title": "TensorScatterUpdate unsupported dtype complex64/128, tf2.3.0, GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 10.1/10.2\r\n- GPU model and memory: TITAN V, RTX2080TI\r\n\r\n**Describe the current behavior**\r\n\r\nThe `tf.tensor_scatter_nd_update` function raises:\r\n\r\n`InvalidArgumentError: Unsupported dtype: complex64 [Op:TensorScatterUpdate]`\r\n`InvalidArgumentError: Unsupported dtype: complex128 [Op:TensorScatterUpdate]`\r\n\r\nwhen running tf2.3.0 on GPU, in eager mode, and using dtypes `complex64` and `complex128`.\r\n\r\nYou can reproduce this error by executing the following code on GPU with tf2.3.0: \r\n\r\n```python\r\nimport tensorflow as tf\r\nvar = tf.Variable(tf.zeros(10, dtype=tf.complex64))\r\nup = tf.constant([1], dtype=tf.complex64) \r\ntf.tensor_scatter_nd_update(var, [[0]], up)\r\n```\r\nNote that the code works as expected if we compile the call with `tf.function`, and it also works fine on CPU.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe `tensor_scatter_nd_update` in tf2.3 should work on GPU if the dtype is complex64 or complex128, as in tf2.2 and tf2.1.", "comments": ["@scarrazza \r\nI am able to replicate the issue on 2.3, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/8f40760297dda1e9a10e76e53359b403/untitled384.ipynb).\r\nThis code is working as expected on tf-nightly GPU, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/f40630d9d03c97966018d4c3fa680057/untitled384.ipynb).", "Thanks for the confirmation. Do you have an ETA for the next release based on this tf-nightly?", "@scarrazza \r\n ETA depends on lot of factors. But the last release candidate is 2.3rc2. So I guess there will in 2.4 in near future.", "Thanks, anyway I would suggest to include a specific test for this function to avoid similar issues in future releases.", "@scarrazza\r\nSurely, Can we move this issue to closed status as its resolved.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42581\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42581\">No</a>\n"]}, {"number": 42580, "title": "Add missing packages to complete GPU installation page", "body": "Hi, \r\n\r\nWhile following instructions on that page https://www.tensorflow.org/install/gpu, I needed to install 4 more packages to correctly install CUDA. It permits to avoid the `Depends: cuda-10-1 (>= 10.1.243) but it is not going to be installed` issue.\r\n\r\n```\r\nUbuntu 18.04 (CUDA 10.1)\r\n# Add NVIDIA package repositories\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo dpkg -i cuda-repo-ubuntu1804_10.1.243-1_amd64.deb\r\nsudo apt-get update\r\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt-get update\r\n\r\n# Install NVIDIA driver\r\nsudo apt-get install --no-install-recommends nvidia-driver-450\r\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\r\n\r\n**# ADDED LINE : \r\nsudo apt-get install freeglut3 freeglut3-dev libxi-dev libxmu-dev**\r\n\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.5.32-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.5.32-1+cuda10.1\r\n\r\n\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\nsudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```\r\nThat solution is suggested by NVIDIA [here](https://forums.developer.nvidia.com/t/cuda-install-unmet-dependencies-cuda-depends-cuda-10-0-10-0-130-but-it-is-not-going-to-be-installed/66488/9). Maybe updating the doc could save few hours to data scientists.", "comments": ["The page has been updated for Cuda11. Closing this issue."]}, {"number": 42579, "title": "Fix TensorFlow Lite conversion of StridedSlice with ellipsis and masks.", "body": "Fixes #42481. For more context, see #42481.\r\n\r\nTensorFlow's `StridedSlice` operator allows for both ellipses, which indicate that prior dimensions of a slice should not be changed, and masks, which indicate that a slice should go to the end of a given dimension. However, TensorFlow Lite removes the ellipses during the conversion process.\r\n\r\nWhen using both ellipses and masks, like so:\r\n\r\n```python\r\nmy_tensor[..., :1, 2:]\r\n```\r\n\r\n...the TensorFlow Lite converter removes the ellipsis, but currently only copies the begin and end masks up to the `n + 1`-th dimension, where `n` is equal to the highest filled bit in the `ellipsis_mask`. Dimensions after the ellipsis mask have their values copied from `n` through the end of the shape, creating an incorrect mask that does not correspond with the output shape of the op, and fails at runtime.\r\n\r\nThis appears to be due to the fact that in `prepare_tf.cc`, `RewriteEllipsisMask` uses two indices - `index`, representing the index in the original shape, and `new_index`, representing the index in the new shape. In the \"After the ellipsis\" loop, the `new_index` is referenced but never incremented.\r\n\r\nThis PR fixes the issue. I have confirmed that the test code in #42481 now passes, but did not find any test code in TensorFlow itself that already references this function, so have not modified or added any unit tests yet.", "comments": ["Thanks @renjie-liu! It looks like the failing Ubuntu/Windows/Mac tests were in totally unrelated files - I've rebased off of `master` and force pushed, which looks like it'll require re-approval."]}, {"number": 42578, "title": "TF2.3 can't use GPU with CUDA11.0(windows)", "body": "Do I have to reduce the CUDA version?", "comments": ["Yes Tensorflow needs the specific CUDA version it was compiled for. CUDA 10.2 or so it is. ", "The following NVIDIA software must be installed on your system:\r\n\r\nNVIDIA GPU drivers, 418.x or higher\r\nCUDA 10.1\r\ncuDNN SDK 7.6", "@davidfegyver When will it be updated to support cuda11.0\uff1fpytorch 1.6 is compatible now, reinstall is a troublesome thing.", "You can install cuda 10.1 next to cuda 11.0, in a different directory.\r\nThen if you need CUDA you can load the correct version to your PATH and other environment variables", "@Stealers,\r\nAs per the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu), please check if you are facing the same issue with CUDA 10.1 and cuDNN 7.4.\r\n\r\nAlso, please take a look at [#42047](https://github.com/tensorflow/tensorflow/issues/42047) for more information regarding TensorFlow support for CUDA 11. Thanks!", "@amahendrakar Thanks! using tf_nightly successfully load cuda, but can't use!\r\n```\r\nUnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\r\n```", "@Stealers,\r\nCould you please provide the complete code and the dataset you are using in order to reproduce the error. Thanks!", "@amahendrakar it's very strange!  i was tested in jupyter lab using following code.\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\n\r\nc = Conv2D(12,3,1,padding='same',name='/Conv')\r\nc(tf.ones((1,64,64,3)))\r\n```\r\n**some jupyter notebook successfully run, but some failed.**\r\n\r\n**fail:**  \r\n```\r\nUnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node model/Head/Conv/Conv2D (defined at <ipython-input-4-71857f6da7f0>:3) ]] [Op:__inference_predict_function_668]\r\n```\r\n**success**  \r\n```\r\n<tf.Tensor: shape=(1, 64, 64, 12), dtype=float32, numpy=\r\narray([[[[ 0.1533156 ,  0.03336769,  0.13701904, ..., -0.53224814,\r\n           0.24510589, -0.28095055],\r\n         [ 0.5889714 ,  0.38427442,  0.16817504, ..., -0.43800074,\r\n           0.25934196,  0.24368674],\r\n         [ 0.5889714 ,  0.38427442,  0.16817504, ..., -0.43800074,\r\n           0.25934196,  0.24368674],\r\n         ...,\r\n```", "@amahendrakar The same  jupyter notebook sometimes can run successfully. sometimes it can't, and it uses a lot of memory(both GPU's and common's) when it  failed to run.  \r\n  \r\nupdate\uff1a  \r\n**I found the key. It can\u2018t be used in multiple notebooks. we can only use tensorflow in one notebook at a time. when the first notebook is created, and uses tensorflow successfully. The next notebook created can't use tensorflow.**\r\nIs this a bug\uff1f", "> **I found the key. It can\u2018t be used in multiple notebooks. we can only use tensorflow in one notebook at a time. when the first notebook is created, and uses tensorflow successfully. The next notebook created can't use tensorflow.**\r\n> Is this a bug\uff1f\r\n\r\n@Stealers,\r\nCould you please check if you are facing the same issue in a virtual environment as well? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "I follow this article and solve the problem:\r\nhttps://medium.com/analytics-vidhya/install-tensorflow-gpu-2-4-0-with-cuda-11-0-and-cudnn-8-using-anaconda-8c6472c9653f\r\n"]}, {"number": 42577, "title": "[IOS TfLite] Missing Operations for TfLite GPU Delegate", "body": "**System information**\r\nIn Podfile: TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['Metal']\r\nTensorflow Lite version: 2.3.0\r\nSwift 5\r\nXcode ver 11.6\r\n\r\n**Model information**\r\nThe model file is YOLOv4-tiny, training with darknet framework, the config file similar to: \r\nhttps://github.com/AlexeyAB/darknet/blob/master/cfg/yolov4-tiny-custom.cfg\r\n\r\nConvert to model tflite using this following open project sourecode:\r\nhttps://github.com/hunglc007/tensorflow-yolov4-tflite\r\n\r\n**\r\nI'm trying to use the GPU delegate for my custom tflite model, create the interpreter with GPU delegate using this code:\r\n\r\n```\r\nvar metalOptions = MetalDelegate.Options()\r\nmetalOptions.waitType = .passive\r\nlet delegate = MetalDelegate(options: metalOptions)\r\nvar options = Interpreter.Options()\r\noptions.threadCount = threadCount\r\ninterpreter = try Interpreter(modelPath: modelPath, options: options,delegates: [delegate])\r\n```\r\n*****\r\nAfter running, got this error:\r\n\r\n```\r\nTensorFlow Lite Error: Following operations are not supported by GPU delegate:\r\nDEQUANTIZE: \r\nSPLIT: Operation is not supported.\r\nSPLIT_V: Operation is not supported.\r\n106 operations will run on the GPU, and the remaining 100 operations will run on the CPU\r\n```\r\nHow can I fix this error?\r\nThanks.\r\n", "comments": ["This actually is warning not error. It's to tell you the some ops are not delegated.", "@terminate25 \r\nCould you please provide with complete indented stand alone code for us to replicate the issue faced, or if possible share a colab gist with the issue reported:\r\n\r\nMeanwhile you may refer to below issues and let us know f they help:\r\n#40157  #34679 #39746", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42577\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42577\">No</a>\n"]}, {"number": 42576, "title": "1st Time Model taking too long to start", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow==2.2\r\n- TensorFlow version (use command below):2.2\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 10.1, cudnn 7.6.5\r\n- GPU model and memory: NVIDIA MX110 2gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n2. `v2.2.0-rc4-8-g2b96f3662b 2.2.0`\r\n\r\n\r\n**Describe the current behavior**\r\nI Installed TF 2 and make a Sequential Model, That jupyter cell is taking forever to load. \r\n\r\n**Describe the expected behavior**\r\nIt should load that cell fastly\r\n**Standalone code to reproduce the issue**\r\n```python3\r\nfrom sklearn.datasets import load_iris\r\niris = load_iris()\r\nX = iris.data\r\ny = iris.target\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.utils import to_categorical\r\nfrom tensorflow.keras.layers import Dense\r\ny = to_categorical(y)\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nX_train, X_test, y_train, y_test = train_test_split(X,y)\r\nmodel1 = Sequential([\r\n    Dense(512, activation='tanh', input_shape = X_train[0].shape),\r\n    Dense(512//2, activation='tanh'),\r\n    Dense(512//4, activation='tanh'),\r\n    Dense(512//8, activation='tanh'),\r\n    Dense(32, activation='relu'),\r\n    Dense(3, activation='softmax')\r\n])\r\n```\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nWhat I can see on my COmmand Line is \r\n```terminal\r\n[I 16:37:13.657 NotebookApp] Starting buffering for 427db0cf-ee0b-49fa-b075-ce24cdc456bb:6564a2664692489a8473d40138e004c7\r\n2020-08-22 16:38:17.412089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-08-22 16:38:17.465067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.465381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce MX110 computeCapability: 5.0\r\ncoreClock: 1.006GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\r\n2020-08-22 16:38:17.465580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-22 16:38:17.467132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-22 16:38:17.468592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-22 16:38:17.468928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-22 16:38:17.470530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-22 16:38:17.471467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-22 16:38:17.474846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-22 16:38:17.475036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.475556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.475947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-22 16:38:17.476205: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-08-22 16:38:17.482259: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1800000000 Hz\r\n2020-08-22 16:38:17.482562: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa670000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-22 16:38:17.482589: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-22 16:38:17.510525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.510905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b17c39ce70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-22 16:38:17.510933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce MX110, Compute Capability 5.0\r\n2020-08-22 16:38:17.511104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.511357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce MX110 computeCapability: 5.0\r\ncoreClock: 1.006GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\r\n2020-08-22 16:38:17.511403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-22 16:38:17.511423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-22 16:38:17.511441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-22 16:38:17.511458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-22 16:38:17.511475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-22 16:38:17.511493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-22 16:38:17.511512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-22 16:38:17.511562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.511828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.512056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-22 16:38:17.512092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-22 16:38:17.513132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-22 16:38:17.513144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-08-22 16:38:17.513150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-08-22 16:38:17.513236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.513508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:38:17.513756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1461 MB memory) -> physical GPU (device: 0, name: GeForce MX110, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n[I 16:39:14.659 NotebookApp] Saving file at /Desktop/Ahmad/REgular/iristest.ipynb\r\n\r\n```\r\nIt is more than 10 mins, while I am waiting for that jupyter cell to load.\r\n", "comments": ["Output for \r\n```python3\r\npython3 -c \"import tensorflow as tf; print(tf.test.is_gpu_available())\"\r\n```\r\nis \r\n```python3\r\nWARNING:tensorflow:From <string>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2020-08-22 16:49:00.218791: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-08-22 16:49:00.243455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1800000000 Hz\r\n2020-08-22 16:49:00.243773: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f48bc000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-22 16:49:00.243798: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-22 16:49:00.245631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-08-22 16:49:00.272044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:49:00.272327: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56105b3aa1e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-22 16:49:00.272346: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce MX110, Compute Capability 5.0\r\n2020-08-22 16:49:00.272476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:49:00.272656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce MX110 computeCapability: 5.0\r\ncoreClock: 1.006GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\r\n2020-08-22 16:49:00.272812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-22 16:49:00.274015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-22 16:49:00.275222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-22 16:49:00.275443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-22 16:49:00.276756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-22 16:49:00.277520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-22 16:49:00.280247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-22 16:49:00.280378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:49:00.280622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:49:00.280782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-22 16:49:00.280816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-22 16:49:00.281477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-22 16:49:00.281489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-08-22 16:49:00.281494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-08-22 16:49:00.281574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:49:00.281770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-22 16:49:00.281952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:0 with 61 MB memory) -> physical GPU (device: 0, name: GeForce MX110, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nTrue\r\n```", "Hi @ahmadmustafaanis, can you provide a little more detail on the issue you're facing? Is it just this particular cell that is taking a long time to run? Is it consistently reproducible? Are you able to train the model without error? I ran the code you provided in a [colab notebook ](https://colab.research.google.com/drive/1TJYVT0mq25AUnGzjitGBCP3INgegEadd?usp=sharing)and didn't face any issues. The cell executed quickly. I also tried running the cell on a VM with 2 GPUs and didn't face any issues. \r\nAlso note that you are loading the data from sklearn and not Tensorflow, so the issue you're facing might be related to sklearn. If you comment out the model definition, does the cell still take a long time to execute?\r\n\r\n", "Hi, @nikitamaia, yes only the particular cell takes a long time. This issue happens every time I run a new instance of a notebook.\r\n\r\nAfter 5 or 6 mins, I am then able to train the models without any error. This long also takes when I run this cell,\r\n\r\n```python3\r\nmodel = Sequential([\r\nDense(10, input_shape=(19,)),\r\nDense(1)\r\n])\r\n```\r\n\r\nWhen I jumped back to Tensorflow 2.0.0, It was working fine there. But when I am working with 2.3.0, or 2.2.0, it was taking a long time. \r\n\r\nFor this comment, I reinstalled 2.3.0, now I am getting this error message\r\n```error\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-6-b597df38e227> in <module>\r\n      1 model = tf.keras.models.Sequential([\r\n      2     tf.keras.layers.Dense(10, input_shape=(10,)),\r\n----> 3     tf.keras.layers.Dense(1)\r\n      4 ])\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    115     # Skip the init in FunctionalModel since model doesn't have input/output yet\r\n    116     super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call\r\n--> 117         name=name, autocast=False)\r\n    118     self.supports_masking = True\r\n    119     self._compute_output_and_mask_jointly = True\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in __init__(self, *args, **kwargs)\r\n    306     self._steps_per_execution = None\r\n    307 \r\n--> 308     self._init_batch_counters()\r\n    309     self._base_model_initialized = True\r\n    310     _keras_api_gauge.get_cell('model').set(True)\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _init_batch_counters(self)\r\n    315     # `evaluate`, and `predict`.\r\n    316     agg = variables.VariableAggregationV2.ONLY_FIRST_REPLICA\r\n--> 317     self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n    318     self._test_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n    319     self._predict_counter = variables.Variable(\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    260       return cls._variable_v1_call(*args, **kwargs)\r\n    261     elif cls is Variable:\r\n--> 262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    254         synchronization=synchronization,\r\n    255         aggregation=aggregation,\r\n--> 256         shape=shape)\r\n    257 \r\n    258   def __call__(cls, *args, **kwargs):\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)\r\n    235                         shape=None):\r\n    236     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    239       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)\r\n   2644       synchronization=synchronization,\r\n   2645       aggregation=aggregation,\r\n-> 2646       shape=shape)\r\n   2647 \r\n   2648 \r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n--> 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    265 \r\n    266 \r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n   1516           aggregation=aggregation,\r\n   1517           shape=shape,\r\n-> 1518           distribute_strategy=distribute_strategy)\r\n   1519 \r\n   1520   def _init_from_args(self,\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\r\n   1650             initial_value = ops.convert_to_tensor(\r\n   1651                 initial_value() if init_from_fn else initial_value,\r\n-> 1652                 name=\"initial_value\", dtype=dtype)\r\n   1653           if shape is not None:\r\n   1654             if not initial_value.shape.is_compatible_with(shape):\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1497 \r\n   1498     if ret is None:\r\n-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1500 \r\n   1501     if ret is NotImplemented:\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py in _default_conversion_function(***failed resolving arguments***)\r\n     50 def _default_conversion_function(value, dtype, name, as_ref):\r\n     51   del as_ref  # Unused.\r\n---> 52   return constant_op.constant(value, dtype, name=name)\r\n     53 \r\n     54 \r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    262   \"\"\"\r\n    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 264                         allow_broadcast=True)\r\n    265 \r\n    266 \r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    273       with trace.Trace(\"tf.constant\"):\r\n    274         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n--> 275     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    276 \r\n    277   g = ops.get_default_graph()\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    298 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\r\n    299   \"\"\"Implementation of eager constant.\"\"\"\r\n--> 300   t = convert_to_eager_tensor(value, ctx, dtype)\r\n    301   if shape is None:\r\n    302     return t\r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     95     except AttributeError:\r\n     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n---> 97   ctx.ensure_initialized()\r\n     98   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     99 \r\n\r\n~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/context.py in ensure_initialized(self)\r\n    537         if self._use_tfrt is not None:\r\n    538           pywrap_tfe.TFE_ContextOptionsSetTfrt(opts, self._use_tfrt)\r\n--> 539         context_handle = pywrap_tfe.TFE_NewContext(opts)\r\n    540       finally:\r\n    541         pywrap_tfe.TFE_DeleteContextOptions(opts)\r\n\r\nInternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n```\r\nThough I can see in command prompt that GPU is working, i.e when I executed the cell, this was output in terminal\r\n```\r\n2020-08-25 11:59:25.118216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-25 11:59:25.119158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce MX110 computeCapability: 5.0\r\ncoreClock: 1.006GHz coreCount: 2 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\r\n2020-08-25 11:59:25.119254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-25 11:59:25.119313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-25 11:59:25.119366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-25 11:59:25.119422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-25 11:59:25.119484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-25 11:59:25.119545: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-25 11:59:25.119606: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-25 11:59:25.119779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-25 11:59:25.120719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-25 11:59:25.121499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n```\r\nAnyways, This issue is not happening in Tf2.0.0 but in latest version. Thanks.", "Can you take a look at this similar issue #41990 for the error message you're facing with 2.3?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42575, "title": "'retval_' must have the same nested structure in the main and else branches", "body": "Tensorflow=2.3\r\npython=3.7\r\n\r\nI want to control the running process of call() through \u2018mode\u2019. but when the number of returned tensors is inconsistent, an error will be prompted. How can I fix this error?\r\n\r\nMy goal is to deploy the saved model to tensorflow serving.\r\n\r\n```python\r\nclass MLP(tf.keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super(MLP, self).__init__(**kwargs)\r\n        self.dense = tf.keras.layers.Dense(1)\r\n    @tf.function\r\n    def call(self, inputs):\r\n        a, b, mode = inputs\r\n        if mode == 'predict':\r\n            return a\r\n        \r\n        return self.dense(a + b),b\r\n```\r\n```python\r\nif __name__ == '__main__':\r\n    a = tf.ones((2, 10))\r\n    b = tf.ones((2, 10))\r\n    mode = 'train'\r\n    mode = tf.cast(mode, tf.string)\r\n    model = MLP()\r\n    print(model((a, b, mode)))\r\n    model.save('test_model/1/')\r\n```\r\n\r\nerrors:\r\n```python\r\n    TypeError: 'retval_' must have the same nested structure in the main and else branches:\r\n    \r\n    The two structures don't have the same nested structure.\r\n    \r\n    First structure: type=Tensor str=Tensor(\"inputs:0\", shape=(2, 10), dtype=float32)\r\n    \r\n    Second structure: type=tuple str=(<tf.Tensor 'cond/dense/BiasAdd:0' shape=(2, 1) dtype=float32>, <tf.Tensor 'inputs_1:0' shape=(2, 10) dtype=float32>)\r\n    \r\n    More specifically: Substructure \"type=tuple str=(<tf.Tensor 'cond/dense/BiasAdd:0' shape=(2, 1) dtype=float32>, <tf.Tensor 'inputs_1:0' shape=(2, 10) dtype=float32>)\" is a sequence, while substructure \"type=Tensor str=Tensor(\"inputs:0\", shape=(2, 10), dtype=float32)\" is not\r\n    Entire first structure:\r\n    .\r\n    Entire second structure:\r\n    (., .)\r\n\r\n\r\n```\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42575\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42575\">No</a>\n", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/020a87afbf540510aad43bee183ebca8/42575.ipynb). Thanks!", "Hi @SmileTM, when you subclass Model, you can optionally have a training argument (boolean) in your call method, which you can use to specify different behavior in training and inference. Example:\r\n\r\n```\r\nclass MLP(tf.keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super(MLP, self).__init__(**kwargs)\r\n        self.dense = tf.keras.layers.Dense(1)\r\n    \r\n    @tf.function\r\n    def call(self, inputs, training):\r\n        a, b = inputs\r\n        if training:\r\n          return self.dense(a + b),b\r\n        else:\r\n          return a\r\n```\r\n\r\nThen you'll get different behavior in the following two scenarios:\r\n\r\n`print(model((a, b),training=True))`\r\n`print(model((a, b),training=False))`\r\n\r\nHope this helps!", "@nikitamaia \r\nYes, this method works well in normal training, inference  and save model.\r\n But when I deployed the model by using docker tensorflow/serving , it cannot control output by using `training=False`\r\n\r\n```python \r\nsaved_model_cli show --dir  test_model/1/  --all\r\n```\r\nthe model info:\r\n```python\r\nsignature_def['serving_default']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['input_1'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: serving_default_input_1:0\r\n    inputs['input_2'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: serving_default_input_2:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['output_1'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: PartitionedCall:0\r\n  Method name is: tensorflow/serving/predict\r\n```\r\n\r\n```bash\r\ncurl -d '{\"inputs\": {\"input_1\":[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]],\"input_2\":[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]},\"training\":false}' -X POST http://localhost:8501/v1/models/test_model:predict\r\n```\r\njust return `a` . The `\"training\":false` not work.", "Ah I see. Presumably you would only ever want training to be False when you're serving the model, then you can just set the default value for training=False like so:\r\n\r\n```\r\n    def call(self, inputs, training=False):\r\n        a, b = inputs\r\n        if training:\r\n          return self.dense(a + b),b\r\n        else:\r\n          return a\r\n```\r\n\r\nThis should give you the desired behavior in when serving without having to pass in an extra argument, and then you could pass training=True in your training environment. Does that work?", "> Ah I see. Presumably you would only ever want training to be False when you're serving the model, then you can just set the default value for training=False like so:\r\n> \r\n> ```\r\n>     def call(self, inputs, training=False):\r\n>         a, b = inputs\r\n>         if training:\r\n>           return self.dense(a + b),b\r\n>         else:\r\n>           return a\r\n> ```\r\n> \r\n> This should give you the desired behavior in when serving without having to pass in an extra argument, and then you could pass training=True in your training environment. Does that work?\r\n\r\nthis still not work.\r\n", "Please provide more information on why that did not work. Is there an error message or stack trace you can provide?", "> Please provide more information on why that did not work. Is there an error message or stack trace you can provide?\r\n\r\nModel information has not changed\r\n\r\n```python\r\nsignature_def['serving_default']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['input_1'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: serving_default_input_1:0\r\n    inputs['input_2'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: serving_default_input_2:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['output_1'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: PartitionedCall:0\r\n  Method name is: tensorflow/serving/predict\r\n```\r\n\r\nNo matter how I input \"train\", I cannot control the output of the model.\r\nThe output format seems to be fixed when I save the model.\r\n**The training process is ok.** \r\n**But** if the model `.pb` file is deployed in tensorflow/serving, the output cannot be controlled by train=\u2018true\u2019 or train=\u2018false\u2019.\r\nSometimes I need the outputs of train=\u2018false\u2019, sometimes I need the outputs of train=\u2018true\u2019. like the `MLP()`\r\nIt seems that the `.pb` file does not save the logical branch structure.\r\nemmm, I suggest you try to deploy the .pb file to tensorflow/serving, and then request the service through `curl`. Then you will understand my question.\r\n\r\n\r\n\r\n\r\n", "@SmileTM This issue is related to tensorflow serving not tensorflow. Please post this issue [here](https://github.com/tensorflow/serving/issues) and close this issue here. Thanks!"]}, {"number": 42574, "title": "[Grappler] Improve HoistCWiseUnaryChainsStage to support Reshape", "body": "It continues the issue #40542 ", "comments": ["@rthadur ", "@xinan-jiang  Can you please check @rmlarsen's comments and keep us posted ? Thanks!", "This appears to produce an invalid graph in the test `tensorflow/python/distribute:cross_device_ops_test`. Please take a look. \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/py/absl/testing/parameterized.py\", line 282, in bound_param_test\r\n    return test_method(self, **testcase_params)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/framework/test_combinations.py\", line 367, in decorated\r\n    execute_test_method()\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/framework/test_combinations.py\", line 350, in execute_test_method\r\n    test_method(**kwargs_to_pass)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/distribute/combinations.py\", line 435, in decorator\r\n    test_method(self, **kwargs)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/distribute/cross_device_ops_test.py\", line 454, in testBatchAllReduceDense\r\n    self.batch_reduce_and_verify(inputs, expect, options)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/distribute/cross_device_ops_test.py\", line 301, in batch_reduce_and_verify\r\n    get_global_mpr(options.num_processes).run(replica_fn)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/distribute/multi_process_runner.py\", line 980, in run\r\n    six.reraise(*process_status.exc_info)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/py/six/__init__.py\", line 703, in reraise\r\n    raise value\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/distribute/multi_process_runner.py\", line 1037, in _run_contained\r\n    return_value = fn(*args, **kwargs)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/distribute/cross_device_ops_test.py\", line 298, in replica_fn\r\n    got = def_function.function(batch_reduce_fn)()\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/eager/def_function.py\", line 784, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/eager/def_function.py\", line 851, in _call\r\n    filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/eager/function.py\", line 1948, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/eager/function.py\", line 561, in call\r\n    ctx=ctx)\r\n  File \"/build/work/54d02ca2125b6ddae3c411e2d47c84f01697/google3/runfiles/google3/third_party/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\n**google3.third_party.tensorflow.python.framework.errors_impl.InvalidArgumentError: Incomplete graph, missing 1 inputs for ArithmeticOptimizer/_Reshape_2_split [Op:__inference_batch_reduce_fn_8924]**", "@xinan-jiang  Can you please check @rmlarsen's comments and keep us posted ? Thanks!", "Sorry, I can not get the error on my local. It seems a multi-device case. Additionally, I think this PR is no relation to the cross-devices situations. I saw this case was rollbacked recently. https://github.com/tensorflow/tensorflow/commits/master/tensorflow/python/distribute/cross_device_ops_test.py", "@rmlarsen  Can you please take a look on above comments from @xinan-jiang. Thanks!", "@rmlarsen  Any update on this PR? Please. Thanks!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42574) for more info**.\n\n<!-- need_author_cla -->", "@rmlarsen  It is a bugfix and modified UT for this bug.", "@rmlarsen @ezhulenev @rthadur  could you help to review the new fix.", "@xinan-jiang Can you please resolve conflicts? Thanks!", "@xinan-jiang sorry for the long delay. You need to rebase. After rebasing and adding TF_RETURN_IF_ERROR in line ~1818, your new tests do not pass anymore. Mind taking a look.", "> @xinan-jiang sorry for the long delay. You need to rebase. After rebasing and adding TF_RETURN_IF_ERROR in line ~1818, your new tests do not pass anymore. Mind taking a look.\r\n\r\nTest fail because of the previous commit. Now it could pass.", "add fix for keras-utils-tests", "@rmlarsen @ezhulenev help to review", "@gbaned, What blocks this PR ?", "> @gbaned, What blocks this PR ?\r\n\r\n@xinan-jiang  Internal errors are appearing with this PR, @rmlarsen is working on this. Thanks!", "@xinan-jiang the issue is that the change appears to break the test in tensorflow/contrib/recurrent:functional_rnn_test. The contrib module was removed in TF2, but we still test against it internally for legacy users. You could try to test your change against it using TF release 1.15.", "@xinan-jiang Can you please check @rmlarsen's comment and resolve conflicts? Thanks!", "@gbaned  I am working on this.", "@rmlarsen @gbaned  It fails with tf1.x \"Concat\" op, which is instead of \"ConcatV2\" in tf2.x. Now it could pass with \"Concat\" op.", "@xinan-jiang  Can you please resolve conflicts? Thanks!", "@rmlarsen please help to review my resolve for confilct with e98fc97bee12655f93627604515a7140eea1cfe0", "@rmlarsen @gbaned help to review.", "@ezhulenev @rthadur help to review it.", "@gbaned I could not see the details of the fail test. Does it block the merge work?", "> @gbaned I could not see the details of the fail test. Does it block the merge work?\r\n\r\n@xinan-jiang This is waiting for internal approval, once done it will be processed to merge.  Thanks!", "I'm afraid this had to be rolled back since it broke tests in the lingvo project. It still seems like the rewrite violates some graph invariants. \r\n\r\n```google3.third_party.tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 2688000 values, but the requested shape has 640000\r\n\t [[node fprop/test_dtmodel/tower_0_0/Reshape_15 (defined at /third_party/py/lingvo/core/layers.py:2501) ]]```\r\n"]}, {"number": 42573, "title": "issues with tf.math.reduce_euclidean_norm", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n    Yes\r\n\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n     macOS Mojave (10.14.5)\r\n\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n    N/A\r\n\r\n-   **TensorFlow installed from (source or binary)**:\r\n    from anaconda\r\n\r\n-   **TensorFlow version (use command below)**:\r\n    1.14\r\n\r\n-   **Python version**:\r\n     3.7\r\n\r\n-   **Bazel version (if compiling from source)**:\r\n     N/A\r\n\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n     N/A\r\n\r\n-   **CUDA/cuDNN version**:\r\n     No GPU needed\r\n\r\n-   **GPU model and memory**:\r\n     N/A\r\n \r\n-   **Exact command to reproduce**:\r\n     Just run the program\r\n\r\n### Describe the problem\r\ntf.math.reduce_euclidean_norm makes the model non-differentiable, I getting the error message ```ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'embedding_matrix:0' shape=(5, 3) dtype=float32_ref>\"] and loss Tensor(\"EuclideanNorm:0\", dtype=float32).``` for the following program\r\n\r\n```\r\nmport tensorflow as tf\r\n\r\nindex1 = tf.placeholder(tf.int32, None)\r\nindex2 = tf.placeholder(tf.int32, None)\r\n\r\nembedding = tf.get_variable('embedding_matrix', [5, 3])\r\n\r\nvector1 = tf.nn.embedding_lookup(embedding, index1)\r\nvector2 = tf.nn.embedding_lookup(embedding, index2)\r\n\r\nloss = tf.math.reduce_euclidean_norm(vector1-vector2, axis=1)\r\ntrain_step = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999).minimize(loss)\r\n\r\nwith tf.Session() as sess:            \r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n   \r\n    for i in range(5):\r\n        result = sess.run([loss, train_step], feed_dict={index1:1,index2:0})\r\n        print(result[0])\r\n```\r\n\r\nReplace the line\r\n\r\n```\r\nloss = tf.math.reduce_euclidean_norm(vector1-vector2, axis=1)\r\n```\r\nwith a custom implementation\r\n\r\n```\r\nloss = tf.math.sqrt(tf.reduce_sum((vector1-vector2)**2, axis=-1))\r\n```\r\n\r\nsolves the problem. So we think this is a bug. It would be great if you can take a look or maybe let us know how we may use ```tf.math.reduce_euclidean_norm``` assuming we misused it.\r\n\r\nThanks", "comments": ["@keowang \r\nI ran the code shared on tf 1.15, as we have support from 1.15 and 2.x, but i face a different error.\r\nPlease refer tot he [gist here](https://colab.research.google.com/gist/Saduf2019/4a46b12ec2bd207ef6472fd5be2fa862/untitled388.ipynb)", "By looking at the last line ```ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'embedding_matrix:0' shape=(5, 3) dtype=float32_ref>\"] and loss Tensor(\"EuclideanNorm:0\", dtype=float32).``` I think the error is the same.", "The reduction dimension is invalid. It should be `axis=0` since both `vector1` and `vector2` are rank-1 tensors:\r\n```\r\nloss = tf.math.reduce_euclidean_norm(vector1-vector2, axis=0)\r\n```\r\nThis now works in the latest version of tensorflow, if you import v1 as\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42573\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42573\">No</a>\n"]}, {"number": 42572, "title": "Tensor Cores no performance improvement CUBLAS tf.matmul()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): see below\r\n- OS Platform and Distribution: CentOS Linux 7\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.4\r\n- GCC/Compiler version (if compiling from source): N/A but it is GCC-8.3.0.\r\n- CUDA/cuDNN version: 10.1.243 / 7.x.x\r\n- GPU model and memory: RTX 2080Ti\r\n\r\n**Describe the current behavior**\r\nI don't see any performance difference running `tf.matmul()` when utilizing the Tensor Cores in Nvidia RTX 2080 Ti. Is my test setup wrong or is there really no performance improvement?\r\n\r\nI run the test two times, setting environment variables for Tensor Cores differently each run.\r\n\r\nAs of Tensorflow 2.3.0 the use of environment variable `TF_DISABLE_CUBLAS_TENSOR_OP_MATH` has been removed (see [this commit](https://github.com/tensorflow/tensorflow/commit/32d63d0a3efb5e0b65dc6f590e54248054cf9f14)), making it impossible to switch between Tensor Core usage during runtime. So I used Tensorflow 2.2.0 using _float16_ datatype.\r\n\r\nTensor Cores disabled:\r\n```\r\nTF_DISABLE_CUBLAS_TENSOR_OP_MATH=1\r\nTF_ENABLE_CUBLAS_TENSOR_OP_MATH_FP32=0\r\nTF_ENABLE_CUDNN_TENSOR_OP_MATH_FP32=0\r\nTF_ENABLE_CUDNN_RNN_TENSOR_OP_MATH_FP32=0\r\nNUMBER=16384\r\nDTYPE=float16            \r\n2020-08-21 12:44:28.189777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-08-21 12:44:32.243417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:5a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-08-21 12:44:32.243729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 12:44:32.246376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 12:44:32.249129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 12:44:32.249554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 12:44:32.252491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 12:44:32.254002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 12:44:32.259926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 12:44:32.281312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-21 12:44:32.282146: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-08-21 12:44:32.291868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz\r\n2020-08-21 12:44:32.292063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3547ca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-21 12:44:32.292081: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-21 12:44:32.694055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x35ba180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-21 12:44:32.694078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-08-21 12:44:32.696876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:5a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-08-21 12:44:32.696914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 12:44:32.696931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 12:44:32.696947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 12:44:32.696957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 12:44:32.696967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 12:44:32.696976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 12:44:32.696985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 12:44:32.715821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-21 12:44:32.715858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 12:44:32.718333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 12:44:32.718348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-08-21 12:44:32.718356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-08-21 12:44:32.723419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10204 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:5a:00.0, compute capability: 7.5)\r\n2020-08-21 12:44:32.725151: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op StatelessRandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:41.983001: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:41.984023: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:42.230340: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:42.231872: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:42.232362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\nNum GPUs Available:  1\r\nGenerating a  16384 x 16384  matrix took:  0.0007753130048513412 s\r\nMultiplying a  16384 x 16384  matrix took:  0.00017198268324136734 s\r\n```\r\n\r\nTensor Cores enabled:\r\n\r\n```\r\nTF_DISABLE_CUBLAS_TENSOR_OP_MATH=0\r\nTF_ENABLE_CUBLAS_TENSOR_OP_MATH_FP32=1\r\nTF_ENABLE_CUDNN_TENSOR_OP_MATH_FP32=1\r\nTF_ENABLE_CUDNN_RNN_TENSOR_OP_MATH_FP32=1\r\nNUMBER=16384\r\nDTYPE=float16         \r\n2020-08-21 12:44:28.189996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-08-21 12:44:32.153926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:62:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-08-21 12:44:32.155894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 12:44:32.173061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 12:44:32.177611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 12:44:32.179239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 12:44:32.184143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 12:44:32.186975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 12:44:32.195284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 12:44:32.211230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-21 12:44:32.212211: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-08-21 12:44:32.223121: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz\r\n2020-08-21 12:44:32.223348: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3547d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-21 12:44:32.223367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-21 12:44:32.658935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x35ba260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-21 12:44:32.658973: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-08-21 12:44:32.660135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:62:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-08-21 12:44:32.660175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 12:44:32.660187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 12:44:32.660197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 12:44:32.660206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 12:44:32.660215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 12:44:32.660225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 12:44:32.660235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 12:44:32.662855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-08-21 12:44:32.662896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 12:44:32.664538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 12:44:32.664554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-08-21 12:44:32.664564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-08-21 12:44:32.694148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10204 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:62:00.0, compute capability: 7.5)\r\n2020-08-21 12:44:32.696836: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op StatelessRandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:41.882224: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:41.883265: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:42.230553: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:42.233699: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-08-21 12:44:42.234656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\nNum GPUs Available:  1\r\nGenerating a  16384 x 16384  matrix took:  0.0015629231929779053 s\r\nMultiplying a  16384 x 16384  matrix took:  0.00017150864005088806 s\r\n```\r\n**Describe the expected behavior**\r\nDifference in execution time of multiplying 2 matrices.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport argparse\r\nimport logging\r\nfrom time import perf_counter\r\n\r\nparser = argparse.ArgumentParser(description='Process some integers.')\r\nparser.add_argument('--number', dest='number', action='store', type=int,\r\n                    default=1024,\r\n                    help='Optional, integer')\r\nparser.add_argument('--dtype', dest='dtype', action='store', type=str,\r\n                    default='float32',\r\n                    choices=['float64','float32','float16','bfloat16','int64','int32','int16','int8','uint64','uint32','uint16','uint8'],\r\n                    help='Optional, dtype')\r\n\r\nargs = parser.parse_args()\r\n\r\nsize = args.number;\r\n\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n\r\ntf.debugging.set_log_device_placement(True)\r\n#initialize libraries\r\ntemp = tf.random_uniform_initializer(minval=0, maxval=1, seed=2)(shape=[2,2],dtype=args.dtype);\r\n\r\nlogging.info(\"Generating a %dx%d randomUniform matrix, please standby\", size, size);\r\nt1_start = perf_counter()\r\nmatrix = tf.random_uniform_initializer(minval=0, maxval=1, seed=2)(shape=[size,size],dtype=args.dtype);\r\nt1_stop = perf_counter()\r\nprint(\"Generating a \",size,\"x\",size,\" matrix took: \", (t1_stop - t1_start), 's')\r\n\r\n# Initialize cuBLAS....\r\ntemp2 = tf.matmul(temp,temp,transpose_a=False,transpose_b=True);\r\n\r\nt1_start = perf_counter()\r\nresult = tf.matmul(matrix,matrix,transpose_a=False,transpose_b=True);\r\nt1_stop = perf_counter()\r\nprint(\"Multiplying a \",size,\"x\",size,\" matrix took: \", (t1_stop - t1_start), 's')\r\n```\r\n**Other info / logs**", "comments": ["@TheNewSound \r\nIt looks like you are using an older Version of Tensorflow. Many issues have been fixed in the latest version. Can you please execute your code using Latest Version (2.7.0) and let us know if the issue still persists?Please have a look at the  colab [gist](https://colab.sandbox.google.com/gist/sushreebarsa/80e4acba6a8af1e14050ad70fdbfcdac/untitled527.ipynb) where I have faced different error.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42571, "title": "Add some information on testing to the contribution guidelines.", "body": "Issue #42569", "comments": ["@freddan80, let me know what you think.", "@advaitjain Looks good so far, but some further info on what a contributor should test before submitting a PR would be great. Something like:\r\n\r\n\r\n1. Run \"./tensorflow/lite/micro/tools/ci_build/test_all.sh\" in order to test xyz. Note: Add \"-Wall -Werror\" as build flags\r\n2. Run e.g. \"bazel run //tensorflow/lite/micro:micro_interpreter_test\" if you have changed xyz. This test is will make sure that xyz.\r\n3. Mbed tests, if you have make changes to the build system, since xyz.\r\n```\r\nRun \"make -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn  generate_kernel_<op_name>_test_mbed_project\"\r\ncd tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/kernel_<op_name>_test/mbed\r\nmbed config root .\r\nmbed deploy\r\nmbed compile -m auto -t GCC_ARM -f --profile mbed-os/tools/profiles/release.json -D__ARM_FEATURE_DSP\r\n\r\n```\r\n\r\netc.\r\n\r\nI think this may save a lot of time. \r\n\r\nCheers!\r\n\r\n", "> @advaitjain Looks good so far, but some further info on what a contributor should test before submitting a PR would be great. Something like:\r\n> \r\n> 1. Run \"./tensorflow/lite/micro/tools/ci_build/test_all.sh\" in order to test xyz. Note: Add \"-Wall -Werror\" as build flags\r\n> 2. Run e.g. \"bazel run //tensorflow/lite/micro:micro_interpreter_test\" if you have changed xyz. This test is will make sure that xyz.\r\n> 3. Mbed tests, if you have make changes to the build system, since xyz.\r\n> \r\n> ```\r\n> Run \"make -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn  generate_kernel_<op_name>_test_mbed_project\"\r\n> cd tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/kernel_<op_name>_test/mbed\r\n> mbed config root .\r\n> mbed deploy\r\n> mbed compile -m auto -t GCC_ARM -f --profile mbed-os/tools/profiles/release.json -D__ARM_FEATURE_DSP\r\n> ```\r\n> \r\n> etc.\r\n> \r\n> I think this may save a lot of time.\r\n> \r\n> Cheers!\r\n\r\nGood suggestions. I have added a link to your comment from the issue. Will send a separate PR for that.\r\n\r\nI am in the process of spending a bit more time myself as a PR author (instead of always writing code via the internal tools) and will update the guidelines as I get a chance to test them out.", "@njeffrie: I had a merge conflict, so needs your review again. [Here](https://github.com/tensorflow/tensorflow/pull/42571/commits/303e22d09a175fdc1093d57fa09b44367851628b) is exactly what I had to change for the merge.\r\n\r\nI'm keeping some notes as I figure out a workflow that works for me as a PR author and will update the guidelines once I have some more confidence in my workflow."]}, {"number": 42570, "title": "Add guidelines around testing.", "body": "Issue #42569", "comments": ["@freddan80, let me know what you think.", "I accidentally deleted this branch in my fork resulted in this PR being closed. Creating a new one now. "]}, {"number": 42569, "title": "Improvements to the contribution guidelines", "body": "@tensorflow/micro\r\n\r\nCouple of comments that we have received that would improve the [TFLM Contribution Guidelines](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md):\r\n\r\n * More visibility on the internal testing (e.g. a short description of what is tested internally) would be good.\r\n * What are the guidelines around unit-testing?", "comments": ["Some suggestions from a PR review are in [this comment](https://github.com/tensorflow/tensorflow/pull/42571#issuecomment-679829454)", "We now have many of the internal CI results visible to the external contributors as well. See https://github.com/tensorflow/tensorflow/pull/44451 as one example.\r\n\r\nClosing the current issue though there is still plenty of room for additional improvements to the documentation."]}, {"number": 42568, "title": "Please Update Conda Install", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):\r\n- TensorFlow installed from conda then used pip to update tensorflow to 2.3.0):\r\n- TensorFlow version (2.3.0):\r\n- Python version 3.7:\r\n- CUDA/cuDNN version (Latest conda install verison):\r\n- GPU model and memory (V100 32gb VRAM):\r\n\r\n**Describe the current behavior**\r\nTensorflow is unbelievable slow to start the training. Takes 30-40 min to initialize. Stops halfway through the first epoch for 10 minutes. Then every epoch after that is fine. I have run a similar code in Google Colab and it runs perfectly normal. Does not take 30-40 min to initialize. Everything is a fresh install (conda, venv, etc). \r\n\r\n**Describe the expected behavior**\r\nFor model.fit() to start training within a minute or two. Not take 40 minutes.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nconda install -c anaconda tensorflow-gpu (I do this because it installs all the cuda drivers in one command. It is impossible to install cuda drivers on a cluster login node that does not contain an nvidia GPU inside of it. Conda is the only way to install TensorFlow with GPU acceleration on computational shared clusters.)\r\n\r\npip install tensorflow-gpu==2.3.0 (because your latest conda version does not install tensorflow-gpu==2.3.0)\r\n\r\nUse the ImageDataGenerator:\r\n\r\nbatch_size=32\r\n\r\ntrain_gen = train_datagen.flow(X_train, y_train, \r\n                                 batch_size=batch_size, \r\n                                 shuffle=True,\r\n                                 subset='training', seed=7)\r\n\r\n\r\nv_gen = val_datagen.flow(X_test, y_test,\r\n                                 batch_size=batch_size,\r\n                                 subset='training', seed=7)\r\n\r\n\r\nds = tf.data.Dataset.from_generator(lambda: train_gen, \r\n    output_types=(tf.float32, tf.float32), \r\n    output_shapes=([32,64,64,3], [32,3])\r\n)\r\n\r\n\r\nv = tf.data.Dataset.from_generator(lambda: v_gen, \r\n    output_types=(tf.float32, tf.float32), \r\n    output_shapes=([32,64,64,3], [32,3])\r\n)\r\n\r\n\r\nmodel.fit_generator(ds,\r\n      epochs=100,  #### set repeat in training dataset\r\n      steps_per_epoch=len(train_gen),\r\n      validation_data=v,\r\n      validation_steps=len(v_gen), \r\n      callbacks=[checkpoints, ], verbose=1)\r\n\r\n\r\nYou can use model.fit() as well. There is still a 40-minute wait for this to start training.", "comments": ["@WilliamJudge94 \r\nPlease provide complete indented stand alone code for us to replicate the issue faced, if possible share a colab gist with the error.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42567, "title": "set isort version to 4.3.21", "body": "", "comments": []}, {"number": 42566, "title": "Bandwidth on TPU v3 > 900 GB/s", "body": "I've testing the performance of EmbeddingTPU on GCP TPU v3-8. I found that the computed memory access\r\nbandwidth is beyond > 900 GB/s when using one core (900 GB/s is the theoretical upper bound). I think this may be\r\na tensorflow bug. The test code is developed in Python interface.\r\n\r\nHere is the code TGTBT.py and the tf_env.txt (file is too big to put here, collected using tf_env_collect.sh).\r\nhttps://github.com/shz0116/testTF/blob/master/TGTBT.py\r\nhttps://github.com/shz0116/testTF/blob/master/tf_env.txt\r\n\r\nThe run command and output is listed at the top of TGTBT.py file. It's pretty simple.\r\n\r\n~$ python3 -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\nv1.12.1-34769-gfd2d4cdb70 2.3.0-dev20200620\r\n\r\n**Describe the current behavior**\r\nWe see the computed memory bandwidth for one TPU v3 core is > 900 GB/s.\r\n \r\n**Describe the expected behavior**\r\nWe expect the bandwidth number is below 900 GB/s.\r\n\r\n**Standalone code to reproduce the issue**\r\nSee above.\r\n\r\nUpdate: I found that if I add a statement res.numpy() into the timer, the performance will change from too good (> 900 GB/s) to too bad (1.4 GB/s).", "comments": ["Hi @shz0116, when you say bandwidth is beyond > 900 GB/s, what is the number you calculated? Trying to understand how much larger than 900. Additionally, can you explain how you did this calculation? I see in your script that your calculation for `total_bytes` depends on command line arguments, and I'm wondering what those numbers were. Additionally can you explain what `em` and `nnz` are?", "@nikitamaia This is for table lookup. Suppose you have a 2D table or matrix, T[features=1000000, em=128] datatype=float32. \r\n Each time (or call batch), we search nnz rows and compute the sum across the columns. The row id is generated by random.\r\nNow we have a sum vector with size [em=128].  Here we repeat the search 65536 times.\r\nSo, finally we have a results matrix R[batch=65536, em=128].  \r\n\r\nDuring this process, we read from the matrix (or memory) total_bytes data. So the memory bandwidth is total_bytes/Time.\r\nIt should be less than theoretical memory bandwidth. By the way, TPU have cache or not like CPU cache ?\r\n\r\nHope this helps. Just let me know if you have any question.", "What was the result of the calculation you did? You mentioned it was larger than 900, But what was the actual number?", "1683.631 GB/s\r\nThe line 10 in file https://github.com/shz0116/testTF/blob/master/TGTBT.py.", "Can you point to where you found the upper bound to be 900 GB/s ? I have not heard this number specifically.", "https://cacm.acm.org/magazines/2020/7/245702-a-domain-specific-supercomputer-for-training-deep-neural-networks/fulltext\r\nDid you find anything wrong with my code ?", "Thanks for sharing that link. Although I couldn't find the 900GB/s noted there specifically. I don't think there's any bug here since it's not possible for the bandwidth to be higher than the maximum bandwidth. It seems that if your calculation is correct than the upper limit for bandwidth is > 900 GB/s.", "Look at \"Table 3. Key processor features.\" Row : Memory GBs/Chip.\r\n\r\nI think we are lacking a reasonable explanation why BW > 900 GB/s the theoretical peak if not a bug.\r\nDo you know whether TPUEMbedding implementation using multiple threading or other parallel data access ?\r\n", "I think in this case it would be worth contacting the authors of that link you provided to understand how they measured the 900GB/s. It doesn't make sense for the BW to be higher than the limit, so either the limit is greater than 900 or your calculation is incorrect. Either way, I think the best next step is to contact the authors to better understand how they got the 900GB/s number.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42565, "title": "Kohonen SOM", "body": "Just wondering how come there is no \"factory\" implementation of Kohonen SOM in Tensorflow? Or is there? Is it planned to include it in next releases?", "comments": ["TF is a library providing the minimum things needed to implement ML models. We cannot incorporate everything as that would result in huge packages and a lot of pieces of code that will no longer be maintained.\r\n\r\nYou can implement self organizing maps using Keras layers. Or, see https://github.com/cgorman/tensorflow-som Alternatively, you can try to look in https://github.com/tensorflow/addons or add an implementation there"]}, {"number": 42564, "title": "TFLite Inference Runtime Error with Models Containing Conv2dLstm", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\ntf-nightly-gpu: v1.12.1-39890-gf74cc7a696 2.4.0-dev20200821\r\n(problem also happens on tensorflow-gpu v2.3.0)\r\n- Python version:\r\n3.7.7\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nAll model's containing Conv2DLstm layers (https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM2D) can be successfully converted to TFLite models, but then they always fail when running inference using the TFLite interpreter. \r\n\r\nSpecifically, the following Runtime Error is thrown when the interpreter's `invoke` method is called:\r\n`Runtime Error Caught: Fill dimensions must be >= 0Node number 7 (FILL) failed to invoke.`\r\n\r\n\r\n**Describe the expected behavior**\r\nAll model's containing Conv2DLstm layers can successfully run inference using the TFLite interpreter.\r\n\r\n**Standalone code to reproduce the issue**\r\nHere is a standalone script to reproduce this issue with either tf-nightly or tensorflow r2.3.0.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\n\r\n# a function to convert the input tensorflow model to a tflite model and test the models\r\n# with some test data\r\ndef convert_and_test(model, test_data):    \r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\n    # this is needed to convert tf.Slice, see https://github.com/tensorflow/tensorflow/issues/35590\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                           tf.lite.OpsSet.SELECT_TF_OPS]\r\n    tflite_model = converter.convert()\r\n\r\n    interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n    input_details = interpreter.get_input_details()\r\n\r\n    # since model has dynamic input shape, we need to reshape the input tensor each time that shape changes\r\n    interpreter.resize_tensor_input(input_details[0]['index'], test_data.shape)\r\n    interpreter.allocate_tensors()\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n    \r\n    # print IO details after resizing and tensor allocation\r\n    print(input_details)\r\n    print(output_details)\r\n\r\n    # Test regular model on data\r\n    tf_results = model(test_data)\r\n    \r\n    # verify shape is correct\r\n    print('Test data shape: ', test_data.shape)\r\n    print('TF model output shape: ', tf_results.shape)\r\n    \r\n    # Test the model\r\n    interpreter.set_tensor(input_details[0]['index'], test_data)\r\n    \r\n    try:\r\n        interpreter.invoke()\r\n\r\n        # get output if inference was successful\r\n        tflite_results = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n        # verify shape is correct\r\n        print('TF lite model output shape: ', tflite_results.shape)\r\n\r\n        # Compare model results\r\n        for tf_result, tflite_result in zip(tf_results, tflite_results):\r\n            np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)\r\n\r\n    except RuntimeError as err:\r\n        print('Runtime Error Caught: %s' % err)\r\n\r\n\r\n# define two helper functions for creating conv2d and conv2dlstms with some\r\n# common features\r\ndef _conv_lstm(filters, kernel_size, dilation_rate, return_sequences):\r\n    conv_layer = layers.ConvLSTM2D(filters=filters, \r\n                                    kernel_size=kernel_size,\r\n                                    strides=(1, 1),\r\n                                    padding='same',\r\n                                    data_format='channels_last',\r\n                                    dilation_rate=dilation_rate,\r\n                                    activation='relu',\r\n                                    recurrent_activation='hard_sigmoid',\r\n                                    return_sequences=return_sequences)\r\n    return conv_layer\r\n\r\ndef _conv(filters, kernel_size, dilation_rate):\r\n    conv_layer = layers.Conv2D(filters=filters, \r\n                                    kernel_size=kernel_size,\r\n                                    strides=(1, 1),\r\n                                    padding='same',\r\n                                    data_format='channels_last',\r\n                                    dilation_rate=dilation_rate,\r\n                                    activation='relu')\r\n    return conv_layer\r\n\r\n# not important for this example, some arbitrary value\r\nnum_classes = 3\r\n\r\n# define a model that DOES work\r\nworking_inputs = keras.Input(shape=(None, None, 1), name='image_sequence')\r\nworking_conv_1 = _conv(filters=8, kernel_size=(3, 3), dilation_rate=(1, 1))(working_inputs)\r\nworking_conv_bn_1 = layers.BatchNormalization()(working_conv_1)\r\nworking_outputs = layers.Conv2D(filters=num_classes, \r\n                        kernel_size=(1, 1),\r\n                        strides=(1, 1),\r\n                        padding='same',\r\n                        data_format='channels_last',\r\n                        dilation_rate=(1, 1),\r\n                        activation=None)(working_conv_bn_1)\r\nworking_model = keras.Model(inputs=working_inputs, outputs=working_outputs)\r\nworking_model.summary(line_length=140)\r\n\r\n# create some data to test model with\r\nworking_data = np.random.rand(1, 256, 128, 1).astype(np.float32)\r\n\r\n# show that model fails to invoke\r\nprint('About to convert and test working fully convolutional model')\r\nconvert_and_test(working_model, working_data)\r\n\r\n# define a model that DOES NOT work\r\nfailing_inputs = keras.Input(shape=(None, None, None, 1), name='image_sequence')\r\nfailing_conv_lstm_1 = _conv_lstm(filters=8, kernel_size=(3, 3), dilation_rate=(1, 1), return_sequences=False)(failing_inputs)\r\nfailing_conv_lstm_bn_1 = layers.BatchNormalization()(failing_conv_lstm_1)\r\nfailing_outputs = layers.Conv2D(filters=num_classes, \r\n                                kernel_size=(1, 1),\r\n                                strides=(1, 1),\r\n                                padding='same',\r\n                                data_format='channels_last',\r\n                                dilation_rate=(1, 1),\r\n                                activation=None)(failing_conv_lstm_bn_1)\r\n\r\nfailing_model = keras.Model(inputs=failing_inputs, outputs=failing_outputs)\r\nfailing_model.summary(line_length=140)\r\n\r\n# create some data to test model with\r\n# since we are using Conv2dLstms here, dimension 1 (0-based) is sequence length\r\nfailing_data = np.random.rand(1, 3, 256, 128, 1).astype(np.float32)\r\n\r\n# show that model fails to invoke\r\nprint('About to convert and test failing fully convolutional LSTM model')\r\nconvert_and_test(failing_model, failing_data)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nOne interesting thing I noticed is that the output_details for the model that fails does not seem to properly reshape the output after the call to allocate_tensors(). I'm not sure if that is related, but it was the one difference between the working model and failing model that I noticed (besides the RuntimeError, of course).\r\n\r\nPlease let me know if there is anything else I can do to help diagnose and fix this, or if you have any other questions. I'm very determined to solve this issue ASAP.\r\n\r\nFor completeness, here is total output of the script above:\r\n\r\n```\r\n2020-08-21 14:36:44.930663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:45.796378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-08-21 14:36:45.801517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2020-08-21 14:36:45.801546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:45.803090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:45.804734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 14:36:45.804935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 14:36:45.806469: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 14:36:45.807182: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 14:36:45.810354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:45.812420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-21 14:36:45.812791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-21 14:36:45.837505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2994095000 Hz\r\n2020-08-21 14:36:45.839632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ed46b621a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-21 14:36:45.839661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-21 14:36:46.496091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ed46bcdcb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-21 14:36:46.496148: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5\r\n2020-08-21 14:36:46.498003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2020-08-21 14:36:46.498048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:46.498078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:46.498094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 14:36:46.498110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 14:36:46.498126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 14:36:46.498141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 14:36:46.498157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:46.501695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-21 14:36:46.501752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:46.986756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 14:36:46.986826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-08-21 14:36:46.986834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-08-21 14:36:46.988998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21417 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5)\r\nWARNING:tensorflow:From /home/jatkinson/anaconda3/envs/tensorflow_2p3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\n2020-08-21 14:36:47.466889: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:tensorflow:From /home/jatkinson/anaconda3/envs/tensorflow_2p3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\n2020-08-21 14:36:47.753827: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-08-21 14:36:47.754022: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-08-21 14:36:47.755162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2020-08-21 14:36:47.755198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:47.755226: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:47.755237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 14:36:47.755246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 14:36:47.755256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 14:36:47.755265: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 14:36:47.755275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:47.755957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-21 14:36:47.755992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 14:36:47.755997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-08-21 14:36:47.756002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-08-21 14:36:47.756718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21417 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5)\r\n2020-08-21 14:36:47.763790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-08-21 14:36:47.763842: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.008ms.\r\n2020-08-21 14:36:47.763850: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-21 14:36:47.796767: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-08-21 14:36:47.796837: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\n2020-08-21 14:36:47.800774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2020-08-21 14:36:47.800822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:47.800846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:47.800856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 14:36:47.800864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 14:36:47.800873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 14:36:47.800881: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 14:36:47.800890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:47.801613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-21 14:36:47.801647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 14:36:47.801653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-08-21 14:36:47.801658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-08-21 14:36:47.802417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21417 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5)\r\n2020-08-21 14:36:47.816103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:49.126173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:51.254963: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-08-21 14:36:51.255136: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-08-21 14:36:51.256116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2020-08-21 14:36:51.256160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:51.256184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:51.256194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 14:36:51.256205: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 14:36:51.256227: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 14:36:51.256237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 14:36:51.256248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:51.256905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-21 14:36:51.256941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 14:36:51.256946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-08-21 14:36:51.256952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-08-21 14:36:51.257671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21417 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5)\r\n2020-08-21 14:36:51.267953: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-08-21 14:36:51.268000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 112 nodes (0), 133 edges (0), time = 1.388ms.\r\n2020-08-21 14:36:51.268004: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 112 nodes (0), 133 edges (0), time = 1.449ms.\r\n2020-08-21 14:36:51.268008: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: functional_3_conv_lst_m2d_while_body_5034\r\n2020-08-21 14:36:51.268012: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-21 14:36:51.268015: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-21 14:36:51.268019: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: functional_3_conv_lst_m2d_while_cond_5033\r\n2020-08-21 14:36:51.268022: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-21 14:36:51.268026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-21 14:36:51.342805: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-08-21 14:36:51.342872: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\nINFO: Created TensorFlow Lite delegate for select TF ops.\r\n2020-08-21 14:36:51.388179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2020-08-21 14:36:51.388213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-21 14:36:51.388235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-21 14:36:51.388244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-21 14:36:51.388252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-21 14:36:51.388260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-21 14:36:51.388268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-21 14:36:51.388276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-21 14:36:51.388956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-21 14:36:51.388990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-21 14:36:51.388996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-08-21 14:36:51.389000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-08-21 14:36:51.389756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21417 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5)\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 16 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 41 nodes with 1 partitions.\r\n\r\nModel: \"functional_1\"\r\n____________________________________________________________________________________________________________________________________________\r\nLayer (type)                                                   Output Shape                                            Param #              \r\n============================================================================================================================================\r\nimage_sequence (InputLayer)                                    [(None, None, None, 1)]                                 0                    \r\n____________________________________________________________________________________________________________________________________________\r\nconv2d (Conv2D)                                                (None, None, None, 8)                                   80                   \r\n____________________________________________________________________________________________________________________________________________\r\nbatch_normalization (BatchNormalization)                       (None, None, None, 8)                                   32                   \r\n____________________________________________________________________________________________________________________________________________\r\nconv2d_1 (Conv2D)                                              (None, None, None, 3)                                   27                   \r\n============================================================================================================================================\r\nTotal params: 139\r\nTrainable params: 123\r\nNon-trainable params: 16\r\n____________________________________________________________________________________________________________________________________________\r\nAbout to convert and test working fully convolutional model\r\n[{'name': 'image_sequence', 'index': 0, 'shape': array([  1, 256, 128,   1], dtype=int32), 'shape_signature': array([-1, -1, -1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n[{'name': 'Identity', 'index': 9, 'shape': array([  1, 256, 128,   3], dtype=int32), 'shape_signature': array([-1, -1, -1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\nTest data shape:  (1, 256, 128, 1)\r\nTF model output shape:  (1, 256, 128, 3)\r\nTF lite model output shape:  (1, 256, 128, 3)\r\nModel: \"functional_3\"\r\n____________________________________________________________________________________________________________________________________________\r\nLayer (type)                                                   Output Shape                                            Param #              \r\n============================================================================================================================================\r\nimage_sequence (InputLayer)                                    [(None, None, None, None, 1)]                           0                    \r\n____________________________________________________________________________________________________________________________________________\r\nconv_lst_m2d (ConvLSTM2D)                                      (None, None, None, 8)                                   2624                 \r\n____________________________________________________________________________________________________________________________________________\r\nbatch_normalization_1 (BatchNormalization)                     (None, None, None, 8)                                   32                   \r\n____________________________________________________________________________________________________________________________________________\r\nconv2d_2 (Conv2D)                                              (None, None, None, 3)                                   27                   \r\n============================================================================================================================================\r\nTotal params: 2,683\r\nTrainable params: 2,667\r\nNon-trainable params: 16\r\n____________________________________________________________________________________________________________________________________________\r\nAbout to convert and test failing fully convolutional LSTM model\r\n[{'name': 'image_sequence', 'index': 0, 'shape': array([  1,   3, 256, 128,   1], dtype=int32), 'shape_signature': array([-1, -1, -1, -1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n[{'name': 'Identity', 'index': 37, 'shape': array([1, 1, 1, 3], dtype=int32), 'shape_signature': array([-1, -1, -1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\nTest data shape:  (1, 3, 256, 128, 1)\r\nTF model output shape:  (1, 256, 128, 3)\r\nRuntime Error Caught: Fill dimensions must be >= 0Node number 5 (FILL) failed to invoke.\r\n```", "comments": ["Please let me know if there's anything else I can do to help resolve this problem. I am trying to run a model with Conv2DLstms in a compute-constrained environment and would like to help resolve this problem ASAP. Just wanted to reiterate this in case it gets lost in the noise of the above message.\r\n\r\nOn another note, TFLite support for Conv2DLstms seems like it was added very recently, but supposedly support exists. Details on that can be found here https://github.com/tensorflow/tensorflow/issues/38220", "After some research, I found this issue where the user manually resized output tensors as well as input tensors (https://github.com/tensorflow/tensorflow/issues/37012). I tried this and that obviously fixed the issue of the output tensor size not being automatically adjusted when the input tensor size changes, but unfortunately it does not fix the issue of `Runtime Error Caught: Fill dimensions must be >= 0Node number 5 (FILL) failed to invoke.` being thrown when invoke() is called. For completeness, I'm adding the updated test script with this change below:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\n\r\n# a function to convert the input tensorflow model to a tflite model and test the models\r\n# with some test data\r\ndef convert_and_test(model, test_data, output_data_shape):    \r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\n    # this is needed to convert tf.Slice, see https://github.com/tensorflow/tensorflow/issues/35590\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                           tf.lite.OpsSet.SELECT_TF_OPS]\r\n    tflite_model = converter.convert()\r\n\r\n    interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n\r\n    # since model has dynamic input shape, we need to reshape the input and output tensor each time that shape changes\r\n    # output needs to be manually resized as well, see https://github.com/tensorflow/tensorflow/issues/37012\r\n    interpreter.resize_tensor_input(input_details[0]['index'], test_data.shape)\r\n    interpreter.resize_tensor_input(output_details[0]['index'], output_data_shape)\r\n    interpreter.allocate_tensors()\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n    \r\n    # print IO details after resizing and tensor allocation\r\n    print(input_details)\r\n    print(output_details)\r\n\r\n    # Test regular model on data\r\n    tf_results = model(test_data)\r\n    \r\n    # verify shape is correct\r\n    print('Test data shape: ', test_data.shape)\r\n    print('TF model output shape: ', tf_results.shape)\r\n    \r\n    # Test the model\r\n    interpreter.set_tensor(input_details[0]['index'], test_data)\r\n    \r\n    try:\r\n        interpreter.invoke()\r\n\r\n        # get output if inference was successful\r\n        tflite_results = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n        # verify shape is correct\r\n        print('TF lite model output shape: ', tflite_results.shape)\r\n\r\n        # Compare model results\r\n        for tf_result, tflite_result in zip(tf_results, tflite_results):\r\n            np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)\r\n\r\n    except RuntimeError as err:\r\n        print('Runtime Error Caught: %s' % err)\r\n\r\n\r\n# define two helper functions for creating conv2d and conv2dlstms with some\r\n# common features\r\ndef _conv_lstm(filters, kernel_size, dilation_rate, return_sequences):\r\n    conv_layer = layers.ConvLSTM2D(filters=filters, \r\n                                    kernel_size=kernel_size,\r\n                                    strides=(1, 1),\r\n                                    padding='same',\r\n                                    data_format='channels_last',\r\n                                    dilation_rate=dilation_rate,\r\n                                    activation='relu',\r\n                                    recurrent_activation='hard_sigmoid',\r\n                                    return_sequences=return_sequences)\r\n    return conv_layer\r\n\r\ndef _conv(filters, kernel_size, dilation_rate):\r\n    conv_layer = layers.Conv2D(filters=filters, \r\n                                    kernel_size=kernel_size,\r\n                                    strides=(1, 1),\r\n                                    padding='same',\r\n                                    data_format='channels_last',\r\n                                    dilation_rate=dilation_rate,\r\n                                    activation='relu')\r\n    return conv_layer\r\n\r\n# not important for this example, some arbitrary value\r\nnum_classes = 3\r\n\r\n# define a model that DOES work\r\nworking_inputs = keras.Input(shape=(None, None, 1), name='image_sequence')\r\nworking_conv_1 = _conv(filters=8, kernel_size=(3, 3), dilation_rate=(1, 1))(working_inputs)\r\nworking_conv_bn_1 = layers.BatchNormalization()(working_conv_1)\r\nworking_outputs = layers.Conv2D(filters=num_classes, \r\n                        kernel_size=(1, 1),\r\n                        strides=(1, 1),\r\n                        padding='same',\r\n                        data_format='channels_last',\r\n                        dilation_rate=(1, 1),\r\n                        activation=None)(working_conv_bn_1)\r\nworking_model = keras.Model(inputs=working_inputs, outputs=working_outputs)\r\nworking_model.summary(line_length=140)\r\n\r\n# create some data to test model with\r\nbatch_size = 1\r\nwidth = 256\r\nheight = 128\r\nchannels = 1\r\nworking_data = np.random.rand(batch_size, width, height, channels).astype(np.float32)\r\noutput_shape = (batch_size, width, height, num_classes)\r\n\r\n# show that model fails to invoke\r\nprint('About to convert and test working fully convolutional model')\r\nconvert_and_test(working_model, working_data, output_shape)\r\n\r\n# define a model that DOES NOT work\r\nfailing_inputs = keras.Input(shape=(None, None, None, 1), name='image_sequence')\r\nfailing_conv_lstm_1 = _conv_lstm(filters=8, kernel_size=(3, 3), dilation_rate=(1, 1), return_sequences=False)(failing_inputs)\r\nfailing_conv_lstm_bn_1 = layers.BatchNormalization()(failing_conv_lstm_1)\r\nfailing_outputs = layers.Conv2D(filters=num_classes, \r\n                                kernel_size=(1, 1),\r\n                                strides=(1, 1),\r\n                                padding='same',\r\n                                data_format='channels_last',\r\n                                dilation_rate=(1, 1),\r\n                                activation=None)(failing_conv_lstm_bn_1)\r\n\r\nfailing_model = keras.Model(inputs=failing_inputs, outputs=failing_outputs)\r\nfailing_model.summary(line_length=140)\r\n\r\n# create some data to test model with\r\n# since we are using Conv2dLstms here, dimension 1 (0-based) is sequence length\r\nseq_len = 3\r\nfailing_data = np.random.rand(batch_size, seq_len, width, height, channels).astype(np.float32).astype(np.float32)\r\noutput_shape = (batch_size, width, height, num_classes)\r\n\r\n# show that model fails to invoke\r\nprint('About to convert and test failing fully convolutional LSTM model')\r\nconvert_and_test(failing_model, failing_data, output_shape)\r\n```", "I am able to replicate the issue faced, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/aedeb27168af0e2632d83292222044f5/untitled387.ipynb)", "I found another bug related to this. I decided to try using fixed input size instead of dynamic sizes. This works as expected for Conv2D, but causes a segmentation fault for Conv2DLstm's. Here is the associated code:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\n\r\n# a function to convert the input tensorflow model to a tflite model and test the models\r\n# with some test data\r\ndef convert_and_test(model, test_data):    \r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\n    # this is needed to convert tf.Slice, see https://github.com/tensorflow/tensorflow/issues/35590\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                           tf.lite.OpsSet.SELECT_TF_OPS]\r\n    tflite_model = converter.convert()\r\n\r\n    interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n    \r\n    # print IO details\r\n    print(input_details)\r\n    print(output_details)\r\n    \r\n    # models have fixed input size, so no need to resize the input/output tensors\r\n    interpreter.allocate_tensors()\r\n    \r\n    # Test regular model on data\r\n    tf_results = model(test_data)\r\n    \r\n    # verify shape is correct\r\n    print('Test data shape: ', test_data.shape)\r\n    print('TF model output shape: ', tf_results.shape)\r\n    \r\n    # Test the model\r\n    interpreter.set_tensor(input_details[0]['index'], test_data)\r\n    \r\n    try:\r\n        interpreter.invoke()\r\n\r\n        # get output if inference was successful\r\n        tflite_results = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n        # verify shape is correct\r\n        print('TF lite model output shape: ', tflite_results.shape)\r\n\r\n        # Compare model results\r\n        for tf_result, tflite_result in zip(tf_results, tflite_results):\r\n            np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)\r\n\r\n    except RuntimeError as err:\r\n        print('Runtime Error Caught: %s' % err)\r\n\r\n\r\n# define two helper functions for creating conv2d and conv2dlstms with some\r\n# common features\r\ndef _conv_lstm(filters, kernel_size, dilation_rate, return_sequences):\r\n    conv_layer = layers.ConvLSTM2D(filters=filters, \r\n                                    kernel_size=kernel_size,\r\n                                    strides=(1, 1),\r\n                                    padding='same',\r\n                                    data_format='channels_last',\r\n                                    dilation_rate=dilation_rate,\r\n                                    activation='relu',\r\n                                    recurrent_activation='hard_sigmoid',\r\n                                    return_sequences=return_sequences)\r\n    return conv_layer\r\n\r\ndef _conv(filters, kernel_size, dilation_rate):\r\n    conv_layer = layers.Conv2D(filters=filters, \r\n                                    kernel_size=kernel_size,\r\n                                    strides=(1, 1),\r\n                                    padding='same',\r\n                                    data_format='channels_last',\r\n                                    dilation_rate=dilation_rate,\r\n                                    activation='relu')\r\n    return conv_layer\r\n\r\n# not important for this example, some arbitrary value\r\nnum_classes = 3\r\n\r\n# define a model that DOES work\r\nbatch_size = 1\r\nwidth = 256\r\nheight = 128\r\nchannels = 1\r\n\r\n# using fixed input sizes with regular Conv2D layers is successful\r\nworking_inputs = keras.Input(shape=(width, height, channels), name='image_sequence')\r\nworking_conv_1 = _conv(filters=8, kernel_size=(3, 3), dilation_rate=(1, 1))(working_inputs)\r\nworking_conv_bn_1 = layers.BatchNormalization()(working_conv_1)\r\nworking_outputs = layers.Conv2D(filters=num_classes, \r\n                        kernel_size=(1, 1),\r\n                        strides=(1, 1),\r\n                        padding='same',\r\n                        data_format='channels_last',\r\n                        dilation_rate=(1, 1),\r\n                        activation=None)(working_conv_bn_1)\r\nworking_model = keras.Model(inputs=working_inputs, outputs=working_outputs)\r\nworking_model.summary(line_length=140)\r\n\r\n# create some data to test model with\r\nworking_data = np.random.rand(batch_size, width, height, channels).astype(np.float32)\r\n\r\n# show that model fails to invoke\r\nprint('About to convert and test working fully convolutional model')\r\nconvert_and_test(working_model, working_data)\r\n\r\n# define a model that DOES NOT work\r\n# since we are using Conv2dLstms here, dimension 1 (0-based) is sequence length\r\nseq_len = 3\r\n\r\n# using fixed input sizes with Conv2DLstms layers results in a seg fault\r\nfailing_inputs = keras.Input(shape=(seq_len, width, height, channels), name='image_sequence')\r\nfailing_conv_lstm_1 = _conv_lstm(filters=8, kernel_size=(3, 3), dilation_rate=(1, 1), return_sequences=False)(failing_inputs)\r\nfailing_conv_lstm_bn_1 = layers.BatchNormalization()(failing_conv_lstm_1)\r\nfailing_outputs = layers.Conv2D(filters=num_classes, \r\n                                kernel_size=(1, 1),\r\n                                strides=(1, 1),\r\n                                padding='same',\r\n                                data_format='channels_last',\r\n                                dilation_rate=(1, 1),\r\n                                activation=None)(failing_conv_lstm_bn_1)\r\n\r\nfailing_model = keras.Model(inputs=failing_inputs, outputs=failing_outputs)\r\nfailing_model.summary(line_length=140)\r\n\r\n# create some data to test model with\r\nfailing_data = np.random.rand(batch_size, seq_len, width, height, channels).astype(np.float32).astype(np.float32)\r\n\r\n# show that model fails to invoke\r\nprint('About to convert and test failing fully convolutional LSTM model')\r\nconvert_and_test(failing_model, failing_data)\r\n```", "@jvishnuvardhan @Saduf2019 My team is trying to make some system design decisions that would be influenced by the resolution of this issue. We were hoping we could get a rough estimate of the timeline for resolving this. Do either of you have any idea what that looks like? Please let me know, and thank you!", "@jatkinson-CRL I am not able to reproduce the segmentation fault. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/3e1f69738ca5885787117c99f2cbdb7e/untitled15.ipynb). \r\n\r\nOnly one change. I am using recent `tf-nightly` whereas you are using `TF2.3`.\r\n\r\nCan you please verify once and let us know whether there is anything missing? Thanks!", "@jvishnuvardhan Thanks for getting back to me so quickly! Very interesting, you are correct that this works with `tf-nightly`. I was able to reproduce on my local machine with nightly build from 5 days ago. However, it is still highly desirable that dynamic input sizes are supported, and `tf-nightly` still fails with that.\r\n\r\nI'm a bit nervous about using `tf-nightly` in production for our systems. Is there a release planned any time soon that would contain at least this fixed size input inference functionality?", "@jvishnuvardhan Another thing I am noticing with `tf-nightly`, the output details for the Conv2DLstm model with fixed input size are still wrong.\r\n\r\n```\r\n[{'name': 'Identity', 'index': 35, 'shape': array([1, 1, 1, 3], dtype=int32), 'shape_signature': array([-1, -1, -1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n```\r\n\r\nThis indicates that the output shape is [1, 1, 1, 3]. This does not seem to affect the actual output size of the model, as the output from inference is indeed the same shape as the input. Besides the sequence length dimension being dropped, they are both [1, 256, 128, 3] in these examples. On the contrary, the output shape in the output details for the Conv2D model is correctly [1, 256, 128, 3]. Perhaps this is related to the error when using dynamic input sizes with Conv2DLstms?", "Renjie, can you take a look\r\n\r\nThanks", "Hi Jatkinson,\r\n\r\nIt seems the input shape is not fixed?\r\n\r\nCan you try set the fixed input size and try again?\r\n\r\nthanks", "@renjie-liu Yes, this works properly with fixed input sizes in tf-nightly. The issue is that it does not support dynamic input sizes. The most important of these is the sequence length. Conv2DLstm supports these in regular tensorflow. Furthermore, Conv2D supports dynamic input (width, height, channels) sizes in TFLite, so why does Conv2DLstm not? There should be no error with dynamic input shapes.", "I see, it's probably some ops does not support this behavior, do you have the converted tflite model that we can take a look?\r\n\r\nthanks", "@renjie-liu There are numerous examples above that will produce a converted TFLite model exhibiting this problem. @Saduf2019 was nice enough to create a gist of one of these examples, that can be found here https://colab.research.google.com/gist/Saduf2019/aedeb27168af0e2632d83292222044f5/untitled387.ipynb. If you really still need just a model file then I can save and upload a model converted by one of the above scripts, please let me know.", "Thanks for the snippet, it looks like the issue is related to TensorArray has fixed [1, -1, -1, 8].\r\n\r\nHaoliang & YC, do you have any idea how to fix the issue?\r\n", "@renjie-liu Any update on this? Please let me know, and thanks.", "Haoliang, Can you help take a look? Thanks!", "@renjie-liu Hi, I'm also facing the same issue while using simple LSTM layer with dynamic input size.\r\n\r\n```\r\nInternal error: Failed to run on the given interpreter: Fill dimensions must be >= 0\r\nNode number 22 (FILL) failed to invoke\r\n```\r\n\r\nWhen I look for tensor details of the interpreter, I find this to be the only layer with the name 'fill'\r\n\r\n{'name': 'tfl.fill',\r\n  'index': 43,\r\n  'shape': array([1, 1, 1, 1]),\r\n  'shape_signature': array([-1, -1, -1, -1]),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32),\r\n   'quantized_dimension': 0},\r\n  'sparsity_parameters': {}}\r\n\r\nfrom the error I guess that shape_signature being negative is probably the problem.\r\n\r\nThe fill tensor is absent in tensor details when I'm using fixed input size and the problem doesn't appear. Any input on how to fix this issue while having dynamic input size will be very helpful.", "@jatkinson-CRL Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42564\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42564\">No</a>\n"]}]