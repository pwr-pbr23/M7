[{"number": 16871, "title": "Request For Tagalog Translation", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI want to help in the Translation for Tagalog version so that this project will be available in our country. Hope you'll grant my request.\r\n\r\n### Source code / logs\r\n", "comments": ["@MarkDaoust is it possible for external contributors to help with docs translations?", "We're working on a plan for translation infrastructure. It's something we know we need to do. I'm closing this since we don't need a bug per language.  \r\n\r\n@ewilderj do you know of any community translation efforts in the mean time?", "@MarkDaoust I haven't any personal experience with it, but Red Hat has a tool called Zanata that can be used for both docs and software http://zanata.org/\r\n\r\nI am very interested in how we can organize community contribution to documentation. We have a large opportunity with China, for instance.\r\n", "FYI we just released our [ML course](https://developers.google.com/machine-learning/crash-course/?hl=es-419)."]}, {"number": 16870, "title": "Improve shape function of SampleDistortedBoundingBox and fix some test cases", "body": "This fix tries to improve the shape function of SampleDistortedBoundingBox and fix several test case errors.\r\n\r\nAs is shown in the kernel of SampleDistortedBoundingBox, the shape of SampleDistortedBoundingBox are required to be 1-D `[height, width, channels]` for image_size, 3-D with shape `[batch, N, 4]` for bounding_boxes. \r\n\r\nIn the test case, the uses shape is incorrect but because there was no check in shape function, the test case passes. (The test case only works for shape but will thrown out an error if run)\r\n\r\nThis fix adds the shape check for SampleDistortedBoundingBox, and fixes the incorrect test cases.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 16869, "title": "Fix broken link in CONTRIBUTING.md", "body": "This fix fixes the broken link in CONTRIBUTING.md.\r\n\r\nWithout `https://`, the markdown will render the link incorrectly to (404):\r\nhttps://github.com/tensorflow/tensorflow/blob/master/www.docker.com\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 16868, "title": "Backpropagation/weight update issue with custom layer", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win 10\r\n- **TensorFlow installed from (source or binary)**: From pip (binary)\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**:---\r\n- **GCC/Compiler version (if compiling from source)**:----\r\n- **CUDA/cuDNN version**:None\r\n- **GPU model and memory**:None\r\n- **Exact command to reproduce**:See source code\r\n\r\n### Describe the problem\r\nI am attempting to implement a custom layer. The layer uses the Image to Patch function and simple tensorflow operator. The layer is implemented in keras to simplify the model building and training but the backend is in tensorflow.\r\n\r\nI am using a simple cnn as a benchmark, whenever I implement my custom layer ( even only as the first layer to 'encode' the data) backpropagation seems to break as no weights get updated in the entirety of the model.\r\n\r\nFrom my understanding the all the operations used (mult, div, add, minus) are differentiable and things such as reshape, transpose and extract_image_patches should not prevent backpropagation and weight updates.\r\n\r\nI tried using the basic layer building method and inheriting from the convolution class (_Conv) and both cases prevent the weight update for the whole model, but such a thing shouldn't be the case.\r\n\r\n### Source code / logs\r\n\r\nPrototype layer: https://github.com/roya0045/cvar2/blob/master/tfvar.py\r\nModel builder: https://github.com/roya0045/cvar2/blob/master/test2.py", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 16867, "title": "How to redirect tfdbg dumping directory", "body": "By default, `tfdbg` dumps saved tensors to `/tmp`, but in my case, `/tmp` is mount in `/root `, `/root` has only several G's space, running the example debug is not a problem, but when debugging large network, for which in one run will generate tensors that exceeds 10 G's memory, it would prompts space not enough.", "comments": ["The constructors `LocalCLIDebugWrapperSession` and `LocalCLIDebugHook` both have a keyword argument called `dump_root`, which allows you to specify where to dump the debug data.\r\n\r\nSee:\r\nhttps://www.tensorflow.org/api_docs/python/tfdbg/LocalCLIDebugWrapperSession#__init__\r\nhttps://www.tensorflow.org/api_docs/python/tfdbg/LocalCLIDebugHook#__init__"]}, {"number": 16866, "title": "Support for Android Gradle Plugin 2.3.3", "body": "Hello folks, \r\n\r\nTrying to use Tensorflow lite (compiled manually) with android gradle plugin 2.3.3,  I get the following error: \r\n\r\n> Error:Error converting bytecode to dex:\r\n> Cause: Dex cannot parse version 52 byte code.\r\n> This is caused by library dependencies that have been compiled using Java 8 or above.\r\n> If you are using the 'java' gradle plugin in a library submodule add \r\n> targetCompatibility = '1.7'\r\n> sourceCompatibility = '1.7'\r\n> to that submodule's build.gradle file.\r\n\r\nI do understand that there's the 3.0.1 version and it work, but it has many breaking changes and it is not trivial to bump the plugin version. It there any workaround or is there support for 2.3.3 on the road map?\r\n\r\nThanks!", "comments": ["Hi folks, It there any update on this?", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, I'm having the same problem. Are there any updates regarding this issue?", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 50 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 65 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 80 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 95 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Is this still an issue, could you move to 3.0.1 ?"]}, {"number": 16865, "title": "tensorflow 1.6.0 built from sources: No module named 'tensorflow.python' ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- ** OS **: Linux Ubuntu 16.04\r\n- **TensorFlow installed  **: from source\r\n- **TensorFlow version **: 'v1.5.0-2271-gf7f7036', 1.6.0-rc0\r\n- **Python version **: 3.6\r\n- **Bazel version **: 0.10.0\r\n- **GCC/Compiler version **: 5.0.4\r\n- **CUDA/cuDNN version **: 9.1/ 7.0.5\r\n- **GPU model and memory **: NVIDIA Titan V 12 Gb (2X)\r\n- **Exact command to reproduce**: among others 'from tensorflow.python.client import device_lib'\r\n### Describe the problem\r\nBug: \r\n\r\nI have installed tensorflow from source today (Feb 8, 2018). It all worked with the installation but when I (in ipython) run the command:\r\n```\r\nIn[1]: from tensorflow.python.client import device_lib\r\n\r\nImportError: No module named 'tensorflow.python'  \r\n```\r\n\r\nIt is a piece of code from Keras' training_utils.py which I use to check if tensorflow 'sees' both my gpus. Of course it is giving the error every time the module tensorflow.python should be imported.\r\n\r\n### Source code / logs\r\n```\r\ndef _get_available_devices():\r\n       from tensorflow.python.client import device_lib\r\n       local_device_protos = device_lib.list_local_devices()\r\n       return [x.name for x in local_device_protos]\r\n```\r\n\r\nif I check myself if there is a python there:\r\n\r\n```\r\n(tfcuda9.1) hanneke@hyperion:~/anaconda3/envs/tfcuda9.1/lib/python3.6/site-packages/tensorflow$ ls\r\naux-bin  core      include      libtensorflow_framework.so  python\r\ncontrib  examples  __init__.py  __pycache__                 tools\r\n\r\n```\r\nhere is a link to how I installed tensorflow as well as cuda and cudnn:\r\nhttps://github.com/hannekevandijk/InstallingHyperion/blob/master/cuda-tf_installfromsources.py", "comments": ["Hi again,\r\n\r\nIssue solved, I found out that when I ran it in python it worked --> so something wrong in my conda environment. The ipython I ran was the one that was installed in the root environment. So when I installed it in the tfcuda9.1 environment, it worked! Very happy running the newest of the newest! thanks for all the work!\r\n\r\nBest,\r\n\r\nHanneke"]}, {"number": 16864, "title": "CPU execution of ops after gradient clipping on windows", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**:1.5.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:CUDA 9.0, cuDNN 7\r\n- **GPU model and memory**: Titan xp, 12gb\r\n- **Exact command to reproduce**: Script attached below\r\n\r\n### Describe the problem\r\nAdding gradient clipping as follows places certain ops on the CPU greatly increasing training time on windows.\r\n```python\r\n    grads = tf.gradients(loss, tf.trainable_variables())\r\n    omnomed_grads, _ = tf.clip_by_global_norm(grads, 0.5)\r\n    train_op = optimizer.apply_gradients(zip(omnomed_grads,  tf.trainable_variables()))\r\n```\r\nI worte a [script](https://github.com/Dhruv-Mohan/G_clip_issue/blob/master/Gptest.py)  to perform a few tests:\r\n\r\n| OS        | TF Version           | Gradient clipping  | Average runtime (m:s.ms) |\r\n| :-------------: |:-------------:| :-----:| :--------: |\r\n| Windows10           | 1.6  | True   | 2:13.57    |\r\n| Windows10           | 1.6  |  False | 0:16.24    |\r\n| Windows10           | 1.5  | True   | 2:13.46    |\r\n| Windows10           | 1.5  |  False | 0:16.52    |\r\n| Windows10           | 1.2  |  True  | 0:24.64    |\r\n| Windows10           | 1.2  |  False | 0:23.80    |\r\n| Linux mint 18.1     | 1.5  | True   | 0:23.45    |\r\n|Linux mint 18.1      | 1.5  |  False | 0:21.29    |\r\n\r\nCuriously the issue isn't present on TF1.2\r\n\r\nForcing operation placement on the GPU:\r\n```python\r\n    with tf.device('/gpu:0'):\r\n        grads = tf.gradients(loss, tf.trainable_variables())\r\n        omnomed_grads, _ = tf.clip_by_global_norm(grads, 0.5)\r\n        train_op = optimizer.apply_gradients(zip(omnomed_grads,  tf.trainable_variables()))\r\n```\r\nresults in the following error on windows:\r\n `Cannot assign a device for operation 'gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.`\r\nThe error generated is similar to [#2803](https://github.com/tensorflow/models/issues/2803) and [#3118](https://github.com/tensorflow/models/issues/3118)\r\n\r\nSetting soft device placement in session configuration results in similar runtime.\r\n\r\n### Source code / logs\r\nI have attached the device placement logs of windows 10 running TF 1.6 [with](https://github.com/tensorflow/tensorflow/files/1707039/Windows_gradclip.txt) and [without](https://github.com/tensorflow/tensorflow/files/1707040/Windows_nogradclip.txt) gradient clipping as well as the device placement logs from Linux mint [with](https://github.com/tensorflow/tensorflow/files/1707038/Mint_gradclip.txt) gradient clipping\r\n\r\n\r\n\r\nA few discrepancies with respect to op placement while gradient clipping are highlighted below:\r\n\r\n| Windows10        |  Linux mint        |\r\n| :-------------: |:-------------:| \r\n| gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax: (LogSoftmax): /job:localhost/replica:0/task:0/device:CPU:0     | gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax: (LogSoftmax): /job:localhost/replica:0/task:0/device:GPU:0 | \r\n| global_norm/L2Loss_6: (L2Loss): /job:localhost/replica:0/task:0/device:CPU:0      | global_norm/L2Loss_6: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0      | \r\n|gradients/conv2d/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter): /job:localhost/replica:0/task:0/device:CPU:0 | gradients/conv2d/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter): /job:localhost/replica:0/task:0/device:GPU:0      | \r\n| gradients/conv2d/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0   | gradients/conv2d/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0   |\r\n| clip_by_global_norm/mul_8: (Mul): /job:localhost/replica:0/task:0/device:CPU:0 | clip_by_global_norm/mul_8: (Mul): /job:localhost/replica:0/task:0/device:GPU:0 |\r\n\r\n\r\n\r\n\r\n", "comments": ["Did you ever make any progress with this? I've had the same issue myself and it seems to be exactly this happening.", "Sorry, haven't made any progress on this issue. I switched training of networks to Linux to mitigate the problem.\n________________________________\nFrom: Jonas Adler <notifications@github.com>\nSent: Monday, March 12, 2018 7:36 PM\nTo: tensorflow/tensorflow\nCc: Dhruv Mohan; Author\nSubject: Re: [tensorflow/tensorflow] CPU execution of ops after gradient clipping on windows (#16864)\n\n\nDid you ever make any progress with this? I've had the same issue myself and it seems to be exactly this happening.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/16864#issuecomment-372435962>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AKxUgkvfQZG75y4_fCqvS25cU-anAMcDks5tds5RgaJpZM4R-Tnm>.\n", "I also have this problem, it seems that there are only CPU kernels for solfmax...\r\nCode:\r\n![image](https://user-images.githubusercontent.com/8580553/38312187-a7c93f52-3853-11e8-92a7-d6a0a2dac2c2.png)\r\nResult:\r\n![image](https://user-images.githubusercontent.com/8580553/38312131-886bc3d2-3853-11e8-917c-cac4c3fd4a58.png)\r\n\r\nI am using tensorflow-1.7.0-rc1 (GPU version from pip) on Windows 10, with GTX 1080Ti card. This is bad  for me since all other ops of my graph is on GPU......", "A tradeoff is to define your own softmax:\r\n```\r\ndef my_softmax(logits, axis = -1):\r\n    tmp = tf.exp(logits)\r\n    return tmp / tf.reduce_sum(tmp, axis, keepdims = True)\r\n```", "Is there any chance for an update on this? This bug is basically rendering a lot of my old code un-usable since it takes weeks to run it. And dropping the clipping changes its behavior.", "Hi @Dhruv-Mohan ! 1.x versions are not supported any more. Have you checked this issue in 2.7 version onward? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 16863, "title": "R1.5", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->"]}, {"number": 16862, "title": "No package nasm", "body": "no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2]", "comments": ["The link http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2 is not accessible.", "I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "yes", "When trying to build on Ubuntu the 1.6.0-rc1", "When trying to build on Ubuntu the 1.5.0", "As you use Jenkins ans don\u00b4t catch this, you should fix Jenkins too", "The problem is that one of two mirrors for nasm is dead, and the second one is sort some reason problematic. Workaround would be to add one more mirror:\r\n```\r\n      urls = [\r\n          \"https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2\",  \r\n          \"http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2\",\r\n          \"http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2\",\r\n      ]\r\n```\r\nin https://github.com/tensorflow/tensorflow/blob/aed54c857802cc191293e0c4df8bbc9a0a15dca9/tensorflow/workspace.bzl#L216", "AND not adding the new mirror in the first place... bazel is a mess", "Thanks, @Randl!", "I speculate it is connected to jdk version ", "I had an issue when trying to build due to the broken nasm link.\r\n\r\n\r\nHere's the details:\r\n\r\nI am trying to build tensorflow from source (Ubuntu 16.04, x64). I checked out `r1.6`. I am following all of the instructions in the install guide. Everything seems to work fine. Once bazel is installed and I run the build command I receive the error which was given initially by the OP.\r\n\r\n```\r\nno such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2]\r\n```\r\n\r\nThe build is unable to continue at this point. I've run it multiple times, all with the same error. I've found that this is because there is only one working mirror link for the nasm package inside of the bazel config.\r\n\r\nI can confirm that link [`http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2`](http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2) is dead (403 response).\r\n\r\nAdding another mirror [`\"http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2\"`](http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2)  to `tensorflow/workspace.bzl` allowed the build to continue\r\n\r\nThis is all done on the r1.6 branch\r\n", "Facing same issue while running \"bazel run tensorflow/examples/speech_commands:test_streaming_accuracy\".  Any progress ? kindly let us know.", "There is another mirror: https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/workspace.bzl#L214\r\nwhich points to https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2\r\nand that seems to be valid.\r\n\r\n@ZacBlanco @surajitghosh715 : Is that mirror somehow missing from your `workspace.bzl`, or are you unable to fetch from it for some reason?\r\n", "When bazel is building it seems that it requires two working mirrors for the build to continue. So when trying to build off of this branch it only succeeds if there are at least 2 working mirrors in workspace.bzl", "@ZacBlanco : That should not be the case, it should work with any one functional mirror. Can you download `https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2` directly? (Wondering if for some reason your network is unable to reach this mirror either)", "I can download it directly and I tried on the machine. It was able to download it. I remember the error message from bazel specifically mentioned not having two working mirrors and that it wasn't able to continue. It seemed weird at the time.\r\n\r\nSince I was able to work around it by adding a new mirror I'll see if I can repro tomorrow to get the exact error message that bazel produced.", "@asimshankar the mirror is available, by it doesn't work for some reason during build (JDK bug?) ", "I ran the build command from the [source build instructions](https://www.tensorflow.org/install/install_sources)\r\n\r\n```\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nHere is the exact error message produced by bazel \r\n\r\n```\r\nERROR: /home/zac/Documents/tmp_tensorflow/tensorflow/tools/pip_package/BUILD:85:1: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /home/zac/.cache/bazel/_bazel_zac/6e2d33f5ebe4d1fe678418dd2ac2b968/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [GET returned 403 Forbidden, sun.security.validator.ValidatorException: End user tried to act as a CA] and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /home/zac/.cache/bazel/_bazel_zac/6e2d33f5ebe4d1fe678418dd2ac2b968/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [GET returned 403 Forbidden, sun.security.validator.ValidatorException: End user tried to act as a CA]\r\nINFO: Elapsed time: 32.277s\r\nFAILED: Build did NOT complete successfully (128 packages loaded)\r\n```", "bazel should be able to work with a single mirror and I seem to be able to build from source at my end.\r\n\r\n@jart may have some ideas here.\r\n", "I think it might be an error with the JDK like @Randl said. I tried on another machine running 16.04 (the same as the one which failed) and everything passed successfully. I'm not sure what's wrong with the original system. Both have jdk-8 installed which is the one expected by bazel. For some reason it's unable to retrieve the file. I can confirm that it's not a network issue as I can download it with `wget` and `curl` without issue.\r\n\r\nThe IOException is pretty vague and doesn't really tell us what's going on or even where exactly it failed. But either way it could be fixed by either adding another nasm mirror to tensorflow since the other mirror is down anyways.", "@asimshankar I have been facing the same issue as well, not being able to build tensorflow from the source because of the nasm mirror stated as being down by bazel. Where as as @ZacBlanco mentioned accessing it directly or even through `wget ` isn't an issue.\r\n\r\nThis is the ERROR log that I get :\r\n```\r\nERROR: /home/ankit/tensorflow/tensorflow/tools/pip_package/BUILD:85:1: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /home/ankit/.cache/bazel/_bazel_root/9f84e1c1cdd4126540de21f768d56655/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [java.lang.RuntimeException: Could not generate DH keypair, sun.security.validator.ValidatorException: End user tried to act as a CA] and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /home/ankit/.cache/bazel/_bazel_root/9f84e1c1cdd4126540de21f768d56655/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [java.lang.RuntimeException: Could not generate DH keypair, sun.security.validator.ValidatorException: End user tried to act as a CA]\r\nINFO: Elapsed time: 45.407s\r\nFAILED: Build did NOT complete successfully (115 packages loaded)\r\n```\r\n\r\nPlease advise if there is a solution to this issue.\r\n", "@uidp1499 You can apply a quick to this by going in to the tensorflow's [`workspace.bzl` file ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl) and adding another mirror to the nasm package.\r\n\r\nYou can try the URL \r\n\r\n`https://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2`", "@uidp1499 : From the error message: `java.lang.RuntimeException: Could not generate DH keypair, sun.security.validator.ValidatorException: End user tried to act as a CA` it sounds like the JVM (which is required by `bazel`) somehow has a different set of certificates it trusts than say what is being used by `wget`.\r\n\r\nI'm not sure what's happening but could you try something like mentioned in https://github.com/bazelbuild/bazel/issues/4332#issuecomment-364557713 ?", "@ZacBlanco @asimshankar Thanks for your solutions.\r\nI tried the build after adding the URL suggested by @ZacBlanco but was still facing the same error. Following @asimshankar 's solution worked like a charm and I was able to build tensorflow r1.7! The issue was with the Certificates and got resolved after using [this solution](https://github.com/bazelbuild/bazel/issues/4332#issuecomment-364557713) .\r\n\r\nThanks!", "Great to hear, thanks.\r\n\r\nClosing this issue out as it seems to be a JVM configuration issue and not a TensorFlow one, and the solution suggested above seems to work. Feel free to reopen if I'm mistaken. Thanks.", "I have installed tensorflow from source and trying to build speech recognition model given as an example but facing quite similar issue. I tried @asimshankar's solution but getting same error. Kindly have a look:\r\n\r\nbazel run tensorflow/examples/speech_commands:generate_streaming_test_wav\r\n.....................................................................\r\nWARNING: /root/.cache/bazel/_bazel_root/344254e166bd59fbb4a4c82f8b03ffce/external/protobuf_archive/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/344254e166bd59fbb4a4c82f8b03ffce/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nERROR: /root/.cache/bazel/_bazel_root/344254e166bd59fbb4a4c82f8b03ffce/external/jpeg/BUILD:211:1: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /root/.cache/bazel/_bazel_root/344254e166bd59fbb4a4c82f8b03ffce/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [java.lang.RuntimeException: Could not generate DH keypair, sun.security.validator.ValidatorException: End user tried to act as a CA] and referenced by '@jpeg//:simd_x86_64_assemblage23'\r\nERROR: Analysis of target '//tensorflow/examples/speech_commands:generate_streaming_test_wav' failed; build aborted: Loading failed\r\nINFO: Elapsed time: 51.342s\r\nFAILED: Build did NOT complete successfully (78 packages loaded)\r\nERROR: Build failed. Not running target\r\n ", "Same error here. Followed  @asimshankar 's solution, still failed. Any one could help? Thank you.\r\n\r\nERROR: /home/ubuntu/tensorflow/tensorflow/tools/pip_package/BUILD:115:1: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [java.lang.RuntimeException: Could not generate DH keypair, sun.security.validator.ValidatorException: End user tried to act as a CA] and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@nasm//': java.io.IOException: Error downloading [https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2] to /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/nasm/nasm-2.12.02.tar.bz2: All mirrors are down: [java.lang.RuntimeException: Could not generate DH keypair, sun.security.validator.ValidatorException: End user tried to act as a CA]\r\n", "@limitless4 @Danielyijun -- In case you haven't resolved this yet I have a suggestion that might help.\r\n\r\nTry converting the https url into a regular http url. It worked for me once I did that.", "@TrevorBasinger  thank you. I solved the problem following @Randl solution \r\n urls = [\r\n          \"https://mirror.bazel.build/www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2\",  \r\n          \"http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2\",\r\n          \"http://pkgs.fedoraproject.org/repo/pkgs/nasm/nasm-2.12.02.tar.bz2/d15843c3fb7db39af80571ee27ec6fad/nasm-2.12.02.tar.bz2\",\r\n      ]\r\nand your suggestion, :)\r\n", "@Danielyijun can you please let us know in which file of the tensorflow source directory you made the changes. It would be a great help if you give some details.", "Hi,\n\ntensorflow/tensorflow/workspace.bzl\n Line 216.\n\nOn Mon, 30 Apr 2018 at 10:38 PM, limitless4 <notifications@github.com>\nwrote:\n\n> @Danielyijun <https://github.com/Danielyijun> can you please let us know\n> in which file of the tensorflow source directory you made the changes. It\n> would be a great help if you give some details.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16862#issuecomment-385603377>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Ad4SyJu6q_-KRWvpHzIbuitpIYpK6-YKks5tt_TkgaJpZM4R-QkB>\n> .\n>\n-- \n\nBest regards,\nMr.Jun Yi\nEmail: danieyijun332@gmail.com\n", "@asimshankar I believe the tensorflow issue is that one of urls is broken, while the fact the second one doesn't work is JVM's one.", "@Randl : Righto. A contribution to update the broken URL will be welcome :)", "@Randl, @asimshankar, I am facing similar intermittent error while building master:\r\n\r\n`ERROR: /home/j/tensorflow/tensorflow/tools/pip_package/BUILD:117:1: no such package '@nasm//': java.io.IOException: block overrun and referenced by '//tensorflow/tools/pip_package:licenses'`\r\n\r\nI tried all solutions mentioned above, but none has helped. `wget` from all 3 links works.\r\nIs there a way to validate it is JDK bug? ", "@namrata-ibm The \"block overrun\" error can only come from Apache Commons Compress `BZip2CompressorInputStream` (Bazel uses v1.9). I find it very concerning that it'd happen on a valid bz2 file. Maybe @bodewig can help us? He works on Apache Commons Compress. Further context:\r\n\r\n- https://github.com/bazelbuild/bazel/blob/master/src/main/java/com/google/devtools/build/lib/bazel/repository/TarBz2Function.java\r\n- https://github.com/bazelbuild/bazel/blob/master/third_party/BUILD#L120\r\n- https://github.com/bazelbuild/bazel/commit/ed7ced0018dc5c5ebd6fc8afc7158037ac1df00d", "Hi, I've just quickly glanced over the thread but can't find a reference to the file that actually causes the issue or I would have tried to reproduce it myself. If you've got a valid bzip2 file that Compress fails to read and can share it then please open an issue with Apache Commons Compress [in JIRA](https://issues.apache.org/jira/projects/COMPRESS).\r\n\r\nYou may want to check whether things would work with Compress 1.16.1 first, there have been some changes to the stream class in question but I don't recall anybody reporting a \"block overrun\" before.", "Tried upgrading Compress to 1.16.1, still facing same issue intermittently. Raising an issue in JIRA.", "Like I said over in https://issues.apache.org/jira/browse/COMPRESS-453 we really need the file that is causing the issue. An URL would be enough as long as it leads to a reproduceable error.", "I tried added the url as stated above but still get errors: complains about checksum\r\n\r\n```\r\nERROR: /home/rjn/tensorflow/serving/tensorflow_serving/example/BUILD:55:1: no such package '@inception_model//inception': Error downloading [http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, https://mirror.bazel.build/github.com/tensorflow/models/archive/6fc65ee60ac39be0445e5a311b40dc7ccce214d0.tar.gz, https://github.com/tensorflow/models/archive/6fc65ee60ac39be0445e5a311b40dc7ccce214d0.tar.gz] to /home/rjn/.cache/bazel/_bazel_rjn/bf38b43f2a87e13b1fa95c62d4e0f2eb/external/inception_model/nasm-2.12.02.tar.bz2: Checksum was 00b0891c678c065446ca59bcee64719d0096d54d6886e6e472aeee2e170ae324 but wanted 7a908017d60fca54c80405527576f08dbf8d130efe6a53791639ff3b26afffbc and referenced by '//tensorflow_serving/example:inception_saved_model'\r\nERROR: Analysis of target '//tensorflow_serving/example:inception_saved_model' failed; build aborted: no such package '@inception_model//inception': Error downloading [http://www.nasm.us/pub/nasm/releasebuilds/2.12.02/nasm-2.12.02.tar.bz2, https://mirror.bazel.build/github.com/tensorflow/models/archive/6fc65ee60ac39be0445e5a311b40dc7ccce214d0.tar.gz, https://github.com/tensorflow/models/archive/6fc65ee60ac39be0445e5a311b40dc7ccce214d0.tar.gz] to /home/rjn/.cache/bazel/_bazel_rjn/bf38b43f2a87e13b1fa95c62d4e0f2eb/external/inception_model/nasm-2.12.02.tar.bz2: Checksum was 00b0891c678c065446ca59bcee64719d0096d54d6886e6e472aeee2e170ae324 but wanted 7a908017d60fca54c80405527576f08dbf8d130efe6a53791639ff3b26afffbc\r\n\r\n```"]}, {"number": 16861, "title": "ImportError: No module named '_pywrap_tensorflow_internal'", "body": "Using TensorFlow backend.\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     17         try:\r\n---> 18             return importlib.import_module(mname)\r\n     19         except ImportError:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py in _gcd_import(name, package, level)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load(name, import_)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load_unlocked(name, import_)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py in _load_unlocked(spec)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py in module_from_spec(spec)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py in create_module(self, spec)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)\r\n\r\nImportError: DLL load failed: No se puede encontrar el m\u00f3dulo especificado.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     20             return importlib.import_module('_pywrap_tensorflow_internal')\r\n---> 21     _pywrap_tensorflow_internal = swig_import_helper()\r\n     22     del swig_import_helper\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     19         except ImportError:\r\n---> 20             return importlib.import_module('_pywrap_tensorflow_internal')\r\n     21     _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-3b3c8d0b8343> in <module>()\r\n----> 1 from keras.models import Sequential, Model\r\n      2 from keras.layers import *\r\n      3 from keras.layers.advanced_activations import LeakyReLU\r\n      4 from keras.activations import relu\r\n      5 from keras.initializers import RandomNormal\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py in <module>()\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import utils\r\n      4 from . import activations\r\n      5 from . import applications\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py in <module>()\r\n      4 from . import data_utils\r\n      5 from . import io_utils\r\n----> 6 from . import conv_utils\r\n      7 \r\n      8 # Globally-importable utils.\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py in <module>()\r\n      1 from six.moves import range\r\n      2 import numpy as np\r\n----> 3 from .. import backend as K\r\n      4 \r\n      5 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py in <module>()\r\n     81 elif _BACKEND == 'tensorflow':\r\n     82     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 83     from .tensorflow_backend import *\r\n     84 else:\r\n     85     raise ValueError('Unknown backend: ' + str(_BACKEND))\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>()\r\n----> 1 import tensorflow as tf\r\n      2 from tensorflow.python.training import moving_averages\r\n      3 from tensorflow.python.ops import tensor_array_ops\r\n      4 from tensorflow.python.ops import control_flow_ops\r\n      5 from tensorflow.python.ops import functional_ops\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     70 for some common reasons and solutions.  Include the entire stack trace\r\n     71 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 72   raise ImportError(msg)\r\n     73 \r\n     74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: No se puede encontrar el m\u00f3dulo especificado.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nI'm in a anaconda environment.\r\n\r\n**CONDA LIST:**\r\n\r\n(gan) C:\\Users\\ZeroCool22\\faceswap-GAN>conda list\r\n packages in environment at C:\\ProgramData\\Anaconda3\\envs\\gan:\r\n\r\nName                    Version                   Build  Channel\r\nabsl-py                   0.1.10                    <pip>\r\nbackports                 1.0              py36h81696a8_1\r\nbackports.weakref         1.0rc1                   py36_0\r\nbleach                    1.5.0                    py36_0    conda-forge\r\nboost                     1.64.0              py36_vc14_4  [vc14]  conda-forge\r\nboost-cpp                 1.64.0                   vc14_1  [vc14]  conda-forge\r\nbzip2                     1.0.6                    vc14_1  [vc14]  conda-forge\r\nca-certificates           2017.08.26           h94faf87_0\r\ncertifi                   2018.1.18                py36_0\r\nclick                     6.7                       <pip>\r\ncudatoolkit               8.0                           3    anaconda\r\ncudnn                     6.0                           0    anaconda\r\ndecorator                 4.0.11                   py36_0    conda-forge\r\ndlib                      19.4              np112py36_201    conda-forge\r\ndlib                      19.9.0                    <pip>\r\nface-recognition          1.2.1                     <pip>\r\nface-recognition-models   0.3.0                     <pip>\r\nffmpeg                    3.4.1                         1    conda-forge\r\nfreetype                  2.8.1                    vc14_0  [vc14]  conda-forge\r\nh5py                      2.7.1                    py36_2    conda-forge\r\nhdf5                      1.10.1                   vc14_1  [vc14]  conda-forge\r\nhtml5lib                  0.9999999                py36_0    conda-forge\r\nicc_rt                    2017.0.4             h97af966_0\r\nicu                       58.2                     vc14_0  [vc14]  conda-forge\r\nimageio                   2.1.2                    py36_0    conda-forge\r\nintel-openmp              2018.0.0             hd92c6cd_8\r\njpeg                      9b                       vc14_2  [vc14]  conda-forge\r\nkeras                     2.0.9                    py36_0    conda-forge\r\nlibgpuarray               0.7.5                    vc14_0  [vc14]  conda-forge\r\nlibiconv                  1.14                     vc14_4  [vc14]  conda-forge\r\nlibpng                    1.6.34                   vc14_0  [vc14]  conda-forge\r\nlibtiff                   4.0.9                    vc14_0  [vc14]  conda-forge\r\nlibwebp                   0.5.2                    vc14_7  [vc14]  conda-forge\r\nlibxml2                   2.9.3                    vc14_9  [vc14]  conda-forge\r\nmako                      1.0.7                    py36_0    conda-forge\r\nMarkdown                  2.6.11                    <pip>\r\nmarkdown                  2.6.9                    py36_0    conda-forge\r\nmarkupsafe                1.0                      py36_0    conda-forge\r\nmkl                       2018.0.1             h2108138_4\r\nmoviepy                   0.2.3.2                  py36_0    conda-forge\r\nnumpy                     1.14.0                    <pip>\r\nnumpy                     1.12.1           py36hf30b8aa_1    anaconda\r\nolefile                   0.44                     py36_0    conda-forge\r\nopencv                    3.3.0                  py36_200    conda-forge\r\nopenssl                   1.0.2n               h74b6da3_0\r\npillow                    5.0.0                    py36_0    conda-forge\r\npip                       9.0.1                    py36_1    conda-forge\r\nprotobuf                  3.5.1               py36_vc14_3  [vc14]  conda-forge\r\nprotobuf                  3.5.1                     <pip>\r\npygpu                     0.7.5                    py36_0    conda-forge\r\npython                    3.6.4                         0    conda-forge\r\npyyaml                    3.12                     py36_1    conda-forge\r\nqt                        5.6.2                    vc14_1  [vc14]  conda-forge\r\nscipy                     1.0.0            py36h1260518_0\r\nsetuptools                38.5.1                    <pip>\r\nsetuptools                38.4.0                   py36_0    conda-forge\r\nsix                       1.11.0                   py36_1    conda-forge\r\nsix                       1.11.0                    <pip>\r\nsqlite                    3.20.1                   vc14_2  [vc14]  conda-forge\r\ntensorboard               0.4.0rc3                 py36_2    conda-forge\r\ntensorflow-gpu            1.3.0                     <pip>\r\ntensorflow-tensorboard    0.1.8                     <pip>\r\ntheano                    1.0.1                    py36_1    conda-forge\r\ntk                        8.6.7                    vc14_0  [vc14]  conda-forge\r\ntqdm                      4.11.2                   py36_0    conda-forge\r\nvc                        14                            0    conda-forge\r\nvs2015_runtime            14.0.25420                    0    conda-forge\r\nwebencodings              0.5                      py36_0    conda-forge\r\nwerkzeug                  0.14.1                     py_0    conda-forge\r\nWerkzeug                  0.14.1                    <pip>\r\nwheel                     0.30.0                    <pip>\r\nwheel                     0.30.0                   py36_2    conda-forge\r\nwincertstore              0.2                      py36_0    conda-forge\r\nyaml                      0.1.7                    vc14_0  [vc14]  conda-forge\r\nzlib                      1.2.11                   vc14_0  [vc14]  conda-forge\r\n\r\n(gan) C:\\Users\\ZeroCool22\\faceswap-GAN>\r\n------------------------\r\n**tensorflow_self_check.py results:**\r\n\r\n(gan) C:\\Users\\ZeroCool22\\Desktop\\Nueva carpeta (3)>python tensorflow_self_check.py\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.6.\r\n\r\n- TensorFlow is installed at: C:\\ProgramData\\Anaconda3\\envs\\gan\\lib\\site-packages\\tensorflow\r\n\r\n- All required DLLs appear to be present. Please open an issue on the\r\n  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues\r\n\r\n**OS: Windows 10\r\nGPU: 1080TI\r\nCPU: 7700K\r\nRAM: 32gb**", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Is it possible your CPU does not have AVX instruction set?\r\nCould you share your CPU model?", "potential duplicate of #17386", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I get the error below and cannot figure out a way of fixing this issue. Followed the guidlines tep by step on the official website.\r\n\r\nPython 3.6.5\r\nW10\r\nGeforce 1050\r\n\r\nModuleNotFoundError: No module named \r\n\r\n> '_pywrap_tensorflow_internal'\r\n", "Please see https://github.com/tensorflow/tensorflow/issues/16861#issuecomment-371414008.", "will like this topic to be reopened cos over a week now am stuck with this same problem\r\n"]}, {"number": 16860, "title": "Tensorflow-gpu 1.6 : failed call to cuInit: CUDA_ERROR_NO_DEVICE", "body": "\r\n- CUDA 9.0\r\n- Cudnn 7.0\r\n- Tensorflow-gpu 1.6\r\n\r\nnvida-smi is good\r\n![nvidia-smi](https://user-images.githubusercontent.com/2728049/35970141-d827bac6-0cfb-11e8-886f-92b068c62c4e.png)\r\n\r\nError \r\n2018-02-08 18:14:24.768537: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n**2018-02-08 18:14:25.438352: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE**\r\n2018-02-08 18:14:25.441350: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: Vincent\r\n2018-02-08 18:14:25.441633: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_diagnostics.cc:165] hostname: Vincent\r\n2018-02-08 18:14:25.443152: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\direct_session.cc:297] Device mapping:\r\n\r\nDevice mapping: no known devices.\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\r\nb: (Const): /job:localhost/replica:0/task:0/device:CPU:0\r\na: (Const): /job:localhost/replica:0/task:0/device:CPU:0\r\n\r\nCode : \r\n`import os\r\nimport tensorflow as tf\r\n\r\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\r\n\r\nfrom tensorflow.python.client import device_lib\r\n#print (device_lib.list_local_devices())\r\n\r\n# Creates a graph.\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\n# Creates a session with log_device_placement set to True.\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n# Runs the op.\r\nprint(sess.run(c))` ", "comments": ["Try set `CUDA_VISIBLE_DEVICES=0`", "Perfect, it's working. thanks!", "Thanks you very much @qmick  :+1: ", "- Windows 10\r\n\r\nMy case is a bit different. I updated the display card driver and it shows '!'  in device manager. I chose to roll it back and it become normal. Then the error is gone.", "export CUDA_VISIBLE_DEVICES=0,1\r\nworks for me", "adding `--runtime=nvidia` to the docker exec/run command"]}, {"number": 16859, "title": "How to improve tensorflow model accuracy ?", "body": "I have created model for chair by using tensorflow. But that model detecting any object as chair, So how can i improve model to detect only chair. We have provided 300 images of chair for training, Total loss of chair model is less than 0.6.  [this is graph](https://i.stack.imgur.com/5yhW4.png) And also give me information about How to improve accuracy of model to detect only chair.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler \r\n\r\nOS Platform and Distribution :- 16.04 \r\nTensorFlow installed from :- https://www.tensorflow.org/install/install_linux\r\nTensorFlow version :- tensorflow (1.4.1)\r\n                                   tensorflow-tensorboard (0.4.0)\r\nBazel version :- blaze (0.11.3)\r\nCUDA/cuDNN version :-  CUDA 8 and cuDNN 6\r\nGPU model and memory :- GeForce GTX 1050 Ti mini, 4GB GDDR5", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 16858, "title": "Branch 184929151", "body": "Had probably 50-100 files with merge conflicts due to some files being formatted by internal tools during a recent GitHub pull. Pretty sure I fixed all of them correctly though.", "comments": ["Ok, github UI confuses me a ton. I accidentally removed reviewer for this. Added reviewers back."]}, {"number": 16857, "title": "[BUG] seq2seq attention_wrapper use previous alignment?", "body": "When we use attention model, it's recommended to use previous alignment (attention weight).\r\nBut I saw the code in the attention_wrapper.py, it ignore the previous alignment.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L399\r\n\r\n![image](https://user-images.githubusercontent.com/5347113/35961865-202877be-0cea-11e8-8f88-38e638c8e3ad.png)\r\n\r\n@ebrevdo ", "comments": ["Thang will be able to say more; after the ICML deadline.\n\nOn Thu, Feb 8, 2018 at 12:07 AM, Jeremy <notifications@github.com> wrote:\n\n> When we use attention model, it's recommended to use previous alignment\n> (attention weight).\n> Bug I saw the code in the attention_wrapper.py, it ignore the previous\n> alignment.\n>\n> https://github.com/tensorflow/tensorflow/blob/master/\n> tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L399\n>\n> @ebrevdo <https://github.com/ebrevdo>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16857>, or mute the\n> thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxuP55wWz8xABMRf02ZxR000bcEsks5tSqs5gaJpZM4R98Z9>\n> .\n>\n", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Hi all,\r\nSorry for the delay. It has been some time since I looked at this code so I might need time to refresh my memory.\r\n\r\nIn any case, can you help elaborate a bit more @LinJM? We do make use for previous attention information, e.g., this line here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L1374. Does it answer?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 16855, "title": "error reported while using TensorForestEstimator. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'FertileStatsResourceHandleOp' in binary running on...", "body": "Have I written custom code - Yes, but provided code in link also has same problem\r\nOS Platform and Distribution - Windows 7\r\nTensorFlow installed from - PIP install\r\nTensorFlow version - 1.4 and 1.5 both on CPU\r\nBazel version - No bazel version used\r\nCUDA/cuDNN version - N/A\r\nGPU model and memory - N/A\r\nExact command to reproduce - provided a link to python script below to reproduce this issue\r\n\r\n\r\nI am trying to use \"TensorForestEstimator\" defined in \"tensorflow.contrib.tensor_forest.client.random_forest\". I get following error.\r\n\r\nSame error is reported when I run this script\r\nhttps://www.kaggle.com/biscuitlickz/iris-predictions-using-tensorflow/code\r\n\r\nTraceback (most recent call last):\r\n  File \"titanic_random_forest.py\", line 201, in <module>\r\n    app.run(main=main)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"titanic_random_forest.py\", line 136, in main\r\n    est.fit(input_fn=train_input_fn, steps=TRAIN_STEPS)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 316, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 480, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 985, in _train_model\r\n    model_fn_ops = self._get_train_ops(features, labels)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1201, in _get_train_ops\r\n    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1165, in _call_model_fn\r\n    model_fn_results = self._model_fn(features, labels, **kwargs)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\client\\random_forest.py\", line 168, in _model_fn\r\n    device_assigner=dev_assn)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\tensor_forest.py\", line 376, in __init__\r\n    tree_variables_class=tree_variables_class)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\tensor_forest.py\", line 350, in __init__\r\n    self.variables.append(tree_variables_class(params, i, training))\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\tensor_forest.py\", line 318, in __init__\r\n    params, '', self.get_tree_name('stats', tree_num))\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\stats_ops.py\", line 102, in fertile_stats_variable\r\n    container, shared_name=name, name=name)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\tensor_forest\\python\\ops\\gen_stats_ops.py\", line 141, in fertile_stats_resource_handle_op\r\n    shared_name=shared_name, name=name)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3162, in create_op\r\n    compute_device=compute_device)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3208, in _create_op_helper\r\n    set_shapes_for_outputs(op)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2427, in set_shapes_for_outputs\r\n    return _set_shapes_for_outputs(op)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2400, in _set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2330, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\", line 627, in call_cpp_shape_fn\r\n    require_shape_fn)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\", line 686, in _call_cpp_shape_fn_impl\r\n    input_tensors_as_shapes, status)\r\n  File \"F:\\programs-all\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'FertileStatsResourceHandleOp' in binary running on ATWOOD_SRAO. Make sure the Op and Kernel are registered in the binary running in this process.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "required details updated above.", "The same is happening for me on windows 10, same version installed from pip CPU only\r\n", "@caisq can you please take a look?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Hi, any updates on this issue? I am facing the same issue when trying to import a saved model using Python as well as Java bindings. Running the latest tensorflow binaries from pip/maven.", "@gilberthendry, @thomascolthurst could you also take a look into this?", "@nataliaponomareva ", "any update on this? I am getting same error.\r\n\r\n   File \"load_grph.py\", line 20, in load_graph\r\n    tf.import_graph_def(graph_def, name=\"prefix\")\r\n  File \"/home/neva/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 285, in import_graph_def\r\n    raise ValueError('No op named %s in defined operations.' % node.op)\r\nValueError: No op named FertileStatsResourceHandleOp in defined operations.", "There may be a dependency we deleted accidentally. Could you try adding `:stats_ops_py` to `tensorflow/contrib/tensor_forest:model_ops_py`?\r\n", "No, never mind, that dependency is already present there.", "I am getting same error. Anybody fixed it?", "I ran into the same issue.", "I am getting same error. ", "I am getting the same issue", "Does this implementation support multi-label classification?", "Nagging Assignee @caisq: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "+@yupbank", "hi... sorry for not the late reply, the ` Op type not registered '*' in binary` is a know issue in java land, since by default  tf.contrib project `.so` didn't get package within the java distribution can be addessed by `TensorFlow.loadLibrary()` https://github.com/tensorflow/tensorflow/issues/10454#issuecomment-344139462\r\n\r\nMeanwhile, for the tensorflow in python having this kind of error could be soemthing to do with misconfiguration with bazel? i'll have to spend more time into reproduce the error to achieve a conclusion", "@Avtarsingh127 do you mind share me a minimum code snippet to reproduce the error? ", "Hello @yupbank, I'm also having the same problem, I wrote a minimum script that reproduces the error:\r\n\r\n```python\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\r\nfrom tensorflow.contrib.tensor_forest.client import random_forest \r\n\r\ndef main():\r\n    model_dir = './model'\r\n\r\n    params = tensor_forest.ForestHParams(\r\n        num_features=1,\r\n        num_classes=2,\r\n        num_trees=100,\r\n        max_nodes=1000,\r\n    ).fill()\r\n\r\n    classifier = random_forest.TensorForestEstimator(\r\n        params,\r\n        model_dir=model_dir\r\n    )\r\n\r\n    data = pd.DataFrame(data={'x':[2, 3], 'y': [0, 1]})\r\n\r\n    x_train, y_train = data, data.pop('y')\r\n\r\n    input_fn_train = tf.estimator.inputs.pandas_input_fn(\r\n        x=x_train,\r\n        y=y_train,\r\n        batch_size=1,\r\n        num_epochs=100,\r\n        shuffle=True,\r\n        target_column='y'\r\n    )\r\n    \r\n    classifier.fit(input_fn=input_fn_train)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```", "Thank you @lanahra  !! can you have do this \r\n```\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n```", "Unfortunately I'm running on a Windows machine, so I cannot run the environment capture script.\r\n\r\nHere is the second one:\r\n```\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\nC:\\Users\\%USER%\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\h5py\\__init__.py:36:\r\nFutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is\r\ndeprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nb'v1.8.0-0-g93bc2e2072' 1.8.0\r\n```", "sorry guys... according to the latest changes to tensor_forest BUILD file.\r\nhttps://github.com/tensorflow/tensorflow/commit/38e0139329482d8e44629dea2e87853808eacd0d#diff-894ca5f2ae1e390cc3eba58d9e4052ed \r\n\r\nwindows support is not being added for now i guess... \r\n\r\ntf.contrib projects are not officially supported, and may change or be removed at any time without notice.\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib#tensorflow-contrib", "![image](https://user-images.githubusercontent.com/741544/39791504-0c2194c4-530a-11e8-8a40-0c555422c19a.png)\r\n![image](https://user-images.githubusercontent.com/741544/39791528-25a19eda-530a-11e8-9095-d406090bee30.png)\r\n\r\ndll missing from the folder", "i'll close this issue for now, and will try to make more priority to add windows support for tensor_forest", "@yupbank I found the same issue on ubuntu18.04 while trying to read the node info from `.pb` model file in TF 1.14.0, and this error is caused by compilation with Bazel(I tried to fix it, and I found in `tensorflow\\contrib\\tensor_forest\\python\\ops\\_stats_ops.so` the so-called `FertileStatsResourceHandleOp` is already existed), so I guess that your team has fixed that problem on Ubuntu whereas `.dll` problem is still in suspensory status and to make the error messages sync among platforms, however, the same error reported on Ubuntu has solutions. Thus, I worked it out with \r\n```  python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\r\nfrom tensorflow.python.ops import resources\r\n```\r\nand this solution is inspired by https://github.com/aymericdamien/TensorFlow-Examples/issues/212#issuecomment-743026970\r\nIn brief words, if anybody has the same problem (in TF 1) on Win10, they can avoid these errors by using Ubuntu and import proper modules in `tf.contrib`."]}, {"number": 16854, "title": "Fixes two wrong links in install document", "body": "There are two wrong links in install document. This fixes them.\r\n", "comments": []}, {"number": 16853, "title": "Make configure script more lenient to the length of CUDA and cuDNN ve\u2026", "body": "\u2026rsions entered.\r\n\r\nFixes #6446", "comments": []}, {"number": 16852, "title": "cmake flag for Visual Studio", "body": "Add the cmake flag for specifying VS version to r1.6 as well.", "comments": []}, {"number": 16851, "title": "Output of Inceptionv3 slim 2016 tflite model is problematic", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A, this is a bug report of a tflite model released by Google\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any one\r\n- **TensorFlow installed from (source or binary)**: both\r\n- **TensorFlow version (use command below)**: after TF Lite released\r\n- **Python version**: both\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: see descriptions below\r\n\r\nIt seems the output of the [inceptionv3 slim 2016 tflite model released by google](https://storage.googleapis.com/download.tensorflow.org/models/tflite/inception_v3_slim_2016_android_2017_11_10.zip) is problematic. If you run [label_image for tflite](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/label_image/label_image.md), you'll get\r\n\r\n```bash\r\n> ./label_image -m inceptionv3_slim_2016.tflite\r\nLoaded model inceptionv3_slim_2016.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 1009.48 ms \r\n8.06111: 653 military uniform\r\n6.19022: 668 mortarboard\r\n5.83456: 401 academic gown\r\n5.26993: 835 suit\r\n4.80701: 855 theater curtain\r\n```\r\n\r\nIf you convert InceptionV3 yourself, \r\n```bash\r\n> curl http://download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz \\\r\n | tar -C /tmp -xzf -\r\n> bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --  \\\r\n--input_file=/tmp/inception_v3_2016_08_28_frozen.pb  \\\r\n--output_file=/tmp/inceptionv3.tflite   --input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE   --inference_type=FLOAT   --input_shape=1,299,299,3 \\\r\n--input_array=input   --output_array=InceptionV3/Predictions/Reshape_1\r\n```\r\n\r\nand push the /tmp/inceptionv3.tflite to your android devices, then you can see expected results like\r\n\r\n```bash\r\n> ./label_image -m inceptionv3.tflite             \r\nLoaded model inceptionv3.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: 1020.93 ms \r\n0.496246: 653 military uniform\r\n0.0764156: 668 mortarboard\r\n0.0535454: 401 academic gown\r\n0.030444: 835 suit\r\n0.0191629: 855 theater curtain\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "updated for the template", "Nagging Assignee @gargn: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gargn: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gargn: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gargn: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, I am getting following error while trying to run label_image ( tensorflow lite ) with inception tflite model. Any idea what is going wrong ?\r\n\r\n./label_image -m inceptionv3_slim_2016.tflite\r\nLoaded model inceptionv3_slim_2016.tflite\r\nresolved reporter\r\ntensorflow/contrib/lite/kernels/concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (17 != 18)\r\nFailed to allocate tensors!\r\nSegmentation fault (core dumped)\r\n", "@meghna1301: I can reproduce your problem with master branch. I don't know what happened. I guess some changes to TF Lite runtime (after I created this issue) broke files converted by old TOCO (well, even converting with TOCO from master branch has the same dimension problem). Something must be wrong. You should create another issue I think.\r\n\r\n@aselle @rmlarsen FYI, I am not sure if this is problem of `tensorflow/contrib/lite/kernels/concatenation.cc`, I saw your names in the commit log of `concatenation.cc`", "@freedomtan : Thanks so much. When I tried with release branch, it worked perfectly. So, looks like that this issue came after last release ( 1.8).\r\nJust FYI:\r\nI was able to run MobileNet float model on master, however numbers were quite different than what I observed with release branch.\r\n\r\nLog with master: \r\n./label_image -m mobilenet_v1_1.0_224.tflite -c 100\r\nLoaded model mobilenet_v1_1.0_224.tflite\r\nresolved reporter\r\ninvoked \r\naverage time: **1329.38** ms \r\n0.859921: 905 window screen\r\n0.057294: 829 strainer\r\n0.0220685: 557 fire screen\r\n0.0208552: 812 space heater\r\n0.0097825: 795 shower curtain\r\n\r\nlog with r1.8:\r\n\r\n./label_image -m mobilenet_v1_1.0_224.tflite -c 1000\r\nnnapi error: unable to open library libneuralnetworks.so\r\nLoaded model mobilenet_v1_1.0_224.tflite\r\nresolved reporter\r\ninitialized \r\ninitialization time: 4.703 ms \r\ninvoked \r\naverage time: **12.9061 ms** \r\n0.479888: 534 dishrag\r\n0.318539: 825 stole\r\n0.101559: 912 wool\r\n0.0152032: 412 apron\r\n0.013553: 540 doormat\r\n\r\n", "I noticed that the prediction seem wrong with -c != 1. I think this is because the input tensor is not reset for the next invocation and TF Lite will overwrite the input during inference.", "@andrefaraujo yes, for c != 1, when TF Lite runtime is used (NN API runtime is not used), prediction is meaningless. But, I think what @meghna1301  asked is performance. I haven't checked it yet.\r\n\r\n@meghna1301 which platform you used to run this?\r\n", "I can reproduce the performance issue on linux. Will investigate further but it might be due to the removal of the SSE path somewhere.", "@andrefaraujo: yes, it was Ubuntu. Thanks.", "There was a bug in the schema where the default values of dilation width and height factors were set to 0 instead of 1. This incorrect value will cause the slow kernel to be selected. \r\nThis got fixed with recent update to [schema](https://github.com/tensorflow/tensorflow/commit/e41e70ed9827b81a07c42f68def80f3f61b70375#diff-16ca4f2738c3598cf9b1d79b45eed593)\r\nThis should be fixed on master now.", "I use my own model  which has the op:concatenation in tflite on ios.When I use the function of \"ResizeInputTensor\" to resize the input,the similar problem happens,the error is  \r\n\"tensorflow/contrib/lite/kernels/concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (20 != 14).Failed to allocate tensors\".\r\nMy tensorflow is r1.10?? How can I do?", "@zhengnianqing Please file a new issue and provide reproducible steps. Include the code that calls the interpreter and the model file if possible.", "@zhengnianqing did you open a new issue? I am facing the same problem", "@davlhd   No,but I am still facing  the same problem. I think It is brecause when converting the model to tflite,the model recordes some parameters that can not be changed, That's just my guess.You can open a new issue.", "@davlhd @meghna1301 Where did you guys find the right config file for the mobilenet_v1_1.0_224 or which config file did you use? Because when I try to run the training with the other config files, it gives me an error of: ValueError: No variables to save", "@Elites2017 I used a custom model", "Ok. Did you successfully convert it to .tflite? Which custom model did you use?", "It converted but it tells me that\r\n`concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (100 != 50) \"Failed to allocate tensors\"`\r\nIts a proprietary model.", "@davlhd Could you please give me a link to the config file or the pipeline file you edited to config it to train it?", "I am sorry I can't", "ok\r\n\r\n> \r\n> \r\n> I am sorry I can't\r\n\r\nOk", "@davlhd @Elites2017 Can you create new issues with as much information as you can provide to reproduce your issue. Preferably include the code you are using to call the model, the command you are using to convert the model, and any other general information you can provide. If you can provide your model with dummy weights that would also be helpful."]}, {"number": 16850, "title": "concurrent.futures for Python 2 installed with tensorflow-gpu with pip3 ", "body": "We noticed an issue with the tensorflow-gpu package available in pip for Python 3: it leads to `concurrent.futures` for Python 2 being installed as a dependency.\r\n\r\n```\r\n$ jupyter-notebook --no-browser\r\nTraceback (most recent call last):\r\n  File \"/share/software/user/open/py-jupyter/1.0.0_py36/bin/jupyter-notebook\", line 7, in <module>\r\n    from notebook.notebookapp import main\r\n  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/notebook/notebookapp.py\", line 35, in <module>\r\n    from jinja2 import Environment, FileSystemLoader\r\n  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/jinja2/__init__.py\", line 81, in <module>\r\n    _patch_async()\r\n  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/jinja2/__init__.py\", line 77, in _patch_async\r\n    from jinja2.asyncsupport import patch_all\r\n  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/jinja2/asyncsupport.py\", line 13, in <module>\r\n    import asyncio\r\n  File \"/share/software/user/open/python/3.6.1/lib/python3.6/asyncio/__init__.py\", line 21, in <module>\r\n    from .base_events import *\r\n  File \"/share/software/user/open/python/3.6.1/lib/python3.6/asyncio/base_events.py\", line 17, in <module>\r\n    import concurrent.futures\r\n  File \"/share/software/user/open/py-tensorflow/1.5.0_py36/lib/python3.6/site-packages/concurrent/futures/__init__.py\", line 8, in <module>\r\n    from concurrent.futures._base import (FIRST_COMPLETED,\r\n  File \"/share/software/user/open/py-tensorflow/1.5.0_py36/lib/python3.6/site-packages/concurrent/futures/_base.py\", line 381\r\n    raise exception_type, self._exception, self._traceback\r\n                        ^\r\nSyntaxError: invalid syntax\r\n```\r\n\r\nThe workaround is to remove concurrent.futures as it is already included in Python 3 standard library.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: no\r\nOS Platform and Distribution: Linux CentOS 7.4\r\nTensorFlow installed from: pip\r\nTensorFlow version: tensorflow-gpu 1.5.0\r\nBazel version: N/A\r\nCUDA/cuDNN version: 9/7\r\nGPU model and memory: Not relevant here, it's a packaging issue\r\nExact command to reproduce: already provided", "@yifeif do you recall what we did for unittest (and enum), which has a similar problem? A module needed for py2, but not as a dependency for py3?", "I don't think we have `concurrent` as one of our dependencies. Could it be from another package @thiell?", "But we are using it in `grpc_debug_server.py`, so maybe we should have a dependency?", "The dependency only makes sense for Python 2 as `concurrent.futures` has been added to Python 3's standard library (see https://docs.python.org/3/library/concurrent.futures.html and https://www.python.org/dev/peps/pep-3148/).", "We don't have concurrent explicitly listed out in our dependencies (see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py). @caisq do you think we need to add it for `grpc_debug_server.py`?\r\n\r\nCurious how `concurrent` got installed here. I saw grpcio has dependency on `future`, but not `concurrent`. ", "@caisq assigning to you -- please reassign when you answer.", "Still no fix?", "Hi @thiell ! I am not getting any issue while running \"jupyter notebook --no-browser\" with 2.8 GPU and python 3.8 . Can this issue be closed now?", "This is an old issue. Thanks!"]}, {"number": 16849, "title": "GLSTMCell fix", "body": "* Make sure it works correctly for input_size != num_units", "comments": ["@case540 could you please have a look", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@qlzh727 is taking lead on deciding which cells in tf.contrib.rnn to keep.  Scott - PTAL?", "Seems that there is a merge conflict with the existing file, can u rebase to the latest?\r\n\r\nAgree with ebrevdo@ that a unit test is need to demonstrate that the change fixed the specific problem, which will prevent the problem happening from any future change.", "@ebrevdo and @qlzh727 thanks for looking into this!\r\nI've reviewed merge conflicts and apparently someone else has fixed this bug. \r\nThe master looks good. Closing, because nothing needs to change in the code."]}, {"number": 16848, "title": "Dropping the Microsoft from the Visual Studio", "body": "cmake invocation.", "comments": ["This is to 1.5. Is that intentional?"]}, {"number": 16847, "title": "Tensorflow website doesn't show older builds to install using pip", "body": "I was at tensorflow 1.4, upgraded tensorflow to 1.5, had to install cudnn 9.0 and now my system is unstable. I went to the tensorflow website in order to get the tensorflow 1.4 build and noticed that there isn't any reference for these build anymore and now I'm stuck at version 1.5.\r\n\r\nWhere are these references about the .whl files? Seems that the '.../install/install_windows' page is the same for all the versions, which suggest just an '--upgrade'.", "comments": ["Solved this by using  `pip uninstall tensorflow_gpu` and `pip install tensorflow_gpu==1.4.0`, but I think that the document could make this explict. Would save people's time."]}, {"number": 16846, "title": "Remove obsolete BernoulliWithSigmoidProbs", "body": "As was pointed out by #9485, BernoulliWithSigmoidProbs is covered\r\nby Bernoulli and is obsolete. This fix removes BernoulliWithSigmoidProbs.\r\n\r\nThis fix closes #9485.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 16845, "title": "ImportError: DLL load failed: Die angegebene Prozedur wurde nicht gefunden.", "body": "### System information\r\n- Have I written custom code: no\r\n- OS Platform and Distribution: Windows 7, 64-bit\r\n- Tensorflow installed from: Anaconda 5.0.1 via pip 9.0.1\r\n(conda create -p C:\\temp\\tensorflow-gpu; pip install tensorflow-gpu)\r\n- Python 3.5.2\r\n- TensorFlow 1.5.0\r\n- CUDA 9.0\r\n- cuDNN 7.0\r\n- Bazel: N/A\r\n- GPU model and memory: NVIDIA Quadro K620, 2GB\r\n\r\n\r\n### Describe the problem\r\nCommands to reproduce:\r\n```\r\nconda create -p C:\\temp\\tensorflow-gpu\r\nactivate C:\\temp\\tensorflow-gpu\r\npip install tensorflow-gpu\r\npython\r\n> import tensorflow\r\n```\r\n\r\nAfter installing all dependencies, tensorflow fails to import. Exactly the same error occurs with other Tf/CUDA/cuDNN versions (tried TF 1.4.0 + CUDA 7.0 + cuDNN 5.1 and TF 1.4.0 + CUDA 8.0 + cuDNN 6.0).\r\n\r\nWhile searching, I discovered a similar bug, but it contains a different error message: https://github.com/tensorflow/tensorflow/issues/5949\r\n\r\n\r\n### Source code / logs\r\n```\r\n(C:\\temp\\tensorflow-gpu) C:\\temp>python\r\nPython 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v\r\n.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_m\r\nodule\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Die angegebene Prozedur wurde nicht gefunden.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_m\r\nodule\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 2\r\n4, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\__init__.py\",\r\n line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_m\r\nodule\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Die angegebene Prozedur wurde nicht gefunden.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensor\r\nflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\temp\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_m\r\nodule\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_probl\r\nems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>\r\n```\r\n\r\nWhen doing \"import tensorflow\", these dlls are loaded:\r\n```\r\n23:09:18,4934154\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\python.exe\tSUCCESS\tImage Base: 0x1ce20000, Image Size: 0xd000\r\n23:09:18,4935443\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\ntdll.dll\tSUCCESS\tImage Base: 0x77190000, Image Size: 0x1aa000\r\n23:09:18,4940523\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\kernel32.dll\tSUCCESS\tImage Base: 0x77070000, Image Size: 0x11f000\r\n23:09:18,4942051\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\KernelBase.dll\tSUCCESS\tImage Base: 0x7fefd010000, Image Size: 0x6a000\r\n23:09:18,4954354\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\python35.dll\tSUCCESS\tImage Base: 0x60840000, Image Size: 0x3e4000\r\n23:09:18,4962254\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\ws2_32.dll\tSUCCESS\tImage Base: 0x7fefe860000, Image Size: 0x4d000\r\n23:09:18,4963049\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\msvcrt.dll\tSUCCESS\tImage Base: 0x7fefec80000, Image Size: 0x9f000\r\n23:09:18,4965005\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\rpcrt4.dll\tSUCCESS\tImage Base: 0x7fefe560000, Image Size: 0x12d000\r\n23:09:18,4967902\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\nsi.dll\tSUCCESS\tImage Base: 0x7fefed20000, Image Size: 0x8000\r\n23:09:18,4969281\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\advapi32.dll\tSUCCESS\tImage Base: 0x7fefed30000, Image Size: 0xdb000\r\n23:09:18,4975579\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\sechost.dll\tSUCCESS\tImage Base: 0x7fefefc0000, Image Size: 0x1f000\r\n23:09:18,4980934\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\vcruntime140.dll\tSUCCESS\tImage Base: 0x7fef9f20000, Image Size: 0x17000\r\n23:09:18,4985102\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-runtime-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fefae30000, Image Size: 0x4000\r\n23:09:18,4990202\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\ucrtbase.dll\tSUCCESS\tImage Base: 0x7fef1980000, Image Size: 0xf6000\r\n23:09:18,4993831\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-core-localization-l1-2-0.dll\tSUCCESS\tImage Base: 0x7fef9f10000, Image Size: 0x3000\r\n23:09:18,4997199\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-core-processthreads-l1-1-1.dll\tSUCCESS\tImage Base: 0x7fef9f00000, Image Size: 0x3000\r\n23:09:18,5000873\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-core-file-l1-2-0.dll\tSUCCESS\tImage Base: 0x7fef9c80000, Image Size: 0x3000\r\n23:09:18,5004132\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-core-timezone-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef9c50000, Image Size: 0x3000\r\n23:09:18,5007251\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-core-file-l2-1-0.dll\tSUCCESS\tImage Base: 0x7fef78f0000, Image Size: 0x3000\r\n23:09:18,5010347\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-core-synch-l1-2-0.dll\tSUCCESS\tImage Base: 0x7fef78e0000, Image Size: 0x3000\r\n23:09:18,5013723\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-string-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef7290000, Image Size: 0x4000\r\n23:09:18,5017053\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-heap-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5b80000, Image Size: 0x3000\r\n23:09:18,5020326\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-stdio-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5b20000, Image Size: 0x4000\r\n23:09:18,5023556\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-convert-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5a00000, Image Size: 0x4000\r\n23:09:18,5027163\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-math-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5680000, Image Size: 0x5000\r\n23:09:18,5030972\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-locale-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5670000, Image Size: 0x3000\r\n23:09:18,5035867\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-time-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5660000, Image Size: 0x3000\r\n23:09:18,5040232\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-environment-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5650000, Image Size: 0x3000\r\n23:09:18,5043476\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-process-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5640000, Image Size: 0x3000\r\n23:09:18,5049748\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-conio-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5630000, Image Size: 0x3000\r\n23:09:18,5053460\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-filesystem-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5620000, Image Size: 0x3000\r\n23:09:18,5100964\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\cryptsp.dll\tSUCCESS\tImage Base: 0x7fefc6b0000, Image Size: 0x18000\r\n23:09:18,5144867\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\rsaenh.dll\tSUCCESS\tImage Base: 0x7fefc3b0000, Image Size: 0x47000\r\n23:09:18,5156094\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\cryptbase.dll\tSUCCESS\tImage Base: 0x7fefccc0000, Image Size: 0xf000\r\n23:09:22,2812159\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\DLLs\\_ctypes.pyd\tSUCCESS\tImage Base: 0x6dae0000, Image Size: 0x23000\r\n23:09:22,2818451\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\ole32.dll\tSUCCESS\tImage Base: 0x7fefe1b0000, Image Size: 0x1fc000\r\n23:09:22,2819936\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\gdi32.dll\tSUCCESS\tImage Base: 0x7fefee10000, Image Size: 0x67000\r\n23:09:22,2821573\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\user32.dll\tSUCCESS\tImage Base: 0x76f70000, Image Size: 0xfa000\r\n23:09:22,2823988\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\lpk.dll\tSUCCESS\tImage Base: 0x7fefef90000, Image Size: 0xe000\r\n23:09:22,2825875\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\usp10.dll\tSUCCESS\tImage Base: 0x7fefe3b0000, Image Size: 0xcb000\r\n23:09:22,2828244\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\oleaut32.dll\tSUCCESS\tImage Base: 0x7fefe480000, Image Size: 0xda000\r\n23:09:22,2852213\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\imm32.dll\tSUCCESS\tImage Base: 0x7fefe7d0000, Image Size: 0x2e000\r\n23:09:22,2854622\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\msctf.dll\tSUCCESS\tImage Base: 0x7fefee80000, Image Size: 0x109000\r\n23:09:22,2873239\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\psapi.dll\tSUCCESS\tImage Base: 0x77350000, Image Size: 0x7000\r\n23:09:22,3305458\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\core\\multiarray.cp35-win_amd64.pyd\tSUCCESS\tImage Base: 0x7fee9230000, Image Size: 0x1a6000\r\n23:09:22,3403641\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\.libs\\libopenblas.BNVRK7633HSX7YVO2TADGR4A5KEKXJAW.gfortran-win_amd64.dll\tSUCCESS\tImage Base: 0x65600000, Image Size: 0x2457000\r\n23:09:22,3413041\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\api-ms-win-crt-utility-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef5310000, Image Size: 0x3000\r\n23:09:22,3504746\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\core\\umath.cp35-win_amd64.pyd\tSUCCESS\tImage Base: 0x7fef1500000, Image Size: 0xcb000\r\n23:09:22,4512966\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\DLLs\\_bz2.pyd\tSUCCESS\tImage Base: 0x6da10000, Image Size: 0x1a000\r\n23:09:22,4549442\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\DLLs\\_lzma.pyd\tSUCCESS\tImage Base: 0x7fef43d0000, Image Size: 0x29000\r\n23:09:22,4646128\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\DLLs\\_hashlib.pyd\tSUCCESS\tImage Base: 0x7fee9c80000, Image Size: 0x167000\r\n23:09:22,4963274\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\linalg\\lapack_lite.cp35-win_amd64.pyd\tSUCCESS\tImage Base: 0x7fef4670000, Image Size: 0xb000\r\n23:09:22,4978504\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\linalg\\_umath_linalg.cp35-win_amd64.pyd\tSUCCESS\tImage Base: 0x7fef41a0000, Image Size: 0x21000\r\n23:09:22,5099393\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\DLLs\\_decimal.pyd\tSUCCESS\tImage Base: 0x6d930000, Image Size: 0x52000\r\n23:09:22,5235329\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\fft\\fftpack_lite.cp35-win_amd64.pyd\tSUCCESS\tImage Base: 0x7fef4620000, Image Size: 0x18000\r\n23:09:22,5429263\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\numpy\\random\\mtrand.cp35-win_amd64.pyd\tSUCCESS\tImage Base: 0x7feef130000, Image Size: 0xaa000\r\n23:09:22,5610733\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\msvcp140.dll\tSUCCESS\tImage Base: 0x7fef1460000, Image Size: 0x9e000\r\n23:09:22,5617687\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\api-ms-win-crt-multibyte-l1-1-0.dll\tSUCCESS\tImage Base: 0x7fef4660000, Image Size: 0x5000\r\n23:09:22,5628030\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\nvcuda.dll\tSUCCESS\tImage Base: 0x7fed7080000, Image Size: 0xd4c000\r\n23:09:22,5629974\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\setupapi.dll\tSUCCESS\tImage Base: 0x7fefdfd0000, Image Size: 0x1d7000\r\n23:09:22,5631437\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\cfgmgr32.dll\tSUCCESS\tImage Base: 0x7fefcfc0000, Image Size: 0x36000\r\n23:09:22,5633367\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\devobj.dll\tSUCCESS\tImage Base: 0x7fefd210000, Image Size: 0x1a000\r\n23:09:22,5634824\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\shell32.dll\tSUCCESS\tImage Base: 0x7fefd240000, Image Size: 0xd8a000\r\n23:09:22,5636238\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\shlwapi.dll\tSUCCESS\tImage Base: 0x7fefeb80000, Image Size: 0x71000\r\n23:09:22,5670519\tpython.exe\t4848\tLoad Image\tC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\cudart64_90.dll\tSUCCESS\tImage Base: 0x7fef3320000, Image Size: 0x61000\r\n23:09:22,5767031\tpython.exe\t4848\tLoad Image\tC:\\temp\\cudnn\\cuda\\bin\\cudnn64_7.dll\tSUCCESS\tImage Base: 0x7fec4ba0000, Image Size: 0x111e9000\r\n23:09:22,5836291\tpython.exe\t4848\tLoad Image\tC:\\temp\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd\tSUCCESS\tImage Base: 0x7feb5630000, Image Size: 0xf564000\r\n23:09:22,5848467\tpython.exe\t4848\tLoad Image\tC:\\Windows\\System32\\wsock32.dll\tSUCCESS\tImage Base: 0x7fef89d0000, Image Size: 0x9000\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nGPU model and memory\nExact command to reproduce", "added remaining fields", "I'm gonna mark as contributions welcome as we don't have the bandwidth to debug install issues. You might also try posting on Stack Overflow.", "I am having the same issue, it been six hours since I am trying to resolve it. \r\nOS Platform and Distribution: Windows 10, 64-bit\r\nTensorflow installed from pip 9.0.1\r\npip install tensorflow-gpu\r\nPython 3.6\r\nTensorFlow 1.10\r\nCUDA 9.0\r\ncuDNN 7.0\r\nBazel: N/A\r\nGPU model and memory: NVIDIA NVIDIA GeForce 940MX\r\nError:\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\hm\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\hm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"C:\\Users\\hm\\Anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\graph_pb2.py\", line 6, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"C:\\Users\\hm\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 47, in <module>\r\n    from google.protobuf.pyext import _message\r\nImportError: DLL load failed: Die angegebene Prozedur wurde nicht gefunden.\r\n\r\nAny idea how can I fix it please!", "@hashamMunir Have you found a solution? I have the same issue.", "Closing as duplicate"]}, {"number": 16844, "title": "Fix comparison in neon_depthwise_conv_op test. ", "body": "This is in preparation for enabling Grappler for all TensorFlow Python tests.", "comments": []}, {"number": 16843, "title": "Have _check_bazel_version_at_least compare versions as ints, not stri\u2026", "body": "Fix bazel version check issue on r1.5 branch. Example breakage https://source.cloud.google.com/results/invocations/9388d7a7-a2ed-45ce-9fcd-cf69fbdebcf5/log\r\n\r\nPiperOrigin-RevId: 182085505", "comments": ["Adding one more fix", "@gunan this means we already have 0.10.0 on these machines?", "it is possible in build infra we have bazel 0.10. Need to check with them to confirm."]}, {"number": 16842, "title": "Bump JetPack default to 3.2 in Android build script", "body": "", "comments": ["@gunan"]}, {"number": 16841, "title": "Testing this on the 1.5 release branch.", "body": "", "comments": []}]