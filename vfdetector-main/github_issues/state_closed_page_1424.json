[{"number": 10256, "title": "string_input_producer possible race while enqueuing", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows-7-6.1.7601-SP1\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: b'unknown' 1.0.1\r\n\r\nPython version `'3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)]'\r\n`\r\n\r\n### Describe the problem\r\nWhen I run the script below in pycharm _most of the time_ (hence race) I get \r\n\r\n> ERROR:tensorflow:Exception in QueueRunner: Attempted to use a closed Session.\r\n\r\nRunning directly from cmd (that's the same command pycharm uses):\r\n\r\n```\r\nC:\\...>C:\\_\\Python35\\python.exe C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_40.py\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') f\r\nor unknown op: BestSplits\r\n...\r\nb'C:\\\\Dropbox\\\\eclipse_workspaces\\\\python\\\\nn_nielsen\\\\resources\\\\tf_records_gap\\\\img_2013-01-01-00-02.tfrecords'\r\nb'C:\\\\Dropbox\\\\eclipse_workspaces\\\\python\\\\nn_nielsen\\\\resources\\\\tf_records_gap\\\\img_2013-01-01-00-01.tfrecords'\r\nb'C:\\\\Dropbox\\\\eclipse_workspaces\\\\python\\\\nn_nielsen\\\\resources\\\\tf_records_gap\\\\img_2013-01-01-00-00.tfrecords'\r\nW c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\kernels\\queue_base.cc:294] _0_input_producer: Skipping cancelled enqueue attem\r\npt with queue not closed\r\n```\r\n\r\n### Source code / logs\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\n\r\ndata_dir = r\"C:\\...\"\r\nfilenames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\r\nqueue = tf.train.string_input_producer(filenames)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    tf.train.start_queue_runners(sess=sess)\r\n    for _ in range(len(filenames)):\r\n        print(queue.dequeue().eval())\r\n```\r\n\r\nRunning this as a test inside pycharm (using PyCharm 2017.1.3, Build #PY-171.4424.42) as in:\r\n\r\n```python\r\n\r\nclass TestFileNameQueue(unittest.TestCase):\r\n    def test__get_filename_queue(self):\r\n        data_dir = r\"C:\\...\"\r\n        filenames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\r\n        queue = tf.train.string_input_producer(filenames)\r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            tf.train.start_queue_runners(sess=sess)\r\n            for _ in range(len(filenames)):\r\n                print(queue.dequeue().eval())\r\n```\r\n\r\nI get a more detailed traceback:\r\n\r\n```\r\nC:\\_\\Python35\\python.exe \"C:\\_\\JetBrains\\PyCharm 2016.3\\helpers\\pydev\\pydevd.py\" --multiproc --save-signatures --qt-support --client 127.0.0.1 --port 4524 --file \"C:\\_\\JetBrains\\PyCharm 2016.3\\helpers\\pycharm\\_jb_unittest_runner.py\" --target tf_test_sanity.TestFileNameQueue.test__get_filename_queue\r\nTesting started at 11:41 PM ...\r\nwarning: Debugger speedups using cython not found. Run '\"C:\\_\\Python35\\python.exe\" \"C:\\_\\JetBrains\\PyCharm 2016.3\\helpers\\pydev\\setup_cython.py\" build_ext --inplace' to build.\r\npydev debugger: process 6148 is connecting\r\n\r\nConnected to pydev debugger (build 171.4424.42)\r\nLaunching unittests with arguments python -m unittest tf_test_sanity.TestFileNameQueue.test__get_filename_queue in C:\\Dropbox\\eclipse_workspaces\\python\\nn_nielsen\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"') for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"') for unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') for unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots\r\nERROR:tensorflow:Exception in QueueRunner: Attempted to use a closed Session.\r\n\r\n\r\nb'resources/tf_records_no_gap\\\\img_2013-01-01-00-00.tfrecords'\r\nb'resources/tf_records_no_gap\\\\img_2013-01-01-00-02.tfrecords'\r\nb'resources/tf_records_no_gap\\\\img_2013-01-01-00-01.tfrecords'\r\n\r\n\r\nRan 1 test in 255.837s\r\n\r\nOK\r\nException in thread Thread-7:\r\nTraceback (most recent call last):\r\n  File \"C:\\_\\Python35\\lib\\threading.py\", line 914, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\_\\Python35\\lib\\threading.py\", line 862, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\_\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\", line 234, in _run\r\n    sess.run(enqueue_op)\r\n  File \"C:\\_\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\_\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 903, in _run\r\n    raise RuntimeError('Attempted to use a closed Session.')\r\nRuntimeError: Attempted to use a closed Session.\r\n\r\n\r\nProcess finished with exit code 0\r\n```", "comments": ["How did you install TensorFlow? Did PyCharm install it?", "Nope in cmd:\r\n\r\n```    \r\n    C:\\Users\\MrD>\"C:\\_\\Python35\\python.exe\" -m pip install --upgrade tensorflow\r\n    Collecting tensorflow\r\n      Downloading tensorflow-1.0.1-cp35-cp35m-win_amd64.whl (14.7MB)\r\n        100% |################################| 14.7MB 37kB/s\r\n    Collecting six>=1.10.0 (from tensorflow)\r\n      Using cached six-1.10.0-py2.py3-none-any.whl\r\n    Collecting wheel>=0.26 (from tensorflow)\r\n      Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)\r\n        100% |################################| 71kB 1.3MB/s\r\n    Collecting numpy>=1.11.0 (from tensorflow)\r\n      Downloading numpy-1.12.1-cp35-none-win_amd64.whl (7.7MB)\r\n        100% |################################| 7.7MB 73kB/s\r\n    Collecting protobuf>=3.1.0 (from tensorflow)\r\n      Downloading protobuf-3.2.0-py2.py3-none-any.whl (360kB)\r\n        100% |################################| 368kB 875kB/s\r\n    Cache entry deserialization failed, entry ignored\r\n    Collecting setuptools (from protobuf>=3.1.0->tensorflow)\r\n      Downloading setuptools-34.3.2-py2.py3-none-any.whl (389kB)\r\n        100% |################################| 399kB 956kB/s\r\n    Collecting packaging>=16.8 (from setuptools->protobuf>=3.1.0->tensorflow)\r\n      Downloading packaging-16.8-py2.py3-none-any.whl\r\n    Collecting appdirs>=1.4.0 (from setuptools->protobuf>=3.1.0->tensorflow)\r\n      Downloading appdirs-1.4.3-py2.py3-none-any.whl\r\n    Collecting pyparsing (from packaging>=16.8->setuptools->protobuf>=3.1.0->tensorflow)\r\n      Downloading pyparsing-2.2.0-py2.py3-none-any.whl (56kB)\r\n        100% |################################| 61kB 1.9MB/s\r\n    Installing collected packages: six, wheel, numpy, pyparsing, packaging, appdirs, setuptools, protobuf, tensorflow\r\n      Found existing installation: setuptools 20.10.1\r\n        Uninstalling setuptools-20.10.1:\r\n          Successfully uninstalled setuptools-20.10.1\r\n    Successfully installed appdirs-1.4.3 numpy-1.12.1 packaging-16.8 protobuf-3.2.0 pyparsing-2.2.0 setuptools-34.3.2 six-1.10.0 tensorflow-1.0.1 wheel-0.29.0\r\n    You are using pip version 8.1.1, however version 9.0.1 is available.\r\n    You should consider upgrading via the 'python -m pip install --upgrade pip' command.\r\n```", "@mrry I'm confused. Is `tf.contrib` supported on Windows? This is the second such issue I'm noticing today. The reason why I'm confused is because https://github.com/tensorflow/tensorflow/issues/5662 yet it is [excluded](https://github.com/tensorflow/tensorflow/blob/0462416f6498d964310ba05a38a23bd1eabba3bf/tensorflow/python/BUILD#L90) from the bazel build.", "@jart I don't think this is using any of `tf.contrib`, is it? FWIW, the Windows releases include `tf.contrib` (via the CMake build), but the Bazel build doesn't include it\u2014IIRC because the method of integrating `tf.load_op_library()`-based extensions doesn't currently work in Bazel.\r\n\r\nOn the original issue, I think this race is \"benign\", and the error messages are printed in a situation where the queue-runner for `tf.train.string_input_producer()` is terminated by closing the session. I think the errors would be avoided if you add `num_epochs=1` to the`tf.train.string_input_producer()` arguments.", ">  I think the errors would be avoided if you add num_epochs=1 to the tf.train.string_input_producer() arguments.\r\n\r\nIndeed:\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\n\r\ndata_dir = r\"C:\\Dropbox\\eclipse_workspaces\\python\\nn_nielsen\\.git\\info\"\r\nfilenames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\r\nqueue = tf.train.string_input_producer(filenames, capacity=3, num_epochs=1)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(tf.local_variables_initializer()) # I had to add this too\r\n    tf.train.start_queue_runners(sess=sess)\r\n    for _ in range(len(filenames)):\r\n        print(queue.dequeue().eval())\r\n```\r\n\r\nNote however the error is only printed for small directories (couple items) in my system - for larger ones I get the warning:\r\n\r\n> W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\kernels\\queue_base.cc:294] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed\r\n\r\nIt's benign as you say but maybe there is something there worth investigating\r\n\r\nThanks!", "I think the way `tf.train.string_input_producer()` is implemented with background threads and queue runners makes it tricky to avoid this happening. One thing we've been working on recently (and released in TensorFlow 1.2) is a new `Dataset` API that lets you do similar things without having to manage the threads. Here's what your program would look like with the new API:\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\n\r\ndata_dir = r\"C:\\...\"\r\nfilenames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(filenames))\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    for _ in range(len(filenames)):\r\n        print(next_element.eval())\r\n```\r\n\r\nNote that there would no longer be any need to start queue runners, and the program should exit without errors.", "I think the new API does need some polishing (why `tf.constant(filenames)`) but thanks :)\r\n\r\nEDIT 2017.09.19 - asked also here: https://stackoverflow.com/q/45662230/281545"]}, {"number": 10255, "title": "Initial scope implementation.", "body": "This is an initial implementation to support scopes for the\r\nJava language bindings. It currently provides only hierarchical\r\nname scopes.\r\n\r\nPlease see https://github.com/tensorflow/tensorflow/issues/7149\r\nto track the master issue.", "comments": ["Can one of the admins verify this patch?", " @Moriadry thanks! I've started [an informal group](https://groups.google.com/forum/#!forum/tensorflow-java-dev-unofficial) to find out who's working on what in this particular area, and consolidate efforts from interested people - we can continue the conversation there.", "@kbsriram Got it, I already submit a request to join, many thanks!", "Gentle ping - could a member wake up the test this please ci bot?", "Jenkins, test this please!", "The single test failure (`//tensorflow/python:basic_session_run_hooks_test`) looks unrelated.", "Jenkins, test this please.", "Broken Mac test rebuilt here: http://ci.tensorflow.org/job/tensorflow-pull-requests-mac/5318/console\r\n\r\n", "Broken Makefile test rebuilt here: http://ci.tensorflow.org/job/tensorflow-pull-requests-makefile/9172/console", "Broken Android test rebuilt here: http://ci.tensorflow.org/job/tensorflow-pull-requests-android/5321/console"]}, {"number": 10254, "title": "custom Android op configuration", "body": "Why does Android lack support for so many ops (especially quantized/quantization)?\r\nAlthough some of them get added after a while, this really gets into the way...\r\n\r\nI know that the background is to lower the binary size...\r\nBut wouldn't it be possible to compile specifically for a given graph definition?\r\n\r\nThis could be offered in parallel to the current solution and provide even more fine-grained control.", "comments": ["@Androbin Yes, it's possible to do exactly what you're asking. The tool you're looking for is https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py, used in conjunction with -DSELECTIVE_REGISTRATION.\r\n\r\nIf you have any specific ops you'd like to see supported by default please submit a PR. Due to selective registration we don't need to be too picky about adding ops for size reasons, but as every new op has the potential to add extra maintenance on mobile we tend to add them as needed by graphs, rather than proactively.", "@andrewharp Particularly on mobile, we should have common quantized ops.\r\nFor example, I just got \r\n\r\n> org.tensorflow.TensorFlowException: Op type not registered 'QuantizedAdd' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.", "And maybe this should be communicated more clearly to whoever gets to deal with\r\n\r\n> No OpKernel was registered to support Op '<FooBar>' with these attrs", "Continuing at #10299", "I am working with an already frozen model, so when I run my android application, I get this exception:\r\n\r\n`     Caused by: org.tensorflow.TensorFlowException: Op type not registered 'NonMaxSuppressionV3' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.`\r\n\r\nI have checked the BUILD file and there is that op: non_max_suppression_op , I really don't know what to do. \r\nPlease tell me how I can fix it.\r\n", "@japer21 The Python tool linked above contains some documentation on its usage:\r\n```\r\nAn example of command-line usage is:\r\n  bazel build tensorflow/python/tools:print_selective_registration_header && \\\r\n  bazel-bin/tensorflow/python/tools/print_selective_registration_header \\\r\n    --graphs=path/to/graph.pb > ops_to_register.h\r\n\r\nThen when compiling tensorflow, include ops_to_register.h in the include search\r\npath and pass -DSELECTIVE_REGISTRATION and -DSUPPORT_SELECTIVE_REGISTRATION\r\n - see core/framework/selective_registration.h for more details.\r\n\r\nWhen compiling for Android:\r\n  bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" \\\r\n    --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" \\\r\n    //tensorflow/contrib/android:libtensorflow_inference.so \\\r\n    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n    --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a\r\n```\r\nNote that the last step is known to make trouble.", "@Androbin After running the first command \r\n```\r\nbazel build tensorflow/python/tools:print_selective_registration_header && \\\r\n  bazel-bin/tensorflow/python/tools/print_selective_registration_header \\\r\n    --graphs=path/to/graph.pb > ops_to_register.h\r\n```\r\nwhich is the next step I should take? Move the file in the same directory as core/framework/selective_registration.h  and then how to compile tensorflow? I am so lost please thanks for understanding me. ", "Yes, that's where you should move it.\r\nUsing the last command you can now compile the file `libtensorflow_inference.so`.\r\nYou probably already have multiple of those, each one optimized for another architecture.\r\nBut you need only this one (armeabi-v7a), which should be compatible with all architectures.\r\nThis native library should contain the ops you need and can be used by TensorFlow for Android.", "@Androbin Before start anything, I just wand to make sure if it is enough if I only provide to my android gradle this line: `implementation 'org.tensorflow:tensorflow-android:1.8.0' `? For instance I do not have any extra libraries like libandroid_tenserflow_inference_java.  \r\nAlthough I have them in my project structure\r\n![screenshot_1](https://user-images.githubusercontent.com/17979719/41165448-ff566c14-6b3d-11e8-8212-1f58490ef40b.png)\r\n", "You should be fine. Just replace `app/libs/armeabi-v7a/libtensorflow_inference.so` with the newly generated one and be sure to either remove the other three architectures or recompile them, too.", "@Androbin I will and I will keep you in touch with the progress. By the way I do not have GPU but a CPU, for more informations about what I have, I raised also an issue about this exception here https://github.com/tensorflow/tensorflow/issues/19854", "@Androbin Actually I got the BUILD failed.\r\n![screenshot_2](https://user-images.githubusercontent.com/17979719/41167205-8e0d9e42-6b42-11e8-8d1f-2dfc7d46a7f7.png)\r\n", "Please amend the flag `--verbose_failures` to get a more detailed error message.", "```\r\nvagrant@vagrant:~/tensorflow$ ../.bazel/bin/bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\r\nWARNING: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:batch_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1518:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nINFO: Analysed target //tensorflow/contrib/android:libtensorflow_inference.so (0 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/vagrant/tensorflow/tensorflow/core/BUILD:1596:1: C++ compilation of rule '//tensorflow/core:android_tensorflow_lib' failed (Exit 1): false failed: error executing command \r\n  (cd /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PWD=/proc/self/cwd \\\r\n  /bin/false -MD -MF bazel-out/armeabi-v7a-opt/bin/tensorflow/core/_objs/android_tensorflow_lib/tensorflow/core/ops/remote_fused_graph_ops.pic.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/tensorflow/core/_objs/android_tensorflow_lib/tensorflow/core/ops/remote_fused_graph_ops.pic.o' -fPIC -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/armeabi-v7a-opt/genfiles -iquote external/protobuf_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/protobuf_archive -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/armeabi-v7a-opt/genfiles/external/local_config_sycl -iquote external/double_conversion -iquote bazel-out/armeabi-v7a-opt/genfiles/external/double_conversion -iquote external/nsync -iquote bazel-out/armeabi-v7a-opt/genfiles/external/nsync -iquote external/fft2d -iquote bazel-out/armeabi-v7a-opt/genfiles/external/fft2d -iquote external/gemmlowp -iquote bazel-out/armeabi-v7a-opt/genfiles/external/gemmlowp -isystem external/protobuf_archive/src -isystem bazel-out/armeabi-v7a-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/src -isystem external/eigen_archive -isystem bazel-out/armeabi-v7a-opt/genfiles/external/eigen_archive -isystem bazel-out/armeabi-v7a-opt/bin/external/eigen_archive -isystem external/double_conversion -isystem bazel-out/armeabi-v7a-opt/genfiles/external/double_conversion -isystem bazel-out/armeabi-v7a-opt/bin/external/double_conversion -isystem external/nsync/public -isystem bazel-out/armeabi-v7a-opt/genfiles/external/nsync/public -isystem bazel-out/armeabi-v7a-opt/bin/external/nsync/public -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-mfpu=neon' '-std=c++11' -DTF_LEAN_BINARY -Wno-narrowing -fomit-frame-pointer -O2 -c tensorflow/core/ops/remote_fused_graph_ops.cc -o bazel-out/armeabi-v7a-opt/bin/tensorflow/core/_objs/android_tensorflow_lib/tensorflow/core/ops/remote_fused_graph_ops.pic.o)\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 0.415s, Critical Path: 0.05s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```", "@Androbin It seems strange the tensorflow/ repository with these bazel repositories:\r\n\r\n![screenshot_4](https://user-images.githubusercontent.com/17979719/41167996-ef5eeed8-6b44-11e8-91f2-5286495e68f7.png)\r\n\r\nAnd it points out here in the BUILD file /home/vagrant/tensorflow/tensorflow/core/BUILD:1596:1\r\n![screenshot_5](https://user-images.githubusercontent.com/17979719/41168202-86cd7a1e-6b45-11e8-885d-5e8231f091e0.png)\r\n\r\n", "You can safely ignore these directories. This is where the bazel tool compiles and caches artifacts.", "You wrote that you use TensorFlow 1.8.0\r\nBut the bemangled line doesn't match the error message:\r\nhttps://github.com/tensorflow/tensorflow/blob/93bc2e2072e0daccbcff7a90d397b704a9e8f778/tensorflow/core/BUILD#L1518\r\nDo you maybe have another version checked out?", "@Androbin Strange but true. I just cloned the repository last Wednesday evening, but now I made a pull and yeah it changed. \r\nDo I have to re-run again the command to generate the file ops_to_register.h or only to re execute the last command which was giving a failure?", "@Androbin  I get the same errors:\r\n```\r\nvagrant@vagrant:~/tensorflow$ ../.bazel/bin/bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\r\nWARNING: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:batch_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nINFO: Analysed target //tensorflow/contrib/android:libtensorflow_inference.so (26 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/fft2d/BUILD.bazel:21:1: C++ compilation of rule '@fft2d//:fft2d' failed (Exit 1): false failed: error executing command \r\n  (cd /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PWD=/proc/self/cwd \\\r\n  /bin/false -MD -MF bazel-out/armeabi-v7a-opt/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.pic.d -fPIC -iquote external/fft2d -iquote bazel-out/armeabi-v7a-opt/genfiles/external/fft2d -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -c external/fft2d/fft/fftsg.c -o bazel-out/armeabi-v7a-opt/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.pic.o)\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 3.166s, Critical Path: 0.01s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "@Androbin Actually I did `bazel clean`  and now it started compiling, I do not know if it's a good sign:\r\n\r\n`INFO: Analysed target //tensorflow/contrib/android:libtensorflow_inference.so (29 packages loaded).`\r\nAnd it is running still.\r\n", "@Androbin  Finally it's the same error:\r\n\r\n```\r\nvagrant@vagrant:~/tensorflow$ ../.bazel/bin/bazel clean \r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nvagrant@vagrant:~/tensorflow$ ../.bazel/bin/bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures\r\nWARNING: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:batch_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_volume_patch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/vagrant/tensorflow/tensorflow/core/BUILD:1525:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nINFO: Analysed target //tensorflow/contrib/android:libtensorflow_inference.so (29 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/external/fft2d/BUILD.bazel:21:1: C++ compilation of rule '@fft2d//:fft2d' failed (Exit 1): false failed: error executing command \r\n  (cd /home/vagrant/.cache/bazel/_bazel_vagrant/2608380002b7e82b3d07fef59e49e485/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PWD=/proc/self/cwd \\\r\n  /bin/false -MD -MF bazel-out/armeabi-v7a-opt/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.pic.d -fPIC -iquote external/fft2d -iquote bazel-out/armeabi-v7a-opt/genfiles/external/fft2d -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -c external/fft2d/fft/fftsg.c -o bazel-out/armeabi-v7a-opt/bin/external/fft2d/_objs/fft2d/external/fft2d/fft/fftsg.pic.o)\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\nINFO: Elapsed time: 211.430s, Critical Path: 13.76s\r\nINFO: 190 processes, local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```", "The `ops_to_register.h` file might still be valid but there's no guarantee.\r\nIf you're using version 1.8.0 in your Android project, better checkout that commit.\r\nThat would be: `git checkout v1.8.0`", "I don't quite see the point in the bemangled command:\r\n```\r\nName: false - do nothing, unsuccessfully\r\nSynopsis: false [ignored command line arguments]\r\n```\r\n\r\nIt's defined in [`/third_party/toolchains/cpus/arm/CROSSTOOL.tpl#L61`](https://github.com/tensorflow/tensorflow/blob/master/third_party/toolchains/cpus/arm/CROSSTOOL.tpl#L61) as of a1fba7f5ac3de39b106af36c3737ea854f09e9ac\r\n@vrv You authored that commit, could you help us out here?\r\nThe commit is stashed and I failed to find the origin of this line.", "Sadly I probably just pushed the commit, I didn't author it.  I think it came from:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/11675 pinging @ebrevdo and @petewarden.\r\n\r\n", "@Androbin Hello again. Do you have an idea of how to build with ios once the header file is created?\r\nAfter executing this command on ios: \r\n```\r\n bazel build tensorflow/python/tools:print_selective_registration_header && \\\r\n  bazel-bin/tensorflow/python/tools/print_selective_registration_header \\\r\n    --graphs=path/to/graph.pb > ops_to_register.h\r\n```\r\n??", "Happily, there is solid documentation on building for iOS:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios#building-the-tensorflow-ios-libraries-from-source\r\n\r\n`tensorflow/contrib/makefile/build_all_ios.sh` lets you set `OPTIMIZE_FOR_GRAPH`.\r\nIt will then generate `tensorflow/core/framework/ops_to_register.h` automatically.\r\n\r\nThis option was added in c4ef927b5eaf144dbf1e0419c0d1d3fd968177bd, but the above docs still refer to `tensorflow/contrib/makefile/tf_op_files.txt` which seems to be outdated now (#20591).", "@Androbin Does this mean I have to add an option when executng the script? cuz apparently, on tensorflow 1.8.0  there are missing operators when working on ios, such as the operator NonMaxSuppressionV3. So I checked out the 1.9.0-rc1 version but I have had some problems, I do not know if you have ever worked with tensorflow fo ios, there seem to be enormous bugs...", "@Androbin So, do I have to check out v1.9.0-rc2 ??? ", "Actually, I just noticed that commit has been cherry-picked, so you should already have that option:\r\n```\r\ntensorflow/contrib/makefile/build_all_ios.sh -a arm64 -g /path/to/your/graph.pb\r\n```"]}, {"number": 10253, "title": "label_keys type error on DNNCLassifier Tensorflow", "body": "I got the following error when I tried to embed an array of label_keys of type string into a DNNClassifier. At the first attempt I folowed the official documentation for instantiating a DNNClassifier.\r\n\r\n`Traceback (most recent call last):\r\n  File \"embedding_model_probe.py\", line 118, in <module>\r\n    m.fit(input_fn=train_input_fn, steps=200)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 430, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 927, in _train_model\r\n    model_fn_ops = self._get_train_ops(features, labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1132, in _get_train_ops\r\n    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1103, in _call_model_fn\r\n    model_fn_results = self._model_fn(features, labels, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 180, in _dnn_model_fn\r\n    logits=logits)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 1004, in create_model_fn_ops\r\n    labels = self._transform_labels(mode=mode, labels=labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 1033, in _transform_labels\r\n    \"label_ids\": table.lookup(labels_tensor),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lookup/lookup_ops.py\", line 179, in lookup\r\n    (self._key_dtype, keys.dtype))\r\nTypeError: Signature mismatch. Keys must be dtype <dtype: 'string'>, got <dtype: 'int64'>.\r\n`\r\n\r\nHere is the \"guilty\" piece of my code:\r\n\r\n`  label_keys_values = [\"satan\", \"ipsweep\", \"nmap\", \"portsweep\"]    `\r\n`  m = tf.contrib.learn.DNNClassifier(model_dir=model_dir,\r\n\t                    feature_columns=deep_columns,\r\n\t                    n_classes=4,\r\n\t                   hidden_units=[12, 4],\r\n\t                   label_keys=label_keys_values)`\r\n`  m.fit(input_fn=train_input_fn, steps=200)`\r\n\r\nOn the other hand, if I make the `label_key_values` column a `numpy.array`\r\n`label_keys_values = np.array([\"satan\", \"ipsweep\", \"nmap\", \"portsweep\"], dtype='string')`\r\n\r\nI will get the following error:\r\n\r\n`Traceback (most recent call last): File \"embedding_model_probe.py\", line 116, in label_keys=label_keys_values) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 337, in init label_keys=label_keys), File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 331, in multi_class_head label_keys=label_keys) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 986, in init if label_keys and len(label_keys) != n_classes: ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`\r\n\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Sorry for trouble.\n\nI just think it is an real error not being able to set a list of strings as\na label_keys parameter for DNNClassifier.\n\nIf you come with an workaround, please notify me.\n\nHave a nice day!\n\nPS: it's me who posted also on Stackoverflow\n<https://stackoverflow.com/questions/44219077/label-keys-type-error-on-dnnclassifier-tensorflow>\n.\n\n2017-05-28 3:01 GMT+03:00 Justine Tunney <notifications@github.com>:\n\n> This question is better asked on StackOverflow\n> <http://stackoverflow.com/questions/tagged/tensorflow> since it is not a\n> bug or feature request. There is also a larger community that reads\n> questions there. Thanks!\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10253#issuecomment-304482961>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/APZj_lj8Qwbpfq8mKzntnbgitroQ5KKRks5r-Ll0gaJpZM4Noakk>\n> .\n>\n"]}, {"number": 10252, "title": "Feature Request:   Tensorflow for Python 3.6 ", "body": "\r\nHi,\r\n\r\nI was wondering if there are plans to release tensorflow for Python 3.6  and if so is there ETA?\r\n\r\n\r\nThank you. ", "comments": ["@Moondra, can you please clarify what operating system(s) you question is about? Thanks.", "I assume \"cp36\" refers to \"python 3.6\". If that's the case, it is already out.", "I cannot seem to find the TF on py3.6 on windows\r\nI tried both CPU and GPU versions at https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.1.0-cp36-cp36m-win_amd64.whl", "cc @gunan ", "It is not available yet.\r\nClosing this issue as a duplicate of #6999 ", "@caisq  Hi, I was looking for the Windows version. Thank you. "]}, {"number": 10251, "title": "Support for custom input producers", "body": "This is a request for custom functions to feed examples into input pipelines. Existing ops are designed to read pre-defined formats. Although it is entirely possible to pre-process all the data beforehand, I felt like it shouldn't be necessary, especially in realtime environments. It'd be more convenient to pass TensorFlow a lambda to use to generate the batches instead of pre-processing them into TFRecords or dealing with nasty IO or using the not scalable option of python dicts.\r\n\r\n[Please tell me if there already exists such a solution, I didn't find a way to do it.]", "comments": ["I think the performance guide already mentions that the solution is to use queues.", "@ppwwyyxx I am referring to how the data is introduced, not how it is processed afterwards.", "What currently can be done: Loading TFRecords, CSV files and whatever format has support\r\nWhat currently isn't as easy: Loading a unknown/custom format and/or applying custom pre-processing before enqueuing the data", "You can load whatever custom formats and apply custom pre-processing, and feed them into queues.", "Thanks for helping our friend @ppwwyyxx.\r\n\r\nIf queues don't work for your use case, let me know and I'll reopen."]}, {"number": 10249, "title": "Fix typos", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please."]}, {"number": 10248, "title": "Branch 155393864", "body": "", "comments": []}, {"number": 10247, "title": "Error arising when import tensorflow ", "body": "alpine 3.5 python 2.7\r\nInstalling tensorflow using pip succesfully, but after `import` tensorflow` I got this\r\n\r\n> ImportError: Error relocating /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal\r\n.so: __sprintf_chk: symbol not found\r\n\r\n\r\n", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "# OS\r\nHost: Windows 10 Professional  64bit\r\nDocker container :  Alpine\r\n`/ # cat /etc/issue`\r\nWelcome to Alpine Linux 3.6\r\nKernel \\r on an \\m (\\l)\r\n\r\n`/ # uname -a`\r\nLinux 3b851449cb60 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 Linux\r\n\r\n# Installation\r\n- Part of my dockerfile\r\n\r\n`FROM frolvlad/alpine-glibc`\r\n`RUN apk update && apk add --no-cache \\\r\n        wget ca-certificates unzip vim git \\\r\n        gcc g++ python python-dev py-numpy-dev && \\\r\n    apk add --no-cache --virtual=build-dependencies \\\r\n        libffi-dev libressl-dev zlib-dev jpeg-dev freetype-dev libpng-dev `\r\n\r\n`RUN wget https://bootstrap.pypa.io/get-pip.py && \\\r\n    python get-pip.py && rm get-pip.py && \\\r\n    ln -s /usr/include/locale.h /usr/include/xlocale.h && \\\r\n    pip --no-cache-dir install requests[security] ipykernel jupyter matplotlib scipy scikit-learn pandas seaborn \\\r\n    https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.0rc1-cp27-none-linux_x86_64.whl && \\\r\n    python -m ipykernel.kernelspec `\r\n\r\nThe dockerfile was built successfully. But when `import tensorflow` in a container , the following happened\r\n\r\n>Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: Error relocating /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: __sprintf_chk: symbol\r\n not found\r\nFailed to load the native TensorFlow runtime.", "????", "Closing this out as a duplicate of #10283"]}, {"number": 10246, "title": "Undo modification to `x` dict by deleting `_TARGET_KEY` after features dequeue", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 10245, "title": "Implement Focused Online Learning which converges faster than SGD", "body": "![image](https://cloud.githubusercontent.com/assets/9004594/26520117/ec115938-42fe-11e7-9350-8da77dc6488e.png)\r\nShai Shalev-Shwartz and Yonatan Wexler. Minimizing the Maximal Loss: How and Why?. ICML, 2016.\r\nhttp://proceedings.mlr.press/v48/shalev-shwartzb16.pdf\r\nhttp://arxiv.org/abs/1602.01690\r\nhttps://www.cs.huji.ac.il/~shais/talks/FOL_talk.pdf", "comments": ["Thoughts on this feature request @fchollet?", "What would be the proposed API?"]}, {"number": 10244, "title": "Fixed a comment typo in GraphView:InitializeNode(), executor.cc.", "body": "From \"EdngeInfo\" to \"EdgeInfo\"^_^", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10243, "title": "UnimplementedError, if only a word as the input data", "body": "When the input tensor only contain a word, the program will raise the UnimplementedError.\r\n\r\n`import numpy as np\r\nimport tensorflow as tf\r\n\r\n# Data settings.\r\nnum_examples = 10\r\nnum_words = 1\r\nnum_features = 100\r\nnum_tags = 5\r\n\r\n# Random features.\r\nx = np.random.rand(num_examples, num_words, num_features).astype(np.float32)\r\n\r\n# Random tag indices representing the gold sequence.\r\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\r\n\r\n# All sequences in this example have the same length, but they can be variable in a real model.\r\nsequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\r\n\r\n# Train and evaluate the model.\r\nwith tf.Graph().as_default():\r\n  with tf.Session() as session:\r\n    # Add the data to the TensorFlow graph.\r\n    x_t = tf.constant(x)\r\n    y_t = tf.constant(y)\r\n    sequence_lengths_t = tf.constant(sequence_lengths)\r\n\r\n    # Compute unary scores from a linear layer.\r\n    weights = tf.get_variable(\"weights\", [num_features, num_tags])\r\n    matricized_x_t = tf.reshape(x_t, [-1, num_features])\r\n    matricized_unary_scores = tf.matmul(matricized_x_t, weights)\r\n    unary_scores = tf.reshape(matricized_unary_scores,\r\n                              [num_examples, num_words, num_tags])\r\n\r\n    # Compute the log-likelihood of the gold sequences and keep the transition\r\n    # params for inference at test time.\r\n    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\r\n        unary_scores, y_t, sequence_lengths_t)\r\n\r\n    # Add a training op to tune the parameters.\r\n    loss = tf.reduce_mean(-log_likelihood)\r\n    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\r\n\r\n    # Train for a fixed number of iterations.\r\n    session.run(tf.global_variables_initializer())\r\n    for i in range(1000):\r\n      tf_unary_scores, tf_transition_params, _ = session.run(\r\n          [unary_scores, transition_params, train_op])\r\n      if i % 100 == 0:\r\n        correct_labels = 0\r\n        total_labels = 0\r\n        for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\r\n                                                          sequence_lengths):\r\n          # Remove padding from the scores and tag sequence.\r\n          tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\r\n          y_ = y_[:sequence_length_]\r\n\r\n          # Compute the highest scoring sequence.\r\n          viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\r\n              tf_unary_scores_, tf_transition_params)\r\n\r\n          # Evaluate word-level accuracy.\r\n          correct_labels += np.sum(np.equal(viterbi_sequence, y_))\r\n          total_labels += sequence_length_\r\n        accuracy = 100.0 * correct_labels / float(total_labels)\r\n        print(\"Accuracy: %.2f%%\" % accuracy)`\r\n\r\nUnimplementedError (see above for traceback): TensorArray has size zero, but element shape <unknown> is not fully defined. Currently only static shapes are supported when packing zero-size TensorArrays.\r\n\t [[Node: gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGatherV3 = TensorArrayGatherV3[_class=[\"loc:@rnn/TensorArray_1\"], dtype=DT_FLOAT, element_shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/TensorArrayGradV3, rnn/TensorArrayUnstack/range, gradients/rnn/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3_grad/TensorArrayGrad/gradient_flow)]]\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 10242, "title": "Fixed tf.contrib.crf.crf_log_norm to handle zero sequence length.", "body": "The original version of tf.contrib.crf.crf_log_norm can not produce zero output when the sequence length is zero or a negtive number, which will leads tf.contrib.crf_log_likelihood to produce non-zero output, so that the training procedure can be disturbed.\r\nThis patch force the output to be zero when the sequence length is equal or less than zero.", "comments": ["Can one of the admins verify this patch?", "Can you add a test with zero-sized sequences?", "Just checking in; did you have a chance to add the test I asked?", "@chqiwang feel free to re-open once you have the test in."]}, {"number": 10241, "title": "C++ Online Documentation codeblocks not formatting", "body": "There are some codeblocks in C++ documentation , written with github-style fenced markdown, \r\nthat are not rendering as `<code>`.\r\n\r\nEg: https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/depth-to-space\r\n\r\n![screenshot of a page with docs not formatted as code](https://cloud.githubusercontent.com/assets/5127634/26518496/5c312d9e-42e4-11e7-856a-972268bcf757.png)\r\n\r\nIt looks like something is going wrong with the site generation,\r\nthat when translating markdown, it does not pickup these blocks.\r\n\r\nIn the pages I quickly checked it seems to occur in the Summary sections, eg in:\r\n\r\n- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/depth-to-space\r\n- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space\r\n- https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space-n-d\r\n\r\n", "comments": ["This is happening in the [1.2 docs](https://www.tensorflow.org/versions/r1.2/api_docs/cc/class/tensorflow/ops/depth-to-space) too.\r\n\r\n@markdaoust Any idea why we're not rendering the code blocks in our C++ ops documentation?", "Maybe triple ``` should be single ` ?", "@shitian-ni: These are rendering correctly in the python docs (singles are for inline, triples are for blocks).\r\n\r\nhttps://www.tensorflow.org/versions/r1.2/api_docs/python/tf/depth_to_space\r\n\r\n@jart: I'm not very familiar with that section of the docs pipeline, I'll find the right person.", "The document is in tensorflow\\core\\ops\\array_ops.cc, I am willing to fix this, should we remove all  ```  as python API: https://www.tensorflow.org/api_docs/python/tf/depth_to_space ?\r\n\r\nThanks", "If you remove the ``` you need to indent 4 spaces so we parse it as Markdown regardless, otherwise it will still render poorly.\r\n\r\nI think we have an internal bug open to do some processing to the C++ docs regardless, however.", "so this issue will be fixed after the internal bug fixed, right?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I'm trying to figure out the state of this, but I think Mark's still working on the backticks bug?  It still looks like the issue is happening in our C++ docs.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is a preprocessing bug.  Tracking this as internal bug #62161343. ", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @MarkDaoust, @dr4b: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @MarkDaoust, @dr4b: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Fixed.", "(fixed internally, it hasn't quite made it up to the site yet)\r\n"]}, {"number": 10240, "title": "wide&deep tutorial for large data.", "body": "When i apply the wide&deep tutorial  code to much larger dataset with millions of rows, I received \r\n\r\n[libprotobuf ERROR google/protobuf/io/zero_copy_stream_impl_lite.cc:173] Cannot allocate buffer larger than kint32max for StringOutputStream.\r\n\r\nor sometimes\r\n\r\n\r\nValueError: GraphDef cannot be larger than 2GB.\r\n\r\nAny simple fix?  I pretty much want to apply the combined classifier in the tutorial.", "comments": ["Googling the error and wide&deep yielded these results. Please see if they help you.\r\n\r\nhttps://stackoverflow.com/questions/36349049/overcome-graphdef-cannot-be-larger-than-2gb-in-tensorflow\r\nhttps://github.com/tensorflow/tensorflow/issues/5383\r\nhttps://stackoverflow.com/questions/41439136/wide-deep-learning-for-large-data-error-graphdef-cannot-be-larger-than-2gb\r\n", "I tried tf.train.slice_input_producer and tf.train.batch, the error still persists. This means, even using batch, the whole data is first loaded into graph somehow... Seems like a bug...", "if you put your data into numpy or pandas then you can use tf.estimator.inputs.pandas_input_fn or tf.estimators.numpy_input_fn.  Those functions does not put all your data into graph.", "@ispirmustafa , ok, so the nice thing of input_fn is that we can preprocess the data. In my case, i would like to have categorical variables hashed and embedded, so input_fn can do this easily. But it is not easy just pass in X and y.\r\nPut it simply, if i want to do the something as in deep&wide tutorial, but given a data set say 100GB. I want to train in batch and load only that batch into the graph, what is the solution? Thanks! Having been struggling with this for days and many people in stackoverflow have a similar question.", "For reading from a large data which is not in-memory, you can check out `tf.contrib.learn.io.read_batch_features` and similar ones. \r\nThey work on tf.Examples. \r\n", "Another thing that bothers me is the following.  m = DNNclassifier(...), and after i trained the model m.fit(), the model is saved. Then i can later restore the model and use new data to train from there. However, i found that the data is accumulated into graph, eventually, i got a cpkt file ~300GB and breaks memory. The question is, how to adjust this? Why after m.fit, the input data as tensor will also be saved and after restore each time, this parts get accumulated...", "your observation says input-fn is doing something wrong.\r\nI would try hard to reuse the input_fns in our library (numpy_input_fn, read_batch_features, ....). Those functions will not have issues you have described.", "I'm using tf.train.slice_input_producer and tf.train.batch inside input_fn, and after the model is trained, the data tensor is saved with the model.", "For concrete purpose, I'm doing something very similar to this http://blog.mdda.net/ai/2017/02/25/estimator-input-fn", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Hi @lancerts,\r\nYou can use given input_fn utilities and also do preprocess. Following is shows an example:\r\n```\r\ndef my_input_fn():\r\n  features, labels = tf.estimator.inputs.pandas_input_fn(...)\r\n  features['a'] = preprocess(features['a'])\r\n```\r\nAlso please try using `tf.data.*` utilities. Following SO question has an example answer: https://stackoverflow.com/questions/47732186/tensorflow-tf-record-too-large-to-be-loaded-into-an-np-array-at-once", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "i met the same problem, have you solve this problem,please give me some advices,thanks!!"]}, {"number": 10239, "title": "can not run   \u201cbazel build inception/download_and_preprocess_imagenet\u201d", "body": "it always give error:\"no such target '//:inception/download_and_preprocess_imagenet': target 'inception/download_and_preprocess_imagenet' not declared in package '' defined by /home/hank/tensorflow/BUILD.\"\r\nthe BUILD file is empty.", "comments": ["It looks like the inception model docs are out of date. We would gladly welcome contributions improving the documentation. https://github.com/tensorflow/models/tree/master/inception", "On second thought, let me take care of this for you.", "Thanks a lot. I have figured it out, i built in a wrong folder. :(\n\nbst rgds\n\n> \u5728 2017\u5e745\u670827\u65e5\uff0c14:07\uff0cJustine Tunney <notifications@github.com> \u5199\u9053\uff1a\n> \n> On second thought, let me take care of this for you.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "I had a feeling people might get confused by that.\r\n\r\nThe good news is that, thanks to you, no one will experience that same pain in the future. I added `cd` statements to all the README examples in https://github.com/tensorflow/models/pull/1510."]}, {"number": 10238, "title": "ImportError with macOS", "body": "when I run \r\n`from tensorflow.examples.tutorials.mnist import input_data`\r\nin my terminal, following error occur:\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-5-7cee33d24aa5> in <module>()\r\n----> 1 from tensorflow.examples.tutorials.mnist import input_data\r\n\r\n/Users/zklgame/anaconda/lib/python2.7/site-packages/tensorflow/examples/tutorials/mnist/__init__.py in <module>()\r\n     19 from __future__ import print_function\r\n     20 \r\n---> 21 from tensorflow.examples.tutorials.mnist import input_data\r\n     22 from tensorflow.examples.tutorials.mnist import mnist\r\n\r\n/Users/zklgame/anaconda/lib/python2.7/site-packages/tensorflow/examples/tutorials/mnist/input_data.py in <module>()\r\n     27 from six.moves import xrange  # pylint: disable=redefined-builtin\r\n     28 import tensorflow as tf\r\n---> 29 from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\r\n\r\n/Users/zklgame/anaconda/lib/python2.7/site-packages/tensorflow/contrib/__init__.py in <module>()\r\n     20 \r\n     21 # Add projects here, they will show up under tf.contrib.\r\n---> 22 from tensorflow.contrib import bayesflow\r\n     23 from tensorflow.contrib import compiler\r\n     24 from tensorflow.contrib import copy_graph\r\n\r\nImportError: cannot import name bayesflow\r\n```\r\n\r\nI have try it on both the pip-installed version and built-from-source version, and they both failed.\r\n Here is some infomation about my env:\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin zklgamedeMacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.5\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 8.1.0 (clang-802.0.42)\r\nTarget: x86_64-apple-darwin16.6.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin zklgamedeMacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nnumpydoc (0.6.0)\r\nprotobuf (3.2.0)\r\ntensorflow (1.0.1)\r\ntensorflow-gpu (1.0.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.0.1\r\ntf.GIT_VERSION = v1.0.1-3-g905662a1c-dirty\r\ntf.COMPILER_VERSION = v1.0.1-3-g905662a1c-dirty\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH /usr/local/cuda/lib:/usr/local/cuda/lib:\r\n\r\n== nvidia-smi ===================================================\r\n\r\n== cuda libs  ===================================================\r\n\r\n```\r\n\r\nSolution:\r\nJust now, I found to update my dask package to 0.14.3 help me.\r\n`conda update dask`\r\n\r\nIt's quite hard for me to found this solution and fix it..\r\n", "comments": []}, {"number": 10237, "title": "Add a tip for tf.train.LoggingTensorHook", "body": "`INFO` logs are not printed by default unless in IPython. Add a friendly tip for newcomers.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "Jenkins, test this please"]}, {"number": 10236, "title": "Remove \"bazel clean\" after new release", "body": "In the new release of bazel, #8880 was fixed which required `bazel clean` at the end of `configure`.\r\n```\r\n# TODO(gunan): Remove once bazel correctly handles changes in remote repositories.\r\nbazel clean\r\n```\r\nCould @gunan look if this is save to remove now?", "comments": []}, {"number": 10235, "title": "fix the return value of Tensor::flat_inner_outer_dims", "body": "The const version of `flat_inner_outer_dims` should return `ConstTensor` instead of `Tensor`", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please."]}, {"number": 10234, "title": "Update tensorboard development instructions", "body": "I want to be able to run tensorboard in development mode and make some changes.\r\n\r\nfrom the [DEVELOPMENT document:](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/DEVELOPMENT.md)\r\n\r\n> bazel run third_party/tensorflow/tensorboard/components/tf_tensorboard:demo\r\n\r\nbut this command seems to be obsolete from the directory structure (there is no target inside /third_party).\r\n\r\nalso seems there is a `.idea` folder committed in the repository. \r\nWould be nice to know how the core team setups their environment.\r\n", "comments": ["@dandelionmane @jart : Mind taking a look?", "[The `README.md` is currently up-to-date.](https://github.com/tensorflow/tensorboard/blob/master/README.md#usage) We should, as you indicate, update `DEVELOPMENT.md`. I'll just go ahead and do this in our new repository at https://github.com/tensorflow/tensorboard. Thanks for reporting.\r\n\r\nAs to development environments, it's just everyone's own taste; we don't have a single unified setup. In fact, we're all quite different: I believe we've got Linux with vim, Linux/Mac with Sublime, Linux on emacs/IntelliJ, and using a Google-internal web IDE. :-)"]}, {"number": 10233, "title": "Tensorboard does not support multiple google cloud directory as logdir", "body": "I would like to launch tensorboard with\r\n\r\n    tensorboard --logdir gs://path1,gs://path2\r\n\r\nor even better\r\n  \r\n     tensorboard --logdir model1:gs://path/1,model2:gs://path/2\r\n\r\nbut this is not currently supported. \r\n\r\nIt should be an easy addition and I can provide a patch if it make sense. \r\n\r\n", "comments": ["This works for me. Help me better understand why it doesn't work for you?", "it only displays the first directory but not the second. Is useful you want to compare two different runs on Google cloud. ", "Chances are something's weird about the second one. Maybe it's slow to load. Maybe it's corrupted. Try flipping 1 and 2 and see what happens.", "I'm closing this due to inactivity. Please feel free to re-open it in our new repository at https://github.com/tensorflow/tensorboard."]}, {"number": 10232, "title": "module 'tensorflow.contrib' has no attribute 'signal'", "body": "Previously, I got the `signal` package merged into `contrib`: #9236\r\n\r\nBut now that I recompiled it all after a while, I got this when trying to use it:\r\n`AttributeError: module 'tensorflow.contrib' has no attribute 'signal'`\r\n\r\nSince all the tests went through, how can it be it can't even be found?\r\nCould I have missed adding yet another reference to the package somewhere?\r\n\r\n`tf.contrib.layers.batch_norm` does work\r\n`tf.contrib.signal.frames` does not work", "comments": ["I think you need to add an import to `tensorflow/contrib/__init__.py`", "(The tests don't import the public API; otherwise all tests would be run on any change to any file).", "Thanks @vrv, what about other unlisted `contrib` packages like:\r\n`android, batching, benchmark_tools, boosted_trees, cmake, hooks, hvx, imperative, makefile, mpi, pi_examples, verbs, xla_tf_graph`\r\nAre all of these not included intentionally or should - at least some of them - be added as well?", "I am not sure, I suspect we should leave as is for now. Thanks!\n\nOn Sun, May 28, 2017, 10:39 AM Androbin <notifications@github.com> wrote:\n\n> Thanks @vrv <https://github.com/vrv>, what about other unlisted contrib\n> packages like:\n> android, batching, benchmark_tools, boosted_trees, cmake, hooks, hvx,\n> imperative, makefile, mpi, pi_examples, verbs, xla_tf_graph\n> Are all of these not included intentionally or should they be added as\n> well?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10232#issuecomment-304528890>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAcTebiaN0XNmcMQG8v-dsxufWZUinIVks5r-bE3gaJpZM4NoHRV>\n> .\n>\n"]}, {"number": 10231, "title": "Disable flaky tests that have been breaking nightly builds.", "body": "FYI @caisq @mrry @ekelsen @alisidd ", "comments": ["Did my CL that went in yesterday not fix the stage_op_test ?  Actually, it looks like it got merged this morning.  You might not need to disable that test.", "@ekelsen @caisq I probably looked into test results before your changes were merged. reverting changes to stabe_op_test and example_test"]}, {"number": 10230, "title": "Suppress linker warnings in windows builds.", "body": "", "comments": []}, {"number": 10229, "title": "[WIP] Add boston.ipynb for better input_fn tutorial", "body": "Here is ipython (jupyter) version, with these features:\r\n- modularized \r\n- with plots to visualize  the model performance\r\n- easy to tune the model", "comments": ["Can one of the admins verify this patch?", "Is this in response to some issue?", "No. It is an improvement and for re-usability.\n\nOn Thu, Jun 8, 2017 at 11:34 AM, Martin Wicke <notifications@github.com>\nwrote:\n\n> Is this in response to some issue?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10229#issuecomment-307140097>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFr9uqaYZRzUd0pSjFfyUclPSL8jWnfiks5sCBSGgaJpZM4Nn9En>\n> .\n>\n", "It's a new file, do you anticipate it being referenced from a tutorial? It's in the tutorials directory, and the name suggests if should be explained in the input_fn tutorial, is that the plan?", "Yes. That is the plan\nOn Thu, Jun 8, 2017 at 11:41 AM Martin Wicke <notifications@github.com>\nwrote:\n\n> It's a new file, do you anticipate it being referenced from a tutorial?\n> It's in the tutorials directory, and the name suggests if should be\n> explained in the input_fn tutorial, is that the plan?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10229#issuecomment-307142213>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFr9ujwzcvlFJi6bC-WRwewWQ54mXDL9ks5sCBYpgaJpZM4Nn9En>\n> .\n>\n", "Ok, in that case, I've marked this WIP, and we'll look at it together with the modifications to the actual tutorial. \r\n\r\n@wolffg @dr4b FYI. Who's working on the input_fn tutorial? Can't find Barry on GH.", "I'm not sure who's working on input_fn (it's not me as far as I know?), but Barry is @jugglerix if that helps.", "@jugglerix any luck with this?", "Closing due to lack of response for 4 weeks, please re-open a new PR with the addressed changes if you can!  Thank you for your contribution."]}, {"number": 10228, "title": "Branch 155393864", "body": "", "comments": []}, {"number": 10227, "title": "Add an option to enable CORS in TensorBoard", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:  b'unknown' 1.1.0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA 8, cuDNN 5.1\r\n- **GPU model and memory**: 1080ti 11GB\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nThe [DeepDream notebook example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb) in TensorFlow provides a snippet that uses https://tensorboard.appspot.com to embed `<iframe>`s inside a Jupyter notebook. Changing this snippet to point to a local instance of TensorBoard fails with a CORS error\r\n\r\n![](http://i.imgur.com/WogWPOR.png)\r\n\r\nHaving the option to enable CORS when starting TensorBoard, or enabling it by default, would make it really easy to use the snippet to visualize directly in Jupyter using a local instance of TensorBoard.\r\n\r\n### Source code / logs\r\n\r\nHere's the snippet in its whole, with modified URL to point to `http://localhost:6006` instead of `https://tensorboard.appspot.com`\r\n\r\n```python\r\n# TensorFlow Graph visualizer code\r\nimport numpy as np\r\nfrom IPython.display import clear_output, Image, display, HTML\r\n\r\ndef strip_consts(graph_def, max_const_size=32):\r\n    \"\"\"Strip large constant values from graph_def.\"\"\"\r\n    strip_def = tf.GraphDef()\r\n    for n0 in graph_def.node:\r\n        n = strip_def.node.add() \r\n        n.MergeFrom(n0)\r\n        if n.op == 'Const':\r\n            tensor = n.attr['value'].tensor\r\n            size = len(tensor.tensor_content)\r\n            if size > max_const_size:\r\n                tensor.tensor_content = \"<stripped %d bytes>\"%size\r\n    return strip_def\r\n\r\ndef show_graph(graph_def, max_const_size=32):\r\n    \"\"\"Visualize TensorFlow graph.\"\"\"\r\n    if hasattr(graph_def, 'as_graph_def'):\r\n        graph_def = graph_def.as_graph_def()\r\n    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\r\n    code = \"\"\"\r\n        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\r\n        <script>\r\n          function load() {{\r\n            document.getElementById(\"{id}\").pbtxt = {data};\r\n          }}\r\n        </script>\r\n        <link rel=\"import\" href=\"http://localhost:6006/tf-graph-basic.build.html\" onload=load()>\r\n        <div style=\"height:600px\">\r\n          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\r\n        </div>\r\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\r\n\r\n    iframe = \"\"\"\r\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\r\n    \"\"\".format(code.replace('\"', '&quot;'))\r\n    display(HTML(iframe))\r\n```", "comments": ["I would recommend working around this with nginx.\r\n\r\n```nginx\r\nserver {\r\n  listen 80 default_server;\r\n  listen [::]:80 default_server ipv6only=on;\r\n\r\n  location / {\r\n    proxy_http_version 1.1;\r\n    proxy_pass http://127.0.0.1:6006;\r\n    add_header 'Access-Control-Allow-Origin' '$cors_origin';\r\n    add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\r\n    add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Custom-Header-1';\r\n  }\r\n}\r\n```\r\n\r\n@dandelionmane Should we add an `--insecure_cors` flag? Or a `--header=Foo:bar` flag where the user repeats all that, and it gets applied to all responses?", "Since the NGINX workaround seems sufficient, I'm going to close this one out.\r\n\r\nPlease note that we're planning to productionize TensorBoard. Things like CORS will be part of our configuration scripts. Please follow https://github.com/tensorflow/tensorboard/issues/92 for more information.\r\n\r\nWith that said, I'm going to close this one out. If anyone feel strongly that header customization or CORS should be part of TensorBoard core, let me know."]}, {"number": 10226, "title": "Inconsistent Tensor Initialization on Multiple GPUs", "body": "### The problem (bug?):\r\nI'm having trouble getting consistent initialization of variables across multiple GPUs, and it appears to be a bug. Below is a test that replicates the bug.\r\n\r\nBasically, the test just sets up a tensor on each GPU and an initializer for each. After running initialization and grabbing the initialized tensors, they do not match despite the same initializer configurations. The problem exists across multiple platforms, any number of GPUs > 1, and multiple TF versions.\r\n\r\nGory details: The inconsistency is non-deterministic, occurring in about 50% of runs with 2 GPUs. Roughly 0.0002% of matrix values do not match. The matrix indices that do not match have significantly different values (i.e. greater than FP rounding errors). Assuming row-major tensor storage, the incorrect indices are in contiguous groups of 4 floats (16B), and the distance - in memory addresses - between these groups is consistent but platform dependent (e.g. 512kB stride between groups on GTX980 vs. 480kB between groups on K40m)\r\n\r\n- **I have written custom code**:\r\n```\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass AllreduceTest(test.TestCase):\r\n    def dumpFailure(self, my_rank, num_ranks, first_output, second_output):\r\n        out_dims = first_output.shape\r\n        assert(len(out_dims) == 2)\r\n        for i in range(out_dims[0]):\r\n            for j in range(out_dims[1]):\r\n                if first_output[i][j] != second_output[i][j]:\r\n                    print(\"{}: [{}][{}]: {} {}\"\r\n                          .format(my_rank, i, j, first_output[i][j],\r\n                                  second_output[i][j]),\r\n                          flush=True)\r\n\r\n    def test_mpi_allreduce(self):\r\n        num_gpus = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\r\n        gpu_indices = [index for index in range(num_gpus)]\r\n\r\n        mat_dim = 3072\r\n\r\n        outputs = []\r\n        for index in gpu_indices:\r\n            with tf.device(\"/gpu:{}\".format(index)):\r\n                initer = tf.random_uniform_initializer(-0.1, 0.1, seed=1234,\r\n                                                       dtype=tf.float32)\r\n                outputs.append(tf.get_variable(\"outputs-{}\".format(index),\r\n                                               shape=(mat_dim, mat_dim),\r\n                                               dtype=tf.float32,\r\n                                               initializer=initer))\r\n\r\n        # Session to test initialization across multiple GPUs\r\n        gpu_options = tf.GPUOptions(\r\n            visible_device_list=','.join(str(idx) for idx in gpu_indices))\r\n        config = tf.ConfigProto(gpu_options=gpu_options)\r\n        with tf.Session(config=config) as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            output_result = sess.run(outputs)\r\n            for index in gpu_indices:\r\n                if not np.allclose(output_result[0], output_result[index]):\r\n                    print(\"CRAP: Init outputs 0 and {} do not match\"\r\n                          .format(index), flush=True)\r\n                    self.dumpFailure(index, num_gpus, output_result[0],\r\n                                     output_result[index])\r\n                    assert(np.allclose(output_result[0],\r\n                                       output_result[index]))\r\n\r\nif __name__ == '__main__':\r\n    test.main()\r\n```\r\n\r\n### System information\r\n- **OS Platform and Distribution**: Linux Ubuntu 14.04.2\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: 1.0.1 (`tf.GIT_VERSION = b'v1.0.1-0-ge895d5c', tf.COMPILER_VERSION = b'v1.0.1-0-ge895d5c', protobuf = 3.1.0`) and 1.1.0-rc2 (`tf.GIT_VERSION = b'v1.1.0-rc2-1164-g1d993dd', tf.COMPILER_VERSION = b'v1.1.0-rc2-1164-g1d993dd', protobuf = 3.3.0`)\r\n- **Bazel version**: 0.45\r\n- **Numpy version**: 1.12.1\r\n- **CUDA/cuDNN version**: cuda-8.0, cudnn-6\r\n- **GPU model and memory**: GeForce GTX 980, TITAN X Maxwell, Tesla K40m, Tesla M40 24GB\r\n", "comments": ["I have traced this bug back to a race condition in the PhiloxRandom GPU code. Taking a stab at a fix, and will post a PR after testing.", "Thanks for looking into it, looking forward to a PR.\r\n\r\nFYI @ekelsen ", "Created PR here that fixes the race condition: #10298", "Thanks for creating the fix @jthestness!"]}]