[{"number": 9797, "title": "Bijector caching breaks when used with TransformedDistribution", "body": "Currently, the caching that [Bijector](https://github.com/tensorflow/tensorflow/blob/7fa0cf39f854d5fdaaa19ad6425dfed02f5fea64/tensorflow/python/ops/distributions/bijector_impl.py#L114) objects do to avoid unnecessary calculations does not work when the bijector is used in a [TransformedDistribution](https://github.com/tensorflow/tensorflow/blob/7fa0cf39f854d5fdaaa19ad6425dfed02f5fea64/tensorflow/python/ops/distributions/transformed_distribution.py#L124) object. I believe the culprit is the reshaping that the distribution object does [here](https://github.com/tensorflow/tensorflow/blob/7fa0cf39f854d5fdaaa19ad6425dfed02f5fea64/tensorflow/python/ops/distributions/distribution.py#L640); when we call Bijector.inverse on the output, the Bijector object cannot tell that this is merely a reshaped version of what it calculated previously.\r\n\r\nMy use case is to sample from a TransformedDistribution and then later calculate the log probability of that sample.\r\n\r\nThis issue is particularly a problem when using a bijector whose inverse is numerically delicate (in my case, I'm chaining together softplus bijectors and my own custom affine bijector).\r\n\r\nI'm willing to work on a fix for this problem, but I'm not sure what the best way to do it is (adding caching to the TransformedDistribution code might work, but that seems like code duplication).\r\n\r\n### System information\r\n- **OS Platform and Distribution**: Ubuntu 16.04\r\n- **TensorFlow installed from**: Source\r\n- **TensorFlow version**: v1.1.0-rc2-773-g7fa0cf3 (commit 7fa0cf39f854d5fdaaa19ad6425dfed02f5fea64)\r\n- **Bazel version**: 0.4.5", "comments": ["@ebrevdo Can you comment?", "Waiting for response as well, deep bijections work slow for me", "My apologies for the slow response, it looks like this issue was inadvertantly misrouted.\r\n\r\nCaching was fixed on Sept 29 and should be working in 1.4.0-rc0.\r\nhttps://github.com/tensorflow/tensorflow/commit/46cf6262476b1d058e43acacc2c15097cc7bbf5a\r\n\r\nIf youre still seeing a problem, please let me know.\r\n\r\n\r\n", "Closing as fixed."]}, {"number": 9796, "title": "doing inference using batch normalization with only one example", "body": "I build my model using batch normalization with `tf.layers.batch_normalization` . But when i am doing inference using saved model, I have to set the parameter `training=True`  in `tf.layers.batch_normalization` to make it work. Does it should be `training=False`?  Moreover, I have to feed a batch of test examples to make it work. It fails when fed with only one example. \r\nSo what is the right way to use `tf.layers.batch_normalization`?\r\n", "comments": []}, {"number": 9795, "title": "Custom configuration of tf.estimator.Estimator - unfavorable change on tf1.1", "body": "This is a feature request, following a change in behavior from TF1.0 to TF1.1.\r\n\r\n------------------------\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 8 (jessie) 64-bit\r\n- **TensorFlow installed from (source or binary)**: installed using pip\r\n- **TensorFlow version (use command below)**: v1.1.0-rc0-61-g1ec6ed5\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n    my_estimator = tf.estimator.Estimator(\\\r\n        model_fn = my_model_fn, \r\n        model_dir = my_model_dir,\r\n        config=tf.contrib.learn.RunConfig(\r\n            save_checkpoints_steps=20,\r\n            save_checkpoints_secs=None,\r\n            save_summary_steps=40,\r\n        )\r\n    )\r\n\r\n### Describe the problem\r\non tf version 1.0 we could easily configure the checkpoint dump (and more) of tf.contrib.learn.Estimator, as stated above: by sending as an input to the estimator tf.contrib.learn.RunConfig with the desired configuration.\r\non tf version 1.1 this became more complex: the above (and more) configurations in RunConfig are static, and changing them requires either changing the original tf code, or maybe creating a class inheriting from tf.estimator.RunConfig to serve as the config for the estimator.\r\n\r\n### Source code / logs\r\nin tf.estimator.RunConfig (v1.1), e.g.:\r\n  @property\r\n  def save_checkpoints_secs(self):\r\n    return 600\r\n\r\nin tf.contrib.learn.RunConfig (v1.0, yet supported on tf1.1):\r\n  @property\r\n  def save_checkpoints_secs(self):\r\n    return self._save_checkpoints_secs\r\n", "comments": ["@martinwicke Can you comment?  Is this a regression?", "Yes. It's a temporary lockdown. An already existing change will fix this by providing a .replace() method to allow mutations.\r\n\r\n@xiejw FYI", "It is fixed at head. You can do \r\n\r\nnew_config = run_config.replace(\r\n  save_checkpoints_steps=20,\r\n  save_checkpoints_secs=None,\r\n  save_summary_steps=40)", "(note it may take a day or two to hit github)", "ah, never mind -- but that only works if you use `tf.contrib.learn.RunConfig` (which you can use for `tf.estimator.Estimator`). I'll reopen this until it is fixed in `tf.estimators.RunConfig`."]}, {"number": 9794, "title": "how to get image shape after decode in C++ ", "body": "### System information\r\n- **OS Platform and Distribution**: Debian\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.0.1\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: cuda-8.0, cudnn5.1.5\r\n- **GPU model and memory**: 12GB\r\n\r\nI follow the tutorial of [inception label_image](https://www.tensorflow.org/tutorials/image_recognition),  \r\n[source codes](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc) , \r\n[README.md](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image) , I can compile and run the demo c++ code successfully.\r\n\r\nI want to adapt this demo to my own project, the input images to my own Network is height fixed, while width varies accordingly, for example, the original image is size of 64x100, and I want to resize it to 32x50, as I said 32 is the new_height, and I want to know original image size after reading from the file, how can I get width=100 and height=64? then I can get new_width = new_height/height x width=32/64x100=50\r\n\r\nthe following is a small piece of the image_recognition tutorial C++ codes, resize is hard coded to a pre-define size, I try `float_caster.shape()`, `tensor()`, `float_caster.dimension(0)`, etc, all failed(`float_caster`, `file_reader` are all not `Tensor`, I don't know why Google design like this, really slow down the development, and I find no documentation about this), is there any easy way to get the image size? or cast the `tensorflow::Ouput` type to `Tensor`?\r\n\r\none possible way is first use opencv to load the image, and resize it, then copy the elements to tensor like this [example](https://gist.github.com/kyrs/9adf86366e9e4f04addb) **pixel by pixel**, but the performance is the main problem and it seems hard to compile tensorflow along with opencv.  Any one knows some methods using tensorflow's API?\r\n\r\nThanks in advance!\r\n\r\n```\r\n\r\n// Given an image file name, read in the data, try to decode it as an image,\r\n// resize it to the requested size, and then scale the values as desired.\r\nStatus ReadTensorFromImageFile(string file_name, const int input_height,\r\n                               const int input_width, const float input_mean,\r\n                               const float input_std,\r\n                               std::vector<Tensor>* out_tensors) {\r\n  auto root = tensorflow::Scope::NewRootScope();\r\n  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\r\n\r\n  string input_name = \"file_reader\";\r\n  string output_name = \"normalized\";\r\n  auto file_reader =\r\n      tensorflow::ops::ReadFile(root.WithOpName(input_name), file_name);\r\n  // Now try to figure out what kind of file it is and decode it.\r\n  const int wanted_channels = 3;\r\n  tensorflow::Output image_reader;\r\n  if (tensorflow::StringPiece(file_name).ends_with(\".png\")) {\r\n    image_reader = DecodePng(root.WithOpName(\"png_reader\"), file_reader,\r\n                             DecodePng::Channels(wanted_channels));\r\n  } else if (tensorflow::StringPiece(file_name).ends_with(\".gif\")) {\r\n    image_reader = DecodeGif(root.WithOpName(\"gif_reader\"), file_reader);\r\n  } else {\r\n    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.\r\n    image_reader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), file_reader,\r\n                              DecodeJpeg::Channels(wanted_channels));\r\n  }\r\n  // Now cast the image data to float so we can do normal math on it.\r\n  auto float_caster =\r\n      Cast(root.WithOpName(\"float_caster\"), image_reader, tensorflow::DT_FLOAT);\r\n  // The convention for image ops in TensorFlow is that all images are expected\r\n  // to be in batches, so that they're four-dimensional arrays with indices of\r\n  // [batch, height, width, channel]. Because we only have a single image, we\r\n  // have to add a batch dimension of 1 to the start with ExpandDims().\r\n  auto dims_expander = ExpandDims(root, float_caster, 0);\r\n  // Bilinearly resize the image to fit the required dimensions.\r\n  auto resized = ResizeBilinear(\r\n      root, dims_expander,\r\n      Const(root.WithOpName(\"size\"), {input_height, input_width}));\r\n  // Subtract the mean and divide by the scale.\r\n  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),\r\n      {input_std});\r\n\r\n  // This runs the GraphDef network definition that we've just constructed, and\r\n  // returns the results in the output tensor.\r\n  tensorflow::GraphDef graph;\r\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));\r\n\r\n  std::unique_ptr<tensorflow::Session> session(\r\n      tensorflow::NewSession(tensorflow::SessionOptions()));\r\n  TF_RETURN_IF_ERROR(session->Create(graph));\r\n  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));\r\n  return Status::OK();\r\n}\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@concretevitamin I have searched stackoverflow, found no related questions, it may takes quite a long time for someone to answer my question. Since you are the member of TensorFlow project, you must know tensorflow very well, can you give me some hints on getting image size in C++?", "i have the same quesion. is there someone can help us?", "if you are using a python model use  tf.image.resize_image_with_crop_or_pad to resize image or [tf.reshape(tensor, shape, name=None)](https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/reshape) to change dimensions and then call this function from c++"]}, {"number": 9793, "title": "is model ready when Fine-tuning in distributed case", "body": "When we finetune a model on a different task, only a part of vars in the model are restored from the pretrained task and others are left as initial values.\r\nAs many docs recommends([page1](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) [page2](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py)), when training with a local graph, we restore the pretrained model **after** running the global init op(call restoring in \"init_fn\" if MonitoredSession or supervisor is included).\r\nBut in the distributed case, does global init op make \"model_ready\" returns true before the restoring-model called? other non-chief nodes will use the \"not ready\" values. \r\n\r\n", "comments": ["codes in \"prepare_session\" of \"SessionManager\". After \" sess.run(init_op)\", the \"wait_for_session\" nodes will get true for \"_model_ready\", but init_fn have not finished.\r\n```\r\n    if not is_loaded_from_checkpoint:\r\n      if init_op is None and not init_fn and self._local_init_op is None:\r\n        raise RuntimeError(\"Model is not initialized and no init_op or \"\r\n                           \"init_fn or local_init_op was given\")\r\n      if init_op is not None:\r\n        sess.run(init_op, feed_dict=init_feed_dict)\r\n      if init_fn:\r\n        init_fn(sess)\r\n\r\n    local_init_success, msg = self._try_run_local_init_op(sess)\r\n    if not local_init_success:\r\n      raise RuntimeError(\r\n          \"Init operations did not make model ready for local_init.  \"\r\n          \"Init op: %s, init fn: %s, error: %s\" % (_maybe_name(init_op),\r\n                                                   init_fn,\r\n                                                   msg))\r\n\r\n    is_ready, msg = self._model_ready(sess)\r\n    if not is_ready:\r\n      raise RuntimeError(\r\n          \"Init operations did not make model ready.  \"\r\n          \"Init op: %s, init fn: %s, local_init_op: %s, error: %s\" %\r\n          (_maybe_name(init_op), init_fn, self._local_init_op, msg))\r\n    return sess\r\n```", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I'm wondering is this a bug", "@passerbydj Hi,have you solved it yet? 9 months past but still I have exactly the same question as you. "]}, {"number": 9792, "title": "Fix quantizing graph with control flows", "body": "Related to #7162", "comments": ["Can one of the admins verify this patch?", "Can one of the admins verify this patch?", "@petewarden any thoughts?", "@petewarden Working on RNN as part of DeepSpeech and trying to get things up and running, I have been relying on that patch for a while already. You may want to be aware that a slight variation is actually required otherwise there's a very big performance impact. I have not been the only one observing this, as you can see at https://github.com/tensorflow/tensorflow/issues/7162#issuecomment-307994191", "@lissyx are you suggesting that this PR as written needs to be fixed?  if so would you like to comment on what needs to be changed?", "@vrv Well, it is not really that I am stating this PR is wrong, I'm not really in position to judge, and it does indeed fix the issue. However, this will add the node input for any case, not just the broken control flow ones. And experience proved that to come with a non neglicitble perf regression, not only documented by me but others on https://github.com/tensorflow/tensorflow/issues/7162#issuecomment-307994191.\r\n\r\nNow, maybe it is wrong to add the input only on /some nodes/ and the correct fix is indeed the one in this PR, or maybe we just need the PR to be more specific to those nodes. I tried to do something nicer than what was suggested by the very same author of the PR: https://github.com/tensorflow/tensorflow/issues/7162#issuecomment-307994191 but I could not find quickly a nicer way to change the `float_node.name().find(\"/while/\") != string::npos` to something more robust.", "@wodesuck Maybe you can elaborate, after all you are the one who confirmed me the perf regression and how you circumvented that :)", "@petewarden I'm going to hold off on merging until you can re-approve to make sure you're okay with this.", "@petewarden Are there any way to identify whether a node is in a control loop or not, so that I could only add control inputs on those nodes. Otherwise maybe I should add `float_node.name().find(\"/while/\") != string::npos` in this PR, which is a dirty solution but good enough for quantizing `dynamic_rnn`.", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "@wodesuck can you sign the CLA?\r\n@petewarden could you have another look, please?", "For me the exception changes from this\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'model.0_1/decoder/attention/while/attention_1/mul_eightbit/model.0_1/decoder/attention/while/attention_1/mul/Enter/reshape' has inputs from different frames. The input 'model.0_1/decoder/attention/while/attention_1/mul/Enter' is in frame 'model.0_1/decoder/attention/while/model.0_1/decoder/attention/while/'. The input 'encoder_1/layer-0/fw/lstm_block_wrapper/mul_eightbit/encoder_1/layer-0/fw/lstm_block_wrapper/BlockLSTM__port__6/reshape_dims' is in frame ''.\r\n```\r\n\r\n ... to this\r\n\r\n```\r\nValueError: graph_def is invalid at node 'encoder_1/layer-0/bw/lstm_block_wrapper/mul_eightbit/encoder_1/layer-0/bw/lstm_block_wrapper/BlockLSTM__port__6/reshape_dims': Control input '^encoder_1/layer-0/bw/lstm_block_wrapper/BlockLSTM:6' not found in graph_def..\r\n```\r\n\r\n... after applying the proposed fix.\r\n\r\nI'm trying to quantize weights  and nodes of a series of RNNs. ```quantize_weights``` works fine, but ```quantize_nodes``` fails with any available tool.\r\n", "@pks Seem cause by `:6` in the name `^encoder_1/layer-0/bw/lstm_block_wrapper/BlockLSTM:6`, making it an invalid control input name, maybe you could try striping it to `^encoder_1/layer-0/bw/lstm_block_wrapper/BlockLSTM` and see if your model work or not. I would modify this pr once you confirm it.", "CLAs look good, thanks!\n\n<!-- ok -->", "@pks @lissyx please chime in so we can merge this PR.", "@drpngx Sorry, I'm not sure what you need from me.", "@petewarden ping for review", "Jenkins, test this please.", "@petewarden said LGTM, so I'll assume he means it.", "now, when I use quantize_nodes, it will appear tensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'map/while/ToAbsoluteCoordinates/Scale/mul_eightbit/map/while/ToAbsoluteCoordinates/Scale/split/reshape' has inputs from different frames. The input 'map/while/ToAbsoluteCoordinates/Scale/split' is in frame 'map/while/map/while/'. The input 'SecondStagePostprocessor/Reshape_2_eightbit/SecondStagePostprocessor/Tile/reshape_dims' is in frame ''\r\n\r\nIs there any solutions for this? When applied only quantize_weights, it is ok.", "I have addressed the problem, but in faster rcnn, when I used quantize nodes, it appears ValueError: graph_def is invalid at node u'Decode/get_center_coordinates_and_sizes/add_1_eightbit/Decode/get_center_coordinates_and_sizes/unstack__port__1/reshape_dims': Control input '^Decode/get_center_coordinates_and_sizes/unstack:1' not found in graph_def..", "@snownus https://github.com/wodesuck/tensorflow/commit/6c1ab6d34213057f5d70d194094ff48137815ae3 this should fix your problem, could you test it for me?", "@wodesuck  It doesn't have running time error now. Thanks very much for your help! I\r\nhave tried fix this problem several days. And it seems the error comes from\r\ncontrol flow.\r\n\r\nMay i know why NodeNameFromInput works but not input_name? Is it current\r\nnode will find another dependency node from this function?\r\n\r\nThanks again for your contribution!", "@wodesuck \r\n\r\nInvalidArgumentError (see above for traceback): input_max_range must be larger than input_min_range.\r\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/mul_eightbit/SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/sub_1/quantize = QuantizeV2[T=DT_QUINT8, mode=\"MIN_FIRST\", round_mode=\"HALF_AWAY_FROM_ZERO\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/sub_1/_1355, SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/mul_eightbit/SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/sub_1/min/_1357, SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/mul_eightbit/SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ClipToWindow_2/Area/sub_1/max/_1359)]]\r\n\t [[Node: SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1/_1255 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_5246_SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n", "@snownus `NodeNameFromInput` just simply strip `:1` at the end of input name, so that the control input would have a correct name. (tf doesn't allow `:x` in control input name)\r\n\r\nFor you second question, I have saw it once, cause by an empty tensor. `Quantize` need `min < max`, and for an empty tensor `x`, `min(x) = inf` and `max(x) = -inf`, which will break the constraint. I solve it by modify the tf kernel. I am not 100% sure that your problem cause by the same reason as mine, but hope those information helps you.", "@wodesuck Thanks for your explanation...  And one more question about the kernel modification, can you show more details? And it's weird that the error often occurs after several running.", "In `tensorflow/core/kernels/quantize_op.cc`, add few lines as below:\r\n\r\n```\r\n  void Compute(OpKernelContext* ctx) override {\r\n    const Tensor& input = ctx->input(0);\r\n    const float input_min_range = ctx->input(1).flat<float>()(0);\r\n    const float input_max_range = ctx->input(2).flat<float>()(0);\r\n\r\n    if (input.NumElements() == 0) {\r\n      Tensor* output = nullptr;\r\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\r\n\r\n      Tensor* output_min_tensor = nullptr;\r\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(1, {}, &output_min_tensor));\r\n      output_min_tensor->flat<float>()(0) = 0.0;\r\n\r\n      Tensor* output_max_tensor = nullptr;\r\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(2, {}, &output_max_tensor));\r\n      output_max_tensor->flat<float>()(0) = 1.0;\r\n\r\n      return;\r\n    }\r\n\r\n    float min_range;\r\n    float max_range;\r\n    OP_REQUIRES(ctx, !(input_max_range < input_min_range),\r\n                errors::InvalidArgument(\r\n                    \"input_max_range must be larger than input_min_range.\"));\r\n```\r\n\r\nIt just detect whether input is empty or not, if yes, just set `min = 0.0, max = 1.0`. (for it's empty, the value of minmax may not matter, I think)", "@wodesuck , thanks for your help!", "@wodesuck , I run the program and found similar errors in requested_output_min_float and requested_output_max_float (requantize.cc) and update the code following your provided but, the final performance is quite lower.  Do u have any suggestions?", "@snownus \r\n\r\nThe simplest thing you could do is try only add control input to nodes in a `tf.while_loop`. (as disscusions in https://github.com/tensorflow/tensorflow/issues/7162#issuecomment-307994191).\r\n\r\nThen, you could do some benchmark with [benchmark_model](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark) and [timeline](https://towardsdatascience.com/howto-profile-tensorflow-1a49fb18073d), to find the bottleneck of your model.\r\n\r\nThe last suggestion, I have found that `QuantizedMatMul` could speed up if `transpose_b=True`, so a general trick is pre-transposing all the weight matrices.", "Great, this solved my problem, Thank you!", "@wodesuck @snownus Hi, Thank you for your great talk, I am also trying to figure out this problem. So basically, if I use NodeNameFromInput(input_name), the quantized model will say errors like: \r\n\"\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell' has inputs from different frames. The input 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell/Enter_1' is in frame 'model/inference/decoder/while/while_context'. The input 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_1/lstm_cell/zeros' is in frame ''.\r\n\"\r\nbut if I use the input_name directly, because the tensorflow system does not allow node_name followed by :x, so I got the error:\r\n\"\r\nValueError: graph_def is invalid at node 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/MatMul_eightbit/model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell__port__6/reduction_dims': Control input '^model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell:6' not found in graph_def..\r\n\"\r\nAny intelligent thoughts? Thank you!", "> @wodesuck @snownus Hi, Thank you for your great talk, I am also trying to figure out this problem. So basically, if I use NodeNameFromInput(input_name), the quantized model will say errors like:\r\n> \"\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell' has inputs from different frames. The input 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell/Enter_1' is in frame 'model/inference/decoder/while/while_context'. The input 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_1/lstm_cell/zeros' is in frame ''.\r\n> \"\r\n> but if I use the input_name directly, because the tensorflow system does not allow node_name followed by :x, so I got the error:\r\n> \"\r\n> ValueError: graph_def is invalid at node 'model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/MatMul_eightbit/model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell__port__6/reduction_dims': Control input '^model/inference/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper/multi_rnn_cell/cell_2/lstm_cell/LSTMBlockCell:6' not found in graph_def..\r\n> \"\r\n> Any intelligent thoughts? Thank you!\r\n\r\nI met the same problem when quantizing Transformer model graph nodes. Have you solved it? Mnay thx!"]}, {"number": 9791, "title": "Fix verbs compile error", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/9752", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please.", "Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 9790, "title": "ResourceExhaustedError", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: NVIDIA GTX 1080 TI, 11 GB\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\n# Disable linter warnings to maintain consistency with tutorial.\r\n# pylint: disable=invalid-name\r\n\r\nimport argparse\r\nimport sys\r\nfrom collections import namedtuple\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\n\r\nfrom dataset import DataSet\r\n\r\nFLAGS = None\r\nHEIGHT = 276\r\nWIDTH = 72\r\nDEPTH = 3\r\nINPUT_DIMENSION = HEIGHT * WIDTH * DEPTH\r\nNUMBER_CLASSES = 2\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nclass DataSet(object):\r\n\r\n    def __init__(self,\r\n                 images,\r\n                 labels,\r\n                 dtype=tf.float32,\r\n                 reshape=False):\r\n        dtype = tf.as_dtype(dtype).base_dtype\r\n        if dtype not in (tf.uint8, tf.float32):\r\n            raise TypeError(\r\n                'Invalid image dtype %r, expected uint8 or float32' % dtype)\r\n\r\n        assert images.shape[0] == labels.shape[0], (\r\n            'images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\r\n        self._num_examples = images.shape[0]\r\n\r\n        # Convert shape from [num examples, rows, columns, depth]\r\n        # to [num examples, rows*columns] (assuming depth == 1)\r\n        if reshape:\r\n            assert images.shape[3] == 1\r\n            images = images.reshape(images.shape[0],\r\n                                    images.shape[1] * images.shape[2])\r\n\r\n        self._images = images\r\n        self._labels = labels\r\n        self._epochs_completed = 0\r\n        self._index_in_epoch = 0\r\n\r\n    @property\r\n    def images(self):\r\n        return self._images\r\n\r\n    @property\r\n    def labels(self):\r\n        return self._labels\r\n\r\n    @property\r\n    def num_examples(self):\r\n        return self._num_examples\r\n\r\n    @property\r\n    def epochs_completed(self):\r\n        return self._epochs_completed\r\n\r\n    def next_batch(self, batch_size, shuffle=True):\r\n        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\r\n        start = self._index_in_epoch\r\n        # Shuffle for the first epoch\r\n        if self._epochs_completed == 0 and start == 0 and shuffle:\r\n            perm0 = np.arange(self._num_examples)\r\n            np.random.shuffle(perm0)\r\n            self._images = self.images[perm0]\r\n            self._labels = self.labels[perm0]\r\n        # Go to the next epoch\r\n        if start + batch_size > self._num_examples:\r\n            # Finished epoch\r\n            self._epochs_completed += 1\r\n            # Get the rest examples in this epoch\r\n            rest_num_examples = self._num_examples - start\r\n            images_rest_part = self._images[start:self._num_examples]\r\n            labels_rest_part = self._labels[start:self._num_examples]\r\n            # Shuffle the data\r\n            if shuffle:\r\n                perm = np.arange(self._num_examples)\r\n                np.random.shuffle(perm)\r\n                self._images = self.images[perm]\r\n                self._labels = self.labels[perm]\r\n            # Start next epoch\r\n            start = 0\r\n            self._index_in_epoch = batch_size - rest_num_examples\r\n            end = self._index_in_epoch\r\n            images_new_part = self._images[start:end]\r\n            labels_new_part = self._labels[start:end]\r\n            return np.concatenate((images_rest_part, images_new_part), axis=0),\\\r\n                np.concatenate((labels_rest_part, labels_new_part), axis=0)\r\n        else:\r\n            self._index_in_epoch += batch_size\r\n            end = self._index_in_epoch\r\n            return self._images[start:end], self._labels[start:end]\r\n\r\n\r\ndef deepnn(x):\r\n    x_image = tf.reshape(x, [-1, DEPTH, HEIGHT, WIDTH])\r\n    is_training = tf.placeholder(tf.bool)\r\n\r\n    with slim.arg_scope([slim.conv2d, slim.max_pool2d],\r\n                        data_format='NCHW', padding='SAME'):\r\n        with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                            weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\r\n                            biases_initializer=tf.constant_initializer(0.1)):\r\n            with slim.arg_scope([slim.dropout],\r\n                                is_training=is_training):\r\n                net = slim.conv2d(x_image, 64, [5, 5], scope='conv1')\r\n                net = slim.max_pool2d(net, kernel_size=3, stride=2, scope='pool1')\r\n                net = slim.conv2d(x_image, 64, [5, 5], scope='conv2')\r\n                net = slim.max_pool2d(net, kernel_size=3, stride=2, scope='pool2')\r\n                net = slim.flatten(net, scope=\"Flatten\")\r\n                net = slim.fully_connected(net, 384, scope='fc_1',\r\n                                           weights_regularizer=slim.l2_regularizer(0.000005))\r\n                net = slim.fully_connected(net, 192, scope='fc_2',\r\n                                           weights_regularizer=slim.l2_regularizer(0.000005))\r\n                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc_out')\r\n\r\n    return net, is_training\r\n\r\n\r\ndef import_images_and_labels():\r\n    file_path = \"/path/to/file/samples.npz\"\r\n    data = np.load(file_path)\r\n\r\n    print(data['one_hot_labels'].shape)\r\n    print(data['images'].shape)\r\n\r\n    images = data['images'].astype(np.float32)\r\n    labels = data['one_hot_labels'].astype(np.float32)\r\n\r\n    number_training_samples = 17950\r\n    train_data = DataSet(images=images[:number_training_samples, :],\r\n                         labels=labels[:number_training_samples, :])\r\n    validation_data = DataSet(images=images[16000:17950, :], labels=labels[16000:17950, :])\r\n    test_data = DataSet(images=images[17950:-1, :], labels=labels[17950: -1, :])\r\n\r\n    DataSets = namedtuple('DataSets', ['train', 'validation', 'test'])\r\n\r\n    return DataSets(train=train_data,\r\n                    validation=validation_data,\r\n                    test=test_data)\r\n\r\n\r\ndef main(_):\r\n    dataset = import_images_and_labels()\r\n\r\n    # Create the model\r\n    x = tf.placeholder(tf.float32, [None, INPUT_DIMENSION])\r\n\r\n    # Define loss and optimizer\r\n    y_ = tf.placeholder(tf.float32, [None, NUMBER_CLASSES])\r\n\r\n    # Build the graph for the deep net\r\n    y_conv, is_training = deepnn(x)\r\n\r\n    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,\r\n                                                                           logits=y_conv))\r\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n    with tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=1)) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        for i in range(20000):\r\n            batch = dataset.train.next_batch(50)\r\n\r\n            if i % 100 == 0:\r\n                train_accuracy = accuracy.eval(feed_dict={x: batch[0],\r\n                                                          y_: batch[1],\r\n                                                          is_training: False})\r\n                print('step %d, training accuracy %g' % (i, train_accuracy))\r\n\r\n            train_step.run(feed_dict={x: batch[0],\r\n                                      y_: batch[1],\r\n                                      is_training: True})\r\n\r\n        print('test accuracy %g' % accuracy.eval(feed_dict={x: dataset.test.images,\r\n                                                            y_: dataset.test.labels,\r\n                                                            is_training: False}))\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--data_dir', type=str,\r\n                        default='/tmp/tensorflow/mnist/input_data',\r\n                        help='Directory for storing input data')\r\n    FLAGS, unparsed = parser.parse_known_args()\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n\r\n```\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux pcdekon0082 4.8.0-51-generic #54~16.04.1-Ubuntu SMP Wed Apr 26 16:00:28 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux pcdekon0082 4.8.0-51-generic #54~16.04.1-Ubuntu SMP Wed Apr 26 16:00:28 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.11.0)\r\nprotobuf (3.2.0)\r\ntensorflow (1.1.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named tensorflow\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/lib:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:/usr/lib/nvidia-375\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue May  9 13:52:52 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Graphics Device     Off  | 0000:01:00.0      On |                  N/A |\r\n| 26%   46C    P8    18W / 250W |    378MiB / 11171MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1514    G   /usr/lib/xorg/Xorg                             190MiB |\r\n|    0      1904    G   kwin_x11                                        41MiB |\r\n|    0      1910    G   /usr/bin/krunner                                 2MiB |\r\n|    0      1915    G   /usr/bin/plasmashell                            94MiB |\r\n|    0      2047    G   ...s-passed-by-fd --v8-snapshot-passed-by-fd    46MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n\r\n```\r\n\r\n### Describe the problem\r\nWhen loading the test images in order to determine the accuracy, an ResourceExhaustedError is thrown.\r\nThis network model works fine with a private theano based framework.\r\n\r\n### Source code / logs\r\n```\r\n...\r\n...\r\nstep 19800, training accuracy 1\r\nstep 19900, training accuracy 1\r\n2017-05-09 13:13:15.970193: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc)\r\nran out of memory trying to allocate 9.21GiB.  Current allocation summary follows.\r\n2017-05-09 13:13:15.970227: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256):   Total Chu\r\nnks: 1, Chunks in use: 0 256B allocated for chunks. 4B client-requested for chunks. 0B in use in bin. 0B\r\nclient-requested in use in bin.\r\n2017-05-09 13:13:15.970239: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512):   Total Chu\r\nnks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B cl\r\nient-requested in use in bin.\r\n2017-05-09 13:13:15.970247: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024):  Total Chu\r\nnks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B cl\r\nient-requested in use in bin.\r\n2017-05-09 13:13:15.970257: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048):  Total Chu\r\nnks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B cl\r\nient-requested in use in bin.\r\n2017-05-09 13:13:15.970266: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096):  Total Chu\r\nnks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B cl\r\nient-requested in use in bin.\r\n2017-05-09 13:13:15.970275: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192):  Total Chu\r\nnks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B cl\r\nient-requested in use in bin.\r\n2017-05-09 13:13:15.970285: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384):         T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970295: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768):         T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970304: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536):         T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970313: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072):        T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970325: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144):        T\r\notal Chunks: 1, Chunks in use: 0 288.0KiB allocated for chunks. 18.8KiB client-requested for chunks. 0B i\r\nn use in bin. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970334: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288):        T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970342: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576):       T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970350: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152):       T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970357: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304):       T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970365: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608):       T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970374: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216):      T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970383: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432):      T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970392: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864):      T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970401: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728):     T\r\notal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bi\r\nn. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970413: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456):     T\r\notal Chunks: 1, Chunks in use: 0 7.61GiB allocated for chunks. 242.58MiB client-requested for chunks. 0B\r\nin use in bin. 0B client-requested in use in bin.\r\n2017-05-09 13:13:15.970423: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 9.21GiB was 25\r\n6.00MiB, Chunk State:\r\n2017-05-09 13:13:15.970436: I tensorflow/core/common_runtime/bfc_allocator.cc:666]   Size: 7.61GiB | Requ\r\nested Size: 242.58MiB | in_use: 0, prev:   Size: 465.75MiB | Requested Size: 465.75MiB | in_use: 1\r\n2017-05-09 13:13:15.970444: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600000\r\n of size 1280\r\n2017-05-09 13:13:15.970450: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600500\r\n of size 256\r\n2017-05-09 13:13:15.970456: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600600\r\n of size 256\r\n2017-05-09 13:13:15.970463: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600700\r\n of size 256\r\n2017-05-09 13:13:15.970470: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600800\r\n of size 256\r\n2017-05-09 13:13:15.970476: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600900\r\n of size 256\r\n2017-05-09 13:13:15.970483: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600a00\r\n of size 256\r\n2017-05-09 13:13:15.970490: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600b00\r\n of size 256\r\n2017-05-09 13:13:15.970496: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600c00\r\n of size 256\r\n2017-05-09 13:13:15.970504: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d600d00\r\n of size 1536\r\n2017-05-09 13:13:15.970510: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601300\r\n of size 256\r\n2017-05-09 13:13:15.970517: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601400\r\n of size 256\r\n2017-05-09 13:13:15.970524: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601500\r\n2017-05-09 13:13:15.970531: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601800\r\n of size 256\r\n2017-05-09 13:13:15.970538: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601900\r\n of size 256\r\n2017-05-09 13:13:15.970544: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601a00\r\n of size 256\r\n2017-05-09 13:13:15.970551: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601b00\r\n of size 256\r\n2017-05-09 13:13:15.970557: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601c00\r\n of size 256\r\n2017-05-09 13:13:15.970565: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d601d00\r\n of size 19200\r\n2017-05-09 13:13:15.970571: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d606800\r\n of size 256\r\n2017-05-09 13:13:15.970578: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1020d606900\r\n of size 488374272\r\n2017-05-09 13:13:15.970585: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a7c6900\r\n of size 1536\r\n2017-05-09 13:13:15.970592: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a7c6f00\r\n of size 294912\r\n2017-05-09 13:13:15.970599: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a80ef00\r\n of size 768\r\n2017-05-09 13:13:15.970606: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a80f200\r\n of size 1536\r\n2017-05-09 13:13:15.970612: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a80f800\r\n of size 256\r\n2017-05-09 13:13:15.970619: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a80f900\r\n of size 19200\r\n2017-05-09 13:13:15.970625: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a814400\r\n of size 256\r\n2017-05-09 13:13:15.970632: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a814500\r\n of size 1536\r\n2017-05-09 13:13:15.970639: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a814b00\r\n of size 17664\r\n2017-05-09 13:13:15.970646: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a819000\r\n of size 256\r\n2017-05-09 13:13:15.970653: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a819100\r\n of size 294912\r\n2017-05-09 13:13:15.970659: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1022a861100\r\n of size 488079360\r\n2017-05-09 13:13:15.970666: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x102479d9100\r\n of size 1536\r\n2017-05-09 13:13:15.970673: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21700\r\n of size 768\r\n2017-05-09 13:13:15.970680: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21a00\r\n of size 256\r\n2017-05-09 13:13:15.970686: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21b00\r\n of size 256\r\n2017-05-09 13:13:15.970686: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21b00\r\n of size 256\r\n2017-05-09 13:13:15.970693: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21c00\r\n of size 256\r\n2017-05-09 13:13:15.970700: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21d00\r\n of size 256\r\n2017-05-09 13:13:15.970706: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a21e00\r\n of size 256\r\n2017-05-09 13:13:15.970713: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a22000\r\n of size 256\r\n2017-05-09 13:13:15.970720: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a22100\r\n of size 256\r\n2017-05-09 13:13:15.970726: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a22200\r\n of size 256\r\n2017-05-09 13:13:15.970733: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a22300\r\n of size 19200\r\n2017-05-09 13:13:15.970740: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a26e00\r\n of size 19200\r\n2017-05-09 13:13:15.970747: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a2b900\r\n of size 256\r\n2017-05-09 13:13:15.970753: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a2ba00\r\n of size 256\r\n2017-05-09 13:13:15.970760: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10247a2bb00\r\n of size 488374272\r\n2017-05-09 13:13:15.970767: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10264bebb00\r\n of size 488374272\r\n2017-05-09 13:13:15.970773: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281dabb00\r\n of size 1536\r\n2017-05-09 13:13:15.970780: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281dac100\r\n of size 1536\r\n2017-05-09 13:13:15.970787: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281dac700\r\n of size 294912\r\n2017-05-09 13:13:15.970793: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281df4700\r\n of size 294912\r\n2017-05-09 13:13:15.970800: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3c700\r\n of size 768\r\n2017-05-09 13:13:15.970807: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3ca00\r\n of size 768\r\n2017-05-09 13:13:15.970814: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3cd00\r\n of size 1536\r\n2017-05-09 13:13:15.970820: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3d300\r\n of size 1536\r\n2017-05-09 13:13:15.970827: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3d900\r\n of size 256\r\n2017-05-09 13:13:15.970834: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3da00\r\n of size 256\r\n2017-05-09 13:13:15.970840: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e3db00\r\n of size 19200\r\n2017-05-09 13:13:15.970847: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10281e42600\r\n of size 488374272\r\n2017-05-09 13:13:15.970855: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x102479d9700\r\nof size 294912\r\n2017-05-09 13:13:15.970861: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x10247a21f00\r\nof size 256\r\n2017-05-09 13:13:15.970868: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1029f002600\r\nof size 8176048640\r\n2017-05-09 13:13:15.970875: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use\r\n Chunks by size:\r\n2017-05-09 13:13:15.970884: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 31 Chunks of size 256\r\ntotalling 7.8KiB\r\n2017-05-09 13:13:15.970892: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 768 t\r\notalling 3.8KiB\r\n2017-05-09 13:13:15.970899: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280\r\ntotalling 1.2KiB\r\n2017-05-09 13:13:15.970908: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 1536\r\ntotalling 13.5KiB\r\n2017-05-09 13:13:15.970916: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 17664\r\n totalling 17.2KiB\r\n2017-05-09 13:13:15.970924: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200\r\n totalling 93.8KiB\r\n2017-05-09 13:13:15.970931: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 29491\r\n2 totalling 1.12MiB\r\n2017-05-09 13:13:15.970940: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 48807\r\n9360 totalling 465.47MiB\r\n2017-05-09 13:13:15.970947: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 48837\r\n4272 totalling 1.82GiB\r\n2017-05-09 13:13:15.970955: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use ch\r\nunks: 2.27GiB\r\n2017-05-09 13:13:15.970966: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:\r\nLimit:                 10619240448\r\nInUse:                  2442896640\r\nMaxInUse:               2995339008\r\nNumAllocs:                  803473\r\nMaxAllocSize:            488374272\r\n2017-05-09 13:13:15.970984: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **********************\r\n**____________________________________________________________________________\r\n2017-05-09 13:13:15.971003: W tensorflow/core/framework/op_kernel.cc:1152] Resource exhausted: OOM when a\r\nllocating tensor with shape[1945,64,276,72]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1039, in _do_ca\r\nll\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1021, in _run_f\r\nn\r\n    status, run_metadata)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in\r\nraise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[194\r\n5,64,276,72]\r\n         [[Node: conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", padding=\"SAME\", strides=[1, 1\r\n, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, conv2/weights/r\r\nead)]]\r\n         [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/\r\ncpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge\r\n_20_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/localhome/bvde102/development/utilities/trunk/Untersuchungen/CNN/tf-tests/src/baumer_challenge_s\r\nlim.py\", line 145, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/localhome/bvde102/development/utilities/trunk/Untersuchungen/CNN/tf-tests/src/baumer_challenge_s\r\nlim.py\", line 136, in main\r\n    is_training: False}))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 569, in eval\r\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3741, in _eval_u\r\nsing_default_session\r\n    return session.run(tensors, feed_dict)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 778, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 982, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1032, in _do_ru\r\nn\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1052, in _do_ca\r\nll\r\nraise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[194\r\n5,64,276,72]\r\n         [[Node: conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", padding=\"SAME\", strides=[1, 1\r\n, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, conv2/weights/r\r\nead)]]\r\n         [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/\r\ncpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge\r\n_20_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'conv2/convolution', defined at:\r\n  File \"/localhome/bvde102/development/utilities/trunk/Untersuchungen/CNN/tf-tests/src/baumer_challenge_s\r\nlim.py\", line 145, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/localhome/bvde102/development/utilities/trunk/Untersuchungen/CNN/tf-tests/src/baumer_challenge_s\r\nlim.py\", line 110, in main\r\n    y_conv, is_training = deepnn(x)\r\n  File \"/localhome/bvde102/development/utilities/trunk/Untersuchungen/CNN/tf-tests/src/baumer_challenge_s\r\nlim.py\", line 56, in deepnn\r\n    net = slim.conv2d(x_image, 64, [5, 5], scope='conv2')\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", lin\r\ne 181, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 9\r\n18, in convolution\r\n    outputs = layer.apply(inputs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 320, in apply\r\n    return self.__call__(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 290, in __call__\r\n    outputs = self.call(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 156, in c\r\nall\r\n    data_format=utils.convert_data_format(self.data_format, self.rank + 2))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 661, in convolution\r\n    op=op)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 331, in with_space_\r\nto_batch\r\n    return op(input, num_spatial_dims, padding)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 653, in op\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 129, in _non_atrous\r\n_convolution\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 403, in conv2d\r\n    data_format=data_format, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768,\r\nin apply_op\r\n    op_def=op_def)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_\r\nop\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in __init_\r\n_\r\n    self._traceback = _extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1945,64,276,72]\r\n         [[Node: conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", padding=\"SAME\", strides=[1, 1\r\n, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape, conv2/weights/r\r\nead)]]\r\n         [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/\r\ncpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge\r\n_20_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\n", "comments": ["Looks like you are running out of GPU memory, one thing which I would suggest is instead of loading all the images at once( which I see is 1945), I would try to load them in batches (maybe ~ 100) to reduce the memory foot print.", "Thanks for the advice. Nevertheless: It run well on a theano based framework. The GTX 1080 TI has 11 GB of memory. It should be sufficient.", "This is the workaround:\r\n\r\n```python\r\ndef test_accuracy(test_dataset, accuracy_eval, x, y_, is_training):\r\n    number_images = len(test_dataset.images)\r\n    accuracy = 0\r\n\r\n    for _ in range(number_images):\r\n        test_image, test_label = test_dataset.next_batch(1)\r\n        accuracy += accuracy_eval.eval(feed_dict={x: test_image,\r\n                                                  y_: test_label,\r\n                                                  is_training: False})\r\n\r\n    accuracy /= number_images\r\n    print('test accuracy {}'.format(accuracy))\r\n```\r\nIf the moderators think, this issue should be closed, then they can close.", "I am new to tensorflow and Machine Learning. Recently I am working on a model. My model is like below,\r\n\r\n1. Character level Embedding Vector -> Embedding lookup -> LSTM1\r\n\r\n2. Word level Embedding Vector->Embedding lookup -> LSTM2 \r\n\r\n3. [LSTM1+LSTM2] -> single layer MLP-> softmax layer\r\n\r\n4. [LSTM1+LSTM2] -> Single layer MLP-> WGAN discriminator\r\n\r\nwhile I'm working on this model I got the following error. I thought My batch is too big. Thus I tried to reduce the batch size from 20 to 10 but it doesn't work. \r\n\r\n> ResourceExhaustedError (see above for traceback): OOM when allocating\r\n> tensor with shape[24760,100] \t [[Node:\r\n> chars/bidirectional_rnn/bw/bw/while/bw/lstm_cell/split =\r\n> Split[T=DT_FLOAT, num_split=4,\r\n> _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients_2/Add_3/y,\r\n> chars/bidirectional_rnn/bw/bw/while/bw/lstm_cell/BiasAdd)]] \t [[Node:\r\n> bi-lstm/bidirectional_rnn/bw/bw/stack/_167 =\r\n> _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\",\r\n> send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\",\r\n> send_device_incarnation=1,\r\n> tensor_name=\"edge_636_bi-lstm/bidirectional_rnn/bw/bw/stack\",\r\n> tensor_type=DT_INT32,\r\n> _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\ntensor with ***shape[24760,100]*** means 2476000*32/1024*1024 = 75.*** MB memory. I am running the code on a titan X(11 GB) gpu. What could go wrong. Why this type of error occured?\r\n\r\nExtra info: the size of the LSTM1 is 100. for bidirectional LSTM it becomes 200.\r\nThe size of the LSTM2 is 300. For Bidirectional LSTM it becomes 600.\r\n\r\n***Note*** : The error occurred after 32 epoch. My question is why after 32 epoch there is an error. Why not at the initial epoch."]}, {"number": 9789, "title": "Tensorflow Support Problem", "body": "In my support tags there is \"py27     winamd64\", but I have installed python 3.5.2 in my Windows 10, now please tell me what should I do to upgrade my support tags to py35 or py36. ", "comments": ["How did you install Tensorflow on Windows 10? Did you install via pip?", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@jubjamie Actually till now I have not installed and want to know how to install.", "Please start a stack overflow question, link it here and I can help you there. "]}, {"number": 9788, "title": "tensorflow for Nvidia TX1", "body": "### System information\r\n- OS Platform and Distribution: Linux Ubuntu 16.4\r\n- Bazel version (if compiling from source): 0.4.4\r\n- CUDA/cuDNN version: cuda-8.0\r\n\r\n### Describe the problem\r\n\r\nI want to install tensorflow 1.0.0 in Nvidia TX1. I am following [this](http://www.yuthon.com/2017/03/10/TensorFlow-r1-0-on-TX1/) so as to install version 1.0.0. But while installing bazel-0.4.4... I am getting this error \r\n\r\n### Logs\r\n\r\n\tINFO: You can skip this first step by providing a path to the bazel binary as second argument:\r\n\tINFO:    ./compile.sh compile /path/to/bazel\r\n\t\ud83c\udf43  Building Bazel from scratch.......\r\n\t\ud83c\udf43  Building Bazel with Bazel.\r\n\t.WARNING: /tmp/bazel_OpcCR2sk/out/external/bazel_tools/WORKSPACE:1: Workspace name in /tmp/bazel_OpcCR2sk/out/external/bazel_tools/WORKSPACE (@io_bazel) does not match the name given in the repository's definition (@bazel_tools); this will cause a build error in future versions.\r\n\tERROR: No toolchain found for cpu 'unknown'. Valid cpus are: [\r\n\t  arm,\r\n\t  armeabi-v7a,\r\n\t  x64_windows_msvc,\r\n\t  s390x,\r\n\t].\r\n\tINFO: Elapsed time: 6.533s\r\n\r\n\tERROR: Could not build Bazel\r\n\tcp: cannot stat 'output/bazel': No such file or directory\r\n\r\nAny suggestion on this, why this is happing, really helpful.\r\n\r\nThanks,\r\n\r\n\r\n", "comments": ["@jart mind taking a look at the Bazel installation issue?", "@GPrathap There seems to be a related Bazel thread here: https://groups.google.com/forum/#!topic/bazel-discuss/dlc3RmSxGRg that says something about https://github.com/bazelbuild/bazel/commit/e59d3a00ad4861c5e64ef90860d56316377bd50e. Are you using ARM or any type of nonstandard CPU?", "@jart  it returns **aarch64**  when I type` uname -m`. I have done this because [cc_configure.bzl](https://github.com/bazelbuild/bazel/blob/0.4.4/tools/cpp/cc_configure.bzl#L145) in here, it tries to execute `uname -m` then if it gives **aarch64** that  function should return **arm**. So answer to your question is yes. It is being used arm processor.  \r\n\r\nI think [this commit ](https://github.com/bazelbuild/bazel/commit/e59d3a00ad4861c5e64ef90860d56316377bd50e)will resolve the issue. Will try and let you know. Thanks for the suggestion.   ", "Glad I was able to help. If that doesn't work, please file an issue with the Bazel project and include a link to this issue in the report.", "Hi, I also met the same problem with you. The error message is cp: cannot stat 'output/bazel': No such file or directory. And I followed this commit [https://github.com/bazelbuild/bazel/commit/e59d3a00ad4861c5e64ef90860d56316377bd50e](url) and tried several times but it still doesn't work. Any thoughts?"]}, {"number": 9787, "title": "Added TensorBoard to the keras.callbacks API", "body": "When porting my code from Keras to use `tensorflow.contrib.keras`, I found that I couldn't use the `TensorBoard` callback anymore. Even though the code is still present, it was removed from the API `__init__.py` file during [the port](https://github.com/tensorflow/tensorflow/commits/master/tensorflow/contrib/keras/python/keras/callbacks.py) by @fchollet.\r\n\r\nI couldn't find it in the commit history but I assume there was a reason to not bring along TensorBoard right away. This PR is a request for this feature and I'll happily help wherever I can to bring it about.", "comments": ["Can one of the admins verify this patch?", "Can one of the admins verify this patch?", "Jenkins, test this please.", ":tada:", "When i use callbacks meet some wrong, run my program output\"InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'conv2d_3_input' with dtype float and shape [?,28,28,1]\r\n\t [[Node: conv2d_3_input = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\"\r\n\r\nmy code includes callbacks as below:\r\ntbCallback=keras.callbacks.TensorBoard(log_dir='./mygraph', \r\n                                       histogram_freq=1,write_graph=True,\r\n                                       write_grads=True,write_images=True)\r\n\r\nhistory=model.fit(train_x,train_y,\r\n          batch_size=batch_size,callbacks=[tbCallback],\r\n          epochs=epochs, verbose=1, \r\n          validation_data=(test_x, test_y))  \r\n\r\nwhen i change histogram_freq=0, then it can work. but no data be shown in tensorboard.\r\nwhen histogram_freq=1 or 2, the program can work just on first time, but no data shown in tensorboard.  I am so sad for this, hope your help!", "i also have this issue, `histogram_freq` must be setting to `histogram_freq=0`, otherwise, it has issues like:\r\n\r\n> Traceback (most recent call last):\r\n  File \"train.py\", line 94, in <module>\r\n    verbose=1)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 1994, in fit_generator\r\n    callbacks.set_model(callback_model)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/callbacks.py\", line 70, in set_model\r\n    callback.set_model(model)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/callbacks.py\", line 687, in set_model\r\n    tf_summary.histogram('{}_grad'.format(mapped_weight_name), grads)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/summary/summary.py\", line 192, in histogram\r\n    tag=tag, values=values, name=scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 188, in _histogram_summary\r\n    \"HistogramSummary\", tag=tag, values=values, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 513, in _apply_op_helper\r\n    raise err\r\nTypeError: Failed to convert object of type <type 'list'> to Tensor. Contents: [None]. Consider casting elements to a supported type.\r\n", "I did some tests when using this code as below, it does work. but can't obtain tfevent file. so confuzed!\r\ncb=TensorBoard(log_dir='./mygraph',histogram_freq=1,write_graph=True,batch_size=BATCH_SIZE,\r\n                                       write_grads=True,write_images=True)\r\ncallback=[] \r\ncallback=callback.append(cb)\r\nhistory=model.fit(train_x,train_y,\r\n          batch_size=BATCH_SIZE,callbacks=callback,\r\n          epochs=epochs, verbose=1, \r\n          validation_data=(test_x, test_y))     "]}, {"number": 9786, "title": "Not a JPEG issue", "body": ">>bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir /Training_image\r\nLooking for images in 'non-human'\r\nLooking for images in 'human'\r\nCreating bottleneck at /tmp/bottleneck/non-human/Data__negatives_jpeg_cr_night_512x384_cr_night_512x384_rCR_m26_a10_d2005-04-07_t22-38_wN.jpg.txt\r\n2017-05-09 01:56:48.890091: W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\r\nNot a JPEG file: starts with 0x89 0x50\r\nTraceback (most recent call last):\r\n  File \"/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 1105, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 844, in main\r\n    bottleneck_tensor)\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 469, in cache_bottlenecks\r\n    jpeg_data_tensor, bottleneck_tensor)\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 417, in get_or_create_bottleneck\r\n    bottleneck_tensor)\r\n  File \"bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 376, in create_bottleneck_file\r\n    raise RuntimeError('Error during processing file %s' % image_path)\r\nRuntimeError: Error during processing file /Training_images/non-human/Data__negatives_jpeg_cr_night_512x384\r\n\r\nHow to fix this?", "comments": ["I'm guessing the problem that is your image is...drumroll...not a jpeg.\r\n\r\nIt's probably a png.  I recommend using `tf.image.decode_image` if you have a dataset that mixes png and jpeg.  I will fix the error message to explicitly say this.", "@petewarden Any objections to me changing the example to `tf.image.decode_image`?  Too many people have png-jpegs.", "@girving No, this seems like a good change to me, thanks!", "`decode_jpeg` now handles pngs without comment.", "Here is a python script to identify those fault jpg images in a directory.\r\n`  \r\n\r\n    \r\n    import glob \r\n    import os \r\n    import re \r\n    import logging \r\n    import traceback    \r\n    filelist=glob.glob(\"/path/to/*.jpg\")\r\n    for file_obj in filelist:\r\n\t  try:\r\n\t\t\r\n\t\t\tjpg_str=os.popen(\"file \\\"\"+str(file_obj)+\"\\\"\").read()\r\n\t\t\tif (re.search('PNG image data', jpg_str, re.IGNORECASE)) or (re.search('Png patch', jpg_str, re.IGNORECASE)):\r\n\t\t\t\tprint(\"Deleting jpg as it contains png encoding - \"+str(file_obj))\r\n\t\t\t\tos.system(\"rm \\\"\"+str(file_obj)+\"\\\"\")\r\n\t  except Exception as e:\r\n\t\tlogging.error(traceback.format_exc())\r\n    print(\"Cleaning jps done\")`", "@Mohit-Ak Note that you don't need to do this anymore; Tensorflow's `decode_jpeg` handles PNGs.", "But I faced the same issue when I used the Object Detection API.  This happens on the Cloud Training when it reads the \".record\" file.\r\n\r\nI don't know the place where the object detection API uses it but it still has the issue. I can give you the logs if you want.", "Ah, the Object Detection API may be parsing the jpeg outside of TensorFlow.  Not much TF can do about that.", "Here are the cloud logs. Just for the reference. We could do a ctrl+F for \"JPEG\" and find a lot of matches.\r\n\r\n21:44:47.081 - Not a JPEG file: starts with 0x89 0x50\r\nTraceback (most recent call last): File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main \"__main__\", fname, loader, pkg_name) File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module> tf.app.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main worker_job_name, is_chief, FLAGS.train_dir) File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 296, in train saver=saver) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 804, in train raise File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__ self.gen.throw(type, value, traceback) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 960, in managed_session self.stop(close_summary_writer=close_summary_writer) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 788, in stop stop_grace_period_secs=self._stop_grace_secs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 386, in join six.reraise(*self._exc_info_to_raise) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 234, in _run sess.run(enqueue_op) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run run_metadata_ptr) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run feed_dict_string, options, run_metadata) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run target_list, options, run_metadata) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call raise type(e)(node_def, op, message) InvalidArgumentError: Invalid JPEG data, size 881303 [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, dct_method=\"\", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:master/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge)]] Caused by op u'case/If_0/DecodeJpeg', defined at: File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main \"__main__\", fname, loader, pkg_name) File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module> tf.app.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main worker_job_name, is_chief, FLAGS.train_dir) File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 184, in train data_augmentation_options) File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 59, in _create_input_queue tensor_dict = create_tensor_dict_fn() File \"/root/.local/lib/python2.7/site-packages/object_detection/builders/input_reader_builder.py\", line 63, in build return tf_example_decoder.TfExampleDecoder().decode(string_tensor) File \"/root/.local/lib/python2.7/site-packages/object_detection/data_decoders/tf_example_decoder.py\", line 121, in decode tensors = decoder.decode(serialized_example, items=keys) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 418, in decode outputs.append(handler.tensors_to_item(keys_to_tensors)) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 302, in tensors_to_item return self._decode(image_buffer, image_format) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 345, in _decode pred_fn_pairs, default=default_decoder, exclusive=True) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2973, in case case_seq = _build_case() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2955, in _build_case name=\"If_%d\" % i) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1738, in cond orig_res, res_t = context_t.BuildCondBranch(fn1) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1639, in BuildCondBranch r = fn() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 323, in decode_jpg return image_ops.decode_jpeg(image_buffer, self._channels) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 345, in decode_jpeg dct_method=dct_method, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op original_op=self._default_original_op, op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__ self._traceback = _extract_stack() InvalidArgumentError (see above for traceback): Invalid JPEG data, size 881303 [[Node: case/If_0/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, dct_method=\"\", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:master/replica:0/task:0/cpu:0\"](case/If_0/DecodeJpeg/Switch:1, ^case/Assert/AssertGuard/Merge)]]", "So that's either an older version of TensorFlow, a different of corruption (not related to PNGs), or a different bug.", "But I cloned it just yesterday and it got fixed after running the above script.", "Then it's a different bug.  Care to diagnose why the format classification logic isn't working?  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/decode_image_op.cc#L156", "@ Mohit-Ak\r\nI am using your code but error occurs 'file' is not recognized as an internal or external command,", "Locking as this is a bug solved over 2 years ago. Please open a new issue, filling in all of the template"]}, {"number": 9784, "title": "add pkg-config generation script", "body": "Opening a pull request as discussed in https://github.com/tensorflow/tensorflow/issues/9703", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I've already signed it.", "CLAs look good, thanks!\n\n<!-- ok -->", "Can one of the admins verify this patch?", "@asimshankar could you take another look, please?", "@tensorflow-jenkins test this please", "@asimshankar thanks.", "Just one quick question. Arch Linux now packages the tensorflow library with the pkgconfig file.\r\nHowever, they place the header file in \r\n```\r\n/usr/include/tensorflow/c_api.h\r\n```\r\ninstead of\r\n```\r\n/usr/include/tensorflow/c/c_api.h\r\n```\r\nIs that a problem? which one should be the standard? Thanks in advance!", "@arrufat : I'd encourage use of `tensorflow/c/c_api.h`. Either can be made to work, but for consistency with the examples we've been putting out and other source code (e.g., how we distribute the tarballs and where other language bindings expect it to be), I'd lean towards `tensorflow/c/c_api.h`.\r\n\r\nHope that helps.\r\n", "@asimshankar thanks for the quick response. I'll suggest that to the packagers."]}, {"number": 9783, "title": "About slim.datasets", "body": "Hello,\r\nI am using tensorflow r1.1.\r\nI try to following the example [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py)\r\n\r\n```\r\npascal_voc_data_provider = DatasetDataProvider(\r\n      slim.datasets.pascal_voc.get_split('train'),\r\n      shuffle=False)\r\n  images, labels = pascal_voc_data_provider.get(['images', 'labels'])\r\n```\r\nBut I get the following error\r\n\r\n```\r\nAttributeError: module 'tensorflow.contrib.slim' has no attribute 'datasets'\r\n```\r\nIs it a bug? or how can I solve this problem?", "comments": ["@sguada The commit history says this was added last June.  Should it work?", "I'm assuming this works by now, please let me know if I'm mistaken.", "I also cannot locate slim.datasets.pascal_voc. please reopen\r\n\r\nEDIT: it seems to have been moved to in general to models/research/slim/datasets , but pascal is no longer there...: "]}, {"number": 9781, "title": "Changing default type from tf.int32 to tf.int64", "body": "I am trying to allocate very large variables inside single-box, but the default out_type of some operators are tf.int32, it's too small as most modern data center machines have more than 100G memory.\r\n\r\nHere is the operators I found:\r\n`tf.shape(input, name=None, out_type=tf.int32)`\r\n`tf.size(input, name=None, out_type=tf.int32)`\r\n`tf.shape_n(input, out_type=None, name=None), out_type defaults to tf.int32`\r\n\r\nFor example if I have one [500000000000] tensor, tf.shape fails with the following error message inside Windows:\r\n\r\n> OverflowError: Python int too large to convert to C long\r\n\r\nLinux has the same issue and chooses overflow instead of raising exceptions.", "comments": ["Unfortunately we can't change the defaults for backwards compatibility reasons.  Can you set `out_type`?", "It's not clear this new default would be a net benefit. People seem to care a lot about training models on GPU fast. This change would double default shape transfer costs, so benchmarking would be needed to make this doesn't introduce a bottleneck that makes some model unexpectedly slow.\r\n\r\nFortunately in Python, there's a general technique you can use to create your own set of custom defaults, called monkey-patching.\r\n\r\nYou could have a module that rewrites TensorFlow Python public API functions with sane defaults for your applications, and because of TensorFlow API compatibility requirements, this would be easy to maintain.\r\n\r\nHere's a fun example of monkey-patching I used to figure out who is adding 'Mul' ops to my graph. \r\n```\r\ndef intersept_op_creation(op_type_name_to_intercept):\r\n  \"\"\"Drops into PDB when particular op type is added to graph.\"\"\"\r\n  from tensorflow.python.framework import op_def_library\r\n  old_apply_op = op_def_library.OpDefLibrary.apply_op\r\n  def my_apply_op(obj, op_type_name, name=None, **keywords):\r\n    print(op_type_name+\"-\"+str(name))\r\n    if op_type_name == op_type_name_to_intercept:\r\n      print(\"Why dost though add %s to my graph!!\" %(op_type_name_to_intercept,))\r\n      import pdb; pdb.set_trace()\r\n    return(old_apply_op(obj, op_type_name, name=name, **keywords))\r\n  op_def_library.OpDefLibrary.apply_op=my_apply_op\r\nintercept_op_creation('Mul')\r\n\r\n```", "I tried to change the default type to int64 and lots of errors, seems quite a lot of dtype inference/computation depends on int32. I think most super-large tensors are used for embedding_lookup, maybe it's possible to change tf.shape out_type to int64 for some operators like gather and gather gradients.\r\n\r\n@yaroslavvb changing default function is one possible solution, thanks.", "@fesun We'd be happy to consider localized changes.", "@girving I changed tf.shape default out_type to int64 inside GatherGrad, everything is fine for me now. No performance impact should happen. Please see pull request #9780 "]}, {"number": 9780, "title": "fix numpy.prod and GatherGrad overflow for large tensors inside windows", "body": "#9462 \r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Sadly, this commit can't solve all overflow issues, see #9781 for tf.shape tf.size etc.", "fixed #9781 ", "Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@fesun This appears to break several tests. Can you take a look?", "@rmlarsen fixed it. Now too many code depends on int32, just suspended windows exception of tf.shape for large tensor.\r\n@tensorflow-jenkins test this please ", "@tensorflow-jenkins test this please", "@rmlarsen There are some python2 issues, already fixed in the latest commit and tested on both python2 and python3. I don't know if there is any way to invoke jenkins test myself? Sorry for your inconvenience.", "@tensorflow-jenkins test this please", "Thanks for the contribution!", "@fesun: Thanks for the contribution. A quick follow up: could you elaborate on the exception thrown that prompted the change to `array_grad.py`? Is there a unittest/code snippet you could share that causes the exception?\r\n\r\n(`array_ops.shape` would throw an exception on all platforms if the provided tensor had a dimension that doesn't fit in 32-bits. So I'm trying to understand what the platform specific part is. Thanks!)"]}, {"number": 9779, "title": "memory leak when implement rnn attention decoder", "body": "### System information\r\n\r\n== cat /etc/issue ===============================================\r\nLinux quad 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux quad 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nprotobuf (3.3.0)\r\ntensorflow-gpu (1.1.0)\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.1.0\r\ntf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\ntf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue May  9 12:16:54 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0     Off |                  N/A |\r\n| 22%   47C    P0    76W / 250W |      0MiB / 12205MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\r\n| 22%   60C    P2   129W / 250W |  11713MiB / 12207MiB |     80%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\r\n| 22%   49C    P0    83W / 250W |      0MiB / 12207MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\r\n| 24%   63C    P2   117W / 250W |  11713MiB / 12207MiB |     70%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    1     21558    C   python3                                      11709MiB |\r\n|    3     21346    C   python3                                      11709MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.7\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-7.5/lib64/libcudart_static.a\r\n/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\r\n/usr/local/cuda-7.5/lib/libcudart_static.a\r\n/usr/local/cuda-7.5/lib/libcudart.so.7.5.18\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\r\n\r\n\r\n### Describe the problem\r\nWhen we try to implement a complex network which contain a rnn attention decoder, It will consume all the memory after several days. I extract the decoder in a test file, the memory still grow in a slower speed. also found that if change softmax to sigmoid, memory doesn't leak.\r\n\r\n### Source code / logs\r\ntest code:\r\n```\r\n# __author__ = \"liusiye\"\r\n# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import GRUCell, MultiRNNCell\r\nfrom os import getpid\r\nimport psutil\r\nimport gc\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nprocess = psutil.Process(getpid())\r\nB, T, H = 20, 60, 256\r\nlayer_num = 4\r\n\r\ndef apply_attention(encoding, rnn_output):\r\n    ''' encoding: [t, b, h1]\r\n        rnn_output: [b, h2]\r\n    '''\r\n    T, B, H1 = encoding.get_shape().as_list()\r\n    _, H2 = rnn_output.get_shape().as_list()\r\n    with tf.variable_scope('attention'):\r\n        w_encoder = tf.get_variable(\r\n            name='W_encoder',\r\n            shape=[H1, H1],\r\n            initializer=tf.random_uniform_initializer(-0.01, 0.01))\r\n        w_decoder = tf.get_variable(\r\n            name='W_decoder',\r\n            shape=[H2, H1],\r\n            initializer=tf.random_uniform_initializer(-0.01, 0.01))\r\n        w_attention = tf.get_variable(\r\n            name='W_attention',\r\n            shape=[H1, 1],\r\n            initializer=tf.random_uniform_initializer(-0.01, 0.01))\r\n    r_decoder = tf.matmul(rnn_output, w_decoder)  # [b, h1]\r\n\r\n    r_encoder = tf.matmul(tf.reshape(encoding, [-1, H1]), w_encoder)\r\n    r_encoder = tf.reshape(r_encoder, [T, B, H1])\r\n    # [t, b, h] -> [t * b, h] -> [t, b, h]\r\n\r\n    r_attention = tf.tanh(r_encoder + r_decoder)  # [t, b, h1]\r\n    attention = tf.matmul(tf.reshape(r_attention, [-1, H1]), w_attention)\r\n    attention = tf.nn.softmax(tf.reshape(attention, [T, B]), dim=0)\r\n    #attention = tf.nn.sigmoid(tf.reshape(attention, [T, B]))\r\n    encoding = tf.transpose(encoding, perm=[2, 0, 1])  # [t, b, h1]->[h1, t, b]\r\n\r\n    context = tf.reduce_sum(encoding * attention, axis=1)  # [h1, b]\r\n    return tf.transpose(context)  # [b, h1]\r\n\r\ndef rnn_attention_decoder_test():\r\n    encoding = tf.get_variable(name='encoding', shape=[T, B, H], dtype=tf.float32)\r\n    rnn_outputs = []  # t * [b, h]\r\n    scope = tf.get_variable_scope()\r\n\r\n    zero_input = tf.constant(0, shape=[B, H], dtype=tf.float32)\r\n    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(H) for i in range(layer_num)], state_is_tuple=True)\r\n    state = cell.zero_state(B, tf.float32)\r\n    with tf.variable_scope(scope) as outer_scope:\r\n        for t in range(T):#T):\r\n            attention_input = zero_input\r\n            rnn_input = apply_attention(encoding, attention_input)\r\n            rnn_output, state = cell(rnn_input, state)\r\n            rnn_outputs.append(rnn_output)\r\n            outer_scope.reuse_variables()\r\n    return tf.stack(rnn_outputs, axis=1), state  # t * [b, h] -> [b, t, h]\r\n\r\nwith tf.Session() as sess, tf.variable_scope('model'):\r\n    with tf.variable_scope('model', reuse=None):\r\n        tensor_lists_test = rnn_attention_decoder_test()\r\n    init_op = tf.group(\r\n        tf.global_variables_initializer(),\r\n        tf.local_variables_initializer()\r\n    )\r\n    sess.run(init_op)\r\n    sess.graph.finalize()\r\n    for step in range(100000):\r\n        after = process.memory_percent()\r\n        if step > 0:\r\n            print(\"MEMORY CHANGE %.7f -> %.7f\" % (before, after))\r\n        before = process.memory_percent()\r\n        sess.run(tensor_lists_test)\r\n        gc.collect()\r\n```\r\n\r\nlog:\r\n```\r\n2017-05-09 09:27:55.435870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-09 09:27:55.435903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-09 09:27:55.435909: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-09 09:27:55.435913: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-09 09:27:55.435916: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-09 09:27:55.732204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \r\nname: GeForce GTX TITAN X\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2405\r\npciBusID 0000:09:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.81GiB\r\n2017-05-09 09:27:55.732232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-05-09 09:27:55.732238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-05-09 09:27:55.732247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\r\nMEMORY CHANGE 1.1297021 -> 1.3666840\r\nMEMORY CHANGE 1.3666840 -> 1.3666840\r\nMEMORY CHANGE 1.3666840 -> 1.3697929\r\nMEMORY CHANGE 1.3697929 -> 1.3697929\r\nMEMORY CHANGE 1.3697929 -> 1.3729200\r\nMEMORY CHANGE 1.3729200 -> 1.3733208\r\nMEMORY CHANGE 1.3733208 -> 1.3733208\r\nMEMORY CHANGE 1.3733208 -> 1.3737215\r\nMEMORY CHANGE 1.3737215 -> 1.3768487\r\nMEMORY CHANGE 1.3768487 -> 1.3799758\r\nMEMORY CHANGE 1.3799758 -> 1.3803644\r\nMEMORY CHANGE 1.3803644 -> 1.3834976\r\nMEMORY CHANGE 1.3834976 -> 1.3834976\r\nMEMORY CHANGE 1.3834976 -> 1.3838862\r\nMEMORY CHANGE 1.3838862 -> 1.3838862\r\nMEMORY CHANGE 1.3838862 -> 1.3842870\r\nMEMORY CHANGE 1.3842870 -> 1.3846878\r\nMEMORY CHANGE 1.3846878 -> 1.3850885\r\nMEMORY CHANGE 1.3850885 -> 1.3850885\r\nMEMORY CHANGE 1.3850885 -> 1.3850885\r\nMEMORY CHANGE 1.3850885 -> 1.3850885\r\nMEMORY CHANGE 1.3850885 -> 1.3850885\r\nMEMORY CHANGE 1.3850885 -> 1.3854771\r\nMEMORY CHANGE 1.3854771 -> 1.3854771\r\nMEMORY CHANGE 1.3854771 -> 1.3854771\r\nMEMORY CHANGE 1.3854771 -> 1.3858779\r\nMEMORY CHANGE 1.3858779 -> 1.3858779\r\nMEMORY CHANGE 1.3858779 -> 1.3858779\r\nMEMORY CHANGE 1.3858779 -> 1.3858779\r\nMEMORY CHANGE 1.3858779 -> 1.3858779\r\nMEMORY CHANGE 1.3858779 -> 1.3858779\r\nMEMORY CHANGE 1.3858779 -> 1.3862665\r\nMEMORY CHANGE 1.3862665 -> 1.3866673\r\nMEMORY CHANGE 1.3866673 -> 1.3866673\r\nMEMORY CHANGE 1.3866673 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3870680\r\nMEMORY CHANGE 1.3870680 -> 1.3874688\r\nMEMORY CHANGE 1.3874688 -> 1.3874688\r\nMEMORY CHANGE 1.3874688 -> 1.3878695\r\nMEMORY CHANGE 1.3878695 -> 1.3878695\r\nMEMORY CHANGE 1.3878695 -> 1.3882581\r\nMEMORY CHANGE 1.3882581 -> 1.3882581\r\nMEMORY CHANGE 1.3882581 -> 1.3886589\r\nMEMORY CHANGE 1.3886589 -> 1.3886589\r\nMEMORY CHANGE 1.3886589 -> 1.3890597\r\nMEMORY CHANGE 1.3890597 -> 1.3894604\r\nMEMORY CHANGE 1.3894604 -> 1.3894604\r\nMEMORY CHANGE 1.3894604 -> 1.3898612\r\nMEMORY CHANGE 1.3898612 -> 1.3898612\r\nMEMORY CHANGE 1.3898612 -> 1.3902619\r\nMEMORY CHANGE 1.3902619 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3906627\r\nMEMORY CHANGE 1.3906627 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3937898\r\nMEMORY CHANGE 1.3937898 -> 1.3941906\r\nMEMORY CHANGE 1.3941906 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3945913\r\nMEMORY CHANGE 1.3945913 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3949921\r\nMEMORY CHANGE 1.3949921 -> 1.3953929\r\nMEMORY CHANGE 1.3953929 -> 1.3953929\r\nMEMORY CHANGE 1.3953929 -> 1.3953929\r\nMEMORY CHANGE 1.3953929 -> 1.3953929\r\nMEMORY CHANGE 1.3953929 -> 1.3953929\r\nMEMORY CHANGE 1.3953929 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3957936\r\nMEMORY CHANGE 1.3957936 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3961944\r\nMEMORY CHANGE 1.3961944 -> 1.3965951\r\nMEMORY CHANGE 1.3965951 -> 1.3965951\r\nMEMORY CHANGE 1.3965951 -> 1.3965951\r\nMEMORY CHANGE 1.3965951 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3969959\r\nMEMORY CHANGE 1.3969959 -> 1.3973967\r\nMEMORY CHANGE 1.3973967 -> 1.3973967\r\nMEMORY CHANGE 1.3973967 -> 1.3973967\r\nMEMORY CHANGE 1.3973967 -> 1.3973967\r\nMEMORY CHANGE 1.3973967 -> 1.3977974\r\nMEMORY CHANGE 1.3977974 -> 1.3977974\r\n```", "comments": ["by the way , if we implement softmax like this, the problem doesn't exists.\r\n# original softmax in TF\r\n    attention = tf.nn.softmax(tf.reshape(attention, [T, B]), dim=0)\r\n\r\n# mannul softmax\r\n    attention = tf.matmul(tf.reshape(r_attention, [-1, H1]), w_attention)\r\n    attention = tf.reshape(attention, [T, B])\r\n    attention_exp = tf.exp(attention)  # [T ,B]\r\n    attention_sum = tf.reduce_sum(tf.exp(attention), axis=0)  # [B]\r\n    attention = attention_exp / attention_sum  # [T, B]", "@ebrevdo Can you take a look?  This seems like a reasonably minimized memory leak bug.", "Is this reproducible in the nightlies?", "This is a stale issue. Please check the issue with latest TensorFlow. If the issue still persists in the newer version of TF, please feel free to reopen it by providing details about the issue and a standalone code to reproduce the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=9779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=9779\">No</a>\n"]}, {"number": 9778, "title": "ImportError: No module named 'tensorflow.tools'", "body": "\r\n### Describe the problem\r\nRun the demo \"transform_graph_test.py\" in Windows, get the error \r\n\"ImportError: No module named 'tensorflow.tools'\"\r\n\r\nDid I miss some installations before running the demo?\r\nThe code \"from tensorflow.tools.graph_transforms import TransformGraph\" cannot work?", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nDirect the demo \"transform_graph_test.py\"\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 7\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nTensorflow 1.0\r\n- **CUDA/cuDNN version**:\r\nCUDA 8.0\r\n\r\n### Describe the problem\r\nRun the source code  demo \"transform_graph_test.py\" in Windows, get the error\r\n\"ImportError: No module named 'tensorflow.tools'\"\r\n\r\nDid I miss some installations before running the demo?\r\nThe code \"from tensorflow.tools.graph_transforms import TransformGraph\" cannot work?", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_tools.cmake#L40 Looking at here, it looks like we do not have transform_graph python files in cmake build.\r\nOur windows binaries are still built using cmake. So, it is expected with the current code that you see this error.\r\n\r\n@petewarden Do we intentionally exclude transrofm_graph python files in cmake build?", "@gunan Will you include transrofm_graph  python files in cmake builds? Or maybe I should install it by source code first?", "We may be able to, but I need to make sure we do not exclude them intentionally on windows, due to other issues.", "We don't intentionally exclude graph transform files for cmake, so I'd be happy to see all of these included by default. Passing back to @gunan for review.", "Actually, we do exclude them intentionally due to posix dependencies graph transform libraries have. Therefore, at the moment this inclusion seems to be infeasible.", "So is it sufficient to install from source (on Windows), or should I switch to Linux?", "Upgrade tensorflow as `pip install --upgrade tensorflow`\r\nIt solved my problem", "@shravan-rams Yes bro your Right!!!\r\n"]}, {"number": 9777, "title": "tf.nn.embedding_lookup  poor performance", "body": "In my programe, I use  f.nn.embedding_lookup as follow:\r\n\r\nembedding = tf.get_variable(\"embedding\", [200000, 128], tf.float32, initializer=tf.        random_normal_initializer(stddev=0.1), trainable=True,partitioner=tf.fixed_size_partitioner(10))\r\n\r\nword_embedding = tf.nn.embedding_lookup(embedding, query_tensor)\r\nwhile(1):\r\n    sess.run(word_embedding )\r\n\r\n\r\nwhen I start 30 worker\uff0ceach worker qps is 3000.\r\nbut when I test tf.nn.embedding_lookup_sparse, each worker qps is 110000\r\n\r\nhow to solve this problem,any suggestion welcome", "comments": ["query_tensor shape is [1000, 20]", "Same problem i got. What is the inner difference implementation in `embedding_lookup_sparse ` and `embedding_lookup `  ? In my view, it is just index lookup and some combination added.", "`embedding_lookup_sparse` invokes `embedding_lookup `, then does some combination. The implementation is different if `sp_weights` is passed or not, which will affect parameter server's load. If `sp_weights` is not passed, ps's load is lower because query ids will be unique.\r\n", "@suiyuan2009  I guess the combination of embedding_lookup_sparse is done in the ps, so the result of embedding_lookup_sparse  is very small ,the shape about [1000,128], but the result of embedding_lookup is a dense tensor,and the shape is [1000,20,128].  the bottleneck is ps network", "@chengdianxuezi , the official api does combination on the device running `embedding_lookup_sparse` op. There is a modified api [embedding_lookup_sparse_with_distributed_aggregation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/embedding_ops.py#L566) which does combination on ps side.", "@suiyuan2009 I use tf.nn.embedding_lookup_sparse and tf.nn.embedding_lookup in the same way,why the  speed gap is great\u3002the speed of tf.nn.embedding_lookup should be fast then tf.nn.embedding_lookup_sparse", "@chengdianxuezi , if `sp_weights` is not passed, duplicates in `sp_ids` will be removed before invoking `embedding_lookup`.", "@suiyuan2009 \r\nI tested the function  `tf.contrib.layers.safe_embedding_lookup_sparse`, which is much more slower than `tf.nn.embedding_lookup_sparse`.  I am not sure whether the time wasted in padding additional values. ", "@wsnooker , try `embedding_lookup_sparse_with_distributed_aggregation`, also I have not tested this api's performance...", "@suiyuan2009 Thank you very much,  use the new api tf.contrib.layers.embedding_lookup_unique, the performance improved, best wish to you", "@chengdianxuezi , can you help to test the performance of `embedding_lookup_sparse_with_distributed_aggregation` compared to `embedding_lookup_sparse`, I write the api but I don't know its performance...", "@suiyuan2009 In the TF distribution, all the variables stored in ps, and the worker has to communicate with ps in the forward and backward. This is a wasteful process if big batch data presented.", "@wsnooker , putting some computation on ps will reduce network traffic and improve parallelism. there is a [paper](https://arxiv.org/abs/1606.08495) at CIKM 2016, they developed a distributed word2vec training system that shares the same thought.", "@suiyuan2009  What kind of computation will be put on ps in TF framework \uff1f As far as I know, the `embedding_lookup` op finished on ps. What about `conv` / `rnn` and some others ?  There is little material about this in TF web.  ", "@wsnooker , I rewrited embedding_lookup mechanism and put some computation on ps.", "Closing due to lack of activity. Please reopen if this is still an issue.", "@suiyuan2009 Why don't you check the performance first before checking in your code? It makes no sense. BTW, I have drew the timeline for ***_distributed_aggregation, sure, part of the computation has been moved to ps, but the overall performance does not improve.", "@chengdianxuezi ,embedding_lookup_unique now can't by found in tensorflow ,do you still use it?"]}, {"number": 9776, "title": "Branch 155393864", "body": "", "comments": ["Jenkins, test this please.\r\n"]}, {"number": 9775, "title": "Feature Request: \"training\" argument for contrib.rnn.DropoutWrapper like the one in tf.layers.dropout", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.0.4\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n\r\n\r\n### Feature Request: \"training\" argument for contrib.rnn.DropoutWrapper for applying dropout depending on train/inference phase.\r\n\r\nIn [`tf.layers.dropout`](https://www.tensorflow.org/api_docs/python/tf/layers/dropout), the `training` parameter is a handy setting that lets you apply dropout depending on whether the model is training or doing inference. It's very convenient to be able to pass a boolean to the model placeholder and have it automatically do the right thing when it comes to dropout.\r\n\r\nUnfortunately, [`tf.contrib.rnn.DropoutWrapper`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper) does not have this same parameter, and I think it would greatly benefit from it. This is a feature request for it.\r\n\r\nI tried implementing it myself with `tf.cond` and either returning the dropped-out outputs/states or the untouched ones, but I couldn't figure out how to share the variables between them in the cond.\r\n", "comments": ["@ebrevdo This seems like a reasonable request.  Can you comment on the best way to add it?", "keep_prob = tf.cond(isDropOut,lambda:tf.constant(0.9), lambda:tf.constant(1.0))\r\ncells = rnn.DropoutWrapper(cells, output_keep_prob=keep_prob) ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Does \"training\" need to be a tensor, or can it be a regular Python bool always?  If so, you don't need the cond() call.", "I understand your confusion. Use a python bool for is_training, it cannot be in graph; while use a tensor.bool for is_training, you need something like tf.is_true(is_training) , but tf without it.\r\n\r\nThe problem can be solved by:\r\n```python\r\nis_training = tf.placeholder_with_default(False, shape=(), name='is_training')\r\nbasic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\r\nkeep_prob = tf.cond(is_training, lambda:tf.constant(0.7), lambda:tf.constant(1.0))\r\nbasic_cell = tf.contrib.rnn.DropoutWrapper(basic_cell, input_keep_prob=keep_prob)\r\noutputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\r\n\r\n# trainging\r\nsess.run(outputs, feed_dict={is_training: True})\r\n```", "Would this approach cause a dropout scaling issue? As I have understood scaling factor is applied to the weights during training phase according to the dropout factor, should it be OK to just change the dropout factor during inference phase?", "Closing this issue, as `tf.contrib` is deprecated in TensorFlow 2.0, and has never been officially supported. Please reopen if the issue is still present in other TF RNN implementations."]}, {"number": 9774, "title": "Cifar-10 link inside Tensorflow webpage report 404", "body": "Not sure if this is the right place for an 404 error...\r\n\r\nThe link to CIFAR-10 source code on Tensorflow webpage reports 404 since yesterday afternoon (08/May/2017), kindly help to fix it.\r\n\r\nThis is the page found contains error:\r\n[https://www.tensorflow.org/tutorials/deep_cnn](url)\r\n\r\nThis is the link found to reports 404:\r\n[https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/image/cifar10/](url)\r\n\r\nThanks", "comments": ["@wolffg - could you please take a look?  ", "This is a duplicate of #9637, and we will be fixing that as soon as we can.   Thanks for reporting!"]}, {"number": 9773, "title": "Add 3D operations for layers: conv3d, avg_pool3d, max_pool3d and conv3d_transpose", "body": "1.Add 3D operations for layers:\r\n\r\nconv3d\r\navg_pool3d\r\nmax_pool3d\r\nconv3d_transpose\r\n\r\n2.Replace a deprecated function in layers_test.py.\r\n\r\n3.Add unit test for avg_pool3d and max_pool3d.", "comments": ["Can one of the admins verify this patch?", "Can one of the admins verify this patch?", "What's the status of this PR?", "@xcyan It's still awaiting the tensorflower's review.", "Thank you. I have fixed the problems you mentioned.", "Some changes from elsewhere got into RELEASE.md. Mind reverting those?", "Jenkins, test this please", "@jhseu OK, now I have reverted the changes of RELEASE.md. Please check it.", "Jenkins, test this please.", "After testing, It gives \"Some checks were not successful.\". When I look at the testing outputs, I found an error:\r\n\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-gpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local_linux-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/layers_test.py\", line 51, in <module>\r\n>     from tensorflow.python.ops.losses import losses\r\n> ImportError: No module named losses\r\n\r\nHowever, when I run it on my computer, or import the losses module directly from Terminal, it has no error. So what's the reason? What need I do to fix it?\r\nThank you.", "@martinwicke Thank you.\r\nNow, I have added the dependency for losses and rescheduled the order of the imports. Please check it.", "Jenkins, test this please.", "It needs to be \"tensorflow/python/ops/losses\".\r\n\r\n```\r\nERROR: /workspace/tensorflow/contrib/layers/BUILD:116:1: no such package 'tensorflow/python/losses': BUILD file not found on package path and referenced by '//tensorflow/contrib/layers:layers_test'.\r\nERROR: Analysis of target '//tensorflow/contrib/layers:layers_test' failed; build aborted.\r\n```", "@martinwicke Thank you. I have modified it. Please test it again.", "Jenkins, test this please.", "It needs to be `//tensorflow/python/ops/losses` or `//tensorflow/python/ops/losses:losses`, without the _py.", "@martinwicke Sorry.\r\nNow I have modified it. Please check and test it again.", "Jenkins, test this please!", "Fixed #9347"]}, {"number": 9772, "title": "Fix how-to reference in distributed runtime README", "body": "The current link 404s, and now that the website documentation has been updated, the link can now point there.", "comments": ["Can one of the admins verify this patch?", "Can one of the admins verify this patch?", "Jenkins, test this please.\r\n"]}, {"number": 9771, "title": "building error, tensorflow master, with bazel 0.4.5, Cuda 8.0, Cudnn 6, Nvidia p100 pci, Ubuntu 16.04", "body": "- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:   ('v1.1.0-rc2-221-g48d9915', '1.1.0-rc2')\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: 8.0/6\r\n- **GPU model and memory**: P100 PCI - 16 GB\r\n- **Exact command to reproduce**:  \r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n./tensorflow/core/util/tensor_format.h(58): warning: missing return statement at end of non-void function \"tensorflow::GetTensorFeatureDimIndex\"                                                                                    \r\n\r\n./tensorflow/core/util/tensor_format.h(71): warning: missing return statement at end of non-void function \"tensorflow::GetTensorSpatialDimIndex\"                                                                                    \r\n\r\nERROR: /root/tensorflow/tensorflow/contrib/verbs/BUILD:135:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 151 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ntensorflow/contrib/verbs/rdma.cc: In member function 'virtual void tensorflow::RdmaTensorBuffer::SendNextItem()':\r\ntensorflow/contrib/verbs/rdma.cc:785:11: error: 'struct tensorflow::WorkerSession' has no member named 'rendezvous_mgr'\r\n         ->rendezvous_mgr->RecvLocalAsync(step_id, parsed, cb);\r\n           ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 252.968s, Critical Path: 205.52s\r\n\r\nThanks", "comments": ["Closing in favor of #9752."]}, {"number": 9770, "title": "Sample Github TensorFlow Issue Renamed", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Testing comments.", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Testing the bot. Updating a comment.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I am commenting on this issue.", "Testing deleted comments with @av8ramit tagged.", "Hi @destinedtobedeleted testing comment."]}, {"number": 9769, "title": "correct the article (a->an) used before ubuntu (uu-boon-tuu)", "body": "To remind developers the correct pronunciation of ubuntu (/\u028a\u02c8bu\u02d0nt\u028a/ uu-boon-tuu). ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please", "Can one of the admins verify this patch?", "Jenkins, test this please.\r\n"]}, {"number": 9768, "title": "download if not exists, extract never overwrite", "body": "Removed the comment for wget and added arguments so that download and extract happens just once", "comments": ["Can one of the admins verify this patch?", "@shlens would you mind taking a look?", "@tensorflow-jenkins test this please", "@shlens you seemed to have an opinion about how should review this. Can you please assign a reviewer?"]}, {"number": 9767, "title": "MKL only supported on 32-bit machine?", "body": "according to [mkl BUILD file](https://github.com/tensorflow/tensorflow/blob/master/third_party/mkl/BUILD#L20) and [mkl util file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/mkl_util.h), the current mkl code is only for 32-bit machine... And I didn't find the declaration of the function`dnnLayoutSerializationBufferSize_F32/64` in header files or `.so` files...", "comments": ["I'm sorry, I download the wrong version of MKL, the right version is in the configure file."]}, {"number": 9766, "title": "Tensorflow worked and now suddenly giving errors ?", "body": "Hello,\r\n\r\nI was able to run tensorflow (both CPU and GPU) without issues yesterday. Today, after restarting my laptop, I get the below error as I tried running Tensorflow. \r\n\r\nI have previously checked that my path variables were set properly and only then Tensorflow worked, but I'm not sure how it suddenly isn't working.\r\n\r\nSystem information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n* Yes\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n* OS = Windows 10\r\n\r\nTensorFlow installed from (source or binary):\r\n*Installed from Source \r\n\r\nTensorFlow version (use command below):\r\n*When I ran =>  python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n*I get only this result =>  b'unknown' 1.0.0\r\n\r\nBazel version (if compiling from source):\r\n*I'm unsure about this as I don't remember installing this\r\n\r\nCUDA/cuDNN version:\r\n*cuda_8.0.61_win10\r\n*cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0\r\n\r\nGPU model and memory:\r\n*GeForce GTX 1050 graphics card\r\n*RAM 32GB\r\n\r\nExact command to reproduce:\r\n*import tensorflow as tf\r\n\r\nError code I got:\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     17         try:\r\n---> 18             return importlib.import_module(mname)\r\n     19         except ImportError:\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py in _gcd_import(name, package, level)\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py in _find_and_load(name, import_)\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py in _find_and_load_unlocked(name, import_)\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py in _load_unlocked(spec)\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py in module_from_spec(spec)\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap_external.py in create_module(self, spec)\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)\r\n---> 41   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     42   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     20             return importlib.import_module('_pywrap_tensorflow_internal')\r\n---> 21     _pywrap_tensorflow_internal = swig_import_helper()\r\n     22     del swig_import_helper\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     19         except ImportError:\r\n---> 20             return importlib.import_module('_pywrap_tensorflow_internal')\r\n     21     _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-3-feaf27c67465> in <module>()\r\n----> 1 import tensorflow as tf\r\n      2 import numpy as np\r\n      3 \r\n      4 IM_SIZE_PX = 50\r\n      5 SLICE_COUNT = 20\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     49 import numpy as np\r\n     50 \r\n---> 51 from tensorflow.python import pywrap_tensorflow\r\n     52 \r\n     53 # Protocol buffers\r\n\r\nC:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     50 for some common reasons and solutions.  Include the entire stack trace\r\n     51 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 52   raise ImportError(msg)\r\n     53 \r\n     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\dines\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.`", "comments": ["It is unable to load the pywrap module. Did you remember to activate your virtualenv if you are using it?\r\n\r\nI would recommend using the dependency walker to find out what DLLs are missing.", "I've managed to solve this issue by uninstalling all (Tensorflow, Anaconda) and reinstalling them all.\r\nI also included .Net Community edition and now it's working all fine."]}]