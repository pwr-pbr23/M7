[{"number": 34023, "title": "Improve logging of TF-TRT", "body": "", "comments": []}, {"number": 34022, "title": "List index out of range for FashionMNIST tutorial.", "body": "I've just started learning a bit about Tensorflow, and I tried out the Fashion MNIST tutorial. However, I keep getting a list index out of range error. I've copied the code from the official tutorial and also tried using tf.reset_default_graph() as suggested in some other posts, but neither have worked.\r\n\r\nHere is the notebook with the error:\r\nhttps://github.com/fsiraj/Tensorflow-Tutorials/blob/master/Fashion%20MNIST.ipynb", "comments": ["@fsiraj ,\r\nHi, in the section \r\n```\r\n# Training loop\r\nmodel.fit(train_images, epochs=10)\r\n```\r\nmodel.fit is expecting `train_labels` \r\nplease use `model.fit(train_images,train_labels, epochs=10)` you will be able to execute the tutorial without any issues.\r\nThanks!", "@oanush \r\nThanks for the quick reply, silly mistake on my behalf. Fixing the issue I ran into another error which I've gotten with another tutorial as well. It says \"InternalError:  Blas GEMM launch failed\". \r\n\r\nHaving just started I'm not sure what to make of this. I've updated the notebook so you can get a look at the new error.", "@fsiraj ,\r\nTry doing a fresh run from the beginning always by restarting the kernal when any changes are made in the code, no error will be faced, please find the [gist](https://colab.sandbox.google.com/gist/oanush/3c3415a29ca3c051fe924b891a579701/34022.ipynb) of colab for your reference . Thanks!", "@oanush \r\nI've tried that but I always run into this error. I'm running the notebook in a conda environment with only tensorflow and other required modules and dependencies. Is this an issue with my system?", "@fsiraj ,\r\nIssue might be due to opening too many Jupyter Notebooks. Please check this [comment](https://github.com/tensorflow/tensorflow/issues/34069#issuecomment-551573104) of similar issue.\r\nAlso find links of these similar issue's and solutions present in them and see if it solves  [1](https://github.com/tensorflow/tensorflow/issues/11812),[2](https://stackoverflow.com/questions/37337728/tensorflow-internalerror-blas-sgemm-launch-failed) and [3](https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed?rq=1).Thanks!", "I tested this and it seems if I have more than one notebook open it always fails. This solves the issue so thank you!\r\n\r\nI was still wondering why this happens it's not very convenient at all."]}, {"number": 34021, "title": "Unable to save TensorFlow Keras LSTM model to SavedModel format", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip installed\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: 3.7.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nUnable to save TensorFlow Keras LSTM model to SavedModel format for exporting to Google Cloud and Google AI platform.\r\n\r\nError message: ValueError: Attempted to save a function b'__inference_lstm_2_layer_call_fn_36083' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 1280), dtype=float32) that is not a simple constant. This is not supported.\r\n\r\n**Describe the expected behavior**\r\nLSTM model would be saved in the SavedModel format to be exported into a Google Cloud bucket to work with Google's AI platform.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n`import tensorflow as tf\r\nimport os\r\nimport cv2\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tqdm\r\nimport datetime\r\nfrom sklearn.preprocessing import LabelBinarizer \r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Masking(mask_value=0.),\r\n    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\r\n    tf.keras.layers.Dense(256, activation='relu'),\r\n    tf.keras.layers.Dropout(0.5),\r\n    tf.keras.layers.Dense(len(LABELS), activation='softmax')\r\n])\r\n\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer='rmsprop',\r\n              metrics=['accuracy', 'top_k_categorical_accuracy'])\r\n\r\ntest_file = 'C:/.../testlist01.txt'\r\ntrain_file = 'C:/.../trainlist01.txt'\r\n\r\nwith open(test_file) as f:\r\n    test_list = [row.strip() for row in list(f)]\r\n\r\nwith open(train_file) as f:\r\n    train_list = [row.strip() for row in list(f)]\r\n    train_list = [row.split(' ')[0] for row in train_list]\r\n\r\ndef make_generator(file_list):\r\n    def generator():\r\n        np.random.shuffle(file_list)\r\n        for path in file_list:\r\n            full_path = os.path.join(BASE_PATH, path).replace('.avi', '.npy')\r\n\r\n            label = os.path.basename(os.path.dirname(path))\r\n            features = np.load(full_path)\r\n\r\n            padded_sequence = np.zeros((SEQUENCE_LENGTH, 1280))\r\n            padded_sequence[0:len(features)] = np.array(features)\r\n\r\n            transformed_label = encoder.transform([label])\r\n            yield padded_sequence, transformed_label[0]\r\n    return generator\r\n\r\ntrain_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\r\n                 output_types=(tf.float32, tf.int16),\r\n                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))\r\ntrain_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\nvalid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\r\n                 output_types=(tf.float32, tf.int16),\r\n                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))\r\nvalid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\nmodel.fit(train_dataset, epochs=17, validation_data=valid_dataset)\r\n\r\nBASE_DIRECTORY = 'C:\\\\...\\\\saved_model\\\\LSTM\\\\1\\\\';\r\ntf.saved_model.save(model, BASE_DIRECTORY)\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@tmartin293 \r\n\r\nRequest you to share the supporting files and code with proper indentation to reproduce the issue in our environment. Thanks!\r\n\r\n", "Project code based on previous LSTM project for activity recognition using UCF101 dataset:\r\nhttps://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter08/ch8_nb1_action_recognition.ipynb\r\n\r\nDataset: https://www.crcv.ucf.edu/data/UCF101.php\r\n\r\nCode:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nimport cv2\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tqdm\r\nimport datetime\r\nfrom sklearn.preprocessing import LabelBinarizer \r\n\r\n# base path of video dataset\r\nBASE_PATH = 'C:\\\\Users\\\\thoma\\\\Documents\\\\CSU East Bay\\\\2nd Year\\\\Fall 2019\\\\CS 663\\\\Exercises\\\\LSTM Exercise\\\\UCF101\\\\UCF-101'\r\nVIDEOS_PATH = os.path.join(BASE_PATH, '**', '*.avi')\r\n\r\n# sequence length LSTM will process\r\nSEQUENCE_LENGTH = 40\r\n\r\ndef frame_generator():\r\n    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\r\n    np.random.shuffle(video_paths)\r\n    for video_path in video_paths:\r\n        frames = []\r\n        cap = cv2.VideoCapture(video_path)\r\n        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\r\n        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\r\n        current_frame = 0\r\n        \r\n        label = os.path.basename(os.path.dirname(video_path))\r\n        \r\n        max_images = SEQUENCE_LENGTH\r\n        while True:\r\n            success, frame = cap.read()\r\n            if not success:\r\n                break\r\n                \r\n            if current_frame % sample_every_frame == 0:\r\n                frame = frame[:, :, ::-1]\r\n                img = tf.image.resize(frame, (224, 224))\r\n                img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\r\n                max_images -= 1\r\n                yield img, video_path\r\n                \r\n            if max_images == 0:\r\n                break\r\n            current_frame += 1\r\n\r\ndataset = tf.data.Dataset.from_generator(frame_generator,\r\n                                         output_types=(tf.float32, tf.string),\r\n                                         output_shapes=((224, 224, 3), ()))\r\n\r\ndataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\nmobilenet_v2 = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\r\nx = mobilenet_v2.output\r\n\r\npooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\r\nfeature_extraction_model = tf.keras.Model(mobilenet_v2.input,pooling_output)\r\n\r\ncurrent_path = None\r\nall_features = []\r\n\r\n# go through the dataset and use the mobilenet_v2 model to \r\n# extract the features for each image\r\nfor img, batch_paths in tqdm.tqdm(dataset):\r\n    batch_features = feature_extraction_model(img)\r\n    # reshape the tensor\r\n    batch_features = tf.reshape(batch_features,\r\n                                (batch_features.shape[0], -1))\r\n    \r\n    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\r\n        if path != current_path and current_path is not None:\r\n            output_path = current_path.decode().replace('.avi','.npy')\r\n            np.save(output_path, all_features)\r\n            all_features = []\r\n            \r\n        current_path = path\r\n        all_features.append(features)\r\n        \r\nLABELS = ['UnevenBars','ApplyLipstick','TableTennisShot','Fencing','Mixing','SumoWrestling','HulaHoop','PommelHorse','HorseRiding','SkyDiving','BenchPress','GolfSwing','HeadMassage','FrontCrawl','Haircut','HandstandWalking','Skiing','PlayingDaf','PlayingSitar','FrisbeeCatch','CliffDiving','BoxingSpeedBag','Kayaking','Rafting','WritingOnBoard','VolleyballSpiking','Archery','MoppingFloor','JumpRope','Lunges','BasketballDunk','Surfing','SkateBoarding','FloorGymnastics','Billiards','CuttingInKitchen','BlowingCandles','PlayingCello','JugglingBalls','Drumming','ThrowDiscus','BaseballPitch','SoccerPenalty','Hammering','BodyWeightSquats','SoccerJuggling','CricketShot','BandMarching','PlayingPiano','BreastStroke','ApplyEyeMakeup','HighJump','IceDancing','HandstandPushups','RockClimbingIndoor','HammerThrow','WallPushups','RopeClimbing','Basketball','Shotput','Nunchucks','WalkingWithDog','PlayingFlute','PlayingDhol','PullUps','CricketBowling','BabyCrawling','Diving','TaiChi','YoYo','BlowDryHair','PushUps','ShavingBeard','Knitting','HorseRace','TrampolineJumping','Typing','Bowling','CleanAndJerk','MilitaryParade','FieldHockeyPenalty','PlayingViolin','Skijet','PizzaTossing','LongJump','PlayingTabla','PlayingGuitar','BrushingTeeth','PoleVault','Punch','ParallelBars','Biking','BalanceBeam','Swing','JavelinThrow','Rowing','StillRings','SalsaSpin','TennisSwing','JumpingJack','BoxingPunchingBag']\r\nencoder = LabelBinarizer()\r\nencoder.fit(LABELS)\r\n\r\n#setup a keras Sequential model with 1) Masking layer  2) LSTM layer with 512 cells, dropout 0.5, recurrent_dropout of 0.5  \r\n# 3) a fully connected relu activation layer with 256 outputs,  4) a droupout layer 5) a final decision fully connected layer of length of labels\r\n# (which is the number of classes) with softmax activation\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Masking(mask_value=0.),\r\n    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\r\n    tf.keras.layers.Dense(256, activation='relu'),\r\n    tf.keras.layers.Dropout(0.5),\r\n    tf.keras.layers.Dense(len(LABELS), activation='softmax')\r\n])\r\n\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer='rmsprop',\r\n              metrics=['accuracy', 'top_k_categorical_accuracy'])\r\n\r\ntest_file = 'C:/Users/thoma/Documents/CSU East Bay/2nd Year/Fall 2019/CS 663/Exercises/LSTM Exercise/testlist01.txt'\r\ntrain_file = 'C:/Users/thoma/Documents/CSU East Bay/2nd Year/Fall 2019/CS 663/Exercises/LSTM Exercise/trainlist01.txt'\r\n\r\nwith open(test_file) as f:\r\n    test_list = [row.strip() for row in list(f)]\r\n\r\nwith open(train_file) as f:\r\n    train_list = [row.strip() for row in list(f)]\r\n    train_list = [row.split(' ')[0] for row in train_list]\r\n[trainlist01.txt](https://github.com/tensorflow/tensorflow/files/3813089/trainlist01.txt)\r\n[testlist01.txt](https://github.com/tensorflow/tensorflow/files/3813090/testlist01.txt)\r\n\r\ndef make_generator(file_list):\r\n    def generator():\r\n        np.random.shuffle(file_list)\r\n        for path in file_list:\r\n            full_path = os.path.join(BASE_PATH, path).replace('.avi', '.npy')\r\n\r\n            label = os.path.basename(os.path.dirname(path))\r\n            features = np.load(full_path)\r\n\r\n            padded_sequence = np.zeros((SEQUENCE_LENGTH, 1280))\r\n            padded_sequence[0:len(features)] = np.array(features)\r\n\r\n            transformed_label = encoder.transform([label])\r\n            yield padded_sequence, transformed_label[0]\r\n    return generator\r\n\r\n# Setup the train_dataset and valid_dataset (validation/testing).  \r\n# Here we setting up training batch sets of 16.  \r\n\r\ntrain_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\r\n                 output_types=(tf.float32, tf.int16),\r\n                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))\r\ntrain_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nvalid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\r\n                 output_types=(tf.float32, tf.int16),\r\n                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))\r\nvalid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = 'logs', update_freq=1000)\r\nmodel.fit(train_dataset, epochs=17, callbacks=[tensorboard_callback], validation_data=valid_dataset)\r\n\r\nBASE_DIRECTORY = 'C:\\\\Users\\\\thoma\\\\Documents\\\\CSU East Bay\\\\2nd Year\\\\Fall 2019\\\\CS 663\\\\Exercises\\\\LSTM Exercise\\\\saved_model\\\\LSTM\\\\1\\\\';\r\ntf.saved_model.save(model, BASE_DIRECTORY)\r\n\r\n```", "@tmartin293 Please post this question in stack overflow as this question is not related to bug/performance, build/install, docs or feature request. Thanks!", "This does seem like a bug", "I tried a different model that has `tf.keras.layers.LSTM` using` tf.saved_model.save()` method without a generator and  I didn't run into any error. Heres my [gist](https://colab.sandbox.google.com/gist/gowthamkpr/b1082d7f664edeca3929108d56792f79/untitled4.ipynb)\r\n\r\n@tmartin293 Can you please check if the error still exists with tf-nightly? Thanks!", "@tmartin293 Can you please try with recent `tf-nightly` and let us know whether it was resolved for you? Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Similar issue https://github.com/tensorflow/tensorflow/issues/34644 was resolved by recent `tf-nightly`. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34021\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34021\">No</a>\n", "It occurs when dropout parameter is used on the LSTM. Still occuring in TF 2.1", "@wtesler Can you please open a new issue with a standalone code to reproduce the error. Thanks!"]}, {"number": 34020, "title": "Checkpoint.restore doesn't restore Dataset iterator state when Dataset contains shuffle()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: not installed\r\n- GPU model and memory: no GPU\r\n\r\n**Describe the current behavior**\r\nThe code at the end results in the following output.\r\n```\r\n2019-11-05 13:54:16.140994: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-05 13:54:16.149389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2397225000 Hz\r\n2019-11-05 13:54:16.151608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50ebc70 executing computations on platform Host. Devices:\r\n2019-11-05 13:54:16.151636: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(72, shape=(), dtype=int64)\r\ntf.Tensor(83, shape=(), dtype=int64)\r\ntf.Tensor(19, shape=(), dtype=int64)\r\nSaved to /tmp/x/ckpt-1\r\ntf.Tensor(74, shape=(), dtype=int64)\r\ntf.Tensor(33, shape=(), dtype=int64)\r\ntf.Tensor(93, shape=(), dtype=int64)\r\nRestored from /tmp/x/ckpt-1\r\ntf.Tensor(21, shape=(), dtype=int64)\r\ntf.Tensor(0, shape=(), dtype=int64)\r\ntf.Tensor(8, shape=(), dtype=int64)\r\n```\r\n\r\n**Describe the expected behavior**\r\nAfter restoring from the checkpoint, I expect the iterator to return the same elements as it did after saving the checkpoint.  I.e.\r\n```\r\n2019-11-05 13:54:16.140994: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-05 13:54:16.149389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2397225000 Hz\r\n2019-11-05 13:54:16.151608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50ebc70 executing computations on platform Host. Devices:\r\n2019-11-05 13:54:16.151636: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(72, shape=(), dtype=int64)\r\ntf.Tensor(83, shape=(), dtype=int64)\r\ntf.Tensor(19, shape=(), dtype=int64)\r\nSaved to /tmp/x/ckpt-1\r\ntf.Tensor(74, shape=(), dtype=int64)\r\ntf.Tensor(33, shape=(), dtype=int64)\r\ntf.Tensor(93, shape=(), dtype=int64)\r\nRestored from /tmp/x/ckpt-1\r\ntf.Tensor(74, shape=(), dtype=int64)\r\ntf.Tensor(33, shape=(), dtype=int64)\r\ntf.Tensor(93, shape=(), dtype=int64)\r\n```\r\n\r\n**Code to reproduce the issue**\r\n```py\r\nimport tensorflow as tf\r\nds = tf.data.Dataset.range(100).shuffle(100, seed=42, reshuffle_each_iteration=False)\r\nit = iter(ds)\r\nckpt = tf.train.Checkpoint(foo=it)\r\nmgr = tf.train.CheckpointManager(ckpt, '/tmp/x', max_to_keep=3)\r\nfor _ in range(3): print(next(it))\r\nmgr.save()\r\nprint(\"Saved to {}\".format(mgr.latest_checkpoint))\r\nfor _ in range(3): print(next(it))\r\nckpt.restore(mgr.latest_checkpoint)\r\nprint(\"Restored from {}\".format(mgr.latest_checkpoint))\r\nfor _ in range(3): print(next(it))\r\n```\r\nFWIW, I get the expected result if I remove `.shuffle(...)`.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Issue replicating for TF-2.0, kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/571af19a2605e0b63938207f55803361/untitled26.ipynb) of colab.Thanks!\r\n\r\n", "@kaisuke Checkpoint.save and Checkpoint.restore write and read object-based checkpoints, in contrast to TensorFlow 1.x's tf.compat.v1.train.Saver which writes and reads variable.name based checkpoints. Object-based checkpointing saves a graph of dependencies between Python objects (Layers, Optimizers, Variables, etc.) with named edges, and this graph is used to match variables when restoring a checkpoint. It can be more robust to changes in the Python program, and helps to support restore-on-create for variables.\r\n\r\nThis is the reason why you are observing changes when you are using .shuffle() method. For more information, you can go through the following [link](https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint). Thanks!", "Thanks @gowthamkpr for the explanation, but I couldn't see the logical connection between your paragraph 1 & 2...\r\n\r\nIn the TensorFlow C++ codebase, I see support for saving/restoring iterators for a shuffling Dataset (`IteratorStateReader` & `IteratorStateWriter` etc. in https://github.com/tensorflow/tensorflow/blob/4fae137/tensorflow/core/kernels/data/shuffle_dataset_op.cc).  So I thought that iterators qualify as _\"types that contain trackable state\"_ as mentioned in the [tf.train.Checkpoint documentation](https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint).\r\n\r\n@jsimsa: It looks like you've been working on tf.data, including `shuffle_dataset_op.cc`.  May I ask what your view on this is?", "@aaudiber could you please take a look? thanks", "I was able to reproduce the issue. It appears that some state is not properly reset when restoring an active shuffle iterator from a checkpoint. I have a fix in-flight.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34020\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34020\">No</a>\n"]}, {"number": 34019, "title": "LSTM model can not save via SavedModel", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Microsoft Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  \r\n- TensorFlow version (use command below):2.0\r\n- Python version:  3.6.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen attempt from python using tf.keras LSTM model to create a SavedModel get error  (first load model from h5 file first)\r\nValueError: Model <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001F7676BDEF0> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nTo be able to create SavedModel directory\r\n**Code to reproduce the issue**\r\n\r\n`# Save the entire model as a SavedModel.\r\nBASE_DATA_PATH = 'C:\\Grewe\\Classes\\CS663\\Mat\\LSTM\\data'  \r\n\r\n#load the previously saved h5 model\r\n# try to reload the saved h5 file\r\n# Recreate the exact same model, including its weights and the optimizer\r\n\r\nmodel_file = os.path.join(BASE_DATA_PATH, 'my_model.h5')\r\nmodel = tf.keras.models.load_model(model_file)\r\n# Show the model architecture\r\nmodel.summary()\r\n\r\n#create directory to save the SavedModel\r\n\r\nsaved_model_dir = os.path.join(BASE_DATA_PATH, 'saved_model\\catsdogsCNN')\r\n!mkdir -#p saved_model_dir\r\nmodel.save(saved_model_dir) \r\n\r\n\r\n`\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@grewe, In order to expedite the trouble-shooting process, please provide a complete code snippet to reproduce the issue reported here. Thanks!\r\n", "Here is the complete code base attached\r\n[pythonLSTMCode.txt](https://github.com/tensorflow/tensorflow/files/3816613/pythonLSTMCode.txt)\r\n\r\n", "@grewe, Thanks for the code. Please provide all the supporting files to reproduce the reported issue. Thanks!", "\r\nThe data is a UCF101 data set.  I have added a zip below AND it contains results from running the part of the code that performs CNN feature extraction on the video data that can take hours to do on a normal laptop.  So each .avi file has a corresponding .npy file containing the CNN feature extraction output.  So, I would block out the part of the code that contains the feature extraction....if you unzip and change the names of the directory paths it should work.\r\n\r\nIf you want I have also provided a link to my trained model saved in h5 that you could simply run the portion of the code that loads the model runs prediction to get input layer setup and then try to save.\r\nSEE attached for a reduced version of the code attached in previous comment --that only loads my stored h5 file, does a few predictions then tries to save to a SavedModel directory format and fails with error reported.   If you use this then it will run quickly (Note: I do not understand why h5 format does not save the input shape information and I have to do predictions to reset when reloading model ---however if using original code that trains model and does SavedModel attempt the error is exactly the same).\r\n\r\n[LSTM_SimpleCodeVersion.py.txt](https://github.com/tensorflow/tensorflow/files/3820468/LSTM_SimpleCodeVersion.py.txt)\r\n\r\n\r\nTraining data - BOTH videos and .npy files with feature vectors from each video to feed into [LSTM](url)\r\n[http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/UCF-101_WithTraininData_InceptionV3CNN_trainedOnImageNet_Sampled_40_per_video.zip](url)\r\n\r\nModel file\r\n[http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/Good17EpochModel/my_model.h5](url)", "@grewe, I am unable to open the zip file that you have shared. Please help us to replicate the issue with more information. Thanks!", "Here are the URLs again for the 2 resources\r\n\r\nMODEL\r\n[](url)http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/Good17EpochModel/my_model.h5\r\n\r\nTraining data - BOTH videos and .npy files with feature vectors from each video to feed into\r\n[](url) http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/UCF-101_WithTraininData_InceptionV3CNN_trainedOnImageNet_Sampled_40_per_video.zip", "Any ideas on this issue?", "@grewe, I tried to open the Zip file but i am unable to open it.\r\nPlease see the screenshot.\r\n![Screenshot from 2019-11-12 15-36-48](https://user-images.githubusercontent.com/48476109/68664696-bfbf2680-0566-11ea-8055-8788e3252c34.png)\r\nThanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34018, "title": "[Intel MKL] Fixing performance regression in eager mode", "body": "This PR fixes performance regression in MKL eager mode caused by the commit https://github.com/tensorflow/tensorflow/commit/f58c9f835c32e02895bdd629c7660567ae011001", "comments": []}, {"number": 34017, "title": "Rename this repo to Big Migraine !!", "body": "I don;t know which version to use for which purpose ... huge compatibility disaster !\r\nTraining on multiple gpu even bill gates cannot do...\r\nAVX instructions are missing for pip install...\r\nTensorflow lite, Tensorflow TFX, Tensorflow serving.... crap after crap.\r\nwhether to use keras or tensorflow\r\nThere are no performance matrix comparing and converting your models...\r\nEven the book publishers and article writers are confused which version should they be using....\r\n", "comments": ["The issue tracker is for bug reports, or feature requests.", "+1 for not releasing cuda 10.1 build even after 8 months."]}, {"number": 34016, "title": "Keras' load_weights() bug: ValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Colab\r\n- TensorFlow version: 2.0.0\r\n\r\n**Describe the current behavior**\r\n\r\nUsing `model.save_weights()` and then `model.load_weights()` caused this error:\r\n`ValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.`\r\n\r\n**Code to reproduce the issue**\r\nSee [this Colab notebook](https://colab.research.google.com/drive/1-8kVsk-2PMTX_V_6VRHMWczz4T_4MPev).", "comments": ["In 2.0, the default saving format is the TensorFlow checkpoint format. Can you try using the TF checkpoint format and see if the colab works? (Just remove the .h5 extension in the save filename, and it will save out to TF checkpoint format.)", "Hi @karmel,\r\nSaving to TF format should work. However, one cannot later load the weights with `by_name=True, skip_mismatch=True`, which I need for doing transfer learning. I tried this on TF 2.1.0.dev20191103 but obtained `Error: shapes incompatible` (the pretrained weights were trained from a different dataset having a different number of classes).", "@netw0rkf10w As mentioned by @karmel I changed your code to save weights in *.tf format and everything works as expected. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/1404f0bfd5a429b585f1de847600ae5a/tf_checkpoint.ipynb) is the gist for your reference. \r\n\r\nI am closing this issue as it was resolved. Please feel free to open if the issue persists with any other models. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34016\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34016\">No</a>\n", "@jvishnuvardhan You are basically saying that the `.h5` format is not officially supported? In that case please remove it from your documentation then. ", "@netw0rkf10w Sorry. I didn't mean that we are not officially supporting `.h5` format. Thanks!\r\nIf you want us to look in detail at your issue, please provide a simple standalone code to reproduce the error. Thanks!", "@netw0rkf10w I think with subclass model, the input/output shape is unknown until it is first tested with proper data. I updated your code as follows which worked without any issue with .h5 format.\r\n \r\n```\r\nnet2 = Net(classes=5)\r\ntemp_predictions = net2(sample[0])\r\nnet2.load_weights('./net.h5')\r\nnew_predictions = net2(sample)\r\n```\r\n\r\nPlease check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/fbc2cdea31a5b588a6525b2d62f009c0/tf_checkpoint.ipynb).\r\n\r\nPlease close the issue if it is resolved. Thanks!", "I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34016\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34016\">No</a>\n"]}, {"number": 34015, "title": "Identity initializer not working as expected in Layer class add_weight method", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):\r\nv1.15.0-rc3-22-g590d6ee 1.15.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0 / cuDNN 7.6.4\r\n- GPU model and memory: Tesla K80\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nIf trying to use the `identity` initializer in the `build` method of a custom `Layer`, passing the shape as a tuple of `Dimension`s fails, e.g.\r\n```\r\n    def build(self, input_shape):\r\n        \"\"\"Build layer.\"\"\"\r\n        self.w = self.add_weight(\r\n            shape=(input_shape[-1], input_shape[-1]),\r\n            initializer=tf.initializers.identity(),\r\n            trainable=True,\r\n        )\r\n```\r\nfails with `TypeError: num_rows and num_columns must be positive integer values.`. However, exactly the same code, where we replace `identity` by `ones` works perfectly.\r\n\r\nFailure happens because `tf.eye` doesn't accept `Dimension` objects as inputs, only integers, e.g.:\r\n```\r\n    def build(self, input_shape):\r\n        \"\"\"Build layer.\"\"\"\r\n        self.w = self.add_weight(\r\n            shape=(input_shape[-1].value, input_shape[-1].value),\r\n            initializer=tf.initializers.identity(),\r\n            trainable=True,\r\n        )\r\n```\r\nworks\r\n\r\n**Describe the expected behavior**\r\nBehavior for different initializers should be consistent. `tf.initializers.identity` should accept a tuple of `Dimension` objects for shape, as other initializers do.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass MyLayer(tf.keras.layers.Layer):\r\n    def __init__(self, *args, kernel_initializer=tf.initializers.identity(), **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.kernel_initializer = kernel_initializer\r\n\r\n    def build(self, input_shape):\r\n        \"\"\"Build layer.\"\"\"\r\n        self.w = self.add_weight(\r\n            shape=(input_shape[-1], input_shape[-1]),\r\n            initializer=self.kernel_initializer,\r\n            trainable=True,\r\n        )\r\n\r\n    def call(self, inputs):\r\n        \"\"\"Apply layer.\"\"\"\r\n        return tf.matmul(inputs, tf.expand_dims(self.w, 0))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.enable_eager_execution()\r\n    inputs = np.random.normal(size=(1, 10, 3))\r\n    layer = MyLayer()\r\n    outputs = layer(inputs)\r\n    print(outputs.numpy())\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nTraceback (most recent call last):\r\n  File \"reproduce.py\", line 27, in <module>\r\n    outputs = layer(inputs)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 894, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"reproduce.py\", line 15, in build\r\n    trainable=True,\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\r\n    aggregation=aggregation)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\r\n    **kwargs_for_getter)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\r\n    shape=variable_shape if variable_shape else None)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\r\n    shape=shape)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2503, in default_variable_creator\r\n    shape=shape)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1537, in _init_from_args\r\n    initial_value() if init_from_fn else initial_value,\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 119, in <lambda>\r\n    init_val = lambda: initializer(shape, dtype=dtype)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py\", line 1211, in __call__\r\n    initializer = linalg_ops_impl.eye(*full_shape, dtype=dtype)\r\n  File \"/home/theophile.allard/miniconda3/envs/ncs_15/lib/python3.6/site-packages/tensorflow_core/python/ops/linalg_ops_impl.py\", line 57, in eye\r\n    'num_rows and num_columns must be positive integer values.')\r\nTypeError: num_rows and num_columns must be positive integer values.\r\n```\r\n", "comments": ["I have tried on colab with TF version 1.15 and i am not seeing any error message. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/75eadc7e4d604f1462811cf67e109b1c/untitled332.ipynb). Thanks!", "@ravikyram, sorry just realized the example to reproduce had `ones` initializer instead of `identity`. Just edited the description and tested on your colab notebook. As shown in [the gist](https://colab.research.google.com/gist/theoallard/251081388e066f5babd4d59de134eeb6/untitled332.ipynb), I confirm this fails:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nclass MyLayer(tf.keras.layers.Layer):\r\n    def __init__(self, *args, kernel_initializer=tf.initializers.ones(), **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.kernel_initializer = kernel_initializer\r\n\r\n    def build(self, input_shape):\r\n        \"\"\"Build layer.\"\"\"\r\n        self.w = self.add_weight(\r\n            shape=(input_shape[-1], input_shape[-1]),\r\n            initializer=self.kernel_initializer,\r\n            trainable=True,\r\n        )\r\n\r\n    def call(self, inputs):\r\n        \"\"\"Apply layer.\"\"\"\r\n        return tf.matmul(inputs, tf.expand_dims(self.w, 0))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.enable_eager_execution()\r\n    inputs = np.random.normal(size=(1, 10, 3))\r\n    layer = MyLayer()\r\n    outputs = layer(inputs)\r\n    print(outputs.numpy())\r\n```", "This works with tf-nightly version '2.2.0-dev20200302'. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34015\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34015\">No</a>\n"]}, {"number": 34014, "title": "Improve math_ops.py docs", "body": "", "comments": ["@yashk2810 can you help re-review this. I've cleared some commits off the log from the previous pull request (referenced above). Thanks", "The ubuntu cpu test was failing at tf.cumsum so I've made minor changes to the doctest to make it pass.", "ubuntu sanity check was failing due to a pylint error(`long line 82/80`) and that has been fixed in the commit above. \r\nQ: Is it by design that the `tf_doctest.py` test doesn't capture these?"]}, {"number": 34013, "title": "Error message in Hello_world example - ML for micro ", "body": "I am having the following error message when I am trying to run the hello_world example for microcontrollers:\r\n\r\n`C:\\Users\\arge10\\tensorflow>make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=mbed TAGS=\"CMSIS disco_f746ng\" generate_hello_world_mbed_project\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\n-m was unexpected at this time.\r\ntensorflow/lite/experimental/micro/tools/make/download_and_extract.sh \"https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip\" \"7e8191b24853d75de2af87622ad293ba\" tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp\r\n'tensorflow' is not recognized as an internal or external command,\r\noperable program or batch file.\r\ntensorflow/lite/experimental/micro/tools/make/Makefile:240: recipe for target 'tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp' failed\r\nmake: *** [tensorflow/lite/experimental/micro/tools/make/downloads/gemmlowp] Error 1`\r\n\r\nI searched for some solution on the internet about this issue, but I was unable to find any solution\r\nDid someone else face this problem before?", "comments": ["@Gus-Ghedim, Please provide details about what platform you are using (operating system, architecture). \r\nMake sure you also include the exact command if possible to produce the output included in your test case. \r\nThanks!\r\n", "@Gus-Ghedim, Provide more information about the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34012, "title": "tf.function accept namedtuples", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": []}, {"number": 34011, "title": "crop_and_resize_v2() got an unexpected keyword argument 'box_ind'\uff0chow to understand the 'box_ind' when the num_boxes equal to 1, batch_size equal to 32?", "body": "I am using the ROI_pooling layer for feature extraction. The dimension of the feature map is 32 * 12 * 12 * 64, and the output clipping dimension is 7 * 7. Only one clipping is needed. How do I use the function tf.image.crop_and_ resize?", "comments": ["Hi @lxz1104 ,\r\nWould you please tell me how did you solved this issue?\r\n"]}, {"number": 34009, "title": "BatchNormalization", "body": "If I want to freeze gamma, beta, moving_average_mean, moving_average_var in BatchNormalization\r\ncould tf.keras.layers.BatchNormalization(trainable=False)  be OK?\r\nor only could freeze gamma, beta ?\r\n", "comments": ["```trainable``` attribute in BatchNormalization disables the updates of the batch statistics\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization#__init__"]}, {"number": 34008, "title": "Why computation time increases proportionally when using more GPUs (mirror strategy)?", "body": "**System**\r\n- Ubuntu 16.04, python 3.6, Tensorflow 2.1.0-dev20191103 (binary), \r\n- CUDA 10.0, cuDNN 7.6.4\r\n- 4 x GPU NVIDIA Titan X 12GB\r\n\r\nI expected a similar computation time of each training step as I increase the # of GPUs thanks to parallelism (or slight increase due to possible overhead). However, I'm getting a proportional increase as if they run serially. **Why am I not getting the advantage of parallelism here? Any advice, please?**\r\n\r\nNote that\r\n- I checked \"per-replica\" input and outputs are the same across those situations.\r\n- I'm repeating the same dummy data here, so I don't think it's a data pipeline-related issue.\r\n- Although I posted this question in stackoverflow, too, I post here since I'm not sure if this is a misuse or a bug.\r\n\r\nThe result looks like:\r\n````bash\r\n$ CUDA_VISIBLE_DEVICES=0 python train_v2_multi_example.py\r\n...\r\nEp 01/100 | step 02 | 0.473 sec/step | loss: 46485.430\r\nEp 01/100 | step 03 | 0.482 sec/step | loss: 9216.726\r\n\r\n$ CUDA_VISIBLE_DEVICES=0,1 python train_v2_multi_example.py\r\n...\r\nEp 01/100 | step 02 | 1.141 sec/step | loss: 22627.699\r\nEp 01/100 | step 03 | 1.091 sec/step | loss: 11679.490\r\n\r\n$ CUDA_VISIBLE_DEVICES=0,1,2 python train_v2_multi_example.py\r\n...\r\nEp 01/100 | step 02 | 1.408 sec/step | loss: 32166.996\r\nEp 01/100 | step 03 | 1.380 sec/step | loss: 14036.578\r\n````\r\n\r\nCode is as follows:\r\n````python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport os, time, sys, numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import (Conv2D, Conv3D, Dense)\r\n\r\n\r\n@tf.function\r\ndef loss_fn(y_pred, y_true):\r\n    return tf.reduce_mean(tf.math.square(y_pred - y_true))\r\n\r\n@tf.function\r\ndef train_step(dist_inputs):\r\n    def step_fn(inputs):\r\n        inputs, labels = inputs\r\n\r\n        # tf.print(\"in\", tf.shape(inputs), \"out\", tf.shape(labels), output_stream=sys.stdout)\r\n        with tf.GradientTape() as tape:\r\n            out = model(inputs)\r\n            loss_value = loss_fn(out, labels)\r\n        grads = tape.gradient(loss_value, model.trainable_weights)\r\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n        return loss_value\r\n\r\n    per_example_losses = strategy.experimental_run_v2(step_fn, args=(dist_inputs,))\r\n    mean_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_example_losses, axis=None)\r\n    return mean_loss\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    BATCH_SIZE_PER_SYNC = 4\r\n    logdir = os.path.join('logs/test')\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    num_gpus = strategy.num_replicas_in_sync\r\n    global_batch_size = BATCH_SIZE_PER_SYNC * num_gpus\r\n    print('num GPUs: {}, global batch size: {}'.format(num_gpus, global_batch_size))\r\n\r\n    # fake data ------------------------------------------------------\r\n    fakea = np.random.rand(global_batch_size, 10, 200, 200, 128).astype(np.float32)\r\n    targets = np.random.rand(global_batch_size, 200, 200, 14)\r\n\r\n    # tf.Dataset ------------------------------------------------------\r\n    def gen():\r\n        while True:\r\n            yield (fakea, targets)\r\n\r\n    dataset = tf.data.Dataset.from_generator(gen,\r\n        (tf.float32, tf.float32),\r\n        (tf.TensorShape(fakea.shape), tf.TensorShape(targets.shape)))\r\n\r\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n    dist_dataset = strategy.experimental_distribute_dataset(dataset)\r\n\r\n    # Model ------------------------------------------------------\r\n    training = True\r\n    with strategy.scope():\r\n        # Model\r\n        va = keras.Input(shape=(10, 200, 200, 128), dtype=tf.float32, name='va')\r\n        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(va)\r\n        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)\r\n        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)\r\n        x = tf.reduce_max(x, axis=1, name='maxpool')  # [\u03a3K, 128]\r\n        b = Conv2D(14, kernel_size=3, padding='same')(x)\r\n        model = keras.Model(inputs=va, outputs=b, name='net')\r\n        optimizer = keras.optimizers.RMSprop()\r\n    model.summary()\r\n\r\n    # TRAIN ---------------------------------------------------------\r\n    writer = tf.summary.create_file_writer(logdir)\r\n\r\n    num_steps = 100\r\n    num_epoches = 100\r\n    global_step = 0\r\n\r\n    with strategy.scope():\r\n        iterator = iter(dist_dataset)\r\n        with writer.as_default():\r\n            for epoch in range(num_epoches):\r\n                for step in range(num_steps):\r\n\r\n                    if global_step == 0 or 5 < global_step < 8:\r\n                        tf.summary.trace_on(graph=True, profiler=True)\r\n\r\n                    start = time.time()\r\n                    loss_value = train_step(next(iterator))\r\n                    duration = time.time() - start\r\n\r\n                    prefix = 'Ep {:02d}/{:02d} | step {:02d} '.format(epoch + 1, num_epoches, step)\r\n                    suffix = '| {:.3f} sec/step | loss: {:.3f} '.format(duration, float(loss_value))\r\n                    print(prefix + suffix)\r\n\r\n                    tf.summary.scalar(\"loss\", loss_value, step=global_step)\r\n\r\n                    if global_step == 0 or 5 < global_step < 8:\r\n                        tf.summary.trace_export(name=\"model_trace\", step=global_step, profiler_outdir=logdir)\r\n                    writer.flush()\r\n                    global_step += 1\r\n````\r\n\r\n\r\n\r\n", "comments": ["@ywpkwon I also observed a significant overhead in the communication between GPUs when using GradientTape (the overhead is negligible when using Keras' `.fit()`). However, if you compute the loss correctly, then you should observe that multi-GPUs converges faster because it processes more images than single GPU training in the same number of steps.", "@netw0rkf10w Thanks for your response. It's good to know that it isn't only my experience. (Because I did a test with an official(?) MNIST example with `.fit()` method and the parallelism worked well, I was planning to check a `.fit()` version of this example.)\r\n\r\nAnyway then, what makes the `.fit()` method special? Simply saying, isn't it just a nicer wrapper of a training loop, but still based on the `GradientTape` and its source scripts are open? Shouldn't we be able to borrow the trick/secret that makes parallelism work correctly?  I'm so cuious.\r\n", "@ywpkwon Keras `.fit()` is highly optimized. I spent a lot of time over the last weeks optimizing my custom training loop but I was never able to reach `.fit()` performance (mine was about 1.2-1.3 times slower). And this is only for multi-GPU training because for single-GPU I observed similar performance between the two. I guess the issue has to do with `tf.distribute.Strategy.experimental_run_v2()` (note the **experimental** prefix).\r\n\r\nI don't know exactly what makes `.fit()` that efficient, maybe somebody here could help.", "What I said above, \"for single-GPU I observed similar performance\", **is not true**!!\r\n\r\nI've just tested my code on a different dataset (Coco segmentation, previous was Oxford Pet), and **even for single-GPU training, GradientTape is 1.7-1.8 times slower than .fit()**.\r\n\r\nKeras .fit() is [unusable with custom loss functions](https://github.com/tensorflow/tensorflow/issues/33988), while GradientTape is too slow. I am fucked up for the next deadline. BIG mistake choosing TensorFlow for the work (I was too excited by the release). I should have realized that this \"stable\" release was pushed by the timing of the TensorFlow World conference...", "For the original scaling issue with multi-gpu, few things to check/try out:\r\n- is the GPU saturated in the one GPU case? or are you able to increase the batch size and get better performance? I am wondering if the batch size is too small/step time too small. In such cases, sometimes the overhead of synchronization across GPUs can be large. So try increasing the batch size and see what happens?\r\n- input pipeline: even with a synthetic input pipeline, there can be overhead of copying the data to the GPU. I see you're using a generator, I am not sure of the performance implications of that. Can you instead simply use tf.data.Dataset.from_tensor_slices() followed by dataset.repeat() to create your dataset? \r\n- Can you provide us with profiles? I see you already have the code to do the profiling `                     tf.summary.trace_on(graph=True, profiler=True)` etc. Here is some information on how to get and use profiling in TF: https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras.\r\n\r\nRe: the questions re: .fit() vs GradientTape, .fit() does use [GradientTape](https://github.com/tensorflow/tensorflow/blob/1d3db869f9154b537a5bfedc2c01eadbb167919b/tensorflow/python/keras/engine/training_eager.py#L245). .fit() also uses the same tf.distribute APIs that you use in your code above (experimental_run_v2, as well as experimental_distribute_dataset). \r\nSo none of these are fundamental reasons why custom training loop should be slower. In fact, in general we are able to make it as fast or better than fit() as you can customize it much more.\r\n\r\nBut of course there could very well be inefficiencies in any custom code, that could cause it to be slower. I don't think there is any fundamental reason it should be. (And of course entire tensorflow is open source so you can definitely look at the .fit() implementation).\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "@guptapriya Thanks for the detailed reply. In two weeks I'll create a small benchmark for comparing GradientTape and .fit().", "@guptapriya Thanks for the reply. I'll investigate more. Really good to know that `.fit()` has nothing special as I initially guessed.  @netw0rkf10w Once you create a small benchmark, could you also include/tag me? I'm so curious.", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34008\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34008\">No</a>\n"]}, {"number": 34007, "title": "Comments on the \"Custom model_fn with TF 2.0 symbols\" section of the \"Migrate your TensorFlow 1 code to TensorFlow 2\" guide", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/guide/migrate#custom_model_fn_with_tf_20_symbols\r\n\r\n## Description of issue (what needs changing):\r\n\r\nMy comments are about this piece of code:\r\n```\r\ndef my_model_fn(features, labels, mode):\r\n  model = make_model()\r\n\r\n  training = (mode == tf.estimator.ModeKeys.TRAIN)\r\n  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()\r\n  predictions = model(features, training=training)\r\n\r\n  # Get both the unconditional losses (the None part)\r\n  # and the input-conditional losses (the features part).\r\n  reg_losses = model.get_losses_for(None) + model.get_losses_for(features)\r\n  total_loss = loss_obj(labels, predictions) + tf.math.add_n(reg_losses)\r\n\r\n  # Upgrade to tf.keras.metrics.\r\n  accuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')\r\n  accuracy = accuracy_obj.update_state(\r\n      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))\r\n\r\n  train_op = None\r\n  if training:\r\n    # Upgrade to tf.keras.optimizers.\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    # Manually assign tf.compat.v1.global_step variable to optimizer.iterations\r\n    # to make tf.compat.v1.train.global_step increased correctly.\r\n    # This assignment is a must for any `tf.train.SessionRunHook` specified in\r\n    # estimator, as SessionRunHooks rely on global step.\r\n    optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\r\n    # Get both the unconditional updates (the None part)\r\n    # and the input-conditional updates (the features part).\r\n    update_ops = model.get_updates_for(None) + model.get_updates_for(features)\r\n    # Compute the minimize_op.\r\n    minimize_op = optimizer.get_updates(\r\n        total_loss,\r\n        model.trainable_variables)[0]\r\n    train_op = tf.group(minimize_op, *update_ops)\r\n\r\n  return tf.estimator.EstimatorSpec(\r\n    mode=mode,\r\n    predictions=predictions,\r\n    loss=total_loss,\r\n    train_op=train_op,\r\n    eval_metric_ops={'Accuracy': accuracy_obj})\r\n\r\n# Create the Estimator & Train.\r\nestimator = tf.estimator.Estimator(model_fn=my_model_fn)\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n```\r\nMy first comment is: why write\r\n```\r\naccuracy = accuracy_obj.update_state(\r\n      y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))\r\n```\r\ninstead of just `accuracy_obj.update_state(y_true=labels, y_pred=tf.math.argmax(predictions, axis=1))` ? First, `accuracy`is never used. Second, this may lead the reader to believe that the `tf.keras.metrics.Metric.update_state` outputs the accuracy value, just like the `tf.keras.metrics.Metric.result` method, whereas the output of `update_state` is `accuracy_obj.count`. See on the code below:\r\n```\r\nimport tensorflow as tf\r\n\r\naccuracy_obj = tf.keras.metrics.Accuracy(name='acc_obj')\r\naccuracy = accuracy_obj.update_state(\r\n      y_true=[0, 1], y_pred=tf.math.argmax([[0.3, 0.7], [0.3, 0.7]], axis=1))\r\n\r\ntf.print(accuracy)\r\n# 2\r\ntf.print(accuracy_obj.result())\r\n# 0.5\r\ntf.print(accuracy_obj.count)\r\n# 2\r\n```\r\n\r\nMy other comment is that we have the line `train_op = tf.group(minimize_op, *update_ops)` whereas in the [\"Custom model_fn with minimal changes\" section](https://www.tensorflow.org/guide/migrate#custom_model_fn_with_minimal_changes) the corresponding line is `train_op = tf.group(minimize_op, update_ops)` without the `*`. Why is that? Is this a mistake?", "comments": ["@durandg12 Thanks for the findings. The guide has been updated addresses the topics discussed in this issue. "]}, {"number": 34006, "title": "Tensorflow mix precision training error", "body": "ystem info:\r\n\r\nGPU Type: Tesla T4\r\nNvidia Driver Version: 418.87.01\r\nCUDA Version: 10.1.243\r\nCUDNN Version: 7.6.3\r\nPython Version (if applicable): 3.7.4\r\nTensorFlow Version (if applicable):1.14.0\r\nOperating System + Version: Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-142-generic x86_64)\r\n\r\nHi, I am training tensorflow version Tacotron2 model with mix precision training.\r\nafter some training iterations , when doing validation, an error occurs, the detailed error info is like below:\r\n\r\n`Exiting due to exception: 2 root error(s) found. (0) Invalid argument: TensorArray dtype is float but Op is trying to write dtype half. [[node Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (defined at /home/yichao.li/lite-tacotron2/tacotron/models/modules.py:225) ]] [[strided_slice_51/_7343]] (1) Invalid argument: TensorArray dtype is float but Op is trying to write dtype half. [[node Tacotron_model/inference/encoder_LSTM/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (defined at /home/yichao.li/lite-tacotron2/tacotron/models/modules.py:225) ]] 0 successful operations. 0 derived errors ignored.`\r\n\r\nDo I need to turn off auto mixed precision on evaluation time?\r\ncould you help to clarify this? how to fix?", "comments": ["@superhg2012 ,\r\nCan you share a simple and standalone code to reproduce the issue?Thanks!", "@oanush Hi, I am using  _tf.train.experimental.enable_mixed_precision_graph_rewrite_ [api](https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp) to do auto mix precision training for my seq2seq model(Tacotron).   if validation is removed, this issue can not be reporduced. \r\n\r\n"]}, {"number": 34005, "title": "Documentation unclear tf.batch_to_space", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/batch_to_space\r\n\r\n## Description of issue (what needs changing):\r\n1. Example needs to be added.\r\n2. `crops` part in `Args:` section is very difficult to understand. Needs to be better formatted (put into code). \r\n\r\n### Clear description:\r\nDocumentation is unclear, no example is shown. Also, there is one extremely long paragraph with code in between in the `crops` section under args.\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? \r\n=> Not well formatted.\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n=> Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? \r\n=> No\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n=> No\r\n\r\n### Submit a pull request?\r\n=> No\r\n", "comments": ["@nikochiko Do you want to work on improving this section? I could not understand from the opened issue if you have only reported an issue or also proposed to work with it? In later case, I can join you in re-formatting the doc for this topic.", "@copperwiring Sure, I would like to work on it. But I will have to look into its technical details before that. If you have any resources, it would be great if you share them. I'll try to learn something about it from code in the meanwhile.", "@oanush Please assign this to me and @copperwiring . Will open a PR soon.", "@nikochiko Feel free to raise a PR and reference this issue. Thanks!", "@ymodak this issue be used for Google Code-in as a Documentation and research challenge?", "@dubesar I had started working on the formatting part of the issue and was planning to make a PR till tomorrow. The job is mostly to \r\n- Sync the docs formatting with its [r1 version](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/batch_to_space_nd).\r\n- Make the documentation easier to understand, editing it and adding \"Examples:\" and \"Raises:\" sections.\r\nI can make some minor edits with the language to make it more suitable as a Google Code-In challenge. \r\n@ymodak , @dubesar ?", "@nikochiko Yeah that would be great if some part of this issue is available for Google Code-in", "@dubesar See the referenced PR and a comment on it. I have made some additional changes and made the task more clear.", "PR merged. Closing issue."]}, {"number": 34004, "title": "tf.keras.layers.SimpleRNN doesn't use GPU?", "body": "First, This is a example in TensorFlow 2.0 with Keras.\r\n\r\n```\r\nfrom tensorflow.keras.datasets import imdb\r\n\r\nnum_words = 10000\r\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\r\n\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\n\r\nmax_len = 500\r\n\r\npad_X_train = pad_sequences(X_train, maxlen=max_len)\r\npad_X_test = pad_sequences(X_test, maxlen=max_len)\r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import SimpleRNN, Dense, Embedding  \r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(input_dim = num_words, output_dim = 32))\r\nmodel.add(SimpleRNN(32, return_sequences = True, dropout = 0.15, recurrent_dropout = 0.15))\r\nmodel.add(SimpleRNN(32))\r\nmodel.add(Dense(1, activation = 'sigmoid'))\r\n\r\nmodel.compile(optimizer='adam',\r\n             loss = 'binary_crossentropy',\r\n             metrics = ['acc'])\r\n\r\n# model.summary()\r\n\r\nhistory = model.fit(pad_X_train, y_train, \r\n                    batch_size = 32, epochs = 15, \r\n                    validation_split = 0.2)\r\n```\r\n\r\n+ Use Window 10 and TF 2.0\r\n+ NVidia Driver : 418.81\r\n+ CUDA : 10.1\r\n+ GPU : GeForce GTX 1050\r\n\r\nAnd, When I use the layer SimpleRNN in keras, GPU-Utils is very low. what happen??\r\n![image](https://user-images.githubusercontent.com/33315343/68199250-04940c00-0001-11ea-9b53-b315e6ff8505.png)\r\n\r\nFor checking if my GPU worked correctly, I use it using Conv2D.\r\n![image](https://user-images.githubusercontent.com/33315343/68199475-753b2880-0001-11ea-90be-bae41dc5d637.png)\r\n\r\nThe above picture was run on the MNIST dataset, which does not seem to require much GPU-Utils.\r\n\r\nI haven't seen 100% use, but my GPU seems to work fine.\r\n\r\nStacking multiple SimpleRNN layers or using just one will not increase GPU-Utils at 10%. \r\nWhat's wrong?\r\n\r\nIs it because of the feature of the layer?", "comments": ["In TensorFlow 2.0, if you want to use GPU, you need to pip install tensorflow-gpu==2.0\r\n\r\nSome history:\r\nFor a long time the tensorflow pip package was CPU only and the tensorflow-gpu pip package was GPU only. This was still true when TensorFlow 2.0 was released.\r\n\r\nTensorFlow 1.15.0 was released after TensorFlow 2.0, and that was the first package where the tensorflow pip package could work with either GPU or CPU.\r\n\r\nTensorFlow 2.1.0, when released, should work the same as TensorFlow 1.15.0 does, but for now to use GPU with TensorFlow 2.0, you need to install tensorflow-gpu", "Thank you for your answer.\r\n\r\nIn my writing, The sentence 'Use Window 10 and TF 2.0' is wrong.\r\n\r\nCorrectly, 'Use Window 10 and TF 2.0-gpu'. \r\n\r\nThis mean, I already install tensorflow-gpu==2.0.0 and The above code run in this environment!\r\n\r\nthanks.", "Can you please attach the logs that TensorFlow generated?", "Thank you for your answer. \r\n\r\nwhat is the logs?\r\n\r\nIn the Running Time, there is no logs. Just run only.\r\n\r\nThe SimpleRNN example code attached to this shows that \r\nthe training is very slow even when compared to LSTM or CNN code.\r\n\r\nThank you!", "By \"logs\" I meant the entire output of the TF program.\r\n\r\nHowever, re-reading the bug report, I don't think the logs will be super useful.  In your case the TF program _is using_ the GPU, just not as much you'd expect, right?\r\n\r\nThis sort of thing is very hard to debug over email, I'd suggest using the [trace viewer](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#trace_viewer) to see if you can spot any red flags.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34004\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34004\">No</a>\n"]}, {"number": 34003, "title": "Something wrong with \"model.fit(x_train, y_train, epochs=5)\"", "body": "Even I copy the code like below from the official website and run it in jupyter notebook, I get an error:\r\n**ValueError: Attempt to convert a value (5) with an unsupported type (<class 'numpy.uint8'>) to a Tensor.**\r\nMy tensorflow version is 2.0, plz help\r\n```\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n\r\n```", "comments": ["The code is correct. It should run well on both tf-1.x and tf -2.x. \r\nSee these links:\r\nhttps://github.com/nikochiko/code/blob/master/tf1_tf-issue_34003.ipynb\r\nhttps://github.com/nikochiko/code/blob/master/tf2_tf-issue_34003.ipynb\r\nCan you share your detailed error log? ", "Sure, here is the total error log, thanks a lot\r\n> ---------------------------------------------------------------------------\r\n> ValueError                                Traceback (most recent call last)\r\n> <ipython-input-1-357d0cd1907d> in <module>\r\n>      16               metrics=['accuracy'])\r\n>      17 \r\n> ---> 18 model.fit(x_train, y_train, epochs=5)\r\n>      19 model.evaluate(x_test, y_test)\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n>     726         max_queue_size=max_queue_size,\r\n>     727         workers=workers,\r\n> --> 728         use_multiprocessing=use_multiprocessing)\r\n>     729 \r\n>     730   def evaluate(self,\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n>     222           validation_data=validation_data,\r\n>     223           validation_steps=validation_steps,\r\n> --> 224           distribution_strategy=strategy)\r\n>     225 \r\n>     226       total_samples = _get_total_number_of_samples(training_data_adapter)\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\r\n>     545         max_queue_size=max_queue_size,\r\n>     546         workers=workers,\r\n> --> 547         use_multiprocessing=use_multiprocessing)\r\n>     548     val_adapter = None\r\n>     549     if validation_data:\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in _process_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\r\n>     604       max_queue_size=max_queue_size,\r\n>     605       workers=workers,\r\n> --> 606       use_multiprocessing=use_multiprocessing)\r\n>     607   # As a fallback for the data type that does not work with\r\n>     608   # _standardize_user_data, use the _prepare_model_with_inputs.\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py in __init__(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\r\n>     319     dataset = dataset_ops.DatasetV2.zip((\r\n>     320         indices_dataset,\r\n> --> 321         dataset_ops.DatasetV2.from_tensors(inputs).repeat()\r\n>     322     ))\r\n>     323 \r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py in from_tensors(tensors)\r\n>     412       Dataset: A `Dataset`.\r\n>     413     \"\"\"\r\n> --> 414     return TensorDataset(tensors)\r\n>     415 \r\n>     416   @staticmethod\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py in __init__(self, element)\r\n>    2333   def __init__(self, element):\r\n>    2334     \"\"\"See `Dataset.from_tensors()` for details.\"\"\"\r\n> -> 2335     element = structure.normalize_element(element)\r\n>    2336     self._structure = structure.type_spec_from_value(element)\r\n>    2337     self._tensors = structure.to_tensor_list(self._structure, element)\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\data\\util\\structure.py in normalize_element(element)\r\n>     109         else:\r\n>     110           normalized_components.append(\r\n> --> 111               ops.convert_to_tensor(t, name=\"component_%d\" % i))\r\n>     112   return nest.pack_sequence_as(element, normalized_components)\r\n>     113 \r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)\r\n>    1182   preferred_dtype = deprecation.deprecated_argument_lookup(\r\n>    1183       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\r\n> -> 1184   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n>    1185 \r\n>    1186 \r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n>    1240       name=name,\r\n>    1241       preferred_dtype=dtype_hint,\r\n> -> 1242       as_ref=False)\r\n>    1243 \r\n>    1244 \r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\r\n>    1294 \r\n>    1295     if ret is None:\r\n> -> 1296       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n>    1297 \r\n>    1298     if ret is NotImplemented:\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py in _default_conversion_function(***failed resolving arguments***)\r\n>      50 def _default_conversion_function(value, dtype, name, as_ref):\r\n>      51   del as_ref  # Unused.\r\n> ---> 52   return constant_op.constant(value, dtype, name=name)\r\n>      53 \r\n>      54 \r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in constant(value, dtype, shape, name)\r\n>     225   \"\"\"\r\n>     226   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n> --> 227                         allow_broadcast=True)\r\n>     228 \r\n>     229 \r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n>     233   ctx = context.context()\r\n>     234   if ctx.executing_eagerly():\r\n> --> 235     t = convert_to_eager_tensor(value, ctx, dtype)\r\n>     236     if shape is None:\r\n>     237       return t\r\n> \r\n> E:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n>      94       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n>      95   ctx.ensure_initialized()\r\n> ---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n>      97 \r\n>      98 \r\n> \r\n> ValueError: Attempt to convert a value (5) with an unsupported type (<class 'numpy.uint8'>) to a Tensor.\r\n> ", "@githubzjm \r\nI have tried on colab with TF version 2.0  and i am not seeing any error message. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/5c1e097d5bb95ca5bc887e279e789e5e/untitled333.ipynb). Thanks!", "@githubzjm , Do similar errors occur for other values of `epochs` ?", "Yes, I change the value of epochs to 6 and the error is the same\uff1a\r\n**ValueError: Attempt to convert a value (5) with an unsupported type (<class 'numpy.uint8'>) to a Tensor.**", "@githubzjm \r\n\r\nDo you have multiple versions of numpy installed in your system?\r\nPlease check using `pip show numpy`\r\nCan you uninstall all numpy versions and later install numpy==1.16.4?\r\n`pip uninstall numpy` (till you uninstall all versions) then you install `pip install numpy==1.16.4` and check whether the issue still persists?. Thanks!", "Thanks, I have solved it! But it seems not the various versions of numpy caused the problem, but the old version 1.15.4 somehow doesn't work well for Tensorflow2.0. Do not need to uninstall all numpy versions, just use `conda update numpy` to update.\r\n\r\nBesides, `pip show numpy` only shows me one version of numpy at first(now it can't find any file after I run `conda remove numpy`), but `conda search numpy`  shows many installed verisons.", "@githubzjm \r\n\r\nI am closing the issue, since the query is been resolved. Thanks!"]}, {"number": 34002, "title": "Can I say the version compatibility of tensorflow is just not great. ", "body": "Can I say the version compatibility of tensorflow is just like shit. The code under older versions can not work at all under the new versions and you never know which version you should use. The defintions of  functions in different versions changes greatly and you never know which function is really what you need. When you want to run a new code, you have to try all the versions to make it work if you don't know its original tf version. Or you must change the code to statisfy the demand of the old versions. And sometimes you waste so much time and then you find you still can't make it work.\r\nAnybody has the same problem? I think it's one of the most important reasons why more and more people are turning to pytorch. ", "comments": ["Don't forget how painful it is to train on multiple gpus. f u Google !", "Thank you for your feedback for tensor-flow version compatibility. TF is a growing community and efforts are being made to address this issue. If you have a specific concern w.r.t. t a certain problem, please don't forget to put the code snippets with the version issues for other to look at it.\r\n\r\nTF accepts constructive criticism.  ", "@yang-yk,\r\nThank you for reporting the issue.\r\nIn order to expedite the trouble-shooting process, please provide a code snippets along with versions you are facing the issue. Thanks!\r\n", "> @yang-yk,\r\n> Thank you for reporting the issue.\r\n> In order to expedite the trouble-shooting process, please provide a code snippets along with versions you are facing the issue. Thanks!\r\n\r\nThanks for your reply and sorry for my rudeness. It\u2019s about the tf estimator using multi-gpus. When I try to use the mirroredstrategy as what the official code teaches, there are always errors. Although I have tried tf version from 1.4 to 1.15, I still can't make it work. The errors are always different under different versions. I am so tired to solve the problem becasue it has taken me all day.  And I have experienced the version problems many  times. Once I was a supporter of tensorflow, but now I start try to use pytorch.  As mentioned above, the tf versions are too confusing. Learning the new version tf costs too much, and the previous codes also need to be corrected.  In most cases, when you just get used to the current tf, the completely different tf is released. And it is not compatible with the previous version. Having said so much, I just hope that tf will not be abandoned by researchers in the future. ", "@yang-yk the issue tracker is for feature requests or bug reports. Your complaint is not constructive in form or content. \r\n\r\nTensorFlow conforms to semver for backwards compatibility. If we violated [our promises](tensorflow.org/guide/versions), that would be a bug we can fix.", "So disappointed! Both the framework and the reply."]}, {"number": 34001, "title": " About failed to load model from pb ", "body": " I train the model in Ubuntu(VM) ,with tensorflow 1.14.0 , export pb file\r\n\r\nbut in android app whit tensorflow-android:1.13.1 \uff0ccan not load pb file\r\n\r\n\u201c failed to load model from pb  \u201d\r\n\r\n", "comments": ["Can you please try setting same version of TF in the android app as well?.\r\nUpdate the android build dependencies to tensorflow-android:1.14.0", "the latest version of tensorflow-android is 1.13.1 \r\n> https://mvnrepository.com/artifact/org.tensorflow/tensorflow-android", "I beg your pardon, you are right. TensorFlow Mobile is deprecated.\r\nSee https://github.com/tensorflow/examples/blob/master/community/en/docs/tfmobile/android_build.md#building-tensorflow-on-android\r\n You may try using TF Lite for your case."]}, {"number": 34000, "title": "Custom layer not working ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: P100\r\n\r\n**Describe the current behavior**\r\nFunctional API in tf.keras complaining about Eager mode\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n!pip install --quiet tensorflow-gpu==2.0\r\n\r\nimport cv2\r\nimport glob\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom pathlib import Path\r\nfrom skimage.io import imread, imshow, imsave\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers as L\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\nfrom tensorflow.keras import backend as K\r\n\r\n\r\nclass Sampling(tf.keras.layers.Layer):\r\n    def __init__(self, mu_shape, **kwargs):\r\n        super(Sampling, self).__init__(**kwargs)\r\n\r\n    def call(self, args):\r\n        mu, log_var = args\r\n        epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\r\n        return mu + K.exp(log_var / 2) * self.epsilon\r\n\r\ndef build_autoencoder(latent_dim_size):\r\n    # Enocder \r\n    input_img = L.Input(shape=(224,224,1), name='image_input')\r\n    x = L.Conv2D(32, (3,3), strides=(2,2), padding='same', name='Conv1')(input_img)\r\n    x = L.BatchNormalization(name=\"bn1\", axis=-1)(x)\r\n    x = L.Activation(\"relu\")(x)\r\n    x = L.Dropout(0.25)(x)\r\n    \r\n    x = L.Conv2D(64, (3,3), strides=(2,2), padding='same', name='Conv2')(x)\r\n    x = L.BatchNormalization(name=\"bn2\", axis=-1)(x)\r\n    x = L.Activation(\"relu\")(x)\r\n\r\n    shape_before_flattening = x.shape[1:]\r\n    \r\n    x = L.Flatten()(x)\r\n    mu = L.Dense(latent_dim_size, name='mu')(x)\r\n    log_var = L.Dense(latent_dim_size, name='log_var')(x)\r\n     \r\n    # This doesn't work!\r\n    encoder_output = Sampling(mu.shape[1:], name=\"encoder_output\")([mu, log_var])\r\n    \r\n    #############################################################\r\n\r\n    # Decoder\r\n    x = L.Dense(np.prod(shape_before_flattening))(encoder_output)\r\n    x = L.Reshape(shape_before_flattening)(x)\r\n\r\n    x = L.Conv2D(64, (3,3), padding='same', name='Conv3')(x)\r\n    x = L.BatchNormalization(name=\"bn3\", axis=-1)(x)\r\n    x = L.Activation(\"relu\")(x)\r\n    x = L.UpSampling2D((2,2), name='upsample1')(x)\r\n\r\n    x = L.Conv2D(32, (3,3), padding='same', name='Conv4')(x)\r\n    x = L.BatchNormalization(name=\"bn4\", axis=-1)(x)\r\n    x = L.Activation(\"relu\")(x)\r\n    x = L.UpSampling2D((2,2), name='upsample2')(x)\r\n    \r\n    x = L.Conv2D(1, (3,3), padding='same', name='Conv5')(x)\r\n    x = L.Activation(\"sigmoid\")(x)\r\n\r\n    #############################################################\r\n\r\n    ae = Model(input_img, x, name=\"autoencoder\")\r\n    return ae, mu, log_var\r\n\r\nae, mu, log_var = build_autoencoder(latent_dim_size=200)\r\nae.summary()\r\n\r\ndef loss_fn(y_true, y_pred):\r\n    r_loss = K.mean(K.square(y_true - y_pred), axis = [1,2,3])\r\n    return r_loss\r\n\r\noptimizer = tf.keras.optimizers.Adam(lr=0.0001)\r\nae.compile(optimizer=optimizer, loss=loss_fn,  metrics = [loss_fn])\r\nae.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=batch_size)\r\n```\r\n**Other info / logs**\r\n```\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: log_var_12/Identity:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```\r\n", "comments": ["@AakashKumarNain  \r\nIt seems to work for me! \r\nhttps://colab.research.google.com/drive/1tCms4KKPp3-CXbSSf00QvIYAbuQUVW3Z\r\nBtw I had to change  a typo\r\n```\r\nepsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\r\n```\r\nto \r\n```\r\nself.epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\r\n\r\n```\r\n", "Even that isn't required. I found out that I was accessing the `mu` layer outside the graph"]}, {"number": 33999, "title": "Fix typos", "body": "replace `output_shards_axes` with `output_shard_axes`", "comments": ["We will not be encouraging one liner changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac", "I think that now that Hackoberfest is over we can start accepting these again.\r\n\r\nAlthough, it would still be great to fix multiple typos in the same file at once, instead of just one by one."]}, {"number": 33998, "title": "tf.tensor_scatter_nd_update() doesn't work in custom layer/graph to update a  2D Tensor with indices", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **NA**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **2.0**\r\n- Python version: **3.7**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:*10.0/7.3.0*                                                                                                                    \r\n                                                                                                                                                              \r\n                                                                    **\r\n- GPU model and memory: GeForce 940m\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**  ValueError: Shape must be at least rank 1 but is rank 0 for 'TensorScatterUpdate' (op: 'TensorScatterUpdate') with input shapes: [64,64], [2], [].\r\n\r\n**Describe the expected behavior** : it should update the tensor given the row, column position\r\n\r\n**Code to reproduce the issue**\r\n**The following code is part of the custom layer and written in call function, the layer is not trainable hence I used Tensor instead of tf.Variable, size of sub_sub_mapl Tensor is 64,64, temp_val will be scalar, and m, n are a row & column position to be updated**\r\n\r\n                 ```\r\n temp_val = tf.convert_to_tensor(\r\n                    tf.add(tf.math.reduce_max(mat[i, j:j + 2]), tf.math.reduce_max(mat[i, l:l + 2])) / 2)\r\n                  indices = tf.constant([m, n], dtype=tf.int32)\r\n                  tf.tensor_scatter_nd_update(self.sub_sub_mapl, indices, temp_val)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTraceback (most recent call last):\r\n  File \"F:/pom/pom_cust_layer_parallel_v5.py\", line 93, in <module>\r\n    tf.keras.layers.Dense(num_classes, activation='softmax')])\r\n  File \"F:\\tf2venv\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"F:\\tf2venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 114, in __init__\r\n    self.add(layer)\r\n  File \"F:\\tf2venv\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"F:\\tf2venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 196, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"F:\\tf2venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 842, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"F:\\tf2venv\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 237, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in converted code:\r\n    relative to F::\r\n\r\n    pom/pom_cust_layer_parallel_v5.py:71 call  *\r\n        self.MAPL = tf.map_fn(fn=self.get_avg_pool, elems=input)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:268 map_fn\r\n        maximum_iterations=n)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:2675 while_loop\r\n        back_prop=back_prop)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:198 while_loop\r\n        add_control_dependencies=add_control_dependencies)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:915 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:176 wrapped_body\r\n        outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:257 compute\r\n        packed_fn_values = fn(packed_values)\r\n    pom/pom_cust_layer_parallel_v5.py:62 get_avg_pool\r\n        self.sub_mapl = tf.map_fn(fn=self.get_avg_pool_channel, elems=mat_unstacked)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:268 map_fn\r\n        maximum_iterations=n)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py:2675 while_loop\r\n        back_prop=back_prop)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:198 while_loop\r\n        add_control_dependencies=add_control_dependencies)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:915 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py:176 wrapped_body\r\n        outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py:257 compute\r\n        packed_fn_values = fn(packed_values)\r\n    pom/pom_cust_layer_parallel_v5.py:50 get_avg_pool_channel\r\n        tf.tensor_scatter_nd_update(self.sub_sub_mapl, indices, temp_val)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py:11087 tensor_scatter_update\r\n        updates=updates, name=name)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:793 _apply_op_helper\r\n        op_def=op_def)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\r\n        compute_device)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3429 _create_op_internal\r\n        op_def=op_def)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1773 __init__\r\n        control_input_ops)\r\n    tf2venv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1613 _create_c_op\r\n        raise ValueError(str(e))\r\n", "comments": ["@Sawatdatta, Please provide the complete standalone code to reproduce the reported issue. Thanks!", "@Sawatdatta, Looks like code is incomplete. Provide us the full code snippet. It will indeed help us to move faster. Thanks!", "Issue is replicating with Tf 2.0. \r\nPlease take a look at [gist](https://colab.sandbox.google.com/gist/gadagashwini/7dda04695bf85c7e26fcce0cd8d7b037/untitled247.ipynb). Thanks!", "Any updates on this issue?", "Was able to reproduce the issue with Tf-nightly==2.2.0.dev20200319.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/4f3b04745e9331890b19851c45935dad/untitled476.ipynb). Thanks!", "The issue comes from the point that you are passing a rank-1 index and a rank-0 update for updating a rank-2 tensor.\r\nSimply changing the code to this would solve the issue:\r\n`temp_val = tf.convert_to_tensor([\r\n                    tf.add(tf.math.reduce_max(mat[i, j:j + 2]), tf.math.reduce_max(mat[i, l:l + 2])) / 2])`\r\n`indices = tf.constant([[m, n]], dtype=tf.int32)`\r\n`self.sub_sub_mapl = tf.tensor_scatter_nd_update(self.sub_sub_mapl, indices, temp_val)`\r\n\r\nThis modification would match the rank of your `indices` with your inputs (rank-2), and would match the rank of the `temp_val` with each entry in your `indices`.", "@hassanhub @ymodak  Yes, this modification worked. Thank you "]}, {"number": 33997, "title": "[TF 2.0] 'Unknown graph' error when using tf.function decorator with pre-trained models", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-rc0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 1050 Ti\r\n\r\n**Describe the current behavior**\r\nIf I remove the `@tf.function` decorator, the error disappears. Facing this error when I created the loss function where feature extraction with the pre-trained VGG16 is a step in the pipeline.\r\n\r\n> ValueError: Unknown graph. Aborting.\r\n\r\n**Code to reproduce the issue**\r\n```\r\n\"\"\"\r\nReproduce the error of keras pretrain model with tf.function wrapper in TF 2.0\r\n\"\"\"\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications import VGG16\r\nfrom tensorflow.keras.models import Model\r\nimport numpy as np\r\n\r\n\r\n@tf.function\r\ndef extract_feat(feat_extractor, _input):\r\n    feat = feat_extractor.predict(_input, steps=1)\r\n    return feat\r\n\r\n\r\ndef main():\r\n    pretrain_vgg16 = VGG16(weights='imagenet', include_top=False)\r\n    feature_extractor = Model(inputs=pretrain_vgg16.input, outputs=pretrain_vgg16.get_layer('block3_conv3').output)\r\n\r\n    # create an dummy input\r\n    _input = np.random.rand(1, 224, 224, 3) - 0.5 / 0.5\r\n\r\n    feat = extract_feat(feature_extractor, _input)\r\n    print(feat.shape)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n2019-11-05 12:03:34.045339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-11-05 12:03:34.066201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.066747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:01:00.0\r\n2019-11-05 12:03:34.066896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-05 12:03:34.067713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-05 12:03:34.068423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-11-05 12:03:34.068599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-11-05 12:03:34.069586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-11-05 12:03:34.070296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-11-05 12:03:34.072541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-05 12:03:34.072620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.073192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.073714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-05 12:03:34.073892: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-05 12:03:34.101732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz\r\n2019-11-05 12:03:34.102528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c6a90fd40 executing computations on platform Host. Devices:\r\n2019-11-05 12:03:34.102541: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-11-05 12:03:34.167039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.167648: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c6a942ac0 executing computations on platform CUDA. Devices:\r\n2019-11-05 12:03:34.167662: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1\r\n2019-11-05 12:03:34.167802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.168336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:01:00.0\r\n2019-11-05 12:03:34.168363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-05 12:03:34.168374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-05 12:03:34.168384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-11-05 12:03:34.168393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-11-05 12:03:34.168403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-11-05 12:03:34.168412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-11-05 12:03:34.168421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-05 12:03:34.168455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.168990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.169514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-05 12:03:34.169538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-05 12:03:34.170424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-05 12:03:34.170433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-11-05 12:03:34.170437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-11-05 12:03:34.170550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.171093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 12:03:34.171631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2787 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"/home/biendltb/Projects/derain_gan/tools/error_reproduce.py\", line 29, in <module>\r\n    main()\r\n  File \"/home/biendltb/Projects/derain_gan/tools/error_reproduce.py\", line 24, in main\r\n    feat = extract_feat(feature_extractor, _input)\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 427, in __call__\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 370, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1847, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2147, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2038, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 320, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/biendltb/anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 905, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in converted code:\r\n    relative to /home/biendltb:\r\n\r\n    Projects/derain_gan/tools/error_reproduce.py:13 extract_feat  *\r\n        feat = feat_extractor.predict(_input, steps=1)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:915 predict\r\n        use_multiprocessing=use_multiprocessing)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py:722 predict\r\n        callbacks=callbacks)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py:189 model_iteration\r\n        f = _make_execution_function(model, mode)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py:565 _make_execution_function\r\n        return model._make_execution_function(mode)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:2155 _make_execution_function\r\n        self._make_predict_function()\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py:2145 _make_predict_function\r\n        **kwargs)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3658 function\r\n        return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\r\n    anaconda3/envs/dynim/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3542 __init__\r\n        raise ValueError('Unknown graph. Aborting.')\r\n\r\n    ValueError: Unknown graph. Aborting.\r\n```\r\n", "comments": ["A temporary solution was suggested here: https://stackoverflow.com/questions/56615565/evaluating-tf-model-inside-a-tf-op-throws-error/58705303#58705303", "I am able to reproduce the issue with Tf 2.0. \r\nPlease see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/c63657b9aa1f9133b430742a689e58fd/untitled236.ipynb). Thanks!", "I think the temporary solution makes sense, but @fchollet would know for sure.", "It does not solve the issue, but I found a workaround to this problem. It worked with the `@tf.function` decorator applying all the layers one by one, replacing the `extract_feat` method by:\r\n\r\n```Python\r\n@tf.function\r\ndef extract_feat(feat_extractor, _input):\r\n  feat = _input\r\n  for layer in feat_extractor.layers:\r\n    feat = layer(feat)\r\n  return feat\r\n```", "It looks like Model.predict is not compatible with tf.function. Note that the error is different in tf-nightly, and I confirmed that it's not caused by autograph by modifying the gist above:\r\n\r\n```\r\n@tf.function(autograph=False)\r\ndef extract_feat(feat_extractor, _input):\r\n    feat = feat_extractor.predict(_input, steps=1)\r\n    return feat\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-1-2656cf5dcf1a> in <module>()\r\n     23 \r\n     24 if __name__ == '__main__':\r\n---> 25     main()\r\n\r\n16 frames\r\n<ipython-input-1-2656cf5dcf1a> in main()\r\n     18     _input = np.random.rand(1, 224, 224, 3) - 0.5 / 0.5\r\n     19 \r\n---> 20     feat = extract_feat(feature_extractor, _input)\r\n     21     print(feat.shape)\r\n     22 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    574         xla_context.Exit()\r\n    575     else:\r\n--> 576       result = self._call(*args, **kwds)\r\n    577 \r\n    578     if tracing_count == self._get_tracing_count():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    621       # This is the first call of __call__, so we have to initialize.\r\n    622       initializers = []\r\n--> 623       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    624     finally:\r\n    625       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    503     self._concrete_stateful_fn = (\r\n    504         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 505             *args, **kwds))\r\n    506 \r\n    507     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2438       args, kwargs = None, None\r\n   2439     with self._lock:\r\n-> 2440       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2441     return graph_function\r\n   2442 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2769 \r\n   2770       self._function_cache.missed.add(call_context_key)\r\n-> 2771       graph_function = self._create_graph_function(args, kwargs)\r\n   2772       self._function_cache.primary[cache_key] = graph_function\r\n   2773       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2659             arg_names=arg_names,\r\n   2660             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2661             capture_by_value=self._capture_by_value),\r\n   2662         self._function_attributes,\r\n   2663         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    438         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    439         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 440         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    441     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    442 \r\n\r\n<ipython-input-1-2656cf5dcf1a> in extract_feat(feat_extractor, _input)\r\n      7 @tf.function(autograph=False)\r\n      8 def extract_feat(feat_extractor, _input):\r\n----> 9     feat = feat_extractor.predict(_input, steps=1)\r\n     10     return feat\r\n     11 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\r\n    917         max_queue_size=max_queue_size,\r\n    918         workers=workers,\r\n--> 919         use_multiprocessing=use_multiprocessing)\r\n    920 \r\n    921   def reset_metrics(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    494         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,\r\n    495         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,\r\n--> 496         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\r\n    497 \r\n    498 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    471               mode=mode,\r\n    472               training_context=training_context,\r\n--> 473               total_epochs=1)\r\n    474           cbks.make_logs(model, epoch_logs, result, mode)\r\n    475 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    166       else:\r\n    167         batch_outs = training_v2_utils._aggregate_predict_results(\r\n--> 168             strategy, batch_outs, model)\r\n    169 \r\n    170       if step == 0:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in _aggregate_predict_results(strategy, batch_outs, model)\r\n    262     nested_outs = batch_outs[i * num_replicas:i * num_replicas + num_replicas]\r\n    263     per_output_result = dist_utils.concat_along_batch_dimension(\r\n--> 264         nest.flatten(nested_outs))\r\n    265 \r\n    266     if need_batch_index_gather:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in concat_along_batch_dimension(outputs)\r\n   1200   if isinstance(outputs[0], ragged_tensor.RaggedTensor):\r\n   1201     return ragged_concat_ops.concat(outputs, axis=0)\r\n-> 1202   return np.concatenate(outputs)\r\n\r\n<__array_function__ internals> in concatenate(*args, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in __array__(self)\r\n    748   def __array__(self):\r\n    749     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\r\n--> 750                               \" array.\".format(self.name))\r\n    751 \r\n    752   def __len__(self):\r\n\r\nNotImplementedError: Cannot convert a symbolic Tensor (StatefulPartitionedCall:0) to a numpy array.\r\n```", "As shown in [this comment](https://github.com/tensorflow/tensorflow/issues/33997#issuecomment-586279455), calling the model/layer's call method can work under a tf.function, but we do not expect calling the model's predict method inside a function to work necessarily. Inside of predict, we wrap the calling of the model itself in a function, but predict takes care of some higher-level processing that doesn't guarantee operation inside of functions.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33997\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33997\">No</a>\n"]}, {"number": 33996, "title": "different gpu to each session in a thread", "body": "tensorflow c API\uff1aI want to create multiple sessions for different models in a thread, how to assign a different gpu to each session.\r\n", "comments": ["@liupengkd \r\nCan you go through the [link](https://www.tensorflow.org/guide/gpu#using_multiple_gpus) and see if it helps you?.Thanks!", "@ravikyram Thank you for your answer\u3002I know how to set it in python\uff0chowever\uff0c I want to set it in C"]}, {"number": 33995, "title": "ResourceExhausted while doing K-fold cross-validation regardless of the chosen K", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nwindows 10\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nTensorflow 2.0.0\r\n- Python version: \r\n3.7\r\n- CUDA/cuDNN version: CUDA 10, cuDNN 7.6\r\n- GPU model and memory: Titan V 12GB\r\n\r\n**Describe the current behavior**\r\nResourceExhausted at last K fold of a K-fold cross-validation. Regardless of the K chosen. I've tried\r\n3 fold, 5 fold and 10 fold and it always happens at the last fold.\r\n\r\n**Code to reproduce the issue**\r\n`\r\nfor j, (train_indices, val_indices) in enumerate(kf.split(datos_random)):\r\n\r\n    train = datos.iloc[train_indices]\r\n    val = datos.iloc[val_indices]    \r\n\r\n    metrics = ['accuracy']\r\n    model = build_model(DROPOUT, FC_LAYERS, num_classes=NUM_CLASSES, opt=OPT, metrics=metrics)\r\n\r\n    train_datagen =  keras.preprocessing.image.ImageDataGenerator(\r\n        preprocessing_function=preprocess_input,\r\n        horizontal_flip=True,\r\n        vertical_flip=True,\r\n        # rotation_range=25,\r\n        fill_mode='constant'\r\n        \r\n    )\r\n    \r\n    test_datagen = keras.preprocessing.image.ImageDataGenerator(\r\n        preprocessing_function=preprocess_input,\r\n    )\r\n    \r\n    train_generator = train_datagen.flow_from_dataframe(\r\n                                          train,\r\n                                          None,\r\n                                          x_col='file',\r\n                                          target_size=(WIDTH, HEIGHT),\r\n                                          y_col=f'Class_cat_{NUM_CLASSES}', \r\n                                          batch_size=BATCH_SIZE, \r\n                                          seed=SEED,\r\n                                          has_ext=True,class_mode='categorical')\r\n\r\n    \r\n    test_generator = test_datagen.flow_from_dataframe(val, \r\n                                          None, \r\n                                          x_col='file', \r\n                                          target_size=(WIDTH, HEIGHT),\r\n                                          y_col=f'Class_cat_{NUM_CLASSES}', \r\n                                          batch_size=BATCH_SIZE,\r\n                                          seed=SEED,\r\n                                          has_ext=True,\r\n                                          class_mode='categorical', \r\n                                          shuffle=True)\r\n    class_list = list(test_generator.class_indices.keys())\r\n   \r\n    checkpoint = keras.callbacks.ModelCheckpoint(name_weights, \r\n                                                 monitor=\"val_accuracy\", \r\n                                                 verbose=1, \r\n                                                 mode='max', \r\n                                                 save_best_only=True)\r\n    callbacks_list = [\r\n                      checkpoint, \r\n                      keras.callbacks.CSVLogger(os.path.join(fold_dir, 'log.csv'))\r\n    ]\r\n    print('Iniciando entrenamiento')\r\n    history = model.fit(train_generator, \r\n                        epochs=EPOCHS, \r\n                        workers=16, \r\n                        shuffle=True, \r\n                        callbacks=callbacks_list, \r\n                        verbose=1, \r\n                        steps_per_epoch=math.ceil(len(train_indices) / BATCH_SIZE),\r\n                        validation_data=test_generator, \r\n                        validation_steps=math.ceil(len(val_indices) / BATCH_SIZE)\r\n                                 )\r\n    \r\n    acc = history.history['accuracy']\r\n    val_accuracy = history.history['val_accuracy']\r\n\r\n    loss = history.history['loss']\r\n    val_loss = history.history['val_loss']\r\n    \r\n    avg_loss.append(val_loss[-1])\r\n    avg_acc.append(val_accuracy[-1]*100)\r\n                                      \r\n    model.save(os.path.join(fold_dir, 'model.h5')) `\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n`\r\nResourceExhaustedError: 2 root error(s) found.\r\n  (0) Resource exhausted: OOM when allocating tensor with shape[128,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node block1_conv2_8/Conv2D}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n  (1) Resource exhausted: OOM when allocating tensor with shape[128,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node block1_conv2_8/Conv2D}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[metrics_16/accuracy/Identity/_3869]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n0 successful operations.\r\n0 derived errors ignored.\r\n`", "comments": ["@marcojulioarg, Please provide the complete code to reproduce the reported issue. Thanks!", "@marcojulioarg,Any update on complete standalone code. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33994, "title": "TOCO failed", "body": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, AVERAGE_POOL_2D, CONCATENATION, CONV_2D, FLOOR, FULLY_CONNECTED, L2_NORMALIZATION, MAX_POOL_2D, MUL, PACK, RELU, RESHAPE, RSQRT, SHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: BatchNormalization, Merge, RandomUniform, Switch.", "comments": ["Please provide the information\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "@widiakha, Provide the information asked in the template. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33993, "title": "tensorflow lite performance", "body": "**System information**\r\n- OS Platform and Distribution : Windows10\r\n- TensorFlow installed from : binary\r\n- TensorFlow version : 2.0\r\n\r\n\r\n**How**\r\n- How to improve the performance for running tensorflow lite model in my ARM cortex-M devices?\r\nSomeone change standard C/C++ lib (for example using inline function to reduce the time) to improve performance. Could you please give me some advice to figure out that?\r\n\r\n", "comments": []}]