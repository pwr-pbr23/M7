[{"number": 8179, "title": "Branch 149461652", "body": "", "comments": []}, {"number": 8178, "title": "Forcing recomputation of graph expressions", "body": "We are using graph editor to rewrite the graph. It seems that there's some kind of caching going on, so that rewiring the graph after first `session.run` call has limited effect.\r\n\r\nUsing `OptimizerOptions.L0` when creating session does not prevent this caching.\r\n\r\nIt would be nice to have a way to force `TF_Run` run exactly the graph given to it by `TF_ExtendGraph`, rather than returning some internally cached result.\r\n\r\nThis is similar to https://github.com/tensorflow/tensorflow/issues/6804 where `Defun` definitions are frozen at first `session.run` call\r\n\r\nHere's an example, we rewrite the graph to have \"v2\" use same initializer op as \"v1\". This has different effect depending on whether rewiring happens before or after first `session.run` call\r\n@purpledog have you seen something like this?\r\n  \r\n```\r\ntf.reset_default_graph()\r\nv1 = tf.Variable([1. ,2. ,3.])\r\nv2 = tf.Variable([9., 9., 9.])\r\nconfig = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))\r\nsess = tf.Session(config=config)\r\n# uncommenting this changes final print from [1, 2, 3] to [9, 9, 9]\r\n# sess.run(tf.constant(1))\r\n\r\nge.reroute_a2b_ts(v1.initial_value, v2.initial_value)\r\ntf.get_default_graph()._version+=1   # make sure TF_ExtendGraph gets called\r\n\r\nsess.run(v2.initializer)\r\nprint(sess.run(v2))\r\n```", "comments": ["TF_ExtendGraph can only add ops to an existing graph (by design, hence the name).  If you modify existing ops in the graphdef which has been used in a session this will have no effect.\r\n\r\nThe only way I know to achieve this is to make a new session using the modified graph.\r\n\r\n@mrry  Is this correct? \r\n\r\n", "Yes, that's correct. `tf.contrib.graph_editor` doesn't work on graphs that have already been used in a `tf.Session`.", "Good point.\r\nAlso, I've just checked the updated Graph Editor guide and it does indeed specify that it must be used without any active sessions, thanks for clarification."]}, {"number": 8177, "title": "Some Tensorboard metadata unsearchable", "body": "### Environment Info\r\nUbuntu 16.04\r\nTensorflow installed from pip, TF version 1.0.\r\n\r\n### Potential Bug\r\nI'm using Tensorboard's embedding projector to perform PCA/t-SNE on a dataset of features I've extracted from ~4K MIDI files. I've created a metadata TSV and pointed my Tensorflow application to it as instructed in [the documentation](https://www.tensorflow.org/get_started/embedding_viz). The metadata parses correctly in Tensorboard, however, when I use the inspector on the right-most panel, many of the fields seem to be unsearchable, or at least yield zero results for any valid query. Searching the first 13 fields (columns) works correctly, however 3 of the last fields are unsearchable, specifically `artist_terms`, `artist_mbtags`,  and `artist_location` in `embedding_logdir/metadata.tsv`.\r\n\r\nI'm finding this to be the case independent of whether regex mode is enabled or disabled. I can also confirm that these fields are being parsed correctly as I can select a data point and view the values for these problematic fields. I've also tried creating a metadata file with only those three problematic fieldnames and they continue to misbehave in this test as well.\r\n\r\n### Reproducing\r\n\r\nI've attached my logdir complete with a checkpoint and metadata.tsv. To reproduce my results, extract the folder and launch Tensorboard from inside `embedding_logdir`'s parent directory like so:\r\n\r\n```\r\ntensorboard --logdir embedding_logdir\r\n``` \r\n\r\nTensorboard must be run from the parent directory of `embedding_logdir` to maintain the correct filepath I specified for the `metadata.tsv` file in my TF program. \r\n \r\n[embedding_logdir.tar.gz](https://github.com/tensorflow/tensorflow/files/825381/embedding_logdir.tar.gz)\r\n", "comments": ["Checking in on this, has anyone been able to reproduce?", "I tried to, unfortunately wasn't able to reproduce any metadata at all, though the embedding visualizations show up nicely.\r\n\r\nWhat i did:\r\n\r\n Extract Files into \r\n\r\n> C:\\Users\\gcfghh\\Downloads\\tmp\\embedding_logdir\r\n![logdir](https://cloud.githubusercontent.com/assets/25869733/25002384/6d573634-204a-11e7-93db-92cb912d7540.PNG)\r\n\r\n\r\nWindows cmd: \r\n\r\n> (py_35) C:\\Users\\gcfghh\\Downloads\\tmp\\embedding_logdir>tensorboard --logdir embedding_logdir/\r\n\r\nThis is my result:\r\n![tensor](https://cloud.githubusercontent.com/assets/25869733/25002417/9a9fbeea-204a-11e7-9e51-d64223c7f846.PNG)\r\n\r\nWhere did i mess up? I think it has to do something with the path i start tensorboard from, not sure though. Any enlightenments would be greatly appreciated.\r\n\r\nEdit1: fixed spelling\r\n\r\nEdit2: I over-read that i'm supposed to start Tensorboard from the parent directory. \r\nSo i tried > (py_35) C:\\Users\\gcfghh\\Downloads\\tmp>tensorboard --logdir embedding_logdir/\r\nand it works like a charm, metadata showing up. I can confirm that the last 3 columns don't show up.\r\n![tensor2](https://cloud.githubusercontent.com/assets/25869733/25003470/d7e930c4-204f-11e7-9cc5-06a9bc2e650c.PNG)\r\n\r\nEdit3: Did you make this work yet, @brannondorsey ?\r\n\r\nEdit4: I didn't check the 'label by\" option, only the \"colour by\". The fields you name actually do show up there ( i did not change anything)\r\n![tensor3](https://cloud.githubusercontent.com/assets/25869733/25003904/e710b098-2051-11e7-8793-67fa81366c3e.PNG)\r\n", "Hey there, thanks for taking the time to try this out. I am only just seeing this, apologies as I must have missed it in my inbox. Are you able to search text strings in any of those columns (searching using the inspector panel on the right, not the left)? Cheers! ", "I should have taken the time to read all of your introductory question. \r\n\r\nI can't search through the problematic fields using the right panel, regardless of regex on/off.", "No worries at all, I appreciate your efforts in reproducing this. Its also worth noting that it isn't just me who is having trouble with this then. @dandelionmane any thoughts on this bug?", "I'm migrating this to https://github.com/tensorflow/tensorboard/issues/79, and assigning @dsmilkov and @nsthorat, who build the embedding projector, to take a look."]}, {"number": 8176, "title": "runtime error of combing tensorflow CTC and SynthText", "body": "Hi,\r\n\r\nI met a runtime error during training when I tried to applied **tensorflow built-in CTC** loss function  (https://www.tensorflow.org/versions/r0.10/api_docs/python/nn/conectionist_temporal_classification__ctc_) to **SynthText dataset**. http://www.robots.ox.ac.uk/~vgg/data/scenetext/ \r\nIt said \" Not enough time for target transition sequence (required: 4, available: 0)\". \r\nHere is the some info for environment: tensorflow version '0.12.0-rc0'.\r\n\r\nI am able to apply **tensorflow built-in CTC** to **Synth90K Dataset** with great performance (http://www.robots.ox.ac.uk/~vgg/data/text/). \r\n\r\nIt seems like the **SynthText dataset** is not compilable with **tensorflow built-in CTC** but **Synth90K Dataset** could. \r\n\r\nPlease find the error message as reference\r\n\r\nstep 980, loss = 50.17 (92.1 examples/sec; 0.695 sec/batch)\r\nW tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Not enough time for target transition sequence (required: 4, available: 0), skipping data instance in batch: 28\r\nTraceback (most recent call last):\r\n  File \"multi-gpu-train.py\", line 305, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"multi-gpu-train.py\", line 301, in main\r\n    train()\r\n  File \"multi-gpu-train.py\", line 270, in train\r\n    _, loss_value = sess.run([train_op, loss])\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Not enough time for target transition sequence (required: 4, available: 0), skipping data instance in batch: 28\r\n\t [[Node: tower_0/CTCLoss = CTCLoss[ctc_merge_repeated=true, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](tower_0/transpose_2/_555, tower_0/Where, tower_0/sub_2/_557, tower_0/Sum_1/_559)]]\r\n\r\nCaused by op u'tower_0/CTCLoss', defined at:\r\n  File \"multi-gpu-train.py\", line 305, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"multi-gpu-train.py\", line 301, in main\r\n    train()\r\n  File \"multi-gpu-train.py\", line 179, in train\r\n    loss,logits_op,images,labels = tower_loss(scope)\r\n  File \"multi-gpu-train.py\", line 79, in tower_loss\r\n    _ = network2.loss(logits,images, labels)\r\n  File \"/home/ubuntu/experiments/network2_dev/network2.py\", line 61, in loss\r\n    out = tf.nn.ctc_loss(logit, to_sparse(y), seq_len, time_major=False)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/ctc_ops.py\", line 145, in ctc_loss\r\n    ctc_merge_repeated=ctc_merge_repeated)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_ctc_ops.py\", line 164, in _ctc_loss\r\n    name=name)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Not enough time for target transition sequence (required: 4, available: 0), skipping data instance in batch: 28\r\n\t [[Node: tower_0/CTCLoss = CTCLoss[ctc_merge_repeated=true, preprocess_collapse_repeated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](tower_0/transpose_2/_555, tower_0/Where, tower_0/sub_2/_557, tower_0/Sum_1/_559)]]", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 8175, "title": "Unclear documentation for tf.layers.dense flattening behavior", "body": "Documentation states:\r\n\r\n> Note: if the `inputs` tensor has a rank greater than 2, then it is\r\n> flattened prior to the initial matrix multiply by `w`.\r\n> \r\n\r\nHowever, the following returns tensor with shape `shape=(2, 2, 2, 400)`, as if the input has not been flattened\r\n`tf.layers.dense(tf.placeholder(tf.float32, (2,2,2,2)), 400)`", "comments": ["Whoops, sorry, didn't mean to remove myself.  Investigating internally, was trying to add the person I think is responsible.", "So, after investigation, what I was told was that it behaves like tensordot, and so the behavior and the current documentation are both correct -- and the engineer I talked to said that they thought we could use more precise language but that it wouldn't necessarily help as the current language is clear and unambiguous when in context.  (See tensordot: https://docs.scipy.org/doc/numpy/reference/generated/numpy.tensordot.html)\r\n\r\nIf you want to try to make a pull request yourself to do some rewording, that would be welcome, but I'm closing this bug for now since we're not going to do anything about it internally.", "Ah thanks, tensordot connection makes it more clear.\r\n\r\nIt seems `tf.dense` behaves by contracting last index of input tensor with first index of weights tensor. The \"flatten\" word was confusing, not sure what it means here\r\n\r\nToy example I made for myself to translate tf.dense to equivalent np.tensordot\r\n\r\n```\r\ntf.reset_default_graph()\r\nx0 = np.ones((3, 3, 3))\r\nw0 = np.arange(6).reshape((3, 2))\r\nx = tf.constant(x0)\r\ny = tf.layers.dense(x, 2)\r\nvar_dict = {v.op.name: v for v in tf.global_variables()}\r\nassert(var_dict[\"dense/kernel\"].get_shape() == (3, 2))\r\nsess = tf.InteractiveSession()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run(tf.assign(var_dict[\"dense/kernel\"], w0))\r\nsess.run(tf.assign(var_dict[\"dense/bias\"], np.zeros((2,))))\r\n\r\nexpected_y0 = np.tensordot(x0,w0,axes=[(2,),(0,)])\r\ny0 = sess.run(y)\r\nnp.testing.assert_allclose(y0, expected_y0)\r\n```"]}, {"number": 8174, "title": "tfdbg requires external ncurses on OSX", "body": "- OSX 10.11.6\r\n- TF from source at `8746f8ac9` (master HEAD from a few hours ago) without GPU\r\n- XCode 8.2.1\r\n\r\nWhen loading it, tfdbg crashes with a curses-related error. Was solved with `brew install homebrew/dupes/ncurses`. If this is really a dependency, it would be useful to mention it in the documentation or installation guide.", "comments": ["@lemonzi thanks for reporting this issue. Yes, curses/ncurses is a dependency for tfdbg on OSX. I will document it better in the next release.", "Great, thanks! Good to know I didn't mess anything up. \r\n\r\nIt also seems Terminal.app sends by default some weird character when pressing the delete key, and requires enabling the \"Delete sends Control-H\" option for the backspace to work. Not sure if this could be considered a bug -- maybe just having it on the FAQ or docs as well will be enough.", "@lemonzi Yep, we are aware that there are keybinding issues on Mac. There is an internal bug tracking that.", "This is fixed. See the last Q&A \"What are the platform-specific system requirements of tfdbg CLI in open-source TensorFlow?\"  here: https://www.tensorflow.org/programmers_guide/debugger#frequently_asked_questions"]}, {"number": 8173, "title": "reduce line count using getattr() on layers 'weighted_sum...' rather than two explicit calls", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Thanks, yes, that's clearer", "Thank you @jhseu think I've made the changes :)", "Jenkins, test this please"]}, {"number": 8172, "title": "Get initialized value of variable without resetting", "body": "As far as I know, there is currently no way to get the current value of a variable while ensuring that it has been initialized once. tf.Variable.initialized_value() has a dependency on the initializer that causes the variable to be reset to its initial value every time it is accessed. Using `return tf.cond(tf.is_variable_initialized(variable), lambda: variable.value(), lambda: variable.initialized_value())` does not work since the true-branch of the conditional requires the variable to be initialized, even though the false-branch becomes active.\r\n", "comments": ["This is one of snags in dependent variable initialization that can't be handled with `initialized_value`, see https://github.com/tensorflow/tensorflow/issues/4920 for discussion.\r\n\r\nI used [smart_initialize](https://gist.github.com/yaroslavvb/d592394c0cedd32513f8fbb87ca05938) that rewrote the graph to automatically initialize the variable on first read, but with VariableV2 change, things changed so that now adding a control dependency in var/read on initializer causes a hang.\r\n\r\nI think perhaps the way to fix it is to have add a piece of code that monkey-patch replaces `tf.Variable` class with a version that returns a Tensor which triggers variable initialization on first read", "Yes, this is a bit of a mess with dynamic control flow.  Here's a workaround due to @vrv.   Note the use of `var.read_value()` rather than `var.value()`\r\n\r\n```\r\ndef initialized_var(t):\r\n  var = tf.Variable(t)\r\n  is_var_init = tf.is_variable_initialized(var)\r\n  return var, tf.cond(is_var_init, lambda: var.read_value(),\r\n                      lambda: var._initializer_op.outputs[0])\r\n```\r\n\r\nPlease let me know if this works for you.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8171, "title": "add backup URL for downloading MNIST", "body": "A lot of folks (https://github.com/tensorflow/tensorflow/issues/6742, https://github.com/tensorflow/tensorflow/issues/8126, https://github.com/tensorflow/tensorflow/issues/8134,\r\nhttps://github.com/tensorflow/tensorflow/issues/8116) have been having sporadic trouble downloading MNIST, because the site where it is canonically hosted sometimes goes down. This PR just adds a backup URL for convenience (though with the increased traffic the backup will get when normal MNIST is down, the backup might fail too. Someone might want to put this up on S3 or something Google-hosted.)", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "We do not have the permission from Yann Lecun to mirror these files.\r\n\r\nTherefore, we cannot accept this PR. We are looking into modifying our tutorials to not depend on mnist dataset.", "Cool, no problem. Maybe someone can contact him and see if he can improve how MNIST is hosted, since it seems like tons and tons of people are downloading it on a daily basis now.", "I found a basic solution. I manually downloaded all dataset from http://yann.lecun.com/exdb/mnist/ to my local and made them reachable by tensorflow. And it's working. I know it's a dummy solution but it's working :)", "It works by manually downloading all dataset. Save them in the format of *.gz in the MINST folder", "which folder to should I download .gz files?\r\n", "MNIST_DATA, next to the corresponding python script\r\nit should be created by previous failed calls", "Was this issue solved?", "I downloaded each of the files from the website and put them into the MNIST_DATA folder, and I still receive an error:\r\nTraceback (most recent call last):\r\n  File ..., line 25, in <module>\r\n    batch_xs, batch_ys = mnist.train.next_batch(100)\r\nNameError: name 'mnist' is not defined", "It looks like you didn't import mnist class properly.\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)", "I tried doing that, and I now get a new error:\r\nValueError: Cannot feed value of shape (100, 10) for Tensor u'Placeholder_1:0', which has shape '(?,)'", "the folder MNIST_data was created, and I added the data into the folder; yet I still get the error."]}, {"number": 8170, "title": "tensorflow 2st test:\"CUDA_ERROR_OUT_OF_MEMORY\", What's wrong here???", "body": "when I run:\r\n>>>import tensorflow as tf\r\n>>>hello=tf.constant('Hello, TensorFlow!')\r\n>>>sess=tf.Session()\r\n ERROR came like that:\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 190.31MiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 190.31M (199557120 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n\r\nIs there anyone who can tell me what's wrong here??? Very gratefull for you help!!!\r\n\r\n\r\n", "comments": ["> Total memory: 7.92GiB\r\n> Free memory: 190.31MiB\r\n\r\nSomething is already consuming all your GPU memory. Run `nvidia-smi` to see what's going on, you have no memory left.\r\n\r\nIf you are trying to run 2 TensorFlow codes in parallel, you will want to change the Session command to this:\r\n```\r\nconfig = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\r\nconfig.gpu_options.allow_growth=True\r\nsess = tf.Session(config=config)\r\n```\r\n\r\nThis way, TensorFlow won't allocate all of the memory for a single process.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I am running boston.py  from this tutorial \r\nhttps://www.tensorflow.org/get_started/input_fn, I have a Nvidia GPU 1080, tensorflow 1.3 on ubuntu 16.04\r\ngetting CUDA out of memory even for such a small dataset.\r\nI could run a test for 10000 x 10000 matrix multiplication"]}, {"number": 8169, "title": "Closes #8165 -- Removing traces of os_setup.md", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@josh11b, i'm not entirely sure whether it makes more sense to link to the website or files under docs_src. Adding you as a reviewer.", "I don't think the link should point to tensorflow.org directly - I think it should use a relative path. @josh11b can you comment?", "I agree it should have relative links. Hold on, I'm updating files and will let you know as soon as it's OK.\r\n\r\nUpdate: Done.", "@dandelionmane We don't want links to docs_src -- they are source files and are not necessarily readable.  tensorflow.org is the source of truth for docs and should be the target of links.  The main exception is if you are modifying something in docs_src or in a comment that will end up in the API docs, then you should use the new @{...} syntax (described in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/g3doc ) for links when possible.", "@josh11b I believe anyone seeing the README file would have a Markdown interpreter, no? Unless they're reading in plain text, then it's safe to assume they will be able to follow links by themselves.\r\n\r\nRelative links will alow users who have an offline copy to continue working, reading their copies of the docs, instead of going online to find the same resource.", "The files in docs_src/ will have lots of problems being rendered by a Markdown interpreter, since we have our own syntax (@{...}) for internal links that requires a preprocessing step to be made useful.", "I see... On a side note, even after this PR there are still 38 references in 16 files to g3doc, they should eventually be fixed as well.\r\n\r\nShould I retreat the last commit with relative links?", "Yes please, retreat the last commit", "@josh11b done. ;)", "Cool, merging it then. Thanks for the fix."]}, {"number": 8168, "title": "tf.case evaluating all outputs when using batches (?)", "body": "Hello,\r\n\r\nI may be missing something here, but I couldn't find any useful information on the documentation, so I'm posting this behavior as a bug, hoping someone can clarify what's going on. Questions at the end of this issue\r\n\r\n**Operating System:** Debian 4.8.15-2\r\n**Installed version of CUDA and cuDNN:** CUDA 8, cuDNN 5\r\n**python3 -c \"import tensorflow; print(tensorflow.__version__)\"**: 1.0.0\r\n\r\n### Reproducible example\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\r\nb = ([tf.constant(i) for i in range(2)],[tf.constant(i) for i in range(2)])\r\n\r\nq1 = tf.train.slice_input_producer(a, num_epochs=3, shuffle=True, capacity=4)\r\nq2 = tf.train.batch(q1, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\r\n\r\nq3 = tf.train.slice_input_producer(b, num_epochs=1, shuffle=True, capacity=4)\r\nq4 = tf.train.batch(q3, batch_size=2, num_threads=1, enqueue_many=False, capacity=4, allow_smaller_final_batch=True)\r\n\r\nq4p = [tf.Print(q4[0], ['q4a']), tf.Print(q4[1], ['q4b'])]\r\nq2p = [tf.Print(q2[0], ['q2a']), tf.Print(q2[1], ['q2b'])]\r\n\r\ndef get_op1():\r\n\tprint('call1')\r\n\treturn tf.Print(q2p, ['op1'])\r\n\r\ndef get_op2():\r\n\tprint('call2')\r\n\treturn tf.Print(q4p, ['op2'])\r\n\r\nswitcher = tf.placeholder(tf.bool)\r\ntest = tf.case([(switcher, get_op1)], default=get_op2, exclusive=True)\r\n\r\ninit = [tf.global_variables_initializer(), tf.local_variables_initializer()]\r\nsess = tf.Session()\r\ncoord = tf.train.Coordinator()\r\nsess.run(init)\r\nthreads = tf.train.start_queue_runners(coord=coord, sess=sess)\r\n\r\nignore = sess.run(test, feed_dict={switcher: True})\r\n\r\nwait = input(\"So far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue.\")\r\n\r\nignore = sess.run(test, feed_dict={switcher: True})\r\n```\r\n\r\n### Output\r\n\r\n```\r\ncall2\r\ncall2\r\ncall1\r\n[None, None]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q4b]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q2a]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q4a]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [q2b]\r\nI tensorflow/core/kernels/logging_ops.cc:79] [op1]\r\n(some warnings/errors)\r\nSo far, so good. We're evaluating q1/q2, but now q3/q4 will run out of examples. Press enter to continue. (enter pressed)\r\n(big errors, queue is empty)\r\n```\r\n\r\n### Questions\r\n\r\n1) Why is `get_op2()` called 2 times before init?\r\n2) Why are there so many messages after the first `sess.run(test...)`? And why do they say `OutOfRange`, when I have enough examples in the queue? (I can only imagine it's because the threads feeding the queue are dying, but weird nevertheless)\r\n3) Although `op2` is not printed, `q4a` and `q4b` are, and they shouldn't, since we're evaluating `q2`. This led me to believe examples are being pulled from `q4` even though I didn't ask for them, and that is why the second `sess.run(test...)` crashes : no more examples in `q4`.\r\n\r\nIt seems tf.case is evaluating everything (weirdly, without printing `op2`), because `q4` goes to exhaustion without being used at all. I am using this system to switch between train/validation sets, but I'm being restricted by the amount of images in validation, which doesn't make any sense. So far I can only imagine either there is a bizarre bug on `tf.case` or I misunderstood something. Could you clarify this please?\r\n\r\nThanks in advance.", "comments": ["Update: This issue is related to #3287, which was closed without a proper solution (IMHO). The documentation doesn't explain why it runs all branches, and the questions 1 and 2 in this topic aren't addressed.", "Conditional execution needs all ops to be created inside the the op. You created `q2p = [tf.Print(q2[0]` ahead of time, so those ops are executed regardless of the condition.\r\n\r\nThere's some extra explanation by mrry here -- http://stackoverflow.com/questions/34401714/is-tensorflow-lazy", "Thanks for the link, I didn't know that -- the documentation should explain this behavior, it's definitely very important.\r\n\r\n> Conditional execution needs all ops to be created inside the the op.\r\n\r\nDoes this mean conditional execution is, by nature, incompatible with anything that involves queues, since we cannot simply redefine the queue each time? -- in this case, redefine the queue = calling slice_input_producer and batch function.\r\n\r\nIf so, I don't see a way to solve the problem of having a batch variable with examples coming from two different sources. The only way to do so would be by putting a placeholder as input for the model, and manually evaluating the batch before passing it in the feed_dict parameter, effectively dividing the graph and treating the condition _\u00e0 la python_. In my opinion, not an elegant solution.\r\n\r\nIs there any way (_or, better, a correct way_) around this specific problem of selecting the set of images to be used?", "Yes, it seems doing lazy dequeue\u00a0with tf.cond is problematic. There's `tf.train.maybe_batch` op that can take over some of the target use cases", "I didn't know `tf.train.maybe_batch` neither, but I don't think it can solve the problem. A quick read on its doc shows:\r\n\r\n> keep_input: A bool Tensor. This tensor controls whether the input is added to the queue or not. If it is a scalar and evaluates True, then tensors are all added to the queue. If it is a vector and enqueue_many is True, then each example is added to the queue only if the corresponding value in keep_input is True. This tensor essentially acts as a filtering mechanism.\r\n\r\nIt seems the `keep_input` parameter can only control `enqueue`, whereas I'm trying to control `dequeue` (i.e. do not `dequeue` from validation if we're training, and do not `dequeue` from train if we're validating).\r\n\r\nIn my understanding, part of the philosophy behind TensorFlow is to have a well built graph, without having to manually control these things \u2014 like calling dequeue from two different places based on a \"python condition\", but rather embed it all into the graph and let TF optimize its way through it. In this perspective, not being able to implement a source selector in the graph sounds like a major fault.\r\n\r\nSince I don't see a possible solution for this, I'm going to switch to the manual conditioning. Thank you very much for the help @yaroslavvb, I learned a lot here. :-)\r\n\r\nPS: Leaving the issue open for a member's response and/or as a feature suggestion.", "Just to be more precise and maybe help people who are looking for a solution:\r\n\r\nThe proposal/request in this thread is for something similar to `tf.QueueBase.from_list`, but receiving `dequeue` operations and/or the output of `tf.train.batch` instead of Queue objects. If one has manual control over the Queues, it is possible to use this method to pick which queue we should dequeue from using a single input variable. Without access to the Queue objects (as when using `tf.train.batch`), this is not possible.\r\n\r\n_Maybe_ it's possible to _hack_ our way through the issue by retrieving the Queue objects from the graph and calling `tf.QueueBase.from_list` with them, but this would not be a clean solution.", "Using multiple queues always bothers me.\r\n\r\nA better option is discussed here #7951. ", "@MicaelCarvalho I seem to have implemented the hack you described. Fairly dirty, but if anybody wants a stopgap...\r\n\r\n```\r\nbatch_train=tf.train.shuffle_batch(...)\r\nbatch_test=tf.train.shuffle_batch(...)\r\nqueue_selector = tf.placeholder(tf.int32, name='queue_selector')\r\ntrain_q = tf.QueueBase(queue_ref=batch_train.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\r\ntest_q = tf.QueueBase(queue_ref=batch_test.op.inputs[0], dtypes=[tf.string], shapes=None, names=None)\r\nselected_batch = tf.QueueBase.from_list(queue_selector, [train_q, test_q])\r\nselected_batch_size = tf.stack([train_batch_size, test_batch_size], axis=0)[queue_selector]\r\ndequeue_op = selected_batch.dequeue_many(selected_batch_size)\r\nfeatures = tf.parse_example(dequeue_op, ....)\r\n```\r\nedit: if it's not entirely clear, batch_train and batch_test are dequeue ops and take the queue reference as their first input. We then use those to construct new QueueBase objects, feed them through a selector  and create our own dequeue op which only runs on the selected queue.", "@MicaelCarvalho I'm working on the exact same issue and wonder if from your minimal code example you could gently write the \"manual\" strategy that you described ... Thanks in advance", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Closing as obsolete since we are moving from queues to datasets, but please reopen if this needs attention."]}, {"number": 8167, "title": "URLError: <urlopen error [Errno 110] Connection timed out> ", "body": "When I run program about Deep MINIST for Experts on Jupyter notebook,I met this question.How do I solve it?", "comments": ["Yann LeCun's website is down, and the dataset is hosted over there. For now, you can only wait for it to come back up, or look for a mirror online.", "Closing as duplicate of #8126"]}, {"number": 8166, "title": "Fix broken link due to recent docs move", "body": "The link was broken when the docs moved from g3doc to their new place. This fixes by linking to the \"Installing TensorFlow\" page on the website.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "There are other places in the repository with the broken URL. I didn't see this PR before submitting another one, otherwise I would post a comment here instead. Anyway, it's basically the same thing, but fixing other places as well: #8165 ", "Closing this as it is redundant with https://github.com/tensorflow/tensorflow/pull/8169/files which also fixes some other files."]}, {"number": 8165, "title": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md 404", "body": "rt, 404 error of link from readme, Download and Setup", "comments": ["Should be fixed by https://github.com/tensorflow/tensorflow/pull/8169\r\n"]}, {"number": 8164, "title": "AttributeError: module 'tensorflow.python.training.training' has no attribute 'SummaryWriter'", "body": "When I use tensorboard\uff0creturn this error\u3002\r\nAttributeError: module 'tensorflow.python.training.training' has no attribute 'SummaryWriter'", "comments": ["SummaryWriter has changed in TensorFlow 1.0. You can use `tf.summary.FileWriter`", "Hello, I have got the related error while training the NN with Tensorflow, any help? Thanks!\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-10bb478fe634> in <module>()\r\n      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(yPredbyNN, Y))\r\n---->optimizer = tf.train.AdamOptimiizer().minimize(loss)\r\n      CorrectPred = tf.equal(tf.argmax(yPredbyNN,1), tf.argmax(Y,1))\r\nAttributeError: module 'tensorflow.python.training.training' has no attribute 'AdamOptimiizer'", "@Kamatio I don't see how the problem is related. But are you correctly importing TensorFlow with `import tensorflow as tf`? Furthermore, check which version you're using; it's possible you have something very old installed.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I have the same issue when I try to run my code with tensorflow\r\nAttributeError: module 'tensorflow.python.training.training' has no attribute 'AdagradDAOptimizer'\r\n\r\n", "hi,,\r\nI am getting this error :\r\ntrain_writer = tf.train.summary.FileWriter(summaries_dir + '/train')\r\nAttributeError: module 'tensorflow.python.training.training' has no attribute 'summary'\r\n\r\nmy code is this\r\ntrain_writer = tf.train.summary.FileWriter(summaries_dir + '/train')\r\n\r\nwhats the problem, \r\nIt was at first summarywriter but I changed that to summary.filewriter still getting this error\r\n\r\n", "@saria85 the correct name is `tf.summary.FileWriter`. All problems reported in this thread seem to be solvable with a simple google search.", "@Techlucy  please verify the spelling it might cause the issue \r\nthanks", "yes\uff0c `writer = tf.summary.FileWriter(log_dir, sess.graph) ` solve my problem.", "AttributeError                            Traceback (most recent call last)\r\n<ipython-input-24-a8333a92c1ae> in <module>()\r\n----> 1 saver=tf.train.saver()\r\n\r\nAttributeError: module 'tensorflow.tools.api.generator.api.train' has no attribute 'saver'\r\n", "@KirosG, it's a class, so you have to correctly use the casing. Saver, with an uppercase S: `saver=tf.train.Saver()`"]}, {"number": 8163, "title": "Go: Handle nil values for list-valued attributes gracefully.", "body": "Without this change, setting a list-valued attribute to 'nil' would\r\nresult in a crash (&list[0] is malformed).", "comments": ["Jenkins, test this please"]}, {"number": 8162, "title": "Show location of using uninitialized variable in the stacktrace", "body": "It's currently hard to debug initialization of multiple variables with initial values depending on each other:\r\n\r\n```python\r\na = tf.Variable(42)\r\nb = tf.Variable(some_function(a.value()))\r\n```\r\n\r\nThe current error message has the form `FailedPreconditionError (see above for traceback): Attempting to use uninitialized value a` and the traceback points to `sess.run(tf.global_variables_initializer())`. However, the place for fixing this problem is the declaration of `b`:\r\n\r\n```python\r\na = tf.Variable(42)\r\nb = tf.Variable(some_function(a.initialized_value()))\r\n```\r\n\r\nWould it be possible to add the line that defines the uninitialized access to the traceback?", "comments": ["Have you tried initializing local variables as well? Maybe you have a local dependency in your function `some_function`.\r\n\r\n`sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])`\r\n\r\nIf you can provide a code that reproduces the problem, it can be easier to debug. I ran the lines you provided, but they work fine here. ;-)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8161, "title": "ImportError: DLL load failed  &  ImportError: No module named '_pywrap_tensorflow_internal'", "body": "Dear friends\uff1a\r\n \r\n>>>import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_intern\r\nal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", l\r\nine 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_intern\r\nal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_intern\r\nal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <modu\r\nle>\r\n    from tensorflow.python import *\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 51, i\r\nn <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", l\r\nine 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_intern\r\nal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", l\r\nine 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_intern\r\nal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_intern\r\nal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_st\r\narted/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n---------------------------------------------------------------------------------------------------------\r\n### previous trying:\r\n 1. installing Microsoft Visual C++ 2015 Redistributable Update 3 (x64 version);\r\n 2. check the env variables path of CUDA and cudnn is C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v7.5 and D:\\software\\caffe\\caffe-installer\\cuda;\r\n 3. C:\\Windows\\System32 has MSVCP140.dll;\r\n\r\n### Environment info\r\nOperating System: win7 + python3.5\r\ninstall tensorflow command is \r\n>>>python35 -m pip install --upgrade D:\\downloads\\tensorflow_gpu-1.0.0-cp35-cp35m-win_amd64.whl\r\n\r\n\r\nInstalled version of CUDA and cuDNN: \r\nCUDA 7.5\r\ncuDNN 7.0\r\n\r\nThand you very much:-)", "comments": ["Can you try upgrading to CUDA 8.0? We don't support CUDA 7.5 in TensorFlow 1.0.", "Dear Mr. mrry, you perfectly solved my problem, thank you very very much!", "You're welcome, and I'm glad to hear it!", "@ry I also met the same problem \"No module named pywrap_tensorflow_internal\".\r\n I cannot update CUDA7.5 to 8.0 due to some reasons. Hence, have to install with sources. I have done everything as this [Page](https://www.tensorflow.org/install/install_sources#PrepareLinux) say. However, when i import tensorflow I have this. Can I install TF1.0 or solve this problem?\r\nReally appreciate for any advises! ", "but if I didn't install gpu version of tensorflow why this error happens\r\nhttps://www.tensorflow.org/install/install_linux says we don't require cuda if don't install tensorflow gpu version\r\n", "anyway I have 8, but it still gives that error", "+1 installing cpu only version gives me the same issue on Windows.\r\n\r\n    ImportError: Traceback (most recent call last):\r\n      File \"C:\\Users\\XXXX\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n        return importlib.import_module(mname)\r\n      File \"C:\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n        return _bootstrap._gcd_import(name[level:], package, level)\r\n      File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n      File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n      File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n      File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n      File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n      File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\r\n      File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n    ImportError: DLL load failed: The specified module could not be found.\r\n\r\n    During handling of the above exception, another exception occurred:\r\n\r\n    Traceback (most recent call last):\r\n      File \"C:\\Users\\XXXX\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n        from tensorflow.python.pywrap_tensorflow_internal import *\r\n      File \"C:\\Users\\XXXX\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n        _pywrap_tensorflow_internal = swig_import_helper()\r\n      File \"C:\\Users\\XXXX\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n        return importlib.import_module('_pywrap_tensorflow_internal')\r\n      File \"C:\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n        return _bootstrap._gcd_import(name[level:], package, level)\r\n    ImportError: No module named '_pywrap_tensorflow_internal'\r\n", "Happens to me as well. \r\nI have installed CUDA8, CuDNN 5.1.\r\nAny solutions?\r\n\r\nEDIT:\r\nI found this excellent guide:\r\nhttps://nitishmutha.github.io/tensorflow/2017/01/22/TensorFlow-with-gpu-for-windows.html\r\nsolves my problem.", "Hi folks! We've posted a script that you can run, and it will give you some suggestions about how to fix your TensorFlow on Windows installation. It's available here:\r\n\r\nhttps://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c\r\n", "Hi Mrry,\r\n\r\ni am NOT using GPU version on windows 7.\r\nThen WHY am i getting these error related to CUDA??\r\n\r\nIs my system not compatible to run tensorflow??\r\nPlease update.\r\nawaiting ur respose..", "Hi Mrry,\r\n\r\ni am NOT using GPU version on windows 7.\r\nThen WHY am i getting these error related to CUDA??\r\n\r\nIs my system not compatible to run tensorflow??\r\nPlease update.\r\nawaiting ur respose..", "I have the same errorss as @nwertzberger . I also have these errors related to Anaconda that keep coming up during a Windows installation with the latest version of CUDA on Windows 10. From writing `source activate envname` because (`activate tensorflow-gpu` won't work) it prompts me with the other command, I get this trace: \r\n\r\n`Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Anaconda3\\Scripts\\conda-script.py\", line 5, in <module>\r\n    sys.exit(conda.cli.main())\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\cli\\main.py\", line 15                                  4, in main\r\n    activate.main()\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\cli\\activate.py\", lin                                  e 160, in main\r\n    prefix = prefix_from_arg(sys.argv[3], shelldict=shelldict)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\cli\\activate.py\", lin                                  e 60, in prefix_from_arg\r\n    prefix = locate_prefix_by_name(context, arg.replace('/', os.path.sep))\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\base\\context.py\", lin                                  e 538, in locate_prefix_by_name\r\n    raise CondaEnvironmentNotFoundError(name)\r\nconda.exceptions.CondaEnvironmentNotFoundError: Could not find environment: envn                                  ame .\r\nYou can list all discoverable environments with `conda info --envs`.\r\n`\r\n\r\nI get this trace when running in python shell `import tensorflow as tf`\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\XXXX\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\XXXX\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 47, in <module>\r\n    import numpy as np`\r\n\r\nThoughts on how to fix? I always seem to have problems with Anaconda, whether on Mac or PC. ", "@mrry any thoughts? It seems to be a common problem with the roaming Python error. I also tried using other pip installs to no avail: https://stackoverflow.com/questions/44991377/trouble-installing-tensorflow-on-windows-10-error-trace-related-to-anaconda", "Hi all,  I just want to thank this thread that save the day!  My env is Windows 10x64 with tensorflow-gpu version,  downgrading cuDNN from V6.0 to V5.1 did the job exactly!  I \r\n\r\n\r\n", "ile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow.py\", line 41, in \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 35, in \r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 30, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 242, in load\r\n_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 342, in load\r\n_dynamic\r\nreturn _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile \"\", line 1, in \r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_\r\ninit_.py\", line 24, in \r\nfrom tensorflow.python import *\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython_init_.py\", line 51, in \r\nfrom tensorflow.python import pywrap_tensorflow\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow.py\", line 52, in \r\nraise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow.py\", line 41, in \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 35, in \r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\p\r\nython\\pywrap_tensorflow_internal.py\", line 30, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 242, in load\r\n_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"C:\\Users\\xxx\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 342, in load\r\n_dynamic\r\nreturn _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_probl\r\nems\r\n\r\nfor some common reasons and solutions. Include the entire stack trace\r\nabove this error message when asking for help.", "@shivam04 Did you try running this script to diagnose common issues?\r\n\r\nhttps://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c\r\n\r\nIf it doesn't point to a solution, please open a new issue with the details!", "@mrry  hi \r\nafter installing the DLL file still im getting the error ", "I have installed Anaconda + tensor flow + CUDA on my system\r\n\r\nAnaconda version installed : Anaconda3-4.2.0-Windows-x86_64\r\ntensorflow for gpu is installed using pip install command.\r\nCuda version installed as: cuda_9.0.176_win10 and its patch is also installed\r\nThen files from cudnn like bin, include, lib copied to installation path\r\nThe graphics card is NVIDIA GeForce 820M\r\nbut when I run simple python scsript\r\nimport tensorflow as tf\r\nwith tf.device('/gpu:0'):\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\n\r\nwith tf.Session() as sess:\r\nprint (sess.run(c))\r\n\r\nThis error appears:\r\n\r\nrunfile('C:/Users/rituraj/Desktop/New folder/check.py', wdir='C:/Users/rituraj/Desktop/New folder')\r\nTraceback (most recent call last):\r\n\r\nFile \"\", line 1, in \r\nrunfile('C:/Users/rituraj/Desktop/New folder/check.py', wdir='C:/Users/rituraj/Desktop/New folder')\r\n\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 866, in runfile\r\nexecfile(filename, namespace)\r\n\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 102, in execfile\r\nexec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\nFile \"C:/Users/rituraj/Desktop/New folder/check.py\", line 17, in \r\nprint (sess.run(c))\r\n\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\r\nrun_metadata_ptr)\r\n\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\r\nfeed_dict_tensor, options, run_metadata)\r\n\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run\r\noptions, run_metadata)\r\n\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call\r\nraise type(e)(node_def, op, message)\r\n\r\nInvalidArgumentError: Cannot assign a device for operation 'MatMul_9': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n[[Node: MatMul_9 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_9, b_9)]]\r\n\r\nCaused by op 'MatMul_9', defined at:\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 223, in \r\nmain()\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 219, in main\r\nkernel.start()\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\r\nioloop.IOLoop.instance().start()\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\r\nsuper(ZMQIOLoop, self).start()\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\r\nhandler_func(fd_obj, events)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\r\nreturn fn(*args, **kwargs)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\r\nself._handle_recv()\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\r\nself._run_callback(callback, msg)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\r\ncallback(*args, **kwargs)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\r\nreturn fn(*args, **kwargs)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\r\nreturn self.dispatch_shell(stream, msg)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\r\nhandler(stream, idents, msg)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\r\nuser_expressions, allow_stdin)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\r\nres = shell.run_cell(code, store_history=store_history, silent=silent)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\r\nreturn super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\r\ninteractivity=interactivity, compiler=compiler, result=result)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2827, in run_ast_nodes\r\nif self.run_code(code, result):\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\r\nexec(code_obj, self.user_global_ns, self.user_ns)\r\nFile \"\", line 1, in \r\nrunfile('C:/Users/rituraj/Desktop/New folder/check.py', wdir='C:/Users/rituraj/Desktop/New folder')\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 866, in runfile\r\nexecfile(filename, namespace)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 102, in execfile\r\nexec(compile(f.read(), filename, 'exec'), namespace)\r\nFile \"C:/Users/rituraj/Desktop/New folder/check.py\", line 12, in \r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2022, in matmul\r\na, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2799, in _mat_mul\r\nname=name)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\nop_def=op_def)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\r\nop_def=op_def)\r\nFile \"C:\\Users\\rituraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in init\r\nself._traceback = self._graph._extract_stack() # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul_9': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\r\n[[Node: MatMul_9 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_9, b_9)]]\r\n\r\nIt is not detecting the gpu.\r\nPlease suggest solution for it.", "i had similar problem\r\n343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed with error code -1073741795\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nwhy if i use cpu tensor i need cuda etc?\r\nBy the way,i tryed to install cuda and cudnn and nothing changed"]}, {"number": 8160, "title": "Tensorflow more tutorial on java? ", "body": "Tensorflow more tutorial on java? I can run the introductory program, but that's far enough and i want to learn more\uff0cI do not understand python,Can provide more java tutorials? Sorry for my bad english!", "comments": ["What kind of tutorial you want to see? I'd like to contribute some.", "Thank you for your reply\uff0cI would like to learn image recognition model training and application, the use of java to identify the characters on the picture or animals, my request can be too much! Thanks again!", "would see what i can do", "I think the best one for java tutorial is that a mnist example by loading graph file which generated by python such as mnist_deep.py python file in mnist tutorials.\r\nand the tutorial verify the same test accuracy ( ex : 0.9921 ) between java and python approach. ", "Hi @youngho1203 \r\n\r\nThey already have a similar thing:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java\r\n", "Thanks for pointing that out @snnn.\r\n\r\n@oahzuw If you really want to build and train models, you'll have a much easier time _learning python_ and doing it there. The java API operates at a much lower level, enough to run an existing model, but you wouldn't want to work in it directly.\r\n\r\nIt looks like there's already a link to that `LabelImage.java` example on the [install/install_java](https://www.tensorflow.org/install/install_java) page. Does anyone have other suggestions on how to make it easier to find?", "@snnn   @MarkDaoust  @youngho1203   Thanks to everyone, decided to learn Python, too few examples of Java, thank you for your reply"]}, {"number": 8159, "title": "MNIST dataset usage issue", "body": "Hi,\r\nI am working with tensorflow to build a network using mnist data set but it is showing connection refused error.\r\n\r\n File \"neuralnw1.py\", line 4, in <module>\r\n    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)  # one-hot -> '2' = (0,0,1,0,0,0,0,0,0)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\", line 189, in read_data_sets\r\n    SOURCE_URL + TRAIN_IMAGES)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 157, in maybe_download\r\n    urllib.request.urlretrieve(source_url, temp_file_name)\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 186, in urlretrieve\r\n    with contextlib.closing(urlopen(url, data)) as fp:\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 161, in urlopen\r\n    return opener.open(url, data, timeout)\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 463, in open\r\n    response = self._open(req, data)\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 481, in _open\r\n    '_open', req)\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 441, in _call_chain\r\n    result = func(*args)\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 1210, in http_open\r\n    return self.do_open(http.client.HTTPConnection, req)\r\n  File \"/usr/lib/python3.4/urllib/request.py\", line 1184, in do_open\r\n    raise URLError(err)\r\nurllib.error.URLError: <urlopen error [Errno 111] Connection refused>\r\n\r\n", "comments": ["LeCun's website seems to be down at the moment, and the dataset is hosted over there. This probably explains the problem, although the error message doesn't say timeout.\r\n\r\nAnyway, in future issues you should post a minimal code to reproduce the problem, not only the stack trace \u2014 it would help us find what is wrong and you would get an answer faster. ;)", "Closed as duplicate of #8126"]}, {"number": 8158, "title": "error while loading shared libraries: __vdso_time: invalid mode for dlopen():Invalid argument", "body": "sorry to trouble you. I use Centos6.4 and CUDA7.0 and I have no \u2018sudo\u2019 authority. I install tensorflow from the source. After I installed glib2.17 and set LD_LIBRARY_PATH, I encountered the same error many people got:\r\n`error while loading shared libraries: __vdso_time: invalid mode for dlopen():Invalid argument`\r\n\r\nI try to search many solutions and there is still not a good or detailed solution. Can you give some detailed instructions. I think it will help many people. \r\nThankyou very much in advance!", "comments": ["See #2924 and #3285.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8157, "title": "Fix typo in map_fn docs", "body": "Typo was introduced in 9ca686593a3e0c69669c3f0d7f75c466d3041904 (248 days ago!).", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 8156, "title": "Add CI build for XLA", "body": "There's no continuous testing for XLA build, so that head can contain errors.\r\nRight now it's broken with syntax error, and this error has been there since Mar 2 or earlier -- https://github.com/tensorflow/tensorflow/pull/8039\r\n\r\nXLA got a lot of publicity at the TF summit, and there've been 90 issues filed on it, 5 of them connected to this breakage. Keeping head free of build errors for XLA build could ease the support burden on this list. @caisq @jhseu ", "comments": ["Sorry for the delays.\r\nThis is now complete.\r\nWe have builds running on github master, and also now running builds on all pull requests."]}, {"number": 8155, "title": "fix tf.Saver to tr.train.Saver after api changed", "body": "@caisq review this pr please", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins Test this please"]}, {"number": 8154, "title": "Error while tf.image.crop_and_resize ", "body": "I am trying to crop and resize an image with a list of co-ordinates using tf.image.crop_and_resize() \r\nbut am getting the following error:\r\n### TypeError: Expected binary or unicode string, got 960, \r\nBelow is the code which I am using\r\n\r\n```python\r\nori_image = Image.open('/home/sumith/imagepyramids/1.jpg')\r\nimg_data = np.asarray(ori_image)\r\nwith tf.Session() as sess:\r\n  sess.run(init)\r\n  im_string = sess.run(tf.image.encode_jpeg(img_data, format=\"rgb\"))\r\n  img_data_tensor = [im_string, img_data.shape[0], img_data.shape[1], 3]\r\n  cropped_list = sess.run(tf.image.crop_and_resize(image=img_data_tensor, boxes=extracted_data,\r\n                                                   crop_size=[40, 36], box_ind=[20]))\r\n```\r\n\r\nand I am getting the above said error. The complete stack trace is given below.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/sumith/PycharmProjects/fddb/tryouts_3.py\", line 87, in <module>\r\n    crop_size=[40, 36], box_ind=[20]))\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_image_ops.py\", line 151, in crop_and_resize\r\n    name=name)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 493, in apply_op\r\n    raise err\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 490, in apply_op\r\n    preferred_dtype=default_dtype)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 165, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 441, in make_tensor_proto\r\n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 441, in <listcomp>\r\n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/util/compat.py\", line 65, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got 960\r\n```\r\n\r\nI am passing a string returned by tf.image.encode_jpeg still it is not working. Can I get any help ? ", "comments": ["I tried passing the UnicodeString  `ori_image.tobytes().decode('utf-8')` in place of im_string, Still getting the same error", "EDIT : removed bad solution, I misinterpreted the problem.", "I am getting error \r\n\r\n**ValueError: could not convert string to float**: **b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01,\\x01,\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x01\\x01\\x01\\x01\\x02\\x01\\x01\\x01\\x02**\r\n\r\nsince im_string is datatype of str and numpy do not allow non numerical data types.", "I didn't pay much attention to your construction of the `image` parameter, it seems you misinterpreted the docs: the `image` parameter is of shape `[batch, image_height, image_width, depth]` \u2014 that doesn't mean it should have the values of `image_height`, `image_width` and `depth` inside of it, the doc is only explaining its shape \u2014 meaning: it has the shape of an image, with the first index referring to the batch position (4D instead of 3D). Since you seem to be processing a single image, we can simply add a dimension to the beginning of the tensor. Here is a working example:\r\n\r\n```\r\nori_image = Image.open('/home/sumith/imagepyramids/1.jpg')\r\nimg_data = np.expand_dims(np.asarray(ori_image).astype(np.float32), axis=0)\r\nsess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\r\ncropped_list = sess.run(tf.image.crop_and_resize(image=img_data, boxes=[[.1,.1,.6,.6]], crop_size=[40, 36], box_ind=[0]))\r\n```", "the code snippet you gave works like charm!! . But is giving error when more than one box is passed in the boxes list \r\n` cropped_list = sess.run(\r\n        tf.image.crop_and_resize(image=img_data, boxes=[[1, 1, 6, 6],[1, 1, 6, 6]], crop_size=[40, 36], box_ind=[0]))`\r\nError is\r\n**ValueError: Dimensions must be equal, but are 2 and 1 for 'CropAndResize' (op: 'CropAndResize') with input shapes: [1,480,640,3], [2,4], [1], [2].**\r\n\r\nCan you suggest where the error is, is it because of the batch size is 1 in img_data array ? Thanks for your help.", "You didn't update the parameter `box_ind`:\r\n> box_ind: A Tensor of type int32. A 1-D tensor of shape [num_boxes] with int32 values in [0, batch). The value of box_ind[i] specifies the image that the i-th box refers to.\r\n\r\nIn your case, you have 2 boxes, so it should be of size 2 as well. For a single image, this will be a vector of zeroes with the same size as dimension 1 of `boxes` (i.e. [0,0]).", "Note for future reference: This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!", "Closing since there doesn't seem to be a bug here.", "Thanks a lot for your help !!"]}, {"number": 8153, "title": "Mkl bfc allocator and static memory allocator registry", "body": "Pull request for\r\n1) Static Registry of CPU Memory Allocators that can be queried to return the highest priority allocator\r\n2) A BFC-based memory allocator that MKL backends can use to request memory from", "comments": ["Can one of the admins verify this patch?", "Looks good after the small nit-pick changes I suggested above.", "@tensorflow-jenkins test this please", "@tensorflow-jenkins Test this please", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 8152, "title": "Error when calling tf.train.Save()", "body": "```\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_1 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_2 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_7 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_3 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_5 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_4 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable_6 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key q_network/Variable not found in checkpoint\r\nTraceback (most recent call last):\r\n  File \"AI_control_4layer.py\", line 191, in <module>\r\n    restore_net(sess,path)\r\n  File \"AI_control_4layer.py\", line 108, in restore_net\r\n    saver.restore(sess, path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1439, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key q_network/Variable_1 not found in checkpoint\r\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\r\n\r\nCaused by op u'save/RestoreV2_1', defined at:\r\n  File \"AI_control_4layer.py\", line 191, in <module>\r\n    restore_net(sess,path)\r\n  File \"AI_control_4layer.py\", line 107, in restore_net\r\n    saver = tf.train.Saver()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1081, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 675, in build\r\n    restore_sequentially, reshape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 402, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 242, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 668, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Key q_network/Variable_1 not found in checkpoint\r\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\r\n```\r\n\r\nHow can I solve it?", "comments": ["Please follow guidelines for posting issues, or at least enclose your _things_ in code/quote/etc formatting.\r\n\r\nYour problem is probably related to variables in your graph that didn't exist when you saved your checkpoint, meaning they can't be loaded because they weren't there before.", "As @MicaelCarvalho says, please can you try deleting your checkpoint.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8151, "title": "Calling Generic conv with data_format='NCHW' Leads to Segfault", "body": "Running on 1.0.0.2 Docker image, this code:\r\n```python\r\n\r\nfrom tensorflow.python.ops import nn_ops\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nimages = np.ones((1,1,15,1)).astype(np.float32)\r\nfilters = 1 * np.ones((1,1,1,1), np.float32)\r\n\r\nwith tf.Session(''):\r\n  output = nn_ops.conv2d(\r\n      images,\r\n      filters,\r\n      strides=[1,1,1,1],\r\n      padding='VALID',\r\n      data_format='NCHW',\r\n  ).eval()\r\n```\r\nyields:\r\n```\r\nF tensorflow/core/kernels/conv_ops.cc:65] Check failed: data_format == FORMAT_NHWC Generic conv implementation only supports NHWC te\r\nnsor format for now.\r\nAborted (core dumped)\r\n```\r\nWhile it does print a helpful error message, it then proceeds to core dump.\r\n\r\nI also see this issue on macOS", "comments": ["@zheng-xq This probably shouldn't have a CHECK fail?  Is there no way it could raise an error via the OpKernel constructor?   (e.g. so interactive usage doesn't take out the runtime!)", "Yes, we can change that to a python error. cancan101, does that solve your problem? \r\n\r\nThe underlying issue is that we don't have fast CPU conv implementation of NCHW format. This is an area that is contribution-welcome. ", "Yes that would solve my problem.", "I think a warning on first use and a non-fatal error would seem more appropriate.", "@cancan101 For tensorflow 1.2.0-rc2 it gives this error:\r\nUnimplementedError: Generic conv implementation only supports NHWC tensor format for now.\r\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Conv2D/input, Conv2D/filter)]]\r\n\r\nClose for now because I think this solves your problem, if not, please reopen.", "i get this error for my code  can somebody help?\r\nerror\r\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_Placeholder_0_0, weights/read)]]\r\n\r\n#from tensorflow.python.client import device_lib\r\n#print(device_lib.list_local_devices())\r\n\r\nimport os\r\nimport time\r\nimport math\r\nimport numpy as np\r\nimport tensorflow as tf\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n\r\n# Load the CIFAR10 dataset\r\nfrom keras.datasets import cifar10\r\nbaseDir = os.path.dirname(os.path.abspath('__file__')) + '/'\r\nclassesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n\r\n\r\n# Select device\r\ndeviceType = \"/cpu:0\"\r\n\r\n\r\n#def train():\r\n(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\r\nxVal = xTrain[49000:, :].astype( np.float )\r\nyVal = np.squeeze( yTrain[49000:, :] )\r\nxTrain = xTrain[:49000, :].astype( np.float )\r\nyTrain = np.squeeze( yTrain[:49000, :] )\r\nyTest = np.squeeze( yTest )\r\nxTest = xTest.astype( np.float )\r\nprint( 'Train image shape:    {0}'.format( xTrain.shape ) )\r\nprint( 'Train label shape:    {0}'.format( yTrain.shape ) )\r\nprint( 'Validate image shape: {0}'.format( xVal.shape ) )\r\nprint( 'Validate label shape: {0}'.format( yVal.shape ) )\r\nprint( 'Test image shape:     {0}'.format( xTest.shape ) )\r\nprint( 'Test label shape:     {0}'.format( yTest.shape ) )\r\n\r\nbatch_size = 100\r\nlearning_rate = 0.0000006\r\nmax_steps = 1100\r\n\r\nmeanImage = np.mean( xTrain, axis=0 )\r\nxTrain -= meanImage\r\nxVal -= meanImage\r\nxTest -= meanImage\r\ntf.reset_default_graph()\r\nwith tf.device( deviceType ):\r\n    x = tf.placeholder( tf.float32, [None, 32,32,3] )\r\n    y= tf.placeholder( tf.int64, [None] )\r\n    filter = tf.get_variable( 'weights', [7, 7, 3, 64],initializer=tf.truncated_normal_initializer( stddev=5e-2, dtype=tf.float32 ),\r\n                              dtype=tf.float32 )\r\n\r\n    conv1 = tf.nn.conv2d(x, filter, strides=[1,1,1,1], padding=\"SAME\") # Stride [batch, height, width, channels]\r\n    conv1=tf.nn.relu(conv1)\r\n    conv1 = tf.layers.max_pooling2d( conv1, 2, 2 )\r\n    fc1 = tf.contrib.layers.flatten( conv1 )\r\n    fc1 = tf.layers.dense( fc1, 1024 )\r\n    fc1 = tf.nn.relu( fc1 )\r\n    yOut = tf.layers.dense( fc1, 10 )\r\n\r\n    # Define Loss\r\n    totalLoss = tf.losses.hinge_loss( tf.one_hot( y, 10 ), logits=yOut )\r\n    meanLoss = tf.reduce_mean( totalLoss )\r\n\r\n    # Define Optimizer\r\n    optimizer = tf.train.AdamOptimizer( 5e-4 )\r\n    trainStep = optimizer.minimize( meanLoss )\r\n\r\n    # Define correct Prediction and accuracy\r\n    correctPrediction = tf.equal( tf.argmax( yOut, 1 ), y )\r\n    accuracy = tf.reduce_mean( tf.cast( correctPrediction, tf.float32 ) )\r\n    lossHistory=[]\r\n\r\n    with tf.Session()as sess:\r\n        sess.run( tf.global_variables_initializer() )\r\n        for i in range( max_steps):\r\n\r\n            s = np.arange( xTrain.shape[0] )\r\n            np.random.shuffle( s )\r\n            xTr = xTrain[s]\r\n            yTr = yTrain[s]\r\n            batch_xs = xTr[:100]\r\n            batch_ys = yTr[:100]\r\n            main_loss, _ = sess.run( [meanLoss, trainStep],\r\n                                     feed_dict=({x: batch_xs, y: batch_ys}) )\r\n            train_accuracy = sess.run( accuracy, feed_dict={x: xTrain, y: yTrain} )\r\n            test_accuracy = sess.run( accuracy, feed_dict={x: xTest, y: yTest} )\r\n\r\n            lossHistory.append( main_loss )\r\n            if i % 100 == 0 and len( lossHistory ) is not 0:\r\n                print( 'Loop {0} loss {1} '.format( i, lossHistory[i] ) )\r\n                print( 'Train_Accuracy {0} Test_Accuracy {1}'.format( train_accuracy, test_accuracy ) )\r\n\r\n# Train Model\r\n\r\n                # def train():\r\n#     (xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\r\n#     xVal = xTrain[49000:, :].astype( np.float )\r\n#     yVal = np.squeeze( yTrain[49000:, :] )\r\n#     xTrain = xTrain[:49000, :].astype( np.float )\r\n#     yTrain = np.squeeze( yTrain[:49000, :] )\r\n#     yTest = np.squeeze( yTest )\r\n#     xTest = xTest.astype( np.float )\r\n\r\n    # batch_size = 10\r\n    # learning_rate = 0.0000006\r\n    # max_steps = 1100\r\n    # print( 'Train image shape:    {0}'.format( xTrain.shape ) )\r\n    # print( 'Train label shape:    {0}'.format( yTrain.shape ) )\r\n    # print( 'Validate image shape: {0}'.format( xVal.shape ) )\r\n    # print( 'Validate label shape: {0}'.format( yVal.shape ) )\r\n    # print( 'Test image shape:     {0}'.format( xTest.shape ) )\r\n    # print( 'Test label shape:     {0}'.format( yTest.shape ) )\r\n    #\r\n    # meanImage = np.mean( xTrain, axis=0 )\r\n    # xTrain -= meanImage\r\n    # xVal -= meanImage\r\n    # xTest -= meanImage\r\n\r\n#     # Reshape data from channel to rows\r\n#     xTrain = np.reshape( xTrain, (xTrain.shape[0], -1) )\r\n#     xVal = np.reshape( xVal, (xVal.shape[0], -1) )\r\n#     xTest = np.reshape( xTest, (xTest.shape[0], -1) )\r\n#\r\n#     # Add bias dimension columns\r\n#\r\n#     print( 'Train image shape after add bias column:   {0}'.format( xTrain.shape ) )\r\n#     print( 'Val image shape after add bias column:     {0}'.format( xVal.shape ) )\r\n#     print( 'Test image shape after add bias column:    {0}'.format( xTest.shape ) )\r\n#\r\n#     image_holder = tf.placeholder( tf.float32, shape=[None, 3072] )\r\n#\r\n#     #label_holder = tf.placeholder( tf.int64, shape=[None] )\r\n#     label_holder=tf.placeholder(tf.int64, [None])\r\n#\r\n#     weight = tf.Variable( tf.zeros( [3072, 10] ), name='weights' )\r\n#     bias = tf.Variable( tf.zeros( [10] ), name='bias' )\r\n#\r\n#     # Define the classifier's result\r\n#     logits = tf.matmul( image_holder, weight ) + bias\r\n#\r\n#     loss = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits( logits=logits,\r\n#                                                                            labels=label_holder ) )\r\n#\r\n#     # Define the training operation\r\n#     train_step = tf.train.GradientDescentOptimizer( learning_rate ).minimize( loss )\r\n#\r\n#     lossHistory = []\r\n#     correct_prediction = tf.equal( tf.argmax( logits, 1 ), label_holder )\r\n#\r\n#     # Operation calculating the accuracy of our predictions\r\n#     accuracy = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )\r\n    #saver = tf.train.Saver()\r\n\r\n\r\n        # cwd = os.getcwd()\r\n        # saver_route = saver.save( sess, cwd + \"/model/model.ckpt\" )\r\n        # print( \"Model saved in this directory: %s\" % saver_route )\r\n        #pass\r\n\r\n\r\n# print ('Real label is:', np.argmax(yTest[num]))\r\n# print ('Neural Network predicted', (classification[0]))\r\n# import string\r\n#\r\n#\r\n# def test(args):\r\n#     classnames = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n#\r\n#     image_holder = tf.placeholder( tf.float32, shape=[None, 3072] )\r\n#     img = cv2.imread( args )\r\n#     print (img.shape)\r\n#\r\n#     img = img.reshape( (1, img.shape[0] * img.shape[1] * img.shape[2]) )\r\n#     #img = img.reshape (1,3072)\r\n#     print (img)\r\n#\r\n#     img = cv2.resize( img, (3072, 1) )\r\n#     #print (img.shape)\r\n#     img = img.astype( np.float32 )\r\n#     print (img)\r\n#     cwd = os.getcwd()\r\n#\r\n#     with tf.Session() as sess:\r\n#         model = tf.train.import_meta_graph( cwd + \"/model/model.ckpt.meta\", clear_devices=True )\r\n#         model.restore( sess, tf.train.latest_checkpoint( cwd + \"/model/\" ) )\r\n#         weight = sess.run( 'weights:0' )\r\n#\r\n#         bias = sess.run( 'bias:0' )\r\n#         logits = tf.matmul( image_holder, weight ) + bias\r\n#         prediction = tf.nn.softmax( logits )\r\n#\r\n#         answer= sess.run( prediction, feed_dict={image_holder: img} )\r\n#         print (answer.shape)\r\n#         print (answer)\r\n#\r\n#         answer = answer.reshape(-1)\r\n#         print (answer.shape)\r\n#         print(answer)\r\n#\r\n#         score= answer.argmax(axis=0)\r\n#         print(score)\r\n#\r\n#         print( classnames[score] )\r\n#         pass\r\n#\r\n#\r\n# def main(argv):\r\n#     if str( argv[0] ) == 'train':\r\n#         train()\r\n#         return\r\n#\r\n#     if str( argv[0] ) == 'test':\r\n#         test( str( argv[1] ) )\r\n#\r\n#\r\n#\r\n#\r\n#\r\n# if __name__ == '__main__':\r\n#     main( sys.argv[1:] )\r\n#\r\n#\r\n", "I have encountered the same error. Im using a CPU not GPU. So I changed the data format of the tensors to overcome in the code.Above Suggested solutions will not work for CPU. \r\nMore can be found in tensorflow documentation. Refer to  data formats\r\nhttps://www.tensorflow.org/guide/performance/overview"]}, {"number": 8150, "title": "Two different user_ops directories", "body": "There are currently two different directories labeled `user_ops`, each with example(s):\r\n* https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/user_ops\r\n* https://github.com/tensorflow/tensorflow/tree/master/tensorflow/user_ops\r\n\r\nIs this intentional or vestigial?\r\n\r\nMight reduce confusion to merge these.", "comments": ["The one in `tensorflow/user_ops` is demonstrating user defined ops built with `tf_custom_op_library`, i.e., when you build custom operations with TF binary installed, the one in `tensorflow/core/user_ops` is demonstrating how you can build user ops with TF sources.", "I'm not sure I 100% understand the distinction here. At the very least maybe a Readme file in the respective directories? That being said I would think the same example should appear in both unless there is a reason to use fact in one case and Ackerman in the other? "]}]