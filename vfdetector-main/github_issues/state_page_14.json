[{"number": 53414, "title": "[TF:TRT] Use the third_party TRT-OSS plugin for CombinedNMS", "body": "This now implements the plugin built locally via the third_party TRT OSS dependency for CombinedNMS.\r\n- Remove the legacy BatchedNMS plugin converter, and replace it entirely with the new EfficientNMS plugin converter.\r\n- Add implicit batch mode support for EfficientNMS.\r\n- Update the commit of the third_party TRT-OSS archive to the 22.02 release, as this includes some plugin updates required for CombinedNMS compatibility.\r\n- Improved the integration test for CombinedNMS for better coverage and representation of the plugin's behavior.", "comments": ["CC: @bixia1 ", "Are you table to split \"TRT-OSS archive to the TRT 8.2 GA release\" into another PR that goes either before or after this PR? Within google, we have a \"hard copy\" of the open source code, so we will need to do something manual to sync with the OSS archive update. Can we discuss this on our Wednesday meeting tomorrow?", "I'm upstreaming the implicit batch mode plugin to OSS instead as it allows the code in TFTRT to be better organized, and we can keep all internal plugin logic away from here which is cleaner as well. \r\nI'll update the archive commit when the update is downloadable.", "@bixia1 I've added the commit id for the recently published plugin update.\r\n\r\nQuestion: I see that commit 5bbc5001dda63a83ce1cfd94dfb2cd8293c24d6e added a flag required to build the plugin: `--define=use_efficient_nms_plugin=1`. Is this still needed? And if so, what is the expected behavior when the flag is not set? As this PR removes the old implementation of CombinedNMS for TFTRT.", "> @bixia1 I've added the commit id for the recently published plugin update.\r\n> \r\n> Question: I see that commit [5bbc500](https://github.com/tensorflow/tensorflow/commit/5bbc5001dda63a83ce1cfd94dfb2cd8293c24d6e) added a flag required to build the plugin: `--define=use_efficient_nms_plugin=1`. Is this still needed? And if so, what is the expected behavior when the flag is not set? As this PR removes the old implementation of CombinedNMS for TFTRT.\r\n\r\nThe define is needed when we support both and the default doesn't use the plugin. Your PR should remove this define then.", "> The define is needed when we support both and the default doesn't use the plugin. Your PR should remove this define then.\r\n\r\nOk all good now, no build flag anymore, and everything works as expected now.\r\n", "Merge conflict resolved + all commits squashed (+ PyLint check fix).", "Moved the relevant PRs from description to here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/52683\r\nhttps://github.com/tensorflow/tensorflow/pull/52967", "@bixia1 I had to resolve another merge conflict that came up in the last few days. Does the PR need to be re-approved?", "@wraveane Can you please resolve conflicts? Thanks!", "> @wraveane Can you please resolve conflicts? Thanks!\r\n\r\nYes, it's in progress. Working towards a solution to resolve the failing CI tests.", "@wraveane Any update on this PR? Please. Thank you!", "@wraveane Any update on this PR? Please. Thank you!", "Still in progress. I will mark this one as draft, but most likely it will end up closed and a new one will be made with the refactored converters."]}, {"number": 53413, "title": "TF_SessionRun() from C API crashes when not enough RAM", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Microsoft Windows 10 Enterprise, version: 10.0.18363 N/A Build 18363\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.\r\n- TensorFlow installed from (source or binary): https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.4.0.zip\r\n- TensorFlow version (use command below): bug is tested and reproducible with tensorflow C API of versions: 2.4.0, 2.7.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: used CPU\r\n- GPU model and memory: used CPU\r\n\r\n**Describe the current behavior**\r\nI'm using tensorflow C API in my C++ code. I'm using microsoft visual studio 2019 (compiler version - msvc 14.26).\r\nWhen there's not enough memory, TF_SessionRun() crashes. Visual Studio debugger shows that TF_SessionRun() throws std::bad_alloc.  If I debug code and place break immediately before executing TF_SessionRun() and immediately after it, after executing TF_SessionRun()  I get the following exception message in Debugger\r\n\"Exception thrown at 0x00007FFB9F7EA859 in MyProject.exe: Microsoft C++ exception: std::bad_alloc at memory location 0x000000F789CFD580\"\r\nAnd here's the callstack from where the exception is thrown.\r\n  \t[External Code]\t\r\n>\tvcruntime140.dll!00007ffb85ba6480()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb108e335f()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb10863eaf()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb108641b3()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb1086c119()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb10866624()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb1432f562()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb1433d9fa()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb1433c248()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb14343589()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb16b2860b()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb16b26531()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb17117799()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb17117c31()\tUnknown\r\n \ttensorflow-2.4.0.dll!00007ffb17111128()\tUnknown\r\n \tucrtbase.dll!thread_start<unsigned int (__cdecl*)(void *),1>()\tUnknown\r\n \tkernel32.dll!BaseThreadInitThunk\u001e()\tUnknown\r\n \tntdll.dll!RtlUserThreadStart\u001e()\tUnknown\r\n\r\nAnd the worst thing is that I cannot wrap this call to TF_SessionRun() in try-catch, because the compiler optimizes it away, since we are calling C code, and C code isn't allowed to throw exceptions. But even if could be caught, it is technically undefined behavior, and I cannot rely on catching exceptions from tensorflow.dll, because 1) it was built with a different compiler 2) it is C API, it should not throw anything.\r\n\r\nI attached files.zip, which contains main.cpp file that reproduces the problem. It reads neural network protobuf (.pb) file and tries to run it. Script, that generated neural network, and the neural network itself are also inside files.zip\r\n\r\nOn line 11 of main.cpp there is variable SIZE (const size_t SIZE = 500;) On my machine TF_SessionRun() crashes when SIZE is around 500. It can vary from machine to machine, try different values to reproduce the problem on your machine.\r\n\r\nSo, the problem is that if SIZE is sufficiently big, a call to TF_SessionRun() on line 63 crashes, and we do not reach the code below TF_SessionRun() that would print either \"FINISHED SUCCESSFULLY\" or \"FINISHED WITH ERROR\".\r\n(But if SIZE is sufficiently small, it successfully finishes and prints \"FINISHED SUCCESSFULLY\")\r\n\r\n**Describe the expected behavior**\r\nIf there's not enough memory, TF_SessionRun() should return error code via TF_Status*, and it should not crash. \r\nIf we reached call to TF_SessionRun() in main.cpp, then after the call it should print either \"FINISHED SUCCESSFULLY\" or \"FINISHED WITH ERROR\"\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nI attached an archive - files.zip. It contains 3 files:\r\nmain.cpp - C++ code that reproduces the problem\r\nfrozen_graph.pb - neural network protobuf file, that is used inside main.cpp\r\ngenerate_graph.py - script, that generates frozen_graph.pb\r\n\r\nI think you can reproduce this bug (where TF_SessionRun() crashes because there isn't enough RAM) with any sufficiently complex neural network, that consumes lots of RAM. I actually encountered this bug with a different neural network, I cannot share it with you, because it is not my Intellectual Property.\r\n\r\n[files.zip](https://github.com/tensorflow/tensorflow/files/7707904/files.zip)\r\n\r\n", "comments": ["is anyone working on this issue?", "The same crash exception in my project. I used C_API of Tensorflow 2.4.0.\r\nThe flowing is the callstack in the dump file:\r\n\r\n>  \t \r\n        Idemera.exe!crashpad::CrashpadClient::DumpAndCrashTargetProcess(void *,void *,unsigned long)\t\r\n \tucrtbase.dll!raise\u001e()\t\r\n \tucrtbase.dll!abort\u001e()\t\r\n \tucrtbase.dll!terminate\u001e()\t\r\n\tVCRUNTIME140_1.dll!FindHandler<__FrameHandler4>(EHExceptionRecord * pExcept=0x000000ea62cfd460, unsigned __int64 * pRN=0x000000ea62cfc490, _CONTEXT * pContext=0x000000ea62cfcc10, _xDISPATCHER_CONTEXT * pDC=0x000000ea62cfca50, FH4::FuncInfo4 * pFuncInfo=0x000000ea62cfc460, unsigned char recursive='\\0', int CatchDepth=0, unsigned __int64 * pMarkerRN=0x0000000000000000) line 682\tC++\r\n \tVCRUNTIME140_1.dll!__InternalCxxFrameHandler<__FrameHandler4>(EHExceptionRecord * pExcept=0x000000ea62cfd460, unsigned __int64 * pRN=0x000000ea62cfc490, _CONTEXT * pContext=0x000000ea62cfcc10, _xDISPATCHER_CONTEXT * pDC=0x000000ea62cfca50, FH4::FuncInfo4 * pFuncInfo=0x000000ea62cfc460, int CatchDepth=0, unsigned __int64 * pMarkerRN=0x0000000000000000, unsigned char recursive='\\0') line 352\tC++\r\n \tVCRUNTIME140_1.dll!__CxxFrameHandler4(EHExceptionRecord * pExcept=0x000000ea62cfd460, unsigned __int64 RN, _CONTEXT * pContext=0x000000ea62cfcc10, _xDISPATCHER_CONTEXT * pDC=0x000000ea62cfca50) line 290\tC++\r\n \tntdll.dll!RtlpExecuteHandlerForException\u001e()\t\r\n \tntdll.dll!RtlDispatchException()\t\r\n \tntdll.dll!RtlRaiseException\u001e()\t\r\n \tKERNELBASE.dll!RaiseException\u001e()\t\r\n \tVCRUNTIME140.dll!_CxxThrowException(void * pExceptionObject=0x000000ea62cfd5b0, const _s__ThrowInfo * pThrowInfo) line 133\tC++\r\n \ttensorflow.dll!Eigen::internal::throw_std_bad_alloc(void)\tC++\r\n \ttensorflow.dll!Eigen::internal::TensorContractionBlockMemAllocator<int,int>::allocateSlices<struct Eigen::ThreadPoolDevice const >(struct Eigen::ThreadPoolDevice const &,__int64,__int64,__int64,__int64,__int64,__int64,class std::vector<int *,class std::allocator<int *> > *,class std::vector<int *,class std::allocator<int *> > *)\tC++\r\n \ttensorflow.dll!Eigen::internal::TensorContractionKernel<float,float,float,__int64,class Eigen::internal::blas_data_mapper<float,__int64,0,0,1>,class Eigen::internal::TensorContractionInputMapper<float,__int64,1,struct Eigen::TensorEvaluator<class Eigen::Tensor<float,2,1,__int64> const ,struct Eigen::ThreadPoolDevice>,class Eigen::array<__int64,1>,class Eigen::array<__int64,1>,8,1,0,0,struct Eigen::MakePointer>,class Eigen::internal::TensorContractionInputMapper<float,__int64,0,struct Eigen::TensorEvaluator<class Eigen::TensorCwiseUnaryOp<struct Eigen::internal::scalar_square_op<float const >,class Eigen::TensorMap<class Eigen::Tensor<float const ,2,1,__int64>,16,struct Eigen::MakePointer> const > const ,struct Eigen::ThreadPoolDevice>,class Eigen::array<__int64,1>,class Eigen::array<__int64,1>,8,1,1,0,struct Eigen::MakePointer> >::allocateSlices<struct Eigen::ThreadPoolDevice const >(struct Eigen::ThreadPoolDevice const &,int,int,int,class std::vector<struct Eigen::internal::ColMajorBlock<float,__int64>,class std::allocato\tC++\r\n \ttensorflow.dll!Eigen::TensorEvaluator<class Eigen::TensorContractionOp<class Eigen::array<struct Eigen::IndexPair<__int64>,1> const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorImagePatchOp<-1,-1,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const > const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const ,struct tensorflow::LaunchFusedConv2DWithOutputKernel<float>::OutputKernelWrapper const > const ,struct Eigen::ThreadPoolDevice>::EvalParallelContext<struct Eigen::TensorEvaluator<class Eigen::TensorContractionOp<class Eigen::array<struct Eigen::IndexPair<__int64>,1> const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorImagePatchOp<-1,-1,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > co\u001e()\tC++\r\n \ttensorflow.dll!Eigen::TensorEvaluator<class Eigen::TensorContractionOp<class Eigen::array<struct Eigen::IndexPair<__int64>,1> const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorImagePatchOp<-1,-1,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const > const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const ,struct tensorflow::LaunchFusedConv2DWithOutputKernel<float>::OutputKernelWrapper const > const ,struct Eigen::ThreadPoolDevice>::evalProductImpl<struct Eigen::TensorEvaluator<class Eigen::TensorContractionOp<class Eigen::array<struct Eigen::IndexPair<__int64>,1> const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorImagePatchOp<-1,-1,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const \u001e()\tC++\r\n \ttensorflow.dll!Eigen::internal::TensorExecutor<class Eigen::TensorAssignOp<class Eigen::TensorMap<class Eigen::Tensor<float,4,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,4> const ,class Eigen::TensorContractionOp<class Eigen::array<struct Eigen::IndexPair<__int64>,1> const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorImagePatchOp<-1,-1,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const > const ,class Eigen::TensorReshapingOp<struct Eigen::DSizes<__int64,2> const ,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer> const > const ,struct tensorflow::LaunchFusedConv2DWithOutputKernel<float>::OutputKernelWrapper const > const > const > const ,struct Eigen::ThreadPoolDevice,1,0>::run(class Eigen::TensorAssignOp<class Eigen::TensorMap<class Eigen::Tensor<float,4,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::Tensor\tC++\r\n \ttensorflow.dll!tensorflow::LaunchFusedConv2DWithOutputKernel<float>::operator()<struct tensorflow::BiasAddOutputKernel<float,struct tensorflow::LeakyRelu> >(struct tensorflow::BiasAddOutputKernel<float,struct tensorflow::LeakyRelu> const &,class tensorflow::OpKernelContext *,class tensorflow::Tensor const &,class tensorflow::Tensor const &,class tensorflow::Tensor *)\tC++\r\n \ttensorflow.dll!tensorflow::LaunchFusedConv2DOp<struct Eigen::ThreadPoolDevice,float>::operator()(class tensorflow::OpKernelContext *,bool,bool,class tensorflow::Tensor const &,class tensorflow::Tensor const &,enum tensorflow::FusedComputationType,struct tensorflow::FusedComputationArgs const &,struct tensorflow::Conv2DParameters const &,struct tensorflow::Conv2DDimensions const &,class tensorflow::Tensor *)\tC++\r\n \ttensorflow.dll!tensorflow::FusedConv2DOp<struct Eigen::ThreadPoolDevice,float>::Compute(class tensorflow::OpKernelContext *)\tC++\r\n \ttensorflow.dll!tensorflow::NewLocalExecutor(struct tensorflow::LocalExecutorParams const &,class tensorflow::Graph const &,class tensorflow::Executor * *)\tC++\r\n \ttensorflow.dll!tensorflow::NewLocalExecutor(struct tensorflow::LocalExecutorParams const &,class tensorflow::Graph const &,class tensorflow::Executor * *)\tC++\r\n \ttensorflow.dll!Eigen::ThreadPoolTempl<struct tensorflow::thread::EigenEnvironment>::WorkerLoop(int)\tC++\r\n \ttensorflow.dll!std::_Func_impl_no_alloc<class <lambda_fe7aa395b13fe170862dcdb4d85eb030>,void>::_Do_call(void)\tC++\r\n \ttensorflow.dll!std::thread::_Invoke<class std::tuple<class std::function<void > >,0>(void *)\tC++\r\n \tucrtbase.dll!thread_start<unsigned int (__cdecl*)(void *),1>()\t\r\n \tKERNEL32.DLL!BaseThreadInitThunk\u001e()\t\r\n \tntdll.dll!RtlUserThreadStart\u001e()\t\r\n\r\n\r\nThe next callstack is from the calling method in the same dump file:\r\n\r\n> \r\n \tntdll.dll!NtWaitForAlertByThreadId\u001e()\t\r\n\tntdll.dll!RtlSleepConditionVariableSRW()\t\r\n \tKERNELBASE.dll!SleepConditionVariableSRW\u001e()\t\r\n \tMSVCP140.dll!__crtSleepConditionVariableSRW(_RTL_CONDITION_VARIABLE * pCond, _RTL_SRWLOCK * pLock, unsigned long dwMs, unsigned long flags) line 659\tC++\r\n \t[\u5185\u8054\u6846\u67b6] MSVCP140.dll!Concurrency::details::stl_condition_variable_win7::wait_for(Concurrency::details::stl_critical_section_interface *) line 216\tC++\r\n \tMSVCP140.dll!Concurrency::details::stl_condition_variable_win7::wait(Concurrency::details::stl_critical_section_interface * lock) line 210\tC++\r\n \tMSVCP140.dll!do_wait(_Cnd_internal_imp_t * cond=0x00000253c8db76c8, _Mtx_internal_imp_t * mtx=0x00000253c8db7678, const xtime * target=0x0000000000000000) line 77\tC++\r\n \ttensorflow.dll!nsync::nsync_mu_semaphore_p_with_deadline(struct nsync::nsync_semaphore_s_ *,struct timespec)\tC++\r\n \ttensorflow.dll!nsync::nsync_sem_wait_with_cancel_(struct nsync::waiter *,struct timespec,struct nsync::nsync_note_s_ *)\tC++\r\n \ttensorflow.dll!nsync::nsync_cv_wait_with_deadline_generic(struct nsync::nsync_cv_s_ *,void *,void (*)(void *),void (*)(void *),struct timespec,struct nsync::nsync_note_s_ *)\tC++\r\n \ttensorflow.dll!nsync::nsync_cv_wait(struct nsync::nsync_cv_s_ *,struct nsync::nsync_mu_s_ *)\tC++\r\n \ttensorflow.dll!tensorflow::Executor::Run(struct tensorflow::Executor::Args const &)\tC++\r\n \ttensorflow.dll!tensorflow::DirectSession::RunInternal(__int64,class tensorflow::RunOptions const &,class tensorflow::CallFrameInterface *,struct tensorflow::DirectSession::ExecutorsAndKeys *,class tensorflow::RunMetadata *,struct tensorflow::thread::ThreadPoolOptions const &)\tC++\r\n \ttensorflow.dll!tensorflow::DirectSession::Run(class tensorflow::RunOptions const &,class std::vector<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class tensorflow::Tensor>,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class tensorflow::Tensor> > > const &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,class std::vector<class tensorflow::Tensor,class std::allocator<class tensorflow::Tensor> > *,class tensorflow::RunMetadata *,struct tensorflow::thread::ThreadPoolOptions const &)\tC++\r\n \ttensorflow.dll!tensorflow::DirectSession::Run(class tensorflow::RunOptions const &,class std::vector<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class tensorflow::Tensor>,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class tensorflow::Tensor> > > const &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const &,class std::vector<class tensorflow::Tensor,class std::allocator<class tensorflow::Tensor> > *,class tensorflow::RunMetadata *)\tC++\r\n \ttensorflow.dll!absl::lts_2020_02_25::StartsWith(class absl::lts_2020_02_25::string_view,class absl::lts_2020_02_25::string_view)\tC++\r\n \ttensorflow.dll!TF_SessionRun\u001e()\tC++\r\n \tTextureProcessLibrary.dll!TFUtils::RunSession(TF_Session * sess=0x000002553c6d15e0, const TF_Output * inputs=0x000002553b7dd530, TF_Tensor * const * input_tensors=0x00000254c74348a0, unsigned __int64 ninputs=1, const TF_Output * outputs=0x0000025539d60e10, TF_Tensor * * output_tensors=0x000002553c6d1160, unsigned __int64 noutputs=4) line 301\tC++\r\n \t[\u5185\u8054\u6846\u67b6] TextureProcessLibrary.dll!TFUtils::RunSession(TF_Session *) line 334\tC++\r\n \tTextureProcessLibrary.dll!TFUtils::RunSession(const std::vector<TF_Output,std::allocator<TF_Output> > & inputs, const std::vector<TF_Tensor *,std::allocator<TF_Tensor *> > & input_tensors={...}, const std::vector<TF_Output,std::allocator<TF_Output> > & outputs, std::vector<TF_Tensor *,std::allocator<TF_Tensor *> > & output_tensors={...}) line 145\tC++\r\n \tTextureProcessLibrary.dll!TexEdit::DeepTextureModelGenerator::generateMap(Base::Path modelPackagePath={...}, QString modelSubPath={...}, cv::Mat & inputMat, std::vector<cv::Mat,std::allocator<cv::Mat> > & outMaps={...}, const char * inputName=0x00007ffa747847b0) \u884c 543\tC++\r\n \tTextureProcessLibrary.dll!TexEdit::DeepTextureModelGenerator::generateMetallicTexturesFromS11() line 327\tC++\r\n \tTextureProcessLibrary.dll!TexEdit::DeepTextureModelGenerator::generate() line 209\tC++\r\n \tMaterialLibrary.dll!XScan::ScanTaskThread::generateDesPngs() line 504\tC++\r\n \tMaterialLibrary.dll!XScan::ScanTaskThread::generateTextures() line 367\tC++\r\n \tMaterialLibrary.dll!XScan::ScanTaskThread::startScan() line 271\tC++\r\n \tMaterialLibrary.dll!XScan::ScanTaskThread::run() line 38\tC++\r\n \tQt5Core.dll!QThreadPrivate::start(void * arg=0x00000253c8d84880) line 405\tC++\r\n \tKERNEL32.DLL!BaseThreadInitThunk\u001e()\t\r\n \tntdll.dll!RtlUserThreadStart\u001e()\t\r\n"]}, {"number": 53410, "title": "tf2 stops working under gpu mode with 3rd order derivative included in loss function", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 20H2, OS build 19042.1348\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): anaconda pip install\r\n- TensorFlow version (use command below): v2.7.0-rc1-69-gc256c071bb2 2.7.0\r\n- Python version: Python 3.7.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: cuda10.0/cudnn11.5\r\n- GPU model and memory: 2080TI & 1080TI\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nIn the case included here, the manually defined loss function includes 3rd order derivative. Attached please find the zip pack that includes the python scripts: NS_tf2.py. \r\nIn NS_tf2.py this term is in the form of \r\n<img src=\"https://latex.codecogs.com/svg.latex?\\frac{\\partial^{3}&space;(pred)}{\\partial&space;(var1)\\partial&space;(var2)\\partial&space;(var2)}\" title=\"\\frac{\\partial^{3} (pred)}{\\partial (var1)\\partial (var2)\\partial (var2)}\" />\r\nwhere pred represents the output of sequential network and var1 and var2 are tensors. \r\n\r\nAt the beginning of the python script \r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\nis used to choose between cpu and gpus. \r\nThe above code work well under cpu mode:\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\nbut get stalled when setting hardware to either 1080ti or 2080ti.\r\n\r\n**Describe the expected behavior**\r\nCode works under gpu mode\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nPlease find the code in attached pack. Please first cd to scripts' directory to run the scripts.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nPlease find the code in attached pack. Please first cd to scripts' directory to run the scripts.\r\n\r\n[tf_bug.zip](https://github.com/tensorflow/tensorflow/files/7707751/tf_bug.zip)\r\n\r\n", "comments": ["@sanatmpa1 Was able to reproduce the issue on colab using TF v[2.7.0](https://colab.research.google.com/gist/sushreebarsa/8bf39cf99a00e6f6cf58ee1ad64659d1/gist53410.ipynb#scrollTo=nb4xo25E9dXW) and [tf-nightly](https://colab.research.google.com/gist/sushreebarsa/9b14d6bea9c8868534937f7ee4cb00d6/gist53410-cpu.ipynb#scrollTo=G8rgmVrVDI82)(2.8.0.dev20211215),please find the attached gists for reference.Thanks!", "@UsherWang can you please further clarify what \"stalled\" means? I opened the script for v2.7.0 by @sushreebarsa and saw that it ran till epoch 840, then got KeyboardInterrupt.", "Hi @JW1992 , \r\n\r\nThank you for your reply. As mentioned in description, under cpu mode it works well but it gets stalled under gpu mode with my env setup. In the test done by @sushreebarsa It's not clear about what platform (C/Gpu) he/she used. Here stall means TF gets stuck at specific iteration step, keeps running and doesn't produce results for an abnormally long time.\r\n\r\n", "Thanks Usher, do you mean that in GPU the code gets blocked on a specific epoch? Is this repeatable (stalled on the same epoch)?\r\n\r\nIt would be really helpful if you can find a simpler reproduction and we can find the root cause much easier.", "Thank you @JW1992 for your reply. I remember the behavior is not deterministic on my system. The epoch number which it stops kinda varies under different attempts. Btw I just tested the code on my linux system, it seems the problem doesn't happen on my linux but appear on windows."]}, {"number": 53403, "title": "New dtype: bcomplex32 ", "body": "\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.7\r\n- Are you willing to contribute it (Yes/No): Probably yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAdd bcomplex32 dtype.\r\nCurrently only a real (like in Math, real field) version is supported (bfloat16)\r\n\r\n**Will this change the current api? How?**\r\nEach function that supports the dtype paramter, should also support the new bcomplex32\r\n**Who will benefit with this feature?**\r\nAnyone who uses the complex plane and wants a speedup for further calculations on supported hardware such as GPUs with compatibility level of 7 and above, for example while using FFT.\r\n**Any Other info.**\r\n", "comments": ["If the primary motivation is for FFT and/or other specific computation, a suggestion is for a user created custom op or ops that where the interface uses real bfloat16 tensor(s) with some structure and internally do whatever the user wants (i.e. treat as bcomplex32). \r\n\r\nAdding a new dtype to tensorfow is a significant change (e.g. there can be issues with binary bloat). Improving complex support (e.g. complex on GPU) is also an area of significant change. A contribution for a small number of ops might be accepted; larger changes are less likely. In general, for each op to support a particular dtype, there needs to be a significant need (e.g. highly used models rely on it) for that op to support it. If you would still like to propose adding bcomplex32, providing a plan that describes and justifies what ops would need the support, and (if the number of ops is significant) how to implement this incrementally would help us understand the request.\r\n"]}, {"number": 53398, "title": "To support casting int32 in HEX format ", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.x\r\n- Are you willing to contribute it (Yes/No): Maybe\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI want something like hex_tensor = tf.cast(int32_tensor, dtype=tf.hex) which allows me to get the hex value representation and can be used for further computation. This becomes relevant for several data where label information is in hex colours while the label images are in PNG (RGB) format. It is one of the basic op in python [Python hex](https://docs.python.org/3/library/functions.html#hex).\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo, extends the functionality.\r\n\r\n\r\n**Who will benefit with this feature?**\r\nAny tensor op that needs to work with hex values, o\r\n\r\n**Any Other info.**\r\nSame as #30493 seems it is closed before finishing.", "comments": ["Hi @Saduf2019! Could you please look at this feature request?", "@khatrishubham88 \r\nPlease feel free to submit a PR for the requested change.", "@Saduf2019 can you point me to the right module to start?", "@Saduf2019 :bump:", "@khatrishubham88 , You can refer [this](https://github.com/tensorflow/tensorflow/blob/v2.7.0/tensorflow/python/ops/math_ops.py#L938-L1007) code to start with  `tf.cast`.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue is being worked on", "Could you please mention the PR which is linked to the issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53385, "title": "Adding support for Zstd Compression", "body": "The current API of `TFRecordOptions` only supports:\r\n- no compression\r\n- GZIP compression\r\n- ZLIB compression\r\n\r\nWith this PR, I have added support for a 4th compression algorithm, ZSTD: https://github.com/facebook/zstd/\r\n\r\nThe API for `TFRecordOptions` is therefore updated to accept the following parameters:\r\n\r\n```\r\n      compression_type: `\"GZIP\"`, `\"ZLIB\"`, `\"ZSTD\"` or `\"\"` (no compression).\r\n      zstd_input_buffer_size: int or `None`. \r\n      zstd_output_buffer_size: int or `None`.\r\n      zstd_flush_mode: int or `None`.\r\n      zstd_nb_workers: int or `None`.\r\n      zstd_compression_level: 0 to 19, or `None`. Default: ZSTD_CLEVEL_DEFAULT.\r\n      zstd_compression_strategy: 0 to 9, or `None`. Default: 0.\r\n      zstd_window_log: between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX. Default: 0.\r\n```\r\n\r\nMaintaining backward compatibility with the current API.\r\n\r\n*Note: the branch is called `adrian-compresssion-r2.6`, as originally it was based on r2.6, but it has been since updated to match current master branch 3038529326066c4eb5cb0453d7f82d929551a24e*", "comments": ["Please open feature PRs against master.", "> Please open feature PRs against master.\r\n\r\nI am still actively working on the PR, and until I have a working version, I am sticking to a stable release as origin.\r\nNevertheless, thanks for the heads up!", "Given the amount of changes you will have a lot of conflicts when you migrate to master. Note that we never merge release branches back into master.", "Also, CI on the release branch is not the same as on master, so you should not rely on its results", "@mihaimaruseac I have finished and refined the PR contents, and it is now ready for review :)", "I am curious, why does the `Code Check - Changed Files` step fail? When clicking into the details it shows \"The specified bucket is missing\".\r\nAlso `import/copybara` fails, and there are no details as to why.\r\nIs there anything I am missing and should I take action to correct these failures?\r\n\r\nThanks a lot in the meantime!", "Oh, the CI setup changed on master recently. Can you rebase to the top of the branch, please?", "@mihaimaruseac I think I have a mismatch of `clang-format` version, as executing `clang-format --style=Google -i tensorflow/python/lib/io/record_io_wrapper.cc` outputs a different result from the one in the Code Check step.\r\n\r\nI am using Ubuntu 18.04 with `clang-format --version`:\r\n```\r\nclang-format version 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\r\n``` \r\n\r\nAny way of knowing which clang-format version it's used in the CI step?", "C++ linter is complaining:\r\n\r\n```\r\nNo message!\r\n(in test file /usertools/code_check_changed_files.bats, line 36)\r\n  `[[ ! -s $BATS_TEST_TMPDIR/needs_help.txt ]]' failed\r\nclang-format is recommended. Here are the suggested changes:\r\n=============================\r\ndiff --git a/tensorflow/python/lib/io/record_io_wrapper.cc b/-\r\nindex e9d403da44d..00000000000 100644\r\n--- a/tensorflow/python/lib/io/record_io_wrapper.cc\r\n+++ b/-\r\n@@ -356,16 +356,17 @@ PYBIND11_MODULE(_pywrap_record_io, m) {\r\n            [](PyRecordWriter* self, py::args) {\r\n              MaybeRaiseRegisteredFromStatus(self->Close());\r\n            })\r\n-      .def(\"write\",\r\n-           [](PyRecordWriter* self, tensorflow::StringPiece record) {\r\n-             tensorflow::Status status;\r\n-             {\r\n-               py::gil_scoped_release release;\r\n-               status = self->WriteRecord(record);\r\n-             }\r\n-             MaybeRaiseRegisteredFromStatus(status);\r\n-           },\r\n-           py::arg(\"record\"))\r\n+      .def(\r\n+          \"write\",\r\n+          [](PyRecordWriter* self, tensorflow::StringPiece record) {\r\n+            tensorflow::Status status;\r\n+            {\r\n+              py::gil_scoped_release release;\r\n+              status = self->WriteRecord(record);\r\n+            }\r\n+            MaybeRaiseRegisteredFromStatus(status);\r\n+          },\r\n+          py::arg(\"record\"))\r\n       .def(\"flush\",\r\n            [](PyRecordWriter* self) {\r\n              MaybeRaiseRegisteredFromStatus(self->Flush());\r\nYou can use clang-format --style=Google -i <file> to apply changes to a file.\r\n```", "Hi @IAL32 Can you please check build failures. Thank you!", "Hmm, I have the following errors I don't currently understand:\r\n- [PyLint](https://github.com/tensorflow/tensorflow/runs/5818563713?check_suite_focus=true) - `The config file tensorflow/tools/ci_build/pylintrc doesn't exist!`.\r\n\r\nI don't think this has anything to do with my changes, I'll rebase and see what happens.\r\n\r\n- [Community CI Build](http://ml-ci.amd.com:21096/job/tensorflow/job/github-prs-upstream-master/job/AMD-ROCm-Community-CI-Build/job/PR-53385/29/display/redirect) - `ERROR: The project you're trying to build requires Bazel 5.1.0 (specified in /workspace/.bazelversion), but it wasn't found in /usr/local/lib/bazel/bin.`\r\n\r\nThis seems to be a problem with the build agent not having the required bazel binary.\r\n\r\nAbout the other failures, I am working on them, but it may take a while.\r\n\r\nThanks!", "@IAL32  Can you please address Ubuntu Sanity errors? Thank you!", "https://github.com/IAL32/TUMWS21GR/blob/master/report/report.pdf\r\n\r\nIn case anyone is interested, this is part of a guided research project @ TUM. I have written a report detailing preprocessing pipeline speeds using this implementation of Zstandard."]}, {"number": 53384, "title": "Perspective transformation data augmentation for object detection", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version :2.7.0\r\n- Are you willing to contribute it \ud83c\udd97 \r\n\r\n\r\n\r\n**Perspective transformation data augmentation for object detection.**\r\n\r\n**Will this change the current api? How? No, the change will be done only in the preprocessing layer.\r\n\r\n**Who will benefit with this feature? As it has been described in [this article](https://ieeexplore.ieee.org/abstract/document/8943416), this feature could be helpful to make the models more general in the object detection projects.\r\n\r\n", "comments": ["@MostafaFiroozi \r\nPlease share your details in issue template for us to understand the issue faced. if possible share the URL where you request the change.", "In object detection projects for the sake of more robust models we need some data augmentation. In the  [preprocessor.py](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py)\r\nthere are some possible functions that can be used in the pipeline config of a TensorFlow model to act as a data-augmentations tool.\r\n![image](https://user-images.githubusercontent.com/73081215/145672704-d7bf2368-1e78-49a3-af0a-2da0e8354560.png)\r\nHowever, there is no technique for perspective transformation data augmentation for object detection. While, as it has been investigated in [this article](https://ieeexplore.ieee.org/abstract/document/8943416), this also could be good practice for data augmentation.\r\nI wanted to ask to add this function also to [preprocessor.py](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py).\r\nHope this will clarify the matter\r\nRegards,", "Take a look at https://github.com/keras-team/keras-cv/issues/333"]}, {"number": 53364, "title": "Selective build for iOS does not produce TensorFlowLiteC_framework.zip", "body": "### System information\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: No\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 11.4\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**: source\r\n-   **TensorFlow version (use command below)**: building from source using latest TF source code\r\n-   **Python version**: 3.9.4\r\n-   **Bazel version (if compiling from source)**: 4.2.1\r\n-   **GCC/Compiler version (if compiling from source)**: Apple clang 13.0.0\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**: \r\n```\r\nbash tensorflow/lite/ios/build_frameworks.sh --input_models=model.tflite --target_archs=x86_64,armv7,arm64\r\n```\r\n\r\n### Describe the problem\r\nWe are performing a selective build for iOS to reduce TF binary size following the instructions here:\r\nhttps://www.tensorflow.org/lite/guide/reduce_binary_size#selective_build_for_ios\r\n\r\nRecently we have followed the instructions for Android on the same page and used the same machine to successfully compile the selective build AAR. For iOS, we followed a similar procedure of running `./configure` with iOS support, then running the selective build script to generate the framework using the command above. \r\n\r\nAccording to the documentation, the framework should be located at `bazel-bin/tensorflow/lite/ios/tmp/TensorFlowLiteC_framework.zip`, but the file does not exist after the build is complete. There are no errors in the output, and it states that the build is successful at the end.\r\n\r\nThe issue does not seem to be related to our specific model, since we also tried it with the MobileNet provided here but encountered the same issue:\r\nhttps://www.tensorflow.org/lite/guide/reduce_binary_size#overview\r\n\r\n\r\n### Source code / logs\r\nThe complete output is attached. Also attached the log when using the provided MobileNet on a fresh repo. That one had some warnings the first time it was run but still stated that the build was successful (no output still), not sure if it's significant.\r\n\r\n[tf-lite-log.txt](https://github.com/tensorflow/tensorflow/files/7682282/tf-lite-log.txt)\r\n[tf-lite-log-mobilenet.txt](https://github.com/tensorflow/tensorflow/files/7682384/tf-lite-log-mobilenet.txt)\r\n\r\n", "comments": ["@sliu54 ,\r\nPlease take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/25800#issuecomment-475818277) from the issue with similar error.It helps.Thanks", "@tilakrayal Thanks for your reply. Do you mind elaborating on how that comment relates to the issue I'm seeing? My issue is that the selective build script does not generate TensorFlowLiteC_framework.zip. Looks like in that comment they already assumed that TensorFlowLiteC_framework.zip exists and talked about how to get it working with CocoaPods. Please let me know if I misunderstood.", "I am seeing this issue as well, the `build_frameworks.sh` script runs successfully but does not provide a build output (TensorFlowLiteC_framework.zip).", "I am experiencing the same issue as well. I am on MacOs 11.1 with TensorFlow 2.8.0 and Bazel 4.2.1 also. \r\n\r\nThis is the original instruction (I removed my username with ***). I tried with and without `sudo`, I thought it was a permission issue. Same result the file is missing at the end.\r\n\r\n`sudo bash tensorflow-2.8.0/tensorflow/lite/ios/build_frameworks.sh --input_models=/Users/***/models/model1.tflite,/Users/***/models/model2.tflite --target_archs=arm64`\r\n\r\nAnd this is the end of the log after 6h running. Is there any solution?\r\n```\r\nINFO: Elapsed time: 27512.231s, Critical Path: 809.68s\r\nINFO: 13693 processes: 3141 internal, 10552 local.\r\nINFO: Build completed successfully, 13693 total actions\r\nOutput can be found here:\r\nls: /Users/***/tensorflow-2.8.0/bazel-bin/tensorflow/lite/ios/tmp/TensorFlowLiteC_framework.zip: No such file or directory\r\n```", "I just found 2 framework files `TensorFlowLiteC_framework.zip` and `TensorFlowLiteSelectTfOps_framework.zip` in this folder:\r\n`/private/var/tmp/_bazel_root/843fec9a8c5b415f6f82b90b06399d42/execroot/org_tensorflow/bazel-out/applebin_ios-ios_arm64-opt-ST-02f4a105b518/bin/tensorflow/lite/ios/tmp`\r\n\r\nand also in this folder (I tried 2 times the build, with/without sudo, so this would make sense): \r\n`/private/var/tmp/_bazel_[MY_USERNAME]/843fec9a8c5b415f6f82b90b06399d42/execroot/org_tensorflow/bazel-out/applebin_ios-ios_arm64-opt-ST-02f4a105b518/bin/tensorflow/lite/ios/tmp`\r\n\r\nLooking at the dates of these files:\r\n- `TensorFlowLiteC_framework.zip` was created when the process started \r\n- `TensorFlowLiteSelectTfOps_framework.zip` created when the build was complete\r\n\r\nAre these the files? \ud83d\ude06\r\n\r\n@sumocodes @sliu54 - Can you confirm you see the same files by doing a search for the word \"framework\" inside `/private/var/tmp/_bazel_root` and/or `/private/var/tmp/_bazel_[YOUR_USERNAME]`?\r\n\r\n@teijeong @tilakrayal If that's the case (and I hope so) that would mean potential error in this [file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/ios/build_frameworks.sh)\r\nHere:\r\n```\r\nfunction print_output {\r\n  echo \"Output can be found here:\"\r\n  for i in \"${OUT_FILES[@]}\"\r\n  do\r\n    # ls command returns failure if the file does not exist.\r\n    ls -1a ${ROOT_DIR}/$i\r\n  done\r\n}\r\n```\r\nThanks.", "Thanks for responding @MoonshotQuest! I was able to find the framework files in `/private/var/tmp/_bazel_[MY_USERNAME]`. It looks like the script needs to be updated to output the new location.", "@MoonshotQuest Great finding! I was also able to find the framework files at the location you specified. Thanks a lot!\r\n\r\n@MoonshotQuest @sumocodes As a side question, have you guys been able to successfully incorporate the generated framework file into your Xcode project? I'm following the instructions [here](https://www.tensorflow.org/lite/guide/build_ios#using_local_tensorflow_lite_core), but I'm not very familiar with CocoaPods so I'm not sure if my `Podfile` and `podspec` configurations are correct. It seems like we need two `podspec`, one for `TensorFlowLiteC` and one for `TensorFlowLiteSwift`? The instructions also mentioned about setting up a private repo, but I have seen solutions where in `podspec` the source is pointed to a local path, so I'm also wondering if this step is required? I tried to have the source in `TensorFlowLiteC.podspec` point to the generated `TensorFlowLiteC_framework.zip`, but I'm confused about how to have the dependency in `TensorFlowLitSwift.podspec` also point to my local `TensorFlowLiteC`. I don't think I'm doing it correctly because right now if I run `pod update`, the process completes successfully, but Xcode is unable to find the TensorFlowLite module when I import it. Just wondering if you have gotten this to work and appreciate any suggestions :)"]}, {"number": 53361, "title": "Running quantized TF Lite model on Android receives error \"Failed to run on the given Interpreter\"", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: tested on Samsung Galaxy device and Pixel 4 emulator\r\n-   **TensorFlow installed from (source or binary)**: tried both (binary compiled on macOS 11.4)\r\n-   **TensorFlow version (use command below)**: tried 2.2.0, 2.5,0, 2.7.0, and nightly\r\n-   **Python version**: Python 3.9\r\n-   **Bazel version (if compiling from source)**: 4.2.1\r\n-   **GCC/Compiler version (if compiling from source)**: Apple clang 13.0.0\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen running inference on a quantized LSTM TF Lite model in Android, we receive the following error:\r\n```\r\njava.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/transpose.cc:55 op_context->perm->dims->data[0] != dims (3 != 2)\r\n    Node number 9 (TRANSPOSE) failed to prepare.\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:241)\r\n        at org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs(InterpreterImpl.java:135)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:80)\r\n        at org.tensorflow.lite.InterpreterImpl.run(InterpreterImpl.java:128)\r\n        at org.tensorflow.lite.Interpreter.run(Interpreter.java:80)\r\n```\r\n\r\nThe unquantized model works fine in Android. The quantized model works fine in iOS and Python.\r\nWe have tried using 2.2.0, 2.5.0, 2.7.0, and nightly to quantize the model in Python and include the respective versions in the Android build.gradle dependencies:\r\n```\r\nimplementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly-SNAPSHOT'\r\nimplementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT'\r\n```\r\nWe have also tried using selective builds with the latest TF source code.\r\n\r\n### Source code / logs\r\nCode for quantizing the model in Python:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_quantizer = True\r\nconverter.experimental_new_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```\r\n\r\nWe referenced the text classification example for Android in the repo for performing inference in Java:\r\n```\r\nByteBuffer buffer = loadModelFile(assetManager, modelPath);\r\nprivate Interpreter tflite = new Interpreter(buffer);\r\nfloat[][] output = new float[1][labels.size()];\r\ntflite.run(input, output);\r\n\r\nprivate static MappedByteBuffer loadModelFile(AssetManager assetManager, String modelPath)\r\n    throws IOException {\r\n  try (AssetFileDescriptor fileDescriptor = assetManager.openFd(modelPath);\r\n      FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor())) {\r\n    FileChannel fileChannel = inputStream.getChannel();\r\n    long startOffset = fileDescriptor.getStartOffset();\r\n    long declaredLength = fileDescriptor.getDeclaredLength();\r\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n  }\r\n}\r\n```", "comments": ["I looked into the source code for `transpose.cc` and saw that the error might mean there is a mismatch between the input and output sizes. My input was a 1-D array, so I added an extra dimension and now it works. However, I'm still curious as to why the unquantized model works fine with 1-D inputs."]}, {"number": 53358, "title": "Batched sparse2sparse (CSRSparseMatrix) multiplication error ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.5 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): preinstalled in Colab\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 11.1/7.6.5\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nWhen multiplying 2 sparse 3D tensors (batched matrices x single 2D matrix) of type tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops.CSRSparseMatrix, with the function tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops.matmul on a GPU, if batch dimension of the first tensor is bigger than 16, we get: \r\n\r\n```\r\nInternalError: tensorflow/core/util/cuda_sparse.cc:866 (cusparseXcsrgemm2Nnz( *gpusparse_handle_, m, n, k, descrA, nnzA, csrSortedRowPtrA, csrSortedColIndA, descrB, nnzB, csrSortedRowPtrB, csrSortedColIndB, descrA, 0, null_ptr<int>(), null_ptr<int>(), descrC, csrSortedRowPtrC, nnzTotalDevHostPtr, info, workspace)): cuSparse call failed with status CUSPARSE_STATUS_EXECUTION_FAILED [Op:SparseMatrixSparseMatMul]\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe tensorflow.python.ops.linalg.sparse.sparse_csr_matrix_ops.matmul function should support matrix multiplication of arbitrary batch dimension, as long there is enough GPU memory. If the problem is the GPU memory, the error message should be more descriptive.  \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing): n/a\r\n\r\n**Standalone code to reproduce the issue**\r\nHere is a link to colab: \r\nhttps://colab.research.google.com/drive/1Abwf6esrNTWW_YmdZpWgnmEuCQ20umfA?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-8-80d3c194e0ae> in <module>()\r\n      3 c = sparse_csr_matrix_ops.matmul(\r\n      4     sparse_csr_matrix_ops.CSRSparseMatrix(a),\r\n----> 5     sparse_csr_matrix_ops.CSRSparseMatrix(b))\r\n      6 c = c.to_sparse_tensor()\r\n      7 a.shape, b.shape, c.shape\r\n\r\n2 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/linalg/sparse/sparse_csr_matrix_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, name)\r\n    204           adjoint_a=adjoint_a,\r\n    205           adjoint_b=adjoint_b,\r\n--> 206           type=a.dtype)\r\n    207 \r\n    208       # In eager mode, shape inference functions are not called, and the output\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/linalg/sparse/gen_sparse_csr_matrix_ops.py in sparse_matrix_sparse_mat_mul(a, b, type, transpose_a, transpose_b, adjoint_a, adjoint_b, name)\r\n   1095       return _result\r\n   1096     except _core._NotOkStatusException as e:\r\n-> 1097       _ops.raise_from_not_ok_status(e, name)\r\n   1098     except _core._FallbackException:\r\n   1099       pass\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\r\n   7105 def raise_from_not_ok_status(e, name):\r\n   7106   e.message += (\" name: \" + name if name is not None else \"\")\r\n-> 7107   raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\n   7108 \r\n   7109 \r\n\r\nInternalError: tensorflow/core/util/cuda_sparse.cc:866 (cusparseXcsrgemm2Nnz( *gpusparse_handle_, m, n, k, descrA, nnzA, csrSortedRowPtrA, csrSortedColIndA, descrB, nnzB, csrSortedRowPtrB, csrSortedColIndB, descrA, 0, null_ptr<int>(), null_ptr<int>(), descrC, csrSortedRowPtrC, nnzTotalDevHostPtr, info, workspace)): cuSparse call failed with status CUSPARSE_STATUS_EXECUTION_FAILED [Op:SparseMatrixSparseMatMul]\r\nSEARCH STACK OVERFLOW\r\n", "comments": ["Hi @chunduriv ! Could you please look at this issue? It is replicating in [2.6](https://colab.sandbox.google.com/gist/mohantym/dd5d7e01395c65f7d867d812112d2c38/gpusparsebatchingfail.ipynb#scrollTo=y-4zRfsDQoQZ),[2.7](https://colab.sandbox.google.com/gist/mohantym/2efb1f9111f1cfb35d606c8864ab5aaf/gpusparsebatchingfail.ipynb#scrollTo=gUxWF2BCV7B_) and [nightly](https://colab.sandbox.google.com/gist/mohantym/5961b71eedb35236ea2a6bbac1cdecd4/gpusparsebatchingfail.ipynb)? Thanks!", "I would like to work on this issue", "Have you looked at the solution provided [here](https://stackoverflow.com/questions/29688627/) for the similar issue.", "Not sure if you asked me, but if the CSR matrix formatting was in fact broken, I would presume that the error would happen for smaller batch sizes also. "]}, {"number": 53351, "title": "sound_classification example can not work on iOS 15.0+", "body": "Source:\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/ios\r\n\r\nI tested it on an iOS14 device and it worked fine.\r\n\r\nI changed several iOS15.0+ devices, but they couldn't work. The phenomenon is that the progress bar jumps randomly and the data is messy.\r\n\r\nI am sure that this is a bug that only appears on iOS 15.0+ and will recur 100%.", "comments": ["@zxl777 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo, https://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/ios\r\nThe source code has not changed.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\niOS 15.0+\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\niPhone 12 mini, iPhone X, iPhone 13 mini\r\n\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n\r\n- TensorFlow version (use command below):\r\n\r\n\r\n- Python version:\r\nNo Python\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe app did not correctly recognize the applause. The progress bar is constantly changing, and the progress bar does not respond to sound as normal as in iOS14.\r\n\r\n**Describe the expected behavior**\r\nLike in iOS14, when I clap my hands, the bottom progress bar shows the largest.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\nno\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/ios\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "I would like to work in this issue do fix the example. There were many updates in iOS 15 that makes the developers to change features a bit. That could be a reason.", "Any news?"]}, {"number": 53336, "title": "Can I repeat a 1-D tensor in segment form?", "body": "According to the doc, TF has: tf.segment_xxx and tf.repeat. But can I repeat a 1-D tensor in segment form?\r\n\r\n#### Example:\r\nsegment = [0 0 0 1 1]\r\nvalue = [0 1 2 3 4]\r\n\r\n#### [ 1 ] If repeat_cnt = [2 2 2 1 1]\r\nWith tf.repeat, I can easily repeat value to: [0 0 1 1 2 2 3 4]\r\n\r\n#### [ 2 ] But I want a segment repeat, which means: segment-0 repeat 2 times, segment-1 repeat 1 time.\r\nThat is to say, if repeat_cnt_new = [2 1], and I want to repeat value to: [0 1 2 0 1 2 3 4].\r\n\r\n#### I mean, repeat blocks in a vector: [0 1 2] * 2 + [3 4] * 1. Are there any TF func or api can help?\r\nThanks!", "comments": ["Hi @HaozhengLi ! Could you look at this [Gist](https://colab.research.google.com/gist/mohantym/b2f9af937f8a138b06aa7fcb93c41092/github_53336.ipynb#scrollTo=Dfk9iJC_OKrG) for answer?", "> Hi @HaozhengLi ! Could you look at this [Gist](https://colab.research.google.com/gist/mohantym/b2f9af937f8a138b06aa7fcb93c41092/github_53336.ipynb#scrollTo=Dfk9iJC_OKrG) for answer?\r\n\r\nNo. I want [0 1 2 0 1 2 3 4], but not [0 0 1 1 2 2 3 4].\r\n\r\nIn this Gist, I understood what you want to do. You want to split value into [0 1 2] and [3 4], then repeat 2 times and 1 time, and finally concat.\r\n\r\nBut when I trying to train a MLP network, I must do all this things in ONE op. That is to say, my value.shape = [batch_size, 1].\r\n\r\nIt means that I can not manually split the value in Python, but only deal with the whole vector in serveral ops.\r\n\r\nThanks.", "Hi @sanatmpa1 ! Could you please look at this issue?", "One possible approach would be to use `RaggedTensor`. You can use `RaggedTensor.from_value_rowids` to construct a ragged tensor from values+segments. E.g.:\r\n\r\n```python\r\n>>> segment = [0, 0, 0, 1, 1]\r\n>>> value = [0, 1, 2, 3, 4]\r\n>>> rt = tf.RaggedTensor.from_value_rowids(value, segment)\r\nprint(rt)\r\n<tf.RaggedTensor [[0, 1, 2], [3, 4]]>\r\n```\r\n\r\nAnd then you can use repeat + gather to repeat those rows:\r\n\r\n```python\r\n>>> repeat_cnt = [2, 1]\r\n>>> gather_indices = tf.repeat(tf.range(tf.size(repeat_cnt)), repeat_cnt)\r\n>>> repeated = tf.gather(rt, gather_indices)\r\n>>> print(repeated)\r\n<tf.RaggedTensor [[0, 1, 2], [0, 1, 2], [3, 4]]>\r\n```\r\n\r\nIf you want the flat tensor (rather than a ragged tensor), you can use repeated.values:\r\n\r\n```python\r\n>>> print(repeated.values)\r\ntf.Tensor([0 1 2 0 1 2 3 4], shape=(8,), dtype=int32)\r\n```"]}, {"number": 53321, "title": "`tf.keras.layers.experimental.EinsumDense` gives different results depending on batch size", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.6.0 and 2.7.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nwhen using `tf.keras.layers.experimental.EinsumDense` layer produce different result depending on the batch size\r\n\r\n**Describe the expected behavior**\r\n\r\nthe output of the layer should be independent of batch dimension\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\ndense = tf.keras.layers.experimental.EinsumDense(\r\n        \"bac,acd->bda\",\r\n        output_shape=[64,4],\r\n        bias_axes=\"da\"\r\n)\r\nx = tf.random.uniform((80,4,32))\r\nprint(dense(x)[0, :4].numpy())\r\nprint(dense(x[:1])[0, :4].numpy())\r\n```\r\nI've got different result in 7th-8th order:\r\n```\r\n[[ 0.12284548  0.2814498  -0.34291047  0.00810905]\r\n [ 0.23635934 -0.08506497  0.12073331  0.33535597]\r\n [-0.30136532  0.34854767  0.41540402  0.1328382 ]\r\n [-0.04340287 -0.07197566  0.17427945 -0.29642397]]\r\n\r\n[[ 0.12284552  0.2814498  -0.34291047  0.00810904]\r\n [ 0.23635934 -0.08506497  0.12073331  0.33535597]\r\n [-0.3013654   0.3485477   0.415404    0.1328382 ]\r\n [-0.04340289 -0.07197568  0.17427945 -0.29642397]]\r\n```\r\nHaving several of Einsum layers leads to accumulated error and wrong predictions\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Similar behavior can be observed for the `tf.einsum`:\r\n```\r\nimport tensorflow as tf\r\nx = tf.random.uniform((80,4,32))\r\nw = tf.random.uniform((4,32,64))\r\nprint(tf.einsum(\"bac,acd->bda\", x, w)[0, :4].numpy())\r\nprint()\r\nprint(tf.einsum(\"bac,acd->bda\", x[:1], w)[0, :4].numpy())\r\n```\r\nI've got different result in 7th-8th order:\r\n```\r\n\r\n[[8.515028  6.533536  8.1234455 6.415581 ]\r\n [8.387905  8.020177  8.997409  6.6566358]\r\n [7.485701  7.6112795 8.145813  7.514901 ]\r\n [8.022375  7.008651  7.9132357 5.918109 ]]\r\n\r\n[[8.515028  6.5335355 8.123446  6.4155803]\r\n [8.387905  8.020177  8.997409  6.6566353]\r\n [7.485701  7.611279  8.145813  7.5149007]\r\n [8.022375  7.0086513 7.9132347 5.9181094]]\r\n```", "The issue is rather important because attention implementation uses einsum dense layers", "@Ghostvv,\r\n\r\nI've tested the code in colab with `TF 2.7.0` and I am able to see the similar result as you expected. Please find the [gist here](https://colab.sandbox.google.com/gist/sanatmpa1/6bbaead47f012b51b482722a5822c902/53321.ipynb) and let me know if I am missing something. Thanks!", "@sanatmpa1 thank you for creating colab notebook. It looks correct there, however locally I ghave `2.7.0` as well, however I get slightly different numbers:\r\n```\r\n>>> import tensorflow as tf\r\n2021-12-07 09:07:10.186065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-12-07 09:07:10.186104: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n>>> tf.__version__\r\n'2.7.0'\r\n>>> x = tf.random.uniform((80,4,32))\r\n2021-12-07 09:07:41.415303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2021-12-07 09:07:41.415326: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-12-07 09:07:41.415352: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cognigy-workstation-128): /proc/driver/nvidia/version does not exist\r\n2021-12-07 09:07:41.415665: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n>>> w = tf.random.uniform((4,32,64))\r\n>>> print(tf.einsum(\"bac,acd->bda\", x, w)[0, :4].numpy())\r\n[[6.923691  5.8655972 8.443382  6.651726 ]\r\n [8.643357  7.0431523 7.812662  7.4349017]\r\n [7.7721167 6.5131044 7.1347017 8.100251 ]\r\n [7.3623085 5.9433074 7.341781  6.8320265]]\r\n>>> print()\r\n\r\n>>> print(tf.einsum(\"bac,acd->bda\", x[:1], w)[0, :4].numpy())\r\n[[6.9236917 5.8655972 8.443382  6.651726 ]\r\n [8.643357  7.0431523 7.812662  7.4349017]\r\n [7.772116  6.5131044 7.1347017 8.100251 ]\r\n [7.3623085 5.943307  7.341781  6.8320265]]\r\n>>> import numpy as np\r\n>>> np.set_printoptions(12)\r\n>>> print(tf.einsum(\"bac,acd->bda\", x, w)[0, :4].numpy())\r\n[[6.923691  5.8655972 8.443382  6.651726 ]\r\n [8.643357  7.0431523 7.812662  7.4349017]\r\n [7.7721167 6.5131044 7.1347017 8.100251 ]\r\n [7.3623085 5.9433074 7.341781  6.8320265]]\r\n>>> print(tf.einsum(\"bac,acd->bda\", x, w)[0, 0].numpy())\r\n[6.923691  5.8655972 8.443382  6.651726 ]\r\n>>> print(tf.einsum(\"bac,acd->bda\", x, w)[0, 0, 0].numpy())\r\n6.923691\r\n>>> print(tf.einsum(\"bac,acd->bda\", x[:1], w)[0, 0, 0].numpy())\r\n6.9236917\r\n```\r\nDo you have an idea why? the result is that my architecture with several attentions implemented with `tf.keras.layers.MultiHeadAttention` produce different prediction confidence for the same example depending on the prediction batch size", "also, I have similar problems with models from tensorflow hub:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\n# Needed for loading universal-sentence-encoder-cmlm/multilingual-preprocess\r\nimport tensorflow_text  # noqa\r\n\r\n\r\nencoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\r\n\r\n\r\ntexts = [\r\n    \"schedule a booking\",\r\n    \"I'd like to book an appointment, please.\",\r\n    \"kuhwb wuehb jweb\",\r\n    \"uiweh uiwe\",\r\n    \"I want to cancel my appointment\",\r\n]\r\n\r\nprint(all(encoder(texts).numpy()[-1] == encoder(texts[-1:]).numpy()[-1]))\r\n```\r\nI get `False`", "@sanatmpa1 I added the example with sentence encoder above and I also get different sentence embeddings depending on the batch size", "@sanatmpa1 sorry for multiple messages \ud83d\ude48 I increased the sizes of the vectors and got different results in your colab notebook for `tf.einsum` as well.\r\n\r\nHere is a link to [the gist](https://colab.research.google.com/gist/Ghostvv/d6ef36229f1277e001ee63cd7046d960/53321.ipynb)", "\u5df2\u6536\u5230\uff0c\u6211\u4f1a\u5c3d\u5feb\u56de\u590d\u4f60\uff01\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2014\u2014\u5218\u52b2\u5b57", "\u00a0 \u60a8\u597d\uff0c\u90ae\u4ef6\u5df2\u7ecf\u6536\u5230\uff0c\u6211\u4f1a\u5c3d\u5feb\u5904\u7406\u7684\u3002\u8c22\u8c22", "e-7 or higher floating point precision error is expected and are negligible which does not impact much on the overall precision/accuracy. ", "I have attention intent model and I noticed that the same sentence has different intent prediction depending on the position in the batch. My guess would be that this error got accumulated given many layers"]}, {"number": 53315, "title": "[TFLite] Conversion support for 3D operators with channels first data format", "body": "Hello,\r\n\r\nTensorFlow Lite currently supports the conversion of 2D operators like `tf.keras.layers.Conv2D`, `tf.keras.layers.MaxPool2D`, ... with `data_format=\"channels_first\"` through the insertion of `TRANSPOSE` operators as the TFLite kernels only support the channels last format.\r\n\r\nWould it be possible to add something similar for 3D operators like  `tf.keras.layers.Conv3D`, `tf.keras.layers.MaxPool3D`, ... that use `data_format=\"channels_first\"`?\r\n\r\nExample script:\r\n```python\r\nimport tensorflow as tf\r\n\r\ninput = tf.keras.Input(shape=[1, 3, 8, 8, 8])\r\noutput = tf.keras.layers.Conv3D(\r\n    filters=12,\r\n    kernel_size=(2, 2, 2),\r\n    data_format=\"channels_first\",\r\n    use_bias=False,\r\n)(input)\r\nmodel = tf.keras.Model(input, output)\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n```\r\n\r\nConversion error with TF 2.7.0 (note that setting `data_format=\"channels_last\"` works):\r\n```\r\nerror: 'tf.Conv3D' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main':\r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select\r\nTF Select ops: Conv3D\r\nDetails:\r\n        tf.Conv3D(tensor<?x3x8x8x8xf32>, tensor<2x2x2x3x12xf32>) -> (tensor<?x12x7x7x7xf32>) : {data_format = \"NCDHW\", device = \"\", dilations = [1, 1, 1, 1, 1], padding = \"VALID\", strides = [1, 1, 1, 1, 1]}\r\n```\r\n\r\nThibaut", "comments": ["@sachinprasadhs, I was able to reproduce the issue on Colab using TF 2.7 and TF-nightly(2.8.0-dev20211208). Please find the [gist here](https://colab.research.google.com/gist/chunduriv/f3f4b6b4f958bf8034ce214062a786e6/untitled68.ipynb) for reference.Thanks!", "Right now Conv3D with data_format=\"channel_first\" operations are not in a listed TFLite operations for conversion. As you have specified data_format = = \"channel_last\" is working and you can use the same.\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "@sachinprasadhs Yes, using `channels_last` works fine for 3D operators. It's mainly a feature request to have feature-parity with 2D operators as supporting `channels_first` can be useful when converting models from one framework to another.\r\n\r\nWould it be possible to re-open the issue as with the end of the year holidays I was late to respond and the issue has been closed as stale? Thanks!"]}, {"number": 53312, "title": "Unable to find version specific documentation for building TFLite", "body": "\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/guide/\r\n\r\n## Description of issue (what needs changing):\r\nUnable to find version-specific documentation to build TFLite building.\r\n\r\n### Clear description\r\nFor version 2.4.1, There used to be documentation which is based on Makefile present in tensorflow/lite/tools/make\r\nBut this became redundant in the current release.\r\nBazel and cmake build process were introduced later.\r\nBazel build on host to generate TFLite shared library was initially kept and removed from the site.\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nNeed version specific documentation to build TFLite library.\r\nIt will be helpful when users are using previous releases and help them in building TFLite library.\r\n\r\n### Correct links\r\nhttps://www.tensorflow.org/lite/guide/\r\nhttps://github.com/tensorflow/tensorflow \r\n\r\n\r\n", "comments": []}, {"number": 53301, "title": "MLIR backend for XLA", "body": "Hello,  may I ask  a few simple questions on XLA .\r\n\r\n1. Is there an open sourced XLA MLIR backend that  one can try \"out of the box\" ?\r\n2. Is there a way to enable/disable various optimizations  that are used in XLA ?\r\n3. What is the best way to figure out  what optimizations are available in XLA ? \r\n", "comments": ["@whatdhack Could you please have a look at the [XLA link ](https://www.tensorflow.org/xla) and let us know if it helps?Thanks!", "@sushreebarsa ,  that link is very cursory and does not address any of the questions above.  Hence I opened the issue . ", "You can refer the Tensorflow code for [XLA](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/xla) and implementation code for [MLIR-HLO](https://github.com/tensorflow/mlir-hlo).\r\nFor information regarding XLA MLIR optimization detail you can refer [this](https://www.tensorflow.org/mlir/xla_gpu_codegen) documentation. Let us know if this helps you. Thanks!", "Thanks.   The link[ MLIR CodeGen for XLA ](https://www.tensorflow.org/mlir/xla_gpu_codegen)  looks like is sort of a roadmap which is yet to be implemented.   Would appreciate if you could clarify the current high level XLA  flow and the  future flow with MLIR.   AFAIK,  the current flow is as follows. Can you  please check and make any correction and enhancement ? \r\n\r\nGrappler (pbb  ?) -> XLA HLO (independent) - XLA HLO ( target dependent) -> LLVM IR ->  PTX -> thunk \r\n\r\nAlong the same line,  what would the MLIR  based flow look like ?\r\n\r\nAlso, none of the documentations seems to mention any flag to  enable/disable category of optimizations. Is it possible to enable/disable certain category of optimizations ?", "@sachinprasadhs , any update on this ?", "Anyone here ?", "> The link[ MLIR CodeGen for XLA ](https://www.tensorflow.org/mlir/xla_gpu_codegen)looks like is sort of a roadmap which is yet to be implemented.\r\n\r\nIt would be also nice to understand where we are now in implementing this roadmap."]}, {"number": 53296, "title": "Cloud TPU VM with v3-32 fails while connecting to the cluster", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04 (Cloud TPU VM)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): preinstalled\r\n- TensorFlow version (use command below): 2.6\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: - \r\n- GPU model and memory: TPU v3-32\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nIf specifying TPU local I only connect to the 8 local cores:\r\n```\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\r\n```\r\n\r\nIf replacing `'local'` with the TPU name I get the following error:\r\n```\r\nTensorFlow version 2.6.0\r\nSonnet version 2.0.0\r\n2021-12-03 15:16:13.982669: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nD1203 15:16:18.394708976   58639 ev_posix.cc:173]            Using polling engine: epollex\r\nD1203 15:16:18.394800582   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"grpclb\"\r\nD1203 15:16:18.394810386   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"priority_experimental\"\r\nD1203 15:16:18.394817121   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"weighted_target_experimental\"\r\nD1203 15:16:18.394820536   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"pick_first\"\r\nD1203 15:16:18.394823674   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"round_robin\"\r\nD1203 15:16:18.394830364   58639 dns_resolver_ares.cc:499]   Using ares dns resolver\r\nD1203 15:16:18.394849444   58639 certificate_provider_registry.cc:33] registering certificate provider factory for \"file_watcher\"\r\nD1203 15:16:18.394861188   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"cds_experimental\"\r\nD1203 15:16:18.394868067   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"xds_cluster_impl_experimental\"\r\nD1203 15:16:18.394874855   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"xds_cluster_resolver_experimental\"\r\nD1203 15:16:18.394879563   58639 lb_policy_registry.cc:42]   registering LB policy factory for \"xds_cluster_manager_experimental\"\r\nI1203 15:16:18.395006237   58639 server_builder.cc:332]      Synchronous server. Num CQs: 1, Min pollers: 1, Max Pollers: 2, CQ timeout (msec): 10000\r\nI1203 15:16:18.395095150   58639 socket_utils_common_posix.cc:353] TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\r\nI1203 15:16:18.433733255   59004 subchannel.cc:1065]         New connected subchannel at 0x815b7a0 for subchannel 0x2918780\r\n2021-12-03 15:16:19.492715: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x8882ad00 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\r\n2021-12-03 15:16:19.492752: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): TPU, 2a886c8\r\n2021-12-03 15:16:19.492760: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): TPU, 2a886c8\r\n2021-12-03 15:16:19.492770: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): TPU, 2a886c8\r\n2021-12-03 15:16:19.492781: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): TPU, 2a886c8\r\n2021-12-03 15:16:19.492790: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (4): TPU, 2a886c8\r\n2021-12-03 15:16:19.492797: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (5): TPU, 2a886c8\r\n2021-12-03 15:16:19.492804: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (6): TPU, 2a886c8\r\n2021-12-03 15:16:19.492811: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (7): TPU, 2a886c8\r\n2021-12-03 15:16:19.503990: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.164.0.8:8470, 1 -> 10.164.0.7:8470, 2 -> 10.164.0.5:8470, 3 -> 10.164.0.6:8470}\r\n2021-12-03 15:16:19.504022: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34945}\r\n2021-12-03 15:16:19.508428: E tensorflow/core/common_runtime/eager/context_distributed_manager.cc:489] unknown service tensorflow.WorkerService\r\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\r\n:{\"created\":\"@1638544579.507078836\",\"description\":\"Error received from peer ipv4:10.164.0.8:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"unknown service tensorflow.WorkerService\",\"grpc_status\":12}\r\nE1203 15:16:19.508989265   58639 completion_queue.cc:244]    assertion failed: queue.num_items() == 0\r\nhttps://symbolize.stripped_domain/r/?trace=7f686921518b,7f686921520f,7f66c58688d8,7f66c586ba19,7f66c586d51d,7f66c57a8900,7f66c57a8c85,7f66bfeec9de,7f66bfeecc75,7f66bfee4d11,7f66bfee799c,7f66bfd23903,7f66ad862451,7f66ad85365b,5f5db8,903aff&map=b7c22d7954df6b6961e4435041132cf899ee4a5e:7f66bbcde000-7f66cf9dd270 \r\n*** SIGABRT received by PID 58639 (TID 58639) on cpu 16 from PID 58639; stack trace: ***\r\nPC: @     0x7f686921518b  (unknown)  raise\r\n    @     0x7f66bb1d41e0        976  (unknown)\r\n    @     0x7f6869215210  (unknown)  (unknown)\r\n    @     0x7f66c58688d9         32  grpc_cq_internal_unref()\r\n    @     0x7f66c586ba1a         32  server_unref()\r\n    @     0x7f66c586d51e        176  grpc_server_destroy\r\n    @     0x7f66c57a8901         96  grpc_impl::Server::~Server()\r\n    @     0x7f66c57a8c86         32  grpc_impl::Server::~Server()\r\n    @     0x7f66bfeec9df        496  tensorflow::GrpcServer::~GrpcServer()\r\n    @     0x7f66bfeecc76         32  tensorflow::GrpcServer::~GrpcServer()\r\n    @     0x7f66bfee4d12       1296  tensorflow::(anonymous namespace)::UpdateContextWithServerDef()\r\n    @     0x7f66bfee799d        720  tensorflow::EagerContextDistributedManager::SetOrUpdateServerDef()\r\n    @     0x7f66bfd23904        176  TFE_ContextSetServerDef\r\n    @     0x7f66ad862452        144  pybind11::cpp_function::initialize<>()::{lambda()#3}::_FUN()\r\n    @     0x7f66ad85365c        720  pybind11::cpp_function::dispatcher()\r\n    @           0x5f5db9  (unknown)  PyCFunction_Call\r\n    @           0x903b00  (unknown)  (unknown)\r\nhttps://symbolize.stripped_domain/r/?trace=7f686921518b,7f66bb1d41df,7f686921520f,7f66c58688d8,7f66c586ba19,7f66c586d51d,7f66c57a8900,7f66c57a8c85,7f66bfeec9de,7f66bfeecc75,7f66bfee4d11,7f66bfee799c,7f66bfd23903,7f66ad862451,7f66ad85365b,5f5db8,903aff&map=b7c22d7954df6b6961e4435041132cf899ee4a5e:7f66bbcde000-7f66cf9dd270,ca1b7ab241ee28147b3d590cadb5dc1b:7f66ae4d5000-7f66bb507b20 \r\nE1203 15:16:19.708636   58639 coredump_hook.cc:292] RAW: Remote crash data gathering hook invoked.\r\nE1203 15:16:19.708659   58639 coredump_hook.cc:384] RAW: Skipping coredump since rlimit was 0 at process start.\r\nE1203 15:16:19.708672   58639 client.cc:222] RAW: Coroner client retries enabled (b/136286901), will retry for up to 30 sec.\r\nE1203 15:16:19.708680   58639 coredump_hook.cc:447] RAW: Sending fingerprint to remote end.\r\nE1203 15:16:19.708688   58639 coredump_socket.cc:124] RAW: Stat failed errno=2 on socket /var/google/services/logmanagerd/remote_coredump.socket\r\nE1203 15:16:19.708701   58639 coredump_hook.cc:451] RAW: Cannot send fingerprint to Coroner: [NOT_FOUND] Missing crash reporting socket. Is the listener running?\r\nE1203 15:16:19.708709   58639 coredump_hook.cc:525] RAW: Discarding core.\r\nE1203 15:16:19.916116   58639 process_state.cc:771] RAW: Raising signal 6 with default behavior\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\n", "comments": ["@sigeisler It could be a mismatch in either one of the following: Tensorflow version, zone or project between compute VM and TPU. If you create both TPU and GCE VM with the same Tensorflow version  and they both are created in the same project and zone. You can just provide the TPU name in TPUClusterResolver and it should work fine:\r\n\r\n `resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='my-tpu-name') `\r\n\r\nPlease try with the latest TF v2.7.0 and let us know if it helps?\r\n\r\n", "@sushreebarsa thanks for the response. I will check out upgrading TensorFlow later.\r\n\r\nHowever, I do not have _both_ a TPU and GCE VM since I am using a [**TPU VM**](https://cloud.google.com/tpu/docs/users-guide-tpu-vm). Moreover, they come with a preinstalled tensorflow etc.", "Since you are using TPU VM it is suggested to use 'local' so that it will consume the TPU which is directly connected to the VM.\r\nAlso, you can leave the `tpu` field blank so that it will automatically resolve the TPU adress on Cloud TPUs.\r\nIf you have the TPU worker gRPC address you can pass the same.", "Yes, but if I am using a TPU VM with e.g. a v3-32 then only 8 cores are local and the remaining ones reside on a different host. Anyhow a TPU VM with e.g. v3-32 causes other Google-Cloud-related issues. For example, once created you cannot stop it any more (i.e. `gcloud alpha compute tpus tpu-vm stop ...` then throws an error).\r\n\r\nSimilarly, I am running into trouble, if I am trying to submit a job from a TPU VM to a different TPU cluster (use case: I am using the TPU VM for \"local\" development but then want to trigger a job on a larger TPU cluster). Then I get an error that the number of cores is not equal on all nodes. For some reason, the 8 cores of the local VM are then added to the 0-th remote node.\r\n\r\nI think both issues are a result of the way how TensorFlow handles the local node for connecting to the TPU cluster.", "I am having exactly the same issue.  I haven't been able to start training with all the 256 cores. I can only use 8 at a time. ", "Are there any updates on this?\r\n"]}, {"number": 53284, "title": "Model not learning when using Dataset.from_generator() instead of Dataset.from_tensor_slices()", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): Nvidia docker (nvcr.io/nvidia/tensorflow:21.08-tf2-py3)\r\n- TensorFlow version (use command below): 2.5 (default installation) / 2.7 (updated with pip), doesn't work for both\r\n- Python version: 3.8.10\r\n- CUDA/cuDNN version: 11.4\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to train a Pose Recognition model (SimpleBaseline - ResNet50) with the COCO dataset. The labels are loaded with a python function first and are then converted to a tf.dataset and further processed. It works well when using Dataset.from_tensor_slices() for conversion, but the model doesn't learn anything if Dataset.from_generator() is used instead. The later dataset functions are kept the same. Currently the training and evaluation are executed on the same (eval) split of the dataset for debugging. When printing the outputs of the dataset while training they are exactly the same for both approaches. \r\n\r\n```\r\n\r\n# Loading labels as python list of dicts:\r\n...\r\nprint(labels[0])\r\n{\r\n  'annotids': [183126], \r\n  'imageid': 425226,\r\n  'raw_keypoints': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 309, 1, 177, 320, 2, 191, 398, 2, 237, 317, 2, 233, 426, 2, 306, 233, 2, 92, 452, 2, 123, 468, 2, 0, 0, 0, 251, 469, 2, 0, 0, 0, 162, 551, 2], \r\n  'keypoints': [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [142, 309, 1], [177, 320, 2], [191, 398, 2], [237, 317, 2], [233, 426, 2], [306, 233, 2], [92, 452, 2], [123, 468, 2], [0, 0, 0], [251, 469, 2], [0, 0, 0], [162, 551, 2]]], \r\n  'imgpath': '/datasets/coco2017/annotations/../images/val2017/000000425226.jpg',\r\n  'raw_width': 480,\r\n  'raw_height': 640,\r\n  'bbox': [73.35, 206.02, 300.58, 372.5], \r\n  'score': 1.0\r\n}\r\n\r\n# This does work\r\n# Convert to dict-of-lists format and create dataset\r\nlabels = {k: [dic[k] for dic in labels] for k in labels[0]}\r\nds = tf.data.Dataset.from_tensor_slices(labels)\r\n\r\n# This doesn't work\r\noutput_types = {\r\n    \"annotids\": tf.int32,\r\n    \"imageid\": tf.int32,\r\n    \"raw_keypoints\": tf.float32,\r\n    \"keypoints\": tf.float32,\r\n    \"imgpath\": tf.string,\r\n    \"raw_width\": tf.int32,\r\n    \"raw_height\": tf.int32,\r\n    \"bbox\": tf.float32,\r\n    \"score\": tf.float32,\r\n}\r\nds = tf.data.Dataset.from_generator(lambda: iter(labels), output_types=output_types)\r\n\r\n# Postprocessing like image loading and heatmap generation with dataset.map calls\r\n# They don't change for both approaches\r\n...\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe model should be able to learn something as well when using from_generator() instead of from_tensor_slices()\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nCurrently the complete training code is to complex to extract a short standalone example\r\n\r\n**Other info / logs**\r\nTraining uses Mirrored Strategy on two gpus. It takes about one epoch of training (~6000 images or ~90x2x32 batch examples) that a difference in the loss can be seen clearly. When training for more epochs the loss of the from_generator() approach doesn't decrease further. The heatmaps the network is trying to learn only show a lot of black with some random noise instead of clear gaussian distributions around a point.\r\n\r\n**Current workaround**\r\nUse Dataset.from_tensor_slices() instead of Dataset.from_generator()\r\n\r\n", "comments": ["@DanBmh ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "@tilakrayal \r\nI uploaded the code to: https://gitlab.com/DANBER/Pingoora\r\n\r\nI hope the instructions in the _Pose2D_ folder are good enough to help you set up the project. You only need to download the _val_ part of the coco dataset. The data pipeline part can be found [here](https://gitlab.com/DANBER/Pingoora/-/blob/main/Pose2D/training/scode/pipelines/pl_top_down.py#L175). You also can find some pipeline debugging tools [here](https://gitlab.com/DANBER/Pingoora/-/blob/main/Pose2D/training/run_tests.py).\r\n\r\nIn case you have any problems with it, please contact me again.", "@DanBmh ,\r\nThe code provided is fairly complex hence it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro or colab gist? That will allow us to determine the source of the issue easily. Thanks!", "Before we simplify the example, could you please test if you can replicate the error with the current code?", "@DanBmh ,\r\nIn order to reproduce the issue, the mentioned code is fairly complex.So it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro or colab gist?", "I found the error. The problem is that I'm using an optimizer with CosineDecaying learning rate schedule. To match the decay steps to the epoch number the steps per epoch are required which I calculated with:\r\n `steps_per_epoch = tf.data.experimental.cardinality(dataset_train).numpy()`\r\n\r\nThis works when the dataset is created with `from_tensor_slices`, but when `from_generator` is used instead, a negative (-2) steps per epoch number is returned. When the schedule is created no error is raised but the network doesn't learn then.", "@DanBmh ,\r\nCan you please provide the reproducible code or the colab gist to debug the issue.Thanks!", "You can still find it at: https://gitlab.com/DANBER/Pingoora\r\nI now have deleted most extra parts, except the datasets and training related scripts.", "@DanBmh ,\r\nWithout the reproducible code, it would be difficult for us to debug the issue.There are multiple files of code available in the link mentioned.So we request you to post `**only reproducible code**` which you are facing issue.It helps to analyse the issue.If you are unable to provide exact code which you are facing the issue please feel free to post in tf discussion forum.Thanks!", "The linked code contains only the scripts to train the train the network with which I'm facing the learning problem. If you follow the readme steps to run a training you should be able to reproduce the problem.\r\n\r\nBut as I wrote above the problem seems to be that one dataset generation method keeps the length information and the other doesn't:\r\n```python3\r\nimport tensorflow as tf\r\nlabels = [{\"a\": \"aa\"}, {\"a\": \"aaa\"}, {\"a\": \"aaaa\"}]\r\n\r\noutput_types = {\"a\": tf.string}\r\nds = tf.data.Dataset.from_generator(lambda: iter(labels), output_types=output_types)\r\nprint(tf.data.experimental.cardinality(ds).numpy())\r\n# -2\r\n\r\nlabels2 = {k: [dic[k] for dic in labels] for k in labels[0]}\r\nds = tf.data.Dataset.from_tensor_slices(labels2)\r\nprint(tf.data.experimental.cardinality(ds).numpy())\r\n# 3\r\n```\r\n\r\nAnd later on I used this value to create a learning rate schedule, which accepted the negative decay steps value, but didn't work for training the network.\r\n```python3\r\nfrom tensorflow.keras.optimizers import schedules\r\nsteps_per_epoch = tf.data.experimental.cardinality(ds).numpy()\r\nlearning_rate = 0.001\r\nconfig = {\"training_epochs\": 200}\r\n\r\nlr_schedule = schedules.CosineDecay(\r\n    initial_learning_rate=learning_rate,\r\n    decay_steps=config[\"training_epochs\"] * steps_per_epoch,\r\n)\r\n```\r\n", "On running the given code snippet, I am facing an error stating `NameError: name 'learning_rate' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/509ed5ace38e4db5cf79b7c92dff7b7d/untitled164.ipynb).", "The learning rate is just some small value. I updated the comment above.", "@DanBmh ,\r\nOn running the given code snippet, I am facing an error stating NameError: name 'config' is not defined. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/cd8e558cefc2eacf10b62792adaa9154/untitled166.ipynb).", "Sorry. Updated the config definition in the snippet above.", "@DanBmh ,\r\nI was not able to find any issue or error while executing the given code.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/b50514cb7e78a956f33665a3efd8e3bc/untitled169.ipynb).Can you please provide the error log you are facing while running the code.It helps to debug the issue.Thanks!", "> I was not able to find any issue or error while executing the given code\r\n\r\nThat's the problem. That you can initialize the schedule with a negative _decay_steps_ value, which results in the optimizer not optimizing the network, but doesn't raise an error.", "From the tf.data side, it is expected that the cardinality of `Dataset.from_generator()` is [unknown](https://www.tensorflow.org/api_docs/python/tf/data/experimental#UNKNOWN_CARDINALITY). There's isn't a good way to determine how much data a given generator will produce. The generator could be infinite or produce random amounts of data.\r\n\r\nIt does seem strange that CosineDelay allows a negative number of decay steps without producing an error. It may be worth creating new issue or sending a PR for that problem specifically.", "As a stop gap, if the number of elements produced by the generator is known, then the tf.data `assert_cardinality` could be used to provide the cardinality information, which should resolve the learning issue."]}, {"number": 53279, "title": "Unsupported data type 14 in tensor", "body": "Hi,\r\nI recently converted my custom LSTM model from TensorFlow '2.7.0' to TensorFlow lite so I can implement it on a Android Device  But, when I tried to test it I got this error 'Unsupported data type 14 in tensor'.\r\nCan anyone help me understand this error?\r\n\r\nHere is code for converting model to tflite\r\n'''\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(TRAIN_MODELS_DIR)\r\nconverter.post_training_quantize=True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n'''\r\n", "comments": ["And yes data type of the tflite  is float32", "@sushreebarsa   I am working with Ankush and we are hoping you can help us.   The code that creates this error is when the Interpreter is being created.   \r\n\r\n\r\n    \r\n```\r\n         lstmModel = FileUtil.loadMappedFile(activity, \"lstm_lookLearn_classifier.tflite\");\r\n\r\n\r\n        // Create a TFLite interpreter instance\r\n        lstmTflite = new Interpreter(lstmModel, tfliteOptions);\r\n```\r\n\r\n\r\n\r\nNote that this is our Android gradle file:\r\n\r\n\r\n```\r\n    /* TensorFlow Lite 2.0+ */\r\n    implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') {changing = true}\r\n    implementation('org.tensorflow:tensorflow-lite-support:0.0.0-nightly') {changing = true}\r\n    implementation('org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly') {changing = true}\r\n```", "@sushreebarsa   \r\n\r\nAlso, note that the exact same model architecture but trained a number of months ago (with a different version of TFLite for conversion) is able to run with this exact same code.   So, there seems to be some kind of issue either in the latest TFLite conversion or support with our tensorflowlite in Android.\r\n", "@AnkushMahajan1,\r\n\r\nCan you share the complete stand-alone code to reproduce this issue? Thanks!", "@sanatmpa1 the github is located at [https://github.com/grewe/USquat](https://github.com/grewe/USquat )\r\n\r\nAnd this is happening with the 2 new models we are trying to load and create Interpreter instances of.  One is the LSTM model that we reported the issue on and the other is another newly created Object Detection API EfficientDet model.   \r\n\r\nThe LSTM model is being created in this [**Classifier.java class**](https://github.com/grewe/USquat/blob/main/app/src/main/java/com/edu/usquat/Classifier/Classifier.java) .   Particuarly see these lines 235-244.   Note it the  line **lstmTflite = new Interpreter(lstmModel, tfliteOptions);** using the lstmModel tied to the new lstm_lookLearnclassifier.tflite file which causes the error in the code snippet following from Classifier.java.   The old model lstm_classifier.tflite works perfectly fine.  Unfortunately, we do not know what combination of tensorflow version was used for training and at that time we had to use tf-nightly to get it to work for TFlite conversion.   As stated above we are trying to use version 2.7.0 for tensorflow training and again have used this for TFlite conversion.\r\n\r\n```\r\n\r\n//Now decide on the Model to use for LSTM - orginal (kelly) or LookLEarn(ankush)\r\n        if(this.mUSquatModel.contains(\"Original\"))\r\n            lstmModel = FileUtil.loadMappedFile(activity, \"lstm_classifier.tflite\");\r\n        else\r\n        //    lstmModel = FileUtil.loadMappedFile(activity, \"lstm_classifier.tflite\");    //flipping back and forth for testing delete later\r\n           lstmModel = FileUtil.loadMappedFile(activity, \"lstm_lookLearn_classifier.tflite\");\r\n\r\n\r\n        // Create a TFLite interpreter instance\r\n        lstmTflite = new Interpreter(lstmModel, tfliteOptions);\r\n```\r\n\r\n\r\nThe other newly created model that is also failing giving the same error is an Object Detector EfficientDet model  and it is being  created in the [LookLearnProcessor.java code](https://github.com/grewe/USquat/blob/main/app/src/main/java/com/edu/usquat/LookLearn/LookLearnProcessor.java)\r\nSee line 248 where it says:\r\n```\r\n\r\n         detector =\r\n                    (TFLiteObjectDetectionEfficientDet) TFLiteObjectDetectionEfficientDet.create(\r\n                            context.getAssets(),\r\n                            TF_OD_API_MODEL_FILE,\r\n                            TF_OD_API_LABELS_FILE,\r\n                            TF_OD_API_INPUT_SIZE,\r\n                            TF_OD_API_IS_QUANTIZED);\r\n```\r\n\r\n", "@sanatmpa1 the github is located at https://github.com/grewe/USquat\r\n\r\nAnd this is happening with the 2 new models we are trying to load and create Interpreter instances of. One is the LSTM model that we reported the issue on and the other is another newly created Object Detection API EfficientDet model.\r\n\r\nThe LSTM model is being created in this Classifier.java class . Particuarly see these lines 235-244. Note it the line lstmTflite = new Interpreter(lstmModel, tfliteOptions); using the lstmModel tied to the new lstm_lookLearnclassifier.tflite file which causes the error in the code snippet following from Classifier.java. The old model lstm_classifier.tflite works perfectly fine. Unfortunately, we do not know what combination of tensorflow version was used for training and at that time we had to use tf-nightly to get it to work for TFlite conversion. As stated above we are trying to use version 2.7.0 for tensorflow training and again have used this for TFlite conversion.\r\n\r\n```\r\n//Now decide on the Model to use for LSTM - orginal (kelly) or LookLEarn(ankush)\r\n        if(this.mUSquatModel.contains(\"Original\"))\r\n            lstmModel = FileUtil.loadMappedFile(activity, \"lstm_classifier.tflite\");\r\n        else\r\n        //    lstmModel = FileUtil.loadMappedFile(activity, \"lstm_classifier.tflite\");    //flipping back and forth for testing delete later\r\n           lstmModel = FileUtil.loadMappedFile(activity, \"lstm_lookLearn_classifier.tflite\");\r\n\r\n\r\n        // Create a TFLite interpreter instance\r\n        lstmTflite = new Interpreter(lstmModel, tfliteOptions);\r\n```\r\nThe other newly created model that is also failing giving the same error is an Object Detector EfficientDet model and it is being created in the LookLearnProcessor.java code\r\nSee line 248 where it says:\r\n\r\n```\r\n         detector =\r\n                    (TFLiteObjectDetectionEfficientDet) TFLiteObjectDetectionEfficientDet.create(\r\n                            context.getAssets(),\r\n                            TF_OD_API_MODEL_FILE,\r\n                            TF_OD_API_LABELS_FILE,\r\n                            TF_OD_API_INPUT_SIZE,\r\n                            TF_OD_API_IS_QUANTIZED);\r\n```", "@sushreebarsa @sanatmpa1 We are stuck on this issue and please need your guidance.", "@sachinprasadhs  It would be great if we could get some traction on this issue --more than reassignment --- is it possible for you to look at this?\r\n\r\n", "If you are not using the latest Tensorflow and TensorFlow Lite runtime version please upgrade to the latest and try again.", "@sachinprasadhs We are using the latest and have also tried an earlier version.   Neither\r\nwork and the error is as reported.\r\n\r\nLynne Grewe |  Professor Computer Science, Director iLab |  California\r\nState University East Bay |\r\n***@***.*** ***@***.***>  *\r\n\r\n\r\n\r\n\r\n\r\nOn Wed, Dec 8, 2021 at 2:43 PM sachinprasadhs ***@***.***>\r\nwrote:\r\n\r\n> If you are not using the latest Tensorflow and TensorFlow Lite runtime\r\n> version please upgrade to the latest and try again.\r\n>\r\n> \u2014\r\n> You are receiving this because you commented.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/53279#issuecomment-989286949>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/ACZ6SXRZXGCTA5TZS6ROU6LUP7NSHANCNFSM5JF4EMZQ>\r\n> .\r\n> Triage notifications on the go with GitHub Mobile for iOS\r\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\r\n> or Android\r\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\r\n>\r\n>\r\n", "I'm facing the same issue.\r\n\r\n### Error\r\n```\r\nTraceback (most recent call last):\r\n  File \"detect.py\", line 8, in <module>\r\n    interpreter = tf.lite.Interpreter(model_path=\"models/saved_model.tflite\")\r\n  File \"/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py\", line 209, in __init__\r\n    model_path, self._custom_op_registerers))\r\nValueError: Unsupported data type 14 in tensor\r\nUnsupported data type 14 in tensor\r\nUnsupported data type 14 in tensor\r\nUnsupported data type 14 in tensor\r\nUnsupported data type 14 in tensor\r\nUnsupported data type 14 in tensor\r\n\r\n```\r\n", "@sachinprasadhs @gaurxvreddy    Please note my previously converted TFLite models still work (but, do not know what version used to convert) and the NEWLY converted TFLite models do not ---and tried with a few different Tensorflow versions specified in  Android build gradle file .     The odd thing is I did try for my new models to retrain them and convert with a lower version too -- for version 2.6  just to see if maybe the TFLite was the issue but got different errors.   \r\n\r\nAND NOTE this is for both a CNN and a LSTM model that both previously worked.\r\n\r\nDo not know how to go about fixing this", "@grewe Actually I'm working arounf with Object Detection. It doesn't work either.\n\nI recommend you to try **tflite-runtime**\n\n```\nimport tflite_runtime.interpreter as tflite\n\ninterpreter = tflite.Interpreter(model_path=args.model_file)\n```", "> @grewe Actually I'm working arounf with Object Detection. It doesn't work either.\n> \n> I recommend you to try **tflite-runtime**\n> \n> ```\n> import tflite_runtime.interpreter as tflite\n> \n> interpreter = tflite.Interpreter(model_path=args.model_file)\n> ```\n\nhttps://www.tensorflow.org/lite/guide/python\n\nfollow the link\n\n> It didn't quite work for me. I got more error when I've done this. You may give it a try and see !!\n\n> And also @grewe, please let me know if you somehow figure out this.\n\nThanks", "Hi @AnkushMahajan1 ! Did you try with latest Tflite version yet?", "Hey @mohantym I was running it on  Tensorflow version 2.7.0 ", "@AnkushMahajan1 ! I was able to run  both tflite models [lstm_classifier.tflite and lstm_lookLearn_classifier.tflite](https://github.com/tensorflow/tensorflow/issues/53279) in interpreter though. Attaching gist for [reference](https://colab.sandbox.google.com/gist/mohantym/717a7f41383b54f9e04cb476b04ef068/git_53279.ipynb#scrollTo=HX5JgWbV7-z-). Thanks!", "> @AnkushMahajan1 ! I was able to run both tflite models [lstm_classifier.tflite and lstm_lookLearn_classifier.tflite](https://github.com/tensorflow/tensorflow/issues/53279) in interpreter though. Attaching gist for [reference](https://colab.sandbox.google.com/gist/mohantym/717a7f41383b54f9e04cb476b04ef068/git_53279.ipynb#scrollTo=HX5JgWbV7-z-). Thanks!\r\n\r\n- Hi! @mohantym  Actually, they both work with using **tensorflow**.  But the model [lstm_lookLearn_classifier.tflite] didn't work with **tflite-runtime**. And the model [lstm_classifier.tflite] works with **tflite-runtime** . ", "@hughjackman111 !I was able to load **lstm_lookLearn_classifier.tflite and lstm_classifier.tflite** with tflite-runtime 2.7. Please check the updated [gist](https://colab.sandbox.google.com/gist/mohantym/717a7f41383b54f9e04cb476b04ef068/git_53279.ipynb#scrollTo=jDacsHsh7Q8F). Thanks!", "> @hughjackman111 !I was able to load **lstm_lookLearn_classifier.tflite and lstm_classifier.tflite** with tflite-runtime 2.7. Please check the updated [gist](https://colab.sandbox.google.com/gist/mohantym/717a7f41383b54f9e04cb476b04ef068/git_53279.ipynb#scrollTo=jDacsHsh7Q8F). Thanks!\r\n\r\nHi! @mohantym I mean you should try to load **lstm_lookLearn_classifier.tflite** without **\"import tensorflow as tf\"**. Please look this [gist](https://colab.research.google.com/drive/1Gqhsa2smR33JTqFwTPqICYnJhhCWbIQm#scrollTo=JVEcyEK_fkQY).  Thanks!", "Yeah. I am getting a [select ops error](https://colab.sandbox.google.com/gist/mohantym/41dc6053a9bab2da4d7e33bfe825c70f/git_53279.ipynb#scrollTo=sAPN4NI27h9n) without doing \"import tensorflow as tf\" . But Select ops issues gets mostly resolved by adding [select ops](https://www.tensorflow.org/lite/guide/ops_select) before converting to tflite model. @hughjackman111 @AnkushMahajan1 ! Can you let us know the results after using select ops and adding select ops dependencies in build.gradle() ? Thanks!", "I have a custom model which has LSTM layers which produces the same error when creating an Interpreter in android studio. @grewe any updates on the error and its solution?"]}, {"number": 53278, "title": "inaccurate tflite model", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installation (pip package or built from source): 2.7.0\r\n- TensorFlow library (version, if pip package or github SHA, if built from source):\r\n\r\n### 2. Code\r\n\r\n```\r\n# h5 model (correct)\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndata = np.ones((1, 320, 160, 6), dtype=np.float32)\r\nmodel = tf.keras.models.load_model(\"model_float32.h5\")\r\nmodel.predict(data)\r\n```\r\n\r\n```\r\n# tflite full integer quantization model (incorrect)\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=\"model_quant_uint8.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ninterpreter.set_tensor(input_details[0]['index'], np.ones((1, 320, 160, 6), dtype=np.uint8))\r\ninterpreter.invoke()\r\n\r\ninterpreter.get_tensor(output_details[0]['index'])\r\n```\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\n- Model produces wrong results and/or has lesser accuracy.\r\n\r\n### 4. (optional) RNN conversion support\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nlinks to models:\r\nhttps://www.dropbox.com/s/pssd04thvgndo74/model_float32.h5?dl=0\r\nhttps://www.dropbox.com/s/fpititzzwcsdmi2/model_float32.tflite?dl=0\r\nhttps://www.dropbox.com/s/k88obxfdb3uowov/model_quant_uint8.tflite?dl=0", "comments": ["@dillon3344 ,\r\nCan you please provide the results of the model to confirm the issue.It helps to analyse and debug the issue.Thanks!", "sure, here you go\r\n\r\nmodel_float32.h5:\r\narray([[-0.46984792, -0.66950595,  0.11530206, -0.22769381,  0.01552141,\r\n         0.4539524 , -0.3669256 , -0.37643647, -0.7434101 , -2.128694  ,\r\n        -2.1474993 , -1.2708825 ,  0.06638837, -0.42041272,  0.04785721,\r\n         0.05974752,  0.03060281, -1.2504989 , -2.8112397 , -3.0098703 ,\r\n        -5.9330635 ,  0.11274323, -0.3211678 ,  0.0370754 ,  0.06911968,\r\n         0.03069666, -1.1859107 , -2.9226751 , -3.081397  , -5.8313227 ,\r\n         0.15223   ,  0.48501986,  0.43894255,  0.5286782 ,  0.99422544,\r\n         0.7068051 ,  0.921492  ,  0.01947963,  0.05753902]],\r\n      dtype=float32)\r\n\r\nmodel_quant_uint8.tflite:\r\narray([[209, 217, 228, 216, 226, 248, 124, 121, 107,  72,  50,  96, 254,\r\n        206, 224, 226, 223,  87,  41,  40,   0, 240, 212, 224, 226, 224,\r\n         83,  37,  39,   0, 249, 244, 244, 239, 239, 222, 254, 226, 223]],\r\n      dtype=uint8)", "@sanatmpa1 ,\r\nI was able to reproduce the issue in tf v2.5, v2.7 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/eb873ac1fa6dc6175bcc650ed5000867/53278.ipynb).", "@sanatmpa1 any update?", "@sachinprasadhs any update?", "Can you try with the post training quantization by referring [this](https://www.tensorflow.org/lite/performance/post_training_quantization) documentation, also quantization is subjected to loss of accuracy, you can check if the difference in accuracy is in acceptable range [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks).", "I've had this issue on all models. Even Resnet 50.\r\nIt appears to be compounded with more ops, so I have some models using  less ops (eg. MobileNet) that perform 'adequately'. Although I believe the issue still exists there.\r\nIs there a version where this quantization works correctly? I can quantize my model to INT8 on other frameworks (such as PyTorch et al) and I get almost identical accuracy to the FP32 version. The problem is I need the model in Tensorflow Lite.\r\n\r\nStrangest part is the more samples I give the quantization, the worse the quantized result becomes.\r\nSamples = 2, max error = 0.5\r\nSamples = 10, max error = 0.7\r\nSamples = 100, max error = 1.0\r\nSamples = 4000, max error = 1.244\r\nMy tolerance is: max error < 0.001\r\nwhere max_error = np.max(tflite_out - tf_out)\r\n\r\nAnd it's consistent with every model I've ever tried.\r\n\r\nMy conversion script: https://pastebin.com/raw/qAD0H7dQ\r\n\r\nI've tried every tutorial I can find already and converted from PB/Flat butter, Keras and other formats.\r\n\r\nQuantize debugger results from most accurate attempt on IR_50 (samples=2):\r\nhttps://pastebin.com/KeKq15W8\r\n\r\nWorst offending ops (RMSE/Scale > 0.5):\r\n```\r\n     op_name      range  rmse/scale                                        tensor_name\r\n2        MUL  52.183345    0.899640        model/batch_normalization/FusedBatchNormV32\r\n61       MUL  14.878242    0.878859      model/batch_normalization_8/FusedBatchNormV32\r\n171  CONV_2D   4.780288    0.559399  model/conv2d_51/BiasAdd;model/conv2d_51/Conv2D...\r\n\r\n```", "@sachinprasadhs i have applied post training quantization. Is there a way to compare the outputs of each layer with the known good model to find where the problem is? ", "You can compare the model with the final outputs using details mentioned [here](https://www.tensorflow.org/lite/guide/faq#how_do_i_test_that_a_tensorflow_lite_model_behaves_the_same_as_the_original_tensorflow_model), not at the layer level though.", "I used the quantize debugger to get the op-by-op accuracy comparison you see above. It takes a bit longer. There's tutorials for how to set it up.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53278\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53278\">No</a>\n", "Issue is definitely not stale.\r\nAny update?", "Thanks for reopening this.\r\nI tested yet another model that exhibits this same issue on Tensorflow 2.8.0rc1.\r\n\r\nI have the Netron graph for before (Keras) and after (Tensorflow Lite int8):\r\n![image](https://user-images.githubusercontent.com/61218/151966818-f8a72458-7c12-4c33-9e78-7864dd15c305.png)\r\nIn the Quantization Debugger, the FusedBatchNormalisationV3(3 and 2) comes out as having the highest error for this model. In the tensorflow lite model these are shown as MUL + ADD but specifically the ADD.\r\n\r\nI'm seriously confused how everyone else has this working because I'm yet to find a working model.\r\n\r\n\r\nIf I remove this line from the Tensorflow Lite conversion, I get no errors in the model:\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\nbut then the model isn't quantized either.\r\n\r\nIs there a way to disable some of these optimisations to ensure they aren't causing the errors?"]}, {"number": 53275, "title": "Model with both complex and real weights does not work with tf.distribute.MirroredStrategy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04, Debian Bullseye\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.5.1-13-g386ce34a1c1 2.5.1\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: 2x V100 32GB\r\n\r\n**Describe the current behavior**\r\nWhen trying to use `tf.distribute.MirroredStrategy` with a model containing both complex and real (float32) weights, the following error is produced:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/storage/tf_complex64_bug.py\", line 67, in <module>\r\n    model2.fit(data)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1178, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:850 train_function  *\r\n        return step_function(self, iterator)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:840 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py:678 _call_for_each_replica\r\n        return mirrored_run.call_for_each_replica(\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\r\n        return _call_for_each_replica(strategy, fn, args, kwargs)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:245 _call_for_each_replica\r\n        coord.join(threads)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:389 join\r\n        six.reraise(*self._exc_info_to_raise)\r\n    /root/miniconda3/lib/python3.8/site-packages/six.py:703 reraise\r\n        raise value\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\r\n        yield\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:238 _call_for_each_replica\r\n        merge_result = threads[0].merge_fn(distribution, *merge_args,\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/utils.py:148 _all_reduce_sum_fn  **\r\n        return distribution.extended.batch_reduce_to(ds_reduce_util.ReduceOp.SUM,\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2402 batch_reduce_to\r\n        return self._batch_reduce_to(reduce_op, value_destination_pairs, options)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py:767 _batch_reduce_to\r\n        return cross_device_ops.batch_reduce(\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py:446 batch_reduce\r\n        return self.batch_reduce_implementation(reduce_op, value_destination_pairs,\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py:874 batch_reduce_implementation\r\n        return self._batch_all_reduce(reduce_op,\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py:887 _batch_all_reduce\r\n        dense_results = self._do_batch_all_reduce(reduce_op, dense_values)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py:910 _do_batch_all_reduce\r\n        device_grad_packs, tensor_packer = _pack_tensors(grouped, self._num_packs)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py:820 _pack_tensors\r\n        device_grad_packs = tensor_packer.pack(device_grads)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/cross_device_ops.py:747 pack\r\n        concat_grads = array_ops.concat(flat_grads, 0)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1768 concat\r\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:1227 concat_v2\r\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n    /root/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:466 _apply_op_helper\r\n        raise TypeError(\"%s that don't all match.\" % prefix)\r\n\r\n    TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, float32, float32, float32, complex64, complex64, float32, float32] that don't all match.\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe model should train successfully\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef complex_uniform_initializer(scale=0.05):\r\n    real_initializer = tf.keras.initializers.RandomUniform(-scale,scale)\r\n    def initializer(shape,dtype):\r\n        if dtype == tf.complex64:\r\n            dtype = tf.float32\r\n        elif dtype == tf.complex128:\r\n            dtype = tf.float64\r\n        real = real_initializer(shape,dtype)\r\n        imag = real_initializer(shape,dtype)\r\n        return tf.dtypes.complex(real,imag)\r\n    return initializer\r\n\r\nclass ComplexDenseLayer(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, out_units, activation=None):\r\n        super().__init__()\r\n        self.out_units = out_units\r\n        self.activation = activation\r\n\r\n    def build(self, input_shape):\r\n        inp_units = input_shape[-1]\r\n        initializer = complex_uniform_initializer()\r\n        self.w = self.add_weight(shape=[inp_units, self.out_units],\r\n                                 initializer = initializer,\r\n                                 dtype=tf.complex64, trainable=True)\r\n        self.b = self.add_weight(shape=[self.out_units],\r\n                                 initializer = initializer,\r\n                                 dtype=tf.complex64, trainable=True)\r\n\r\n    def call(self,inp):\r\n        x = tf.einsum('bi,ij->bj', inp, self.w)\r\n        x = tf.nn.bias_add(x, self.b)\r\n        return self.activation(x)\r\n\r\n    \r\n\r\ndef model(input_units, intermediate_units, output_units):\r\n    inp = tf.keras.layers.Input((input_units,))\r\n    xreal = tf.keras.layers.Dense(intermediate_units)(inp)\r\n    ximag = tf.keras.layers.Dense(intermediate_units)(inp)\r\n    x = tf.cast(xreal, 'complex64') + 1j*tf.cast(ximag,'complex64')\r\n    x = ComplexDenseLayer(intermediate_units, activation = lambda w: w * tf.math.conj(w))(x)\r\n    x = tf.math.real(x)\r\n    x = tf.keras.layers.Dense(output_units)(x)\r\n    return tf.keras.Model(inp,x) \r\n\r\nnsamples = 100\r\nbsize = 10\r\nninp,nintermediate,nout = 16,128,16\r\ninp = np.random.rand(nsamples, ninp)\r\ntar = np.random.rand(nsamples, nout)\r\ndata = tf.data.Dataset.from_tensor_slices((inp,tar)).batch(bsize)\r\n\r\n#Single GPU training works fine\r\nmodel1 = model(ninp,nintermediate,nout)\r\nmodel1.summary()\r\nmodel1.compile(loss='mse', optimizer='adam')\r\nmodel1.fit(data)\r\n\r\n#Distributed training fails\r\ndistribute_strategy =  tf.distribute.MirroredStrategy()\r\nwith distribute_strategy.scope():\r\n    model2 = model(ninp,nintermediate,nout)\r\n    model2.summary()\r\n    model2.compile(loss='mse', optimizer='adam')\r\n    model2.fit(data)\r\n```\r\n", "comments": ["@aligirayhanozbay \r\nCould you please try with TensorFlow  latest stable version v2.7 and let us know if you are facing the same error. Thanks!\r\n", "@tilakrayal I currently cant test it with 2.7 GPU version as the only machine with multiple physical GPUs I have access to permits TF installation via conda. On that machine I tested the same script as above with TF 2.6.2 and the issue persists. \r\n\r\nOn CPU TF 2.7 I can confirm that on the CPU version the issue exists with `cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()`\r\n\r\nHowever, I found that setting `cross_device_ops=tf.distribute.ReductionToOneDevice()` fixes the issue both with GPU TF 2.6.2 and CPU TF 2.7.", "I was able to run the sample code you have provided without any issues in Tensorflow 2.7, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/c957319d59826eda5da65ee6fb67270a/53275.ipynb) and confirm. Thanks!", "@sachinprasadhs \r\n\r\nI can confirm that the issue still exists in Tensorflow 2.7 but with GPU only it seems. [Please see this modified version of the gist.](https://colab.research.google.com/gist/aligirayhanozbay/7ab0fcde7435f3de40cd74ba9b5b3688/53275.ipynb)\r\n\r\n(Note that a GPU colab session and `cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()` is necessary to reproduce the issue with 2 logical GPUs. I can reproduce this on a local machine with the default `cross_device_ops` _only_ if there are two physical GPUs present)", "@sachinprasadhs This issue still exists in Tensorflow 2.8, as seen in [the gist from my previous post](https://colab.research.google.com/gist/aligirayhanozbay/7ab0fcde7435f3de40cd74ba9b5b3688/53275.ipynb). Do you know if it may be fixed any time soon? Here's the stack trace from Colab:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 236, in _call_for_each_replica\r\n    **merge_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\r\n    return converted_call(f, args, kwargs, options=options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\r\n    return _call_unconverted(f, args, kwargs, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\r\n    return f(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\", line 152, in _all_reduce_sum_fn\r\n    grads_and_vars)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2456, in batch_reduce_to\r\n    return self._batch_reduce_to(reduce_op, value_destination_pairs, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 768, in _batch_reduce_to\r\n    options=self._communication_options.merge(options))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 444, in batch_reduce\r\n    options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 872, in batch_reduce_implementation\r\n    [v[0] for v in value_destination_pairs])\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 884, in _batch_all_reduce\r\n    dense_results = self._do_batch_all_reduce(reduce_op, dense_values)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 907, in _do_batch_all_reduce\r\n    device_grad_packs, tensor_packer = _pack_tensors(grouped, self._num_packs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 817, in _pack_tensors\r\n    device_grad_packs = tensor_packer.pack(device_grads)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 744, in pack\r\n    concat_grads = array_ops.concat(flat_grads, 0)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 458, in _apply_op_helper\r\n    raise TypeError(f\"{prefix} that don't all match.\")\r\nTypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, float32, float32, float32, complex64, complex64, float32, float32] that don't all match.\r\n\r\n---------------------------------------------------------------------------\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n[<ipython-input-1-f6e3c733669f>](https://localhost:8080/#) in <module>()\r\n     83     model2.summary()\r\n     84     model2.compile(loss='mse', optimizer='adam')\r\n---> 85     model2.fit(data)\r\n\r\n1 frames\r\n\r\n[/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\n[/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py](https://localhost:8080/#) in autograph_handler(*args, **kwargs)\r\n   1145           except Exception as e:  # pylint:disable=broad-except\r\n   1146             if hasattr(e, \"ag_error_metadata\"):\r\n-> 1147               raise e.ag_error_metadata.to_exception(e)\r\n   1148             else:\r\n   1149               raise\r\n\r\nTypeError: in user code:\r\n\r\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\r\n        return step_function(self, iterator)\r\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\r\n        raise value\r\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\", line 152, in _all_reduce_sum_fn  **\r\n        grads_and_vars)\r\n\r\n    TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [float32, float32, float32, float32, complex64, complex64, float32, float32] that don't all match.\r\n```"]}, {"number": 53271, "title": "Code completion of Keras Module no longer work since 2.6", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 20H2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1/\r\n- Python version: 3.8.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version:  N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nCode completion is no longer work for `tf.keras` on the VSCode. since TensorFlow 2.6.\r\n![image](https://user-images.githubusercontent.com/6873761/144241798-4239b2ac-39b4-4c96-98ca-7c89918900e1.png)\r\n\r\n**Describe the expected behavior**\r\nCode completion is work for `tf.keras` on the VSCode until TensorFlow 2.5.\r\n![image](https://user-images.githubusercontent.com/6873761/144241133-3a2f04f8-3513-491e-8a43-243666c4d164.png)\r\n\r\nA related issue found #52031.\r\nThe cause of this problem is lazy import of Keras.\r\nA similar problem exists in TensorFlow Probability.\r\n\r\nOne solution is to prepare a stub file, but that is a lot of work.\r\nAre you aware that this problem is a VSCode/Pylance problem?\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n- Do you want to contribute a PR? (yes/no): yes, but I don't have a solution.\r\n- Briefly describe your candidate solution(if contributing): N/A.\r\n", "comments": ["It also doesn't work in PyCharm, I opened issue here #53144\r\n\r\nAt first I was using Visual Studio to write tensorflow python code, but then I switched to PyCharm because code completion was broken and I thought it was Visual Studio issue. Now I see that writing tensorflow keras code is absolutely broken in every major IDE.\r\n\r\nI can't believe so few people are complaining about this, what IDE are other people using to write tensorflow code, notepad++? :D", "> I can't believe so few people are complaining about this, what IDE are other people using to write tensorflow code, notepad++? :D\r\n\r\nVim :P\r\n\r\nBut coming back to the issue, I think this is due to the keras moving to a separate repository. Probably the solution would also come from there.", "> But coming back to the issue, I think this is due to the keras moving to a separate repository. Probably the solution would also come from there.\r\n\r\nI think so.\r\nAnd also currently Keras is not work code completion too.\r\nThis is very similarly with this issue.", "@elda27 try my solution.\r\n https://github.com/tensorflow/tensorflow/issues/53144#issuecomment-985179600", "@cpuimage \r\nThanks.\r\nA module completion such as `from tensorflow.keras import ~` is works good.\r\nBut `tf.keras.~` is not work code completions.\r\n\r\nCan you work completion about `tf.keras.~` on the PyCharm.\r\nMy VSCode is not work code completion after changes.\r\n\r\nMaybe PyCharm is more intelligence.", "@cpuimage Oh nice! maybe my work is something wrong.\r\nI will read again your posts.\r\n\r\nBy the way, I found good feature in PEP563.\r\nhttps://www.python.org/dev/peps/pep-0563/#runtime-annotation-resolution-and-type-checking\r\n\r\nThere are example code in the document.\r\n\r\n```python\r\nimport typing\r\n\r\nif typing.TYPE_CHECKING:\r\n    import expensive_mod\r\n\r\ndef a_func(arg: expensive_mod.SomeClass) -> None:\r\n    a_var: expensive_mod.SomeClass = arg\r\n    ...\r\n```\r\n\r\nThis code is work good in the VSCode. (I'm not check on the PyCharm)\r\n``` python\r\nimport typing\r\nif typing.TYPE_CHECKING:\r\n  from tensorflow import keras\r\nelse:\r\n  _keras_module = \"keras.api._v2.keras\"\r\n  keras = _LazyLoader(\"keras\", globals(), _keras_module)\r\n  _module_dir = _module_util.get_parent_dir_for_name(_keras_module)\r\n  if _module_dir:\r\n    _current_module.__path__ = [_module_dir] + _current_module.__path__\r\n  setattr(_current_module, \"keras\", keras)\r\n```", "> @cpuimage Oh nice! maybe my work is something wrong. I will read again your posts.\r\n> \r\n> By the way, I found good feature in PEP563. https://www.python.org/dev/peps/pep-0563/#runtime-annotation-resolution-and-type-checking\r\n> \r\n> There are example code in the document.\r\n> \r\n> ```python\r\n> import typing\r\n> \r\n> if typing.TYPE_CHECKING:\r\n>     import expensive_mod\r\n> \r\n> def a_func(arg: expensive_mod.SomeClass) -> None:\r\n>     a_var: expensive_mod.SomeClass = arg\r\n>     ...\r\n> ```\r\n> \r\n> This code is work good in the VSCode. (I'm not check on the PyCharm)\r\n> \r\n> ```python\r\n> import typing\r\n> if typing.TYPE_CHECKING:\r\n>   from tensorflow import keras\r\n> else:\r\n>   _keras_module = \"keras.api._v2.keras\"\r\n>   keras = _LazyLoader(\"keras\", globals(), _keras_module)\r\n>   _module_dir = _module_util.get_parent_dir_for_name(_keras_module)\r\n>   if _module_dir:\r\n>     _current_module.__path__ = [_module_dir] + _current_module.__path__\r\n>   setattr(_current_module, \"keras\", keras)\r\n> ```\r\n\r\ngood job. it work good in PyCharm.", "@cpuimage Thanks! I haven't been successful your suggestion yet. Maybe VSCode has something difference with PyCharm.\r\n@sanatmpa1 Can you review my solution and please tell us to any one is better for TensorFlow?", "@elda27,\r\n\r\nAs @mihaimaruseac pointed out in this [comment](https://github.com/tensorflow/tensorflow/issues/53271#issuecomment-983828570), it may be due to keras being moved to a different repo. \r\nCan you please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) Thanks!", "@sanatmpa1 This change apply the `tensorflow/__init__.py`.\r\nI guess the issue for tensorflow-team.\r\n"]}, {"number": 53268, "title": "Closing as stale. Please reopen if you'd like to work on this further.", "body": "Closing as stale. Please reopen if you'd like to work on this further.\r\n\r\n_Originally posted by @google-ml-butler[bot] in https://github.com/tensorflow/tensorflow/issues/52214#issuecomment-947901218_", "comments": ["Hi,\r\n\r\nI am also facing the exact problem.\r\nI can do the batch inference on TF 2.4.1 but cannot do that on TF  2.6.2.\r\n\r\nDo you have any idea?\r\nThank you!\r\n\r\nRegards,\r\nTerry", "Hi @terrycmchan ! \r\nCould you please update the [template](https://github.com/tensorflow/tensorflow/issues/new/choose) too as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    [detect_video.py](https://github.com/theAIGuysCode/tensorflow-yolov4-tflite/blob/master/detect_video.py) of [theAIGuysCode/tensorflow-yolov4-tflite](https://github.com/theAIGuysCode/tensorflow-yolov4-tflite)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n    Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n    No\r\n- TensorFlow installed from (source or binary):\r\n    Binary (PyPI)\r\n- TensorFlow version (use command below):\r\n    v2.4.1 and v2.6.2\r\n- Python version:\r\n    3.8.10\r\n- Bazel version (if compiling from source):\r\n    Not suitable\r\n- GCC/Compiler version (if compiling from source):\r\n    Not suitable\r\n- CUDA/cuDNN version:\r\n    NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4\r\n- GPU model and memory:\r\n    (Geforce 3070 ti and 8G) x2\r\n\r\n**Describe the current behavior**\r\n    I was going to run the inference on video \"[detect_video.py](https://github.com/theAIGuysCode/tensorflow-yolov4-tflite/blob/master/detect_video.py)\".\r\n    It was ok when I ran on TF version 2.4.1. However, I found that the code could not be ran on TF version 2.6.2 successfully.\r\n    When running on TF v2.6.2, only the 1st frame could detect object and the rest of frames could not.\r\n", "Ok @terrycmchan !Could you please try again with latest version TF 2.7 with Cuda 11.2 and CuDNN 8.1?", "@mohantym I tested with Tf v2.7.0 with Cuda release 11.2, V11.2.152 and CuDNN 8.1.1. However, the result is still not OK. Only the 1st frame can detect object.", "Hi @sachinprasadhs ! Could you please look at this issue?", "@terrycmchan What error do you see? If possible, can you provide the two models (working/not working)?", "@srjoglekar246 The problem is that:\r\nI was going to run the inference on video.\r\nIt was ok when I ran on TF version 2.4.1. However, I found that the code could not be ran on TF version 2.6.2 and 2.7.0 successfully.\r\nWhen running on TF v2.6.2/v2.7.0, only the 1st frame could detect object and the rest of frames could not.\r\n[results.zip](https://github.com/tensorflow/tensorflow/files/7646337/results.zip)\r\n\r\nYou can get the source from [here](https://drive.google.com/file/d/16Nl4T6p2f9459acT86xclytwxUjFAfuc/view?usp=sharing).\r\nJust run:\r\n`python3 detect_video.py --weights ./checkpoints/yolov4-416 --size 416 --model yolov4 --video ./data/video/video.mp4 --output ./detections/results.avi\r\n`", "I think your code isn't running TFLite, correct? @sachinprasadhs can we route to an appropriate person on the TF side?", "@srjoglekar246 The code is not running on TFLite. It is running on TF.", "@srjoglekar246 @sachinprasadhs @mohantym Any update on this issue?", "@sachinprasadhs @mohantym Any update on this issue? Thanks!", "Hi @terrycmchan ! Sorry for the late response! Team is still investigating this issue. Thank you for your patience!", "Hi @mohantym Would you mind to update the progress?"]}, {"number": 53265, "title": "all_reduce_indexed_slices remove not eager context", "body": "@crccw So why there is a eager runtime error before?\r\n\r\nall_reduce_indexed_slices can be called in eager mode and runs ok in my environment multiworker mirrored strategy.", "comments": []}, {"number": 53260, "title": "float16 constant readout doesn't match with it's original numpy array", "body": "I tried to create float16 constant from numpy array and read it back, but the returned array doesn't match with it's original numpy array. This seems to be happening only at M1 Macs.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 11.3.1 on M1 Mac mini\r\n- TensorFlow installed from (source or binary): Binary (tensorflow-macos)\r\n- TensorFlow version (use command below): unknown 2.5.0\r\n- Python version: 3.8.12\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow.compat.v1 as tf\r\n\r\nnp.random.seed(0)\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    x = np.random.sample([1, 1, 1, 1, 768]).astype(np.float16)\r\n    y = tf.constant(x)\r\n\r\n    x = np.ones([1, 1, 384, 1, 1], dtype=np.float16)\r\n    y = tf.constant(x, name='97f6762f328ca2b7cceaf2851e0c01a6')\r\n    z = y * 3\r\n\r\n    t = sess.graph.get_tensor_by_name('97f6762f328ca2b7cceaf2851e0c01a6:0')\r\n    v = sess.run(t, feed_dict={})\r\n\r\n    #print(x.squeeze())\r\n    #print(v.squeeze())\r\n    assert np.array_equiv(x, v)\r\n```\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 19, in <module>\r\n    assert np.array_equiv(x, v)\r\nAssertionError\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nTwo arrays should be equal.\r\n", "comments": ["@youchangkim,\r\n\r\nIt is working fine when checked with TF `2.7.0` on colab. Here's the [gist](https://colab.sandbox.google.com/gist/sanatmpa1/f1630709d0bdf3db437a4fcd232be6f1/53260.ipynb). Since its not a bug from TF end and you also mentioned that the issue is with M1, Can you try posting your question in this [tf-metal developer forum](https://developer.apple.com/forums/tags/tensorflow-metal) of Apple? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53260\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53260\">No</a>\n", "@cfRod @everton1984 Have you seen similar issues before? Could you please help try this code on other Arm machines as well? I wonder if this is specific to M1.\r\n\r\n@youchangkim Are these lines necessary in producing the error? (We don't have M1s so it's hard for us to test.)\r\n```\r\n    x = np.random.sample([1, 1, 1, 1, 768]).astype(np.float16)\r\n    y = tf.constant(x)\r\n```\r\nAlso, do you see the same error in eager mode?", "@penpornk In the code below, it works fine when I comment out `@tf.function`. So it seems to be a problem with graph execution.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nnp.random.seed(0)\r\n\r\n@tf.function\r\ndef my_func():\r\n    print('tracing')\r\n\r\n    x = np.ones([1, 1, 384, 1, 1], dtype=np.float16)\r\n    y = tf.constant(x, name='97f6762f328ca2b7cceaf2851e0c01a6')\r\n    z = y * 3\r\n\r\n    return z, y\r\n\r\nz, y = my_func()\r\n\r\nprint(y.numpy().squeeze())\r\nassert np.array_equiv(y, np.ones(y.shape))\r\n```\r\n", "> @cfRod @everton1984 Have you seen similar issues before? Could you please help try this code on other Arm machines as well? I wonder if this is specific to M1.\r\n> \r\n> @youchangkim Are these lines necessary in producing the error? (We don't have M1s so it's hard for us to test.)\r\n> \r\n> ```\r\n>     x = np.random.sample([1, 1, 1, 1, 768]).astype(np.float16)\r\n>     y = tf.constant(x)\r\n> ```\r\n> \r\n> Also, do you see the same error in eager mode?\r\n\r\n@penpornk It ran just fine on aarch64 with 2.6.0. I don't have a 2.5.0 binary easily available but I could try compiling my own if you think it's necessary. ", "Same outcome as @everton1984 on the aarch64 machine I have. It ran fine.", "@everton1984 @cfRod Thank you very much for the help! I think 2.6.0 is fine. :)\r\n\r\n@youchangkim Thank you for the quick reply! \r\nWhat is the output of `print(y.numpy().squeeze())`?\r\nCould you please help check if the issue still persist with the latest TF (2.8.0)? (Just in case we are lucky.)\r\n\r\nCan we try if removing each of the following still produces the error?\r\n1. Remove `name='97f6762f328ca2b7cceaf2851e0c01a6'`\r\n2. Removing both `print` statements.\r\n3. Removing `np.random.seed(0)` or setting it to something else.\r\n", "@penpornk I was only able to try 2.7.0 since 2.8.0 requires macOS 12.3 but I'm currently using 11.3. I can try 2.8.0 after I upgrade my OS. Interestingly TF 2.5.0 and 2.7.0 produces different outputs but both are wrong.\r\n\r\nTF 2.5.0\r\n```\r\ntracing\r\n2022-03-09 15:56:44.089426: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n[6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08 6.e-08\r\n 6.e-08 6.e-08 6.e-08 6.e-08]\r\nTraceback (most recent call last):\r\n  File \"test3.py\", line 19, in <module>\r\n    assert np.array_equiv(y, np.ones(y.shape))\r\nAssertionError\r\n```\r\n\r\nTF 2.7.0\r\n```\r\ntracing\r\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\r\nTraceback (most recent call last):\r\n  File \"test3.py\", line 19, in <module>\r\n    assert np.array_equiv(y, np.ones(y.shape))\r\nAssertionError\r\n```\r\n\r\nThings you asked:\r\n\r\n> 1. Remove name='97f6762f328ca2b7cceaf2851e0c01a6'\r\n\r\nFail both 2.5.0 and 2.7.0\r\n\r\n> 2. Removing both print statements.\r\n\r\nFail both 2.5.0 and 2.7.0\r\n\r\n> 3. Removing np.random.seed(0) or setting it to something else.\r\n\r\nFail both 2.5.0 and 2.7.0, and setting seed to 1 doesn't help\r\n\r\nApplying 1, 2, and 3 at the same time also fails.\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef my_func():\r\n    x = np.ones([1, 1, 384, 1, 1], dtype=np.float16)\r\n    y = tf.constant(x)\r\n    z = y * 3\r\n\r\n    return z, y\r\n\r\nz, y = my_func()\r\n\r\nassert np.array_equiv(y, np.ones(y.shape))\r\n```"]}, {"number": 53259, "title": "Added logging statements when data loading was detected", "body": "These logging statements are placed so they will log when data has been loaded.", "comments": ["@LoggingMan  Can you please sign CLA. Thanks!", "@LoggingMan Can you please sign CLA. Thanks!", "@LoggingMan Can you please sign CLA. Thanks!"]}, {"number": 53251, "title": "[TFLite] Support for depth-wise 3D convolution", "body": "Hello,\r\n\r\nTensorFlow Lite currently supports depth-wise convolutions through ` tf.keras.layers.DepthwiseConv2D` and ` tf.nn.depthwise_conv2d` layers that are converted into TFL `DEPTHWISE_CONV_2D` operators.\r\n\r\nSuch specific layers aren't available for 3D depth-wise convolutions but the ` tf.keras.layers.Conv3D` layer has a `groups` parameter that can be set to the same number as the input channels to compute the depth-wise 3D convolution. Such parametrized Conv3D layers are unfortunately not convertible in TFL. The example\r\n```python\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.Sequential(\r\n    [\r\n        tf.keras.layers.InputLayer(\r\n            input_shape=(2, 4, 4, 3), batch_size=1\r\n        ),\r\n        tf.keras.layers.Conv3D(filters=3, kernel_size=(2, 4, 4), groups=3),\r\n    ]\r\n)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_quant_model = converter.convert()\r\n```\r\nerrors-out in TF 2.7.0 with the following message as the TFL `CONV_3D` operator doesn't support the `groups` parameter (it works if the `groups` parameter is removed or set to 1):\r\n```\r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select\r\nTF Select ops: Conv3D\r\n```\r\n\r\nIs there any plan to eventually add  ` tf.keras.layers.DepthwiseConv3D` and ` tf.nn.depthwise_conv3d` layers to TF and later on add a  `DEPTHWISE_CONV_3D` operator in TFL? \r\n\r\nWe could also detect ` tf.keras.layers.Conv3D` configurations that lead to a depth-wise convolution but interestingly the ` tf.keras.layers.Conv2D` layer with a `groups` parameter equals to the number of input channels isn't converted to a TFL `DEPTHWISE_CONV_2D` and the TFL inference errors-out with:\r\n```\r\nRuntimeError: tensorflow/lite/kernels/conv.cc:349 input->dims->data[3] != filter->dims->data[3] (12 != 1)Node number 1 (CONV_2D) failed to prepare.\r\n```\r\n\r\nSuch cases could be detect for both `Conv2D` and `Conv3D` in the TFL converter so that a `DEPTHWISE_CONV_2/3D` is generated instead.\r\n\r\n\r\nThibaut", "comments": ["Hi @Tessil ! \r\nCould you please update the template too as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "@jianlijianli for visibility", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@mohantym Thanks, I added a small example though the post is more of a feature request for `tf.keras.layers.DepthwiseConv3D` and `tf.nn.depthwise_conv3d` layers in TF and `DEPTHWISE_CONV_3D` operator in TFLite than an issue per se.", "Hi @sachinprasadhs ! Could you please look at this  feature request?", "There is exact same issue created by you here #53315, you can change it to feature request and track it there. Closing this issue here.", "@sachinprasadhs Sorry I'm a bit confused as both issues are quite different, one is for channel first support conversion in 3D operators and this one is for depth-wise 3D convolution support. Would it be possible to keep this issue open? Thanks!"]}, {"number": 53247, "title": "Quantized model demonstrates bad performance on DSP compared to CPU", "body": "I trained the same binary segmentation model with the same architecture with TF2.2.0 vs TF2.4.0.\r\nI converted the 2.4.0 model to a quantized TFlite and got inferior performance on DSP compared to CPU. \r\nBy inferior performance, I mean that most of the maps are empty / contain very few white pixels, while the maps on the CPU seem as expected. \r\nThe 2.2.0 model (2.2.0) showed similar results on both CPU and DSP.   \r\n\r\nWhat can be the problem?\r\n\r\n", "comments": ["Hi @aviaisr! \r\nCould you please update the template too as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "### 1. System information\r\n\r\nTensor flow versions: 2.2.0 vs. 2.4.0\r\n\r\n### 2. Code\r\n\r\nI copied the main training lines of both training sessions to this notebook:\r\nNote 1st model trained with TF 2.2.0:quantized tflite model demonstrates the similar segmentation outputs on CPU and DSP.\r\n2nd model trained with TF2.4.0: quantized tflite model demonstrates bad output maps on the DSP and the results don\u2019t match the CPU outputs.\r\nhttps://colab.research.google.com/drive/14rghRb2-0kknbCfSnxcU3WR4mI8mL9La?usp=sharing\r\n\r\n### 3. Failure after conversion\r\nThe conversion is successful, but the generated model gives bad results on DSP\r\n![image](https://user-images.githubusercontent.com/39811082/144209418-1c3ee009-f240-423b-af84-db52e0897906.png)\r\n", "Ok @aviaisr ! Above notebook seems to be restricted. Did you check in latest version TF 2.7 too?", "I updated the link to the notebook. Can you please try again?\r\nhttps://colab.research.google.com/drive/14rghRb2-0kknbCfSnxcU3WR4mI8mL9La?usp=sharing\r\n\r\nI'm currently checking TF2.7. \r\nI'll post the results soon.", "I uploaded the Keras hdf5 file (trained with 2.4) + quantized TFLite file to:\r\nhttps://drive.google.com/drive/folders/1IoUiItzZ1ePoQCQmH0Yy2EA7eCiEq9Fo?usp=sharing\r\n\r\n", "BTW, I tried converting from Keras to quantized TFLite with TF2.7 the model I trained with 2.4, which shows the difference between DSP and CPU, and got empty maps on both HWs", "Hi @sachinprasadhs ! Could you please look at this issue?", "Could you please train the model in the latest version and try again, this can be due to the changes made in the saved models after Tensorflow version 2.4.", "I ran a short training with TF2.7 and I do see matching results DSP vs CPU after saving the HDF5 and converting to quantized TFLite.\r\n![image](https://user-images.githubusercontent.com/39811082/145179616-5ea84690-6b87-428f-97c1-8327c19ddf09.png)\r\n\r\nMy model was trained for over a month over millions of images. Any chance I can do something to fix this issue in the existing model without re-training it?", "Hi,\r\nAny chance you can help me with the model I already trained on 2.4? It was trained for over a month and I need it to work soon. Re-training will take a lot of time.\r\nThanks.", "Update - I tried to train my model with the large (4.5M) images and checked the results ~20 epochs - and the CPU DSP results were completely different as well with **TF version 2.7**. So updating the version didn't solve the problem. What should I do?\r\n![image](https://user-images.githubusercontent.com/39811082/146264788-9a40782f-542b-42fe-90c0-75edc925663f.png)\r\n\r\n", "Hi,\r\nI continued debugging and tried training different versions and I suspect that the problem is different. I get matching results CPU and DSP when the maps contains low values, and none matching results when the maps contain high values. Hence, I suspect it is an overflow issue and that the values are being clamped. "]}, {"number": 53245, "title": "[Feature Request] Make tf.unique operations return mask", "body": "**System information**\r\n- TensorFlow version (you are using): 2.7 (request independent of version)\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\ntf.unique (also tf.raw_ops versions) return the indices of first occurrence for each element in a tensor as well as the unique\r\nelements themselves. In addition, I would like the API to return a boolean_mask. The reason is that I need to filter the values of a \r\ntensor B depending on the unique values of a tensor A. Right now I need to construct the mask from indices which is tedious,\r\nerror-prone, not very clean and slower since the result is basically already computed. \r\n\r\n**Will this change the current api? How?**\r\nYes. tf.raw_ops.Unique* methods accept an additional parameter \"return_mask\" with \"False\" as default. Using \"True\" an additional\r\noutput \".mask\" is included in the result.\r\n\r\n**Who will benefit with this feature?**\r\nPeople who would like to filter a set of tensors based on the result of another.", "comments": ["@tilakrayal I can implement this. Do you thing that it will be worth it ?", "You could use [tf.sequence_mask](https://www.tensorflow.org/api_docs/python/tf/sequence_mask) to mask the output of `tf.unique`. Let us know if this is the operation if you were looking for. Thanks!", "Hello, unfortunately this does not seem to solve the problem in a straightforward manner. Let me introduce an example.\r\n\r\n```python\r\narray = [0, 1, 2, 3, 0, 1, 2, 3] \r\nidx = tf.unique(array).idx\r\n```\r\n\r\n`idx` then equals `array` since the values of the first 4 elements match the array index. I could not come up with a solution using `tf.sequence_mask`. From the example above, the desired output should be a boolean equivalent of `[1, 1, 1, 1, 0, 0, 0, 0]` \r\nto be used with `tf.boolean_mask`."]}, {"number": 53244, "title": "[PluggableDevice] AsyncOpKernel", "body": "This PR is adding kernel C API for `AsyncOpKernel`. The main difference with `OpKernel` is `void (*compute_async_func)(void*, TF_OpKernelContext*, TF_DoneCallback*)` function with an additional `TF_DoneCallback` param.", "comments": ["Hi @penpornk , can you take a look at this PR? The `AsyncOpKernel` C API is almost the same as `OpKernel`, with an additional `TF_DoneCallback` param. Thanks!", "@penpornk Could you please help to review this PR?"]}]