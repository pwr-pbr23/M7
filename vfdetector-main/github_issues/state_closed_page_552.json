[{"number": 37156, "title": "Tensorflow 2 installation problem in windows 10", "body": "(base) C:\\Windows\\system32>pip install tensorflow\r\nCollecting tensorflow\r\n  Using cached tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8 MB)\r\nRequirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\r\nRequirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\r\nRequirement already satisfied: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\r\nRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\r\nRequirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\r\nRequirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\r\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\r\nRequirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.25.0)\r\nRequirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\r\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.1)\r\nRequirement already satisfied: gast==0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\r\nRequirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.1.8)\r\nRequirement already satisfied: protobuf>=3.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.1)\r\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\r\nRequirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\r\nRequirement already satisfied: keras-preprocessing>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\r\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\r\nRequirement already satisfied: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.9.0)\r\nRequirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\r\nRequirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.2.0.post20200210)\r\nRequirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\r\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\r\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\r\nRequirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\r\nRequirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\r\nRequirement already satisfied: cachetools<3.2,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\r\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\r\nInstalling collected packages: tensorflow\r\nSuccessfully installed tensorflow-2.1.0\r\n\r\n(base) C:\\Windows\\system32>python\r\nPython 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n\r\n\r\nMy System Configuration:\r\nAcer Predator PHP315-51, Intel i5-8300H CPU @ 2.3GHz, 8gb RAM, Windows 10 64-bit, NVIDIA GeForce GTX 1050 Ti GPU.\r\n\r\n", "comments": ["@abhinabasaha,\r\n\r\nCould you please check [this](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) comment on a similar issue and let us know if it works? Thanks!", "@amahendrakar thanks for your suggestion, and I have gone through those points earlier, but I have the MSVC 2019 redistributable installed, and my CPU/Python is on 64 bits, but I am not sure about \"Your CPU does not support AVX2 instructions\", and \"There is a library that is in a different location/not installed on your system that cannot be loaded.\"\r\n\r\npreviuosly I tried to install tensorflow and keras and its subsequent packages by anaconda navigator, but the installation crashed everytime, then I tried to install it by conda, it got installed but the version was 1.x but not the latest 2.1, then tried with pip, it again got installed.\r\n\r\nBut now as I try to import it, The previous mentioned ( https://github.com/tensorflow/tensorflow/issues/37156#issue-572621424 ) error is shown.\r\n\r\nI tried pip uninstall tensorflow, conda remove tensorflow, then reinstalled it 1st by conda, faced the same error, then installed with pip after removing the conda version, again faced the same error...!!\r\n", "Solved the problem:\r\n\r\n1. Uninstalled anaconda (manually had to delete some of its files from C:\\Users\\Programdata)\r\n2. Reinstalled it.\r\n3. Updated anaconda ( conda update anaconda) and anaconda navigator\r\n4. I had previously installed cuda 10.2\r\n4. Installed tensorflow (pip install tensorflow and pip install tensorflow-gpu)\r\n5. Successfully imported tensorflow, but couldnot have gpu access, error \r\n       \"Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found \"\r\n6. Solved by following this instruction : https://stackoverflow.com/a/60024201\r\n7. For systems without GPU, follow this: https://stackoverflow.com/a/59616239\r\n\r\nNow everything is set.\r\n![image](https://user-images.githubusercontent.com/35966875/75848754-0d5aea00-5e09-11ea-90d9-4fcc8da3a9fb.png)\r\n\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37156\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37156\">No</a>\n"]}, {"number": 37155, "title": "TFLu: Update CMSIS URL and remove ARM_MATH_LOOPUNROLL", "body": "", "comments": []}, {"number": 37154, "title": "Issues in usage of hexagon delegate in raspi(armv7) and hikey(aarch64).", "body": "I was running label_image.cpp tflite example. I was modifying some of the default parameters and trying to make use of them. I am also trying to make use of hexagon delegate API in raspi, Hikey boards. \r\n\r\nI have few queries in the example.\r\n1. In documentation, it is mentioned the Hexagon Delegate API works in Qualcomm specific processors such as snapdragon 660,835 etc.. If I have development board having Qualcomm mentioned processors with Linux os installed. Could I be able to make use of it ?\r\n\r\n2. The Tflite model expects input mean and std deviation to be specified. \r\n**Is this input mean and std deviation setting varies from model to model?**\r\n**How to know what mean and std deviation to be kept to get better classification results based on model ?**\r\nFor Quantized models, We are not using mean and std deviation?\r\n**Why is this only required for float models but not Quantized models ?**\r\n\r\n3. what does **allow_fp16** ideally does ? I tried to use this flag but even after setting to true, didn't notice any difference in memory , performance and even interpreter state. \r\n\r\nIn documentation, It is mentioned as it does fp16  precision calculations even for fp32. But interpreter tensors are always created in fp32(but not fp16).\r\n**What happens when we use this flag for tflite (float) models ?**\r\n**What happens when we use this flag for Quantized(uint8) models ?**\r\n\r\n4. What does **profiling and max_profiling_buffer_entries** do ?\r\nWhich value i should keep for max_profiling_buffer_entries ? why is it 1024 ?\r\nI was able to return elapsed times even when i set profiling flag to false and verbose to true.\r\n\r\nPlease provide, sufficient details in each question to help us in proceeding further.\r\n\r\n\r\n", "comments": ["1. Nope, Hexagon is Qualcomm's DSP shipped with its SoCs. Neither Raspberry Pi nor HiKey boards use Qualcomm SoCs. If you run `label_image --hexagon_delegate 1 ...`, you are supposed to get something like `Hexagon acceleration is unsupported on this platform.invoked` and TFLite interpreter will be used to run your model.\r\n\r\n2. Usually models are trained with normalized/preprocessed images, those steps include converting images from integer to floating point numbers because models are trained in floating point. Check [1] for an example of preprocessing.\r\n\r\n3. `--allow_fp16` is mainly for allowing running fp32 models with fp16 via `NNAPI` [2]\r\n4.  To see TFLite per op profiling results, build `label_image` with  `--cxxopt=-DTFLITE_PROFILING_ENABLED` and run it with `-p 1` \r\n\r\n\r\n[1] https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing.py\r\n[2] https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1gab822719f98f0c92e5da3684cdaca6ba0", "1, If I have board with Qualcomm soc and which was running on Linux OS, Can I be able to use Hexagon Delegate. Is it restricted to only Android/ Ios ?\r\n\r\n2. What standard deviation and mean to be used in all models ? is it stored under model ? How the user know what mean and std deviation to be used for any pre trained network.\r\n\r\n", "1. Yes. Hexagon delegate is only available on Android at the moment.\r\n2. You just need to provide dataset. Calculation is done by quantizer. \r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations", "Hi terryheo, \r\n\r\nI have few issues regarding 2 point mentioned \r\n\r\n1. I was using label_image.cpp example in TfLite example. There there was option to pass mean and std deviation ? Why is it default set to 127.5 .\r\n\r\n2. Does the TfLite Model has the information about values of mean and std deviation ? If Quantizer does the calculation based on data set, Why this information is not stored in TfLite Model ?\r\n   Why in the example label_image.cpp, he is not using model to get mean and std deviation info ? Why is he expecting the user to pass ?\r\n   Would the provided example won't work for other models unless mean and std deviation are modified appropriately ?\r\n\r\n3. If I use the quantizer and provided data set, How would I know, what quantizer has  set the mean and standard deviation ?\r\n\r\nPlease provide me details on the above questions.", "when training image classifiers in floating point, usually image RGB values in [0,255], are converted to floating point numbers in [0,1] or [-1,1]. For, x in [0, 255], -1 <= (x-127.5) / 127.5  <= 1.0. ", "If i use pretrained tflite models from tensorflow lite website . How to know what kind of conversion is done to RGB values ? Can I use mean = 127.5 and std = 127.5 for all those models. ", "As far as I know, you have to check how the model is trained. So far it seems the classification models at the [TFLite hosted models](https://www.tensorflow.org/lite/guide/hosted_models) page are trained with inception processing, but I am not sure if that be will always true.", "> 1. Yes. Hexagon delegate is only available on Android at the moment.\r\n\r\n@terryheo I have a debian based system. Is there a way to use the snapdragon hexagon delegate with that? This builds fine on my dragonboard 820c and now I'm trying to accelerate it.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/label_image\r\n\r\n", "@arrow53 no. It's only supported by Android at the moment.\r\nTo enable it for ARM Linux, you may need to update https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/make/Makefile to include\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/delegates/hexagon\r\nwhich we haven't tested it."]}, {"number": 37153, "title": "InvalidArgumentError:  Size 1 must be non-negative, not -21", "body": "https://www.kaggle.com/super13579/u-net-base-on-resnet34-transfer-learning-keras\r\n\r\n```\r\nfig, m_axs = plt.subplots(20, 2, figsize = (10, 40))\r\n[c_ax.axis('off') for c_ax in m_axs.flatten()]\r\nfor (ax1, ax2), c_img_name in zip(m_axs, test_paths):\r\n    c_path = os.path.join(test_image_dir, c_img_name)\r\n    c_img = imread(c_path)\r\n    #print(c_img.shape)\r\n    first_img = np.expand_dims(c_img, 0)/255.0\r\n    #print('a')\r\n    first_seg = fullres_model.predict(first_img)\r\n    #print('b')\r\n    ax1.imshow(first_img[0])\r\n    ax1.set_title('Image')\r\n    ax2.imshow(first_seg[0,:, :, 0])\r\n    ax2.set_title('Prediction')\r\n#fig.savefig('test_predictions.png')\r\n```\r\n\r\n\r\n> ---------------------------------------------------------------------------\r\n> InvalidArgumentError                      Traceback (most recent call last)\r\n> <ipython-input-54-a91de316977a> in <module>\r\n>       7     first_img = np.expand_dims(c_img, 0)/255.0\r\n>       8     #print('a')\r\n> ----> 9     first_seg = .predict(first_img)\r\n>      10     #print('b')\r\n>      11     ax1.imshow(first_img[0])\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\r\n>    1460                                             verbose=verbose,\r\n>    1461                                             steps=steps,\r\n> -> 1462                                             callbacks=callbacks)\r\n>    1463 \r\n>    1464     def train_on_batch(self, x, y,\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/engine/training_arrays.py in predict_loop(model, f, ins, batch_size, verbose, steps, callbacks)\r\n>     322             batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\r\n>     323             callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)\r\n> --> 324             batch_outs = f(ins_batch)\r\n>     325             batch_outs = to_list(batch_outs)\r\n>     326             if batch_index == 0:\r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)\r\n>    3738         value = math_ops.cast(value, tensor.dtype)\r\n>    3739       converted_inputs.append(value)\r\n> -> 3740     outputs = self._graph_fn(*converted_inputs)\r\n>    3741 \r\n>    3742     # EagerTensor.numpy() will often make a copy to ensure memory safety.\r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n>    1079       TypeError: For invalid positional/keyword argument combinations.\r\n>    1080     \"\"\"\r\n> -> 1081     return self._call_impl(args, kwargs)\r\n>    1082 \r\n>    1083   def _call_impl(self, args, kwargs, cancellation_manager=None):\r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_impl(self, args, kwargs, cancellation_manager)\r\n>    1119       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\r\n>    1120           list(kwargs.keys()), list(self._arg_keywords)))\r\n> -> 1121     return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n>    1122 \r\n>    1123   def _filtered_call(self, args, kwargs):\r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n>    1222     if executing_eagerly:\r\n>    1223       flat_outputs = forward_function.call(\r\n> -> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n>    1225     else:\r\n>    1226       gradient_name = self._delayed_rewrite_functions.register()\r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n>     509               inputs=args,\r\n>     510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n> --> 511               ctx=ctx)\r\n>     512         else:\r\n>     513           outputs = execute.execute_with_cancellation(\r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n>      65     else:\r\n>      66       message = e.message\r\n> ---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n>      68   except TypeError as e:\r\n>      69     keras_symbolic_tensors = [\r\n> \r\n> ~/venv/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n> \r\n> InvalidArgumentError:  Size 1 must be non-negative, not -21\r\n> \t [[{{node u-resnet34_1/bn_data/batchnorm/mul-1-ReshapeNHWCToNCHW-LayoutOptimizer}}]] [Op:__inference_keras_scratch_graph_62290]\r\n> \r\n> Function call stack:\r\n> keras_scratch_graph\r\n> fullres_model", "comments": ["@SlowMonk \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\nRequest you to share a colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Please, fill [issue template ](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n\r\n", "@SlowMonk \r\n\r\nAny update on this issue please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37152, "title": "apply_transform not in preprocessing.image", "body": "I have to run this code which import \r\n`from tensorflow.python.keras.preprocessing.image import apply_transform`\r\n but I got issue **\"ImportError: cannot import name 'apply_transform'\"**\r\nIn this link https://stackoverflow.com/questions/51311062/cant-import-apply-transform-from-keras-preprocessing-image They told use apply_affine_tensorflow.\r\n\r\nI want to scaling image with this code \r\n```\r\ndef scale(mel_spectrogram, scale_factor):\r\n        w = mel_spectrogram.shape[0]\r\n        h = mel_spectrogram.shape[1]\r\n        transform = np.array([[scale_factor, 0, 0], [0, 1, 0], [0, 0, 1]])\r\n        image = mel_spectrogram.astype(np.float64).reshape(w, h)\r\n        scaled_image = apply_transform(image, transform, fill_mode='constant').astype(np.float16)\r\n        # if the result is shorter, shorten the np array as well\r\n        if scale_factor > 1:\r\n            new_length = int(scaled_image.shape[1] / scale_factor)\r\n            scaled_image = scaled_image[:, :new_length, ]\r\n        mel_spectrogram = np.expand_dims(scaled_image.astype(mel_spectrogram.dtype), axis=2)\r\n        return mel_spectrogram\r\n\r\n    return mel_sample_loader\r\n```\r\n\r\nFrom : https://github.com/hendriks73/directional_cnns/blob/095b6f524f666005adb138c4e336cf6da1f046e5/directional_cnns/loader.py#L51\r\n\r\nHow can I deal with it?\r\n", "comments": ["@jkpower,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "tensorflow version 1.15\r\n\r\nComplete Code\r\n```\r\nfrom tensorflow.python.keras.preprocessing.image import apply_transform\r\n\r\n\r\ndef create_mel_sample_loader(dataset, shape=(40, 256, 1), random_offset=True, normalizer=None):\r\n    \"\"\"\r\n    Create sample loading function that is capable of loading and augmenting a sample\r\n    based on an augmentation parameter. The loader function is suitable for the Mel spectrograms\r\n    we use for tempo estimation.\r\n    :param normalizer: normalization function\r\n    :param shape: desired shape\r\n    :param random_offset: return the first X frames or randomly chosen X frames, X=shape[1]\r\n    :param dataset: dataset, dict that maps a ``key`` to a sample\r\n    :return: function that returns a sample for a key (or sample id)\r\n    \"\"\"\r\n    def mel_sample_loader(key, augmentation_parameter=1.):\r\n        scale_factor = augmentation_parameter\r\n        if scale_factor is None:\r\n            scale_factor = 1.\r\n        mel_spectrogram = dataset[key]\r\n        # we want (40, length)\r\n        offset = 0\r\n        length = shape[1]\r\n        max_length_after_scaling = max(length, math.ceil(length * scale_factor))\r\n        if mel_spectrogram.shape[1] < max_length_after_scaling:\r\n            # the source is too short, let's pad with zeros\r\n            # better with np.pad()?\r\n            copy = np.zeros((mel_spectrogram.shape[0], max_length_after_scaling, mel_spectrogram.shape[2]))\r\n            copy[:, :mel_spectrogram.shape[1], :] = mel_spectrogram\r\n            mel_spectrogram = copy\r\n        if random_offset and max_length_after_scaling < mel_spectrogram.shape[1]:\r\n            # only compute random offset, if we really have material to work with\r\n            offset = np.random.randint(0, mel_spectrogram.shape[1] - max_length_after_scaling)\r\n        if scale_factor is not None and scale_factor != 1.:\r\n            unscaled = mel_spectrogram[:, offset:offset + max_length_after_scaling]\r\n            data = scale(unscaled, scale_factor)\r\n        else:\r\n            data = mel_spectrogram[:, offset:offset + length]\r\n        if normalizer is not None:\r\n            data = normalizer(data)\r\n\r\n        return data\r\n\r\n    def scale(mel_spectrogram, scale_factor):\r\n        w = mel_spectrogram.shape[0]\r\n        h = mel_spectrogram.shape[1]\r\n        transform = np.array([[scale_factor, 0, 0], [0, 1, 0], [0, 0, 1]])\r\n        image = mel_spectrogram.astype(np.float64).reshape(w, h)\r\n        scaled_image = apply_transform(image, transform, fill_mode='constant').astype(np.float16)\r\n        # if the result is shorter, shorten the np array as well\r\n        if scale_factor > 1:\r\n            new_length = int(scaled_image.shape[1] / scale_factor)\r\n            scaled_image = scaled_image[:, :new_length, ]\r\n        mel_spectrogram = np.expand_dims(scaled_image.astype(mel_spectrogram.dtype), axis=2)\r\n        return mel_spectrogram\r\n\r\n    return mel_sample_loader\r\n```", "@jkpower,\r\n\r\nAs per the [documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#apply_transform) for TF 1.15, could you please try importing as\r\n```\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nImageDataGenerator.apply_transform\r\n```\r\nAttached [gist](https://colab.sandbox.google.com/gist/amahendrakar/aafb757113b45c6e6abf21c4a2ae7b2d/37152.ipynb) for reference. Thanks!", "Any updates regarding this issue? Thanks!", "Thank you."]}, {"number": 37151, "title": "Run distributed training mnist failed", "body": "My dependencies\r\n```\r\nPython 3.6.8 (default, Aug  7 2019, 17:28:10) \r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> print(tf.__version__)\r\n2.2.0-dev20200227\r\n```\r\nHere is my code\r\nhttps://gist.github.com/pingsutw/bd4e1b1b2d4055d4e807abcdd2f0d6f4\r\n\r\nI use both `ParameterServerStrategy` and `MultiWorkerMirroredStrategy` all failed.\r\n\r\nI can successfully run this tutorial locally.\r\nAnd I follow this [link](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) to run distributed training, but always fails.\r\nInstead of run multiworker locally, I run on 3 machines. \r\n\r\nBelow are error messages\r\n```\r\n2020-02-27 21:54:15.735213: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cloudera/parcels/CDH/lib64:/opt/jdk1.8.0_221/jre/lib/amd64/server\r\n2020-02-27 21:54:15.735272: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-02-27 21:54:15.735320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kevin2): /proc/driver/nvidia/version does not exist\r\n2020-02-27 21:54:15.735784: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-27 21:54:15.849834: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2494140000 Hz\r\n2020-02-27 21:54:15.933775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fd9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-27 21:54:15.933870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-02-27 21:54:16.139575: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> kevin2:38518}\r\n2020-02-27 21:54:16.139650: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:43854, 1 -> kevin2:36868}\r\n2020-02-27 21:54:16.157359: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:43854\r\n2020-02-27 21:54:16.157667: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:394] Server already started (target: grpc://localhost:43854)\r\nWARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the iterator's `initializer` property instead.\r\nWARNING:tensorflow:From /yarn/nm/usercache/root/appcache/application_1582468300204_0090/container_1582468300204_0090_01_000003/tf2.zip/tf2/lib64/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the iterator's `initializer` property instead.\r\n```", "comments": ["@pingsutw Can you post the failure stack trace when running with MultiWorkerMirroredStrategy? The messages that you pasted above are warning messages. \r\n\r\nAlso, we don't currently support ParameterServer strategy with TF 2 and Keras native APIs so you will probably see an error if you try to use it with Keras compile/fit APIs.\r\n", "Closing this issue since there's no way to reproduce the error, and as mentioned above ParameterServer strategy is currently not supported for the Keras API.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37151\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37151\">No</a>\n"]}, {"number": 37150, "title": "Change quotes in TFLite tablegen to fix syntax highlighting", "body": "This PR removes some unnecessary quotes in the descriptions of the TFLite MLIR ops TableGen definitions which breaks syntax highlighting (tested in the Atom text editor).", "comments": []}, {"number": 37149, "title": "Structure type Errors in TensorFlow", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  **YES**\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): **`Mac OS Catalina`**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): **`binary`**\r\n- TensorFlow version (use command below): **`2.1`**\r\n- Python version: **`3.7.2`**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: **10.2**\r\n- GPU model and memory: **4gb ram**   Graphics:  **Intel HD Graphics 4000 1536 MB**\r\n\r\n**Describe the current behavior**\r\nI am attempting to build a stock prediction model using LSTM\r\nHere are a list of my import statements:\r\n\r\n```\r\nimport requests\r\nimport math\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pandas_datareader as web\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential, load_model\r\nfrom tensorflow.keras.layers import LSTM, Dense\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom bs4 import BeautifulSoup\r\nimport matplotlib.pyplot as plt\r\nfrom datetime import datetime, date\r\n```\r\n\r\nHere is the code for the model itself:\r\n\r\n```\r\n\r\n#split the data into x-train and y-train datasets\r\nx_train = []\r\ny_train = []\r\n\r\nfor i in range(20, len(train_data)):\r\n    x_train.append(train_data[i-20:i, 0])\r\n    y_train.append(train_data[i, 0])\r\n\r\n    if i<= 20:\r\n        print(x_train)\r\n        print(y_train)\r\n\r\n#convert x-train and y-train to numpy arrays to train models\r\nx_train, y_train = np.array(x_train), np.array(y_train)\r\n\r\n#reshape the data, LSTM model expects 3D dataset\r\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\r\n\r\n#Build LSTM MODEL\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n    tf.keras.layers.Dense(25, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(loss='mean_squared_error',\r\n              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)\r\n\r\n#create testing data set\r\n#creat new array containing scaled values\r\ntest_data = scaled_data[training_data_len - 20: , :]\r\n\r\n#create the datasets x-test and y-test\r\nx_test=[]\r\ny_test=dataset[training_data_len:, :]\r\nfor i in range(20, len(test_data)):\r\n    x_test.append(test_data[i-20:i, 0])\r\n\r\n#convert data to numpy array\r\nx_test = np.array(x_test)\r\n\r\n#reshape data to 3D\r\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\r\n\r\n#Get predicted price values\r\npredictions = model.predict(x_test)\r\npredictions = scaler.inverse_transform(predictions)\r\n\r\n#get root mean squared error\r\nrmse=np.sqrt(np.mean(((predictions- y_test)**2)))\r\nprint(rmse)\r\n\r\n```\r\nExecuting this code returns the error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/owner/Desktop/algo/predict.py\", line 98, in <module>\r\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\r\nIndexError: tuple index out of range\r\n```\r\n**Describe the expected behavior**\r\n`print(rmse)` should return the average.\r\n\r\nI am new to tensorflow and neural programming so I am not completely sure what to do here.\r\nIf I try `x_test = np.reshape(x_test, (x_test.shape[0]))`\r\n\r\nI get this error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/owner/Desktop/algo/predict.py\", line 103, in <module>\r\n    predictions = model.predict(x_test)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1013, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 498, in predict\r\n    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 475, in _model_iteration\r\n    total_epochs=1)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 615, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 497, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 85, in distributed_function\r\n    per_replica_function, args=args)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 763, in experimental_run_v2\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1819, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 2164, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 292, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 212, in _predict_on_batch\r\n    result = predict_on_batch(model, x)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 556, in predict_on_batch\r\n    return predict_on_batch_fn(inputs)  # pylint: disable=not-callable\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 737, in __call__\r\n    self.name)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\", line 177, in assert_input_compatibility\r\n    str(x.shape.as_list()))\r\nValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [32, 1]\r\n```\r\n\r\nAny help will be greatly appreciated, I am dying to learn what is wrong!\r\nThankyou,\r\nRRR.\r\n\r\n", "comments": ["It seems like your x_test is not of the size you expect it to be. Are you able to provide the following values:\r\n`test_data.shape, x_test.shape, scaled_data.shape, training_data_len`\r\n\r\nNote that `.shape` does not work on lists. So obtain the values after conversion to numpy.", "training_data_len = 50 . This also prints 311 sometimes\r\ntest_data.shape = (20, 1)\r\nscaled_data.shape = (311, 1)\r\nx_test.shape = (0,)\r\n\r\nSometimes the model tests with a sample of 30 and sometimes with a sample of 291", "> training_data_len = 50 . This also prints 311 sometimes\r\n> test_data.shape = (20, 1)\r\n> scaled_data.shape = (311, 1)\r\n> x_test.shape = (0,)\r\n> \r\n> Sometimes the model tests with a sample of 30 and sometimes with a sample of 291\r\n\r\nHere, what do you mean by **sometimes**?\r\n\r\nWhen training_data_len = 311, test_data.shape will be (20,1). If this happens x_test will end up being empty (shape=(0,)), based on your code. In that case, the error you have is expected. \r\n```\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-74-83e32771dadc> in <module>\r\n----> 1 x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\r\n\r\nIndexError: tuple index out of range\r\n```\r\n\r\nNow the issue is how you compute training_data_len.\r\n\r\n(FYI: This seems more like an implementation error than a bug/issue. You might get useful feedback on SO)", "This is how I compute training data len:\r\n\r\nRegarding the sometimes,  when I printed( training_data_len) the only modification i made to the code was to add `print(training_data_len)` When I ran the program the sample size was 291.\r\nI went back to the code and added `print(scaled_data.shape)` the sample size was 30.\r\n\r\n```\r\n\r\n#get closing price\r\ndata = df.filter(['Close'])\r\n\r\n#get closing price values\r\ndataset = data.values\r\n\r\n#set training data length to len of total data set\r\ntraining_data_len = math.ceil(len(dataset))\r\nprint(training_data_len)\r\n\r\n#Scale the data\r\nscaler = MinMaxScaler(feature_range=(0,1))\r\nscaled_data = scaler.fit_transform(dataset)\r\n\r\n```", "I think there is a problem with your for loop where you are trying to generate a sequence data of window size 20 for the test data. Assuming the training_data_len is 311, Can you run your code by updating, the range of for loop:\r\n\r\n```\r\nfor i in range(20, len(test_data)+1):\r\n    x_test.append(test_data[i-20:i, 0])\r\n```\r\nOtherwise, `len(test_data) = 20 `and the for loop will not happen.", "Okay Thank you,  I ran the code with the update and this error returned.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/owner/Desktop/algo/predict.py\", line 103, in <module>\r\n    x_test = np.reshape(x_test, (x_test.shape[0]))\r\n  File \"<__array_function__ internals>\", line 6, in reshape\r\n  File \"/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 301, in reshape\r\n    return _wrapfunc(a, 'reshape', newshape, order=order)\r\n  File \"/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 61, in _wrapfunc\r\n    return bound(*args, **kwds)\r\nValueError: cannot reshape array of size 20 into shape (1,)\r\n```\r\nAny ideas?", "As the error reports... your test data is of size 20, so it cannot be reshaped to size 1. I believe, you should be using the reshape as in the original code you shared:\r\n\r\n`\r\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))`", "Yes Thank you sir, that fixed the error, however it did present me with a new error.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/37159"]}, {"number": 37148, "title": "Simplify keras conv compute_output_shape", "body": "This should improve readability of the output shape computation in keras convolutional layers.", "comments": ["I cannot reproduce the CI failure locally. I rebased onto master to see if it is fixed there.", "> I cannot reproduce the CI failure locally. I rebased onto master to see if it is fixed there.\r\n\r\nCI uses a version of pylint from 2016 which has inconsistent behaviour with indentation. c5b4df3d1f8d4609baa1bd975a7a0993ae95b7fa should finally fix the error on CI."]}, {"number": 37147, "title": "Error on ESP32", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution Windows 10):\r\n- TensorFlow installed from (2.x on gogole collab):\r\n- Tensorflow version (same as before):\r\n- Target platform (ESP32):\r\n\r\nHello gentlemen, i'm trying to deploy a simple model (trained with kera tf 2.x on collab) and converted with this:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_quantizer = True\r\nconverter.experimental_new_converter = True\r\ntflite_float_model = converter.convert()\r\n```\r\n\r\nMy idea is to pass as input three values (float) of RGB to recognize the color with a sensor (Flora sensor of adafruit)\r\nWhen i flash the firmware on my esp32 i got this error on invoke (and some of my serial print)\r\n\r\n```\r\nrst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)\r\nconfigsip: 0, SPIWP:0xee\r\nclk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00\r\nmode:DIO, clock div:2\r\nload:0x3fff0018,len:4\r\nload:0x3fff001c,len:1044\r\nload:0x40078000,len:8896\r\nload:0x40080400,len:5828\r\nentry 0x400806ac\r\nLoading Tensorflow model....\r\nColor model loaded!\r\nAllocating tensors to memory pool\r\nTensors size: 14\r\nInput size: 1\r\nNo TCS34725 found ... check your connections\r\nStarting inferences...\r\nInput type 1\r\nInput shape 2\r\nabort() was called at PC 0x400dae25 on core 1\r\n\r\nBacktrace: 0x4008c49c:0x3ffb1e00 0x4008c6cd:0x3ffb1e20 0x400dae25:0x3ffb1e40 0x400db185:0x3ffb1e90 0x400e174a:0x3ffb1f70 0x400d198a:0x3ffb1f90 0x400e64bd:0x3ffb1fb0 0x40088bd9:0x3ffb1fd0\r\n\r\nRebooting...\r\nets Jun  8 2016 00:22:57\r\n\r\nrst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)\r\nconfigsip: 0, SPIWP:0xee\r\nclk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00\r\nmode:DIO, clock div:2\r\nload:0x3fff0018,len:4\r\nload:0x3fff001c,len:1044\r\nload:0x40078000,len:8896\r\nload:0x40080400,len:5828\r\nentry 0x400806ac\r\n\r\n--- exit ---\r\n```\r\n\r\n\r\nFollowing my code:\r\n```\r\n#include <Arduino.h>\r\n#include <math.h>\r\n#include \"tensorflow/lite/experimental/micro/kernels/all_ops_resolver.h\"\r\n#include \"tensorflow/lite/experimental/micro/micro_error_reporter.h\"\r\n#include \"tensorflow/lite/experimental/micro/micro_interpreter.h\"\r\n#include \"model_data.h\"\r\n#include \"Adafruit_TCS34725.h\"\r\n\r\n// Create a memory pool for the nodes in the network\r\nconstexpr int tensor_pool_size = 2 * 2048;\r\nuint8_t tensor_pool[tensor_pool_size];\r\n\r\n// Define the model to be used\r\nconst tflite::Model *sine_model;\r\n\r\n// Define the interpreter\r\ntflite::MicroInterpreter *interpreter;\r\n\r\n// Input/Output nodes for the network\r\nTfLiteTensor *input;\r\nTfLiteTensor *output;\r\n\r\nAdafruit_TCS34725 tcs = Adafruit_TCS34725(TCS34725_INTEGRATIONTIME_154MS, TCS34725_GAIN_1X);\r\nuint16_t red, green, blue, clear;\r\n\r\nbool sensor = false;\r\n// Set up the ESP32's environment.\r\nvoid setup()\r\n{\r\n\t// Start serial at 115200 baud\r\n\tSerial.begin(115200);\r\n\r\n\t// Load the sample sine model\r\n\tSerial.println(\"Loading Tensorflow model....\");\r\n\tsine_model = tflite::GetModel(model_data);\r\n\tSerial.println(\"Color model loaded!\");\r\n\r\n\t// Define ops resolver and error reporting\r\n\tstatic tflite::ops::micro::AllOpsResolver resolver;\r\n\r\n\tstatic tflite::ErrorReporter *error_reporter;\r\n\tstatic tflite::MicroErrorReporter micro_error;\r\n\terror_reporter = &micro_error;\r\n\r\n\t// Instantiate the interpreter\r\n\tstatic tflite::MicroInterpreter static_interpreter(sine_model, resolver, tensor_pool, tensor_pool_size, error_reporter);\r\n\r\n\tinterpreter = &static_interpreter;\r\n\r\n\t// Allocate the the model's tensors in the memory pool that was created.\r\n\tSerial.println(\"Allocating tensors to memory pool\");\r\n\tSerial.printf(\"Tensors size: %d\\n\", interpreter->tensors_size());\r\n\tSerial.printf(\"Input size: %d\\n\", interpreter->inputs_size());\r\n\r\n\tif (interpreter->AllocateTensors() != kTfLiteOk)\r\n\t{\r\n\t\tSerial.println(\"There was an error allocating the memory...ooof\");\r\n\t\twhile (true)\r\n\t\t\t;\r\n\t}\r\n\r\n\tif (tcs.begin())\r\n\t{\r\n\t\tSerial.println(\"Found sensor\");\r\n\t\tsensor = true;\r\n\t}\r\n\telse\r\n\t{\r\n\t\tSerial.println(\"No TCS34725 found ... using fake value for Green\");\r\n\t\tsensor = false;\r\n\t}\r\n\r\n\t// Define input and output nodes\r\n\tinput = interpreter->input(0);\r\n\toutput = interpreter->output(0);\r\n\tSerial.println(\"Starting inferences... \");\r\n\tSerial.printf(\"Input type %d\\n\", input->type);\r\n\tSerial.printf(\"Input shape %d\\n\", input->dims->size);\r\n\r\n}\r\n\r\n// Logic loop for taking user input and outputting the sine\r\nvoid loop()\r\n{\r\n\r\n\tif (sensor)\r\n\t{\r\n\t\ttcs.setInterrupt(false); // turn on LED\r\n\t\tdelay(1);\r\n\t\ttcs.getRawData(&red, &green, &blue, &clear);\r\n\t\ttcs.setInterrupt(true); // turn off LED\r\n\t\t//r,g,b,c\r\n\t\tdelay(100);\r\n\t}\r\n\telse\r\n\t{\r\n\t\tred = 688;\r\n\t\tgreen = 319;\r\n\t\tblue = 290;\r\n\t\tclear = 1228;\r\n\t}\r\n\r\n\tinput->data.f[0] = (red / clear);\r\n\tinput->data.f[1] = (green / clear);\r\n\t//input->data.f[2] = (blue / clear);\r\n\r\n\r\n\tSerial.println(interpreter->Invoke());\r\n\tif (interpreter->Invoke() != kTfLiteOk)\r\n\t{\r\n\t\tSerial.println(\"There was an error invoking the interpreter!\");\r\n\t\twhile (true) delay(1000);\r\n\t}\r\n\r\n\t// Print the output of the model.\r\n\tSerial.print(\"Input: \");\r\n\tSerial.printf(\"%d,%d,%d,%d\\n\", red, green, blue, clear);\r\n\tSerial.print(\"Output: \");\r\n\tSerial.println(output->data.f[0]);\r\n\tSerial.println(\"\");\r\n\tdelay(1000);\r\n}\r\n```\r\n\r\nCould you help me? (i can pass the entire project)", "comments": ["UPDATE i re-trained my model without using any optimization options and now seems that works but the output seem to be broken:\r\n\r\nIf i will print input->dims->size (and output) it will says that the dim is 2 (but in training i passed a tuple of 3 floats) same for the outpu (i need the three classes output rgb percentage right?)", "@fedyfausto Could you please have a look on the [link1](https://stackoverflow.com/questions/68873659/how-to-fix-compilation-error-for-esp32-in-arduino-ide) , [link2](https://github.com/espressif/arduino-esp32/issues/333) and let us know if it helps? .Also please try to execute the code in latest tf version 2.7 . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37147\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37147\">No</a>\n"]}, {"number": 37146, "title": "Added ResNext models", "body": "Added ResNext models. It seems like the implementation of ResNext models was dropped, despite them being available options in `WEIGHT_HASHES`. The implementation can simply be achieved by using `stack3`, which is also a function that was declared and not used.\r\n\r\nAddresses tensorflow/models#1248, tensorflow/models#6764. ", "comments": ["@jaketae Can you please address Ubuntu Sanity errors? Thanks!", "@tanzhenyu  @gbaned Please correct me if I'm wrong, but to my knowledge the CI failures seem to be happening due to things unrelated to this PR. I'm by no means familiar with CI's automated testing, but here's an [example log](https://source.cloud.google.com/results/invocations/da266721-5903-4975-a630-8f3a80d978a9/targets/%2F%2Ftensorflow%2Fcompiler%2Ftests:sort_ops_test_cpu/log) for reference:\r\n\r\n```\r\nif (!operand_cst->isVariableLength()) {\r\n           ~~~~~~~~~~~  ^\r\ntensorflow/compiler/mlir/xla/operator_writer_gen.cc:111:33: error: no member named 'getNumVariableLengthOperands' in 'mlir::tblgen::Operator'; did you mean 'getNumVariadicOperands'?\r\n  if (op.getNumOperands() == op.getNumVariableLengthOperands()) {\r\n                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n                                getNumVariadicOperands\r\nexternal/llvm-project/mlir/include/mlir/TableGen/Operator.h:145:12: note: 'getNumVariadicOperands' declared here\r\n  unsigned getNumVariadicOperands() const;\r\n```\r\n\r\nCould you give me some pointers on where to go from here? Thank you in advance.", "@jaketae See b7c1d24656c61b39375635644dd3f168e9a811cb which fixes https://github.com/tensorflow/tensorflow/commit/f5ee7354284987cb0449c2c4be5a7b81717babaf#commitcomment-38456646.\r\n\r\ncc @d0k ", "@byronyi Got it. So since a fix was pushed out, a quick merge and a CI rerun should address the problem? I'll try it today and get back to you.", "> @byronyi Got it. So since a fix was pushed out, a quick merge and a CI rerun should address the problem? I'll try it today and get back to you.\r\n\r\nI think you don't even need to rebase/merge any commits for this PR. Simply kicking off CI again will do, assuming no one is breaking the HEAD on GitHub again.", "Thanks Jake. I realized that 1) this needs API proto generation, which you probably wouldn't be able to do so; 2) this needs basic unit test, 3) there's a bug on line of code to `load_weights`, you need a comma in front of `by_name`.\r\n\r\nSo I'm gonna create a commit instead and acknowledge your PR inside the commit.", "@tanzhenyu, thank you for the review. Yes, the API proto generation part is well beyond my reach (not even really sure what that would entail), so I agree that this is the best way to go. Looking forward to your PR!", "@tanzhenyu Any update on this PR? Please. Thanks!", "@tanzhenyu Any update on this PR? Please. Thanks!", "There is an error when input_shape is (None, None, 3)\r\n\r\n![image](https://user-images.githubusercontent.com/36766404/104439245-7da6d000-55c3-11eb-88a6-55f5ee47b7c7.png)\r\n", "@jaketae  Can you please check @fchollet's comments and keep us posted ? Thanks!", "@jaketae  Any update on this PR? Please. Thanks!\r\n", "> @jaketae Any update on this PR? Please. Thanks!\r\n\r\nMy apologies, I've been caught up lately with some other things. I'll try to make changes to the PR as needed throughout this week (and potentially beyond, depending on how much progress I make). Thanks for the friendly reminders!", "The unit tests could be as simple as just adding the new models to the list of covered models in `keras/applications/applications_test.py`.", "@jaketae Can you please check @fchollet's comments and keep us posted ? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I just added the two models in the unittest, but I'm unsure about some details. I hope to get this PR finalized by this weekend, should any additional work and debugging be necessary ~~(waiting for the CI at the moment).~~ \r\n\r\n**Update:** The CI seems to have passed. Please let me know if there's anything I'm missing. Also, belated apologies for delaying such a simple fix!", "@fchollet Thank you for the review! Before I get too excited though, can you give me some pointers as to how to debug the backward compatibility issues the CI is complaining about? I'm assuming it has to be attended to, but I'm not entirely sure how to interpret the log. Thanks in advance!", "Hi @jaketae,\r\n\r\nDon't worry about the CI check about API files. We'll take care of it.\r\n\r\nI was looking at merging this earlier and there's a problem we need to fix. First of all, please add the new models to the test `keras/applications/applications_load_weight_test.py`, like this:\r\n\r\n```\r\nARG_TO_MODEL = {\r\n    'resnet': (resnet, [resnet.ResNet50, resnet.ResNet101, resnet.ResNet152,\r\n                                  resnet.ResNeXt50, resnet.ResNeXt101]),\r\n   ...\r\n```\r\n\r\nWhen you do this, you will see that the test fails because the weights are not loaded correctly. The model's predictions are incorrect after loading the pretrained weights.\r\n\r\nWe need to fix this. In the process of fixing it we need to get rid of the `by_name = True` flag. Instead of that we should be loading weights normally, from a checkpoint that is specific to each new model. So you'll have to prepare two new checkpoint files, make sure that the test `applications_load_weight_test.py` passes with the files, then upload the checkpoints to GitHub or a cloud bucket. Then we'll take it over from there.", "@jaketae Can you please check @fchollet's comments and keep us posted ? Thanks!", "@jaketae  Any update on this PR? Please. Thanks!", "> Hi @jaketae,\r\n> \r\n> Don't worry about the CI check about API files. We'll take care of it.\r\n> \r\n> I was looking at merging this earlier and there's a problem we need to fix. First of all, please add the new models to the test `keras/applications/applications_load_weight_test.py`, like this:\r\n> \r\n> ```\r\n> ARG_TO_MODEL = {\r\n>     'resnet': (resnet, [resnet.ResNet50, resnet.ResNet101, resnet.ResNet152,\r\n>                                   resnet.ResNeXt50, resnet.ResNeXt101]),\r\n>    ...\r\n> ```\r\n> \r\n> When you do this, you will see that the test fails because the weights are not loaded correctly. The model's predictions are incorrect after loading the pretrained weights.\r\n> \r\n> We need to fix this. In the process of fixing it we need to get rid of the `by_name = True` flag. Instead of that we should be loading weights normally, from a checkpoint that is specific to each new model. So you'll have to prepare two new checkpoint files, make sure that the test `applications_load_weight_test.py` passes with the files, then upload the checkpoints to GitHub or a cloud bucket. Then we'll take it over from there.\r\n\r\n\r\nIs the problem fixed? thanks.", "@jaketae  Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@jaketae Any update on this PR? Please. Thanks!", "Huge apologies for the belated update. I haven't had the time to look into this recently, which is compounded by the fact that I don't have enough resources to run experiments and train the model to optimality. I'd be happy to relay this issue to anyone else who'd be interested. If not, I'll try to find time and the compute to prepare model weights.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 45 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 37144, "title": "WARNING:tensorflow:AutoGraph could not transform and will run it as-is. Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.", "body": "**System information** \r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution : Windows 10\r\n- TensorFlow installed from (source or binary): Anaconda\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nI'm using anaconda tensorflow, Spyder. When run my custom layers, it shows warning as below: \r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method GroupSoftmax.call of <__main__.GroupSoftmax object at 0x000002A957B843C8>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nWARNING: AutoGraph could not transform <bound method GroupSoftmax.call of <__main__.GroupSoftmax object at 0x000002A957B843C8>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n```\r\n**Describe the method I tried**\r\nI have already tried the solution which others provided: pip install gast==0.2.2\r\nI also re-installed all of the softwares (anaconda, tensorflow, spyder). \r\nHowever, these methods doesn't solve my problem.  \r\nIs there any other solution? \r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nclass GroupSoftmax(layers.Layer):\r\n    def __init__(self, axis=-1, **kwargs):\r\n        super(GroupSoftmax, self).__init__(**kwargs)\r\n        self.supports_masking = True\r\n        self.axis = axis\r\n\r\n    def call(self, inputs):\r\n        return tf.divide(inputs, tf.reduce_sum(inputs, axis=self.axis))\r\n\r\n    def get_config(self):\r\n        config = {'axis': self.axis}\r\n        base_config = super(GroupSoftmax, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n    \r\n    @tf_utils.shape_type_conversion\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape\r\n\r\n'''\r\n-----------------network of g-----------------\r\n'''\r\ngModel = tf.keras.Sequential([\r\n# \u6dfb\u52a0\u4e00\u4e2a\u6709Nodes\u4e2a\u795e\u7ecf\u5143\u7684\u5168\u8fde\u63a5\u5c42\uff0c\u201cinput_shape\u201d\u4e3a\u8be5\u5c42\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\uff0c\u201cactivation\u201d\u6307\u5b9a\u8be5\u5c42\u6240\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\r\nlayers.Dense(Nodes, activation='sigmoid', input_shape=(60,), use_bias = False),#\u5c01\u88c5\u6570\u636e\u5e94\u8be5\u4e3a\uff083000\uff0c10\uff0c6\uff09\r\n# \u6dfb\u52a0\u7b2c\u4e8c\u4e2a\u7f51\u7edc\u5c42\r\nlayers.Dense(Nodes, activation='sigmoid', use_bias = False),\r\n# \u6dfb\u52a0\u7b2c3\u4e2a\u7f51\u7edc\u5c42\r\nlayers.Dense(Nodes, activation='sigmoid', use_bias = False),\r\n# \u6dfb\u52a0\u7b2c4\u4e2a\u7f51\u7edc\u5c42\r\nlayers.Dense(Nodes, activation='sigmoid', use_bias = False),\r\n# \u6dfb\u52a0\u7b2c5\u4e2a\u7f51\u7edc\u5c42\r\nlayers.Dense(Nodes, activation='sigmoid', use_bias = False),\r\n# \u6dfb\u52a0\u7b2c6\u4e2a\u7f51\u7edc\u5c42,\u6539\u53d8\u8282\u70b9\u6570\u76ee\r\nlayers.Dense(66, activation='sigmoid', use_bias = False),\r\n# \u6dfb\u52a0\u7b2c7\u4e2a\u7f51\u7edc\u5c42,\u6539\u53d8shape\r\nlayers.Reshape((11, 6)),\r\n# \u6dfb\u52a0output\u7f51\u7edc\u5c42,\u5206\u7ec4softmax\r\n#layers.Dense(6, activation=layers.Softmax(axis=0),input_shape=(11,6), use_bias = False), # [11,6]\r\n#layers.Softmax(axis=0)\r\nGroupSoftmax(axis=0)\r\n])\r\n\r\ngModel.summary()   \r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@nsssss \r\n\r\nI have tried in colab with TF 2.1.0 and i am not seeing any issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/5acb8f3e34b93bd1a7d237e2f1d64fe9/untitled685.ipynb).I have made few assumptions in code while executing. If you feel there is an issue please do update in attached colab and help me to reproduce the issue. It helps me in localizing the issue faster. Thanks!", "> @nsssss\r\n> \r\n> I have tried in colab with TF 2.1.0 and i am not seeing any issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/5acb8f3e34b93bd1a7d237e2f1d64fe9/untitled685.ipynb).I have made few assumptions in code while executing. If you feel there is an issue please do update in attached colab and help me to reproduce the issue. It helps me in localizing the issue faster. Thanks!\r\n\r\nThanks. there's no problem with colab. But there's always a warning when using spyder in anaconda tensorflow. It seems there's no influence on the results, but I'm not sure if it will influence the speed. ", "You can safely ignore the warning log as its intended to debug logging in AutoGraph issues. Thanks !", "> It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?\r\n\r\nYes, this problem still exists. ", "@nsssss \r\n\r\nThe warning will not hurt performance, but I'm curious as to what the cause might be. Can you add this line just before importing tensorflow: `tf.autograph.set_verbosity(3, True)`? That will print additional details with the warning message that we could use to investigate.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37144\">No</a>\n", "Hello, \r\n\r\nI have used `tf.autograph.set_verbosity(3, True)` and here is what I have got:\r\n\r\n```\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x00000225B41F2D38>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x00000225B41F2D38>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x00000225B41F2D38>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x00000225B41F2D38>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x00000225B41F2438>\r\n    args: (<tf.Tensor 'args_0:0' shape=(100,) dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x00000225B41F2438>\r\n    args: (<tf.Tensor 'args_0:0' shape=(100,) dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x00000225B41F2438>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x00000225B41F2438>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x000002258096BE58>\r\n    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(100, 35, 1) dtype=float32>,))\r\n    kwargs: {}\r\n\r\nConverted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x000002258096BE58>\r\n    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, (<tf.Tensor 'args_1:0' shape=(100, 35, 1) dtype=float32>,))\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x000002258096BE58>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x000002258096BE58>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000002264AF74A48>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000002264AF74A48>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Cache hit for entity <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x000002264AF74FC8>, frozenset({'self'})): _ConvertedEntityFactoryInfo(tf__predict_function in tmpmvnq3xyi)\r\nCache hit for entity <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x000002264AF74FC8>, frozenset({'self'})): _ConvertedEntityFactoryInfo(tf__predict_function in tmpmvnq3xyi)\r\nINFO:tensorflow:Error transforming entity <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 538, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 362, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 300, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 94, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\nError transforming entity <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8>\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000225B4276EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nINFO:tensorflow:Converted call: <bound method Model.predict_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000002264C0EBC88>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, 35, 1) dtype=float32>,),)\r\n    kwargs: {}\r\n\r\nConverted call: <bound method Model.predict_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000002264C0EBC88>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, 35, 1) dtype=float32>,),)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <bound method Model.predict_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000002264C0EBC88>>: from cache\r\nWhitelisted <bound method Model.predict_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000002264C0EBC88>>: from cache\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 538, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 362, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 300, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\katica.ristic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 94, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\n```", "Hope this could help solve the issue. \r\nI am using  Windows 10, Anaconda, TensorFlow version 2.2.0\r\nPython version 3.7", "@KaticaR thank you for the logs, they seem to indicate an incompatibility with the toolchain, though it's unclear which piece. At any rate, the faulting piece was refactored recently. If you have the chance, please retry with tf-nightly.", "Hi I got this as well, and as the message says I set the env variable and recorded the stack trace:\r\n\r\n```\r\nWARNING: AutoGraph could not transform <function initialize_tpu_system.<locals>._tpu_init_fn at 0x7fdbda21fcb0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: No module named 'tensorflow_core.keras'\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-9-2eec46e4b091>\", line 13, in <module>\r\n    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/tpu/tpu_strategy_util.py\", line 103, in initialize_tpu_system\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 942, in numpy\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 910, in _numpy\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'InvalidArgumentError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    from ._api.v2 import data\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    from ._api.v2 import audio\r\n  File \"/opt/conda/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\r\nModuleNotFoundError: No module named 'tensorflow_core.keras'\r\n```\r\n\r\nI was running `tensorflow` in a Kaggle kernel.", "When we downgraded the versions of keras and tensorflow to match, then the error disappointed.", "> When we downgraded the versions of keras and tensorflow to match, then the error disappointed.\r\n\r\nHey KaticaR, may I ask to which version of Keras have you downgraded to match TF 2.1? I know TF 2.2 is out but its GPU version is still not supported by Anaconda yet.", "i am having this while trying Xception model on tpu : \r\n\r\n```\r\nWARNING: AutoGraph could not transform <function <lambda> at 0x7f1e447a1950> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function <lambda> at 0x7f1e447a1950>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n```\r\n\r\n\r\nand also it is taking a lot of time\r\nfor 2 epochs it takes 59 minutes on TPU with Xception model\r\nbut same code where if i change Xception with efficientnet-b6 or b7 then i can run 13 epochs which will finish within 1 hour!!\r\n\r\nhere is my code : https://www.kaggle.com/mobassir/in-depth-melanoma-and-modeling?scriptVersionId=38354798\r\n\r\nand here you can see : https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once\r\n\r\nsame code with efficientnet-b6 or b7 is extremely fast compared to my simple Xception model\r\nplease help?", "@mobassir94 try the following to avoid the warning:\r\n\r\n```\r\nds_train     = ds_train.map(lambda img, label: (img, tuple([label])))\r\n```\r\n\r\nwith:\r\n\r\n```\r\nunpack_label = lambda img, label: (img, tuple([label]))\r\nunpack_label = tf.autograph.do_not_convert(unpack_label)  # Runtime not compatible\r\nds_train = ds_train.map(unpack_label)\r\n```\r\n\r\nThe slowness problem is unrelated, though.", "@mdanatg  thanks\r\nwhere do i ask about that slowness problem and how do i solve this slowness issue? only thing i changed is model from efficientnet to xception :(", "I recommend StackOverflow. If you are certain that xception should be as fast as efficientnet, and can reproduce it with a simple example, consider filing a separate  GitHub issue as well.\r\n\r\nMore info: https://www.tensorflow.org/community", "@mdanatg  stackoverflow is a terrible place for data science/Deep learning help, i have asked tons of questions there and never got any help except some downvotes even for a good post!", "@mdanatg  my tf version 2.2.0 and with your code i get this erro : AttributeError: module 'tensorflow._api.v2.autograph' has no attribute 'do_not_convert'", "Sorry, for 2.2 please use `tf.autograph.experimental.do_not_convert`.", "@mdanatg  Thanks, the problem is fixed with this solution.", "> @mobassir94 try the following to avoid the warning:\r\n> \r\n> ```\r\n> ds_train     = ds_train.map(lambda img, label: (img, tuple([label])))\r\n> ```\r\n> \r\n> with:\r\n> \r\n> ```\r\n> unpack_label = lambda img, label: (img, tuple([label]))\r\n> unpack_label = tf.autograph.do_not_convert(unpack_label)  # Runtime not compatible\r\n> ds_train = ds_train.map(unpack_label)\r\n> ```\r\n> \r\n> The slowness problem is unrelated, though.\r\n\r\nsorry, would you please put your fix in order. what ds_train refers to?", "@spawnaga this workaround refers specifically to @mobassir94's code. It is not a general fix. Also note that the issue is fixed in tf-nightly.", "@fchollet might have better advice on active user groups who could answer @mobassir94's questions", "> > @mobassir94 try the following to avoid the warning:\r\n> > ```\r\n> > ds_train     = ds_train.map(lambda img, label: (img, tuple([label])))\r\n> > ```\r\n> > \r\n> > \r\n> > with:\r\n> > ```\r\n> > unpack_label = lambda img, label: (img, tuple([label]))\r\n> > unpack_label = tf.autograph.do_not_convert(unpack_label)  # Runtime not compatible\r\n> > ds_train = ds_train.map(unpack_label)\r\n> > ```\r\n> > \r\n> > \r\n> > The slowness problem is unrelated, though.\r\n> \r\n> sorry, would you please put your fix in order. what ds_train refers to?\r\n\r\n@mobassir94  Can you please detail it about below code  (as i am getting same error in tensorflow api )\r\ndoes it create tfrecord ?\r\nunpack_label = lambda img, label: (img, tuple([label]))\r\n unpack_label = tf.autograph.do_not_convert(unpack_label)  # Runtime not compatible\r\n ds_train = ds_train.map(unpack_label)", "@shubhamgajbhiye1994 can you create a small snippet that we can run separately to reproduce the error you're seeing? That would help us give you better advice.", "I have this same issue. My error logs:\r\n\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x13ffac310> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unsupported operand type(s) for -: 'NoneType' and 'int'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-08-15 10:38:47.649790: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph sequential/MLCSubgraphOp_2_0 with frame_id = 0 and iter_id = 0 with error: Internal: ExecuteMLCInferenceGraph: Failed to execute MLC inference graph. (error will be reported 5 times unless TF_MLC_LOGGING=1).\r\n2021-08-15 10:38:47.652117: F tensorflow/core/framework/op_kernel.cc:983] Check failed: outputs_[index].tensor == nullptr (0x13fd05cb0 vs. nullptr)\r\nzsh: abort      python test.py\r\n```\r\n\r\nCode to reproduce:\r\n\r\n```\r\nfrom tensorflow.keras.datasets import fashion_mnist\r\nfrom tensorflow.keras import Sequential\r\nfrom tensorflow.keras.layers import Dense, Flatten\r\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\r\n\r\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n\r\nX_train = X_train / 255\r\nX_test = X_test / 255\r\n\r\nmodel = Sequential([\r\n    Flatten(input_shape=X_train.shape[1:]),\r\n    Dense(30, activation='relu'),\r\n    Dense(30, activation='relu'),\r\n    Dense(10, activation='softmax')\r\n    ])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(X_train, y_train, epochs=30)\r\n\r\ny_pred = model.predict(X_test)  # <--- Error occurs here\r\nprint(np.argmax(predictions[0]))\r\n```\r\n\r\nI am on a MacBook Air (M1, 2020) running macOS Big Sur (11.4). ", "Hi, we have solved the problem by setting the right versions of the\npackages. Hope this info helps!\n\nAll the best,\nKatica\n\n\nOn Sun, Aug 15, 2021, 11:46 jda5 ***@***.***> wrote:\n\n> I have this same issue. My error logs:\n>\n> WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x13ffac310> and will run it as-is.\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n> Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n> 2021-08-15 10:38:47.649790: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph sequential/MLCSubgraphOp_2_0 with frame_id = 0 and iter_id = 0 with error: Internal: ExecuteMLCInferenceGraph: Failed to execute MLC inference graph. (error will be reported 5 times unless TF_MLC_LOGGING=1).\n> 2021-08-15 10:38:47.652117: F tensorflow/core/framework/op_kernel.cc:983] Check failed: outputs_[index].tensor == nullptr (0x13fd05cb0 vs. nullptr)\n> zsh: abort      python test.py\n>\n> Code to reproduce:\n>\n> from tensorflow.keras.datasets import fashion_mnist\n> from tensorflow.keras import Sequential\n> from tensorflow.keras.layers import Dense, Flatten\n> from tensorflow.keras.losses import SparseCategoricalCrossentropy\n>\n> (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n>\n> X_train = X_train / 255\n> X_test = X_test / 255\n>\n> model = Sequential([\n>     Flatten(input_shape=X_train.shape[1:]),\n>     Dense(30, activation='relu'),\n>     Dense(30, activation='relu'),\n>     Dense(10, activation='softmax')\n>     ])\n>\n> model.compile(optimizer='adam',\n>               loss=SparseCategoricalCrossentropy(from_logits=True),\n>               metrics=['accuracy'])\n>\n> model.fit(X_train, y_train, epochs=30)\n>\n> y_pred = model.predict(X_test)  # <--- Error occurs here\n> print(np.argmax(predictions[0]))\n>\n> I am on a MacBook Air (M1, 2020) running macOS Big Sur (11.4).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37144#issuecomment-899024223>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AGZMARMZSRCENOE53K7AGWTT46EFPANCNFSM4K5DJK3A>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n", "Would you be more specific? What right versions? How to set them. ", "> I have this same issue. My error logs:\r\n> \r\n> ```\r\n> WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x13ffac310> and will run it as-is.\r\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n> Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\r\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n> 2021-08-15 10:38:47.649790: I tensorflow/compiler/tf2mlcompute/kernels/mlc_subgraph_op.cc:326] Compute: Failed in processing TensorFlow graph sequential/MLCSubgraphOp_2_0 with frame_id = 0 and iter_id = 0 with error: Internal: ExecuteMLCInferenceGraph: Failed to execute MLC inference graph. (error will be reported 5 times unless TF_MLC_LOGGING=1).\r\n> 2021-08-15 10:38:47.652117: F tensorflow/core/framework/op_kernel.cc:983] Check failed: outputs_[index].tensor == nullptr (0x13fd05cb0 vs. nullptr)\r\n> zsh: abort      python test.py\r\n> ```\r\n> \r\n> Code to reproduce:\r\n> \r\n> ```\r\n> from tensorflow.keras.datasets import fashion_mnist\r\n> from tensorflow.keras import Sequential\r\n> from tensorflow.keras.layers import Dense, Flatten\r\n> from tensorflow.keras.losses import SparseCategoricalCrossentropy\r\n> \r\n> (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n> \r\n> X_train = X_train / 255\r\n> X_test = X_test / 255\r\n> \r\n> model = Sequential([\r\n>     Flatten(input_shape=X_train.shape[1:]),\r\n>     Dense(30, activation='relu'),\r\n>     Dense(30, activation='relu'),\r\n>     Dense(10, activation='softmax')\r\n>     ])\r\n> \r\n> model.compile(optimizer='adam',\r\n>               loss=SparseCategoricalCrossentropy(from_logits=True),\r\n>               metrics=['accuracy'])\r\n> \r\n> model.fit(X_train, y_train, epochs=30)\r\n> \r\n> y_pred = model.predict(X_test)  # <--- Error occurs here\r\n> print(np.argmax(predictions[0]))\r\n> ```\r\n> \r\n> I am on a MacBook Air (M1, 2020) running macOS Big Sur (11.4).\r\nsame error as well.  Are you using the older version of tensorflow or the apple's metal thing. \r\nI tried both: \r\n1. the above error happens with the older version and the now archived apple repositoryl \r\n2. The more official apple package requires mac os >=12.0", "Could you set the verbosity to 3 and include the log messages, along with the pip package versions that you used? That would help reproduce the issue. I tried the snippet in colab on the stable version, but couldn't reproduce it.", "It would also be a good idea to file a new issue - this warning is very generic and could signal many different issues.", "![image](https://user-images.githubusercontent.com/36342491/130327971-341a732b-4398-4cec-9502-1815845f9aca.png)\r\nall my installed packages : https://blog.csdn.net/Linli522362242/article/details/108037567\r\n`pip install gast==0.2.2`\r\n![image](https://user-images.githubusercontent.com/36342491/130328041-1aa5d292-b7c2-49ff-b04e-c3dedaf1bac7.png)\r\n\r\n`pip install  tensorflow-serving-api==2.1.0`\r\n![image](https://user-images.githubusercontent.com/36342491/130328010-24c3f740-774e-4ab5-97d1-319d55e209e2.png)\r\n", "@liqinglin54951 that looks like an incompatible version of gast. Could you try 0.3.0?", "I have python 3.9.6, windows 10, tensorflow 2.6, I got the following error, \r\n\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function f1_m at 0x0000024D9B260DC0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n\r\nthe verbos has been set to 10, \r\n\r\nthis is the final report\r\n\r\nOSError: Unable to create file (unable to open file: name = 'D:/TESTS/building_detection/Data/Checkpoints\\weights.01-0.93.hdf5', errno = 24, error message = 'Too many open files', flags = 13, o_flags = 302)\r\n\r\nsame code has been used with other data, I didn't get this message.", "Hi everyone!\r\n\r\nI've had the same warnings and suddenly found out that they are caused by jupyter's magic commands. It was `%%time` command in my case. Also, these commands are also causing bugs with TF not being able to retrieve the source code for some functions. \r\n\r\nI didn't do a very thorough research, but as far as I understand, it happens due to magic commands wrapping the cells with code into some object or something. So when TensorFlow tries to get the source code with `inspect` module, it fails or at least has some difficulties, because the magic command incapsulates the whole cell code, thus making the contents of the cell not accessible to `inspect`.\r\n\r\nThus, avoid using jupyter's magic commands along with the tensorflow, they can cause this warning. And also the rule of thumb here will be to avoid any decorating structures over `@tf.function`-s.", "That's a useful find. I suspect that it you put all your code in functions in a separate cell, and only call those functions from the `%%time` ones, it should work?", "@mdanatg, I tried this and it doesn't seem to work, unfortunately. I finally did a little research and I found out that `inspect.unwrap(my_func_wrapped_in_tf_function).__code__` returns `<code object my_func_wrapped_in_tf_function at 0x7fd706258390, file \"<timed exec>\", line 36>`. Actually I found this `\"<timed exec>\"` in ipython repo, but it's hard to get why it's hiding the actual source code. But I managed to find some kind of explanation here: https://github.com/ipython/ipython/issues/11659#issuecomment-529234690\r\n\r\n> We actually do not run things in global scope, but create an anonymous function and run _this function_. So in your example, Gloop is not really globlal.\r\n> \r\n> I'm pretty sure starting your timeit with `global Gloop` should work around the issue. It's just quite hard.\r\n\r\nIt confirms my hypothesis, but doesn't provide any hacks for our case. Trying to set function name as global (in the hope that it would make its name really global) didn't work for me either.", "I see, that makes sense. This is in fact a limitation of Python itself - in order for `inspect.getsource` to work, one must load the function from a file on disk (basically, only `imp.load_module` wires source code properly); it's even a bit of mystery how Jupyter does manage to wire that source info, I suspect it does some surgery on Python's internal caches.\r\n\r\nAnyhow, we ought to get this to work if _any function that is wrapped by autograph is placed inside a Python file (and imported instead)_. In other words, no @tf.function call anywhere in the ipython code.\r\n\r\nWe're basically looking for the following call stack (conceptually):\r\n\r\nipython > timeit wrappers > module in a file > tf.function > autograph > rest of the code\r\n\r\nAssuming timeit just calls external functions without doing anything else to them, things should work that way."]}, {"number": 37143, "title": "Can I use asymmetrical images as input?", "body": "For instance, an image of 500x3000 pixels.", "comments": ["@Tylersuard,\r\nIf you are pre-processing the images to resize all of them to fixed size then yes, you can use asymmetrical images as inputs while training.\r\n\r\nFor more information, you can check [this](https://www.tensorflow.org/tutorials/load_data/images#load_using_tfdata) example from Tensorflow, which uses images of different sizes for training.", "Thank you for your help!"]}, {"number": 37141, "title": "ValueError: No gradients provided for any variable in Tensorflow 2.0, WAE", "body": "I am a tensorflow2.0 learner who is trying to reproduce the code of Wasserstein AutoEncoder or Adversarial AutoEncoder and do something interesting based on that on my own. My code below is based on[ timsainb/tensorflow2-generative-models](https://github.com/timsainb/tensorflow2-generative-models) with some of modifications.\r\n\r\n```\r\n%tensorflow_version 2.x\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow_probability as tfp\r\nfrom tqdm import tqdm\r\n'''Python 3.6.6\r\n   pip install tensorflow==2.0.0b1\r\n   pip install tfp-nightly==0.7.0.dev20190510\r\n   pip install tensorflow_probability==0.8.0rc0 --user --upgrade'''\r\n\r\nds = tfp.distributions\r\ntf.keras.backend.set_floatx('float32') # sets dtype as tf.float32\r\n\r\n#%%%\r\n'''Define the network as tf.keras.model object'''\r\n\r\nclass VAE(tf.keras.Model):\r\n    \"\"\"a VAE class for tensorflow\r\n\r\n    Extends:\r\n        tf.keras.Model\r\n    \"\"\"\r\n\r\n    def __init__(self, **kwargs):\r\n        super(VAE, self).__init__()\r\n        self.__dict__.update(kwargs)\r\n\r\n        self.pad3 = 'same'    \r\n\r\n        self.disc = tf.keras.Sequential([\r\n            tf.keras.layers.InputLayer(input_shape=int(self.intrinsic_size/4) * int(self.intrinsic_size/4)),\r\n            tf.keras.layers.Dense(units=32, activation=\"relu\", name=\"disc1\"),\r\n            tf.keras.layers.Dense(units=64, activation=\"relu\", name=\"disc2\"),\r\n            tf.keras.layers.Dense(units=128, activation=\"relu\", name=\"disc3\"),\r\n            tf.keras.layers.Dense(units=1, activation=None)\r\n            ])\r\n\r\n        self.enc = tf.keras.Sequential([\r\n            tf.keras.layers.InputLayer(input_shape=self.ipt_shape),        \r\n            tf.keras.layers.Conv2D(filters=self.hidden_layer_sizes[0], kernel_size=5, strides=(2, 2), padding='same', activation=self.activation, name=\"conv1\"),                 \r\n            tf.keras.layers.BatchNormalization(),            \r\n            tf.keras.layers.Conv2D(filters=self.hidden_layer_sizes[1], kernel_size=5, strides=(2, 2), padding='same', activation=self.activation, name=\"conv2\"),                                       \r\n            tf.keras.layers.BatchNormalization(),                   \r\n            tf.keras.layers.Conv2D(self.hidden_layer_sizes[2], kernel_size=3, strides=(2, 2), padding='same', activation=self.activation, name=\"conv3\"),\r\n            tf.keras.layers.BatchNormalization(),                \r\n            tf.keras.layers.Flatten(),\r\n            tf.keras.layers.Dense(units=self.intrinsic_size + self.intrinsic_size * self.intrinsic_size, use_bias=False, name=\"lastlayer\") #no activation function                \r\n            ]) \r\n\r\n        self.dec = tf.keras.Sequential([\r\n            tf.keras.layers.Dense(units=self.hidden_layer_sizes[2]*int(self.ipt_shape[0]/4)*int(self.ipt_shape[0]/4), activation=self.activation, name=\"revealed\"),                \r\n            tf.keras.layers.Reshape(target_shape=(int(self.ipt_shape[0]/4), int(self.ipt_shape[0]/4), self.hidden_layer_sizes[2])),                                     \r\n            tf.keras.layers.BatchNormalization(),\r\n            tf.keras.layers.Conv2DTranspose(filters=self.hidden_layer_sizes[1], kernel_size=3, strides=(2, 2), padding='same', activation=self.activation, name=\"deconv3\"),                                       \r\n            tf.keras.layers.BatchNormalization(),                      \r\n            tf.keras.layers.Conv2DTranspose(filters=self.hidden_layer_sizes[0], kernel_size=5, strides=(2, 2), padding='same', activation=self.activation, name=\"deconv2\"),\r\n            tf.keras.layers.BatchNormalization(),      \r\n            tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=5, strides=(1, 1), padding='same', activation=\"sigmoid\", name=\"deconv1\")\r\n            ])\r\n\r\n        self.vae_optimizer = tf.keras.optimizers.Adam(self.lr)\r\n        self.disc_optimizer = tf.keras.optimizers.Adam(self.lr)\r\n        self.enc_optimizer = tf.keras.optimizers.Adam(self.lr)\r\n\r\n\r\n    def encode(self, x):\r\n        mu, sigma = tf.split(self.enc(x), num_or_size_splits=[self.intrinsic_size, self.intrinsic_size * self.intrinsic_size], axis=1)\r\n        return mu, sigma    \r\n\r\n    def enc_dist(self, x):\r\n        mu, sigma = self.encode(x)\r\n        M = tf.reshape(sigma, (sigma.shape[0], self.intrinsic_size, self.intrinsic_size))        \r\n        N = ds.MultivariateNormalDiag(loc=np.zeros((sigma.shape[0], self.intrinsic_size)), scale_diag=[1.0]*self.intrinsic_size)              \r\n        eps = tf.expand_dims(tf.cast(N.sample(), tf.float32), -1)\r\n        z = tf.expand_dims(mu, -1) + tf.matmul(M, eps)\r\n        z = tf.squeeze(z)        \r\n        return z\r\n\r\n    def discriminate(self, x):\r\n        return self.disc(x) \r\n\r\n\r\n    def decode(self, z):\r\n        return self.dec(z) \r\n\r\n    def gradient_penalty(self, x, x_gen):\r\n        epsilon = tf.random.uniform([x.shape[0], 1], 0.0, 1.0)\r\n        x_hat = epsilon * x + (1 - epsilon) * x_gen\r\n        self.x_hat = x_hat\r\n        with tf.GradientTape() as t:\r\n            t.watch(x_hat)\r\n            d_hat = self.discriminate(x_hat)\r\n        gradients = t.gradient(d_hat, x_hat)\r\n        ddx = tf.sqrt(tf.reduce_sum(gradients ** 2, axis=[1]))\r\n        d_regularizer = tf.reduce_mean((ddx - 1.0) ** 2)\r\n        return d_regularizer\r\n\r\n\r\n    def compute_loss_vae(self, x):   \r\n        vae_loss = []                \r\n        latent_loss = []\r\n        enc_loss = []        \r\n        for _ in range(int(self.num_sampling)):           \r\n\r\n            self.z = z = self.enc_dist(x)             \r\n\r\n            self.x_recon = x_recon = self.decode(z)\r\n            N = ds.MultivariateNormalDiag(loc=np.zeros((z.shape[0], self.intrinsic_size)), scale_diag=[1.] * self.intrinsic_size)                \r\n            self.z_gen = z_gen = tf.cast(N.sample(), tf.float32)\r\n\r\n            self.logits_z = logits_z = self.discriminate(z)\r\n            self.logits_z_gen = logits_z_gen = self.discriminate(z_gen)            \r\n\r\n\r\n            self.d_regularizer = d_regularizer = self.gradient_penalty(z, z_gen)\r\n            self.wasserstein = wasserstein = tf.reduce_mean(logits_z_gen) - tf.reduce_mean(logits_z) + d_regularizer * self.gradient_penalty_weight\r\n\r\n            rec = tf.reduce_mean(tf.reduce_sum(tf.math.square(x - x_recon), axis=0))                      \r\n            enc = -tf.reduce_mean(logits_z)\r\n\r\n            vae_loss.append(rec)\r\n            latent_loss.append(wasserstein) \r\n            enc_loss.append(enc)                     \r\n\r\n        self.vae_loss = vae_loss = tf.reduce_mean(vae_loss, axis=0)        \r\n        self.latent_loss = latent_loss = tf.reduce_mean(latent_loss, axis=0)    \r\n        self.enc_loss = enc_loss = tf.reduce_mean(enc_loss, axis=0)\r\n        return (vae_loss, latent_loss, enc_loss)\r\n\r\n\r\n    def compute_gradients(self, x):               \r\n        with tf.GradientTape() as vae_tape, tf.GradientTape() as disc_tape, tf.GradientTape() as enc_tape:\r\n            vae_loss, latent_loss, enc_loss = self.compute_loss_vae(x)\r\n\r\n        self.vae_gradients = vae_gradients = vae_tape.gradient( vae_loss, self.enc.trainable_variables +  self.dec.trainable_variables )            \r\n        self.disc_gradients = disc_gradients = disc_tape.gradient( -latent_loss, self.disc.trainable_variables )\r\n        self.enc_gradients = enc_gradients = enc_tape.gradient(enc_loss, self.enc.trainable_variables )\r\n\r\n        return vae_gradients, disc_gradients, enc_gradients\r\n\r\n\r\n\r\n    def apply_gradients_vae(self, vae_gradients, disc_gradients, enc_gradients):        \r\n        self.vae_optimizer.apply_gradients(\r\n            zip(vae_gradients, self.enc.trainable_variables + self.dec.trainable_variables)\r\n        )\r\n        self.disc_optimizer.apply_gradients(\r\n            zip(disc_gradients, self.disc.trainable_variables)\r\n        )       \r\n\r\n        self.enc_optimizer.apply_gradients(\r\n            zip(enc_gradients, self.enc.trainable_variables)\r\n        )\r\n\r\n    @tf.function\r\n    def train(self, x):\r\n        vae_gradients, disc_gradients, enc_gradients = self.compute_gradients(x)\r\n        self.apply_gradients_vae(vae_gradients, disc_gradients, enc_gradients)\r\n\r\n\r\n    def fit(self, x):\r\n\r\n        losses = pd.DataFrame(columns=['vae_loss', 'disc_loss', 'enc_loss'])\r\n        Vae_loss = Disc_loss = Enc_loss = []\r\n\r\n        n_samples, n_height, n_width, n_channel = x.shape\r\n\r\n\r\n        n_batch = (n_samples - 1) // self.batch_size + 1\r\n        self.n_batch = n_batch\r\n\r\n        idx = np.arange(int(n_samples))\r\n        np.random.shuffle(idx)       \r\n\r\n        for epoch in range(self.epoch_size):\r\n            print(f\" Epoch: {epoch+1}/{self.epoch_size}\")\r\n\r\n            loss = []\r\n            for batch in tqdm(range(self.n_batch), position=0):\r\n                i_start = int(batch * self.batch_size)\r\n                i_end = int((batch + 1) * self.batch_size)\r\n                self.i_start = i_start\r\n                self.i_end = i_end\r\n                self.x_batch = x_batch = x[ idx[ i_start : i_end ] ]  \r\n                self.train(x_batch)\r\n\r\n\r\n                loss.append(self.compute_loss_vae(x_batch))\r\n                self.loss = loss\r\n            losses.loc[len(losses.T)] = np.mean(loss, axis=0)\r\n\r\n\r\n\r\n            self.Vae_loss = Vae_loss.append(np.mean(loss, axis=0)[0])\r\n            self.Disc_loss = Disc_loss.append(np.mean(loss, axis=0)[1])\r\n            self.Enc_loss = Enc_loss.append(np.mean(loss, axis=0)[2])\r\n            print(\" epoch: {}/{} : &\\n {}\".format(epoch+1, self.epoch_size, losses))\r\n\r\n(X_train_origin, y_train_origin), (X_test_origin, y_test_origin) = tf.keras.datasets.mnist.load_data()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    input_shape = (28,28,1)\r\n    num_train = 5000                  \r\n    X_train = X_train_origin[0:num_train]                 \r\n    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\r\n\r\n    model = VAE(\r\n            lr = 1e-3,\r\n            latent_loss_div=1, \r\n            epoch_size = 2, \r\n            batch_size = 128,\r\n            ipt_shape = input_shape,\r\n            activation = \"relu\",\r\n            hidden_layer_sizes = (32,64,128),\r\n            intrinsic_size = 16,\r\n            num_sampling = 3,\r\n            gradient_penalty_weight = 10.0,\r\n            prior_c = 0.2,\r\n            )\r\n\r\n    model.fit(X_train)\r\n```\r\n\r\nHowever, I always get a ``No gradients provided'' error. Please check the description:\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    704           except Exception as e:  # pylint:disable=broad-except\r\n    705             if hasattr(e, \"ag_error_metadata\"):\r\n--> 706               raise e.ag_error_metadata.to_exception(type(e))\r\n    707             else:\r\n    708               raise\r\n\r\nValueError: in converted code:\r\n\r\n    <ipython-input-9-8e8f91e623b2>:158 train  *\r\n        self.apply_gradients_vae(vae_gradients, disc_gradients, enc_gradients)\r\n    <ipython-input-9-8e8f91e623b2>:148 apply_gradients_vae\r\n        zip(disc_gradients, self.disc.trainable_variables)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:427 apply_gradients\r\n        grads_and_vars = _filter_grads(grads_and_vars)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:975 _filter_grads\r\n        ([v.name for _, v in grads_and_vars],))\r\n\r\n    ValueError: No gradients provided for any variable: ['disc1_4/kernel:0', 'disc1_4/bias:0', 'disc2_4/kernel:0', 'disc2_4/bias:0', 'disc3_4/kernel:0', 'disc3_4/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0'].\r\n```\r\n\r\nIf I print the gradients of discriminators, it always shows:\r\n`ListWrapper([None, None, None, None, None, None, None, None])`\r\n\r\nI know that the issue must be in the discriminator part (because once I remove the apply gradient to discriminator, the code works). However, I don't know how to fix it with discriminator and I've been thinking about it for several days. \r\n\r\nCould you please let me know where I didn't connect the network successfully? Or I stupidly messed up something somewhere?", "comments": ["I have tried on colab with TF version 2.1.0 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/1b66029ea4fa213685d03bbd323878eb/untitled689.ipynb). Thanks!", "@JCL823 I think tients are performed outside the tape context and this is the reason why the gradients are not available.\r\nFor more information, please take a look at this [issue](https://stackoverflow.com/questions/58947679/no-gradients-provided-for-any-variable-in-tensorflow2-0) ", "@gowthamkpr Oh! Thank you so much!!! You provided me a huge hint!!!\r\nI just simply remove the negative sign for `latent_loss` to be:\r\n        ```self.disc_gradients = disc_gradients = disc_tape.gradient( latent_loss, self.disc.trainable_variables )```\r\n   \r\nthen it works!!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37141\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37141\">No</a>\n"]}, {"number": 37140, "title": "Micro_speech example with a different microphone bitrate", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Windows 10\r\n- TensorFlow installed from Arduino library\r\n- 1.15.0-ALPHA precompiled\r\n- ESP32, Arduino\r\n\r\nFollowing the micro_speech example in the Arduino_TensorFlowLite library, I tried to modify the code so that it could run with my 32 bits per sample I2S microphone.\r\nHowever, this proved to be a challenge since the audio_provider files require a certain number of samples of a certain size.\r\nWhat happened, in the end, is that the code was stuck in a loop gathering data.\r\n\r\nI'm not sure where to even begin debugging this, but I'm guessing the capture buffer needs to be adjusted in order to accommodate the larger sample size\r\n\r\nSo far I've modified the arduino_audio_provider.cpp file to be the following\r\n````\r\n#include \"audio_provider.h\"\r\n#include <Arduino.h>\r\n#include <driver/i2s.h>\r\n#include \"micro_features_micro_model_settings.h\"\r\nconst i2s_port_t I2S_PORT = I2S_NUM_0;\r\n#define BUFFER_SIZE 1024\r\nTaskHandle_t audioInputTaskHandle;\r\nnamespace {\r\nbool g_is_audio_initialized = false;\r\n// An internal buffer able to fit 16x our sample size\r\nconstexpr int kAudioCaptureBufferSize = BUFFER_SIZE * 32;\r\nint32_t g_audio_capture_buffer[BUFFER_SIZE];\r\n// A buffer that holds our output\r\nint16_t g_audio_output_buffer[kMaxAudioSampleSize];\r\n// Mark as volatile so we can check in a while loop to see if\r\n// any samples have arrived yet.\r\nvolatile int32_t g_latest_audio_timestamp = 0;\r\n}  // namespace\r\nvolatile uint32_t testerino = 0;\r\nvolatile bool audioCaptureFlag = 0;\r\nvoid CaptureSamples( void *) {\r\n  while(1)\r\n  {\r\n    if(audioCaptureFlag)\r\n    {\r\n      // Determine the index, in the history of all samples, of the last sample\r\n      const int32_t start_sample_offset =\r\n          g_latest_audio_timestamp * (kAudioSampleFrequency / 1000);//0\r\n      // Determine the index of this sample in our ring buffer\r\n      const int capture_index = start_sample_offset % kAudioCaptureBufferSize;//0\r\n      size_t bytesRead;\r\n      i2s_read(I2S_PORT, (void*) g_audio_capture_buffer + capture_index, BUFFER_SIZE, &bytesRead, portMAX_DELAY);\r\n      // This is how many bytes of new data we have each time this is called\r\n      const int number_of_samples = bytesRead / 8;\r\n      // Calculate what timestamp the last audio sample represents\r\n      const int32_t time_in_ms =\r\n          g_latest_audio_timestamp +\r\n          (number_of_samples / (kAudioSampleFrequency / 1000)); //6,12\r\n      \r\n      // Read the data to the correct place in our buffer\r\n      // Serial.println(g_latest_audio_timestamp);\r\n      // Serial.println(start_sample_offset);\r\n      Serial.println(capture_index);\r\n      delay(1);\r\n      // for(uint16_t i = 0; i < bytesRead; i++)\r\n        // Serial.printf(\"%d, %ld\\n\", i, g_audio_capture_buffer[i]);\r\n        // Serial.println(g_audio_capture_buffer[i]);\r\n      \r\n      // PDM.read(g_audio_capture_buffer + capture_index, DEFAULT_PDM_BUFFER_SIZE);\r\n      // This is how we let the outside world know that new audio data has arrived.\r\n      // Serial.print(\"latest timestamp: \");\r\n      // Serial.println(bytesRead);\r\n      // Serial.flush();\r\n      // delay(1);\r\n      testerino++;\r\n\r\n      g_latest_audio_timestamp = time_in_ms;\r\n    }\r\n    vTaskDelay(1);\r\n  }\r\n}\r\n\r\nTfLiteStatus InitAudioRecording(tflite::ErrorReporter* error_reporter) {\r\n    Serial.println(\"init audio recording\");\r\n    delay(10);\r\n\r\n  // Hook up the callback that will be called with each sample\r\n  // PDM.onReceive(CaptureSamples);\r\n  // Start listening for audio: MONO @ 16KHz with gain at 20\r\n  // PDM.begin(1, kAudioSampleFrequency);\r\n  // PDM.setGain(20);\r\n   // The I2S config as per the example\r\n  const i2s_config_t i2s_config = {\r\n      .mode = i2s_mode_t(I2S_MODE_MASTER | I2S_MODE_RX), // Receive, not transfer\r\n      .sample_rate = 16000,                         // 16KHz\r\n      .bits_per_sample = I2S_BITS_PER_SAMPLE_32BIT, // could only get it to work with 32bits\r\n      .channel_format = I2S_CHANNEL_FMT_ONLY_RIGHT, // although the SEL config should be left, it seems to transmit on right\r\n      .communication_format = i2s_comm_format_t(I2S_COMM_FORMAT_I2S | I2S_COMM_FORMAT_I2S_MSB),\r\n      .intr_alloc_flags = ESP_INTR_FLAG_LEVEL1,     // Interrupt level 1\r\n      .dma_buf_count = 8,                           // number of buffers\r\n      .dma_buf_len = BUFFER_SIZE                              // 32 samples per buffer (minimum)\r\n  };\r\n\r\n  // The pin config as per the setup\r\n  const i2s_pin_config_t pin_config = {\r\n      .bck_io_num = 13,   // BCKL\r\n      .ws_io_num = 15,    // LRCL\r\n      .data_out_num = -1, // not used (only for speakers)\r\n      .data_in_num = 32   // DOUT\r\n  };\r\n  esp_err_t err;\r\n  // Configuring the I2S driver and pins.\r\n  // This function must be called before any I2S driver read/write operations.\r\n  err = i2s_driver_install(I2S_PORT, &i2s_config, 0, NULL);\r\n  if (err != ESP_OK) {\r\n    Serial.printf(\"Failed installing driver: %d\\n\", err);\r\n    while (true);\r\n  }\r\n  err = i2s_set_pin(I2S_PORT, &pin_config);\r\n  if (err != ESP_OK) {\r\n    Serial.printf(\"Failed setting pin: %d\\n\", err);\r\n    while (true);\r\n  }\r\n  Serial.println(\"I2S driver installed.\");\r\n  delay(1);\r\n  // uint32_t samples[8];\r\n  // int bytes_read = i2s_pop_sample(I2S_PORT, (char *)&sample, portMAX_DELAY); // no timeout\r\n  // size_t bytes_read;\r\n  // esp_err_t error = i2s_read(I2S_PORT, (char *)samples, 8, &bytes_read, portMAX_DELAY);\r\n  // Serial.println(error == ESP_OK);\r\n  // delay(1);\r\n  // if (bytes_read > 0) {\r\n  //   float mean = 0;\r\n  //   for (int i = 0; i < bytes_read; ++i) {\r\n  //     mean += samples[i];\r\n  //   }\r\n  //   Serial.println(mean);\r\n  // }\r\n  // delay(10);\r\n  // Block until we have our first audio sample\r\n  xTaskCreate(CaptureSamples, \"adc_read_task\", kAudioCaptureBufferSize, NULL, 5, &audioInputTaskHandle);\r\n  audioCaptureFlag = 1;\r\n\r\n  while (!g_latest_audio_timestamp) {\r\n  }\r\n\r\n  return kTfLiteOk;\r\n}\r\n\r\nTfLiteStatus GetAudioSamples(tflite::ErrorReporter* error_reporter,\r\n                             int start_ms, int duration_ms,\r\n                             int* audio_samples_size, int16_t** audio_samples) {\r\n  // Set everything up to start receiving audio\r\n  if (!g_is_audio_initialized) {\r\n    TfLiteStatus init_status = InitAudioRecording(error_reporter);\r\n    if (init_status != kTfLiteOk) {\r\n      return init_status;\r\n    }\r\n    g_is_audio_initialized = true;\r\n  }\r\n  else\r\n  {\r\n    // Serial.println(\"task resumed\");\r\n    // Serial.flush();\r\n    // delay(10);\r\n    // xTaskCreate(CaptureSamples, \"adc_read_task\", kAudioCaptureBufferSize, NULL, 1, &audioInputTaskHandle);\r\n    audioCaptureFlag = 1;\r\n    // vTaskResume(audioInputTaskHandle);\r\n  }\r\n\r\n\r\n  // This next part should only be called when the main thread notices that the\r\n  // latest audio sample data timestamp has changed, so that there's new data\r\n  // in the capture ring buffer. The ring buffer will eventually wrap around and\r\n  // overwrite the data, but the assumption is that the main thread is checking\r\n  // often enough and the buffer is large enough that this call will be made\r\n  // before that happens.\r\n\r\n  // Determine the index, in the history of all samples, of the first\r\n  // sample we want\r\n  const int start_offset = start_ms * (kAudioSampleFrequency / 1000);\r\n  // Determine how many samples we want in total\r\n  const int duration_sample_count =\r\n      duration_ms * (kAudioSampleFrequency / 1000);\r\n  // Serial.println(duration_sample_count);\r\n  // delay(10);\r\n  for (int i = 0; i < duration_sample_count; ++i) {\r\n    \r\n    // delay(1);\r\n    // For each sample, transform its index in the history of all samples into\r\n    // its index in g_audio_capture_buffer\r\n    const int capture_index = (start_offset + i) % kAudioCaptureBufferSize;\r\n    \r\n    // Write the sample to the output buffer\r\n    g_audio_output_buffer[i] = ((int16_t*)g_audio_capture_buffer)[capture_index];\r\n    // Serial.printf(\"inside loop %d\\n\", i);\r\n    // delay(1);\r\n  }\r\n  \r\n  // Serial.printf(\"got samples\\n\");\r\n  audioCaptureFlag = 0;\r\n  // Serial.println(testerino);\r\n  // delay(10);\r\n  // testerino = 0;\r\n  // vTaskDelete(audioInputTaskHandle);\r\n  \r\n  // Serial.println(\"task deleted\");\r\n  // delay(10);\r\n\r\n\r\n  // Set pointers to provide access to the audio\r\n  *audio_samples_size = kMaxAudioSampleSize;\r\n  *audio_samples = g_audio_output_buffer;\r\n\r\n  return kTfLiteOk;\r\n}\r\n\r\nint32_t LatestAudioTimestamp() { return g_latest_audio_timestamp; }\r\n```\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37140\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37140\">No</a>\n"]}, {"number": 37139, "title": "Conda install Tensorflow 2.1 with mkl (avx/avx2 support) not working", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):  tensorflow 3.1 with mkl binary from Anaconda installation\r\n- TensorFlow version: 3.1.0\r\n- Python version: 3.7.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: na\r\n- GPU model and memory: na\r\n\r\n\r\n\r\nI was using tensorflow 2.0 with mkl (avx/avx2 optimization) and has zero problem. I just upgraded to tf 2.1 using Anaconda. After upgrade, tf complains that \"Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\".\r\n\r\nTo make sure I upgraded correctly. I uninstalled all tensorflow components, and then do a fresh install using command conda install tensorflow-mkl. The installation succeed but the problem persists.\r\n\r\nwhen I run the same training script, I saw the performance is worse than the 2.0. So, I guess the avx2 is not used in 2.1 \r\n\r\n\r\n\r\n\r\n", "comments": ["@wangzhizhengduke, Can you provide the standalone complete code to analyze the issue. Thanks!", "@wangzhizhengduke, Can you provide more information to understand the issue better. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37139\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37139\">No</a>\n", "I have tensorflow2.0 with mkl. Can you please help here? \r\n\r\nHere's the code:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ninput_A = keras.layers.Input(shape=[5], name=\"wide_input\")\r\ninput_B = keras.layers.Input(shape=[6], name=\"deep_input\")\r\nhidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\r\nhidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\r\nconcat = keras.layers.concatenate([input_A, hidden2])\r\noutput = keras.layers.Dense(1, name=\"output\")(concat)\r\nmodel = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\r\n\r\n```\r\n\r\nHere's the output:\r\n```\r\n2020-12-12 17:06:46.037846: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2020-12-12 17:06:46.040928: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n```\r\nPlease let me know how I can assist in debugging this issue.\r\n\r\nHere's the mkl check from https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html\r\nCode:\r\n```\r\nmajor_version = int(tf.__version__.split(\".\")[0])\r\nif major_version >= 2:\r\n   from tensorflow.python import _pywrap_util_port\r\n   print(\"MKL enabled:\", _pywrap_util_port.IsMklEnabled())\r\nelse:\r\n   print(\"MKL enabled:\", tf.pywrap_tensorflow.IsMklEnabled()) \r\n```\r\nOutput:\r\n\r\n`MKL enabled: True\r\n`"]}, {"number": 37138, "title": "Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@png_archive//': Traceback (most recent call last):", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version:1.13\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):0.21.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory: Geforce GTX 1050/4gb\r\n\r\n\r\n\r\n**when i try to build tensorflow from source with below command it arises errors**\r\n\r\n`**bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package**\r\n`\r\n\r\n```\r\n**C:\\Tensorflow_build\\tensorflow>bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\nc:\\tensorflow_build\\tensorflow/.bazelrc\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nINFO: Invocation ID: 72078163-23a3-48fa-bd94-3ebfaea84d8b\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/tensorflow_build/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/tensorflow_build/tensorflow/third_party/repo.bzl\", line 73, in _apply_patch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/tensorflow_build/tensorflow/third_party/repo.bzl\", line 52, in _execute_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(2) when executing 'C:\\tools\\msys64\\usr\\bin\\bash.exe -l -c \"patch\" \"-p1\" \"-d\" \"\"C:/users/shahansha c/_bazel_shahansha c/6v547imx/external/png_archive\"\" \"-i\" \"C:/tensorflow_build/tensorflow/third_party/png_fix_rpi.patch\"':\r\nStdout:\r\nStderr: patch: **** Can't change to directory C:/users/shahansha : No such file or directory\r\nINFO: Elapsed time: 6.859s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (5 packages loaded, 338 targets configured)\r\n    Fetching @icu; fetching 5s\r\n    Fetching @grpc; fetching 5s\r\n    Fetching @eigen_archive; fetching 5s\r\n    Fetching @boringssl; fetching 5s\r\n    Fetching @png_archive; fetching 5s\r\n    Fetching @curl; fetching 5s\r\n    Fetching @swig; fetching 5s\r\n    Fetching @nasm; fetching**\r\n```\r\n\r\ni have a space in my username :(\r\nmay be that is the problem But i dont know how to change it\r\nis there any way to build tensorflow from source when there is a white space in user name (on the path)", "comments": ["there is no reply :( ", "Just to verify did you follow the instuctions from [Tensorflow website](https://www.tensorflow.org/install/gpu#windows_setup) and followed the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu)..Make sure you update environment path for cuda. Provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "@ravikyram \r\ni followed the instruction from [Build from source on Windows](https://www.tensorflow.org/install/source_windows)", "i am trying to build the tensorflow from source to just convert my custom trained object detection ssd model to to tensorflow lite. is there any way to do that without building tensorflow from source?\r\ni have already installed tensorflow by pip", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37138\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37138\">No</a>\n"]}, {"number": 37137, "title": "NameError: name 'LSTM' is not defined ", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  **MAC OS CATALINA**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): **I'm pretty sure it is binary**\r\n- TensorFlow version: **2.1.0**\r\n- Python version: **3.7.6**\r\n- Installed using virtualenv? pip? conda?: **pip3**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **10.2**\r\n- GPU model and memory:  **Intel HD Graphics 4000 1536 MB** . Memory = **4 GB 1600 MHz DDR3**\r\n\r\n**The problem**\r\nI am attempting to build a LSTM model to process and predict datasets.  I have tensorflow installed on my mac and have keras installed.  I have also installed CUDA and some other sequential model libraries I heard would help, but my problem persists.  My program is returning the error\r\n\r\n`Traceback (most recent call last):\r\n  File \"/Users/owner/Desktop/algo/predict.py\", line 64, in <module>\r\n    model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\r\nNameError: name 'LSTM' is not defined`\r\n\r\nMy import statements look like this:\r\n\r\n`import requests`\r\n`import math`\r\n`import numpy as np`\r\n`import pandas as pd`\r\n`import pandas_datareader as web`\r\n`import tensorflow as tf`\r\n`from tensorflow import keras`\r\n`from tensorflow.keras import layers`\r\n`from tensorflow.keras.models import Sequential, load_model`\r\n`from sklearn.preprocessing import MinMaxScaler`\r\n`from bs4 import BeautifulSoup`\r\n`import matplotlib.pyplot as plt`\r\n`from datetime import datetime, date`\r\n\r\nand the code for the model looks like this:\r\n\r\n`#Build LSTM MODEL`\r\n`model = tf.keras.Sequential()`\r\n`model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))`\r\n`model.add(LSTM(50, return_sequences=False))`\r\n`model.add(Dense(25))`\r\n`model.add(Dense(1))`\r\n`model.compile(optimizer='adam', loss='mean_squared_error')`\r\n\r\nI tried to look for an import statement that could import lstm from tensorflow\r\nsomething like:\r\n`from tensorflow.keras.models import LSTM`\r\nBut I could not find anything.\r\n\r\nThankYou,\r\nRRR.\r\n", "comments": ["It should be from tensorflow.keras.layers import LSTM. Thank you.", "After solving for LSTM, you'll  get the same error for Dense. \r\nDo something, use  layers.LSTM and layers.Dense instead of LSTM and DENSE directly cuz you have already imported \"layers\"", "@rehanmahmood,\r\nCould you please add these two import statements in your code\r\n```\r\nfrom tensorflow.keras.layers import LSTM\r\nfrom tensorflow.keras.layers import Dense\r\n```\r\nPlease take a look at [this](https://colab.sandbox.google.com/gist/amahendrakar/0b12b11b100e169afc1bfd1a61cdcb78/37137.ipynb) gist as a reference. Thanks!", "Yessir thank you.  However I am returning a completely different error now.  Could you please see this issue.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/37149", "I think it would be a good idea to close this issue given that you have opened a new issue that is being discussed in a separate thread!"]}, {"number": 37136, "title": "[ROCm][XLA:GPU] Fixing xla executable buffer creation", "body": "Discovered this when having VLOG on. (line 76 will de-reference the nullptr, causing a segmentation fault) This commit also fixed some intermittent ROCm CI failures.\r\n\r\n/cc: @whchung @cheshire ", "comments": []}, {"number": 37135, "title": "Save and load model neural network", "body": "Hi,\r\nI am a beginner in neural network, I follow a tutorial (https://www.datacamp.com/community/tutorials/cnn-tensorflow-python) for create it.\r\n[tuto.py.tar.gz](https://github.com/tensorflow/tensorflow/files/4262620/tuto.py.tar.gz)\r\n-> It is my soft.\r\n\r\nI add some lines to save a model of my network. I have \".meta\" file.\r\nMy problem is, how I can use this model on an other soft for predict if I have shirt, coat, ... in my image.\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Sorry, I forget something. I want to do load with low level tensorflow API. \r\nBecause with keras I know how to do that", "@AlturRang, Please find the [Tensorflow doc](https://www.tensorflow.org/api_docs/python/tf/saved_model/load) for loading the saved model. Use tf.saved_mdel.load() function as \r\n`imported = tf.saved_model.load(path)` to load saved model .\r\nThanks!", "@gadagashwini, Thanks for your quick answer. I try to use the function that you say. But I have a problem with:\r\npath ='/home/cassip01/tuto_tensorflow/fashion_mnist'\r\nloaded = tf.saved_model.load(path, None)\r\nWhen I execute the soft I have this error:\r\nTraceback (most recent call last):\r\n  File \"load.py\", line 9, in <module>\r\n    loaded = tf.saved_model.load(path, None)\r\n  File \"/home/cassip01/.local/lib/python3.5/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\nTypeError: load() missing 1 required positional argument: 'export_dir'\r\nDo you have an idea what is the problem exactly?\r\nBecause I put 2 argument, the path for the model and the tags", "@AlturRang, Can you share the complete code to analyze the issue. Thanks!", "[fashion_mnist.tar.gz](https://github.com/tensorflow/tensorflow/files/4274156/fashion_mnist.tar.gz)\r\nIn this folder you can see \"tuto.py\" for the training of the neural network and \"load.py\" is for load the neural network's model.\r\nI use python 3.5 for execute python file", "@AlturRang, Can you share the Tensorflow version that you are using. Thanks!", "I use tensorflow 1.15.0", "I was able to replicate the issue with Tf 1.15.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/63019ec8c97b8220b06605ccd5dec1b9/untitled433.ipynb). Thanks", "Sorry I have very busy, so I can't answer early.\r\nOk, you have the same error like me but do you find an answer to fix it?", "@AlturRang The issue is with saving the model here. Looks like its not saved at all and its being used. I would recommed to post this issue in satckoverflow as it is not a bug/performance, build/install, feature request related issue where there is a wider community to respond. Thanks!"]}, {"number": 37134, "title": "list of operators for which you will need custom implementations: StatelessWhile, TensorListFromTensor, TensorListReserve, TensorListStack, While.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04\r\n- TensorFlow installed from (source or binary):pip3 install\r\n- TensorFlow version (or github SHA if from source):2.1.0\r\n\r\nI  want to convert an RNN model to tflite. The code I used is :\r\n` converter = tf.lite.TFLiteConverter.from_saved_model(fd_path)\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]\r\n    tflite_quant_model = converter.convert()`\r\n\r\nbut I got :\r\n\r\n`Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: StatelessWhile, TensorListFromTensor, TensorListReserve, TensorListStack, While.`\r\n\r\n\r\nI guess this error may be because I used `tfa.seq2seq.dynamic_decode` in my model. So I try to set:\r\n\r\n`converter.experimental_new_converter = True`\r\n\r\nand convert it again, but I got a new error:\r\n\r\n`Exception: <unknown>:0: error: loc(\"TensorArrayV2Write/cond@__inference_Tacotron_model_inference_decoder_while_body_1121_661_frozen\"): failed to legalize operation 'tf.If'\r\n`\r\n\r\n\r\nI can't find any way to resolve this issue, and I want to know does TFlite support convert `dynamic_decode`? can this issue be resolved if I custom implementations: StatelessWhile, TensorListFromTensor, TensorListReserve, TensorListStack, While?\r\n", "comments": ["@xuexuanyu \r\n\r\nCan you try with the below code and see if it helps you. If you still face the issue please share simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(fd_path)\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_quant_model = converter.convert()\r\n```\r\n", "> @xuexuanyu\r\n> \r\n> Can you try with the below code and see if it helps you. If you still face the issue please share simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!\r\n> \r\n> ```\r\n> converter = tf.lite.TFLiteConverter.from_saved_model(fd_path)\r\n> converter.experimental_new_converter = True\r\n> converter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n> tflite_quant_model = converter.convert()\r\n> ```\r\n\r\nHI\uff01@ravikyram\r\nthank you for your reply\uff01\r\n\r\nI have try the code you provide , but I stll got error info:\r\n`Skipping registering GPU devices...\r\n2020-02-28 20:06:40.803980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-28 20:06:40.803994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-02-28 20:06:40.804011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\nloc(\"TensorArrayV2Write/cond@__inference_Tacotron_model_inference_decoder_while_body_1121_661_frozen\"): error: failed to legalize operation 'tf.If'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"TensorArrayV2Write/cond@__inference_Tacotron_model_inference_decoder_while_body_1121_661_frozen\"): failed to legalize operation 'tf.If'`\r\n\r\nThe entire code I used is just :\r\n`    import tensorflow as tf\r\n   \r\n    if __name__ == '__main__':\r\n        fd_path = '/data2/user/models/xVJhm1iUo8_pb/new'\r\n        converter = tf.lite.TFLiteConverter.from_saved_model(fd_path)\r\n        converter.experimental_new_converter = True\r\n        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n        tflite_quant_model = converter.convert()`\r\n\r\nI really want to know how to resolve this issue, I can't found any useful info.\r\n\r\nMaybe the issue is in my saved_model, but the model size is too big(about 120MB), I don't know how to upload to here.\r\nWould you mind give me your E-mail address so I can send the model file to you?\r\n", "Can you try using the nightly TF Pip to test this again? We've landed a lot of improvements since 2.1 to this path.", "> Can you try using the nightly TF Pip to test this again? We've landed a lot of improvements since 2.1 to this path.\r\n\r\n@jdduke \r\nMy efficientdet model was trained with tf 2.1. I can converted it to tf lite successfully. However, I get an error when running interpreter.allocate_tensors().\r\n\"RuntimeError: Encountered unresolved custom op: TensorListFromTensor.Node number 864 (TensorListFromTensor) failed to prepare.\"\r\nThe error is detailed in this \r\n\r\n> https://github.com/tensorflow/tensorflow/issues/37003#issue-569633708\r\n\r\nWhen I converted the model trained with tf 2.1 using tf-nightly(2.2.0.dev20200304), I get another error as follows.   \r\nMy converting code:\r\n`export_dir = \"tf_save/ckpts_B1_image-size-640/mbconv_head_anchor-extend_1e-6/\"\r\ntf.saved_model.save(efficientdet_model, export_dir)  \r\nexport_dir = \"tf_save/ckpts_B1_image-size-640/mbconv_head_anchor-extend_1e-6/\"\r\nmodel_tfsave = tf.saved_model.load(export_dir)   \r\nconcrete_func = model_tfsave.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]   concrete_func.inputs[1].set_shape([1,511500,4])   \r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])   \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True  \r\n converter.allow_custom_ops = True   \r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS] \r\n tflite_model = converter.convert()  `\r\n`---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-46-c548bab089a8> in <module>()\r\n----> 1 tflite_model = converter.convert()\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    225       stdout = _try_convert_to_unicode(stdout)\r\n    226       stderr = _try_convert_to_unicode(stderr)\r\n--> 227       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    228   finally:\r\n    229     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-03-05 02:57:40.843279: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:305] Ignored output_format.\r\n2020-03-05 02:57:40.843347: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:308] Ignored drop_control_dependency.\r\nloc(fused[callsite(\"efficientdet_p/filtered_detections/map/TensorArrayV2_2@__inference__wrapped_model_150128\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":604:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":578:0 at callsite(\"<ipython-input-13-e6e1ea129831>\":2:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":533:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":196:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":235:0))))))))), \"StatefulPartitionedCall/efficientdet_p/filtered_detections/map/TensorArrayV2_2\"]): error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\nloc(fused[callsite(\"efficientdet_p/filtered_detections/map/TensorArrayV2_2@__inference__wrapped_model_150128\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":604:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":578:0 at callsite(\"<ipython-input-13-e6e1ea129831>\":2:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":533:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":196:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":235:0))))))))), \"StatefulPartitionedCall/efficientdet_p/filtered_detections/map/TensorArrayV2_2\"]): error: failed to legalize operation 'tf.TensorListReserve'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:604:27: error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\n                          export_dir)\r\n                          ^\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:578:3: note: called from\r\n  return load_internal(export_dir, tags)\r\n  ^\r\n<ipython-input-13-e6e1ea129831>: note: called from\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\r\n                exec(code_obj, self.user_global_ns, self.user_ns)\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\r\n                if self.run_code(code, result):\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\r\n                   interactivity=interactivity, compiler=compiler, result=result)\r\n                   ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:533:9: note: called from\r\n        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:196:13: note: called from\r\n            res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n            ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\r\n                                        user_expressions, allow_stdin)\r\n                                        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:235:17: note: called from\r\n                handler(stream, idents, msg)\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:604:27: error: failed to legalize operation 'tf.TensorListReserve'\r\n                          export_dir)\r\n                          ^\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:578:3: note: called from\r\n  return load_internal(export_dir, tags)\r\n  ^\r\n<ipython-input-13-e6e1ea129831>: note: called from\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\r\n                exec(code_obj, self.user_global_ns, self.user_ns)\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\r\n                if self.run_code(code, result):\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\r\n                   interactivity=interactivity, compiler=compiler, result=result)\r\n                   ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:533:9: note: called from\r\n        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:196:13: note: called from\r\n            res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n            ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\r\n                                        user_expressions, allow_stdin)\r\n                                        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:235:17: note: called from\r\n                handler(stream, idents, msg)`\r\n\r\n.\r\n\r\nCan you help me?", "The error comes from here:\r\nhttps://github.com/tensorflow/tensorflow/blob/3006330ea0c3e88651195ac7c7de654291377ebb/tensorflow/compiler/mlir/lite/transforms/lower_static_tensor_list.cc#L352\r\n\r\nIn that case, the Tensorlist op receives a dynamic shape and it isn't supported by MLIR converter, so we raise an error here. Could you locate where the TensorArray is created in your model and try pass it with a static element_shape?", "> Can you try using the nightly TF Pip to test this again? We've landed a lot of improvements since 2.1 to this path.\r\n\r\nHi jdduke , I have tried on tf-nigthly-2.2, but still got this error message: 'failed to legalize operation 'tf.If' \r\n\r\n\r\n\r\n`\r\nSkipping registering GPU devices... 2020-02-28 20:06:40.803980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-02-28 20:06:40.803994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108] 0 2020-02-28 20:06:40.804011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0: N loc(\"TensorArrayV2Write/cond@__inference_Tacotron_model_inference_decoder_while_body_1121_661_frozen\"): error: failed to legalize operation 'tf.If' Traceback (most recent call last): File \"/usr/local/bin/toco_from_protos\", line 10, in <module> sys.exit(main()) File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main app.run(main=execute, argv=[sys.argv[0]] + unparsed) File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef) File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run _run_main(main, args) File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main sys.exit(main(argv)) File \"/home/user/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute enable_mlir_converter) Exception: <unknown>:0: error: loc(\"TensorArrayV2Write/cond@__inference_Tacotron_model_inference_decoder_while_body_1121_661_frozen\"): failed to legalize operation 'tf.If'`", "> The error comes from here:\r\n> https://github.com/tensorflow/tensorflow/blob/3006330ea0c3e88651195ac7c7de654291377ebb/tensorflow/compiler/mlir/lite/transforms/lower_static_tensor_list.cc#L352\r\n> \r\n> In that case, the Tensorlist op receives a dynamic shape and it isn't supported by MLIR converter, so we raise an error here. Could you locate where the TensorArray is created in your model and try pass it with a static element_shape?\r\n\r\nAre these lines of code with list comprehension TensorArray and Tensorlist op?\r\n\r\n`features = [layers.Conv2DTranspose(w_bifpn, (3,3), strides=2, padding=\"same\",  \r\nactivation=\"relu\",name=\"deconv_\"+str(i))(fe) for i,fe in enumerate(features)]  \r\n\r\nregression = [regress_head(feature) for feature in features]  \r\n\r\nclassification = [class_head(feature) for feature in features]  \r\n\r\nfeatures = [layers.UpSampling2D(interpolation='bilinear')(fe) for fe in features]`  ", "@xuexuanyu \r\nI get one similar error message: failed to legalize operation 'tf.TensorListReserve'.  I trained my model and converted it to tf.lite with tf-nightly 2.2.0-dev20200304.\r\nThe error as follows. How to resolve it?\r\n`---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-16-c548bab089a8> in <module>()\r\n----> 1 tflite_model = converter.convert()\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    225       stdout = _try_convert_to_unicode(stdout)\r\n    226       stderr = _try_convert_to_unicode(stderr)\r\n--> 227       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    228   finally:\r\n    229     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-03-05 08:05:55.555460: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:305] Ignored output_format.\r\n2020-03-05 08:05:55.555524: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:308] Ignored drop_control_dependency.\r\nloc(fused[callsite(\"efficientdet_p/filtered_detections/map/TensorArrayV2_2@__inference__wrapped_model_38314\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":604:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":578:0 at callsite(\"<ipython-input-7-e6e1ea129831>\":2:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":533:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":196:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":235:0))))))))), \"StatefulPartitionedCall/efficientdet_p/filtered_detections/map/TensorArrayV2_2\"]): error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\nloc(fused[callsite(\"efficientdet_p/filtered_detections/map/TensorArrayV2_2@__inference__wrapped_model_38314\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":604:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":578:0 at callsite(\"<ipython-input-7-e6e1ea129831>\":2:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":533:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":196:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":235:0))))))))), \"StatefulPartitionedCall/efficientdet_p/filtered_detections/map/TensorArrayV2_2\"]): error: failed to legalize operation 'tf.TensorListReserve'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:604:27: error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\n                          export_dir)\r\n                          ^\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:578:3: note: called from\r\n  return load_internal(export_dir, tags)\r\n  ^\r\n<ipython-input-7-e6e1ea129831>: note: called from\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\r\n                exec(code_obj, self.user_global_ns, self.user_ns)\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\r\n                if self.run_code(code, result):\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\r\n                   interactivity=interactivity, compiler=compiler, result=result)\r\n                   ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:533:9: note: called from\r\n        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:196:13: note: called from\r\n            res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n            ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\r\n                                        user_expressions, allow_stdin)\r\n                                        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:235:17: note: called from\r\n                handler(stream, idents, msg)\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:604:27: error: failed to legalize operation 'tf.TensorListReserve'\r\n                          export_dir)\r\n                          ^\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:578:3: note: called from\r\n  return load_internal(export_dir, tags)\r\n  ^\r\n<ipython-input-7-e6e1ea129831>: note: called from\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\r\n                exec(code_obj, self.user_global_ns, self.user_ns)\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\r\n                if self.run_code(code, result):\r\n                ^\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\r\n                   interactivity=interactivity, compiler=compiler, result=result)\r\n                   ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:533:9: note: called from\r\n        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:196:13: note: called from\r\n            res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n            ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\r\n                                        user_expressions, allow_stdin)\r\n                                        ^\r\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:235:17: note: called from\r\n                handler(stream, idents, msg)\r\n                ^\r\n\r\n\r\n`", "> > The error comes from here:\r\n> > https://github.com/tensorflow/tensorflow/blob/3006330ea0c3e88651195ac7c7de654291377ebb/tensorflow/compiler/mlir/lite/transforms/lower_static_tensor_list.cc#L352\r\n> > \r\n> > In that case, the Tensorlist op receives a dynamic shape and it isn't supported by MLIR converter, so we raise an error here. Could you locate where the TensorArray is created in your model and try pass it with a static element_shape?\r\n> \r\n> Are these lines of code with list comprehension TensorArray and Tensorlist op?\r\n> \r\n> `features = [layers.Conv2DTranspose(w_bifpn, (3,3), strides=2, padding=\"same\",\r\n> activation=\"relu\",name=\"deconv_\"+str(i))(fe) for i,fe in enumerate(features)]\r\n> \r\n> regression = [regress_head(feature) for feature in features]\r\n> \r\n> classification = [class_head(feature) for feature in features]\r\n> \r\n> features = [layers.UpSampling2D(interpolation='bilinear')(fe) for fe in features]`\r\n\r\nIt doesn't seem like those are where tensorlist ops originated. Do you mind sharing your model file along with a reproducible script? ", "> @xuexuanyu\r\n> I get one similar error message: failed to legalize operation 'tf.TensorListReserve'. I trained my model and converted it to tf.lite with tf-nightly 2.2.0-dev20200304.\r\n> The error as follows. How to resolve it?\r\n> `---------------------------------------------------------------------------\r\n> ConverterError Traceback (most recent call last)\r\n> in ()\r\n> ----> 1 tflite_model = converter.convert()\r\n> \r\n> 2 frames\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n> 225 stdout = _try_convert_to_unicode(stdout)\r\n> 226 stderr = _try_convert_to_unicode(stderr)\r\n> --> 227 raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n> 228 finally:\r\n> 229 # Must manually cleanup files.\r\n> \r\n> ConverterError: See console for info.\r\n> 2020-03-05 08:05:55.555460: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:305] Ignored output_format.\r\n> 2020-03-05 08:05:55.555524: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:308] Ignored drop_control_dependency.\r\n> loc(fused[callsite(\"efficientdet_p/filtered_detections/map/TensorArrayV2_2@__inference__wrapped_model_38314\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":604:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":578:0 at callsite(\"\":2:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":533:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":196:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":235:0))))))))), \"StatefulPartitionedCall/efficientdet_p/filtered_detections/map/TensorArrayV2_2\"]): error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\n> loc(fused[callsite(\"efficientdet_p/filtered_detections/map/TensorArrayV2_2@__inference__wrapped_model_38314\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":604:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\":578:0 at callsite(\"\":2:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":533:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":196:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":235:0))))))))), \"StatefulPartitionedCall/efficientdet_p/filtered_detections/map/TensorArrayV2_2\"]): error: failed to legalize operation 'tf.TensorListReserve'\r\n> Traceback (most recent call last):\r\n> File \"/usr/local/bin/toco_from_protos\", line 8, in\r\n> sys.exit(main())\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n> app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n> _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n> File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n> _run_main(main, args)\r\n> File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n> sys.exit(main(argv))\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n> enable_mlir_converter)\r\n> Exception: /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:604:27: error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\n> export_dir)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:578:3: note: called from\r\n> return load_internal(export_dir, tags)\r\n> ^\r\n> : note: called from\r\n> /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\r\n> exec(code_obj, self.user_global_ns, self.user_ns)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\r\n> if self.run_code(code, result):\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\r\n> interactivity=interactivity, compiler=compiler, result=result)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:533:9: note: called from\r\n> return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:196:13: note: called from\r\n> res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\r\n> user_expressions, allow_stdin)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:235:17: note: called from\r\n> handler(stream, idents, msg)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:604:27: error: failed to legalize operation 'tf.TensorListReserve'\r\n> export_dir)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:578:3: note: called from\r\n> return load_internal(export_dir, tags)\r\n> ^\r\n> : note: called from\r\n> /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\r\n> exec(code_obj, self.user_global_ns, self.user_ns)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\r\n> if self.run_code(code, result):\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\r\n> interactivity=interactivity, compiler=compiler, result=result)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:533:9: note: called from\r\n> return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:196:13: note: called from\r\n> res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\r\n> user_expressions, allow_stdin)\r\n> ^\r\n> /usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:235:17: note: called from\r\n> handler(stream, idents, msg)\r\n> ^\r\n> \r\n> `\r\n\r\nThe issue is the same. Do you have a reproducible script?", "@haozha111 \r\nCould you try the following shared link again and download all in the link.\r\n\r\n> https://drive.google.com/open?id=15i6d9yJ-OAcPROiGEs-RWmG-v6KyQauK\r\n\r\nThen,you can train one model with train_test.ipynb and convert it with convert_model_test.ipynb.\r\nAnd, should I implement the custom op \"TensorListFromTensor\" by myself according to my issue?", "I am facing the same error as I run:\r\n\r\n```python\r\nconcrete_fn = model.predict.get_concrete_function()\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_fn])\r\nconverter.experimental_new_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```\r\n\r\nI am using a `tf.TensorArray` in order to collect the model-output in my decoding loop:\r\n\r\n\r\n```python\r\ndef infer(self, inputs: tf.Tensor, blank=0):\r\n\r\n    # ...\r\n\r\n    predicted_ids = tf.TensorArray(dtype=tf.int32, size=100, dynamic_size=True)\r\n    predicted_ids = predicted_ids.write(0, blank)\r\n\r\n    # ...\r\n\r\n    _, _, _, _, predicted_ids = tf.while_loop(\r\n        cond=condition_,\r\n        body=body_,\r\n        loop_vars=(time_steps, i, encoder_states, predict_state, predicted_ids),\r\n        shape_invariants=(\r\n            tf.TensorShape([]),\r\n            tf.TensorShape([]),\r\n            tf.TensorShape([None, None]),\r\n            get_shape_invariants(predict_state),\r\n            tf.TensorShape([])\r\n        )\r\n    )\r\n\r\n    return predicted_ids.gather(tf.range(predicted_ids.size()))\r\n```\r\n\r\nThe errors:\r\n\r\n```none\r\nerror: requires element_shape to be 1D tensor during TF Lite transformation pass\r\nerror: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n```\r\n\r\n<details>\r\n   <summary>Entire error log output (click to expand)</summary>\r\n\r\n```none\r\nloc(callsite(\"TensorArrayV2\"(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":464:0) at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":1071:0 at callsite(\"/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py\":496:0 at callsite(\"/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py\":562:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":962:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":600:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":986:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3065:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3213:0 at \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":2906:0)))))))))): error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\nloc(callsite(\"TensorArrayV2\"(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":464:0) at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py\":1071:0 at callsite(\"/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py\":496:0 at callsite(\"/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py\":562:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":962:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\":600:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\":986:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3065:0 at callsite(\"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":3213:0 at \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\":2906:0)))))))))): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\nTraceback (most recent call last):\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 196, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: /home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:1071:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:496:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:562:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:962:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:986:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3065:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3213:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2906:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: note: see current operation: %68 = \"tf.TensorListReserve\"(%66, %0) {device = \"\"} : (tensor<i32>, tensor<i32>) -> tensor<!tf.variant<tensor<*xi32>>>\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:1071:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:496:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:562:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:962:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:986:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3065:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3213:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2906:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: note: see current operation: %68 = \"tf.TensorListReserve\"(%66, %0) {device = \"\"} : (tensor<i32>, tensor<i32>) -> tensor<!tf.variant<tensor<*xi32>>>\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/sfalk/tmp/my-speech-v2/asr/bin/demo.py\", line 54, in <module>\r\n    main()\r\n  File \"/home/sfalk/tmp/my-speech-v2/asr/bin/demo.py\", line 44, in main\r\n    tflite_model = converter.convert()\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1076, in convert\r\n    return super(TFLiteConverterV2, self).convert()\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 899, in convert\r\n    return super(TFLiteFrozenGraphConverterV2,\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 629, in convert\r\n    result = _toco_convert_impl(\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 569, in toco_convert_impl\r\n    data = toco_convert_protos(\r\n  File \"/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 202, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: /home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: error: requires element_shape to be 1D tensor during TF Lite transformation pass\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:1071:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:496:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:562:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:962:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:986:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3065:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3213:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2906:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: note: see current operation: %68 = \"tf.TensorListReserve\"(%66, %0) {device = \"\"} : (tensor<i32>, tensor<i32>) -> tensor<!tf.variant<tensor<*xi32>>>\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:1071:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:496:0: note: called from\r\n/home/sfalk/tmp/my-speech-v2/asr/model/transducer.py:562:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:962:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:600:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:986:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3065:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3213:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2906:0: note: called from\r\n/home/sfalk/miniconda3/envs/asr2/lib/python3.8/site-packages/tensorflow/python/ops/tensor_array_ops.py:464:0: note: see current operation: %68 = \"tf.TensorListReserve\"(%66, %0) {device = \"\"} : (tensor<i32>, tensor<i32>) -> tensor<!tf.variant<tensor<*xi32>>>\r\n```\r\n</details>\r\n\r\nIs there a solution to this?", "> ```python\r\n> predicted_ids = tf.TensorArray(dtype=tf.int32, size=100, dynamic_size=True)\r\n> ```\r\n\r\nCan you specify element_shape when building the TensorArray?\r\npredicted_ids = tf.TensorArray(dtype=tf.int32, size=100, dynamic_size=True)\r\n\r\nWe don't support dynamic_size right now and you need to explicitly specify the element_shape there.", "@haozha111 Hi!\r\n\r\nIt seems that `TensorArray` is not supported (see https://github.com/tensorflow/tensorflow/issues/42181#issuecomment-671633243).", "> @haozha111 Hi!\r\n> \r\n> It seems that `TensorArray` is not supported (see [#42181 (comment)](https://github.com/tensorflow/tensorflow/issues/42181#issuecomment-671633243)).\r\n\r\nHi,\r\n\r\ntf.TensorArray is the high-level python API, and it's still supported in TF 2.x. The backing ops are changed to TensorLists, but it doesn't affect how you use the python API. Could you give a try?\r\n\r\nSee:\r\nhttps://www.tensorflow.org/api_docs/python/tf/TensorArray", "Hi @xuexuanyu ! \r\nWe are checking to see whether you still need help with this issue . Have you checked the above [comment](https://github.com/tensorflow/tensorflow/issues/37134#issuecomment-673887624) yet ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37134\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37134\">No</a>\n"]}, {"number": 37133, "title": "How to access intermediate tensors that are used during the application (tf.app) lifecycle", "body": "\r\n\r\nBasically, I am running the evaluation script, provided by Tf's Object Detection API, using:\r\n\r\n```\r\npython3 object_detection/legacy/eval.py \\\r\n    --pipeline_config_path=../../faster_rcnn_resnet101_voc12.pbtxt\\\r\n    --checkpoint_dir=../../trainedmodel_voc07 \\\r\n    --eval_dir=../../eval_results \\\r\n    --run_once=True \\\r\n    --alsologtostderr\r\n```\r\n\r\nNow, this script outputs the bounding boxes on image along with prediction scores. But what I need is, the metrics calculated.\r\n\r\nWhen I looked into the eval.py, I found that, it returns nothing. It run the evaluation, calculates the metrics but doesn't return it. So, I just changed the code to return the metrics and print it on console.\r\n\r\n```\r\nmetrics = evaluator.evaluate(\r\n        create_input_dict_fn,\r\n        model_fn,\r\n        eval_config,\r\n        categories,\r\n        FLAGS.checkpoint_dir,\r\n        FLAGS.eval_dir,\r\n        graph_hook_fn=graph_rewriter_fn,\r\n    )\r\nprint(metrics)\r\n```\r\n\r\nBut, as we know, this won't print the values inside the metric. I have tried several things like `metrics.numpy()` which won't work when eager execution is turned off. I have also tried using `metrics.eval()` by creating a session but this just hangs up the PC and does nothing.\r\n\r\nAlso, `tf.print()` won't work as it runs in graph mode.\r\n\r\nThen I found that TF stores summaries of metrics and we can visualize it using tensorboard. That's okay.. but what I wanted to extract values from other tensors?\r\n\r\nSo, basically, how can I access the intermediate tensors in the script?", "comments": ["@ParikhKadam,\r\nLooks like this issue is related to tensorflow/models repo. This is a duplicate of an earlier issue you have mentioned [#8209](https://github.com/tensorflow/models/issues/8209).\r\nCan we track that issue and close this one. It will help us to follow easily. Please let us know. Thanks!", "@amahendrakar  Maybe you should close that issue then. Because, I think this as a flaw in tf.app rather than of models repo. `tf.app` doesn't provide a way to access tensors directly (maybe).", "@ParikhKadam Closing this issue here as it a duplicate of [#8209](https://github.com/tensorflow/models/issues/8209). Lets track it in the models repo."]}, {"number": 37132, "title": "\"Could not append to the internal temporary file\" when writing checkpoints to GCP during TPU training", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Debian GNU/Linux 9.11 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n - TensorFlow version (use command below): 2.2.0.dev20200119\r\n- Python version: Python 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from\r\nsource): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen training a model for 2 days+ on a TPU pod and saving checkpoints to a GCP bucket, I run into `tensorflow.python.framework.errors_impl.InternalError: Could not append to the internal temporary file. [Op:ReadVariableOp]` when writing checkpoints. This has happened a couple of times and is fixed by acquiring a new pod, so I suspect it is due to running out of space (on the TPU host it seems)? If this is the case, is it possible to diagnose when this is happening and delete old checkpoints to avoid training crashing?\r\n\r\n**Describe the expected behavior**\r\nDetect that space on the (TPU host?) is close to full and delete old checkpoints.\r\n\r\n**Standalone code to reproduce the issue** \r\nStandard model run on TPU; wouldn't be reproducible without running a model for > 2 days.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nFile \"/home/helen/.../estimator.py\", line 233, in train_and_evaluate\r\n    checkpoint.save(os.path.join(output_dir, \"ckpt\"))\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1927, in save\r\n    file_path = self.write(\"%s-%d\" % (file_prefix, checkpoint_number))\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1857, in write\r\n    output = self._saver.save(file_prefix=file_prefix)\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1187, in save\r\n    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1135, in _save_cached_when_graph_building\r\n    save_op = saver.save(file_prefix)\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 250, in save\r\n    sharded_saves.append(saver.save(shard_prefix))\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 70, in save\r\n    tensors.append(spec.tensor)\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py\", line 55, in tensor\r\n    return self._tensor() if callable(self._tensor) else self._tensor\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py\", line 91, in f\r\n    x = v.read_value()\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 638, in read_value\r\n    value = self._read_variable_op()\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 616, in _read_variable_op\r\n    self._dtype)\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\", line 479, in read_variable_op\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/helen/anaconda3/envs/.../python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 6625, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: Could not append to the internal temporary file. [Op:ReadVariableOp]\r\n```", "comments": ["The stack trace leads back here, a temp file on the TPU host, which does seem to suggest that we are exhausting storage on the host.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e2e13ee6901301082b9e8e91c687c4ba930dd5de/tensorflow/core/platform/cloud/gcs_file_system.cc#L491", "Hi, just checking in as to updates on this? I thought I had fixed it with a CheckpointManager which only saves the last 5 model checkpoints (each 6.6GB), but this just crashed on me which is surprising because I thought we had ~60GB of storage on the TPU host disk. If you could confirm how much storage space gets allocated on a TPU host that would also help me workaround in the meantime by saving fewer checkpoints. Thanks!", "Update: I re-ran the same code with a new TPU pod and this time the checkpoint saving worked as expected (5 checkpoints saved without issues, and old ones deleted), with the exact same model. Does this mean that different TPU hosts are assigned different amounts of storage?", "For what it's worth, I am running into the exact same problem, except it has crashed twice in the span of 24 hours, roughly 12 hours into training both times.", ">The stack trace leads back here, a temp file on the TPU host, which does seem to suggest that we are exhausting storage on the host.\r\n\r\nHi @mathemakitten which host do u mean here? is the VM where we access the tpus or the gcs?", "I believe it's the host for the TPU. Seems like files pass through the TPU host and then get written to GCS.", "thx for the quick reply! That means TPU Pod I assume?", "Yes, this only happens on pods.", "thanks!", "for anyone is interested: my problem was solved by cleaning up the /tmp directory, and my assumption is that the tfrecord file will be temperorily saved there then upload to gcs?", "Hi @crystina-z, can you clarify /tmp on which machine? Do you mean your local GCP VM? I wasn't aware that GCS artifacts get moved through the VM (I just assumed they would go through the TPU host, which might be wrong).", "yup the local GCP VM (the one where we store the core and requesting the tpu etc).\r\n\r\nFor me I've tried to request another TPU pod as previous recommended, yet it was not working. But It's possible that this error can be caused by multiple reasons?", "If anyone's still seeing this, we were in touch with TFRC recently and they pushed an update to the nightly build, where it no longer happens. It was indeed due to the TPU host disk being full.", "@mathemakitten  It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version 2.5 or 2.4.1 and let us know if the issue still persists? Thanks!", "haven't seen this in a while while running on 2.4.1, thanks!\n\nOn Mon, Jun 28, 2021 at 12:54 PM sushreebarsa ***@***.***>\nwrote:\n\n> @mathemakitten <https://github.com/mathemakitten> Could you please try on\n> latest stable version of tf 2.5 or 2.4.1 and let us know if this is still\n> an issue.Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37132#issuecomment-869846546>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AHRC5I6CI4XUJVQQ3YGRVGTTVCSMJANCNFSM4K45JXPQ>\n> .\n>\n", "@mathemakitten  Thank you for your update, glad its working fine for you, kindly move this issue to closed status as it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37132\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37132\">No</a>\n"]}, {"number": 37131, "title": "TensorRT 6/7 converter crash with tf 2.1.0", "body": "Test code and steps to reproduce: https://github.com/bioothod/trt_crash_efficientnet\r\nHappens both with `nvcr.io/nvidia/tensorflow:20.02-tf2-py3` and `tensorflow/tensorflow:2.1.0-gpu-py3`.\r\n\r\nStack trace:\r\n```\r\n(gdb) bt\r\n#0  0x00007fff60219560 in tensorflow::Node::name() const () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2\r\n#1  0x00007fff6796af66 in tensorflow::tensorrt::convert::UpdateToEngineNode(std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, unsigned long, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> > const&, bool, std::string const&, tensorflow::Node**, int*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fff6796cfc5 in tensorflow::tensorrt::convert::CreateTRTNode(tensorflow::tensorrt::convert::ConversionParams const&, std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, int, int, tensorflow::Graph*, nvinfer1::IGpuAllocator*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fff67972041 in tensorflow::tensorrt::convert::ConvertAfterShapes(tensorflow::tensorrt::convert::ConversionParams const&) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fff679ac34b in tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fff6a31f937 in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fff6a320ccd in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fff6a322714 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fff6371cc07 in TF_OptimizeGraph(GCluster, tensorflow::ConfigProto const&, tensorflow::MetaGraphDef const&, bool, std::string const&, bool, TF_Status*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fff637217d6 in _wrap_TF_OptimizeGraph () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n#10 0x000000000050a8af in ?? ()\r\n#11 0x000000000050c5b9 in _PyEval_EvalFrameDefault ()\r\n#12 0x0000000000508245 in ?? ()\r\n#13 0x000000000050a080 in ?? ()\r\n#14 0x000000000050aa7d in ?? ()\r\n```", "comments": ["Full trace when running `test.py`:\r\n```\r\n docker run --ulimit core=-1 --network=host -ti --user=`id -u`:`id -g` --runtime=nvidia -v /home:/home -v `pwd`:`pwd` -w `pwd` --rm -e CUDA_DEVICE_ORDER=PCI_BUS_ID -e CUDA_VISIBLE_DEVICES=\"2\" nvcr.io/nvidia/tensorflow:20.02-tf2-py3 python3 ./test.py --output_dir test/test --num_classes 8 --model_name efficientnet-b0\r\n\r\n\r\n                                                                                                                                                \r\n================\r\n== TensorFlow ==\r\n================\r\n\r\nNVIDIA Release 20.02-tf2 (build 9892252)\r\nTensorFlow Version 2.1.0\r\n\r\nContainer image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.\r\nCopyright 2017-2019 The TensorFlow Authors.  All rights reserved.\r\n\r\nVarious files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\r\nNVIDIA modifications are covered by the license terms that apply to the underlying project or file.\r\n\r\nERROR: This container was built for NVIDIA Driver Release 440.33 or later, but\r\n       version 430.26 was detected and compatibility mode is UNAVAILABLE.\r\n\r\n       [[CUDA Driver UNAVAILABLE (cuInit(0) returned 803)]]\r\n\r\nNOTE: MOFED driver for multi-node communication was not detected.\r\n      Multi-node communication performance may be reduced.\r\n\r\nNOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\r\n   insufficient for TensorFlow.  NVIDIA recommends the use of the following flags:\r\n   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\r\n\r\n2020-02-27 15:00:38.681656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-27 15:00:39.644278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7\r\n2020-02-27 15:00:39.645200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7\r\nWARNING:tensorflow:Skipping full serialization of Keras model <__main__.main.<locals>.MyModel object at 0x7efccf2842e8>, because its inputs are not defined.\r\n2020-02-27 15:00:40.702881: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\n2020-02-27 15:00:42.116607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-02-27 15:00:46.364817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: TITAN V computeCapability: 7.0\r\ncoreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\r\n2020-02-27 15:00:46.364870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-27 15:00:46.364924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-27 15:00:46.367187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-27 15:00:46.367563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-27 15:00:46.370137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-27 15:00:46.371503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-27 15:00:46.371553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-27 15:00:46.373868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-27 15:00:46.402696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099995000 Hz\r\n2020-02-27 15:00:46.404973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4861400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-27 15:00:46.405007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-02-27 15:00:46.701309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48c6e20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-02-27 15:00:46.701370: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN V, Compute Capability 7.0\r\n2020-02-27 15:00:46.702813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: TITAN V computeCapability: 7.0\r\ncoreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\r\n2020-02-27 15:00:46.702859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-27 15:00:46.702882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-27 15:00:46.702907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-27 15:00:46.702927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-27 15:00:46.702946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-27 15:00:46.702964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-27 15:00:46.702982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-27 15:00:46.705153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-27 15:00:46.705193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-27 15:00:47.875709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-27 15:00:47.875772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-02-27 15:00:47.875788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-02-27 15:00:47.878202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10777 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:08:00.0, compute capability: 7.0)\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efcb36b56a0>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efcb36b76a0>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efcb36b8978>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf2d9d30>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf259ef0>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf259e48>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf201278>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf210400>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf21e668>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf1ac7f0>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf1bc978>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf1cac18>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf1d7dd8>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf1e5f98>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf182208>, because it is not built.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <efficientnet.MBConvBlock object at 0x7efccf1914a8>, because it is not built.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n2020-02-27 15:01:13.556715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_25184) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference___call___5773) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_14833) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_10559) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_8958) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_12916) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (__inference_model_layer_call_and_return_conditional_losses_26817) with ops with custom gradients. Will likely fail if a gradient is requested.\r\n2020-02-27 15:01:21.595617: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-02-27 15:01:21.595779: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-27 15:01:21.597073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: TITAN V computeCapability: 7.0\r\ncoreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\r\n2020-02-27 15:01:21.597126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-27 15:01:21.597152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-27 15:01:21.597182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-27 15:01:21.597204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-27 15:01:21.597225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-27 15:01:21.597248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-27 15:01:21.597266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-27 15:01:21.598431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-27 15:01:21.598473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-27 15:01:21.598488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-02-27 15:01:21.598501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-02-27 15:01:21.599745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10777 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:08:00.0, compute capability: 7.0)\r\n2020-02-27 15:01:21.684924: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:841] Optimization results for grappler item: graph_to_optimize\r\n2020-02-27 15:01:21.684968: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:843]   function_optimizer: Graph size after: 1612 nodes (1298), 3048 edges (2734), time = 50.653ms.\r\n2020-02-27 15:01:21.684981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:843]   function_optimizer: function_optimizer did nothing. time = 0.88ms.\r\n2020-02-27 15:01:23.573166: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-02-27 15:01:23.573660: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-27 15:01:23.574864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: TITAN V computeCapability: 7.0\r\ncoreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\r\n2020-02-27 15:01:23.574914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-02-27 15:01:23.574940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-27 15:01:23.574966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-27 15:01:23.574987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-27 15:01:23.575006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-27 15:01:23.575026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-27 15:01:23.575044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-27 15:01:23.576209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-27 15:01:23.576256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-27 15:01:23.576273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-02-27 15:01:23.576287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-02-27 15:01:23.577518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10777 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:08:00.0, compute capability: 7.0)\r\n2020-02-27 15:01:24.310026: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 58 ops of 6 different types in the graph that are not converted to TensorRT: IdentityN, Reshape, Identity, Cast, NoOp, Placeholder, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n2020-02-27 15:01:24.427240: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:636] Number of TensorRT candidate segments: 50\r\n2020-02-27 15:01:24.481901: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 0 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_0/bn1/TRTEngineOp_0.\r\n2020-02-27 15:01:24.482110: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 1 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_1.\r\n2020-02-27 15:01:24.482278: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 2 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_0/se/TRTEngineOp_2.\r\n2020-02-27 15:01:24.482388: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 3 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_1/bn1/TRTEngineOp_3.\r\n2020-02-27 15:01:24.482528: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 4 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_4.\r\n2020-02-27 15:01:24.482732: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 5 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_1/se/TRTEngineOp_5.\r\n2020-02-27 15:01:24.482847: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 6 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_10/bn1/TRTEngineOp_6.\r\n2020-02-27 15:01:24.482995: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 7 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_7.\r\n2020-02-27 15:01:24.483192: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 8 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_8.\r\n2020-02-27 15:01:24.483363: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 9 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_10/se/TRTEngineOp_9.\r\n2020-02-27 15:01:24.483488: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 10 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_11/bn1/TRTEngineOp_10.\r\n2020-02-27 15:01:24.483634: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 11 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_11.\r\n2020-02-27 15:01:24.483808: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 12 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_11/se/TRTEngineOp_12.\r\n2020-02-27 15:01:24.483928: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 13 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_12/bn1/TRTEngineOp_13.\r\n2020-02-27 15:01:24.484072: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 14 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_14.\r\n2020-02-27 15:01:24.484237: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 15 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_12/se/TRTEngineOp_15.\r\n2020-02-27 15:01:24.484357: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 16 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_13/bn1/TRTEngineOp_16.\r\n2020-02-27 15:01:24.484495: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 17 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_17.\r\n2020-02-27 15:01:24.484669: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 18 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_13/se/TRTEngineOp_18.\r\n2020-02-27 15:01:24.484786: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 19 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_14/bn1/TRTEngineOp_19.\r\n2020-02-27 15:01:24.484921: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 20 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_20.\r\n2020-02-27 15:01:24.485092: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 21 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_14/se/TRTEngineOp_21.\r\n2020-02-27 15:01:24.485207: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 22 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_15/bn1/TRTEngineOp_22.\r\n2020-02-27 15:01:24.485371: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 23 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_23.\r\n2020-02-27 15:01:24.485541: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 24 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_15/se/TRTEngineOp_24.\r\n2020-02-27 15:01:24.485658: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 25 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_2/bn1/TRTEngineOp_25.\r\n2020-02-27 15:01:24.485808: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 26 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_26.\r\n2020-02-27 15:01:24.485956: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 27 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_2/se/TRTEngineOp_27.\r\n2020-02-27 15:01:24.486077: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 28 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_3/bn1/TRTEngineOp_28.\r\n2020-02-27 15:01:24.486227: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 29 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_29.\r\n2020-02-27 15:01:24.486417: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 30 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_3/se/TRTEngineOp_30.\r\n2020-02-27 15:01:24.486524: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 31 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_4/bn1/TRTEngineOp_31.\r\n2020-02-27 15:01:24.486667: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 32 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_32.\r\n2020-02-27 15:01:24.486832: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 33 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_4/se/TRTEngineOp_33.\r\n2020-02-27 15:01:24.486936: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 34 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_5/bn1/TRTEngineOp_34.\r\n2020-02-27 15:01:24.487069: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 35 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_35.\r\n2020-02-27 15:01:24.487224: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 36 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_5/se/TRTEngineOp_36.\r\n2020-02-27 15:01:24.487333: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 37 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_6/bn1/TRTEngineOp_37.\r\n2020-02-27 15:01:24.487466: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 38 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_38.\r\n2020-02-27 15:01:24.487619: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 39 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_6/se/TRTEngineOp_39.\r\n2020-02-27 15:01:24.487730: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 40 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_7/bn1/TRTEngineOp_40.\r\n2020-02-27 15:01:24.487862: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 41 consisting of 22 nodes by StatefulPartitionedCall/model/TRTEngineOp_41.\r\n2020-02-27 15:01:24.488007: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 42 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_7/se/TRTEngineOp_42.\r\n2020-02-27 15:01:24.488109: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 43 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_8/bn1/TRTEngineOp_43.\r\n2020-02-27 15:01:24.488247: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 44 consisting of 21 nodes by StatefulPartitionedCall/model/TRTEngineOp_44.\r\n2020-02-27 15:01:24.488385: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 45 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_8/se/TRTEngineOp_45.\r\n2020-02-27 15:01:24.488495: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 46 consisting of 9 nodes by StatefulPartitionedCall/model/blocks_9/bn1/TRTEngineOp_46.\r\n2020-02-27 15:01:24.488605: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 47 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_9/se/TRTEngineOp_47.\r\n2020-02-27 15:01:24.488704: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 48 consisting of 9 nodes by TRTEngineOp_48.\r\n```\r\n\r\nAt this point python converter code crashes", "When running under gdb, here is a null pointer dereference of `tensorflow::Node` in `tensorflow::tensorrt::convert::UpdateToEngineNode()`:\r\n\r\n```\r\n...\r\n2020-02-27 15:24:00.726184: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 47 consisting of 7 nodes by StatefulPartitionedCall/model/blocks_9/se/TRTEngineOp_47.\r\n2020-02-27 15:24:00.726261: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 48 consisting of 9 nodes by TRTEngineOp_48.\r\n\r\n\r\nThread 1 \"python3\" received signal SIGSEGV, Segmentation fault.\r\n0x00007fff674b4271 in tensorflow::Node::name() const () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2\r\n(gdb) x/i $rip\r\n=> 0x7fff674b4271 <_ZNK10tensorflow4Node4nameEv+1>:\tmov    0x90(%rdi),%rax\r\n(gdb) p/x $rdi\r\n$2 = 0x0\r\n```", "On `tf-nightly` this does not segfault, but nevertheless fails with\r\n\r\n```\r\nOP_REQUIRES failed at trt_engine_resource_ops.cc:196 : Not found: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_15)\r\n```\r\n\r\n@bixia1 can you PTAL?", "@sanjoy I can confirm that Efficient-Net D1 fails as you indicate in our application code (by that I mean, not a test.)\r\n```\r\n2020-11-07 00:15:18.393082: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at trt_engine_resource_ops.cc:196 : Not found: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_0)\r\n\r\n2020-11-07 00:15:18.394636: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at trt_engine_resource_ops.cc:196 : Not found: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_1)\r\n```\r\ntill `TRTEngineOp_0_59`", "@bioothod Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "Hey @sushreebarsa , works fine with 2.4.1", "Thank you for your update, glad its working fine for you, kindly move this issue to closed status as it is resolved.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37131\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37131\">No</a>\n"]}, {"number": 37130, "title": "Half precision training very slow and returning nan loss ", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information** \r\n\r\n- OS Platform and Distribution : Win10\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version:  10.1 / 7.6.4\r\n- GPU model and memory: RTX2080ti (11GB)\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI used the \"mixed_float16\" policy to train the efficientnet model (https://github.com/qubvel/efficientnet), but the training become almost 10 times slower and return nan even if I set a large epsilon.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy?hl=en\r\n\r\nhere are some of the codes to setup mixed float training:\r\n```\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\nK.set_epsilon(1e-3)\r\n```\r\nP.S.: When I trained the densenet121 from (tf.keras.applications) using mixed float16, it runs pretty well. ", "comments": ["Can you provide a full example, which creates and runs the efficient net model? I'm not sure how to run efficient net", "Sure, I made a colab file.\r\nhttps://colab.research.google.com/drive/1tQbhe_gGhIFoMuHu-HqazHzlP0Z83kwj\r\n", "On the line `out = keras.layers.BatchNormalization()(x)`, I'm getting the error \"name 'x' is not defined\". There are other undefined values as well, such as `BATCH_SIZE`.", "Sorry, I just changed the code.\r\n\r\nThere are two data files needed \"train.csv\" and \"train_origin2.zip\". \r\nAll could be downloaded from https://drive.google.com/drive/folders/1abgTg2uuWBmo2TTvipqiXVhxkBuLmNwb?usp=sharing", "Thanks for filing the issue! I could reproduce the slowness on TF 2.1 but not TF 2.2rc0, so I'm assuming the issue has been fixed. I also could not reproduce the NaN issue on 2.2rc0 after waiting for 1 epoch, but did not try on 2.1 since I got impatient waiting. Let me know if you still see the NaN issue.\r\n\r\nYou can get the fix either by installing 2.2rc0 with `pip install tensorflow==2.2rc0` or by waiting for 2.2 to come out.", "@reedwm Could you post the root cause for slowness on TF 2.1 please? Thanks.", "> @reedwm Could you post the root cause for slowness on TF 2.1 please? Thanks.\r\n\r\nI'm not sure what the root cause was. Maybe c476ffbbd8e35ac8683cc339802bfd9cdcdaa7a9?", "> Check out the loss scaler [TF](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer) and the [mixed precision guide](https://www.tensorflow.org/guide/keras/mixed_precision#loss_scaling) .\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/38495#issuecomment-618682103\r\n\r\nWhy did you set Keras' epsilon?", "Same thing. \r\nMixed precision with `mixed_float16` is super slow. **10 times slower than without it**\r\nI've used the same batch size, the same model and started to count the time for \r\n\r\n**1. Feedforward process ~10x worst\r\n2. Loss computing process ~6x worst\r\n3. Gradient computing process ~6x worst**\r\n\r\nAll points get worst ", "> Same thing.\r\n> Mixed precision with `mixed_float16` is super slow. **10 times slower than without it**\r\n> I've used the same batch size, the same model and started to count the time for\r\n> \r\n> **1. Feedforward process ~10x worst 2. Loss computing process ~6x worst 3. Gradient computing process ~6x works**\r\n> \r\n> All points get worst\r\n\r\nIncrease the network's size. I've spent hours to figure out that MP is faster for big-huge networks. What model architecture are you using?", "@Arktius \r\nI'm using our designed network, which consists of regular layers like Conv2D, BatchNorm, Activation, etc..\r\nIt is an autoencoder, which consists of a pre-trained encoder (vgg, resnet, etc..) and 1-3 decoders.\r\n**I've figured out the problem is related to bilinear upsampling (inside Upsample2D or tf.image.resize) and it breaks the mixed-precision performance.**\r\n**It is too bad because the same network implemented with another framework is ~7-8x faster**", "> @Arktius\r\n> I'm using our designed network, which consists of regular layers like Conv2D, BatchNorm, Activation, etc..\r\n> It is an autoencoder, which consists of a pre-trained encoder (vgg, resnet, etc..) and 1-3 decoders.\r\n\r\nDo you train the whole network or just the last couple of layers? (Transfer Learning)\r\nVGG uses convlayers of size 3x3. Two remarks here: 1.) 3x3 is not a multiple of 8 which is a prerequisite of MP. 2.) Even 8x8 might not yield any performance gain, because it's simply too small. \r\n\r\n> **I've figured out the problem is related to bilinear upsampling (inside Upsample2D or tf.image.resize) and it breaks the mixed-precision performance.**\r\n\r\nHow did you figure this out? According to this website [ClickMe](https://developer.nvidia.com/blog/accelerating-medical-image-segmentation-tensor-cores-tensorflow-2/), upsampling shouldn't be a problem. \r\n\r\n> **It is too bad because the same network implemented with another framework is ~7-8x faster**\r\n\r\nNamely PyTorch? MP can even slow down training if not configured properly. \r\n\r\nIs your data casted to float 16? Is your Batchsize a multiple of 8? Is the image shape a multiple of 8 for both dimensions (width/height)? ", "@Arktius \r\nAlmost everything in my network is multiple of 8. Batch Size, Decoder Filter Count, input shape, etc. \r\n**Also, if I'm not mistaken, they don't require everything to be a multiple of 8 (for example kernel size or dilation rate). \r\nThen why do I need mixed-precision, if it requires only certain numbers for my network?**\r\nWhat about the output of my network? e.g I have 6 classes, how to force them to make 8?\r\n\r\nAbout the resize operation. I replace it with **Conv2DTranspose**, the whole network remains the same, everything works fine in terms of the speed.", "'Almost'? What is not?\r\n\r\nWhat do you mean? Why do you need MP when it restricts the developer in many cases? Well, the benefit of training a model 2-8 x faster is enough motivation to fulfil all prerequisites. Training a model in 5 days instead of 10 or 14 days can save a lot of time and thus money.\r\n\r\nWhat's your activation function at the output layer? Sigmoid for the case where always one class is present? Why not just add another 2 classes at the output? There must be always zero then. \r\n\r\nCould you provide all the details of your model and your data?", "I noticed the same issue, but I don't have a reproducible example to share yet, however I can say that my network uses some bilinear upsampling (as well as a lot of other stuff).\r\nMore specifically, my training time is 6x longer for the epochs where no nans are present. Nans start appearing after roughly 2000 steps (which takes about 4 hours).\r\n\r\n@Hazarapet I don't know if you had seen this, but indeed bilinear upsampling is a cause of inefficiency for mixed precision in TensorFlow as reported in [this issue](https://github.com/tensorflow/tensorflow/issues/41934). They should have fixed the problem for [tf 2.4](https://github.com/tensorflow/tensorflow/commit/67d15573a776119d5a544ed266dc2514ae13c3b5).\r\n\r\nHowever, I [am still wondering ](https://github.com/tensorflow/tensorflow/issues/41934#issuecomment-743068647) if the Nan issue has the same cause, and therefore the same fix."]}, {"number": 37129, "title": "DOC: small doc fix for tf.transpose_v2", "body": "Found some inconsistencies while going through the docs. Hope this helps!", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37129) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37129) for more info**.\n\n<!-- ok -->", "We will not be encouraging one liner grammatical changes as this is expensive process,please include more such changes so that we can review it, thank you for your interest.\r\nCC @mihaimaruseac "]}, {"number": 37128, "title": "AttributeError: module 'tensorflow' has no attribute 'app' in tensorflow 2.1.0", "body": "\r\n**System information** \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or\r\nbinary): source\r\n- TensorFlow version (use command below): V2.1.0\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: 10.1/7.6\r\n- GPU model and memory: GTX 1050, 8G\r\n\r\n**Describe the current behavior**\r\nI write `FLAGS = tf.compat.v1.flags.FLAGS` in my file, but there is still an error,\r\n`\r\n FLAGS = tf.compat.v1.app.flags.FLAGS\r\nAttributeError: module 'tensorflow' has no attribute 'app'\r\n`\r\n\r\n", "comments": ["![Screenshot from 2020-02-27 23-25-58](https://user-images.githubusercontent.com/41910134/75471693-9365d380-59b8-11ea-8a1b-e90078a4ed5a.png)\r\n\r\nI am using the same version.This Shouldn't happen.\r\n\r\nTensorflow didn't have any attribute 'app' ever, i guess.", "yeah, if I type the same command in my prompt, it shows me the same results.\r\n<pre>\r\n>>> tf.version.VERSION\r\n'2.1.0'\r\n>>> tf.compat.v1.flags.FLAGS\r\ntensorflow.python.platform.flags._FlagValuesWrapper object at 0x000001CC872DFF48 \r\n</pre>\r\n\r\nbut it did occur when I compile my file,  all the information is as following:\r\n<pre>\r\nI tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\PC\\Desktop\\gae-master\\gae-upgrade\\train.py\", line 14, in <module>\r\n    from gae.optimizer import OptimizerAE, OptimizerVAE\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 668, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 638, in _load_backward_compatible\r\n  File \"D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py\", line 3, in <module>\r\n    FLAGS = tf.compat.v1.flags.FLAGS\r\nAttributeError: module 'tensorflow' has no attribute 'app'\r\n</pre>\r\n\r\nand my relevant code like this,\r\n<pre>\r\nimport tensorflow as tf\r\nFLAGS = tf.compat.v1.flags.FLAGS\r\n</pre>", "@Billy1900, Please take a look at similar issue [#34431(comment)](https://github.com/tensorflow/tensorflow/issues/34431#issuecomment-555836995) help you to resolve this issue. Thanks!", "@Billy1900, Was the above comment help you to resolve this issue?", "> @Billy1900, Was the above comment help you to resolve this issue?\r\n\r\nsort of, I have to use the previous version to run my code. but it is not what i truly want.", "@Billy1900, Did you try with `import tensorflow.compat.v1 as tf`? ", "> @Billy1900, Did you try with `import tensorflow.compat.v1 as tf`?\r\n\r\nisn't it with the same meaning as `FLAGS = tf.compat.v1.flags.FLAGS` I wrote?", "`tf.app` is removed from TF2. So using `compat.v1` is the only way. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37128\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37128\">No</a>\n"]}, {"number": 37127, "title": "Tensorflow 2.1.0 failed to get convolution algorithm in docker", "body": "ref. https://github.com/tensorflow/tensorflow/issues/27141#issuecomment-591939338\r\n\r\n\r\n> This problem may cause with tensorflow's docker (2.1.0-gpu-py3) in the below host\r\n> \r\n> - OS: 5.5.2-1-MANJARO\r\n> - Cuda: 10.1\r\n> - cuddn: 7.6.5\r\n> - docker-compose version 1.25.4\r\n> - docker-version: 19.03.5-ce, build 633a0ea838\r\n> \r\n> Tensorflow is affected by HOST OS?", "comments": ["@MokkeMeguru \r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Sorry, I think it's nvidia-docker and some environment settings problem.\r\nHOST's OS cannot detect cuda and cuddn's libraries.\r\nI think this is not TF's Problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37127\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37127\">No</a>\n"]}, {"number": 37126, "title": "Can i use embedding projector as a stand alone application in my personal/commercial applications ? ", "body": "", "comments": ["Yes you can use embedding projector as a standalone application.\r\nPlease refer to the following [link](https://github.com/tensorflow/embedding-projector-standalone).\r\n\r\nI am closing this issue, if you have any more questions please post them on stackoverflow as there is a wider community to respond. Thanks!"]}, {"number": 37125, "title": "Remove never used arg `sample_weight_mode` in tf.keras.Model:compile", "body": "Argument `sample_weight_mode` of tf.keras.Model:compile never used in code. \r\n\r\nRemove `sample_weight_mode` from arguments and docs.", "comments": ["@omalleyt12 I will make another PR to add a comment about this in the code, in case someone tries to remove it too.", "> @omalleyt12 I will make another PR to add a comment about this in the code, in case someone tries to remove it too.\r\n\r\nSounds good, thanks!", "the commit [Remove sample_weight_mode arg from compile and cleanup docs](https://github.com/tensorflow/tensorflow/commit/c7aa3e8d1711f49add2c6dc76fc8c000ce1edee8) have merged into the master branch by @pavithrasv, that commit has fixed this issue."]}]