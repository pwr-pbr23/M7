[{"number": 18127, "title": "Was the ExpandDims op merged into TFLite?", "body": "[Here](https://github.com/tensorflow/tensorflow/pull/14849) I see somebody proposing a pull request for ExpandDims. However, when I run TOCO on my model, I get a message saying \r\n\r\n`Here is a list of operators for which you will need custom implementations: ExpandDims, ...`\r\n\r\nWhat is the status of this pull request? If it has been merged, why does TOCO still complain?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It seems that PR was closed by the author and was not merged.\r\nReassigning to folks who'd have a better understanding of the current state.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "ExpandDims are usually changed by toco into Reshapes. The fact that they appear in the list of ops needing implementation is odd, but that should go away when the other ops are supported.", "Whats the status on this? We are also still getting the `Here is a list of operators for which you will need custom implementations: ExpandDims`.", "Nagging Assignees @aselle, @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @aselle, @andrehentz: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "ExpandDims is supported now.", "TOCO can not find ExpandDims yet. Can you tell me which tensorflow version particularly ?"]}, {"number": 18126, "title": "Fix the tpu related broken link especially for imagenet_to_gcs.py", "body": "As you can see in [using_tpus](https://www.tensorflow.org/programmers_guide/using_tpu), the link of below \"a script\" is 404 and no longer valid due to tpu-demos repo moved to tpu repo and adjust its correponding structure.\r\n\r\nThis PR is to fix the below tpu related broken links and also some minor typo.\r\n\r\n> The TPU-demos repo includes [a script](https://github.com/tensorflow/tpu-demos/blob/master/cloud_tpu/datasets/imagenet_to_gcs.py) for downloading the imagenet dataset", "comments": []}, {"number": 18125, "title": " Fix some formatting issue in cudnn_rnn and factorization docstrings", "body": "This PR is to fix several formatting issues especially math equation in cudnn_rnn and factorization related docstrings.\r\nTake [CudnnCompatibleGRUCell](https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnCompatibleGRUCell) as an example below:\r\nBefore:\r\n![image](https://user-images.githubusercontent.com/1680977/38145874-061ed4b0-347e-11e8-8c9b-00d1d0ed28fe.png)\r\n\r\nAfter:\r\n![image](https://user-images.githubusercontent.com/1680977/38145929-53f00d76-347e-11e8-9312-8afe813175f0.png)\r\n\r\nBTW, in order to not break pylint error about line length not longer than 80 chars, some lines are split into multple new lines since added new characters.\r\n", "comments": []}, {"number": 18124, "title": "Model behavior changes after saving and restoring!", "body": "Hi there,\r\nMy tf version is 1.2.1.\r\nIt's Okay if I feed the test data after model training, to get an accuracy of 98%.\r\nBut after I save and restore the model. The accuracy will only be around 10%. What happened...\r\n\r\nBesides, I think the accuracy from the test data should be a constant given that weights and biases won't be updated after training, but each time the accuracy is slightly different. Say, 0.1012, 0.9982, things like that...\r\n\r\nAny help?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue because the issues template was not filled out."]}, {"number": 18123, "title": "No float16 batch matrix multiplication support for GPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: b'v1.6.0-rc1-1857-g67e2efa' 1.6.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: not relevant\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy.random as npr\r\n\r\nwith tf.device('/gpu:0'):\r\n    a = tf.constant(npr.rand(10, 5, 5).astype('float16'))\r\n    b = tf.constant(npr.rand(10, 5, 5).astype('float16'))\r\n    c = tf.matmul(a, b)\r\n\r\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\r\nsess.run(c)\r\n```\r\n\r\n### Describe the problem\r\nThe problem is the same as in issue #605, but for float16: there is no GPU support for batch matrix multiplication. There is a quick workaround of reshaping the tensors to 2D, multiplying and reshaping back, but that is not possible to do when this function is called inside some TensorFlow classes, like in attention_wrapper.py line 336. And this significantly slows down computation of RNNs with attention on float16.\r\n\r\n### Source code / logs\r\nTraceback:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1329     try:\r\n-> 1330       return fn(*args)\r\n   1331     except errors.OpError as e:\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1312       # Ensure any changes to the graph are reflected in the runtime.\r\n-> 1313       self._extend_graph()\r\n   1314       return self._call_tf_sessionrun(\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _extend_graph(self)\r\n   1360             tf_session.TF_ExtendGraph(self._session,\r\n-> 1361                                       graph_def.SerializeToString(), status)\r\n   1362           self._opened = True\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    515             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 516             c_api.TF_GetCode(self.status.status))\r\n    517     # Delete the underlying status object from memory otherwise it stays alive\r\n\r\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n\r\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-1-8739d1f2e967> in <module>()\r\n      8 \r\n      9 sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\r\n---> 10 sess.run(c)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    906     try:\r\n    907       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 908                          run_metadata_ptr)\r\n    909       if run_metadata:\r\n    910         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1141     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1142       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1143                              feed_dict_tensor, options, run_metadata)\r\n   1144     else:\r\n   1145       results = []\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1322     if handle is None:\r\n   1323       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1324                            run_metadata)\r\n   1325     else:\r\n   1326       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1341         except KeyError:\r\n   1342           pass\r\n-> 1343       raise type(e)(node_def, op, message)\r\n   1344 \r\n   1345   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n\r\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\r\n\r\nCaused by op 'MatMul', defined at:\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\r\n    self.io_loop.start()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-8739d1f2e967>\", line 7, in <module>\r\n    c = tf.matmul(a, b)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 2082, in matmul\r\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1236, in batch_mat_mul\r\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3306, in create_op\r\n    op_def=op_def)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1669, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n\r\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\r\n```\r\n", "comments": ["@benbarsdell I thought you had a fix for this few months ago?", "@zhangyaobit, PTAL!", "https://github.com/tensorflow/tensorflow/pull/18436", "Nagging Assignee @zhangyaobit: It has been 150 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @zhangyaobit: It has been 164 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing this issue as a PR(#18436) has been created and merged for this. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 18122, "title": "Adding optional generated code printing in the demo notebook", "body": "", "comments": []}, {"number": 18121, "title": "Fix several formatting issues in python api guides", "body": "This PR is to fix several formatting issues in `Python API Guides`\r\n- Add intent to below code blocks under bullet in [Graph Editor (contrib)](https://www.tensorflow.org/api_guides/python/contrib.graph_editor#Sub_graph)\r\n    ![image](https://user-images.githubusercontent.com/1680977/38141048-1ace9d42-3469-11e8-8df5-dda60b1d4d74.png)\r\n\r\n- Fix two incorrect links in [Inputs and Readers](https://www.tensorflow.org/api_guides/python/io_ops);\r\n   - https://www.tensorflow.org/api_guides/python/reading_data#Feeding;\r\n   - https://www.tensorflow.org/api_guides/python/reading_data#standard_tensorflow_format\r\n\r\n- Fix incorrect math equation rendering in [Neural Network](https://www.tensorflow.org/api_guides/python/nn#Convolution);\r\nBefore:\r\n![image](https://user-images.githubusercontent.com/1680977/38141307-0b2f2748-346a-11e8-8191-c1ae093d7694.png)\r\nAfter:\r\n![image](https://user-images.githubusercontent.com/1680977/38141403-96fff234-346a-11e8-899f-d9ce8a223c5d.png)\r\n", "comments": []}, {"number": 18120, "title": "Branch 191063815", "body": "", "comments": []}, {"number": 18119, "title": "can I use tracker(used android example) from opencv tracking lib?", "body": "The performance of tracker used android example is very nice.\r\nI really want to use it via opencv tracking library.\r\nis it possible in the future? anyone send pull request to opencv library?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "The object tracker is open sourced, so you are welcome to reproduce it as you wish within the Apache 2.0 guidelines.\r\n\r\nQuestions regarding making PRs to the opencv repo in particular are probably best asked at https://github.com/opencv/opencv"]}, {"number": 18118, "title": "tfdbg error on windows 10", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 x64 pro\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary 1.7.0 gpu win64\r\n- **TensorFlow version (use command below)**:\r\n1.7.0\r\n- **Python version**: \r\n3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n9.0/7.0\r\n- **GPU model and memory**:\r\nGTX1080 GDDR5X 8GB\r\n- **Exact command to reproduce**:\r\npython -m tensorflow.python.debug.examples.debug_mnist --debug\r\n\r\n### Describe the problem\r\n\r\n### Source code / logs\r\n\r\nWARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: Data\r\nSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future v\r\nersion.\r\nInstructions for updating:\r\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\r\n2018-03-30 20:50:57.501717: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU suppo\r\nrts instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-03-30 20:50:57.892716: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1344] Found devi\r\nce 0 with properties:\r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.835\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 8.00GiB freeMemory: 6.60GiB\r\n2018-03-30 20:50:57.904881: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1423] Adding vis\r\nible gpu devices: 0\r\n2018-03-30 20:50:58.560856: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:911] Device inte\r\nrconnect StreamExecutor with strength 1 edge matrix:\r\n2018-03-30 20:50:58.568769: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:917]      0\r\n2018-03-30 20:50:58.574326: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 0:   N\r\n2018-03-30 20:50:58.578842: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created Te\r\nnsorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6379 MB memory) -> physical GPU (device: 0, name: GeF\r\norce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\cli\\ui_factory.py\", line 60, in get_ui\r\n    from tensorflow.python.debug.cli import curses_ui\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\cli\\curses_ui.py\", line 21, in <module>\r\n    import curses\r\n  File \"C:\\Anaconda3\\lib\\curses\\__init__.py\", line 13, in <module>\r\n    from _curses import *\r\nModuleNotFoundError: No module named '_curses'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\cli\\ui_factory.py\", line 63, in get_ui\r\n    from tensorflow.python.debug.cli import readline_ui\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\cli\\readline_ui.py\", line 20, in <module>\r\n    import readline\r\nModuleNotFoundError: No module named 'readline'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\examples\\debug_mnist.py\", line 193, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\examples\\debug_mnist.py\", line 136, in main\r\n    acc = sess.run(accuracy, feed_dict=feed_dict(False))\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\framework.py\", line 462, in run\r\n    is_callable_runner=bool(callable_runner)))\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 255, in on_run_start\r\n\r\n    self._prep_cli_for_run_start()\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\wrappers\\local_cli_wrapper.py\", line 277, in _prep_cli_fo\r\nr_run_start\r\n    self._run_cli = ui_factory.get_ui(self._ui_type)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\cli\\ui_factory.py\", line 71, in get_ui\r\n    available_ui_types=available_ui_types)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\debug\\cli\\ui_factory.py\", line 69, in get_ui\r\n    raise ValueError(\"Exhausted all fallback ui_types.\")\r\nValueError: Exhausted all fallback ui_types.", "comments": ["Take a look at the note at the top here: https://www.tensorflow.org/programmers_guide/debugger\r\n\r\nYou are probably missing the curses or pyreadline package on your system which tfdbg relies on for the user interface.\r\n\r\nFor Windows, I say go ahead and try out the curses wheel for your system on the site mentioned in those docs, as I think it's a nicer looking UI than readline. If I recall correctly, with windows curses-based tfdbg, you need to do long mouse presses (click and hold) for button/link presses in the terminal.", "@pvaneck \r\n\r\nthx, solved after install pyreadline( using conda ) and unofficial curses 2.2 ", "@alapurple how did you install unofficial curses 2.2. can you please tell?"]}, {"number": 18117, "title": "unexpected 10 sec hang, related to tf.TensorArray", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, code is below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9.4, Linux wc4 4.9.0-6-amd64  SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux\r\n- **TensorFlow installed from (source or binary)**: binary pip\r\n- **TensorFlow version (use command below)**: v1.5.0-0-g37aa430d84 1.5.0\r\n- **Python version**: 3.5.3\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GeForce GTX 1080, 11GB\r\n- **Exact command to reproduce**: see code below\r\n\r\n### Describe the problem\r\nThe test case below causes an unexpected hang for about 10 seconds.\r\nI think it is related to `tf.TensorArray` but also the other operations in the graph are important.\r\nI have already tried to reduce it as much as possible. If I remove something now,\r\nthe hang will disappear.\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\nimport contextlib\r\nimport numpy\r\n\r\n@contextlib.contextmanager\r\ndef make_scope():\r\n  \"\"\"\r\n  :rtype: tf.Session\r\n  \"\"\"\r\n  with tf.Graph().as_default() as graph:\r\n    with tf.Session(graph=graph) as session:\r\n      yield session\r\n\r\n\r\ndef test_slow_TensorArray():\r\n  import time\r\n  random = numpy.random.RandomState(seed=1)\r\n  num_inputs = 4\r\n  num_outputs = 3\r\n  seq_len = 10\r\n  limit = 1.0\r\n\r\n  def linear(x, output_dim):\r\n    input_dim = x.get_shape().dims[-1].value\r\n    assert input_dim is not None\r\n    with tf.variable_scope(\"linear\", reuse=tf.AUTO_REUSE):\r\n      weights = tf.get_variable(\"W\", shape=(input_dim, output_dim))\r\n      bias = tf.get_variable(\"b\", shape=(output_dim,))\r\n    assert x.get_shape().ndims == 2  # (batch,input_dim)\r\n    return tf.matmul(x, weights) + bias\r\n\r\n  with make_scope() as session:\r\n    print(\"create graph\")\r\n    src_placeholder = tf.placeholder(tf.float32, (None, seq_len, num_inputs), name=\"src_placeholder\")\r\n    tgt_placeholder = tf.placeholder(tf.float32, (None, seq_len, num_outputs), name=\"tgt_placeholder\")\r\n    batch_size = tf.shape(src_placeholder)[0]\r\n\r\n    def make_feed_dict():\r\n      return {\r\n        src_placeholder: random.uniform(-limit, limit, (1, seq_len, num_inputs)),\r\n        tgt_placeholder: random.uniform(-limit, limit, (1, seq_len, num_outputs)),\r\n      }\r\n\r\n    state = tf.zeros((batch_size, num_outputs))\r\n    loss_ta = tf.TensorArray(tf.float32, size=seq_len, element_shape=(None,))\r\n    # Unroll the loop here.\r\n    for f in range(seq_len):\r\n      inputs = src_placeholder[:, f]\r\n      x = tf.concat([inputs, state], axis=-1)\r\n      with tf.variable_scope('h'):\r\n        h = tf.tanh(linear(x, num_outputs))\r\n      with tf.variable_scope('t'):\r\n        t = tf.sigmoid(linear(x, num_outputs))\r\n      state += t * (h - state)\r\n      frame_loss = tf.reduce_mean(tf.squared_difference(tgt_placeholder[:, f], state), axis=1)\r\n      assert frame_loss.get_shape().ndims == 1  # (batch,)\r\n      loss_ta = loss_ta.write(f, frame_loss)\r\n    loss = tf.reduce_sum(loss_ta.stack())\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.1, epsilon=1e-16, use_locking=False)\r\n    minimize_op = optimizer.minimize(loss)\r\n\r\n    print('variables:')\r\n    train_vars = (\r\n      tf.trainable_variables() +\r\n      tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES))\r\n    print(train_vars)\r\n    print('init vars')\r\n    session.run(tf.global_variables_initializer())\r\n    print('graph size:', session.graph_def.ByteSize())\r\n    print('train')\r\n    for s in range(10):\r\n      start_time = time.time()\r\n      loss_val, _ = session.run([loss, minimize_op], feed_dict=make_feed_dict())\r\n      print(\"step %i, loss: %f, time: %f\" % (s, loss_val, time.time() - start_time))\r\n\r\ntest_slow_TensorArray()\r\n```\r\n\r\nMy output:\r\n\r\n```\r\ncreate graph\r\nvariables:\r\n[<tf.Variable 'h/linear/W:0' shape=(7, 3) dtype=float32_ref>, <tf.Variable 'h/linear/b:0' shape=(3,) dtype=float32_ref>, <tf.Variable 't/linear/W:0' shape=(7, 3) dtype=float32_ref>, <tf.Variable 't/linear/b:0' shape=(3,) dtype=float32_ref>]\r\ninit vars\r\ngraph size: 222234\r\ntrain\r\nstep 0, loss: 5.506713, time: 10.675434\r\nstep 1, loss: 7.865020, time: 0.003913\r\nstep 2, loss: 5.450877, time: 0.003354\r\nstep 3, loss: 3.361173, time: 0.003227\r\nstep 4, loss: 4.493120, time: 0.003563\r\nstep 5, loss: 5.137649, time: 0.003203\r\nstep 6, loss: 3.610677, time: 0.003376\r\nstep 7, loss: 3.657249, time: 0.003544\r\nstep 8, loss: 4.405594, time: 0.003454\r\nstep 9, loss: 4.380188, time: 0.003491\r\n```\r\n", "comments": ["I just updated to TensorFlow 1.7.0 (v1.7.0-3-g024aecf414 1.7.0) and the problem seems to be mostly gone (still there is some hang, but much less):\r\n```\r\nstep 0, loss: 4.614282, time: 0.329974\r\nstep 1, loss: 7.103771, time: 0.003420\r\nstep 2, loss: 4.263576, time: 0.003305\r\nstep 3, loss: 2.140168, time: 0.003355\r\nstep 4, loss: 3.948706, time: 0.003271\r\nstep 5, loss: 3.063313, time: 0.003162\r\nstep 6, loss: 4.229179, time: 0.003354\r\nstep 7, loss: 4.908344, time: 0.003289\r\nstep 8, loss: 4.345730, time: 0.003188\r\nstep 9, loss: 3.079849, time: 0.003256\r\n```\r\n", "I recall there being up to 60 seconds hand on the first sess.run in some situations (PTX compilation). There may also be things like cuda autotuning that happen in earlier iterations but not in later", "In general it is expected that the first call to session.run may take longer than subsequent calls. I'm closing since 1/3s seems in a more reasonable range than 10s, but please reopen if you think there is a bug to look into."]}, {"number": 18116, "title": "ImportError : Could not find 'msvcp140.dll'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Window 7\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5, 1.6, 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: import tensorflow as tf\r\n\r\n### Problem\r\nI am using python 3.6 and have successfully installed tensorflow 1.7 via pip3 command. While importing tensorflow in python interpreter an OSError occurs and while handling the exception ImportError also occurs which gives the message that 'Couldnot find msvcp140.dll'. I checked that the dll files are present in the directory that is in the PATH variable and also installed the Visual C++ Redistributable as mentioned.\r\n\r\n### Logs\r\n>>> import tensorflow as tf\r\n<module 'tensorflow.python.platform.build_info' from 'C:\\\\Python36\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\platform\\\\build_info.py'>\r\nTraceback (most recent call last):\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\",\r\n line 48, in preload_check\r\n    ctypes.WinDLL(build_info.msvcp_dll_name)\r\n  File \"C:\\Python36\\lib\\ctypes\\__init__.py\", line 348, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 193] %1 is not a valid Win32 application\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\",\r\n line 56, in preload_check\r\n    % build_info.msvcp_dll_name)\r\nImportError: Could not find 'msvcp140.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. You may install this DLL by downloading Visual C++ 2015 Redistributable Update 3 from this URL:https://www.microsoft.com/en-us/download/details.aspx?id=53587\r\n", "comments": ["What result do you get if you type `where msvcp140.dll` in the same command prompt as you used for the Python interpreter?", "C:\\Windows\\System32\\msvcp140.dll\r\nC:\\Windows\\SysWOW64\\msvcp140.dll", "Can you try running the following command at the same command prompt?\r\n\r\n```\r\npython -c \"import ctypes; print(ctypes.WinDLL('msvcp140.dll'))\"\r\n```", "Nagging Assignee @mrry: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @mrry: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Installing the DLL as in the error message fixed the issue for me. ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "i have the same issue", "Hi I am facing the same issue but in pycharm virtual environment. Any help is highly appreciated", "@shathesh18, I had the same issue. I then went [here (sorry for the German link)](https://support.microsoft.com/de-de/help/2977003/the-latest-supported-visual-c-downloads) and downoaded the  Microsoft Visual C++ Redistributable f\u00fcr Visual Studio 2015, 2017 und 2019 for my platform. The problem went away after restarting.", "@punyidea, I had the same issue. It worked pretty neat for me, thanks.", "Just click this link https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads Then install\r\n\r\n    x64: vc_redist.x64.exe\r\n\r\nand restart your pc.\r\n", "Same issue faced download this x64: vc_redist.x64.exe problem solved\r\n\r\nhttps://support.microsoft.com/en-us/topic/the-latest-supported-visual-c-downloads-2647da03-1eea-4433-9aff-95f26a218cc0", "> Just click this link https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads Then install\r\n> \r\n> ```\r\n> x64: vc_redist.x64.exe\r\n> ```\r\n> \r\n> and restart your pc.\r\n\r\nit not work in my PC\r\n", "Then Maybe you need to check the following things\r\n1. Check the path variable it must be inside local/prpgrams/python39 if u have previously installed 32 bit python the path must be inside roaming\r\n2. So make sure you hyave 64 bit python installed\r\n3. C++ redistributable may vary for your system so download it according to your configuration\r\n4.  ", "I had the same problem, this guide helped me:\r\nhttps://winbindex.m417z.com/?file=msvcp140.dll"]}, {"number": 18115, "title": "image restauration", "body": "", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of information - the issue is empty."]}, {"number": 18114, "title": "Docs cherry-picks for r1.7", "body": "", "comments": ["Thanks @yifeif ", "Yes. Thank you. This really helped us out."]}, {"number": 18113, "title": "Allow ComplexAbs Op on mobile platforms", "body": "Seems like it was disabled long time ago before open-sourcing Tensorflow.\r\nI think disabling it is no longer necessary.\r\nWorks now on Android. Could anyone check on iOS?\r\n\r\nSomewhat related issue: #11804", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 18112, "title": "Why is tf.images.resize_bicubic different from misc.imresize with bicubic method", "body": "Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10\r\nTensorFlow installed from (source or binary): binary \r\nTensorFlow version (use command below): 1.6\r\nPython version: 3.6\r\nBazel version (if compiling from source): \r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 9.0  cudnn 7.0\r\nGPU model and memory: GTX 1080ti\r\nExact command to reproduce: N\r\n\r\nI consider the implement of tf.images.resize_bicubic is similar to opencv resize method, but it has problem.\r\nThe opencv resize has more noise and less soomth. If we use opencv to resize image and process image super-resolution, it will degrade the performance.\r\nThere are some visual results generated by tensorflow and scipy.misc:\r\ntersorflow:\r\n![res2](https://user-images.githubusercontent.com/8861423/38127143-649f5e44-3427-11e8-8bcc-3c0c4f46b617.png)\r\nmisc:\r\n![res1](https://user-images.githubusercontent.com/8861423/38127136-592109fa-3427-11e8-800e-1e0ad4fe61a7.png)\r\n\r\nI wish the tensorflow can offer the implement of misc (or PIL, MATLAB)  resize method. Thanks!\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@rmlarsen : Any idea why this doesn't match opencv, and whether we're open to a change in that direction?", "Yes, and I also notice that TF's version has a little shift on images (usually several pixels), even with `aligned_corners=True`, which makes `tf.image.resize_image` inpractical to use.", "This sounds more like a bug than a feature request. \r\n\r\n`tf.images.resize_bicubic` is no longer supported in TensorFlow, and `scipy.misc.imresize` has been deprecated. Can someone reproduce with `tf.image.resize(..., method=bicubic)`, and confirm that there is still a discrepancy with OpenCV?", "@dynamicwebpaige Is `tf.image.resize(..., method=bicubic)` or any other interpolators intended to behaviour exactly the same as **OpenCV**?\r\n\r\nAs we know **OpenCV**'s `resize` behaves differently with PIL or matlab. For a researcher's point of view, it's more likely to use PIL or matlab's image functions rather than those functions provided in TF or OpenCV.\r\n\r\nMoreover, `align_corners` also affects the image quality and the output image is not actually \"aligned\" to the ground truth.", "@linchuming We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions.check [link1](https://www.tensorflow.org/api_docs/python/tf/image/resize) , [link2](https://stackoverflow.com/questions/57414277/alternative-to-scipy-misc-imresize) Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/18112\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/18112\">No</a>\n"]}, {"number": 18111, "title": "importing tensorflow.contrib produces a warning", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows and Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\npython\r\nimport tensorflow.contrib\r\n\r\n### Describe the problem\r\nUsing tensorflow.contrib produces a warning in 1.7. The warning is\r\n\r\nWARNING:tensorflow:From ...\\envs\\tf-1.7\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.", "comments": ["Encounter the same warning with python 2.7, TF1.7.0-rc1 from source, bazel version 0.11.1, gcc 5.4.0, ubuntu 16.04, Cuda 9.0, Cudnn 7.0.5", "Thank you for the report!\r\nI cherrypicked relevant fix in 1.7: https://github.com/tensorflow/tensorflow/pull/18130\r\nSo, this will be fixed in 1.7.1.", "Thanks @annarev! \r\n\r\nThis should be fixed once 1.7.1 arrives so I'm closing the issue.", "When will 1.7.1 be released? Is there a temporary solution to mute this output?\r\n", "@stefanievonk you can create a logging filter. A bit cumbersome but it gets the job done:\r\n\r\n```\r\nimport logging\r\n\r\nclass WarningFilter(logging.Filter):\r\n    def filter(self, record):\r\n        msg = record.getMessage()\r\n        tf_warning = 'retry (from tensorflow.contrib.learn.python.learn.datasets.base)' in msg\r\n        return not tf_warning\r\n            \r\nlogger = logging.getLogger('tensorflow')\r\nlogger.addFilter(WarningFilter())\r\n```\r\n", "Sorry for delay in response.\r\nWe decided to include the fix in 1.8.0rc0 instead of releasing 1.7.1.\r\n1.8.0rc0 should (most likely) be out later today.", "I used 1.8.0rc0 just now and still see the same error:\r\n\r\nWARNING:tensorflow:From C:\\Users\\Gebruiker\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\n\r\nPython 3.6.4, Windows10\r\n\r\nIs there a way around this, or should I wait for an update?", "@Nasnl do you see it when importing tensorflow.contrib?", "Hi @annarev \r\nThanks for checking this out. Sorry for not mentioning this right away.\r\n\r\nNo, I get the message when I gave the command \"python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config\" (creating a recognition engine for neighborhood parking issues to support the neighborhood detecting the amount of parked cars in the streets in a smarter way than manually counting them).\r\n", "I still see this message with tf 1.8 when following the tensorflow example of loading mnist dataset:\r\n```\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = nput_data.read_data_sets(\"MNIST_data/\", one_hot=True) \r\n```\r\n", "@Nasnl, sorry, forgot to reply back then. If the code uses \"retry\" from tensorflow.contrib.learn.python.learn.datasets.base then the error is expected. Original issue reported here happened when just importing \"tensorflow.conrib\" causes this warning to be printed.\r\n\r\n@kirk86, the warning gets printed because tensorflow.examples.tutorials.mnist.input_data depends on \r\nfrom tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/input_data.py\r\nwhich depends on deprecated \"maybe_download\" function:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/base.py\r\nThis issue is different from the one originally reported here. A fix would require updating the example so that it doesn't depend on this deprecated function. Can you open a separate issue for that?", "I still see this message with tf 1.8 when following the tensorflow example of loading mnist dataset:\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = nput_data.read_data_sets(\"MNIST_data/\", one_hot=True) \r\n\r\n**i got same error for that**", "Yes,still it's come\n\n\nOn Mon, Jul 23, 2018, 11:59 Sachin Prabhu <notifications@github.com> wrote:\n\n> Warning still persists in tf 1.8\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18111#issuecomment-406952870>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AZAqAbmXauHboKU4DBVbZy1fndpRxomlks5uJW1hgaJpZM4TBT1X>\n> .\n>\n", "Did you resolve this issue ?"]}, {"number": 18110, "title": "Branch 191029891", "body": "", "comments": []}, {"number": 18109, "title": "Branch 191024726", "body": "", "comments": []}, {"number": 18108, "title": "building from source with branch r1.7 gives tf1.5.1 after building wheel", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu 16.04.9\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.5.1 after successful building, but i want 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: build label 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**:5.4.0 when i type gcc --version, 7.2.0 shown in python terminal\r\n- **CUDA/cuDNN version**:cuda 9, cudnn 7\r\n- **GPU model and memory**: gtx1080 ti 11 gb\r\n- **Exact command to reproduce**: following this https://gist.github.com/kmhofmann/e368a2ebba05f807fa1a90b3bf9a1e03\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI've make sure i'd pull everything from tensorflow. i remove all other branch and check out r1.7, building was successful. No errors and stuff. The wheel i got says tensorflow-1.5.1-cp36 ... etc. , i go on to install it, tf.__version__ = 1.5.1 . I am confused how to build tf 1.7 from source.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Looking at your gist in https://gist.github.com/kmhofmann/e368a2ebba05f807fa1a90b3bf9a1e03 it seems you're using `git checkout v1.7.0`. There is no such branch in the repository, so that command likely did not switch you to the appropriate branch.\r\n\r\nRelease branches in this repository are named `r<version>`, so you'd want to do `git checkout r1.7` instead.\r\n\r\nClosing this since this seems to be an error in the steps being followed. Please feel free to re-open or create a new issue with more details if I'm mistaken. Thanks!"]}, {"number": 18107, "title": "Mask_Rcnn real time?", "body": "Though Mask_Rcnn is amazing, if it can't be applied to mobile devices, it will be useless. Can theoretically run on mobile devices in real time?\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:1.7\r\n- **TensorFlow version (use command below)**:1.7\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:none\r\n- **GCC/Compiler version (if compiling from source)**:none\r\n- **CUDA/cuDNN version**:9.0\r\n- **GPU model and memory**:7.1\r\n- **Exact command to reproduce**:none\r\n", "comments": ["This is not an issue with TensorFlow - your question is better suited for Stack Overflow. That said, perhaps you could look into using [TensorRT with TF 1.7](https://developers.googleblog.com/2018/03/tensorrt-integration-with-tensorflow.html) to speed up your Mask RCNN inference. This would be just one of many optimizations you could try.", "Nagging Assignee @tatatodd: It has been 173 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 18106, "title": "Fix issue with Luong attention when scale=True and dtype of tf.float16/tf.float64", "body": "This fix tries to address the issue raised in #18099 where Luong throws a ValueError when scale=True and dtype is not tf.float32.\r\n\r\nThis fix addresses the issue with the additional test case added.\r\n\r\nThis fix fixes #18099.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@ebrevdo Thanks for the review. The PR has been updated. Please take a look."]}, {"number": 18105, "title": "Fix typo in comment", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@msofka Thanks for the fix!"]}, {"number": 18104, "title": "Fix casting in Keras estimator", "body": "Fixes #18094\r\n\r\nThis allows users to have Inputs which are not numeric like booleans or strings.", "comments": ["I made the code cleaner. \r\nis_numeric_tensor will return False when provided with a numpy array so that's why the code was weird.", "We need a closure so that eager.context and all the other modules are loaded.\r\nOtherwise, you would get errors like context is None.\r\n\r\nI'll try to dig into this issue before Monday or should I just try a simpler test to fix this issue and investigate the eager context issue after?\r\n\r\nEDIT: We still need a local import for the closure, but it works with a lambda. When we clone the model to create an estimator, the environment of the function is not saved. So probably a bug in the get_config of Lambda.", "The Lambda bug is harder than expected. So I simplified the test to fix the actual bug (forcing casting to float). Ready for review."]}, {"number": 18103, "title": "Keras TimeDistributed wrapper around GlobalMaxPooling2D error with TPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0-rc1\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: Google Cloud TPU v2-8 running TF 1.7\r\n- **Exact command to reproduce**: See below\r\n\r\n\r\n### Describe the problem\r\nUsing a Keras TimeDistributed wrapper to wrap a Keras GlobalMaxPooling2D layer, and processing on a Google Cloud TPU results in a ```ValueError```. The layer behaves as expected if the TPUEstimator is configured to use CPU. Error raised by the TPU failure case:\r\n```ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/time_distributed/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/time_distributed/while/while_context').```\r\n\r\n### Source code / logs\r\nTest code minimal example keras_td_test.py:\r\n```python\r\n\"\"\" Test for Keras model TimeDistributed wrapper on TPU.\r\n    Based on https://github.com/tensorflow/tpu/blob/master/models/official/resnet/\r\n\"\"\"\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom absl import flags\r\nimport absl.logging as _logging  # pylint: disable=unused-import\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_config\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_estimator\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_optimizer\r\n\r\n# Define flags for the system\r\nFLAGS = flags.FLAGS\r\nflags.DEFINE_bool(\r\n    'use_tpu', True,\r\n    help=('Use TPU to execute the model for training and evaluation. If'\r\n          ' --use_tpu=false, will use whatever devices are available to'\r\n          ' TensorFlow by default (e.g. CPU and GPU)'))\r\nflags.DEFINE_string(\r\n    'tpu_name', default=None,\r\n    help='Name of the Cloud TPU for Cluster Resolvers.')\r\nflags.DEFINE_string(\r\n    'model_dir', default=None,\r\n    help=('The directory where the model and training/evaluation summaries are'\r\n          ' stored.'))\r\n\r\ndef main(unused_argv):\r\n    # Get the TPU GRPC URL if it is needed\r\n    if FLAGS.use_tpu:\r\n        tpu_cluster_resolver = (\r\n            tf.contrib.cluster_resolver.TPUClusterResolver(\r\n                FLAGS.tpu_name))\r\n        tpu_grpc_url = tpu_cluster_resolver.get_master()\r\n    else:\r\n        tpu_grpc_url = None\r\n\r\n    # Set the configuration for the TPU\r\n    config = tpu_config.RunConfig(\r\n        master=tpu_grpc_url,\r\n        model_dir=FLAGS.model_dir)\r\n\r\n    # Create the TPUEstimator\r\n    test_estimator = tpu_estimator.TPUEstimator(\r\n            use_tpu=FLAGS.use_tpu,\r\n            model_fn=test_model_fn,\r\n            config=config,\r\n            train_batch_size=1024)\r\n\r\n    # Train the estimator for 10 steps\r\n    test_estimator.train(input_fn, max_steps=10)\r\n\r\ndef input_fn(params):\r\n    # Generate a random dataset of the correct shape\r\n    data = np.random.rand(1024, 10, 10, 10).astype(np.float32)\r\n    label = np.random.rand(1024,10).astype(np.float32)\r\n\r\n    # Repeat and batch\r\n    rand_dataset = tf.data.Dataset.from_tensor_slices((data, label)).repeat()\r\n    rand_dataset = rand_dataset.apply(tf.contrib.data.batch_and_drop_remainder(params['batch_size']))\r\n\r\n    # Make input_fn for the TPUEstimator train step\r\n    rand_dataset_fn = rand_dataset.make_one_shot_iterator().get_next()\r\n    return rand_dataset_fn\r\n\r\ndef test_model_fn(features, labels, mode, params):\r\n    # Dense layer to give the system something to train\r\n    dense_out = tf.keras.layers.Dense(10)(features)\r\n\r\n    ##########################################\r\n    # The Keras wrapper that causes an error #\r\n    ##########################################\r\n    predictions = tf.keras.layers.TimeDistributed(\r\n        tf.keras.layers.GlobalMaxPooling2D()\r\n    )(dense_out)\r\n\r\n    # Create ops for the TPUEstimatorSpec\r\n    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)\r\n    optimizer = tf.train.GradientDescentOptimizer(0.001)\r\n    if FLAGS.use_tpu:\r\n        optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)\r\n    global_step = tf.train.get_global_step()\r\n    train_op = optimizer.minimize(loss, global_step)\r\n\r\n    # Return the TPUEstimatorSpec\r\n    return tpu_estimator.TPUEstimatorSpec(\r\n        mode=mode,\r\n        loss=loss,\r\n        train_op=train_op)\r\n\r\nif __name__ == '__main__':\r\n    # Do the thing\r\n    print('main wrapper')\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run()\r\n```\r\n\r\nError on TPU, and sanitized log file:\r\n```\r\n$ python keras_td_test.py --model_dir=gs://my_bucket/keras_td_test --tpu_name=tpu-name\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0329 19:53:32.386956 139824142264064 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\nmain wrapper\r\nW0329 19:53:32.582829 139824142264064 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\r\n    from . import file_cache\r\n  File \"/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\r\n    'file_cache is unavailable when using oauth2client >= 4.0.0')\r\nImportError: file_cache is unavailable when using oauth2client >= 4.0.0\r\n2018-03-29 19:53:32.619736: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-03-29 19:53:32.622444: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:44849}\r\n2018-03-29 19:53:32.623808: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:44849\r\nW0329 19:53:32.704463 139824142264064 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f2b1fc4d7d0>) includes params argument, but params are not passed to Estimator.\r\nI0329 19:53:32.705055 139824142264064 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2b1fc4bc90>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_td_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nI0329 19:53:32.772562 139824142264064 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.\r\n2018-03-29 19:53:32.773276: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\r\nI0329 19:53:32.776926 139824142264064 tf_logging.py:116] Found TPU system:\r\nI0329 19:53:32.777101 139824142264064 tf_logging.py:116] *** Num TPU Cores: 8\r\nI0329 19:53:32.777353 139824142264064 tf_logging.py:116] *** Num TPU Workers: 1\r\nI0329 19:53:32.777436 139824142264064 tf_logging.py:116] *** Num TPU Cores Per Worker: 8\r\nI0329 19:53:32.777509 139824142264064 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]\r\nI0329 19:53:32.789855 139824142264064 tf_logging.py:116] Calling model_fn.\r\nTraceback (most recent call last):\r\n  File \"keras_td_test.py\", line 101, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"keras_td_test.py\", line 57, in main\r\n    test_estimator.train(input_fn, max_steps=10)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 824, in _train_model\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 805, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 1827, in _model_fn\r\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2016, in _train_on_tpu_system\r\n    device_assignment=ctx.device_assignment)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 491, in shard\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 323, in replicate\r\n    outputs = computation(*computation_inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2009, in multi_tpu_train_steps_on_single_shard\r\n    name=b'loop')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\r\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3202, in while_loop\r\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2940, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2877, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 120, in body_wrapper\r\n    outputs = body(*(inputs + dequeue_ops))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 203, in body_wrapper\r\n    return [i + 1] + _convert_to_list(body(*args))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 1076, in train_step\r\n    self._call_model_fn(features, labels))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 1230, in _call_model_fn\r\n    estimator_spec = self._model_fn(features=features, **kwargs)\r\n  File \"keras_td_test.py\", line 89, in test_model_fn\r\n    train_op = optimizer.minimize(loss, global_step)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 399, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_optimizer.py\", line 85, in compute_gradients\r\n    return self._opt.compute_gradients(loss, var_list=var_list, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 492, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 488, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 625, in _GradientsHelper\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 379, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 625, in <lambda>\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_grad.py\", line 131, in _TensorArrayWriteGrad\r\n    grad = g.read(index)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 861, in read\r\n    return self._implementation.read(index, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 260, in read\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6419, in tensor_array_read_v3\r\n    dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1696, in __init__\r\n    self._control_flow_post_processing()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1707, in _control_flow_post_processing\r\n    self._control_flow_context.AddOp(self)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2429, in AddOp\r\n    self._AddOpInternal(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2450, in _AddOpInternal\r\n    real_x = self.AddValue(x)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2382, in AddValue\r\n    real_val = grad_ctxt.grad_state.GetRealValue(val)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1152, in GetRealValue\r\n    history_value = cur_grad_state.AddForwardAccumulator(cur_value)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1017, in AddForwardAccumulator\r\n    value, self.forward_context)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 752, in GetMaxSizeFromNestedMaximumIterations\r\n    \"the tf.while_loop call ('%s').\" % (value_name, while_ctxt.name))\r\nValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/time_distributed/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/time_distributed/while/while_context').\r\n```\r\n\r\nWorking as expected on CPU:\r\n```\r\n$ python keras_td_test.py --model_dir=gs://my_bucket/keras_td_test --use_tpu=False\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0329 19:52:51.631102 140253725816576 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\nmain wrapper\r\nW0329 19:52:51.829307 140253725816576 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f8f24f2c7d0>) includes params argument, but params are not passed to Estimator.\r\nI0329 19:52:51.829844 140253725816576 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8f24f2a550>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_td_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nI0329 19:52:51.967509 140253725816576 tf_logging.py:116] Calling model_fn.\r\nI0329 19:52:51.967808 140253725816576 tf_logging.py:116] Running train on CPU\r\nI0329 19:52:52.141927 140253725816576 tf_logging.py:116] Done calling model_fn.\r\nI0329 19:52:52.143158 140253725816576 tf_logging.py:116] Create CheckpointSaverHook.\r\nI0329 19:52:53.315506 140253725816576 tf_logging.py:116] Graph was finalized.\r\n2018-03-29 19:52:53.315908: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nI0329 19:52:53.452600 140253725816576 tf_logging.py:116] Running local_init_op.\r\nI0329 19:52:53.456309 140253725816576 tf_logging.py:116] Done running local_init_op.\r\nI0329 19:52:55.594362 140253725816576 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_td_test/model.ckpt.\r\nI0329 19:52:58.770798 140253725816576 tf_logging.py:116] loss = 0.62052673, step = 0\r\nI0329 19:52:59.185467 140253725816576 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_td_test/model.ckpt.\r\nI0329 19:53:03.196044 140253725816576 tf_logging.py:116] Loss for final step: 0.5509924.\r\n```", "comments": ["May be related to #18102 ", "Nagging Assignee @fchollet: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @fchollet: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @fchollet: It has been 52 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "You are correct; the issues are related.  The XLA compiler used for TPU compilation requires that all tensors have static shapes.  In the case of TimeDistributed, the underlying layer must have a fixed input length, which appears to be the case here.  Unfortunately, the required wiring of the input length to the maximum iteration count is only available in TF 1.9.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/backend.py#L3195\r\n\r\nYou should be able to use this today by installing the TF 1.9 RC0 on your host VM (barring network incompatibilities with the TPU), and in general when TF 1.9 is released."]}, {"number": 18102, "title": "Keras LSTM layer error with TPU unless it is unrolled", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0-rc1\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: Google Cloud TPU v2-8 running TF 1.7\r\n- **Exact command to reproduce**: See below\r\n\r\n\r\n### Describe the problem\r\nUsing a Keras LSTM layer, and processing on a Google Cloud TPU results in a ```ValueError``` if the lstm is not unrolled. The layer behaves as expected if the TPUEstimator is configured to use CPU, or if the lstm loop is unrolled on either the TPU or CPU. Error raised by the TPU failure case:\r\n```ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/lstm/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/lstm/while/while_context').```\r\n\r\n### Source code / logs\r\nTest code minimal example keras_lstm_test.py:\r\n```python\r\n\"\"\" Test for Keras model LSTM on TPU.\r\n    Based on https://github.com/tensorflow/tpu/blob/master/models/official/resnet/\r\n\"\"\"\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom absl import flags\r\nimport absl.logging as _logging  # pylint: disable=unused-import\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_config\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_estimator\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_optimizer\r\n\r\n# Define flags for the system\r\nFLAGS = flags.FLAGS\r\nflags.DEFINE_bool(\r\n    'use_tpu', True,\r\n    help=('Use TPU to execute the model for training and evaluation. If'\r\n          ' --use_tpu=false, will use whatever devices are available to'\r\n          ' TensorFlow by default (e.g. CPU and GPU)'))\r\nflags.DEFINE_string(\r\n    'tpu_name', default=None,\r\n    help='Name of the Cloud TPU for Cluster Resolvers.')\r\nflags.DEFINE_string(\r\n    'model_dir', default=None,\r\n    help=('The directory where the model and training/evaluation summaries are'\r\n          ' stored.'))\r\nflags.DEFINE_bool(\r\n    'unroll_lstm', default=False,\r\n    help=('Unrolls the Keras LSTM if this is True.'))\r\n\r\ndef main(unused_argv):\r\n    # Get the TPU GRPC URL if it is needed\r\n    if FLAGS.use_tpu:\r\n        tpu_cluster_resolver = (\r\n            tf.contrib.cluster_resolver.TPUClusterResolver(\r\n                FLAGS.tpu_name))\r\n        tpu_grpc_url = tpu_cluster_resolver.get_master()\r\n    else:\r\n        tpu_grpc_url = None\r\n\r\n    # Set the configuration for the TPU\r\n    config = tpu_config.RunConfig(\r\n        master=tpu_grpc_url,\r\n        model_dir=FLAGS.model_dir)\r\n\r\n    # Create the TPUEstimator\r\n    test_estimator = tpu_estimator.TPUEstimator(\r\n            use_tpu=FLAGS.use_tpu,\r\n            model_fn=test_model_fn,\r\n            config=config,\r\n            train_batch_size=1024)\r\n\r\n    # Train the estimator for 10 steps\r\n    test_estimator.train(input_fn, max_steps=10)\r\n\r\ndef input_fn(params):\r\n    # Generate a random dataset of the correct shape\r\n    data = np.random.rand(1024, 10, 10).astype(np.float32)\r\n    label = np.random.rand(1024,10).astype(np.float32)\r\n\r\n    # Repeat and batch\r\n    rand_dataset = tf.data.Dataset.from_tensor_slices((data, label)).repeat()\r\n    rand_dataset = rand_dataset.apply(tf.contrib.data.batch_and_drop_remainder(params['batch_size']))\r\n\r\n    # Make input_fn for the TPUEstimator train step\r\n    rand_dataset_fn = rand_dataset.make_one_shot_iterator().get_next()\r\n    return rand_dataset_fn\r\n\r\ndef test_model_fn(features, labels, mode, params):\r\n    ###################################################################\r\n    # The Keras LSTM layer that causes an error unless it is unrolled #\r\n    ###################################################################\r\n    predictions = tf.keras.layers.LSTM(10, unroll=FLAGS.unroll_lstm)(features)\r\n\r\n    # Create ops for the TPUEstimatorSpec\r\n    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)\r\n    optimizer = tf.train.GradientDescentOptimizer(0.001)\r\n    if FLAGS.use_tpu:\r\n        optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)\r\n    global_step = tf.train.get_global_step()\r\n    train_op = optimizer.minimize(loss, global_step)\r\n\r\n    # Return the TPUEstimatorSpec\r\n    return tpu_estimator.TPUEstimatorSpec(\r\n        mode=mode,\r\n        loss=loss,\r\n        train_op=train_op)\r\n\r\nif __name__ == '__main__':\r\n    # Do the thing\r\n    print('main wrapper')\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run()\r\n```\r\n\r\n\r\nError on TPU with unroll_loop set to False, and sanitized log file:\r\n```\r\n$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --tpu_name=tpu-name --unroll_lstm=False\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0329 19:54:49.412791 140278551017216 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\nmain wrapper\r\nW0329 19:54:49.621851 140278551017216 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\r\n    from . import file_cache\r\n  File \"/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\r\n    'file_cache is unavailable when using oauth2client >= 4.0.0')\r\nImportError: file_cache is unavailable when using oauth2client >= 4.0.0\r\n2018-03-29 19:54:49.659244: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-03-29 19:54:49.662161: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:45589}\r\n2018-03-29 19:54:49.663623: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:45589\r\nW0329 19:54:49.753117 140278551017216 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f94eca3f7d0>) includes params argument, but params are not passed to Estimator.\r\nI0329 19:54:49.753689 140278551017216 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94eca3d710>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nI0329 19:54:49.827284 140278551017216 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.\r\n2018-03-29 19:54:49.828047: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\r\nI0329 19:54:49.831892 140278551017216 tf_logging.py:116] Found TPU system:\r\nI0329 19:54:49.832133 140278551017216 tf_logging.py:116] *** Num TPU Cores: 8\r\nI0329 19:54:49.832345 140278551017216 tf_logging.py:116] *** Num TPU Workers: 1\r\nI0329 19:54:49.832411 140278551017216 tf_logging.py:116] *** Num TPU Cores Per Worker: 8\r\nI0329 19:54:49.832514 140278551017216 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]\r\nI0329 19:54:49.845520 140278551017216 tf_logging.py:116] Calling model_fn.\r\nTraceback (most recent call last):\r\n  File \"keras_lstm_test.py\", line 99, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"keras_lstm_test.py\", line 60, in main\r\n    test_estimator.train(input_fn, max_steps=10)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 355, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 824, in _train_model\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 805, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 1827, in _model_fn\r\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2016, in _train_on_tpu_system\r\n    device_assignment=ctx.device_assignment)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 491, in shard\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 323, in replicate\r\n    outputs = computation(*computation_inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2009, in multi_tpu_train_steps_on_single_shard\r\n    name=b'loop')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\r\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3202, in while_loop\r\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2940, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2877, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 120, in body_wrapper\r\n    outputs = body(*(inputs + dequeue_ops))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 203, in body_wrapper\r\n    return [i + 1] + _convert_to_list(body(*args))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 1076, in train_step\r\n    self._call_model_fn(features, labels))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 1230, in _call_model_fn\r\n    estimator_spec = self._model_fn(features=features, **kwargs)\r\n  File \"keras_lstm_test.py\", line 87, in test_model_fn\r\n    train_op = optimizer.minimize(loss, global_step)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 399, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_optimizer.py\", line 85, in compute_gradients\r\n    return self._opt.compute_gradients(loss, var_list=var_list, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 492, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 488, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 625, in _GradientsHelper\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 379, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 625, in <lambda>\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_grad.py\", line 131, in _TensorArrayWriteGrad\r\n    grad = g.read(index)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 861, in read\r\n    return self._implementation.read(index, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 260, in read\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6419, in tensor_array_read_v3\r\n    dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1696, in __init__\r\n    self._control_flow_post_processing()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1707, in _control_flow_post_processing\r\n    self._control_flow_context.AddOp(self)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2429, in AddOp\r\n    self._AddOpInternal(op)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2450, in _AddOpInternal\r\n    real_x = self.AddValue(x)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2382, in AddValue\r\n    real_val = grad_ctxt.grad_state.GetRealValue(val)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1152, in GetRealValue\r\n    history_value = cur_grad_state.AddForwardAccumulator(cur_value)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1017, in AddForwardAccumulator\r\n    value, self.forward_context)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 752, in GetMaxSizeFromNestedMaximumIterations\r\n    \"the tf.while_loop call ('%s').\" % (value_name, while_ctxt.name))\r\nValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/lstm/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/lstm/while/while_context').\r\n```\r\n\r\n\r\nWorking as expected on TPU with unroll_lstm set to True:\r\n```\r\n$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --tpu_name=tpu-name --unroll_lstm=True\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0329 19:54:56.462137 140718335936256 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\nmain wrapper\r\nW0329 19:54:56.665755 140718335936256 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\r\n    from . import file_cache\r\n  File \"/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\r\n    'file_cache is unavailable when using oauth2client >= 4.0.0')\r\nImportError: file_cache is unavailable when using oauth2client >= 4.0.0\r\n2018-03-29 19:54:56.704991: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-03-29 19:54:56.707871: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:42697}\r\n2018-03-29 19:54:56.709444: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:42697\r\nW0329 19:54:56.802102 140718335936256 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7ffb51dff7d0>) includes params argument, but params are not passed to Estimator.\r\nI0329 19:54:56.802637 140718335936256 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ffb51dfdcd0>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nI0329 19:54:56.876996 140718335936256 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.\r\n2018-03-29 19:54:56.877690: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\r\nI0329 19:54:56.881433 140718335936256 tf_logging.py:116] Found TPU system:\r\nI0329 19:54:56.881619 140718335936256 tf_logging.py:116] *** Num TPU Cores: 8\r\nI0329 19:54:56.881828 140718335936256 tf_logging.py:116] *** Num TPU Workers: 1\r\nI0329 19:54:56.881892 140718335936256 tf_logging.py:116] *** Num TPU Cores Per Worker: 8\r\nI0329 19:54:56.881998 140718335936256 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]\r\nI0329 19:54:56.894473 140718335936256 tf_logging.py:116] Calling model_fn.\r\nI0329 19:55:00.045663 140718335936256 tf_logging.py:116] Done calling model_fn.\r\nI0329 19:55:00.046016 140718335936256 tf_logging.py:116] Create CheckpointSaverHook.\r\nI0329 19:55:01.532725 140718335936256 tf_logging.py:116] TPU job name tpu_worker\r\nI0329 19:55:01.588900 140718335936256 tf_logging.py:116] Graph was finalized.\r\nI0329 19:55:02.225465 140718335936256 tf_logging.py:116] Running local_init_op.\r\nI0329 19:55:02.271645 140718335936256 tf_logging.py:116] Done running local_init_op.\r\nI0329 19:55:02.415777 140718335936256 tf_logging.py:116] Init TPU system\r\nI0329 19:55:07.818669 140718335936256 tf_logging.py:116] Start infeed thread controller\r\nI0329 19:55:07.819324 140713782138624 tf_logging.py:116] Starting infeed thread controller.\r\nI0329 19:55:07.819504 140718335936256 tf_logging.py:116] Start outfeed thread controller\r\nI0329 19:55:07.820395 140713773745920 tf_logging.py:116] Starting outfeed thread controller.\r\nI0329 19:55:10.587852 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.\r\nI0329 19:55:10.588713 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.\r\nI0329 19:55:12.060930 140718335936256 tf_logging.py:116] Saving checkpoints for 2 into gs://my_bucket/keras_lstm_test/model.ckpt.\r\nI0329 19:55:15.523288 140718335936256 tf_logging.py:116] loss = 0.4525105, step = 0\r\nI0329 19:55:15.525207 140718335936256 tf_logging.py:116] loss = 0.4525105, step = 0\r\nI0329 19:55:15.527029 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.\r\nI0329 19:55:15.527189 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.\r\nI0329 19:55:15.618277 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.\r\nI0329 19:55:15.618545 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.\r\nI0329 19:55:15.628783 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.\r\nI0329 19:55:15.629064 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.\r\nI0329 19:55:15.640600 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.\r\nI0329 19:55:15.640825 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.\r\nI0329 19:55:15.649879 140718335936256 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.\r\nI0329 19:55:19.049213 140718335936256 tf_logging.py:116] Stop infeed thread controller\r\nI0329 19:55:19.049483 140718335936256 tf_logging.py:116] Shutting down InfeedController thread.\r\nI0329 19:55:19.049849 140713782138624 tf_logging.py:116] InfeedController received shutdown signal, stopping.\r\nI0329 19:55:19.050069 140713782138624 tf_logging.py:116] Infeed thread finished, shutting down.\r\nI0329 19:55:19.050215 140718335936256 tf_logging.py:116] Stop output thread controller\r\nI0329 19:55:19.050323 140718335936256 tf_logging.py:116] Shutting down OutfeedController thread.\r\nI0329 19:55:19.050463 140713773745920 tf_logging.py:116] OutfeedController received shutdown signal, stopping.\r\nI0329 19:55:19.050602 140713773745920 tf_logging.py:116] Outfeed thread finished, shutting down.\r\nI0329 19:55:19.050734 140718335936256 tf_logging.py:116] Shutdown TPU system.\r\nI0329 19:55:19.303575 140718335936256 tf_logging.py:116] Loss for final step: 0.45125633.\r\n```\r\n\r\n\r\nWorking as expected with unroll_loop set to either True or False on CPU:\r\n```\r\n$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --use_tpu=False --unroll_lstm=False\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0329 19:55:58.036350 139650416416512 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\nmain wrapper\r\nW0329 19:55:58.224196 139650416416512 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f02ace3f7d0>) includes params argument, but params are not passed to Estimator.\r\nI0329 19:55:58.224781 139650416416512 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f02ace3d590>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nI0329 19:55:58.333888 139650416416512 tf_logging.py:116] Calling model_fn.\r\nI0329 19:55:58.334151 139650416416512 tf_logging.py:116] Running train on CPU\r\nI0329 19:55:58.917757 139650416416512 tf_logging.py:116] Done calling model_fn.\r\nI0329 19:55:58.919229 139650416416512 tf_logging.py:116] Create CheckpointSaverHook.\r\nI0329 19:56:00.058123 139650416416512 tf_logging.py:116] Graph was finalized.\r\n2018-03-29 19:56:00.058509: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nI0329 19:56:00.216192 139650416416512 tf_logging.py:116] Running local_init_op.\r\nI0329 19:56:00.223177 139650416416512 tf_logging.py:116] Done running local_init_op.\r\nI0329 19:56:01.895720 139650416416512 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_lstm_test/model.ckpt.\r\nI0329 19:56:04.683254 139650416416512 tf_logging.py:116] loss = 0.4141244, step = 0\r\nI0329 19:56:05.080931 139650416416512 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.\r\nI0329 19:56:08.176239 139650416416512 tf_logging.py:116] Loss for final step: 0.41163954.\r\n```\r\n```\r\n$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --use_tpu=False --unroll_lstm=True\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0329 19:56:34.716190 140417782937344 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\nmain wrapper\r\nW0329 19:56:34.914796 140417782937344 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7fb55784e7d0>) includes params argument, but params are not passed to Estimator.\r\nI0329 19:56:34.915416 140417782937344 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb55784c590>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}\r\nI0329 19:56:35.047240 140417782937344 tf_logging.py:116] Calling model_fn.\r\nI0329 19:56:35.047514 140417782937344 tf_logging.py:116] Running train on CPU\r\nI0329 19:56:37.489144 140417782937344 tf_logging.py:116] Done calling model_fn.\r\nI0329 19:56:37.490300 140417782937344 tf_logging.py:116] Create CheckpointSaverHook.\r\nI0329 19:56:39.153974 140417782937344 tf_logging.py:116] Graph was finalized.\r\n2018-03-29 19:56:39.154479: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nI0329 19:56:39.485604 140417782937344 tf_logging.py:116] Running local_init_op.\r\nI0329 19:56:39.513873 140417782937344 tf_logging.py:116] Done running local_init_op.\r\nI0329 19:56:43.631685 140417782937344 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_lstm_test/model.ckpt.\r\nI0329 19:56:47.166574 140417782937344 tf_logging.py:116] loss = 0.41451082, step = 0\r\nI0329 19:56:48.535309 140417782937344 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.\r\nI0329 19:56:52.381931 140417782937344 tf_logging.py:116] Loss for final step: 0.41207257.\r\n```\r\n", "comments": ["May be related to #18103 ", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 51 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This behavior is expected for TPUs.  The XLA compiler (which is used to compile TPU programs), requires all tensors in a graph to have static shapes.  In this case, the default Keras RNN behavior results in a loop with dynamic shape since TensorFlow cannot, in general, infer the number of iterations taken by a while loop.\r\n\r\n(The error message can likely be improved)\r\n\r\nIn TF 1.9, you can specify a maximum input length using the `input_length` argument to your RNN/LSTM instead of unrolling the network.", "@rjpower I understand the need for all tensors in the XLA compiled graph to have static shapes, and in this case all tensors do have static shapes.\r\n\r\nFor instance, printing the dataset before calling the make_one_shot_iterator:\r\n``` <_RestructuredDataset shapes: ((1024, 10, 10), (1024, 10)), types: (tf.float32, tf.float32)> ```\r\n\r\nThe 'features' tensor prior to the LSTM layer:\r\n``` Tensor(\"InfeedQueue/dequeue:0\", shape=(128, 10, 10), dtype=float32, device=/device:TPU_REPLICATED_CORE:0) ```\r\n\r\nAnd the 'predictions' tensor  after the LSTM layer:\r\n``` Tensor(\"lstm/TensorArrayReadV3:0\", shape=(128, 10), dtype=float32) ```\r\n\r\nThat being said, it looks like the changes in TF 1.9 will work for this use-case as well.", "I understand what you mean now.  The issue you're seeing is because there's an internally dynamic shape but the shape inference at the Keras level is static.  (As we integrate more native Keras support we will have more static checks at the Keras level to identify these issues and give appropriate error messages)."]}, {"number": 18101, "title": "Issue in understanding tf.record and tf-slim. (I couldn't find Documentation)", "body": "I am trying to fine-tune inceptionv3 model using slim tensorflow library. \r\nI tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the checkpoint. However, I am unable to understand certain things while writing the code for it.   Here are the steps I followed \r\n\r\n 1. I created a tf.record for my training data which is fine, now I am reading the data using the below code. \r\n[\r\n  ```\r\n  import tensorflow as tf\r\n    import tensorflow.contrib.slim.nets as nets\r\n    import tensorflow.contrib.slim as slim\r\n    import matplotlib.pyplot as plt\r\n    import numpy as np\r\n    \r\n    # get the data and labels here\r\n    \r\n    data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'\r\n    \r\n    # Training setting\r\n    num_epochs = 100\r\n    initial_learning_rate = 0.0002\r\n    learning_rate_decay_factor = 0.7\r\n    num_epochs_before_decay = 5\r\n    num_classes = 5980\r\n    \r\n    # load the checkpoint\r\n    model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'\r\n    \r\n    # log directory\r\n    log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'\r\n    \r\n    with tf.Session() as sess:\r\n        feature = {'train/image': tf.FixedLenFeature([], tf.string),\r\n                   'train/label': tf.FixedLenFeature([], tf.int64)}\r\n    \r\n        # Create a list of filenames and pass it to a queue\r\n        filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\r\n    \r\n        # Define a reader and read the next record\r\n        reader = tf.TFRecordReader()\r\n        _, serialized_example = reader.read(filename_queue)\r\n    \r\n        # Decode the record read by the reader\r\n        features = tf.parse_single_example(serialized_example, features=feature)\r\n    \r\n        # Convert the image data from string back to the numbers\r\n        image = tf.decode_raw(features['train/image'], tf.float32)\r\n    \r\n        # Cast label data into int32\r\n        label = tf.cast(features['train/label'], tf.int32)\r\n    \r\n        # Reshape image data into the original shape\r\n        image = tf.reshape(image, [128, 128, 3])\r\n    \r\n        # Creates batches by randomly shuffling tensors\r\n        images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,\r\n                                                min_after_dequeue=64)](url)\r\n```\r\n\r\nNow I am finetuning the model using slim and this is the code. \r\n\r\n      init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n        sess.run(init_op)\r\n    \r\n        # Create a coordinator and run all QueueRunner objects\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(coord=coord)\r\n    \r\n        # load model\r\n    \r\n        # load the inception model from the slim library - we are using inception v3\r\n        #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))\r\n    \r\n        img, lbl = sess.run([images, labels])\r\n        one_hot_labels = slim.one_hot_encoding(lbl, num_classes)\r\n    \r\n        with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):\r\n            logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,\r\n                                                              dropout_keep_prob=.6)\r\n    \r\n        # Restore convolutional layers:\r\n    \r\n        variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])\r\n        init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\r\n    \r\n        # loss function\r\n        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)\r\n        total_loss = tf.losses.get_total_loss()\r\n    \r\n        # train operation\r\n        train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))\r\n    \r\n        print('Im here')\r\n        # Start training.\r\n        slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)\r\n\r\nNow I have few questions about the code, which I am quite unable to figure out. Once, the code reaches **slim.learning.train** I don't see anything printing however, it's training, I can see in the log. Now, \r\n1. How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.  \r\n2. How do I make sure that in the code **tf.train.shuffle_batch** I am not repeating my images and I am training over the whole dataset? \r\n3. How can I print the loss values while it's training?\r\n4. If I create a validation set then how can I switch betweem training the model and validation? \r\n\r\nThanks for the help!  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nI'll leave this issue open for a while in case someone who can answer your questions comes across it.  I'm not sure whether your questions are really slim specific, so you really might do better on StackOverflow.\r\n"]}, {"number": 18100, "title": "Use rules_go to build go API", "body": "This PR allows to add tensorflow dependency for Go API using rules_go and bazel.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Tested that it builds successfully.\r\n\r\n```\r\n$ bazel build tensorflow/go:go_default_library\r\nWARNING: /Users/gangil/dev/githu/tensorflow/tensorflow/go/BUILD.bazel:31:1: in srcs attribute of cc_library rule //tensorflow/go:go_default_library.cgo_c_lib: please do not import '//tensorflow/c:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'go_library_macro', the error might have been caused by the macro implementation in /private/var/tmp/_bazel_gangil/34179f030f2886356df4228bf65afbfe/external/io_bazel_rules_go/go/private/rules/cgo.bzl:364:14\r\nWARNING: /Users/gangil/dev/githu/tensorflow/tensorflow/go/BUILD.bazel:31:1: in srcs attribute of cc_library rule //tensorflow/go:go_default_library.cgo_c_lib: please do not import '//tensorflow/c:c_api_experimental.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'go_library_macro', the error might have been caused by the macro implementation in /private/var/tmp/_bazel_gangil/34179f030f2886356df4228bf65afbfe/external/io_bazel_rules_go/go/private/rules/cgo.bzl:364:14\r\nINFO: Analysed target //tensorflow/go:go_default_library (15 packages loaded).\r\nINFO: Found 1 target...\r\nINFO: From Linking tensorflow/go/libgo_default_library.cgo_c_lib.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/go/libgo_default_library.cgo_c_lib.lo(doc.cgo2.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/go/libgo_default_library.cgo_c_lib.lo(lib.cgo2.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/go/libgo_default_library.cgo_c_lib.lo(shape.cgo2.o) has no symbols\r\nTarget //tensorflow/go:go_default_library up-to-date:\r\n  bazel-bin/tensorflow/go/darwin_amd64_stripped/go_default_library~/github.com/tensorflow/tensorflow/tensorflow/go.a\r\nINFO: Elapsed time: 83.756s, Critical Path: 24.73s\r\nINFO: Build completed successfully, 31 total actions\r\n```", "ping @jart ", "Hi @jart do you know why the two builds are failing? \r\nFor example the Ubuntu Sanity build just says\r\n```exited with error code 1```", "@akashgangil looks like you need to update the build files. I see this error in the logs:\r\n\r\n```\r\n=== Sanity check step 4 of 13: do_buildifier (buildifier check) ===\r\nRunning do_buildifier on 325 files\r\ntensorflow/go/genop/internal/BUILD # callsort\r\ntensorflow/go/genop/BUILD # callsort\r\nbuildifier took 1 s\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n24d23\r\n<     importpath = \"github.com/tensorflow/tensorflow/go/genop/internal\",\r\n25a25\r\n>     importpath = \"github.com/tensorflow/tensorflow/go/genop/internal\",\r\n13d12\r\n<     importpath = \"github.com/tensorflow/tensorflow/go/genop\",\r\n14a14\r\n>     importpath = \"github.com/tensorflow/tensorflow/go/genop\",\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "I signed it!", "@rmlarsen Do you know whose CLA isn't there? Both me and the co-author zanes2016, have signed the CLA. ", "I signed it!", "It looks like some changes by user \"Ubuntu\" were commited into your branch: https://github.com/tensorflow/tensorflow/pull/18100/commits/f98aa82ece87487c7c936fa33872c5fb70e4cf9a", "CLAs look good, thanks!\n\n<!-- ok -->", "@jart all the changes that you requested have been addressed. Could you please take a look at it once again?\r\n\r\nI am just waiting for builds to retrigger.", "This build code is surprisingly simple and elegant. If Bazel and rules_go have progressed this much then I'm very happy.", "@akashgangil Thanks for the contribution!\r\n@jart Thanks for the review.", "@akashgangil It looks like the sanity check failed with:\r\n\r\nERROR: /tmpfs/src/github/tensorflow/tensorflow/go/genop/BUILD:3:1: no such package 'tensorflow/tensorflow/go/genop/internal': BUILD file not found on package path and referenced by '//tensorflow/go/genop:go_default_library'\r\nERROR: Analysis of target '//tensorflow/go/genop:genop' failed; build aborted: no such package 'tensorflow/tensorflow/go/genop/internal': BUILD file not found on package path\r\nINFO: Elapsed time: 9.534s\r\nFAILED: Build did NOT complete successfully (379 packages loaded)\r\nFAIL: bazel build --nobuild --config=hdfs --config=gcp -- //tensorflow/... -//tensorflow/contrib/lite/java/demo/app/... -//tensorflow/contrib/lite/examples/android/... -//tensorflow/contrib/lite/schema/...\r\n  This is due to invalid BUILD files. See lines above for details.\r\n", "@jart thanks! I will sure make all the tests pass and then ping again. \r\n\r\n@rmlarsen Just committed a fix for that. thanks!", "Run, Kokoro! Run like the wind!", "@akashgangil it looks like there are more failing tests: https://source.cloud.google.com/results/invocations/f94e43c4-ff09-4258-a1b3-1ad7923d805b/log", "@rmlarsen what does this mean?\r\n\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\n-----------------------------------------------------------------------------\r\ndyld: Library not loaded: @rpath/libtensorflow_framework.so\r\n  Referenced from: /Volumes/BuildData/tmpfs/bazel_output/_bazel_kbuilder/d1b2600cd78e76a92812a06683f5de10/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/go/darwin_amd64_stripped/go_default_test.runfiles/org_tensorflow/tensorflow/go/darwin_amd64_stripped/go_default_test\r\n  Reason: image not found\r\nAbort trap: 6\r\n```\r\n\r\nIs it that in some tests it tried to build libtensorflow_framework.so and failed? But I am wondering why could be breaking it on MacOS.", "nvm I think its just the tests targets I failing. I will look into that.", "@akashgangil yes, the go tests failed. Let me know when you have a fix.", "@akashgangil Do you have time to fix the one failing check?", "yea, will fix the remaining test.", "its still valid", "still valid", "still valid", "@jart, can you take a look and approve if all is good, or request changes as necessary?", "@akashgangil -- It looks like there are some build failures on MacOS:\r\n\r\n```\r\n//tensorflow/go:go_default_test                                          FAILED in 0.1s\r\n//tensorflow/go:test                                                     FAILED in 2.5s\r\n//tensorflow/go/op:go_default_test                                       FAILED in 0.1s\r\n```\r\n\r\nCan you take a look and fix?", "It has been 17 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@karmel can you please help retriggering the tests?", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes.", "May this pull request be reexamined? It seems Tensorflow is still not using rules_go."]}, {"number": 18099, "title": "Luong attention fails when used with scale=True and dtype=tf.float16", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: b'v1.6.0-rc1-1857-g67e2efa' 1.6.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: not relevant\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\ndtype = tf.float16\r\n\r\nwith tf.variable_scope(\"name\", dtype=dtype):\r\n    cell = tf.nn.rnn_cell.LSTMCell(128)\r\n\r\n    encoder_outputs = tf.placeholder(dtype, shape=[64, None, 256])\r\n    input_lengths = tf.placeholder(tf.int32, shape=[64])\r\n    tgt_lengths = tf.placeholder(tf.int32, shape=[64])\r\n    input_vectors = tf.placeholder(dtype, shape=[64, None, 128])\r\n\r\n    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\r\n        num_units=128,\r\n        memory=encoder_outputs,\r\n        scale=True,\r\n        memory_sequence_length=input_lengths,\r\n        probability_fn=tf.nn.softmax,\r\n        dtype=dtype,\r\n    )\r\n    attn_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention_mechanism)\r\n\r\n    helper = tf.contrib.seq2seq.TrainingHelper(\r\n        inputs=input_vectors,\r\n        sequence_length=tgt_lengths,\r\n    )\r\n\r\n    decoder = tf.contrib.seq2seq.BasicDecoder(\r\n        cell=attn_cell,\r\n        helper=helper,\r\n        initial_state=attn_cell.zero_state(64, dtype),\r\n    )\r\n\r\n    tf.contrib.seq2seq.dynamic_decode(decoder=decoder)\r\n```\r\n\r\n### Describe the problem\r\nLuong attention fails when using with scale=True and dtype=tf.float16. Changing lines 341-342 of attention_wrapper.py to:\r\n```\r\ng = variable_scope.get_variable(\r\n    \"attention_g\", dtype=dtype, shape=(),\r\n    initializer=init_ops.ones_initializer(),\r\n)\r\n```\r\nseems to solve the problem.\r\n\r\n### Source code / logs\r\nTraceback:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-4dec9cd8e3b2> in <module>()\r\n     31     )\r\n     32 \r\n---> 33     tf.contrib.seq2seq.dynamic_decode(decoder=decoder)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in dynamic_decode(decoder, output_time_major, impute_finished, maximum_iterations, parallel_iterations, swap_memory, scope)\r\n    307         ],\r\n    308         parallel_iterations=parallel_iterations,\r\n--> 309         swap_memory=swap_memory)\r\n    310 \r\n    311     final_outputs_ta = res[1]\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\r\n   3203     if loop_context.outer_context is None:\r\n   3204       ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\r\n-> 3205     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n   3206     if maximum_iterations is not None:\r\n   3207       return result[1]\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)\r\n   2941       with ops.get_default_graph()._lock:  # pylint: disable=protected-access\r\n   2942         original_body_result, exit_vars = self._BuildLoop(\r\n-> 2943             pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2944     finally:\r\n   2945       self.Exit()\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2878         flat_sequence=vars_for_body_with_tensor_arrays)\r\n   2879     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n-> 2880     body_result = body(*packed_vars_for_body)\r\n   2881     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n   2882     if not nest.is_sequence(body_result):\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py in body(time, outputs_ta, state, inputs, finished, sequence_lengths)\r\n    252       \"\"\"\r\n    253       (next_outputs, decoder_state, next_inputs,\r\n--> 254        decoder_finished) = decoder.step(time, inputs, state)\r\n    255       if decoder.tracks_own_finished:\r\n    256         next_finished = decoder_finished\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py in step(self, time, inputs, state, name)\r\n    135     \"\"\"\r\n    136     with ops.name_scope(name, \"BasicDecoderStep\", (time, inputs, state)):\r\n--> 137       cell_outputs, cell_state = self._cell(inputs, state)\r\n    138       if self._output_layer is not None:\r\n    139         cell_outputs = self._output_layer(cell_outputs)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    230         setattr(self, scope_attrname, scope)\r\n    231       with scope:\r\n--> 232         return super(RNNCell, self).__call__(inputs, state)\r\n    233 \r\n    234   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    712 \r\n    713         if not in_deferred_mode:\r\n--> 714           outputs = self.call(inputs, *args, **kwargs)\r\n    715           if outputs is None:\r\n    716             raise ValueError('A layer\\'s `call` method should return a Tensor '\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in call(self, inputs, state)\r\n   1409       attention, alignments, next_attention_state = _compute_attention(\r\n   1410           attention_mechanism, cell_output, previous_attention_state[i],\r\n-> 1411           self._attention_layers[i] if self._attention_layers else None)\r\n   1412       alignment_history = previous_alignment_history[i].write(\r\n   1413           state.time, alignments) if self._alignment_history else ()\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _compute_attention(attention_mechanism, cell_output, attention_state, attention_layer)\r\n   1046   \"\"\"Computes the attention and alignments for a given attention_mechanism.\"\"\"\r\n   1047   alignments, next_attention_state = attention_mechanism(\r\n-> 1048       cell_output, state=attention_state)\r\n   1049 \r\n   1050   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in __call__(self, query, state)\r\n    427     \"\"\"\r\n    428     with variable_scope.variable_scope(None, \"luong_attention\", [query]):\r\n--> 429       score = _luong_score(query, self._keys, self._scale)\r\n    430     alignments = self._probability_fn(score, state)\r\n    431     next_state = alignments\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py in _luong_score(query, keys, scale)\r\n    340     # Scalar used in weight scaling\r\n    341     g = variable_scope.get_variable(\r\n--> 342         \"attention_g\", dtype=dtype, initializer=1.)\r\n    343     score = g * score\r\n    344   return score\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n   1315       partitioner=partitioner, validate_shape=validate_shape,\r\n   1316       use_resource=use_resource, custom_getter=custom_getter,\r\n-> 1317       constraint=constraint)\r\n   1318 get_variable_or_local_docstring = (\r\n   1319     \"\"\"%s\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\r\n   1064         if init_dtype != dtype:\r\n   1065           raise ValueError(\"Initializer type '%s' and explicit dtype '%s' \"\r\n-> 1066                            \"don't match.\" % (init_dtype, dtype))\r\n   1067       if initializer is None:\r\n   1068         initializer = self._initializer\r\n\r\nValueError: Initializer type '<dtype: 'float32'>' and explicit dtype '<dtype: 'float16'>' don't match.\r\n```", "comments": ["It looks like the dtype=tf.float16 or dtype=tf.float64 was not test covered. Added a PR #18106 for the fix."]}, {"number": 18098, "title": "[tfgan] Add one sided wasserstein gradient penalty", "body": "This PR adds an optional argument to `tf.contrib.gan.losses.wasserstein_gradient_penalty` which allows for a one sided wasserstein gradient penalty.\r\n\r\nThe paper [On the regularization of Wasserstein GANs](https://arxiv.org/abs/1709.08894) presents theoretical arguments why using a weaker regularization term is preferable over the [two sided gradient penalty](https://arxiv.org/abs/1704.00028) and shows experimental results supporting these arguments.\r\n\r\nFor reference, [here is the code used in the paper](https://github.com/lukovnikov/improved_wgan_training/blob/master/gan_cifar.py#L144).\r\n\r\n/cc @joel-shor @sguada", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Great addition, @lgeiger ! I'm excited to polish this up and get it submitted.", "Thanks for the fast review. I addressed the comments, this is now ready for testing.", "@lgeiger Thanks for the contribution!"]}]