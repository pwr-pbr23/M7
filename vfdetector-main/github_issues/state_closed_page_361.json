[{"number": 43231, "title": "add suport for mips64 platform", "body": "Since tensorflow is not supported on MIPS64 platform\uff0c use this patch\uff0cit can be build pass on MIPS64 platform\u3002\r\nand then\uff0c tensorflow can be supported on MIPS64 platform\uff01", "comments": ["dear sir\uff0c\r\n Can this patch be merged\uff1f", "@zhangqiang-hf please edit your change according to the comments, then we can start merging."]}, {"number": 43230, "title": "Models loaded from files do not perform as before saving", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-45-generic x86_64)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version: 3.7.5 \r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version:  CUDA Version: 10.1 \r\n- GPU model and memory:   NVIDIA-SMI 430.50       Driver Version: 430.50      \r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI created a semi-supervised GAN model, based on: https://machinelearningmastery.com/semi-supervised-generative-adversarial-network/. It works with MNIST data.\r\nDuring the training the model reaches >90% accuracy, and gets saved in a file.\r\nHowever, when I try to load the saved model and run it on the same data, it performs at random (~10% accuracy).\r\nI tried both SavedModel and H5 formats, but I get the same results. \r\n\r\n**Describe the expected behavior**\r\nI would have expected the model loaded from the file to result in same performance as the model before saving.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nCollab notebook for training: https://colab.research.google.com/drive/1-FnGgEhCPwEjyQHiSWLuwTtqRVb-frpT?usp=sharing\r\nCollab notebook applying the model: https://colab.research.google.com/drive/1JDeMO1e3Z7RVbdW-QEC2V0yWbRtSz0jx?usp=sharing \r\n(Note: the code is meant to run on a machine, not in Collab)\r\n\r\n", "comments": ["@dmitra79 \r\nI ran the colab shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/e461d52e8e3a9eea05cc270b312ab2da/untitled413.ipynb).", "@Saduf2019 sorry, the code was run on my machine and I just copied it to Colab. The particular error is due to 'res/' directory not being in place. I've modified the notebooks to store in local folder directly. Btw, it should run faster with GPU.", "@dmitra79 \r\nI ran the code sheared in colab and did not face any errors, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/8276d5cfd33ae02b3adf9745632c13dc/untitled414.ipynb). \r\nIf this does not replicate your problem, please share a colab gist with issue reported.", "@Saduf2019, there is no error thrown. The problem is that saving/loading a model results in a very different accuracy.\r\nI updated the scenario so that a single notebook has training and loading/applying of the model: https://colab.research.google.com/drive/1-FnGgEhCPwEjyQHiSWLuwTtqRVb-frpT?usp=sharing\r\n\r\nSee the end of the output:\r\n```\r\n>2999, c[0.005,100], d[0.731,0.631], g[1.269]\r\n>3000, c[0.007,100], d[0.714,0.621], g[1.113]\r\nClassifier Accuracy: 93.730%\r\n>Saved: res/generated_plot_3000.png, res/g_model_3000.h5, res/c_model_3000.h5 and res/c_model_3000_sm\r\nFinal Accuracy: 93.730%\r\nWARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\r\nWARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\r\nFinal Accuracy: 9.687%\r\n```\r\n\r\nEdit: I reduced the number of epochs to 1, so it stops after 600 steps. The behavior is pretty much the same. I don't see what the warning re optimizer state has to do with applying a trained model.\r\n", "Hi, thanks for the report! This has been fixed in TF 2.4.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43230\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43230\">No</a>\n"]}, {"number": 43229, "title": "Confused which version TensorfFlow CPU supports", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Ubuntu 18.04/Linux Mint\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: v 1.x to  2.3.0\r\n- Python version: 3.6 to 3.8\r\n- Installed using virtualenv? pip? conda?: virtualenv, pip & conda\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CUDA/cuDNN version: N/a\r\n- GPU model and memory: N/a\r\n\r\n**Describe the problem**\r\n\r\nIn terms of the OS Platform, I have used 3 different OS such as Windows 10, Ubuntu 18.04 and Linux Mint.\r\n\r\nI am having a persistent problem in installing TensorFlow GPU before because the NVIDIA Driver cannot be installed/continued due to incompatible versions. Thus, I gave up on it, and now am only interested in installing TensorFlow CPU.\r\n\r\nI used to having problems when installing TensorFlow GPU when it always says 'DLL failed to load when ......' and 'Importerror no name image_preprocessing'.\r\n\r\n**My issue** is whatever I issue 'import tensorflow as tf' in Python 3.6 to Python 3.8 with TF 1.1+ to 2.3, respectively, the following message always appears (see logs).\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nPython = 3.6 to 3.8\r\nTensorflow = 1.1+ to 2.3.0\r\n\r\n**Any other info / logs**\r\n\r\n```\r\n(tensor0) root@opwrd:/home/user# python\r\nPython 3.8.5 (default, Sep  4 2020, 07:30:14) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nIllegal instruction (core dumped)\r\n```\r\n\r\n**Is there any simpler way of installing TensorFlow CPU without concerning about its version/getting errors?** I have been working on this for days.\r\n\r\nI seriously look forward to hearing from the TensorFlow team about this issue. I am needing to install TensorFlow to perform performance benchmarks on my object detection models, but this cannot be done without having TensorFlow in my machine.\r\n\r\nHighly appreciated your answers/advice.", "comments": ["@trystbinx \r\n\r\nPlease, follow the instructions as mentioned [here](https://www.tensorflow.org/install/gpu).\r\nPlease, see tested build configurations for [linux/mac](https://www.tensorflow.org/install/source#tested_build_configurations),[windows](https://www.tensorflow.org/install/source_windows#tested_build_configurations).\r\nPlease, see steps for installing through[ pip](https://www.tensorflow.org/install/pip),[hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\r\n\r\nIn case of windows please make sure  to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\nAlso, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows).\r\nPlease, check Your CPU/Python is on 32 bits?\r\nRegarding DLL errors please see similar issues.\r\n.Please, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n\r\nThanks!", " @ravikyram \r\n> \r\n> Please, follow the instructions as mentioned [here](https://www.tensorflow.org/install/gpu).\r\n> Please, see tested build configurations for [linux/mac](https://www.tensorflow.org/install/source#tested_build_configurations),[windows](https://www.tensorflow.org/install/source_windows#tested_build_configurations).\r\n> Please, see steps for installing through[ pip](https://www.tensorflow.org/install/pip),[hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\r\n> \r\n> In case of windows please make sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n> Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows).\r\n> Please, check Your CPU/Python is on 32 bits?\r\n> Regarding DLL errors please see similar issues.\r\n> .Please, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n> \r\n> Thanks!\r\n\r\n**Should I install GPU as instructed if I decide to only use the CPU for TensorFlow?** What I mean is that I dismiss the GPU installations. I have been dealing with this GPU issue since a week ago and still cannot be installed properly. I find it extremely difficult/complicated. Thus, my main focus is just to install TensorFlow CPU even it is much slower and better than keeping installing for hours/days.\r\n\r\nMy Python is between 3.6 to 3.8. For Python 3.6, my TF is 1.1x till 2.20 and for Python  3.7, my TF is 2.1+.0.\r\n\r\n```\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              2\r\nOn-line CPU(s) list: 0,1\r\n```\r\n\r\nActually I had been installing  a number of versions of NVIDIA drivers (like 30 GB). I kept having 'NVIDIA Driver cannot continue' even though I could install the CUDA toolkit and cudnn smoothly. Due to this reason, if I cannot keep up with the installation by today, I would have to drop my Tensorflow task as a part of my project.\r\n\r\nThank you.", "@trystbinx \r\n\r\nCan you install from source following this [guide](https://www.tensorflow.org/install/source).\r\n\r\n TensorFlow is only [tested and supported for 64-bit, x86 systems.](https://www.tensorflow.org/install).I don't believe you can install TensorFlow through pip or conda normally from a 32-bit system", "@ravikyram \r\n> \r\n> Can you install from source following this [guide](https://www.tensorflow.org/install/source).\r\n\r\nWell, I will do it now and see if I can do it properly.\r\n\r\n> TensorFlow is only [tested and supported for 64-bit, x86 systems.](https://www.tensorflow.org/install).I don't believe you can install TensorFlow through pip or conda normally from a 32-bit system\r\n\r\nThanks for the clarification. Yes, I installed everything in my virtualenv or through pip/conda. That's what I followed on YouTube.\r\n\r\nI have unsuccessfully installed TensorFlow GPU on Windows 10. Now, I have to use my Ubuntu with no nvidia yet. The end project would be to use Raspberry Pi to perform object detection. Installing TF is a headache for now because it is the base of my project development. I have to find which object detection models are the best to perform object detection on a very slow embedded device.\r\n\r\nI just confirmed somewhere that my CPU does not support AVX and that I am required to build from source.", "@trystbinx What is the output of `grep -o 'avx[^ ]*' /proc/cpuinfo` on your linux machine?", "@trystbinx What is your CPU? If your CPU does not support AVX then I would **not** recommend going for the **build from source** route. Better find a setup where AVX is available and everything would go much smoother (including the NVIDIA GPU drivers and CUDA installation). You can always install the latest NVIDIA drivers but make sure CUDA is 10.1, for TF 2.2, 2.3 and do not try to install other CUDA versions in parallel.\r\n\r\nRaspberry Pi has an ARM CPU, so AVX is not relevant there and setup is somewhat different, more likely going to need the TensorFlow Lite and convert the object detection model for it. If you need better performance than the CPU on a Raspberry Pi can provide, have a look at the Coral Edge TPU line-up. Either an USB Accelerator that plugs into the Raspberry Pi and supports the TF Lite models, or the whole dev board without the Raspberry board.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43229\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43229\">No</a>\n"]}, {"number": 43228, "title": "\"Function call stack: _dist_train_step\" error on tensorflow2 object detection api", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to StackOverflow.\r\n\r\nIf you are reporting a vulnerability, please use the dedicated reporting process.\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nEvery time I try to train the object detection models (any model, I tried ssd, faster rcnn, efficientdet..) by tf2 model train script (which is model_main_tf2.py), I got this error message every 1500~2000 steps.\r\n\r\nimage\r\n\r\nI ran the notebook in google colab, and I got the colab pro upgrade either. (I thought this issue might be the memory issue on GPU or TPU)\r\n\r\nI just followed the object detection api todo ..\r\nAnyone can help..?\r\nI also put a link to my colab notebook too.\r\n\r\nhttps://colab.research.google.com/drive/1Xg5NKpipLTUCCyTFDYYCC_xAkPRTUyCc?usp=sharing", "comments": ["@dingjiaweiww \r\nThis is a duplicate of #43227, please move this to close status.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43227, "title": "\"Function call stack: _dist_train_step\" error on tensorflow2 object detection api", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nEvery time I try to train the object detection models (any model, I tried ssd, faster rcnn, efficientdet..) by tf2 model train script (which is model_main_tf2.py), I got this error message every 1500~2000 steps.\r\n\r\n![image](https://user-images.githubusercontent.com/70259589/93154006-87b3e180-f73d-11ea-90c7-ddc11707d7f2.png)\r\n\r\nI ran the notebook in google colab, and I got the colab pro upgrade either. (I thought this issue might be the memory issue on GPU or TPU)\r\n\r\nI just followed the object detection api todo ..\r\nAnyone can help..?\r\nI also put a link to my colab notebook too. \r\n\r\nhttps://colab.research.google.com/drive/1Xg5NKpipLTUCCyTFDYYCC_xAkPRTUyCc?usp=sharing\r\n", "comments": ["@mobinity-yoom \r\nPlease close this ticket and open a new one at https://github.com/tensorflow/models/ directly.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "I also had same issue, This error occurs when VRAM on Colab become full thus program halts, So either reduce your input image size or reduce batch size. I used to resolve this issue by reducing batch size to 1 in config file, located at TensorFlow/workspace/training_demo/models/ YOUR-MODEL-NAME/pipeline.config", "> \r\n> \r\n> I also had same issue, This error occurs when VRAM on Colab become full thus program halts, So either reduce your input image size or reduce batch size. I used to resolve this issue by reducing batch size to 1 in config file, located at TensorFlow/workspace/training_demo/models/ YOUR-MODEL-NAME/pipeline.config\r\n\r\nI also have the same issue. I modified TensorFlow/workspace/training_demo/models/ YOUR-MODEL-NAME/pipeline.config to batch_size: 1 (on line 135). Im still getting this error. Please can anyone help\r\n\r\n```    _ensure_model_is_built(model, input_dataset, unpad_groundtruth_tensors)\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 169, in _ensure_model_is_built\r\n    strategy.run(\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1259, in run\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 2730, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\", line 628, in _call_for_each_replica\r\n    return mirrored_run.call_for_each_replica(\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_run.py\", line 75, in call_for_each_replica\r\n    return wrapped(args, kwargs)\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 888, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2942, in __call__\r\n    return graph_function._call_flat(\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\r\n    outputs = execute.execute(\r\n  File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n         [[node ssd_mobile_net_v2fpn_keras_feature_extractor/model/Conv1/Conv2D (defined at C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection\\models\\ssd_mobilenet_v2_fpn_keras_feature_extractor.py:219) ]] [Op:__inference__dummy_computation_fn_13690]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node ssd_mobile_net_v2fpn_keras_feature_extractor/model/Conv1/Conv2D:\r\n args_1 (defined at C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection\\model_lib_v2.py:169)\r\n\r\nFunction call stack:\r\n_dummy_computation_fn\r\n\r\n\r\n(tensorflow) C:\\TensorFlow\\workspace\\training_demo>```", "@Her0Mark I am getting the same error on google colab while I run tensorflow faster rcnn object detection api. I reduced batch size=1 but didn't passed through it. Have you solved your's?", "> > I also had same issue, This error occurs when VRAM on Colab become full thus program halts, So either reduce your input image size or reduce batch size. I used to resolve this issue by reducing batch size to 1 in config file, located at TensorFlow/workspace/training_demo/models/ YOUR-MODEL-NAME/pipeline.config\r\n> \r\n> I also have the same issue. I modified TensorFlow/workspace/training_demo/models/ YOUR-MODEL-NAME/pipeline.config to batch_size: 1 (on line 135). Im still getting this error. Please can anyone help\r\n> \r\n> ```\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 169, in _ensure_model_is_built\r\n>     strategy.run(\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1259, in run\r\n>     return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 2730, in call_for_each_replica\r\n>     return self._call_for_each_replica(fn, args, kwargs)\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\", line 628, in _call_for_each_replica\r\n>     return mirrored_run.call_for_each_replica(\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_run.py\", line 75, in call_for_each_replica\r\n>     return wrapped(args, kwargs)\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n>     result = self._call(*args, **kwds)\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 888, in _call\r\n>     return self._stateless_fn(*args, **kwds)\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2942, in __call__\r\n>     return graph_function._call_flat(\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\r\n>     return self._build_call_outputs(self._inference_function.call(\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\r\n>     outputs = execute.execute(\r\n>   File \"C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n> tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n>          [[node ssd_mobile_net_v2fpn_keras_feature_extractor/model/Conv1/Conv2D (defined at C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection\\models\\ssd_mobilenet_v2_fpn_keras_feature_extractor.py:219) ]] [Op:__inference__dummy_computation_fn_13690]\r\n> \r\n> Errors may have originated from an input operation.\r\n> Input Source operations connected to node ssd_mobile_net_v2fpn_keras_feature_extractor/model/Conv1/Conv2D:\r\n>  args_1 (defined at C:\\Users\\preto\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection\\model_lib_v2.py:169)\r\n> \r\n> Function call stack:\r\n> _dummy_computation_fn\r\n> \r\n> \r\n> (tensorflow) C:\\TensorFlow\\workspace\\training_demo>```\r\n> ```\r\n\r\nHi, did you manage to fix this? I'm having the same issue right now..", "\u0130 hade the same issue did you solv it?\r\n", "I have the same issue did you solv it ", "just replace the batch size =1 and make sure you're use CPU/GPU at `use_bfloat16 :`\r\n\r\n-"]}, {"number": 43226, "title": "DataFormatDimMap supports 5D tensors and grappler layout optimizer supports ReduceOps for 5D tensors", "body": "This PR does:\r\n(1) Allow DataFormatDimMap to support 5D dim tensors and map the dims to different combinations of NDHWC formats.\r\n(2) Enable the grappler layout optimizer to handle ReduceOps when tensors are in 5D. This feature relies on (1), since the inputs of the reduce ops commonly contain a \"reduce axis\" which is a vector of dims. This \"reduce axis\" needs to be updated to correct format using DataFormatDimMap.\r\n\r\ncc. @nluehr   ", "comments": ["The tests between tf2xla and TF are shared, and the new test cases added for DataFormatDimMap are failing for the tf2xla kernel https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/data_format_ops.cc. Can this kernel also be updated?", "> The tests between tf2xla and TF are shared, and the new test cases added for DataFormatDimMap are failing for the tf2xla kernel https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/data_format_ops.cc. Can this kernel also be updated?\r\n\r\nSure. Done. PTAL."]}, {"number": 43225, "title": "[INTEL MKL] MKL DNN 0.x code cleanup - Transpose Op", "body": "DNN 0.x cleanup of MKL Transpose Op:\r\n\r\n(1) Remove all DNN 0.x related code\r\n(2) Replace all DNN 1.x macro usages", "comments": []}, {"number": 43224, "title": "keras layers API documentation not sorted properly", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers\r\n\r\n## Description of issue (what needs changing):\r\n\r\nVery minor issue, but the overview list of all layer classes is not consistently sorted alphabetically, though it very much feels like it is intended to (e.g. the GRU layer is listed above the GaussianDropout layer). In the sidebar it is sorted correctly alphabetically. I personally nearly overlooked the presence of the GRU layer because they are differently sorted in the sidebar and overview.\r\n\r\nUnfortunately could I not find the API documentation in the tensorflow/docs repository, which is why I am opening the issue instead of offering a pull request. If you point me to the API documentation source can I gladly take care of that.", "comments": ["I think that the error is in the gen/sorting graph logic at https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/api_generator/generate_lib.py. \r\n\r\nE.g. `GaussiaDropout` is at `n` as it is in `noise.py` https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/noise.py\r\n\r\n/cc @yashk2810\r\n\r\n", "I think this is the offending line: https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/api_generator/generate_lib.py#L170\r\n\r\nTechnically, `GRU` should come before `GausionDropout` according to python's sorting rules.\r\n\r\n```\r\nIn [1]: l = ['GRU', 'GaussianDropout', 'GRU']\r\n\r\nIn [2]: sorted(l)\r\nOut[2]: ['GRU', 'GRU', 'GaussianDropout']\r\n```\r\n\r\nLet me know if you need any help in fixing this :)", "@yashk2810 I think that your example is not the same:\r\n```python\r\nl = ['GRU', 'GaussianDropout', 'GRU']\r\nl_sorted = sorted(l, key=lambda x: (x.upper(), x))\r\nprint(l_sorted)\r\n```\r\n\r\n```shell\r\n['GaussianDropout', 'GRU', 'GRU']\r\n```", "Right, that's what I am saying. The TOC sorting is wrong because of the .upper(). If that's removed the TOC sorting should match the sorting on the Classes section of this page: https://www.tensorflow.org/api_docs/python/tf/keras/layers", "Ok so do you prefer `lower` for all?", "Thank you very much for fixing this so quickly and providing a pull request. Especially to you @bhack as you were also addressing the random NaN issue I was opening 2 days ago and to which you already proposed a solution that I still need to process.\r\n\r\nAs this issue therefore seems addressed will I close it in order not to take time away from any other TF contributor. Thanks!"]}, {"number": 43223, "title": "OP_REQUIRES failed : Not found: No algorithm worked!", "body": "**System information**\r\n- OS Platform and Distribution:  Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (pip install)\r\n- TensorFlow version (use command below): v1.12.1-41444-g9396e98574 2.4.0-dev20200913\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0 and 8.0\r\n- GPU model and memory: GTX 2060\r\n\r\n**Describe the current behavior**\r\nThe script crashes at prediction.\r\n\r\n**Describe the expected behavior**\r\nThe script shall compute prediction\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.keras.layers import Dense, Dropout\r\nfrom tensorflow.keras.applications import ResNet50\r\nfrom tensorflow.keras.models import Sequential\r\nimport numpy as np\r\n\r\nmodel = Sequential([\r\n    ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3), pooling=\"avg\"),\r\n    Dropout(0.5),\r\n    Dense(64, activation='relu'),\r\n])\r\n\r\nX = np.zeros((1, 224, 224, 3))\r\nprint(model.predict(X))\r\n```\r\n\r\nNote that if adding the line `tf.config.set_visible_devices([], 'GPU')`, this problem disappear\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n2020-09-14 21:29:32.163353: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\n2020-09-14 21:29:32.931061: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-09-14 21:29:32.931534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-09-14 21:29:32.953860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:32.954284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-09-14 21:29:32.954301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\n2020-09-14 21:29:32.956135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-09-14 21:29:32.957003: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-09-14 21:29:32.957172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-09-14 21:29:32.959170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-09-14 21:29:32.959632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\r\n2020-09-14 21:29:32.959728: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-09-14 21:29:32.959814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:32.960277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:32.960669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-09-14 21:29:32.960919: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-09-14 21:29:32.961335: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-09-14 21:29:32.961418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:32.961827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-09-14 21:29:32.961841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\n2020-09-14 21:29:32.961854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-09-14 21:29:32.961864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-09-14 21:29:32.961873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-09-14 21:29:32.961882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-09-14 21:29:32.961892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\r\n2020-09-14 21:29:32.961900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-09-14 21:29:32.961949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:32.962375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:32.962759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-09-14 21:29:32.962779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\n2020-09-14 21:29:33.321292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-14 21:29:33.321321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-09-14 21:29:33.321325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-09-14 21:29:33.321485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:33.321815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:33.322113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-14 21:29:33.322399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5352 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:09:00.0, compute capability: 7.5)\r\n2020-09-14 21:29:34.367791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 1)\r\n2020-09-14 21:29:34.384838: I tensorflow/core/platform/profile_utils/cpu_utils.cc:108] CPU Frequency: 3593095000 Hz\r\n2020-09-14 21:29:34.803301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-09-14 21:29:35.075322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-09-14 21:29:35.505290: W tensorflow/core/framework/op_kernel.cc:1774] OP_REQUIRES failed at conv_ops.cc:1114 : Not found: No algorithm worked!\r\nTraceback (most recent call last):\r\n  File \"report_bug.py\", line 13, in <module>\r\n    print(model.predict(X))\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 102, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1584, in predict\r\n    tmp_batch_outputs = self.predict_function(iterator)\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 787, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 853, in _call\r\n    return self._concrete_stateful_fn._call_flat(\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 556, in call\r\n    outputs = execute.execute(\r\n  File \"/opt/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.NotFoundError:  No algorithm worked!\r\n         [[node sequential/resnet50/conv1_conv/Conv2D (defined at report_bug.py:13) ]] [Op:__inference_predict_function_6649]\r\n\r\nFunction call stack:\r\npredict_function\r\n```\r\n", "comments": ["What is the output of:\r\n```\r\nimport tensorflow as tf\r\nprint(tf.config.list_physical_devices())\r\n```", "@Ambistic \r\n\r\nI have tried in colab with TF nightly version and i am not seeing any issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/3f34c393bb1371f297bcc9cea6f0ca4f/untitled351.ipynb).\r\n\r\nIt looks like cuda problem.Can you try with tested build configurations from [here](https://www.tensorflow.org/install/source#gpu) and see if the problem still persists. Thanks!", "@ravikyram  You cannot test tf-nightly with GPU only ISSUES on colab currently cause It has only CPU visibile devices.", "@ravikyram check https://github.com/tensorflow/tensorflow/issues/42957", "> What is the output of:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> print(tf.config.list_physical_devices())\r\n> ```\r\n\r\nThe output is :\r\n```\r\n2020-09-15 11:52:23.068529: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-09-15 11:52:23.069203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-09-15 11:52:23.094984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-15 11:52:23.095310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-09-15 11:52:23.095332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\n2020-09-15 11:52:23.097519: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-09-15 11:52:23.098514: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-09-15 11:52:23.098681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-09-15 11:52:23.100594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-09-15 11:52:23.101058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\r\n2020-09-15 11:52:23.101151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-09-15 11:52:23.101234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-15 11:52:23.101552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-15 11:52:23.101800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n```\r\n\r\n@ravikyram I actually need features from tensorflow 2.3.0 and I couldn't find it in the tested build configurations", "Can you print `tf.config.get_visible_devices()`?", "> Can you print `tf.config.get_visible_devices()`?\r\n\r\n`[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]`\r\n\r\nJust as previous output", "And do you still require `tf.config.set_visible_devices([], 'GPU')`?\r\nHave you tried with the last `tf-nightly`?", "Yes I still require that line and it's the same with `tf-nightly-2.4.0.dev20200915`\r\n\r\nInterestingly, this error appear when creating a model with a submodel from tensorflow.keras.applications and a layers (such as Dense), but the problem dissappear if using only the application or only the keras layers. \r\nIt's also working if using a model from applications and only Dropout, not Dense", "So the problem is only on GPU. \r\nI need to wait for https://github.com/googlecolab/colabtools/issues/1574 to check if it is reproducible on tf-nightly.", "Have you tried setting set_memory_growth to True?", "Actually it seems to work, thank you very much !", "This is the code to add\r\n```python\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntry:\r\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\nexcept:\r\n    pass\r\n```", "if that is not the case probably we have to restart the environment to make things working!", "@Ambistic \r\n\r\nPlease, close this thread if your issue was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43223\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43223\">No</a>\n", "I add that using `Model()` instead of `Sequential()` seems also to correct the problem", "Same issue using r2.4 sources on arch.", "same issue when using TF2.4.1 on RTX3060, compiled by myself, weird", "> same issue when using TF2.4.1 on RTX3060, compiled by myself, weird\r\n\r\nDid u find the solution?"]}, {"number": 43222, "title": "Fix the compilation problem of S3 test cases", "body": "", "comments": []}, {"number": 43221, "title": "Fix the compilation problem of HDFS test cases", "body": "", "comments": []}, {"number": 43220, "title": "Add test ReadWhileOverwriting", "body": "This is a PR from TaiJi AI platform in Tencent.\r\n\r\n- The file copied by TF from HDFS to local may be wrong, when HDFS file is being overwritten [#42597](https://github.com/tensorflow/tensorflow/issues/42597)", "comments": ["@vnvo2409 @mihaimaruseac \r\nadd the `ReadWhileOverwriting` test case. "]}, {"number": 43219, "title": "LR Custom Scheduler not working TF 2.3", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04.5 LTS\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GTX 1050 \r\n\r\nRest of the information attached \r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/5220028/tf_env.txt)\r\n\r\n\r\n**Describe the current behavior**\r\nReturns an error when using the fit function. see the log below.\r\n\r\n**Describe the expected behavior**\r\nDecays the lr during training. works by just passing schdule object to optimizer lr argument.\r\n\r\n![lr_schedule](https://user-images.githubusercontent.com/17620536/92232869-b671c280-eec8-11ea-9f20-9c274cadcddc.png)\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n  def __init__(self, warmup_steps=1e4):\r\n    super().__init__()\r\n\r\n    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\r\n    \r\n  def __call__(self, step):\r\n    step = tf.cast(step, tf.float32)\r\n    m = tf.maximum(self.warmup_steps, step)\r\n    m = tf.cast(m, tf.float32)\r\n    lr = tf.math.rsqrt(m)\r\n    \r\n    return lr\r\n\r\n```\r\n```\r\nlearning_rate_fn = CustomSchedule()\r\noptimizer = tf.keras.optimizer.Adam(learning_rate_fn)\r\n\r\nmodel.compile(optimizer=optimizer, ...)\r\nmodel.fit(dataset, epochs=1)\r\n```\r\n### Traceback\r\n**TypeError: To be compatible with tf.eager.defun, Python functions must return zero or more Tensors; in compilation of <function Model.make_train_function.<locals>.train_function at 0x7fdf2c2b9c80>, found return value of type <class '__main__.CustomSchedule'>, which is not a Tensor.**\r\n\r\n\r\n```\r\nEpoch 1/50\r\n/home/ml/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\r\n    547     try:\r\n--> 548       str_values = [compat.as_bytes(x) for x in proto_values]\r\n    549     except TypeError:\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py in <listcomp>(.0)\r\n    547     try:\r\n--> 548       str_values = [compat.as_bytes(x) for x in proto_values]\r\n    549     except TypeError:\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/util/compat.py in as_bytes(bytes_or_text, encoding)\r\n     86     raise TypeError('Expected binary or unicode string, got %r' %\r\n---> 87                     (bytes_or_text,))\r\n     88 \r\n\r\nTypeError: Expected binary or unicode string, got <__main__.CustomSchedule object at 0x7f02bc039a20>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in convert(x)\r\n    941         try:\r\n--> 942           x = ops.convert_to_tensor_or_composite(x)\r\n    943         except (ValueError, TypeError):\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_or_composite(value, dtype, name)\r\n   1621   return internal_convert_to_tensor_or_composite(\r\n-> 1622       value=value, dtype=dtype, name=name, as_ref=False)\r\n   1623 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor_or_composite(value, dtype, name, as_ref)\r\n   1660         as_ref=as_ref,\r\n-> 1661         accepted_result_types=(Tensor, composite_tensor.CompositeTensor))\r\n   1662 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1498     if ret is None:\r\n-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1500 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    337   _ = as_ref\r\n--> 338   return constant(v, dtype=dtype, name=name)\r\n    339 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 264                         allow_broadcast=True)\r\n    265 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    281           value, dtype=dtype, shape=shape, verify_shape=verify_shape,\r\n--> 282           allow_broadcast=allow_broadcast))\r\n    283   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\r\n    551                       \"Contents: %s. Consider casting elements to a \"\r\n--> 552                       \"supported type.\" % (type(values), values))\r\n    553     tensor_proto.string_val.extend(str_values)\r\n\r\nTypeError: Failed to convert object of type <class '__main__.CustomSchedule'> to Tensor. Contents: <__main__.CustomSchedule object at 0x7f02bc039a20>. Consider casting elements to a supported type.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-22-8c9c3cff7892> in <module>\r\n      1 epochs_done = 0\r\n      2 model.fit(train_dataset, epochs=50, callbacks=callbacks, \r\n----> 3           validation_data=validation_dataset, initial_epoch=epochs_done)\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    695     self._concrete_stateful_fn = (\r\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 697             *args, **kwds))\r\n    698 \r\n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3073             arg_names=arg_names,\r\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3075             capture_by_value=self._capture_by_value),\r\n   3076         self._function_attributes,\r\n   3077         function_spec=self.function_spec,\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    989       # TensorArrays and `None`s.\r\n    990       func_outputs = nest.map_structure(convert, func_outputs,\r\n--> 991                                         expand_composites=True)\r\n    992 \r\n    993       check_mutation(func_args_before, func_args, original_func)\r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\n~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in convert(x)\r\n    946               \"must return zero or more Tensors; in compilation of %s, found \"\r\n    947               \"return value of type %s, which is not a Tensor.\" %\r\n--> 948               (str(python_func), type(x)))\r\n    949       if add_control_dependencies:\r\n    950         x = deps_ctx.mark_as_return(x)\r\n\r\nTypeError: To be compatible with tf.eager.defun, Python functions must return zero or more Tensors; in compilation of <function Model.make_train_function.<locals>.train_function at 0x7f02601460d0>, found return value of type <class '__main__.CustomSchedule'>, which is not a Tensor.\r\n\r\n```", "comments": ["Can you share a very minimal but complete runnable example or colab?", "@HarrisDePerceptron \r\nOr if possible share a colab gist with issue reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43219\">No</a>\n"]}, {"number": 43218, "title": "Update README.md", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43218) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43218) for more info**.\n\n<!-- ok -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43218) for more info**.\r\n\r\n@googlebot I signed it!", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac "]}, {"number": 43217, "title": "[Grappler] Fold broadcast select", "body": "This PR applies constant folding on select when predicate is all ones or all zeros and inputs are broadcastable.", "comments": []}, {"number": 43216, "title": "[Intel MKL] Adding support for convolution fusions with native format", "body": "", "comments": ["Thank you for reviewing the PR. I have addressed your comments."]}, {"number": 43215, "title": "[Intel MKL] Enable Conv3D and Depthwise Conv in eager mode", "body": "This PR depends on #43213 ", "comments": []}, {"number": 43214, "title": "[XLA] Fix a test on Maxwell GPUs.", "body": "This behavior is triggered by the following lines: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc#L3732-L3739", "comments": []}, {"number": 43213, "title": "[Intel MKL] Adding support for Conv3D and Depthwise Conv with native format", "body": "", "comments": ["Thank you for reviewing the PR. I have replied to your comments."]}, {"number": 43212, "title": "tensorflow model to MLIR", "body": "I want convert tensorflow model to MLIR .\r\n\r\nI saved tensorflow model using model.save() as saved_model.pb.\r\n\r\n\r\nHow can lower the convert model to MLIR (affine/std dialect)?\r\nWhat are the steps to do so?\r\n\r\nThank You", "comments": ["I suggest to post your question in https://groups.google.com/a/tensorflow.org/g/mlir", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43211, "title": "Converter Error : for converting saved-model to tflite ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version (or github SHA if from source): 2.3.0 , also installed tf-nightly\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Copy and paste here the exact command\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = 'C:\\\\Users\\\\diksh\\\\Desktop\\\\Fine_Tuned_Model\\\\saved_model'\r\n\r\n\r\nmodel = tf.saved_model.load(saved_model_dir)\r\nmodel.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[0].set_shape([1, 256, 256, 3])\r\ntf.saved_model.save(model, \"saved_model_updated\", signatures=model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY])\r\n# Convert\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_updated', signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\n## TFLite Interpreter to check input shape\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test the model on random input data.\r\ninput_shape = input_details[0]['shape']\r\nprint(input_shape)\r\n\r\n**The output from the converter invocation**\r\nException                                 Traceback (most recent call last)\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    198                                                  debug_info_str,\r\n--> 199                                                  enable_mlir_converter)\r\n    200       return model_str\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n     37       debug_info_str,\r\n---> 38       enable_mlir_converter)\r\n     39 \r\n\r\nException: <unknown>:0: error: loc(\"Func/StatefulPartitionedCall/input/_0\"): requires all operands and results to have compatible element types\r\n<unknown>:0: note: loc(\"Func/StatefulPartitionedCall/input/_0\"): see current operation: %1 = \"tf.Identity\"(%arg0) {_class = [\"loc:@Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_702\"], device = \"\"} : (tensor<1x256x256x3x!tf.quint8>) -> tensor<1x256x256x3xui8>\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-4-b50eec57af9d> in <module>\r\n     11 converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n     12 converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n---> 13 tflite_model = converter.convert()\r\n     14 \r\n     15 ## TFLite Interpreter to check input shape\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n   1074         Invalid quantization parameters.\r\n   1075     \"\"\"\r\n-> 1076     return super(TFLiteConverterV2, self).convert()\r\n   1077 \r\n   1078 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    898 \r\n    899     return super(TFLiteFrozenGraphConverterV2,\r\n--> 900                  self).convert(graph_def, input_tensors, output_tensors)\r\n    901 \r\n    902 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self, graph_def, input_tensors, output_tensors)\r\n    631         input_tensors=input_tensors,\r\n    632         output_tensors=output_tensors,\r\n--> 633         **converter_kwargs)\r\n    634 \r\n    635     calibrate_and_quantize, flags = quant_mode.quantizer_flags(\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    572       input_data.SerializeToString(),\r\n    573       debug_info_str=debug_info_str,\r\n--> 574       enable_mlir_converter=enable_mlir_converter)\r\n    575   return data\r\n    576 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    200       return model_str\r\n    201     except Exception as e:\r\n--> 202       raise ConverterError(str(e))\r\n    203 \r\n    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: <unknown>:0: error: loc(\"Func/StatefulPartitionedCall/input/_0\"): requires all operands and results to have compatible element types\r\n<unknown>:0: note: loc(\"Func/StatefulPartitionedCall/input/_0\"): see current operation: %1 = \"tf.Identity\"(%arg0) {_class = [\"loc:@Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_702\"], device = \"\"} : (tensor<1x256x256x3x!tf.quint8>) -> tensor<1x256x256x3xui8>\r\n\r\n```\r\n# Copy and paste the output here.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please could you share a very, very minimal but complete standalone or colab example that we could copy, past and run to reproduce your issue?", "Here is the link with the jupyter notebooks and saved model data\r\nhttps://drive.google.com/drive/folders/1MCvDti2ygukqw6fGE18WpnFOSzR_AanF?usp=sharing\r\nIm working on a team where i have been requested to convert the saved_model to a tflite.\r\nThe \"FLIR_retraining.ipynb\" is the file to retrain the model.\r\nand the \"TFLite_converter.ipynb\" is a shorter version that I have been trying to use for the conversion.\r\n\r\nThank you.", "@dikshantjn,\r\nI was able to reproduce the error with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/ced1f50c56218d3da7c401a91bb5acbc/43211.ipynb).\r\n\r\nHowever, with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/3c9f9d7540e521fa298398a6e5538bee/43211-tf-nightly.ipynb) I was able to run the code without any issues. Please find the attached gist. Thanks! ", "I'm still getting the same error:\r\n\"<unknown>:0: error: loc(\"Func/StatefulPartitionedCall/input/_0\"): requires all operands and results to have compatible element types\r\n<unknown>:0: note: loc(\"Func/StatefulPartitionedCall/input/_0\"): see current operation: %1 = \"tf.Identity\"(%arg0) {_class = [\"loc:@Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_702\"], device = \"\"} : (tensor<1x256x256x3x!tf.quint8>) -> tensor<1x256x256x3xui8>\"", "@amahendrakar \r\nThank you .... I was able to convert the model to tflite in colab, previously I was trying it on my windows PC\r\nI am now trying to save it on my drive using :\r\ntflite_file = 'Fine_Tuned_Model/head_detector.tflite'\r\nopen(tflite_file, \"wb\").write(tflite_model)\r\n\r\nBut it is not generating any files\r\nPlease help", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43211\">No</a>\n", "@amahendrakar here is the colab\r\nhttps://colab.research.google.com/drive/1_9l_DcyNuVV1NxU3PsmSMjWeI9nTEwNS?usp=sharing", "@amahendrakar .... with the latest version of tf-nightly, the  order of output tensors changes. If you could help me understand that and what is the meaning of each of them", "@dikshantjn,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "> @amahendrakar .... with the latest version of tf-nightly, the order of output tensors changes. If you could help me understand that and what is the meaning of each of them\r\n\r\n\r\nI faced this issue too. Had to debug the shape of each output to get it to work. \r\n\r\nRegardless, it worked. Not with the current tf-nightly build but with the one used in the gist posted by @amahendrakar [in this link](https://colab.research.google.com/gist/amahendrakar/3c9f9d7540e521fa298398a6e5538bee/43211-tf-nightly.ipynb)\r\n\r\ni.e. instead of !pip install tf-nightly, i used !pip install tf-nightly==2.4.0.dev20200914"]}, {"number": 43210, "title": "clone_model doesn't work properly. Dimensions of inputs should match.", "body": "**System information**\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.1\r\n- Python version: 3.7:\r\n- GCC/Compiler version (if compiling from source):\r\n- GPU model and memory: tesla v100\r\n\r\n**Describe the current behavior**\r\nI am training my custom models and I have used the following code to clone and train a model for domain adaptation tasks. Suddenly this stopped working. I am training on a cluster and using this line of code for 4 months without a problem. \r\n\r\n```\r\nmodel.fit(train_dataset)\r\nmodel_target = tf.keras.models.clone_model(model)\r\nmodel_target.set_weights(model.get_weights())\r\n\r\nfor layer in model_target.layers:\r\n        layer._name = layer.name + str(\"_target\")\r\n\r\nmodel_target.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\r\n                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                      metrics=[\"accuracy\"])\r\n\r\nmodel_target.fit(train_dataset)\r\n```\r\nIt produces the error :\r\n\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-46-095ac6db4568> in <module>\r\n     15                       metrics=[\"accuracy\"])\r\n     16 print(\"second\")\r\n---> 17 model_target.fit(train_dataset)\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\r\n   1377             with trace.Trace('TraceContext', graph_type='test', step_num=step):\r\n   1378               callbacks.on_test_batch_begin(step)\r\n-> 1379               tmp_logs = test_function(iterator)\r\n   1380               if data_handler.should_sync:\r\n   1381                 context.async_wait()\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    838         # Lifting succeeded, so variables are initialized and we can run the\r\n    839         # stateless function.\r\n--> 840         return self._stateless_fn(*args, **kwds)\r\n    841     else:\r\n    842       canon_args, canon_kwds = \\\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2827     with self._lock:\r\n   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2830 \r\n   2831   @property\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)\r\n   1846                            resource_variable_ops.BaseResourceVariable))],\r\n   1847         captured_inputs=self.captured_inputs,\r\n-> 1848         cancellation_manager=cancellation_manager)\r\n   1849 \r\n   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1922       # No tape is watching; skip to running the function.\r\n   1923       return self._build_call_outputs(self._inference_function.call(\r\n-> 1924           ctx, args, cancellation_manager=cancellation_manager))\r\n   1925     forward_backward = self._select_forward_and_backward_functions(\r\n   1926         args,\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    548               inputs=args,\r\n    549               attrs=attrs,\r\n--> 550               ctx=ctx)\r\n    551         else:\r\n    552           outputs = execute.execute_with_cancellation(\r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nInvalidArgumentError:  ConcatOp : Dimensions of inputs should match: shape[0] = [5,16384] vs. shape[1] = [20,8192]\r\n\t [[node functional_1/features_target/concat (defined at <ipython-input-46-095ac6db4568>:17) ]] [Op:__inference_test_function_125643]\r\n\r\nFunction call stack:\r\ntest_function\r\n```\r\n\r\nthe main model trains without any problem on the same dataset, so the dataset can not be the problem. \r\nI am making the main model using the following code:\r\n\r\n\r\n```\r\ninput_range = Input(input_shape_range, name=\"input_range\")\r\n    input_doppler = Input(input_shape_doppler, name=\"input_doppler\")\r\n\r\n    r = Conv2D(filters=8, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c1_r\",\r\n               data_format=\"channels_first\")(input_range)\r\n    r = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c2_r\",\r\n               data_format=\"channels_first\")(r)\r\n    r = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"Valid\", name=\"m1_r\",\r\n                  data_format=\"channels_first\")(r)\r\n    r = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c3_r\",\r\n               data_format=\"channels_first\")(r)\r\n    r = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c4_r\",\r\n               data_format=\"channels_first\")(r)\r\n    r = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"Valid\", name=\"m2_r\",\r\n                  data_format=\"channels_first\")(r)\r\n\r\n    features_range = Flatten(name=\"flatten_r\")(r)\r\n\r\n    d = Conv2D(filters=8, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c1_d\",\r\n               data_format=\"channels_first\")(input_doppler)\r\n    d = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c2_d\",\r\n               data_format=\"channels_first\")(d)\r\n    d = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"Valid\", name=\"m1_d\",\r\n                  data_format=\"channels_first\")(d)\r\n    d = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c3_d\",\r\n               data_format=\"channels_first\")(d)\r\n    d = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", name=\"c4_d\",\r\n               data_format=\"channels_first\")(d)\r\n    d = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"Valid\", name=\"m2_d\",\r\n                  data_format=\"channels_first\")(d)\r\n    features_doppler = Flatten(name=\"flatten_d\")(d)\r\n\r\n    features = tf.keras.layers.concatenate([features_range, features_doppler], name=\"features\" ,axis=1)\r\n\r\n    fc_1 = Dense(256, activation=\"relu\", use_bias=True, name=\"fc_1\",\r\n                 kernel_regularizer= tf.keras.regularizers.l2(0.01))(features)\r\n    drop_1 = Dropout(0.2)(fc_1)\r\n    fc_2 = Dense(128, activation=\"relu\", use_bias=True, name=\"fc_2\",\r\n                 kernel_regularizer= tf.keras.regularizers.l2(0.01))(features)\r\n    drop_2 = Dropout(0.2)(fc_2)\r\n    fc_3 = Dense(64, activation=\"relu\", use_bias=True, name=\"fc_3\",\r\n                 kernel_regularizer= tf.keras.regularizers.l2(0.01))(drop_2)\r\n    drop_3 = Dropout(0.2)(fc_3)\r\n    out = Dense(5, use_bias=True, name=\"out\")(drop_3)\r\n\r\n    model = tf.keras.Model(inputs=[input_range, input_doppler], outputs=out)\r\n```", "comments": ["Please could you share a very, very minimal but complete standalone or colab example that we could copy, past and run to reproduce your issue?", "Sorry but I don't know any dataset, which needs 2 inputs. And apparently the Concatenation is causing the problem. ", "But I just found out that this is causing the Problem\r\n```\r\nfor layer in model_source.layers:\r\n        layer._name = layer.name + str(\"_source\")\r\n```\r\nactually changing the name of Inputs causing the error. \r\nany idea how to solve this?", "I don't think It Is a bug. For support request on your model use [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow)", "@hamidkhb \r\nPlease feel free to move the issue to closed status as it will be taken care at stack-overflow.", "Well I tried the code in different ways and even made the network again and it all works. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43210\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43210\">No</a>\n"]}, {"number": 43209, "title": "Expose modular file system header in pip install package", "body": "This PR tries to expose modular file system header in pip install package\r\nso that downstream packages could use the header files with pip install\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 43208, "title": "Question about TFLite GPU delegate", "body": "I was trying to build TFLite GPU delegate on ARM device such as Raspberry pi 4.\r\nAfter reading the guide document, I found that GPU delegate only uses Bazel build system and it only supports Android and iOS.\r\n\r\nMy question is that:\r\n1) Is there any plan to support Makefile or CMake to build TFLite GPU delegate?\r\n\r\n2) If I'd like to use TFLite GPU delegate on other Linux dist such as Ubuntu ARM, can I do that? If possible, how?\r\n\r\n3) Is there any roadmap or plan when Raspberry pi 4 GPU will be a supported TFLite GPU delegate?\r\n\r\n\r\nThank you in advance.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux dist instead of Android.\r\n- Mobile device: Raspberry pi 4 or other ARM device.\r\n- TensorFlow build from source\r\n- TensorFlow version: latest \r\n", "comments": ["There was some activity in https://github.com/tensorflow/tensorflow/pull/38806 for Linux and for Cmake https://github.com/tensorflow/tensorflow/pull/36180\r\nFor raspberry 4 the last update was https://github.com/tensorflow/tensorflow/issues/27320#issuecomment-657820659. You can ask there if there is a new update.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43208\">No</a>\n"]}, {"number": 43207, "title": "RuntimeError: Quantization not yet supported for op: %", "body": "**System information**\r\n- OS Platform and Distribution (Linux Ubuntu 18.04):\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): TF 2.3.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n```\r\ndef representative_data_gen():\r\n    dataset_list = os.listdir(data_dir)\r\n    num_calibration_images = 100\r\n    norm_factor = 255.0\r\n    for i in range(num_calibration_images):\r\n        image_name = next(iter(dataset_list))\r\n \r\n        image = cv2.imread(os.path.join(data_dir, image_name), 1)\r\n        image = image.astype(np.float32)\r\n        image = image/norm_factor\r\n\r\n        image = tf.expand_dims(image, 0)\r\n        yield [image]\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.target_spec.supported_types = [tf.int8]\r\n\r\n# These set the input and output tensors to uint8 (added in r2.3)\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\nconverter.allow_custom_ops = True\r\ntflite_model = converter.convert()\r\n```\r\n\r\n** Model definition:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ndef conv2d_block_3layers(input_tensor, n_filters, kernel_size=3, dropout=0.2, \r\n                         batchnorm=True, activation=True):\r\n    # first layer\r\n    x = layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\r\n                      padding = 'same')(input_tensor)\r\n    if batchnorm:\r\n        x = layers.BatchNormalization()(x)\r\n    if activation:\r\n        x = layers.Activation('relu')(x)\r\n    x = layers.Dropout(dropout)(x)\r\n    # second layer\r\n    x = layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\r\n                      padding = 'same')(x)\r\n    if batchnorm:\r\n        x = layers.BatchNormalization()(x)\r\n    if activation:\r\n        x = layers.Activation('relu')(x)\r\n    x = layers.Dropout(dropout)(x)\r\n    # third layer\r\n    x = layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\r\n                      padding = 'same')(x)\r\n    if batchnorm:\r\n        x = layers.BatchNormalization()(x)\r\n    if activation:\r\n        x = layers.Activation('relu')(x)\r\n    return x\r\n\r\ndef UNET_v2(nClasses=25, input_height=288, input_width=224, n_filters=64, dropout=0.2, \r\n            batchnorm=True, activation=True):\r\n  \r\n    img_input = layers.Input(shape=(input_height, input_width, 3))  \r\n\r\n    c1 = conv2d_block_3layers(img_input, n_filters * 1, kernel_size=3, batchnorm = batchnorm, activation=activation)\r\n    p1 = layers.MaxPooling2D((2, 2))(c1) \r\n\r\n    c2 = conv2d_block_3layers(p1, n_filters * 2, kernel_size=3, batchnorm = batchnorm,  activation=activation)\r\n    p2 = layers.MaxPooling2D((2, 2))(c2) \r\n\r\n    c3 = conv2d_block_3layers(p2, n_filters * 4, kernel_size=3, batchnorm = batchnorm,  activation=activation)\r\n    p3 = layers.MaxPooling2D((2, 2))(c3) \r\n\r\n    c4 = conv2d_block_3layers(p3, n_filters * 4, kernel_size=3, batchnorm = batchnorm,  activation=activation)\r\n    p4 = layers.MaxPooling2D((2, 2))(c4) \r\n\r\n    c5 = conv2d_block_3layers(p4, n_filters = n_filters * 8, kernel_size=3, batchnorm = batchnorm, activation=activation)\r\n    p5 = layers.Dropout(dropout)(c5) \r\n\r\n    up6  = layers.Conv2DTranspose(n_filters * 4, kernel_size=(3,3), strides=(2,2), padding=\"same\")(p5)\r\n    # up6  = layers.UpSampling2D()(p5) \r\n    m6 = layers.Concatenate(axis=3)([up6, c4])\r\n    c6 = conv2d_block_3layers(m6, n_filters * 4, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    up7 = layers.Conv2DTranspose(n_filters * 4, kernel_size=(3,3), strides=(2,2), padding=\"same\")(c6)\r\n    # up7  = layers.UpSampling2D()(c6) \r\n    m7 = layers.Concatenate(axis=3)([up7, c3])\r\n    c7 = conv2d_block_3layers(m7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    up8 = layers.Conv2DTranspose(n_filters * 2, kernel_size=(3,3), strides=(2,2), padding=\"same\")(c7)\r\n    # up8  = layers.UpSampling2D()(c7) \r\n    m8  = layers.Concatenate(axis=3)([up8, c2])\r\n    c8 = conv2d_block_3layers(m8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    up9 = layers.Conv2DTranspose(n_filters * 1, kernel_size=(3,3), strides=(2,2), padding=\"same\")(c8)\r\n    # up9  = layers.UpSampling2D()(c8) \r\n    m9 = layers.Concatenate(axis=3)([up9, c1])\r\n    c9 = conv2d_block_3layers(m9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    outputlayer = tf.keras.layers.Conv2D(filters=nClasses, kernel_size=1, activation=\"softmax\")(c9)\r\n    \r\n    model = tf.keras.Model(inputs=img_input, outputs=outputlayer)\r\n    model.summary(line_length=124)\r\n    return model\r\n```\r\n \r\n**The output from the converter invocation**\r\n```\r\nTraceback (most recent call last):\r\n  File \"keras_to_tflite.py\", line 105, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 831, in convert\r\n    self).convert(graph_def, input_tensors, output_tensors)\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 638, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 452, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 98, in calibrate_and_quantize\r\n    np.dtype(activations_type.as_numpy_dtype()).num)\r\nRuntimeError: Quantization not yet supported for op: %\r\n\r\n```\r\n\r\n\r\n\r\nThe model architecture uses Conv2D, batchnormalization, dropout, MaxPooling2D, Conv2DTranspose, Concatenate layers. Is the operation % used in any of the mentioned layers? The % operation is not used at all.  \r\n", "comments": ["Can you please attach your model/ share google colab code to debug further? Thanks!", "[test_model.zip](https://github.com/tensorflow/tensorflow/files/5219078/test_model.zip)\r\nHere is the Keras *.hdf5 model file.", "I think you need to update your example also with the missing source of `converter.representative_dataset = representative_data_gen`", "@ehazrati,\r\nOn running the code I am facing an error stating `NameError: name 'data_dir' is not defined`.\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the dataset you are using as well. Thanks!", "[dataset.tar.gz](https://github.com/tensorflow/tensorflow/files/5223152/dataset.tar.gz)\r\nHere is the example data set. Thanks.", "You are using what in Doc is described as [Integer only quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_integer-only_quantization):\r\n> To quantize the input and output tensors, and make the converter throw an error if it encounters an operation it cannot quantize, convert the model again with some additional parameters.\r\n\r\nYou have some operations that it can't quantize.\r\n\r\nYou can check this running your example with `pip install tf-nightly`:\r\n\r\n```\r\nRuntimeError: Quantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'DIV'.\r\n```", "The problem is I want to be able to perform the inference on a Coral USB accelerator which has an edge TPU and it is an \"integer-only\" hardware. Therefore, I have to convert using integer-only quantization. For that to work, all operations in the model should have a quantized implementation, otherwise I won't get an end-to-end integer-only model and I cannot run it on an edge TPU. \r\nAs mentioned in the previous comments, the model uses the following layers:\r\n- layers.Conv2D \r\n- layers.BatchNormalization\r\n- layers.Dropout\r\n- layers.MaxPooling2D \r\n- layers.Concatenate\r\n- layers.Activation('relu')\r\n- layers.Conv2DTranspose  or layers.UpSampling2D\r\n- layers.Activation('softmax')\r\n\r\nAccording to the guides, the above layers all have a quantized implementation, except for the  layers.Conv2DTranspose layer which I am not sure. For that reason I created two models one with layers.Conv2DTranspose and another one with layers.UpSampling2D.\r\nTrying both, I got the sane Error you mentioned in your comment: \r\n```\r\nTraceback (most recent call last):\r\n  File \"keras_to_tflite.py\", line 108, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 847, in convert\r\n    self).convert(graph_def, input_tensors, output_tensors)\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 648, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 476, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \"/home/ths/anaconda3/envs/py37_tf23/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 98, in calibrate_and_quantize\r\n    np.dtype(activations_type.as_numpy_dtype()).num)\r\nRuntimeError: Quantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'DIV'.\r\n```\r\nI suspect that the error could be related to Softmax, as it is the one uses EXP and DIV operations. But, then I am able to perform all the steps mentioned in this tutorial: convert, compile, and run the model on TPU, without any problem (using tensorflow2.3): \r\nhttps://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb#scrollTo=19IQ2gqneqmS\r\nThe model above uses Softmax as well.\r\n\r\nAny idea what is happening? Is there a way to check where exactly the operations 'EXP'  and 'DIV' are performed in the model?    \r\nThanks.  \r\n \r\n\r\n\r\n \r\n", "Can you edit/complete you example with your dummy model definition and saving instead of the saved file? \r\nSo that we have a minimal but complete example to run.\r\n\r\nThanks", "** model definition\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ndef conv2d_block_3layers(input_tensor, n_filters, kernel_size=3, dropout=0.2, \r\n                         batchnorm=True, activation=True):\r\n    # first layer\r\n    x = layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\r\n                      padding = 'same')(input_tensor)\r\n    if batchnorm:\r\n        x = layers.BatchNormalization()(x)\r\n    if activation:\r\n        x = layers.Activation('relu')(x)\r\n    x = layers.Dropout(dropout)(x)\r\n    # second layer\r\n    x = layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\r\n                      padding = 'same')(x)\r\n    if batchnorm:\r\n        x = layers.BatchNormalization()(x)\r\n    if activation:\r\n        x = layers.Activation('relu')(x)\r\n    x = layers.Dropout(dropout)(x)\r\n    # third layer\r\n    x = layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\r\n                      padding = 'same')(x)\r\n    if batchnorm:\r\n        x = layers.BatchNormalization()(x)\r\n    if activation:\r\n        x = layers.Activation('relu')(x)\r\n    return x\r\n\r\ndef UNET_v2(nClasses=25, input_height=288, input_width=224, n_filters=64, dropout=0.2, \r\n            batchnorm=True, activation=True):\r\n  \r\n    img_input = layers.Input(shape=(input_height, input_width, 3))  \r\n\r\n    c1 = conv2d_block_3layers(img_input, n_filters * 1, kernel_size=3, batchnorm = batchnorm, activation=activation)\r\n    p1 = layers.MaxPooling2D((2, 2))(c1) \r\n\r\n    c2 = conv2d_block_3layers(p1, n_filters * 2, kernel_size=3, batchnorm = batchnorm,  activation=activation)\r\n    p2 = layers.MaxPooling2D((2, 2))(c2) \r\n\r\n    c3 = conv2d_block_3layers(p2, n_filters * 4, kernel_size=3, batchnorm = batchnorm,  activation=activation)\r\n    p3 = layers.MaxPooling2D((2, 2))(c3) \r\n\r\n    c4 = conv2d_block_3layers(p3, n_filters * 4, kernel_size=3, batchnorm = batchnorm,  activation=activation)\r\n    p4 = layers.MaxPooling2D((2, 2))(c4) \r\n\r\n    c5 = conv2d_block_3layers(p4, n_filters = n_filters * 8, kernel_size=3, batchnorm = batchnorm, activation=activation)\r\n    p5 = layers.Dropout(dropout)(c5) \r\n\r\n    up6  = layers.Conv2DTranspose(n_filters * 4, kernel_size=(3,3), strides=(2,2), padding=\"same\")(p5)\r\n    # up6  = layers.UpSampling2D()(p5) \r\n    m6 = layers.Concatenate(axis=3)([up6, c4])\r\n    c6 = conv2d_block_3layers(m6, n_filters * 4, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    up7 = layers.Conv2DTranspose(n_filters * 4, kernel_size=(3,3), strides=(2,2), padding=\"same\")(c6)\r\n    # up7  = layers.UpSampling2D()(c6) \r\n    m7 = layers.Concatenate(axis=3)([up7, c3])\r\n    c7 = conv2d_block_3layers(m7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    up8 = layers.Conv2DTranspose(n_filters * 2, kernel_size=(3,3), strides=(2,2), padding=\"same\")(c7)\r\n    # up8  = layers.UpSampling2D()(c7) \r\n    m8  = layers.Concatenate(axis=3)([up8, c2])\r\n    c8 = conv2d_block_3layers(m8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    up9 = layers.Conv2DTranspose(n_filters * 1, kernel_size=(3,3), strides=(2,2), padding=\"same\")(c8)\r\n    # up9  = layers.UpSampling2D()(c8) \r\n    m9 = layers.Concatenate(axis=3)([up9, c1])\r\n    c9 = conv2d_block_3layers(m9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm, activation=activation)\r\n\r\n    outputlayer = tf.keras.layers.Conv2D(filters=nClasses, kernel_size=1, activation=\"softmax\")(c9)\r\n    \r\n    model = tf.keras.Model(inputs=img_input, outputs=outputlayer)\r\n    model.summary(line_length=124)\r\n    return model\r\n```", "Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/3043b00079794220298cb59fb238ba75/43207.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/806ca7fbab4575784d6459cab4ee5fff/43207-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@ehazrati I saw your model and I think that what is missing is that you are using the `softmax` activation in your conv. This is different from the official colab that you have mentioned in this ticket cause there the `softmax` activation is in a Dense layer:\r\n\r\n` outputlayer = tf.keras.layers.Conv2D(filters=nClasses, kernel_size=1, activation=\"softmax\")(c9)`", "Clear, thanks for the support and clarification.", "Hi @njeffrie,\r\n\r\nSeems the problem is almost resolved, but the initial error message seems weird. Can you take a look?\r\n`RuntimeError: Quantization not yet supported for op: %`", "@teijeong Just a note, the original message was on TF 2.3 only. \r\nI don't know If you want to improve the nightly error message.", "Ah I see, thanks!\r\n\r\nHi @ehazrati, could you close this issue if it's resolved?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43207\">No</a>\n", "I resolved this error by using TOCO:\r\nconverter.experimental_new_converter = False\r\n"]}, {"number": 43206, "title": "Architecture of Tensorflow model Zoo ", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/models/tree/master/official\r\n\r\n## Description of issue:\r\nWhere i can find full architecture of all the pre-trained model of Tensorflow object detection api. And also the difference between different version. For example: Difference between SSD MobileNet V2 FPNLite 640x640 and SSD MobileNet v2 320x320???\r\n\r\n", "comments": ["Please close this ticket and open a new one at https://github.com/tensorflow/models/ directly."]}, {"number": 43205, "title": "Sparse tensor error message when applying constraint to dense variable", "body": "\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Conda\r\n- TensorFlow version: I tried versions 2.2.0, 2.3.0, 1.15, and 1.14\r\n- Python version: 3.6 and 3.8.3\r\n- CUDA/cuDNN version: CUDA 10.1 and cuDNN 7.6 for TF 2.3.0 and 2.2.0, CUDA 10.0 and cuDNN 7.4 for TF 1.15 and 1.14\r\n- GPU model and memory: GeForce GTX TITAN X (12 GB)\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying to impose a constraint on a trainable variable. \r\nHowever, at some point in my pipeline, I am applying a tf.gather operation to the variable that I am constraining, which is causing a runtime error.\r\nThe error message (see below) says that a constraint function cannot be used on a sparse variable.\r\nHowever, my variable is not sparse.\r\nWhen I am excluding the tf.gather operation, it works without any errors.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe variable should be constrained to a specific range without any errors.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nColab: https://colab.research.google.com/drive/1Cv-ftL1E0tpC7-1sqO3AMNQ9kSto8m4_?usp=sharing#scrollTo=RY1T16oqz9yo\r\n\r\nThis is not working:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.compat.v1.disable_v2_behavior()\r\n\r\ny = tf.Variable(name='y',\r\n                initial_value=np.random.rand(5, 2) * 2,\r\n                dtype=tf.float32,\r\n                constraint=lambda x: tf.clip_by_value(x, clip_value_min=-1.0, clip_value_max=1.0), \r\n                )\r\n\r\nyy = tf.gather(y, axis=0, indices=[0, 1, 2])\r\nloss = tf.reduce_sum(yy)\r\nstep = tf.compat.v1.train.AdamOptimizer(learning_rate=0.1).minimize(loss=loss, var_list=[y])\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    y_, _ = sess.run(fetches=[y, step])\r\n    print(y_)\r\n```\r\n\r\n\r\nThis is working (just removed the tf.gather operation):\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.compat.v1.disable_v2_behavior()\r\n\r\ny = tf.Variable(name='y',\r\n                initial_value=np.random.rand(5, 2) * 2,\r\n                dtype=tf.float32,\r\n                constraint=lambda x: tf.clip_by_value(x, clip_value_min=-1.0, clip_value_max=1.0), \r\n                )\r\n\r\nloss = tf.reduce_sum(y)\r\nstep = tf.compat.v1.train.AdamOptimizer(learning_rate=0.1).minimize(loss=loss, var_list=[y])\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    y_, _ = sess.run(fetches=[y, step])\r\n    print(y_)`\r\n```\r\n\r\n**Other info / logs** \r\n```python\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-13-1e1802616fbe> in <module>()\r\nloss = tf.reduce_sum(yy)\r\nstep = tf.compat.v1.train.AdamOptimizer(learning_rate=0.1).minimize(loss=loss, var_list=[y])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py in update_op(self, optimizer, g)\r\nif self._v.constraint is not None:\r\n raise RuntimeError(\r\n\"Cannot use a constraint function on a sparse variable.\")\r\nreturn optimizer._resource_apply_sparse_duplicate_indices(\r\ng.values, self._v, g.indices)\r\nRuntimeError: Cannot use a constraint function on a sparse variable.\r\n```", "comments": ["/cc @tanzhenyu is this a dup of https://github.com/tensorflow/tensorflow/issues/33755?", "@matthias-wright Probably we are in the same class of problems as #33755. \r\n\r\nYou can check yourself with these two lines:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L640\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_grad.py#L588\r\n", "@bhack Thank you for the response! \r\nFrom the documentation of [tf.IndexedSlices](https://www.tensorflow.org/api_docs/python/tf/IndexedSlices): _The IndexedSlices class is used principally in the definition of gradients for operations that have sparse gradients (e.g. tf.gather)._ That means that even though the variable is dense, the gradient is sparse. That makes sense then. \r\nI do think that the error message is a little confusing, because the constraint is applied to the variable and not the gradient.", "I tried in colab with TF 2.3, nightly versions and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/950eaf955e33b0cd3530da791ea56bcf/untitled393.ipynb). Thanks!", "@matthias-wright Can we go ahead and close this issue as it is not bug. Thanks!", "Yes, we can close it. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43205\">No</a>\n"]}, {"number": 43204, "title": "Move LevelDB code to third_party vendoring in Bazel", "body": "This PR is part of the effort to resolve the issue raised in #43015 where the files from levelDB have conflicting copyright/license info than TensorFlow.\r\n\r\nThis PR moves all levelDB files out of the repo, and, replaced with the vendoring of LevelDB directly.\r\n\r\nSome additional updates has been make so that `leveldb::[WritableFile|RandomAccessFile|Status]` can be converted to TF's `[WritableFile|RandomAccessFile|Status]`.\r\n\r\nThe `leveldb::Slice` has also been converted to `StringPiece`.\r\n\r\nThis PR fixes #43015.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": ["Base on https://github.com/tensorflow/tensorflow/issues/43015#issuecomment-700370316 I think this PR can be closed."]}, {"number": 43203, "title": "tf-mlir-translate is not coming in binaries", "body": "I built mlir using : bazel build --config opt tensorflow/compiler/mlir/...\r\n\r\nBut tf-mlir-translate is not there in the tensorflow/bazel-bin/tensorflow/compiler/mlir/tensorflow/\r\n\r\n\r\nThank You", "comments": ["@ArunaKote,\r\nCould you please fill in the below details\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\nand also provide the exact sequence of commands / steps that you executed before running into the problem? Thanks!", "OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):https://github.com/tensorflow/tensorflow.git\r\nTensorFlow version:2.0\r\nPython version:3.8\r\nInstalled using virtualenv? pip? conda?:pip\r\nBazel version (if compiling from source):3.1.0\r\nGCC/Compiler version (if compiling from source):9.3.0\r\nI am installing only for CPU.\r\n\r\nThank You", "@ArunaKote `translate` is present in `tensorflow/tensorflow/compiler/mlir/tensorflow/` Please take a look at [here](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/compiler/mlir/tensorflow) in tensorflow 2.0 ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43203\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43203\">No</a>\n"]}, {"number": 43200, "title": "tf.keras.callbacks.TensorBoard histogram summary breaks on tf.bool layer weights", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NixOS 20.03 (irrelevant, as tensorflow is installed over pip)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0 (applies to HEAD as well)\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nTensorboard callback crashes with InvalidArgumentError in an attempt to save a histogram for tf.bool layer variable.\r\n\r\n**Describe the expected behavior**\r\nThe most simple fix would be to skip over non-trainable weights / not-supported types in [_log_weights](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/callbacks.py#L2227).\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_addons as tfa\r\nimport numpy as np\r\n\r\nthemodel = tf.keras.Sequential([\r\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1)) # breaks due to tf.bool [_initialzed](https://github.com/tensorflow/addons/blob/v0.11.2/tensorflow_addons/layers/wrappers.py#L105) layer weight\r\n    #tf.keras.layers.Dense(1) # works fine\r\n])\r\n\r\nbatch_size=1\r\nx = np.zeros([batch_size, 10])\r\ny = np.zeros([batch_size, 1])\r\n\r\nthemodel.compile(optimizer='sgd', loss='binary_crossentropy')\r\nthemodel.fit(x, y, batch_size=batch_size, epochs=1, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='/tmp',histogram_freq=1,update_freq='epoch')])\r\n\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\n  File \".../.venv/lib/python3.7\r\n/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute              \r\n    inputs, attrs, num_outputs)                                                            tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is\r\n not in the list of allowed values: float, double, int32, uint8, int16, int8, int64, bfloat\r\n16, uint16, half, uint32, uint64\r\n        ; NodeDef: {{node WriteHistogramSummary}}; Op<name=WriteHistogramSummary; signature\r\n=writer:resource, step:int64, tag:string, values:T -> ; attr=T:type,default=DT_FLOAT,allowe\r\nd=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UI\r\nNT16, DT_HALF, DT_UINT32, DT_UINT64]; is_stateful=true> [Op:WriteHistogramSummary]\r\n```", "comments": ["Can you close this and open a ticket in https://github.com/tensorflow/addons", "To be honest, I don't think this has anything to do with tf addons.\r\nI've just used WeightNormalization as a practical example of a layer having bool weights.\r\nThe root cause is TensorBoard callback I believe.", "I think that there two different issues:\r\n-  If your case is specific to `WeightNormalization` we could try to workaround in TF-addons.\r\n- Instead if you are interested in generic tf.bool then is a known constrain:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/compat/ops_history_v2/WriteHistogramSummary.pbtxt", "Neither\r\n\r\nThe point is TensorBoard callback crashes where it could actually do something more reasonable.\r\nInstead of sending unsupported type into summary writer it could just skip over or cast to tf.int8 or...", "To clarify, I'm thinking of something like this\r\n```\r\ndef _log_weights(self, epoch):\r\n    \"\"\"Logs the weights of the Model to TensorBoard.\"\"\"\r\n    with self._train_writer.as_default():\r\n      with summary_ops_v2.always_record_summaries():\r\n        for layer in self.model.layers:\r\n          for weight in layer.weights:\r\n--------------\r\n            # either (trivial, but may break stuff)\r\n            if not weight.trainable:\r\n              <perhaps emit a warning>\r\n              continue\r\n\r\n            # or (more convoluted, but can't break anything as it is broken anyways)\r\n            if weight.dtype not in <supported types>:\r\n              <perhaps emit a warning>\r\n              continue\r\n--------------\r\n            weight_name = weight.name.replace(':', '_')\r\n            summary_ops_v2.histogram(weight_name, weight, step=epoch)\r\n            if self.write_images:\r\n              self._log_weight_as_image(weight, weight_name, epoch)\r\n        self._train_writer.flush()\r\n```", "Ok you can  try to propose this extra condition to `_log_weights` with a PR \r\n/cc @dnguyen28061  @annarev (for c++) @omalleyt12 (for python)", "Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/0072c1bae1cf5704f47ef1de10518399/43200.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/c31bc03e5a46953f4194581a104b8fa7/43200-tf-nightly.ipynb). Please find the attached gist. Thanks!", "I am not really familiar with WriteHistogramSummary op. Adding +@alextp who might know more about that op.", "@annarev I've seen that you have recently reviewed some changes in the underline c++ `summary` ops https://github.com/tensorflow/tensorflow/pull/41209. \r\nThe mention was just to know if we have any interest in `bool` `dtype`.", "@manivaradarajan can you take a look at this issue?", "> you can try to propose this extra condition to `_log_weights` with a PR\r\n\r\nCould give it a try. Any pointers re which of the proposed fixes would be preferred?", "cc: @omalleyt12 \r\n\r\n@unsatcore Thank you for considering fixing this. I suggest starting with your second option -- as you state, it should be innocuous and can only help. Once that's through, we can also look at pursuing the first one, though I think it will be harder to get right.", "This is working fine without breaking in `Tensorflow 2.7` and `Tensorflow Addons 0.15.0 `version, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/720d071e3b6950bb79d6d8a97effb7aa/43200.ipynb) for reference. \r\nFeel free to  reopen the issue if you still face an issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43200\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43200\">No</a>\n"]}]