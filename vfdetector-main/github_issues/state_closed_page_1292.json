[{"number": 14357, "title": "Following instructions in batch_normalization docs produces an exception", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: Binary (pip install tensorflow)\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6.3\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: (see the \"Source code\" section)\r\n\r\n### Describe the problem\r\nI was following the instructions for updating `moving_mean` and `moving_variance` by using the code snippet provided in [batch_normalization documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) and it resulted in an \"tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\" exception.\r\n\r\n### Source code / logs\r\n\r\nFull instructions to reproduce: \r\n\r\n    git clone -b control-dependencies-exc https://github.com/naktinis/language-id.git ctrl-dep-exc\r\n    cd ctrl-dep-exc/\r\n    python3 -m venv venv\r\n    . venv/bin/activate\r\n    pip install tensorflow==1.4.0 Pillow\r\n    python3 main.py --image-dir test_data/ --label-file test_data/labels.csv --model rnn\r\n\r\nThe specific code change that was enough to produce the exception (seems to match the snippet in the official [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization)):\r\nhttps://github.com/naktinis/language-id/commit/50740f\r\n\r\nFull exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 173, in <module>\r\n    tf.app.run(main=run_experiment)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"main.py\", line 165, in run_experiment\r\n    hparams=params,\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 218, in run\r\n    return _execute_schedule(experiment, schedule)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 46, in _execute_schedule\r\n    return task()\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 625, in train_and_evaluate\r\n    self.train(delay_secs=0)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 367, in train\r\n    hooks=self._train_monitors + extra_hooks)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 807, in _call_train\r\n    hooks=hooks)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/naktinis/code/ctrl-dep-exc/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\r\n\r\n```", "comments": ["It's hard to say if this is a local issue (for which [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) may be more helpful) or a documentation bug. @fchollet, can you take a look?", "@naktinis can you provide standalone code snippet to reproduce your issue? Something that could be copy/pasted and run, that would result in the exception you're seeing.", "@fchollet this seems to be enough to reproduce it https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528", "A simply modification of the reproduction script no longer produces the error (removing the GRU):\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nclass_count = 5\r\nwidth = 100\r\n\r\n# Placeholders\r\nph = tf.placeholder(shape=[None, width], dtype=tf.float32)\r\nlabels_ph = tf.placeholder(shape=[None], dtype=tf.int32)\r\n\r\nnorm_output_gru = tf.layers.batch_normalization(ph, training=True, axis=1)\r\n\r\n# The prediction layer\r\nlogits = tf.layers.dense(inputs=norm_output_gru, units=class_count)\r\nonehot_labels = tf.one_hot(labels_ph, depth=class_count)\r\n\r\n# Optimizer\r\nloss = tf.losses.softmax_cross_entropy(onehot_labels, logits)\r\noptimizer = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9)\r\n\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    train_op = optimizer.minimize(loss)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run([train_op, loss],\r\n             feed_dict={ph: np.zeros([1, width]),\r\n                        labels_ph: np.zeros([1])})\r\n```\r\n\r\nThis indicates that the problem lies in the combination of `GRU` and batchnorm updates.\r\n\r\nLooking at the stack trace, the error appears in many contexts, but seems most commonly associated with TF RNNs and while loops.", "/CC @ebrevdo can you take a look, since this looks to be an RNN issue?", "Is this still an issue in TF nightlies?", "@ebrevdo Yes, I just ran the [example](https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528) with a fresh `pip install tf-nightly` and it seems to still produce the same `tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value`.", "@ebrevdo the issue still exists in tf nightly. Can you please take another look?", "@skye we should be giving better rror messages here.  i believe the update_op is created inside a while loop context; but we're allowing it to be added as a control dependency on an op outside the context.\r\n\r\n@sguada i remember we had a variant of batch_normalization that didn't require update op collections.  do you recall how?", "@jpienaar had some plans to raise a better error when an op inside a while loop is used as a control input to an op outside the loop. I'm not sure what the status or timeline of that is at the moment.", "I got this error too, ` Retval[0] does not have value`\r\nI used batch norm after a dynamic_rnn made up of GRUCell, before a dense layer. As I happened to notice, using batch norm WITHOUT incorporating the dynamic_rnn seem to eliminate the issue.\r\nI've no idea if batch norm and dynamic rnn working together could yield better results.", "@ebrevdo it is part of tf.contrib.layers.batch_norm you need to use update_collection=None for that\r\nhttps://github.com/tensorflow/tensorflow/blob/7a0def60d45c1841a4e79a0ddf6aa9d50bf551ac/tensorflow/contrib/layers/python/layers/layers.py#L437\r\n", "I met the same problem\r\n```\r\ninputs = ....\r\ninputs = RNN op on inputs\r\ninputs = tf.layers.batch_normalization(inputs, training=self.is_train, trainable=True)\r\n.....\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    self.optimizer = ....\r\n```\r\n\r\nWhen removing RNN ops or replacing `tf.layers.batch_normalization` with `tf.contrib.layers.batch_norm(inputs=inputs, updates_collections=None)`, all things go well. Otherwise,  `Retval[0] does not have value` occur.\r\n", "I met the same problem using TensorFlow 1,8.0", "I met the same problem using:\r\n\r\n- TF 1.5.1 w: CUDA 9.0: Deadlocks the computation instead of throwing an error (you have to kill the process, not even interrupt works)\r\n- TF 1.6 CPU: Throws error described above\r\n\r\nI've also managed to find a workaround. Saving the `update_ops` operation and forcing its evaluation explicitly through in `session.run()` call instead of using `with tf.control_dependencies(update_ops)`  seems to mitigate the issue.\r\n", "I ran into this issue as well.\r\n\r\nI noticed that similar to @petrroll's issues with deadlocks on GPU, if you use a MonitoredTrainingSession in TF 1.5.1 it deadlocks instead of throwing an error even on CPU.", "Have you tried using batch norm with:\n\n\ntf.contrib.layers.batch_norm you need to use update_collection=None\n\nOn Tue, Aug 7, 2018, 12:00 PM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Assignee @ebrevdo <https://github.com/ebrevdo>: It has been 46\n> days with no activity and this issue has an assignee. Please update the\n> label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14357#issuecomment-411165413>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim4GSKmqHEznhv2ZnzjtbiDAbAnbGks5uOePlgaJpZM4QWKkb>\n> .\n>\n", "Nagging Assignee @ebrevdo: It has been 19 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm assuming the solutions above suffice.  Please reopen if you continue to have issues with the TF nightlies.", "1. How is the workaround with `tf.contrib.layers.batch_norm` using `updates_collection=None` supposed to work exactly? Does it update the batch norm stats with the input iff `is_training` is True? If it updates the batch norm stats on every input, even when `is_training` is False, then it's a poor workaround. I can't tell the exact behavior from reading the docs, which just says \"one can set updates_collections=None to force the updates in place\".\r\n\r\n2. I have a similar problem using a [modified version](https://gist.github.com/jchia/4c30e4f6a901d117193c4833680f8be4) of the @naktinis's [gist](https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528) using Keras layers. I was able to make the problem go away by applying the `tf.contrib.layers.batch_norm` workaround. So, is the official prescription to never use a recurrent layer followed by a batch norm layers other than a `tf.contrib.layers.batch_norm` with `updates_collections=None`? Is it OK to mix Keras layers with non-Keras layers like those from tf.contrib.layers? However, isn't tf.contrib going away with TF 2.0? How should the current problem be addressed then?", "+Francois Chollet <fchollet@google.com> the keras batchnorm layer needs an\noption to work via control dependencies.\n\nOn Fri, Nov 23, 2018, 12:02 AM Joshua Chia <notifications@github.com wrote:\n\n>\n>    1.\n>\n>    How is the workaround with tf.contrib.layers.batch_norm using\n>    updates_collection=None supposed to work exactly? Does it update the\n>    batch norm stats with the input iff is_training is True? If it updates\n>    the batch norm stats on every input, even when is_training is False,\n>    then it's a poor workaround. I can't tell the exact behavior from reading\n>    the docs, with just says \"one can set updates_collections=None to force the\n>    updates in place\".\n>    2.\n>\n>    I have a similar problem using a modified version\n>    <https://gist.github.com/jchia/4c30e4f6a901d117193c4833680f8be4> of\n>    the @naktinis <https://github.com/naktinis>'s gist\n>    <https://gist.github.com/naktinis/4200f955087bb07223f1fc3bb6255528>\n>    using Keras layers. I was able to make the problem go away by applying the\n>    tf.contrib.layers.batch_norm workaround. So, is the official\n>    prescription to never use a recurrent layer followed by a batch norm layers\n>    other than a tf.contrib.layers.batch_norm with updates_collections=None?\n>    Is it OK to mix Keras layers with non-Keras layers like those from\n>    tf.contrib.layers? However, isn't tf.contrib going away with TF 2.0? How\n>    should the current problem be addressed then?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14357#issuecomment-441174532>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8vrBaoFIjuk2SvWF10cr6a7zPOhks5ux6ukgaJpZM4QWKkb>\n> .\n>\n", "@fchollet ", "After setting updates_collections=None in tf.contrib.layers.batch_norm, do we also need to do this:\r\n```\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    self.optimizer = ....\r\n```", "Not necessary, since update_ops would be an empty list.\r\n\r\n```\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nprint(update_ops)  # Should print an empty list []\r\n```", "@ebrevdo \r\n\r\nDoes the `tf.contrib.layers.batch_norm` workaround work if I'm not doing the usual `optimizer.minimize()` training, but using `optimizer.compute_gradients()` on 2 small batches, adding up the gradients, and then calling `optimizer.apply_gradients()` on the summed gradients? Will the BN moving mean & variance get update once every small batch, every other small batch, every `apply_gradients()` or never?\r\n\r\nThis is important for cases where the batch size is too big for GPU memory and each batch needs to have gradients calculated separately for smaller sub-batches.\r\n\r\nI don't think I have authorization to re-open this issue."]}, {"number": 14356, "title": "Keras application - Tensor is not an element of this graph on eval after train", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.1\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6.3\r\n- **CUDA/cuDNN version**: N/A CPU only\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nUsing the estimator API and using `tf.keras.applications.VGG16` and it's output for transfer learning, I get an exception raised of `TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"vgg_base/Placeholder:0\", shape=(3, 3, 3, 64), dtype=float32) is not an element of this graph.` when the model is run a second time. \r\n\r\nThis is raised when it runs the eval step after train from `tf.estimator.train_and_evaluate`. See source code for model and estimator output. This also occurs if I re-run the train_and_evaluate a second time. I am running in a Jupyter notebook and my assumption about memory is that if I do a Kernel \u279d Restart it will run a training run again without the error, but cannot be run in two executions without this.\r\n\r\nSee https://github.com/damienpontifex/fastai-course/blob/master/deeplearning1/lesson1%2B3/DogsVsCats.ipynb for full notebook, but main parts for estimator model and output are below:\r\n\r\n### Source code / logs\r\n#### Estimator Model\r\n```python\r\ndef vgg16_model_fn(features, mode, params):\r\n    \r\n    is_training = mode == tf.estimator.ModeKeys.TRAIN\r\n    \r\n    with tf.variable_scope('vgg_base'):\r\n        # Use a pre-trained VGG16 model and drop off the top layers as we will retrain \r\n        # with our own dense output for our custom classes\r\n        vgg16_base = tf.keras.applications.VGG16(\r\n            include_top=False,\r\n            input_shape=(224, 224, 3),\r\n            input_tensor=features['image'],\r\n            pooling='avg')\r\n\r\n        # Disable training for all layers to increase speed for transfer learning\r\n        # If new classes significantely different from ImageNet, this may be worth leaving as trainable = True\r\n        for layer in vgg16_base.layers:\r\n            layer.trainable = False\r\n\r\n        x = vgg16_base.output\r\n    \r\n    with tf.variable_scope(\"fc\"):\r\n        x = tf.layers.flatten(x)\r\n        x = tf.layers.dense(x, units=4096, activation=tf.nn.relu, trainable=is_training, name='fc1')\r\n        x = tf.layers.dense(x, units=4096, activation=tf.nn.relu, trainable=is_training, name='fc2')\r\n        x = tf.layers.dropout(x, rate=0.5, training=is_training)\r\n        \r\n    # Finally add a 2 dense layer for class predictions\r\n    with tf.variable_scope(\"Prediction\"):\r\n        x = tf.layers.dense(x, units=NUM_CLASSES, trainable=is_training)\r\n        return x\r\n```\r\n#### Estimator setup\r\n```python\r\ndog_cat_estimator = tf.estimator.Estimator(\r\n    model_fn=model_fn,\r\n    config=run_config,\r\n    params=params\r\n)\r\ntrain_spec = tf.estimator.TrainSpec(\r\n    input_fn=data_input_fn(train_record_filenames, num_epochs=None, batch_size=10, shuffle=True), \r\n    max_steps=10)\r\neval_spec = tf.estimator.EvalSpec(\r\n    input_fn=data_input_fn(validation_record_filenames)\r\n)\r\ntf.estimator.train_and_evaluate(dog_cat_estimator, train_spec, eval_spec)\r\n```\r\n#### train_and_evaluate output\r\n```\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Restoring parameters from /tmp/DogsVsCats/model.ckpt-1\r\nINFO:tensorflow:Saving checkpoints for 2 into /tmp/DogsVsCats/model.ckpt.\r\nINFO:tensorflow:loss = 0.0, step = 2\r\nINFO:tensorflow:Saving checkpoints for 10 into /tmp/DogsVsCats/model.ckpt.\r\nINFO:tensorflow:Loss for final step: 0.0.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1063             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\r\n-> 1064                                                     allow_operation=False)\r\n   1065           except Exception as e:\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in as_graph_element(self, obj, allow_tensor, allow_operation)\r\n   3034     with self._lock:\r\n-> 3035       return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n   3036 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _as_graph_element_locked(self, obj, allow_tensor, allow_operation)\r\n   3113       if obj.graph is not self:\r\n-> 3114         raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\r\n   3115       return obj\r\n\r\nValueError: Tensor Tensor(\"vgg_base/Placeholder:0\", shape=(3, 3, 3, 64), dtype=float32) is not an element of this graph.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-12-67c818ea66c5> in <module>()\r\n----> 1 tf.estimator.train_and_evaluate(dog_cat_estimator, train_spec, eval_spec)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)\r\n    428       config.task_type != run_config_lib.TaskType.EVALUATOR):\r\n    429     logging.info('Running training and evaluation locally (non-distributed).')\r\n--> 430     executor.run_local()\r\n    431     return\r\n    432 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run_local(self)\r\n    614       # condition is satisfied (both checks use the same global_step value,\r\n    615       # i.e., no race condition)\r\n--> 616       metrics = evaluator.evaluate_and_export()\r\n    617 \r\n    618       if not metrics:\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in evaluate_and_export(self)\r\n    749           name=self._eval_spec.name,\r\n    750           checkpoint_path=latest_ckpt_path,\r\n--> 751           hooks=self._eval_spec.hooks)\r\n    752 \r\n    753       if not eval_result:\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in evaluate(self, input_fn, steps, hooks, checkpoint_path, name)\r\n    353         hooks=hooks,\r\n    354         checkpoint_path=checkpoint_path,\r\n--> 355         name=name)\r\n    356 \r\n    357   def _convert_eval_steps_to_hooks(self, steps):\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _evaluate_model(self, input_fn, hooks, checkpoint_path, name)\r\n    808           input_fn, model_fn_lib.ModeKeys.EVAL)\r\n    809       estimator_spec = self._call_model_fn(\r\n--> 810           features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\r\n    811 \r\n    812       if model_fn_lib.LOSS_METRIC_KEY in estimator_spec.eval_metric_ops:\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n    692     if 'config' in model_fn_args:\r\n    693       kwargs['config'] = config\r\n--> 694     model_fn_results = self._model_fn(features=features, **kwargs)\r\n    695 \r\n    696     if not isinstance(model_fn_results, model_fn_lib.EstimatorSpec):\r\n\r\n<ipython-input-8-e251e8b8fccf> in model_fn(features, labels, mode, params)\r\n      3     tf.summary.image('images', features['image'], max_outputs=6)\r\n      4 \r\n----> 5     logits = vgg16_model_fn(features, mode, params)\r\n      6 \r\n      7     # Dictionary with label as outcome with greatest probability\r\n\r\n<ipython-input-7-93330b8a5aa6> in vgg16_model_fn(features, mode, params)\r\n     10             input_shape=(224, 224, 3),\r\n     11             input_tensor=features['image'],\r\n---> 12             pooling='avg')\r\n     13 \r\n     14         # Disable training for all layers to increase speed for transfer learning\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/applications/vgg16.py in VGG16(include_top, weights, input_tensor, input_shape, pooling, classes)\r\n    199           WEIGHTS_PATH_NO_TOP,\r\n    200           cache_subdir='models')\r\n--> 201     model.load_weights(weights_path)\r\n    202     if K.backend() == 'theano':\r\n    203       layer_utils.convert_all_kernels_in_model(model)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in load_weights(self, filepath, by_name)\r\n   1097       load_weights_from_hdf5_group_by_name(f, self.layers)\r\n   1098     else:\r\n-> 1099       load_weights_from_hdf5_group(f, self.layers)\r\n   1100 \r\n   1101     if hasattr(f, 'close'):\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in load_weights_from_hdf5_group(f, layers)\r\n   1484                        str(len(weight_values)) + ' elements.')\r\n   1485     weight_value_tuples += zip(symbolic_weights, weight_values)\r\n-> 1486   K.batch_set_value(weight_value_tuples)\r\n   1487 \r\n   1488 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py in batch_set_value(tuples)\r\n   2404       assign_ops.append(assign_op)\r\n   2405       feed_dict[assign_placeholder] = value\r\n-> 2406     get_session().run(assign_ops, feed_dict=feed_dict)\r\n   2407 \r\n   2408 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    887     try:\r\n    888       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 889                          run_metadata_ptr)\r\n    890       if run_metadata:\r\n    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1065           except Exception as e:\r\n   1066             raise TypeError('Cannot interpret feed_dict key as Tensor: '\r\n-> 1067                             + e.args[0])\r\n   1068 \r\n   1069           if isinstance(subfeed_val, ops.Tensor):\r\n\r\nTypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"vgg_base/Placeholder:0\", shape=(3, 3, 3, 64), dtype=float32) is not an element of this graph.\r\n```\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@bignamehyp I had assumed this was a bug as it seems to be occurring with variables setup inside \u2018tf.keras.applications.VGG16\u2019 rather than any I had setup. Thoughts? ", "@bignamehyp Someone already asked a [similar question ](https://stackoverflow.com/questions/46911596/why-does-tensorflow-say-a-tensor-is-not-an-element-of-this-graph-when-training-a) on stack overflow.\r\n\r\nThe solution is to call `tf.keras.backend.clear_session()` after the call to `train()`. However, this won't work if the user wants to use `train_and_evaluate()` since there is no place to call `clear_session()`.", "@bignamehyp does this information from @hsm207 provide any further insights? If I have to call `clear_session()` between runs, this would seem to be unexpected behaviour and be a bug? \r\n\r\nJust still not sure why it's happening to provide insights on a potential solution.", "tf.Tensor 'shuffle_batch:0' shape=(64, 256, 256, 1) dtype=float32> cannot be interpreted as a Tensor", "If you find this problem, try to write K.clear_session() when you secondly use your function for establishing your graph. Besides, you should reload the model and predict it randomly with a simple input. I fixed my code just like this:\r\n````\r\nuncerts_normal = get_mc_predictions(model, X_test, Y_label,\r\nbatch_size=args.batch_size) \r\n.var(axis=0)#.mean(axis=1)\r\nprint(uncerts_normal.shape)\r\nuncerts_normal1 = l2_normalize(a, axis=-1)\r\nK.clear_session() \r\nmodel = load_model('../data/model_%s.h5' % args.dataset)\r\nprint('testing model1:', model.predict(np.zeros((1, 28, 28, 1))))\r\nuncerts_noisy = get_mc_predictions(model, X_test_noisy,Y_label,\r\n                                   batch_size=args.batch_size).var(axis=0)\r\n````", "K.clear_session() did not work for me\r\n\r\nhowever, what worked was : \r\n\r\n\r\n\tdef load_model():\r\n\t\tglobal model\r\n\t\tmodel = ResNet50(weights=\"imagenet\")\r\n                # this is key : save the graph after loading the model\r\n\t\tglobal graph\r\n\t\tgraph = tf.get_default_graph()\r\n\r\nWhile predicting, use the same graph\r\n\r\n        with graph.as_default():\r\n\t\tpreds = model.predict(image)\r\n\t\t#... etc\r\n\r\n", "This worked for me \r\n`from keras import backend as K`\r\nand after predicting my data i inserted this part of code\r\n`K.clear_session()`\r\n", "The solution given by @anujgupta82 worked for me. Thanks a lot !", "Same problem here when trying to make an inference using a keras pre-trained model from a flask application. Thanks @anujgupta82 !", "The solution from @anujgupta82 worked for me too. But, can someone help me to understand what is going on? ", "The solution given by @Qmoliang and @mohammedyunus worked for me. Thanks :)", "The solution by @anujgupta82 also worked for me. Saved me a lot of stress!", "Wow,  thanks @anujgupta82 a lot ! Really a nice answer :-)", "> clear_session()\r\n\r\nIn my case, load_model() **works for the first time** but not afterward. If you are experiencing the same issue, you need to clear_session() after each time you load the model!", "Thanks @anujgupta82 \uff0cworks for me too!", "Thanks a lot, worked for me!", "> If you find this problem, try to write K.clear_session() when you secondly use your function for establishing your graph. Besides, you should reload the model and predict it randomly with a simple input. I fixed my code just like this:\r\n> \r\n> ```\r\n> uncerts_normal = get_mc_predictions(model, X_test, Y_label,\r\n> batch_size=args.batch_size) \r\n> .var(axis=0)#.mean(axis=1)\r\n> print(uncerts_normal.shape)\r\n> uncerts_normal1 = l2_normalize(a, axis=-1)\r\n> K.clear_session() \r\n> model = load_model('../data/model_%s.h5' % args.dataset)\r\n> print('testing model1:', model.predict(np.zeros((1, 28, 28, 1))))\r\n> uncerts_noisy = get_mc_predictions(model, X_test_noisy,Y_label,\r\n>                                    batch_size=args.batch_size).var(axis=0)\r\n> ```\r\n\r\nWhat if the model we have trained has already been saved and we are in the loading, then predicting phase when this error occurs? Any other thoughts?", "> K.clear_session() did not work for me\r\n> \r\n> however, what worked was :\r\n> \r\n> ```\r\n> def load_model():\r\n> \tglobal model\r\n> \tmodel = ResNet50(weights=\"imagenet\")\r\n>             # this is key : save the graph after loading the model\r\n> \tglobal graph\r\n> \tgraph = tf.get_default_graph()\r\n> ```\r\n> While predicting, use the same graph\r\n> \r\n> ```\r\n>     with graph.as_default():\r\n> \tpreds = model.predict(image)\r\n> \t#... etc\r\n> ```\r\n\r\ngod among men. Worked.", "The reason why the code from @anujgupta82 works is given in [this StackOverFlow answer](https://stackoverflow.com/questions/51127344/tensor-is-not-an-element-of-this-graph-deploying-keras-model). \r\n\r\n> Flask uses multiple threads. The problem you are running into is because the tensorflow model is not loaded and used in the same thread. One workaround is to force tensorflow to use the gloabl default graph .", "> K.clear_session() did not work for me\r\n> \r\n> however, what worked was :\r\n> \r\n> ```\r\n> def load_model():\r\n> \tglobal model\r\n> \tmodel = ResNet50(weights=\"imagenet\")\r\n>             # this is key : save the graph after loading the model\r\n> \tglobal graph\r\n> \tgraph = tf.get_default_graph()\r\n> ```\r\n> While predicting, use the same graph\r\n> \r\n> ```\r\n>     with graph.as_default():\r\n> \tpreds = model.predict(image)\r\n> \t#... etc\r\n> ```\r\n\r\nThanks. I struggled the same problem for half a day and solved it as your suggestion.", "The solution  by @anujgupta82  worked for me. thanks", "The approach provided mohamedadaly is described here with an example. check this link:\r\nhttps://interviewbubble.com/typeerror-cannot-interpret-feed_dict-key-as-tensor-tensor-tensor-is-not-an-element-of-this-graph/", "hi, dear.\r\ni use your function, but no work for me, no any error message, and no any reponse.\r\n```python\r\n# load_keras_model.py\r\nclass LoadKerasModel:\r\n    model = None\r\n    graph = None\r\n\r\n    def __init__(self):\r\n        self.keras_resource()\r\n        self.init_model()\r\n\r\n    def init_model(self):\r\n        self.graph = tf.get_default_graph()\r\n        self.model = load_model(file_path)\r\n        self.model.predict(np.ones((1, 1, 1, 1)))\r\n\r\n    def keras_resource(self):\r\n        num_cores = 4\r\n\r\n        if os.getenv('TENSORFLOW_VERSION') == 'GPU':\r\n            num_gpu = 1\r\n            num_cpu = 1\r\n        elif os.getenv('TENSORFLOW_VERSION') == 'CPU':\r\n            num_gpu = 0\r\n            num_cpu = 1\r\n        else:\r\n            raise NonResourceException()\r\n\r\n        config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\r\n                                inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\r\n                                device_count={'CPU': num_cpu, 'GPU': num_gpu})\r\n        config.gpu_options.allow_growth = True\r\n\r\n        session = tf.Session(config=config)\r\n        K.set_session(session)\r\n\r\n    def predict_target(selfl, img_generator):\r\n        with self.graph.as_default():\r\n            predict = self.model.predict_generator(\r\n                img_generator,\r\n                steps=len(img_generator),\r\n                verbose=1\r\n            )\r\n        return predict\r\n\r\nload_keras_model = LoadKerasModel()\r\n```\r\nmy environment\r\n```\r\npython 3.5\r\nkeras 2.24\r\ntensorflow: 1.12\r\n```\r\nmy activate uwsgi command\r\n```\r\nuwsgi --http-socket 0.0.0.0:5001 --wsgi-file wsgi.py --callable app --http-enable-proxy-protocol --processes 4 --threads 2 --stats 0.0.0.0:5002\r\n```\r\nwhile i use flask run to activate my application, it works very well, but not work while use uwsgi.\r\nflask is factory method to activate, while init flask app, i import load_keras_model.\r\ni don't sure where i wrong, because no any error message, hope somebody can help me, thanks.", "this works for me,\r\n@shaoeChen how is this working for you? It turns out this way does not need a clear_session call and is at the same time configuration friendly\r\n```\r\nfrom keras.backend.tensorflow_backend import set_session\r\n# load_keras_model.py\r\nclass LoadKerasModel:\r\n    model = None\r\n    graph = None\r\n\r\n    def __init__(self):\r\n        config = self.keras_resource()\r\n        self.init_model(config)\r\n\r\n    def init_model(self, _config, *args):\r\n        session = tf.Session(config=_config)\r\n        self.graph = session.graph\r\n        set_session(session)\r\n        self.model = load_model(file_path)\r\n\r\n    def keras_resource(self):\r\n        num_cores = 4\r\n\r\n        if os.getenv('TENSORFLOW_VERSION') == 'GPU':\r\n            num_gpu = 1\r\n            num_cpu = 1\r\n        elif os.getenv('TENSORFLOW_VERSION') == 'CPU':\r\n            num_gpu = 0\r\n            num_cpu = 1\r\n        else:\r\n            raise NonResourceException()\r\n\r\n        config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\r\n                                inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\r\n                                device_count={'CPU': num_cpu, 'GPU': num_gpu})\r\n        config.gpu_options.allow_growth = True\r\n        \r\n        return config\r\n\r\n    def predict_target(self, img_generator):\r\n        with self.graph.as_default():\r\n            predict = self.model.predict_generator(\r\n                img_generator,\r\n                steps=len(img_generator),\r\n                verbose=1\r\n            )\r\n        return predict\r\n\r\nload_keras_model = LoadKerasModel()\r\nload_keras_model.predict_target(np.ones((1, 1, 1, 1))) #img_generator\r\n```", "@ArashHosseini \r\nhi dear.\r\ni try it  and get same reply, it's no response and no error. the browser is reading, reading, reading.\r\neven i set uwsgi one process one thread as below:\r\n```\r\nuwsgi --http-socket 0.0.0.0:5001 --wsgi-file wsgi.py --callable app --http-enable-proxy-protocol --processes 1 --threads 1 --stats 0.0.0.0:5002\r\n```\r\nNow, i try use gunicron as below, and five seconds can get predict_generator response:\r\n```\r\ngunicorn --thread=2 --workers=1 wsgi:app -b 0.0.0.0:5001\r\n```\r\nIt work well for me, i think i need study how to use uwsgi correctly.\r\nthanks for your guidnace.", "@shaoeChen, thx for reply, i edited the code, `set_session` in `__init__` was missing, now the GPU consumption should be significantly lower, let me know if that(gpu_config) worked in your case, thanks", "@ArashHosseini , sorry to late to reply,\r\nnow i notice that GPU resource is not under my control.\r\nOriginal it use 1355MB, but now it use all 1888MB as below say:\r\n![image](https://user-images.githubusercontent.com/28851695/54017515-2d89a600-41c1-11e9-9c2b-bb636b44de52.png)\r\n\r\noriginal gpu memory:\r\n![image](https://user-images.githubusercontent.com/28851695/54099059-62307400-43f2-11e9-8a42-a1f734b37bc3.png)\r\n\r\n\r\nhi @ArashHosseini . i am sorry.\r\ni think i miss some setting, now i sure the gpu memory usage is the same, as below say:\r\n![image](https://user-images.githubusercontent.com/28851695/54180391-79e12880-44d6-11e9-9cca-35e0a1e7f052.png)\r\n\r\nthanks your advice.", "> This worked for me\r\n> `from keras import backend as K`\r\n> and after predicting my data i inserted this part of code\r\n> `K.clear_session()`\r\n\r\nThank you!", "I have encountered this error in a code I was working with, and none of the above answers worked for me.\r\n\r\nWhat I found as the problem was that the code had mixed uses of `keras` and `tensorflow.keras`, and using `keras.backend.clear_session()` instead of `tensorflow.keras.backend.clear_session()` broke everything after the network was trained for the first time. ", "@anujgupta82 you save my day", "> I have encountered this error in a code I was working with, and none of the above answers worked for me.\r\n> \r\n> What I found as the problem was that the code had mixed uses of `keras` and `tensorflow.keras`, and using `keras.backend.clear_session()` instead of `tensorflow.keras.backend.clear_session()` broke everything after the network was trained for the first time.\r\n\r\nthanks, I got the same problem with you, and follow your answer, I fixed this problem.", "> K.clear_session() did not work for me\r\n> \r\n> however, what worked was :\r\n> \r\n> ```\r\n> def load_model():\r\n> \tglobal model\r\n> \tmodel = ResNet50(weights=\"imagenet\")\r\n>             # this is key : save the graph after loading the model\r\n> \tglobal graph\r\n> \tgraph = tf.get_default_graph()\r\n> ```\r\n> \r\n> While predicting, use the same graph\r\n> \r\n> ```\r\n>     with graph.as_default():\r\n> \tpreds = model.predict(image)\r\n> \t#... etc\r\n> ```\r\n\r\ncan you please help in this code that you have written", "> K.clear_session() did not work for me\r\n> \r\n> however, what worked was :\r\n> \r\n> ```\r\n> def load_model():\r\n> \tglobal model\r\n> \tmodel = ResNet50(weights=\"imagenet\")\r\n>             # this is key : save the graph after loading the model\r\n> \tglobal graph\r\n> \tgraph = tf.get_default_graph()\r\n> ```\r\n> \r\n> While predicting, use the same graph\r\n> \r\n> ```\r\n>     with graph.as_default():\r\n> \tpreds = model.predict(image)\r\n> \t#... etc\r\n> ```\r\n\r\nHad the same issue and the solution helped me, but with small improvement:\r\n\r\n\r\n```\r\nimport ktrain\r\nimport tensorflow as tf\r\nimport flask\r\n\r\napp = flask.Flask(__name__)\r\npredictor = None\r\ngraph = None\r\n\r\ndef load_predictor():\r\n    global predictor\r\n\r\n    predictor = ktrain.load_predictor('saved_model')\r\n\r\n    if hasattr(predictor.model, '_make_predict_function'):\r\n        predictor.model._make_predict_function()\r\n\r\n    global graph\r\n    graph = tf.get_default_graph()\r\n\r\n@app.route(\"/analyze/<text>\")\r\ndef predict(text):\r\n    with graph.as_default():\r\n        prediction = predictor.predict(text)\r\n    return prediction, 200\r\n\r\nif __name__ == \"__main__\":\r\n    load_predictor()\r\n    app.run()\r\n```\r\n\r\ntensorflow==1.15.0rc2\r\nktrain==0.5.2\r\nflask==0.12.2", "Use:\r\nimport keras\r\nkeras.backend.clear_session()\r\n\r\nBefore Initializing the Model", "I reverted my TF to 1.13.1 and Keras to 2.2.4 and this error disappeared.", "have tried all the above, but no use\r\nhttps://github.com/tensorflow/models/issues/8448", "I use train_and_evaluate() and meet the same error.  @damienpontifex since this issue is continuously referenced by similar errors, could you kindly upload the fixed code please?"]}, {"number": 14355, "title": "Java API and Node.js: java.lang.IllegalArgumentException: graphDef and prefix cannot be null", "body": "I'm using [node-java](https://github.com/joeferner/node-java) to run the JAVA API within a `Node.js` application. Most of the work is done in Java, but I have some issues when loading the graph through node using the Java api `graph.importGraphDef` I get a `java.lang.IllegalArgumentException: graphDef and prefix cannot be null`.\r\nI'm loading the inception graph as a binary file `tensorflow_inception_graph.pb` and passing it to the api like:\r\n\r\n```javascript\r\nvar graph = java.newInstanceSync(\"org.tensorflow.Graph\");\r\nvar builder = java.newInstanceSync(\"org.example.GraphBuilder\", graph);\r\n\r\nconst getBinary = (graphPath, asBuffer = false, cb) => {\r\n    let readStream = fs.createReadStream(graphPath)\r\n    let data = ''\r\n    readStream.setEncoding('binary')\r\n    readStream.once('error', err => {\r\n        return cb(err)\r\n    })\r\n    readStream.on('data', chunk => (data += chunk))\r\n    readStream.on('end', () => {\r\n        return cb(null, asBuffer ? Buffer.from(data, 'binary') : data)\r\n    })\r\n}\r\n\r\ngetBinary(graphPath, true, (error, graphDef) => {\r\n    console.log(\"type is\", typeof(graphDef));\r\n    console.log(\"read graph %d\", graphDef.length);\r\n    graph.importGraphDefSync(graphDef, \"\");\r\n});\r\n```\r\n\r\nThe graph object is loaded by `Node.js` since I can see its bytes length in the logs:\r\nThe output is:\r\n\r\n```bash\r\nTensorflow.getVersion: 1.4.0\r\n2017-11-08 09:59:51.249872: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\r\ntype is object\r\nread graph 53884595\r\n/MyProject/tensorflow/index.js:106\r\n                        graph.importGraphDefSync(graphDef,\"\");\r\n                              ^\r\n\r\nError: Error running instance method\r\njava.lang.IllegalArgumentException: graphDef and prefix cannot be null\r\n\tat org.tensorflow.Graph.importGraphDef(Graph.java:127)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\r\n    at Error (native)\r\n    at getBinary (/MyProject/tensorflow/index.js:106:31)\r\n    at ReadStream.readStream.on (/MyProject/tensorflow/index.js:99:34)\r\n    at emitNone (events.js:91:20)\r\n    at ReadStream.emit (events.js:185:7)\r\n    at endReadableNT (_stream_readable.js:974:12)\r\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\r\n    at process._tickCallback (internal/process/next_tick.js:98:9)\r\n```", "comments": ["Node and node-java bridging isn't officially supported by the TF team. Try asking a question on [Stack Overflow](stackoverflow.com/questions/tagged/tensorflow), which is better suited for problems that are not bugs or feature requests. If you can track this back to a problem isolated within the Java API, please file another issue. Thanks!", "@angersson Yes sir of course I did before posting here, but the response did not help me https://stackoverflow.com/questions/47160365/read-binary-data-with-node-js-stream"]}, {"number": 14354, "title": "Fix estimator convert from Keras to export_savedmodel() #14284", "body": "PR for #14284 \r\n[FIX]the estimator generate by tf.keras.model_to_estimator() cannot export saved_model because the model_fn provided by _create_keras_model_fn wasn't set export_outputs in the returned EstimatorSpec. Here I provide a default export_outputs with serve_default key and Predict API, and the result inside is same as predictions\r\n\r\n[FIX]_save_first_checkpoint call saver.save with only a path and without filename, that make the saved ckpt files with name like `{model_dir}/.meta` and `{model_dir}/.index`, which is not be able to found by latest_checkpoint(\"{model_dir}\"). As state by Saver.save(), save_path should be a path to the checkpoint name. So to fix this, I change the name to `{model_dir}/keras_model.ckpt`", "comments": ["Can one of the admins verify this patch?", "Thanks @yifeif for the review. The PR has been updated with review comments addressed. Please take a look.\r\n", "Thanks @yjmade!"]}, {"number": 14353, "title": "variance goes negative when set layers.batch_norm reuse=True", "body": "#### TF 1.2.1 running on cpu & distributed version\r\n\r\n#### layers.batch_norm set reuse=True\r\nI use a sequence of items features which contains n (feature length) * N (sequence length) real-value features. And do batch_norm on each item of the sequence, then do some full_connected, etc. Finally concat them as dnn input.\r\nHere is a simple code of the this. In order to make variance quickly go negative, I set decay=0.6.\r\n\r\n\timport tensorflow as tf\r\n\tfrom tensorflow.contrib import layers\r\n\timport numpy as np\r\n\t\r\n\tseq_length = 1000\r\n\tbatch = 100\r\n\tlength = 3\r\n\tplace_holders = []\r\n\tseq_raw_f = []\r\n\tfor i in range(seq_length):\r\n\t  x = True if i != 0 else None\r\n\t  sequence_place_holder = tf.placeholder(dtype=tf.float32, shape=[None, length])\r\n\t  place_holders.append(sequence_place_holder)\r\n\t  sequence = layers.batch_norm(inputs=sequence_place_holder, scope=\"bn\", reuse=x, decay=0.6, scale=True,\r\n\t                               # updates_collections=None,\r\n\t                               zero_debias_moving_mean=True)\r\n\t  seq_raw_f.append(sequence)\r\n\t\r\n\tinput = tf.concat(seq_raw_f, axis=0)\r\n\t\r\n\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n\t\r\n\tsess = tf.Session()\r\n\tsess.run(tf.initialize_all_variables())\r\n\t\r\n\tplace_holder = {}\r\n\tfor i in range(seq_length):\r\n\t  place_holder[place_holders[i]] = np.random.rand(batch, length)\r\n\t\r\n\tfor i in range(10000):\r\n\t  sess.run(update_ops, place_holder)\r\n\t  # sess.run(input, place_holder)\r\n\t  print sess.run(\"bn/moving_variance:0\")\r\n\t  \r\n#### variance can be :\r\n\r\n\t[ 0.08063364  0.08680637  0.08229597]\r\n\t[ 0.09141719  0.08313672  0.08208766]\r\n\t[ 0.07279671  0.08088712  0.08174741]\r\n\t[-0.1192904  -0.13598624 -0.31083935]\r\n\t[ 0.24966593  0.26548591  0.16420737]\r\n\t[ 0.07931737  0.07920683  0.0833094 ]\r\n\t[ 0.08559028  0.08299339  0.08146621]\r\n\t[ 0.08117087  0.08168832  0.08265808]\r\n\t\r\n\r\n#### Reason probably the code below. \r\nWhen reuse=True, this code will subtract update_delta many times according to reuse times. Then the formula goes wrong. `a * m_v - (1-a) v -> a * m_v -N * (1-a) v.`\r\n\t\r\n\tupdate_delta = (variable - value) * decay\r\n\treturn state_ops.assign_sub(variable, update_delta, name=scope)\r\n\t\r\nwhen, updates_collections=None,  to force update variance, it still happened.\r\n\r\n#### temporary fix\r\n     \r\n     if not zero_debias:\r\n       # variable * decay + value * (1 - decay)\r\n       state_ops.assign(variable, variable * decay + value * (1 - decay))\r\n\r\n\t\r\n\r\n", "comments": ["@fchollet, can you take a look at this?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "I can reproduce on 1.2 but not on 1.5, so I'm assuming this is fixed and closing.", "Still went wrong when set fused=False. Maybe fused=False has not been corrected implemented.\r\n     \r\n      sequence = layers.batch_norm(inputs=sequence_place_holder, scope=\"bn\", reuse=x, decay=0.1, scale=True,\r\n                               # updates_collections=None,\r\n                               zero_debias_moving_mean=True, fused=False)", "/CC @joel-shor. Note, it's recommended to run with fused=True (the default), where this issue doesn't occur.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I ran the example code, and every line of variance was positive. I'm closing this out unless someone is able to produce buggy code."]}, {"number": 14352, "title": "How can I export the model as serving format?", "body": "# I want to get the serving model format for using server.\r\nTo export estimator m there are four steps:\r\n1.Define estimator's features.\r\n\r\n2.Create a feature config.\r\n\r\n3.Build an export_input_fn suitable for use in serving.\r\n\r\n4.Export the model using export_savedmodel().\r\n\r\n\r\nI try to use \uff1a\r\n    export_dir_base = \"./serving_save_model\"\r\n    feature_spec = {\r\n                    'times': tf.placeholder(tf.float32, name='times')\r\n                    }\r\n    serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n\r\n    estimator.export_savedmodel(export_dir_base, serving_input_fn)\r\n\r\nBut I encountered an error like this:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:/MyProject/Py/tensorFlow_time_series_predict/train_lstm_multivariate.py\", line 231, in <module>\r\n    estimator.export_savedmodel(export_dir_base, serving_input_fn)\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 504, in export_savedmodel\r\n    serving_input_receiver = serving_input_receiver_fn()\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\export\\export.py\", line 142, in serving_input_receiver_fn\r\n    features = parsing_ops.parse_example(serialized_tf_example, feature_spec)\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 577, in parse_example\r\n    [VarLenFeature, SparseFeature, FixedLenFeature, FixedLenSequenceFeature])\r\n  File \"H:\\ProgramFiles\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\", line 291, in _features_to_raw_params\r\n    raise ValueError(\"Invalid feature %s:%s.\" % (key, feature))\r\nValueError: Invalid feature times:Tensor(\"times:0\", dtype=float32).\r\n\r\n\r\nHow should I use it correctly?\r\nThanks so much\uff01\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14351, "title": "memmap changes", "body": "@andrewharp  @martinwicke \r\nHere is the new PR with changes as discussed in 12922\r\n", "comments": ["Can one of the admins verify this patch?", "@martinwicke @andrewharp  Could someone be assigned to review, and we could finish it?", "@andrewharp can you continue to look at this? It's a continuation of another PR.", "@andrewharp I added a check for res/raw and if model file is not in there, check in the assets.  Can you review it please", "@martinwicke can anyone else review it?", "@petewarden can you take a look or find someone who can?", "@martinwicke  What can I do to move this along?", "Sorry, have been on vacation the past couple of weeks. Will take a look as soon as I can.", "@andrewharp I update the file to remove the extension check and try the res/raw first with a fallback to assets.  ", "@cloudbank could you address @andrewharp comments?", "@drpngx  Yes.  I am refactoring.", "Nice, looking forward to the next push!", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@cloudbank any luck with this?", "I have been busy elsewhere.  I will work on it this week.\n\nBest regards,\n\nSabine G. Vogel\n\n\n\n\nOn Wed, Jan 17, 2018 at 10:30 AM, drpngx <notifications@github.com> wrote:\n\n> @cloudbank <https://github.com/cloudbank> any luck with this?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/14351#issuecomment-358397401>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ACLqppLZy1Eq5OnDIbcOCdpaTQQWklRfks5tLjw9gaJpZM4QV-mE>\n> .\n>\n", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @jhseu, @yifeif: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing due to inactivity, but feel free to send a new pull request with the requested changes."]}, {"number": 14350, "title": "Bag of words", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 14349, "title": "The efficiency of data access", "body": "   \r\ndef test_tf():\r\n    with  tf.Session() as sess:\r\n        array=tf.ones([1024,5],dtype=tf.float32) \r\n        t0=time.clock()\r\n        out=0\r\n        for i in range(array.shape[0]):\r\n            out+=array[i]\r\n        out=sess.run([out])\r\n        t1=time.clock()\r\n        print(\"test_tf:\",out,t1-t0)  \r\n     \r\ndef test_np():\r\n    array=np.ones((1024,5),dtype=np.float32)\r\n    print array.shape\r\n    t0=time.clock()\r\n    out=0\r\n    for i in range(array.shape[0]):\r\n        out+=array[i]\r\n    t1=time.clock()\r\n    print(\"test_np:\",out,t1-t0)  \r\n                        \r\nconsole output:\r\n('test_tf:', [array([ 1024.,  1024.,  1024.,  1024.,  1024.], dtype=float32)], 2.395962)\r\n(1024, 5)\r\n('test_np:', array([ 1024.,  1024.,  1024.,  1024.,  1024.], dtype=float32), 0.0008499999999997954)\r\n\r\nhow to speed up the data access?", "comments": ["this may be better for stackoverflow :)"]}, {"number": 14348, "title": "how to use java client to request tensorflow serving for wide&deep model or how to use java to load wide&deep model and predict?", "body": "i have write python client to request wide&deep model by tensorflow serving successful, but i am am doubt how to use java to resolve it, because example and document is too lack", "comments": ["Same as #14346 "]}, {"number": 14347, "title": "Is my code right to use batch normalization layers in tensorflow?", "body": "I have two inputs: `qi_pos & qi_neg` with the same shape. They should be processed by the two mlp layers, and finally get two results which acts as score. Here is my codes:\r\n```\r\n  self.mlp1_pos  =    nn_layers.full_connect_(qi_pos,        256, activation='relu', use_bn = None, keep_prob=self.keep_prob,  name = 'deep_mlp_1')\r\n  self.mlp2_pos  =    nn_layers.full_connect_(self.mlp1_pos, 128,  activation='relu', use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_2')\r\n  self.pos_pair_sim = nn_layers.full_connect_(self.mlp2_pos,  1,  activation=None, use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_3')\r\n  tf.get_variable_scope().reuse_variables()\r\n  self.mlp1_neg  =    nn_layers.full_connect_(qi_neg,        256, activation='relu', use_bn = None, keep_prob=self.keep_prob,  name = 'deep_mlp_1')\r\n  self.mlp2_neg  =    nn_layers.full_connect_(self.mlp1_neg, 128,  activation='relu', use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_2')\r\n  self.neg_pair_sim = nn_layers.full_connect_(self.mlp2_neg,  1,  activation=None, use_bn = True, keep_prob=self.keep_prob,  name = 'deep_mlp_3')\r\n```\r\n\r\nI use BN layer to normalize the nodes in hidden layers:\r\n\r\n```\r\ndef full_connect_(inputs, num_units, activation=None, use_bn = None, keep_prob = 1.0, name='full_connect_'):\r\n  with tf.variable_scope(name):\r\n    shape = [inputs.get_shape()[-1], num_units]\r\n    weight = weight_variable(shape)\r\n    bias = bias_variable(shape[-1])\r\n    outputs_ = tf.matmul(inputs, weight) + bias\r\n    if use_bn:\r\n        outputs_ = tf.contrib.layers.batch_norm(outputs_, center=True, scale=True, is_training=True,decay=0.9,epsilon=1e-5, scope='bn')\r\n    if activation==\"relu\":\r\n      outputs = tf.nn.relu(outputs_)\r\n    elif activation == \"tanh\":\r\n      outputs = tf.tanh(outputs_)\r\n    elif activation == \"sigmoid\":\r\n      outputs = tf.nn.sigmoid(outputs_)\r\n    else:\r\n      outputs = outputs_\r\n    return  outputs\r\n\r\n   with tf.name_scope('predictions'):\r\n      self.sim_diff = self.pos_pair_sim - self.neg_pair_sim # shape = (batch_size, 1)\r\n      self.preds = tf.sigmoid(self.sim_diff) # shape = (batch_size, 1)\r\n      self.infers = self.pos_pair_sim\r\n```\r\n\r\nBelow is the loss definition.It seems all right.\r\n\r\nwith tf.name_scope('predictions'):\r\n  sim_diff = pos_pair_sim - neg_pair_sim\r\n  predictions = tf.sigmoid(sim_diff)\r\n  self.infers = pos_pair_sim\r\n## loss and optim\r\nwith tf.name_scope('loss'):\r\n  self.loss = nn_layers.cross_entropy_loss_with_reg(self.labels, self.preds)\r\n  tf.summary.scalar('loss', self.loss)\r\n\r\nI am not sure whether I have use the BN layers in right way. I mean that the BN parameters are derived from the hidden units from the two separate parts, which are based on qi_pos and qi_neg tensors as inputs. Anyway, anyone could help check it ?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14346, "title": "how to use java client to request tensorflow serving for wide&deep model or how to use java to load wide&deep model and predict?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["i have write python client to request wide&deep model by tensorflow serving successful, but i am am doubt how to use java to resolve it, because example and document is too lack", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14345, "title": "CUBLAS_STATUS_ALLOC_FAILED when attempting to train linear regressor", "body": "### System information\r\n- This is my code.\r\n- Windows 10 x64\r\n- installed tensorflow using pip\r\n- tensorflow-gpu v1.4.0\r\n- Python 3.6.0\r\n- CUDA v8.0, Cudunn v6.0\r\n- EVGA GTX 980 SC ATX 4GB\r\n\r\n### Describe the problem\r\nWhenever I try to train a linear regression network with this dataset, it gives me a CUDA error saying CUBLAS_STATUS_ALLOC_FAILED. I suspect it's not because I'm using too much memory, as when it does occasionally work, it always maxes out my gpu memory usage, no matter what size the network is.\r\nI've included my script and my data file that i ran it with, and a log of the error occurring.\r\n[error.log](https://github.com/tensorflow/tensorflow/files/1452557/error.log)\r\nHere is my source:\r\n[predictlaptimes.txt](https://github.com/tensorflow/tensorflow/files/1452561/predictlaptimes.txt)\r\n(just pretend it's a python file)\r\nAnd here's my data:\r\n[carnumbers.txt](https://github.com/tensorflow/tensorflow/files/1452562/carnumbers.txt)\r\npretend it's a csv file.\r\nGithub won't let me upload .py or .csv files for some reason.\r\n\r\n----\r\n\r\nLooking online I found a solution by changing the allow_growth option to True. I added this line to my code;\r\n\r\n    regressor._session_options.gpu_options.allow_growth = True\r\n\r\nAnd now it runs without any problems.", "comments": ["This looks like it's been resolved, since you posted a solution. If you think others may run into the same problem, consider posting an answered question on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow). Thanks!", "@angersson there is already an answered question: https://stackoverflow.com/questions/47389988/how-to-control-gpu-memory-size-with-tf-estimator."]}, {"number": 14344, "title": "update create_train_op to use get_global_step", "body": "Fixes this warning:\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/training/python/training/training.py:412: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.get_or_create_global_step\r\n```", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 14343, "title": "Add curses install note for Windows in tfdbg docs", "body": "On Windows, using the curses UI with tfdbg is a nicer experience than the suggested readline, so I thought it would be worthwhile to include a note in the documentation about Windows curses installation.", "comments": ["Can one of the admins verify this patch?", "@pvaneck Thanks!"]}, {"number": 14342, "title": "[Feature Request] Add payload only compression support for TFRecord files", "body": "This feature request is a follow up to PR #12369 and issue #12344.\r\n\r\nIssue #12344 raised the feature request of supporting gzipped TFRecord files. However, the compression means the TFRecord file is gzipped as a whole and the header is compressed as well.\r\n\r\nIn certain situations, it might be desirable to expose the header and only compress the payload for better visibility and lookup performance.\r\n\r\nThis issue is a feature request to support payload only compression for TFRecord files.", "comments": ["Thank you very much for adding gzip and zlib to TFRecords. For payload only compression the current option is to add compressed strings to the payload. \r\n\r\nWe currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!", "This issue is related to PR #14599 and related comment is https://github.com/tensorflow/tensorflow/pull/14599#issuecomment-352551762\r\n\r\nWould like to get some feedback from @asimshankar before moving forward. Maybe this issue could be closed as well?", "Yeah, I think that after https://github.com/tensorflow/tensorflow/pull/15132 - we have all the necessary building blocks for this without a feature specific to the TFRecord reader. Thanks!"]}, {"number": 14341, "title": "Add checkpoint file prefix check", "body": "V2 format refers checkpoint files by their file name prefix whereas V1 format refers checkpoint by actual file. I added a check to verify the V2 checkpoint reference is not a file. Also, the return value for saver.save() has changed for V2 so I corrected the doc string. ", "comments": ["Can one of the admins verify this patch?", "Apparently that breaks existing behavior.\r\n\r\n@tedhtchang could you check the tests?", "@drpngx In a freez_graph_test.py log, for example:\r\nhttps://source.cloud.google.com/results/invocations/4266b4b2-9313-48dd-a120-8579baf5a4e6/targets/%2F%2Ftensorflow%2Fpython%2Ftools:freeze_graph_test/log\r\n\r\n```\r\n\"File \"/tmp/botexec/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph_test.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph_test.py\", line 151, in testFreezeGraphV1\r\n    self._testFreezeGraph(saver_pb2.SaverDef.V1)\r\n```\r\nMy code has this logic `if (os.path.isfile(save_path) and self._write_version != saver_pb2.SaverDef.V1)`. I am not sure how `testFreezeGraphV1` test triggers this error. Let me take a look `freeze_graph_test.py` first.", "@drpngx The problem is freez_graph_test.py does not pass [saver_pb2.SaverDef.V1](https://github.com/tensorflow/tensorflow/blob/f99275a6a309699c73e1bbebd89ba9aa32e79aa3/tensorflow/python/tools/freeze_graph_test.py#L151) into freez_graph.py. And in freez_graph.py, it does not explicitly initialize the Saver() to use [write_version=saver_pb2.SaverDef.V1](https://github.com/tensorflow/tensorflow/blob/2ebfeda9bad9d1f867205fa8de3db564953ebc23/tensorflow/python/tools/freeze_graph.py#L103) but still be able to restore a V1 checkpoint file.\r\nWhich solution do you prefer?\r\n1. Drop the testFreezeGraphV1 test since V1 will be deprecated.\r\n2. Introduce additional argument (write_version=saver_pb2.SaverDef.V2) to the freez_test.py\r\n3. Drop this PR ;however people will not get the useful message when passing any V2 checkpoint file to the restore function.", "Option 2 seems to be the best. Thank you!", "@drpngx Two other failed [tests](https://source.cloud.google.com/results/invocations/35acfd09-b536-4b71-b689-aed4f35f81cb/targets/%2F%2Ftensorflow%2Fcontrib%2Fslim:evaluation_test/log), testAdditionalHooks and testRestoredModelPerformance, also have same problem that the Saver is initialized with [write_version=saver_pb2.SaverDef.V1](https://github.com/tensorflow/tensorflow/blob/4cb0c13c7779da536cac6c682180c5757611b384/tensorflow/contrib/slim/python/slim/evaluation_test.py#L239). I will open another PR to remove write_version=saver_pb2.SaverDef.V1 because I believe it is also fine with V2.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@tedhtchang is the other PR fixing a test in this one? We try not to submit PRs that have broken tests, to make it easier to bisect. If that's the case, then please fold the other PR into this one.", "@drpngx I folded other PRs into this one.", "@drpngx is this good to go?", "What I'm saying is that we shouldn't pass the checkpoint version to the `freeze_graph_with_def_protos` that will cause it to *write* in the `V1` format.", "OK on second thoughts actually, this is good.", "@drpngx thanks!", "How am i supposed to use this with the Tensorflow Object Detection API? \r\nThere i have a \"Fine-Tune Checkpoint\" which is an option in the configuration file that points to a single file. I use the Inception v2 Checkpoint from [here](https://github.com/tensorflow/models/tree/master/research/slim) - again, a single file. \r\nPreviously (r1.5) the training worked just fine with that. However, using TF from the current master or r1.6 (which includes this change here, other than r1.5) it only produces the ValueError you raise in saver.py at line 1749. \r\nIs the API simply missing support for this and i should post it there or am i doing it wrong?", "@tedhtchang @drpngx it does look like this may be too restrictive. The inception_v2 checkpoint is a v1 checkpoint, and that should be read automatically without raising an error. \r\n\r\nOn other words, we cannot assume that we read only v2 checkpoints just because we want to write only v2 checkpoints. Removing the check in saver.py should be enough to fix this, the other changes are still good (I think)\r\n\r\n@av8ramit I think this will require a cherry-pick for 1.6 to fix the backwards incompatible change in behavior.", "@gunan who owns the rc1 including cherrypicks.", "Yeah, I didn't realize v1 could also be single files. Sorry. We should simply revert the PR."]}, {"number": 14340, "title": " Fixes for Python3 Raspberry Pi CI Build", "body": "Passes a needed environment variable through to the build script.", "comments": ["Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please.", "Retrying, as we had a breakage.\r\nJenkins, test this please.", "Jenkins, test this please (Mac OS failure seems unrelated)", "Jenkins, test this please.\r\nLinux CPU Tests (Python 3) fails on //bazel_pip/tensorflow/contrib/estimator:replicate_model_fn_test, which seems unrelated to this change.\r\nMacOS CPU Tests times out on //tensorflow/python/kernel_tests:slice_op_test, which also seems unrelated.\r\n", "I think all the above are existing failures. none of them should be related to your change.\r\n"]}, {"number": 14339, "title": "PeriodicResample Op: Fixes #9369 (clean history)", "body": "This is the same PR as #9376 with no CLA issues", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@tensorflow-jenkins test this please.", "Jenkins, test this please. \r\n\r\n(I have merged fixes for these, so everything should pass)", "@jhetherly can you look into the test failures? I left a comment where I thought the cause is.", "Since I can't seem to find my previous comment I'll repeat it here; I've added back the Keras line that mysteriously got deleted in the CMake build. Should work now.", "@tensorflow-jenkins test this please!", "I'm not sure what is causing these failures, but it doesn't seem to have anything to do with my contribution. Could you rerun the tests?", "@tensorflow-jenkins test this please.", "There are some known unrelated failures, I'll look at it when the tests return.", "Jenkins, test this please", "It seems like the issue was a Timeout on a test that appears unrelated to my contribution. Not sure how that could happen.", "Yes, that's a known failure, you can ignore it.", "@jhetherly can you look into the merge conflict", "@sb2nov  fixed", "@sb2nov I don't think these errors are due to any of my code. ", "I just fixed tests on master so will re-run these in a bit and then merge the PR. Sorry about the delay.", "The build died midway, going to try one more time."]}, {"number": 14338, "title": "Branch 174921332", "body": "", "comments": ["Jenkins, test this please!", "Disabled test failing in MacOS/Jenkins. This seems to be an XCode issue, so merging away anyway once sanity confirms my fix isn't breaking everything. "]}, {"number": 14337, "title": "Allow tfcompile_flags to be a list", "body": "This PR is a follow up to #12769 and #14333 to address the issue raised in #12767 so that it is possible to specify the flag with\r\n```\r\ntfcompile_flags = [\"--target_cpu='core-avx2'\", \"--xla_enable_fast_math=false\"]`\r\n```\r\nPreviously it was only possible to specify the flag with:\r\n```\r\ntfcompile_flags = \"--target_cpu='core-avx2' --xla_enable_fast_math=false\"\r\n```\r\n\r\nThis PR will fix #12767.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "/cc @martinwicke", "Thanks!\r\n\r\nJenkins, test this please.", "Jenkins, test this please.", "Re-running GPU only, looks like infra failure.", "GPU rebuild passed: https://ci.tensorflow.org/job/tensorflow-pull-requests-gpu/7410/", "Mac failure unrelated."]}, {"number": 14336, "title": "Disable flaky multinomial_test", "body": "", "comments": ["Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 14335, "title": "MKL: Faster CPU implementation of batch matmul kernel using MKL cblas apis", "body": "", "comments": ["Can one of the admins verify this patch?", "@rmlarsen thanks for the feedback. will get back in a day or two.", "@rmlarsen pushed changes addressing your feedback. please take a look.", "@tensorflow-jenkins test this please\r\n@jbobba thanks for the changes. Looks good!", "@rmlarsen failing on an unrelated issue (hopefully intermittent). can you restart the tests?", "The failing test is unrelated. Merging.", "@jbobba Thanks for the contribution."]}, {"number": 14334, "title": "Float16 not supported by Maxpool3D", "body": "I was trying to switch the training of my neural net to Mixed-precision but while conv/deconv3d layers are supporting the float16 type,  Maxpool3D layers still require a float32 input. Can we expect these to support float16 precision soon?\r\n\r\nThanks!", "comments": ["We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!"]}, {"number": 14333, "title": "Revert \"Allow tfcompile_flags to be a list\"", "body": "Reverts tensorflow/tensorflow#12769, which breaks everything.", "comments": ["@yongtang I have to revert this. I think the test invocation was old. Please reopen? I believe the change is still a good one.", "Thanks @martinwicke. The PR has been created in #14337. Please take a look."]}, {"number": 14332, "title": "Update Android JCenter links", "body": "Looks like the bintray repo was reorganized and the previous references to tensorflow-android now 404. This PR adds working links.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14331, "title": "Added missing parts for uint32 and uint64 support to golang bindings", "body": "Added missing parts for uint32 and uint64 support to golang bindings", "comments": ["Can one of the admins verify this patch?", "Sorry, I was merging oldest first, so the breaking PR was merged first. It's my bad because I didn't wait for the go test. ", "Jenkins, test this please"]}, {"number": 14330, "title": "Add `decode_libsvm` for libsvm format support", "body": "This fix is an effort to add libsvm format support with the implementation of `decode_libsvm`, as was proposed in #14313.\r\n\r\nThe implementation is done in contrib with, e.g.,\r\n```\r\nlabel, feature = tf.contrib.libsvm.decode_libsvm(input, num_features=6)\r\n```\r\n\r\nwhere the input is a string tensor and the output is a tuple of label and feature.\r\n\r\nThe label tensor is the same shape as input. The feature tensor is of the shape `[input_shape, num_features]`.\r\n\r\nThis fix fixes #14313.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for contributing this! One suggestion: since libsvm format is primarily used for representing sparse data, would it make sense for this op to return a `tf.SparseTensor` of features?", "@mrry Thanks for the feedback. Let me take a look and update the PR.", "As said by @mrry, `SparseTensor` for features is really what I need. I am looking forward to the improvement. Thanks for your work, @yongtang. ", "@mrry @facaiy The PR has been updated by returning sparse tensors. Please take a look and let me know if there are any issues.", "Thanks for the review and feedback. The PR has been updated. Please take a look.", "Thanks @mrry for the review. The PR has been updated. Please take a look and let me know if there are any issues.", "@tensorflow-jenkins test this please.", "The PR has been rebased and pushed to resolve the merge conflict.", "All tests passed except `//tensorflow/python/keras:data_utils_test` in ubuntu. The error code is `timeout`. I assume this is unrelated?", "This looks good to merge. I'll kick off the tests one more time to try and get a clean bill of health.\r\n\r\n@tensorflow-jenkins test this please.", "@tensorflow-jenkins test this please", "Thanks all for the help! \ud83d\udc4d \ud83c\udf89 ", "Woohoo! Glad to see this PR land!", "Many thanks, @yongtang !"]}, {"number": 14329, "title": "MKL: Fixing a regression in slice op", "body": "Fixing a build/runtime issue in MKL Slice op caused by another PR.", "comments": ["Can one of the admins verify this patch?", "@gunan can you kick off the test here?", "We have an ongoing breakage right now. As soon as the fix is verified and merged, I can.", "Jenkins, test this please.", "@gunan, is gpu6 the possibly broken worker? \r\n\r\nTrying again...\r\n\r\nJenkins, test this please.", "Could the conv_op_test failure be related? ", "@martinwicke I don't think so since that test is passing on CPU. ", "Confirmed by re-running GPU tests."]}, {"number": 14328, "title": "DataLossError (see above for traceback): corrupted record at 46064268          [[Node: parallel_read/ReaderReadV2_2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](parallel_read/TFRecordReaderV2_2, parallel_read/filenames)]]", "body": "I am trying to train AlexNet from scratch through slim (https://github.com/tensorflow/models/tree/master/research/slim). \r\nMy setup is Python 2.7.12, Tensorflow 1.0.0, in a Linux16.04 system. Below is my error report after 3 hours training.\r\n![screen shot 2017-11-07 at 12 57 15](https://user-images.githubusercontent.com/15274537/32509450-53bbcde2-c3bb-11e7-9dcb-e5fa2eab2783.png)\r\nA similar problem also exists when I train vgg_16 using slim. May I know how to solve this?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Are you kidding me? How on earth this is not a bug??????"]}]