[{"number": 35363, "title": "DCGAN Tutorial in TF Learn results different as in the tutoroial", "body": "Hallo. I am a new learner for deep learning. I tried this DCGAN tutorial from Tensor Flow but the training result is different compared to what is shown in the tutorial website. \r\n\r\nThis is my result:\r\n\r\n![image](https://user-images.githubusercontent.com/36468837/71376946-83e69a80-25c3-11ea-9f77-d9f492a328f0.png)\r\n\r\nBased on the tutorial, it supposed to have a result like this:\r\n![image](https://user-images.githubusercontent.com/36468837/71377054-e5a70480-25c3-11ea-8b08-05226e41465a.png)\r\n\r\nI already tried to run the train several times after it finishes the 50th epoch. But still it didnt show the same result as the tutorial. I appreciate the help to solve this. Thank you\r\n", "comments": ["Hey, there may be something wrong with your training as I trained the same notebook for 50 epochs and getting approx same result as shown in the notebook tutorial\r\n![image](https://user-images.githubusercontent.com/35973532/71428187-38c4a880-26e5-11ea-9aa9-3f8c82053710.png)\r\n", "Animated preview of the trained model is also as per the shown in notebook\r\n![dcgan](https://user-images.githubusercontent.com/35973532/71428225-75909f80-26e5-11ea-914c-757fe249398d.gif)", "Just tried it and the code works as expected. Can you send us the code you tried?", "@fadelkoto \r\nI have tried on colab with TF version 2.1.0-rc1 and i am getting approximately same result as shown in tutorial. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/5f6bd200a1a6363e28c1f3bcf64e8850/untitled500.ipynb). Thanks!", "Hey Guys, thank you for the responses. I checked again my code and I realized that I skipped the code for the image normalization:\r\n\r\ntrain_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\r\n\r\nIt works now after I add the code.\r\nThank you. "]}, {"number": 35362, "title": "TensorFlow building error: C++ compilation of rule '//tensorflow/compiler/mlir/tensorflow:convert_graphdef' failed", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 16.04.6`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `N/A`\r\n- TensorFlow installed from (source or binary): `source`\r\n- TensorFlow version: `2.0.0 (master)`\r\n- Python version: `Python 3.5.2`\r\n- Installed using virtualenv? pip? conda?: `apt`\r\n- Bazel version (if compiling from source): `1.1.0`\r\n- GCC/Compiler version (if compiling from source): `gcc 5.4.0`\r\n- CUDA/cuDNN version: `CUDA 10.2 / cuDNN 7.6.5.32-1+cuda10.2`\r\n- GPU model and memory: `NVIDIA Tesla V100`\r\n\r\n\r\n\r\n**Describe the problem**\r\nObserved after a25c899dcc938c36b2ca8b77393001cd59fd9b97 commit.\r\nTensorFlow building fails with the error:\r\n```\r\n[2019-12-23T02:02:25.156Z] ERROR: /scrap/jenkins/workspace/_ML_DevOps_team/ml-tensorflow-ci-pipeline/tensorflow/tensorflow/compiler/mlir/tensorflow/BUILD:330:1: C++ compilation of rule '//tensorflow/compiler/mlir/tensorflow:convert_graphdef' failed (Exit 1)\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc: In member function 'tensorflow::GraphImportConfig::InputArrays tensorflow::{anonymous}::SavedModelV1Importer::ParseInputArrays(const google::protobuf::Map<std::__cxx11::basic_string<char>, tensorflow::TensorInfo>&)':\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:3015:75: error: no matching function for call to 'std::pair<std::__cxx11::basic_string<char>, tensorflow::ArrayInfo>::pair(<brace-enclosed initializer list>)'\r\n[2019-12-23T02:02:25.156Z]                                                       std::move(array_info)});\r\n[2019-12-23T02:02:25.156Z]                                                                            ^\r\n[2019-12-23T02:02:25.156Z] In file included from /usr/include/c++/5/bits/stl_algobase.h:64:0,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/bits/char_traits.h:39,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/string:40,\r\n[2019-12-23T02:02:25.156Z]                  from ./tensorflow/compiler/mlir/tensorflow/translate/import_model.h:19,\r\n[2019-12-23T02:02:25.156Z]                  from tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:16:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:206:9: note: candidate: template<class ... _Args1, long unsigned int ..._Indexes1, class ... _Args2, long unsigned int ..._Indexes2> std::pair<_T1, _T2>::pair(std::tuple<_Args1 ...>&, std::tuple<_Args2 ...>&, std::_Index_tuple<_Indexes1 ...>, std::_Index_tuple<_Indexes2 ...>)\r\n[2019-12-23T02:02:25.156Z]          pair(tuple<_Args1...>&, tuple<_Args2...>&,\r\n[2019-12-23T02:02:25.156Z]          ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:206:9: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:3015:75: note:   '__gnu_cxx::__alloc_traits<std::allocator<absl::string_view> >::value_type {aka absl::string_view}' is not derived from 'std::tuple<_Elements ...>'\r\n[2019-12-23T02:02:25.156Z]                                                       std::move(array_info)});\r\n[2019-12-23T02:02:25.156Z]                                                                            ^\r\n[2019-12-23T02:02:25.156Z] In file included from /usr/include/c++/5/bits/stl_algobase.h:64:0,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/bits/char_traits.h:39,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/string:40,\r\n[2019-12-23T02:02:25.156Z]                  from ./tensorflow/compiler/mlir/tensorflow/translate/import_model.h:19,\r\n[2019-12-23T02:02:25.156Z]                  from tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:16:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:155:9: note: candidate: template<class ... _Args1, class ... _Args2> std::pair<_T1, _T2>::pair(std::piecewise_construct_t, std::tuple<_Args1 ...>, std::tuple<_Args2 ...>)\r\n[2019-12-23T02:02:25.156Z]          pair(piecewise_construct_t, tuple<_Args1...>, tuple<_Args2...>);\r\n[2019-12-23T02:02:25.156Z]          ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:155:9: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:3014:67: note:   cannot convert 'node_names.std::vector<_Tp, _Alloc>::at<absl::string_view, std::allocator<absl::string_view> >(0ul)' (type '__gnu_cxx::__alloc_traits<std::allocator<absl::string_view> >::value_type {aka absl::string_view}') to type 'std::piecewise_construct_t'\r\n[2019-12-23T02:02:25.156Z]      results.insert(std::pair<std::string, ArrayInfo>{node_names.at(0),\r\n[2019-12-23T02:02:25.156Z]                                                                    ^\r\n[2019-12-23T02:02:25.156Z] In file included from /usr/include/c++/5/bits/stl_algobase.h:64:0,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/bits/char_traits.h:39,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/string:40,\r\n[2019-12-23T02:02:25.156Z]                  from ./tensorflow/compiler/mlir/tensorflow/translate/import_model.h:19,\r\n[2019-12-23T02:02:25.156Z]                  from tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:16:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:150:12: note: candidate: template<class _U1, class _U2, class> constexpr std::pair<_T1, _T2>::pair(std::pair<_U1, _U2>&&)\r\n[2019-12-23T02:02:25.156Z]   constexpr pair(pair<_U1, _U2>&& __p)\r\n[2019-12-23T02:02:25.156Z]             ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:150:12: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:3015:75: note:   '__gnu_cxx::__alloc_traits<std::allocator<absl::string_view> >::value_type {aka absl::string_view}' is not derived from 'std::pair<_T1, _T2>'\r\n[2019-12-23T02:02:25.156Z]                                                       std::move(array_info)});\r\n[2019-12-23T02:02:25.156Z]                                                                            ^\r\n[2019-12-23T02:02:25.156Z] In file included from /usr/include/c++/5/bits/stl_algobase.h:64:0,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/bits/char_traits.h:39,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/string:40,\r\n[2019-12-23T02:02:25.156Z]                  from ./tensorflow/compiler/mlir/tensorflow/translate/import_model.h:19,\r\n[2019-12-23T02:02:25.156Z]                  from tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:16:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:144:12: note: candidate: template<class _U1, class _U2, class> constexpr std::pair<_T1, _T2>::pair(_U1&&, _U2&&)\r\n[2019-12-23T02:02:25.156Z]   constexpr pair(_U1&& __x, _U2&& __y)\r\n[2019-12-23T02:02:25.156Z]             ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:144:12: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:141:38: error: no type named 'type' in 'struct std::enable_if<false, void>'\r\n[2019-12-23T02:02:25.156Z]        template<class _U1, class _U2, class = typename\r\n[2019-12-23T02:02:25.156Z]                                       ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:138:12: note: candidate: template<class _U2, class> constexpr std::pair<_T1, _T2>::pair(const _T1&, _U2&&)\r\n[2019-12-23T02:02:25.156Z]   constexpr pair(const _T1& __x, _U2&& __y)\r\n[2019-12-23T02:02:25.156Z]             ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:138:12: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:3014:67: note:   cannot convert 'node_names.std::vector<_Tp, _Alloc>::at<absl::string_view, std::allocator<absl::string_view> >(0ul)' (type '__gnu_cxx::__alloc_traits<std::allocator<absl::string_view> >::value_type {aka absl::string_view}') to type 'const std::__cxx11::basic_string<char>&'\r\n[2019-12-23T02:02:25.156Z]      results.insert(std::pair<std::string, ArrayInfo>{node_names.at(0),\r\n[2019-12-23T02:02:25.156Z]                                                                    ^\r\n[2019-12-23T02:02:25.156Z] In file included from /usr/include/c++/5/bits/stl_algobase.h:64:0,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/bits/char_traits.h:39,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/string:40,\r\n[2019-12-23T02:02:25.156Z]                  from ./tensorflow/compiler/mlir/tensorflow/translate/import_model.h:19,\r\n[2019-12-23T02:02:25.156Z]                  from tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:16:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:133:12: note: candidate: template<class _U1, class> constexpr std::pair<_T1, _T2>::pair(_U1&&, const _T2&)\r\n[2019-12-23T02:02:25.156Z]   constexpr pair(_U1&& __x, const _T2& __y)\r\n[2019-12-23T02:02:25.156Z]             ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:133:12: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:131:27: error: no type named 'type' in 'struct std::enable_if<false, void>'\r\n[2019-12-23T02:02:25.156Z]        template<class _U1, class = typename\r\n[2019-12-23T02:02:25.156Z]                            ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:128:17: note: candidate: constexpr std::pair<_T1, _T2>::pair(std::pair<_T1, _T2>&&) [with _T1 = std::__cxx11::basic_string<char>; _T2 = tensorflow::ArrayInfo]\r\n[2019-12-23T02:02:25.156Z]        constexpr pair(pair&&) = default;\r\n[2019-12-23T02:02:25.156Z]                  ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:128:17: note:   candidate expects 1 argument, 2 provided\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:127:17: note: candidate: constexpr std::pair<_T1, _T2>::pair(const std::pair<_T1, _T2>&) [with _T1 = std::__cxx11::basic_string<char>; _T2 = tensorflow::ArrayInfo]\r\n[2019-12-23T02:02:25.156Z]        constexpr pair(const pair&) = default;\r\n[2019-12-23T02:02:25.156Z]                  ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:127:17: note:   candidate expects 1 argument, 2 provided\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:124:12: note: candidate: template<class _U1, class _U2, class> constexpr std::pair<_T1, _T2>::pair(const std::pair<_U1, _U2>&)\r\n[2019-12-23T02:02:25.156Z]   constexpr pair(const pair<_U1, _U2>& __p)\r\n[2019-12-23T02:02:25.156Z]             ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:124:12: note:   template argument deduction/substitution failed:\r\n[2019-12-23T02:02:25.156Z] tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:3015:75: note:   '__gnu_cxx::__alloc_traits<std::allocator<absl::string_view> >::value_type {aka absl::string_view}' is not derived from 'const std::pair<_T1, _T2>'\r\n[2019-12-23T02:02:25.156Z]                                                       std::move(array_info)});\r\n[2019-12-23T02:02:25.156Z]                                                                            ^\r\n[2019-12-23T02:02:25.156Z] In file included from /usr/include/c++/5/bits/stl_algobase.h:64:0,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/bits/char_traits.h:39,\r\n[2019-12-23T02:02:25.156Z]                  from /usr/include/c++/5/string:40,\r\n[2019-12-23T02:02:25.156Z]                  from ./tensorflow/compiler/mlir/tensorflow/translate/import_model.h:19,\r\n[2019-12-23T02:02:25.156Z]                  from tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:16:\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:112:26: note: candidate: constexpr std::pair<_T1, _T2>::pair(const _T1&, const _T2&) [with _T1 = std::__cxx11::basic_string<char>; _T2 = tensorflow::ArrayInfo]\r\n[2019-12-23T02:02:25.156Z]        _GLIBCXX_CONSTEXPR pair(const _T1& __a, const _T2& __b)\r\n[2019-12-23T02:02:25.156Z]                           ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:112:26: note:   no known conversion for argument 1 from '__gnu_cxx::__alloc_traits<std::allocator<absl::string_view> >::value_type {aka absl::string_view}' to 'const std::__cxx11::basic_string<char>&'\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:108:26: note: candidate: constexpr std::pair<_T1, _T2>::pair() [with _T1 = std::__cxx11::basic_string<char>; _T2 = tensorflow::ArrayInfo]\r\n[2019-12-23T02:02:25.156Z]        _GLIBCXX_CONSTEXPR pair()\r\n[2019-12-23T02:02:25.156Z]                           ^\r\n[2019-12-23T02:02:25.156Z] /usr/include/c++/5/bits/stl_pair.h:108:26: note:   candidate expects 0 arguments, 2 provided\r\n[2019-12-23T02:02:25.156Z] Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n[2019-12-23T02:02:25.156Z] Use --verbose_failures to see the command lines of failed build steps.\r\n[2019-12-23T02:02:25.156Z] ERROR: /scrap/jenkins/workspace/_ML_DevOps_team/ml-tensorflow-ci-pipeline/tensorflow/tensorflow/lite/toco/python/BUILD:77:1 C++ compilation of rule '//tensorflow/compiler/mlir/tensorflow:convert_graphdef' failed (Exit 1)\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n.tf_configure.bazelrc:\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.5/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_CUDA_VERSION=\"10.2\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TF_NCCL_VERSION=\"2.6.0\"\r\nbuild --action_env TF_CUDA_PATHS=\"/hpc/local/oss/cuda10.2/cuda-toolkit,/usr,/usr/local/cuda\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/hpc/local/oss/cuda10.2/cuda-toolkit\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr\"\r\nbuild --action_env NCCL_INSTALL_PATH=\"<cut>/nccl/stable\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"7.0\"\r\nbuild --action_env LD_LIBRARY_PATH=\"<cut>/nccl/stable/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/nccl_rdma_sharp_plugin/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/ucx/lib/ucx:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/ucx/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/sharp/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/hcoll/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/ompi/lib:/hpc/local/oss/cuda10.2/cuda-toolkit/lib64:/hpc/local/oss/cuda10.2/cuda-toolkit/lib64/stubs:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc-5\"\r\nbuild --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_env=LD_LIBRARY_PATH\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```", "comments": ["It looks like the problem has been fixed - not reproducible within today's nightly testing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35362\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35362\">No</a>\n"]}, {"number": 35361, "title": "geting error in tensorflow for Keras ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Windows 8.1):\r\n- TensorFlow installed from (pip install tensor flow):\r\n- TensorFlow version ():\r\n- Python version:3.8.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n\r\n\r\n**Describe the current behavior**\r\nim using keras for deep learning which use tensorflow as a backend but I try to import the models in keras it gives this error:\r\n\r\nFile \"E:\\Deep\\LSTM_model.py\", line 8, in <module>\r\n    import keras.models\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils\\__init__.py\", line 26, in <module>\r\n    from .vis_utils import model_to_dot\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils\\vis_utils.py\", line 7, in <module>\r\n    from ..models import Model\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\models.py\", line 10, in <module>\r\n    from .engine.input_layer import Input\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\engine\\__init__.py\", line 7, in <module>\r\n    from .network import get_source_inputs\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\engine\\network.py\", line 15, in <module>\r\n    from . import saving\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\engine\\saving.py\", line 35, in <module>\r\n    from tensorflow.python.lib.io import file_io as tf_file_io\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Bilal\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 114\r\n    def TFE_ContextOptionsSetAsync(arg1, async):\r\n                                         ^\r\nSyntaxError: invalid syntax\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nimport xlrd\r\nimport xlwt\r\nimport numpy as np\r\nfrom numpy import *\r\nfrom sklearn.externals import joblib\r\nimport warnings\r\n**from keras.models import * #here it gives error**\r\n\r\n", "comments": ["Its a local error with your system @bilal124 as I dont face any errors on colab [here](https://colab.sandbox.google.com/gist/gowthamkpr/ab71776f7376eb3c217550bdced98aa5/untitled264.ipynb). Try downgrading the version of python to 3.6.  And also try using tensorfow.keres instead of using keras with tensorflow backend as shown [here](https://www.tensorflow.org/api_docs/python/tf/keras). \r\n\r\nI am gonna close this issue as its caused due to your local system and not due to tensorflow. If you have any more questions, please post them of stack overflow. thanks!"]}, {"number": 35360, "title": "[ROCm] Fix for the broken ROCm CSB - 191223", "body": "The following commit breaks the ROCm CSB\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/b32c69cb54595991058c9210ab4f08f6b70030ef\r\n\r\nIt leads to the following runtime error in many tests\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jenkins/workspace/tensorflow-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/config_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1377, in decorated\r\n    if not is_gpu_available():\r\n  File \"/home/jenkins/workspace/tensorflow-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/config_test_gpu.runfiles/org_tensorflow/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/jenkins/workspace/tensorflow-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/config_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1494, in is_gpu_available\r\n    gpu_info = gpu_util.compute_capability_from_device_desc(local_device)\r\n  File \"/home/jenkins/workspace/tensorflow-rocm-nightly/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/config_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/gpu_util.py\", line 56, in compute_capability_from_device_desc\r\n    cc = int(match.group(2)), int(match.group(3)) if match.group(2) else None\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\r\n\r\n```\r\n\r\nThis is because, the way it is written, the `if` check in file `gpu_util.py:56`\r\napplies only to `int(match.group(3))` instead of to the tuple\r\n`int(match.group(2)), int(match.group(3))`, which I believe is the intent here.\r\n\r\nThis results in runtime failures on ROCm platform where `match.group(2)` is indeed `None`\r\n\r\nThe fix is to make the tuple explicit to ensure the if condition is applied as intended\r\n\r\n\r\n---------------------\r\n\r\n/cc @whchung @chsigg \r\n\r\n", "comments": []}, {"number": 35359, "title": "Add Edge Board Support in Arduino Library Build for TFLu (micro)", "body": "Add support for the SparkFun Edge board in the Arduino library build. Allows individuals who are less comfortable with command line tools to get started with TFLu examples. \r\n\r\n**dependencies**\r\n[Update TFLu (micro) to use AmbiqSuite SDK Release 2.2.0 for Apollo3](https://github.com/tensorflow/tensorflow/pull/35236)\r\n[Upgrade Edge Board Support Package in TFLu (micro)](https://github.com/tensorflow/tensorflow/pull/35290)", "comments": ["Currently the solution for providing the various implementations of data providers and result responders is fairly ugly (using Arduino-provided macros to determine what source code is valid). I will make another attempt to use the Makefile and scripts (python / bash) to get additional source files to be copied over. If anyone with experience with those tools want to chime in I am all ears!", "Still having trouble coercing the build to copy additional source files. The desired effect is to make board-specific feature provider and responder files such as:\r\n\r\naudio_provider_arduino_nano33ble.cpp\r\naudio_provider_sparkfun_edge.cpp\r\n\r\nEach file would still use the preprocessor and board-unique macros from Arduino IDE to exclude the implementation when compiled for any other board. ", "Latest commits have gotten this branch working well. All three examples in the generated library can be built for either the Arduino Nano 33 BLE or the SparkFun Edge board simply by selecting the correct board in Arduino IDE", "@oclyke  Can you please check build failures? Thanks!", "@gbaned @petewarden \r\n\r\nThe Ubuntu Sanity check failed in step 2 (pylint) thanks to missing a space after a comma. I expect that the latest commit will resolve the failure. \r\n\r\nHere's the relevant output that clued me in.\r\n\r\n\r\n```\r\n9f8df38c-ci_build_gen_ci_sanity_out-shard1run1attempt1-test.log\r\n\r\n=== Sanity check step 2 of 15: do_pylint (Python 3 pylint) ===\r\n\r\n...\r\n\r\nFAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/lite/micro/tools/make/fix_arduino_subfolders.py:31: [C0326(bad-whitespace), ] Exactly one space required after comma\r\n\r\n...\r\n\r\n==== Summary of sanity check results ====\r\n1. do_configure_test: Run ./configure\r\n  \u001b[0;32mPASS\u001b[0m\r\n2. do_pylint: Python 3 pylint\r\n  \u001b[0;31mFAIL\u001b[0m\r\n3. do_check_futures_test: Check that python files have certain __future__ imports\r\n  \u001b[0;32mPASS\u001b[0m\r\n4. do_buildifier: buildifier check\r\n  \u001b[0;32mPASS\u001b[0m\r\n5. do_bazel_nobuild: bazel nobuild\r\n  \u001b[0;32mPASS\u001b[0m\r\n6. do_bazel_deps_query: bazel query\r\n  \u001b[0;32mPASS\u001b[0m\r\n7. do_pip_package_licenses_check: pip: license check for external dependencies\r\n  \u001b[0;32mPASS\u001b[0m\r\n8. do_lib_package_licenses_check: C library: license check for external dependencies\r\n  \u001b[0;32mPASS\u001b[0m\r\n9. do_java_package_licenses_check: Java Native Library: license check for external dependencies\r\n  \u001b[0;32mPASS\u001b[0m\r\n10. do_pip_smoke_test: Pip Smoke Test: Checking py_test dependencies exist in pip package\r\n  \u001b[0;32mPASS\u001b[0m\r\n11. do_check_load_py_test: Check load py_test: Check that BUILD files with py_test target properly load py_test\r\n  \u001b[0;32mPASS\u001b[0m\r\n12. do_code_link_check: Code Link Check: Check there are no broken links\r\n  \u001b[0;32mPASS\u001b[0m\r\n13. do_check_file_name_test: Check file names for cases\r\n  \u001b[0;32mPASS\u001b[0m\r\n14. do_pip_no_cuda_deps_check_ubuntu: Check Ubuntu gpu pip package does not depend on cuda shared libraries\r\n  \u001b[0;32mPASS\u001b[0m\r\n15. do_pip_no_cuda_deps_check_windows: Check Windows gpu pip package does not depend on cuda shared libraries\r\n  \u001b[0;32mPASS\u001b[0m\r\n\r\n1 failed; 14 passed.\r\n\r\nSanity checks \u001b[0;31mFAILED\u001b[0m\r\n```\r\n", "@gbaned Is there anything I need to do to get the checks to run again? Thanks for your help.", "@oclyke Can you please resolve conflicts? Thanks!", "@gbaned taken care of, thanks!", "@gbaned Is there anything I can do to help move this PR up through the CI queue? We are hoping that we could announce TF Arduino support of the Edge board alongside the 2020 TensorFlow Dev Summit. Thanks!", "@gbaned awesome! What are the next steps in your process? Must the ```import/copybara``` check be completed before a merge?", "> @gbaned awesome! What are the next steps in your process? Must the `import/copybara` check be completed before a merge?\r\n\r\n@oclyke This is waiting for the reviewer approval at this moment. It will be processed further once approved by a reviewer. Thank you!", "@gbaned will the Windows Bazel and Windows Bazel GPU check failures prevent merging? In my two past PRs I believe they did not delay acceptance. I have also contacted Pete W. and Nat J. together for reviews - since Pete has taken care of it I am not sure that Nat is planning to look. May we remove the 'awaiting review' label?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35359) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35359) for more info**.\n\n<!-- ok -->", "@rthadur, @gbaned, @petewarden \r\n\r\nI made quite a blunder committing those changes with my personal email - anyhow I fixed the issue with CLAs and the ```TF_LITE_REPORT_ERROR``` macro is now the only way by which the error reporter is accessed. \r\n\r\nI have verified that the project successfully generates the Arduino library and that the source files compile for both the SparkFun Edge and Arduino Nano 33 BLE. \r\n\r\nI think this means we should be good to go, as long as we re-approve and run CI etc... If there is anything more you need from me please say so. Thanks!", "@oclyke can you please address above review comments ?"]}, {"number": 35358, "title": "Read data from TFRecordDataset throws TensorShape error", "body": "**Describe the current behavior**\r\nI'm trying to save/load a numpy dataset into a TFRecordDataset in TF2.0 for training on TPU. Saving succeeds but when reading the file I and I pass the data through a model I get an error about the shape of the tensors.\r\n\r\nI compared the tensors resulted from reading the TFRecordDataset and they are equal. The dataset I get read back from the file reader is a `MapDataset` instead of a `DatasetV1Adapter`. \r\nI have also opened an issue on stack overflow here: https://stackoverflow.com/questions/59314315/read-data-from-tfrecorddataset-throws-tensorshape-error .\r\n\r\n**Describe the expected behaviour**  \r\nReading the file should result in a dataset identical with the one that was written. Running the dataset through a model should produce similar effects.\r\n\r\n**Code to reproduce the issue** . \r\nA minimum reproducible example is available as a Python notebook here https://gist.github.com/vicpara/3b4ea00553a1990620a2df77d8b6aa1f  .\r\n\r\n**System information**\r\n`tf_env_collect.sh` output:   \r\n```\r\n== check python ===================================================\r\npython version: 3.7.4\r\npython branch: \r\npython build version: ('default', 'Sep 29 2019 19:47:40')\r\npython compiler version: Clang 10.0.1 (clang-1001.0.46.4)\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Darwin\r\nos kernel version: Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64\r\nos release version: 18.7.0\r\nos platform: Darwin-18.7.0-x86_64-i386-64bit\r\nlinux distribution: ('', '', '')\r\nlinux os distribution: ('', '', '')\r\nmac version: ('10.14.6', ('', '', ''), 'x86_64')\r\nuname: uname_result(system='Darwin', node='Viktors-MacBook-Pro.local', release='18.7.0', version='Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64', machine='x86_64', processor='i386')\r\narchitecture: ('64bit', '')\r\nmachine: x86_64\r\n\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 10.0.1 (clang-1001.0.46.4)\r\nTarget: x86_64-apple-darwin18.7.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n== check pips ===================================================\r\nnumpy                    1.17.2              \r\nprotobuf                 3.9.2               \r\ntensorflow               2.0.0               \r\ntensorflow-datasets      1.2.0               \r\ntensorflow-estimator     2.0.0               \r\ntensorflow-metadata      0.14.0              \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.0.0\r\ntf.version.GIT_VERSION = v2.0.0-rc2-26-g64c3d382ca\r\ntf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)\r\n/Users/victor/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\r\n  warnings.warn(msg)\r\n/Users/victor/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\r\n  warnings.warn(msg)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_collect.sh: line 147: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.0.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /Users/victor/.pyenv/versions/3.7.4/lib/python3.7/site-packages\r\nRequired-by: \r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 7, 4, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\n```", "comments": ["@vicpara \r\n\r\nI tried to execute your code with TF 2.0 and was not able to reproduce it.However i tried with TF 2.1.0-rc1 and i am seeing different error message `ValueError: Cannot take the length of shape with unknown rank.`.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/51dd46b75fa2933f579a44d53340e80d/untitled496.ipynb). Thanks!", "@ravikyram How can I help reproducing this error on TF2.0. I am also wondering if I'm using the api incorrectly. Thanks.", "@vicpara \r\nSorry my bad for the typo error.\r\nI am getting the below error message with TF 2.0\r\n`ValueError: as_list() is not defined on an unknown TensorShape.`\r\nI am getting the below error message with 2.1.0-rc1 and 2.1.0-rc2\r\n`ValueError: Cannot take the length of shape with unknown rank`", "duplicate #24520", "i have the same problem.  \r\n\r\ni create TFRecord file to save MNIST image as below:  \r\n```python\r\nwith tf.io.TFRecordWriter(path='./MNIST.tfrecords') as tf_writer:        \r\n    for image, label in zip(x_train, y_train):\r\n        feature = {\r\n            'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(image).numpy()])),\r\n            'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))            \r\n        }\r\n        example = tf.train.Example(features=tf.train.Features(feature=feature))\r\n        tf_writer.write(example.SerializeToString())\r\n```\r\n\r\nthen use ` tf.data.TFRecordDataset` to load the file object.  \r\n\r\n```python\r\ndatasets_tfrecord = tf.data.TFRecordDataset('MNIST.tfrecords')\r\n```\r\n\r\nit's my feature mapping:\r\n```python\r\nfeature_type = {\r\n    'image': tf.io.FixedLenFeature([], tf.string),\r\n    'label': tf.io.FixedLenFeature([], tf.int64)\r\n}\r\n```\r\n\r\nthen set parser function:\r\n```python\r\ndef parser_tfrecord(tfrecord_example):\r\n    _feature = tf.io.parse_single_example(tfrecord_example, feature_type)\r\n    _feature['image'] = tf.io.parse_tensor(_feature['image'], tf.float64)\r\n    return _feature['image'], _feature['label']\r\n```\r\nuse map function:\r\n```python\r\ndatasets = datasets_tfrecord.map(parser_tfrecord)\r\n```\r\n\r\ni try to print shape or show image , and all is fine:\r\n```python\r\nfor image, label in datasets.take(1):\r\n    plt.imshow(image.numpy()[:, :, 0])\r\n    plt.title(label.numpy())\r\nplt.show()\r\n```\r\n\r\nthen structure model:\r\n```python\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\r\n    tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), padding='valid', activation='tanh'),\r\n    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\r\n    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), padding='valid', activation='tanh'),\r\n    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(120, activation='tanh'),\r\n    tf.keras.layers.Dense(84, activation='tanh'),\r\n    tf.keras.layers.Dense(10, activation='softmax'),\r\n])\r\n```\r\nand compile\r\n```python\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\r\n    loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n    metrics=['accuracy']\r\n)\r\n```\r\nfinally, fit the model\r\n```python\r\nmodel.fit(datasets,\r\n          epochs=5, \r\n          steps_per_epoch=int(len(x_train)/128))\r\n```\r\n\r\nget the error message as below:\r\n```python\r\nTrain for 468 steps\r\nEpoch 1/5\r\n  1/468 [..............................] - ETA: 12s\r\n\r\nValueErrorTraceback (most recent call last)\r\n<ipython-input-156-a8a69bd97ab0> in <module>()\r\n----> 1 get_ipython().run_cell_magic(u'time', u'', u'model.fit(datasets,\\n          epochs=5, \\n          steps_per_epoch=int(len(x_train)/128))')\r\n\r\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc in run_cell_magic(self, magic_name, line, cell)\r\n   2115             magic_arg_s = self.var_expand(line, stack_depth)\r\n   2116             with self.builtin_trap:\r\n-> 2117                 result = fn(magic_arg_s, cell)\r\n   2118             return result\r\n   2119 \r\n\r\n</usr/local/lib/python2.7/dist-packages/decorator.pyc:decorator-gen-60> in time(self, line, cell, local_ns)\r\n\r\n/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc in <lambda>(f, *a, **k)\r\n    186     # but it's overkill for just that one bit of state.\r\n    187     def magic_deco(arg):\r\n--> 188         call = lambda f, *a, **k: f(*a, **k)\r\n    189 \r\n    190         if callable(arg):\r\n\r\n/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc in time(self, line, cell, local_ns)\r\n   1187         if mode=='eval':\r\n   1188             st = clock2()\r\n-> 1189             out = eval(code, glob, local_ns)\r\n   1190             end = clock2()\r\n   1191         else:\r\n\r\n<timed eval> in <module>()\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc in _call(self, *args, **kwds)\r\n    492       # In this case we have not created variables on the first call. So we can\r\n    493       # run the first trace but we should fail if variables are created.\r\n--> 494       results = self._stateful_fn(*args, **kwds)\r\n    495       if self._created_variables:\r\n    496         raise ValueError(\"Creating variables on a non-first call to a function\"\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/function.pyc in __call__(self, *args, **kwargs)\r\n   1820   def __call__(self, *args, **kwargs):\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n-> 1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/function.pyc in _maybe_define_function(self, args, kwargs)\r\n   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n   2149         if graph_function is None:\r\n-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n   2151           self._function_cache.primary[cache_key] = graph_function\r\n   2152         return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/function.pyc in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2039             arg_names=arg_names,\r\n   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2041             capture_by_value=self._capture_by_value),\r\n   2042         self._function_attributes,\r\n   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/func_graph.pyc in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    913                                           converted_func)\r\n    914 \r\n--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n    916 \r\n    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc in wrapped_fn(*args, **kwds)\r\n    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    357         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    360 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in distributed_function(input_iterator)\r\n     64     \"\"\"A single step of the distributed execution across replicas.\"\"\"\r\n     65     x, y, sample_weights = _prepare_feed_values(\r\n---> 66         model, input_iterator, mode)\r\n     67     # Call `Model.{train,test,predict}_on_batch` on every replica passing\r\n     68     # PerReplicas as arguments.  On every replica inside this call, each\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in _prepare_feed_values(model, inputs, mode)\r\n    110     for inputs will always be wrapped in lists.\r\n    111   \"\"\"\r\n--> 112   inputs, targets, sample_weights = _get_input_from_iterator(inputs)\r\n    113 \r\n    114   # When the inputs are dict, then we want to flatten it in the same order as\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in _get_input_from_iterator(iterator)\r\n    147   # Validate that all the elements in x and y are of the same type and shape.\r\n    148   dist_utils.validate_distributed_dataset_inputs(\r\n--> 149       distribution_strategy_context.get_strategy(), x, y, sample_weights)\r\n    150   return x, y, sample_weights\r\n    151 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.pyc in validate_distributed_dataset_inputs(distribution_strategy, x, y, sample_weights)\r\n    306   # If each element of x and y are not tensors, we cannot standardize and\r\n    307   # validate the input and targets.\r\n--> 308   x_values_list = validate_per_replica_inputs(distribution_strategy, x)\r\n    309 \r\n    310   if y is not None:\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.pyc in validate_per_replica_inputs(distribution_strategy, x)\r\n    354     if not context.executing_eagerly():\r\n    355       # Validate that the shape and dtype of all the elements in x are the same.\r\n--> 356       validate_all_tensor_shapes(x, x_values)\r\n    357     validate_all_tensor_types(x, x_values)\r\n    358 \r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.pyc in validate_all_tensor_shapes(x, x_values)\r\n    371 def validate_all_tensor_shapes(x, x_values):\r\n    372   # Validate that the shape of all the elements in x have the same shape\r\n--> 373   x_shape = x_values[0].shape.as_list()\r\n    374   for i in range(1, len(x_values)):\r\n    375     if x_shape != x_values[i].shape.as_list():\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/tensor_shape.pyc in as_list(self)\r\n   1169     \"\"\"\r\n   1170     if self._dims is None:\r\n-> 1171       raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\n   1172     return [dim.value for dim in self._dims]\r\n   1173 \r\n\r\nValueError: as_list() is not defined on an unknown TensorShape.\r\n\r\n```\r\n\r\ni am not sure where is wrong, please give me a hand.", "i find, if use `tf.GradientTape()` to get gradient and train model, it's work fine.\r\n\r\nthe same TFRecord, just different training mode.\r\n\r\ndefine loss function and optimizer:\r\n```python\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\r\noptimizer = tf.keras.optimizers.Adam()\r\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\r\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\r\n```\r\nset training step function.\r\n```python\r\ndef train_step(x, y):\r\n    with tf.GradientTape() as tape:\r\n        predictions = model(x)\r\n        loss = loss_object(y, predictions)\r\n    \r\n    gradients = tape.gradient(loss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n    \r\n    train_loss(loss)\r\n    train_accuracy(y, predictions)\r\n```\r\n\r\nset batch size\r\n```python\r\ndatasets = datasets.batch(64)\r\n```\r\n\r\ntraining model\r\n```python\r\nfor epoch in range(1):  \r\n    for x, y in datasets:\r\n        train_step(x, y)\r\n```\r\n\r\nit work fine.\r\n\r\nand i find something interesting.\r\nabove, i set batch one time, and batch size is 64, so the shape is 64x28x28x1\r\n```python\r\nfor x, y in datasets:\r\n    print(x.shape)\r\n    break\r\n\r\n# (64, 28, 28, 1)\r\n```\r\n\r\nif i set batch again, the shape will become 64x64x28x28x1\r\n```python\r\ndatasets = datasets.batch(64)\r\n\r\nfor x, y in datasets:\r\n    print(x.shape)\r\n    break\r\n\r\n# (64, 64, 28, 28, 1)\r\n```\r\n\r\nif set again, it will raise exception. i don't sure it's bug or not.\r\n", "Closing this issue since we are already tracking this with #24520 Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35358\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35358\">No</a>\n", "> ```python\r\n> datasets = datasets.batch(64)\r\n> for x, y in datasets:\r\n>     print(x.shape)\r\n>     break\r\n> ```\r\n>\r\n> if i set batch again, the shape will become 64x64x28x28x1\r\n\r\n`datasets = datasets.batch(64)` doesn't set the batch size. It actually tells the `dataset` object that at runtime it should batch everything you pass through into batches of 64. If you call batch twice then you get the result above. I think the function works as expected.", "> > ```python\r\n> > datasets = datasets.batch(64)\r\n> > for x, y in datasets:\r\n> >     print(x.shape)\r\n> >     break\r\n> > ```\r\n> > \r\n> > \r\n> > if i set batch again, the shape will become 64x64x28x28x1\r\n> \r\n> `datasets = datasets.batch(64)` doesn't set the batch size. It actually tells the `dataset` object that at runtime it should batch everything you pass through into batches of 64. If you call batch twice then you get the result above. I think the function works as expected.\r\n\r\nHi. thanks for your reply.\r\nbut according [tensorflow document](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch)\uff0cit means \u300eCombines consecutive elements of this dataset into batches.\u300f, and the \"batches\" from parameter \"batch_size\", then you get \"batch_size\" return array every time.\r\n\r\nso i think, `datasets = datasets.batch(64)` is set batch size, tell the dataset object every time get how many record for you need.\r\n\r\n![image](https://user-images.githubusercontent.com/28851695/73411053-01c66000-433f-11ea-8a2a-d71c8a09117a.png)\r\n\r\nif call twice get the result is as expected,  why call third time raise exception?but maybe it's not important, for general we wouldn't do such operation.\r\n", "> Closing this issue since we are already tracking this with #24520 Thanks!\r\n\r\nfinally, according #24520 , i modify as bellow..\r\n\r\nparser function\r\n```python\r\ndef parser_tfrecord(tfrecord_example):\r\n    _feature = tf.io.parse_single_example(tfrecord_example, feature_type)\r\n    _feature['image'] = tf.io.parse_tensor(_feature['image'], tf.float64)\r\n   # add this line\r\n    _feature['image'].set_shape((28,28,1))\r\n    return _feature['image'], _feature['label']\r\n```\r\nthen it work fine. thanks for help."]}, {"number": 35357, "title": "tf-lite C++ API giving same inference output for every input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave(v.10.14.5)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n.a.\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): git tag: v1.14.0\r\n- Python version: n.a.\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.12)\r\n- CUDA/cuDNN version: n.a.\r\n- GPU model and memory: n.a.\r\n\r\n**Describe the current behavior**\r\nModel giving same output for every input.\r\n\r\n**Describe the expected behavior**\r\nModel should give different output for different inputs, and outputs of python API and C++ API should match.\r\n\r\n**Code to reproduce the issue**\r\nI want to evaluate tf model in a C++ project.\r\n\r\nI built tf-lite dynamic library using following command\r\n`bazel build -c opt //tensorflow/contrib/lite:libtensorflowLite.so --cxxopt=\"-std=c++11\" --verbose_failures`.\r\n\r\nIn my project's cmake file, I set target_link_library property to `tensorflow/bazel-bin/tensorflow/lite/libtensorflowlite.so`, and I set appropriate header search paths so that my code compiles properly.\r\n\r\nI converted my model to .tflite format via this snippet\r\n```import tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file('model.h5') \r\ntfmodel = converter.convert() \r\nopen(\"model.tflite\", \"wb\").write(tfmodel)\r\n```\r\n\r\nI wrote this code for my model evaluation\r\n```// Load the model\r\nstd::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(\"model.tflite\");\r\n\r\n// Build the interpreter\r\ntflite::ops::builtin::BuiltinOpResolver resolver;\r\nstd::unique_ptr<tflite::Interpreter> interpreter;\r\n\r\ntflite::InterpreterBuilder builder(*model, resolver);\r\nbuilder(&interpreter);\r\ninterpreter->AllocateTensors();\r\n\r\n// Check interpreter state\r\ntflite::PrintInterpreterState(interpreter.get());\r\n\r\nstd::vector<std::vector<double>> tensor;     // I filled this vector, (dims are 2050, 6)\r\n\r\nint input = interpreter->inputs()[0];      // input dims are (1, 2050, 6)\r\nfloat* input_data_ptr = interpreter->typed_input_tensor<float>(input);\r\nfor (int i = 0; i < 2050; ++i) {\r\n    for (int j = 0; j < 6; j++) {\r\n        *(input_data_ptr) = (float)tensor[i][j];\r\n        input_data_ptr++;\r\n    }\r\n}\r\n\r\ninterpreter->Invoke();\r\nint output_idx = interpreter->outputs()[0];\r\nfloat* output = interpreter->typed_output_tensor<float>(output_idx);\r\nstd::cout << \"OUTPUT: \" << *output << std::endl;\r\n```\r\n\r\n```INFO: Initialized TensorFlow Lite runtime.\r\nInterpreter has 96 tensors and 42 nodes\r\nInputs: 10\r\nOutputs: 8\r\n\r\n         < ........................ other layers>\r\nTensor   8 dense_2/Sigmoid      kTfLiteFloat32  kTfLiteArenaRw          4 bytes ( 0.0 MB)  1 1\r\n         < ........................ other layers>\r\nTensor  10 input_1              kTfLiteFloat32  kTfLiteArenaRw      49200 bytes ( 0.0 MB)  1 2050 6\r\n         < ........................ other layers>\r\n\r\nOUTPUT: -3.74034\r\n```\r\nIssue is that I get this same output for all the inputs, and its also wrong as sigmoid should be between 0-1\r\n\r\nTrying evaluation from python yields expected results. I used this snippet to run in python\r\n```import numpy as np\r\nimport tensorflow as tf\r\n\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\nprint(\"INPUT DETAILS: \", input_details)\r\nprint(\"OUTPUT DETAILS: \", output_details)\r\n\r\n# Evaluate\r\ndataset = h5py.File('dataset.h5', 'r')\r\ninput_data1 = np.array(dataset[\"test\"][:])    #shape is (1, 2050, 6)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data1)\r\ninterpreter.invoke()\r\n\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nprint(\"OUTPUT_DATA: \", output_data)\r\n```\r\nThis gives correct output \r\n```\r\nINPUT DETAULS:  [{'name': 'input_1', 'index': 10, 'shape': array([   1, 2050,    6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\r\nOUTPUT DETAILS:  [{'name': 'dense_2/Sigmoid', 'index': 8, 'shape': array([1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\r\n\r\nOUTPUT_DATA [[0.02964767]]\r\n```", "comments": ["This is not a bug, but wrong API usage.\r\n\r\nChanging `typed_input_tensor` to `typed_tensor` and `typed_output_tensor` to `typed_tensor` resolved the issue for me.\r\n\r\nFor anyone else having the same issue, \r\n```\r\nint input_tensor_idx = 0;\r\nint input = interpreter->inputs()[input_tensor_idx];\r\nfloat* input_data_ptr = interpreter->typed_input_tensor<float>(input_tensor_idx);\r\n```\r\nand\r\n```\r\nint input_tensor_idx = 0;\r\nint input = interpreter->inputs()[input_tensor_idx];\r\nfloat* input_data_ptr = interpreter->typed_tensor<float>(input);\r\n```\r\nare identical. \r\n\r\nThis can be verified by looking at implementation of [typed_input_tensor](https://github.com/tensorflow/tensorflow/blob/49f453f1f9d8c878f7d381b7631051995336a264/tensorflow/lite/interpreter.h#L269).\r\n```\r\n  template <class T>\r\n  T* typed_input_tensor(int index) {\r\n    return typed_tensor<T>(inputs()[index]);\r\n  }\r\n```\r\n", "I am facing the same problem right now, I get the output all equal for all the classes no matter what input data I type in, I am using tensorflow 2.3 C++ API, @rishabhrishu I even changed the API as you suggested but still the same! \r\nAnyone any help here! "]}, {"number": 35356, "title": "[TF2.0] String dtype will cause Dateset from MirroredStrategy.experimental_distribute_dataset raise RuntimeError when using GPU.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tf-nightly-gpu\r\n- TensorFlow version (use command below): v1.12.1-20829-ga3bf777 2.1.0-dev20191218\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cudatoolkit=10.0.130 cudnn=7.6.4\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nWhen iterating a dataset which is returned by ```MirroredStrategy.experimental_distribute_dataset``` and contains ```tf.dtypes.string``` elements with GPU, a ```RuntimeError``` will be raised after the last iteration, and it says ```Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.```.\r\n\r\nWhen change to ```OneDeviceStrategy```, everything is fine.\r\n\r\n\r\n**Describe the expected behavior**\r\nIteration over the dataset should end successfully no matter which kind of distribute strategy is used and no matter what kind of dtype elements it contains.\r\n\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\ndistribute_strategy = tf.distribute.MirroredStrategy([\"/gpu:0\"])\r\n## OneDeviceStrategy is fine\r\n#distribute_strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\r\n\r\nds = tf.data.Dataset.from_tensor_slices([[\"A\", \"C\", \"F\"], [\"\", \"D\", \"A\"], [\"B\", \"A\", \"\"]])\r\nds = ds.batch(1)\r\nds = distribute_strategy.experimental_distribute_dataset(ds)\r\n\r\nfor i, inputs in enumerate(ds):\r\n    print(\"step[{}] inputs={}\".format(i, inputs))\r\n```\r\n\r\n\r\n**Other info / logs**\r\n```\r\nWARNING:tensorflow:Falling back to tensorflow client, its recommended to install the cloud tpu client directly with pip install cloud-tpu-client .\r\n2019-12-23 19:13:59.324449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-12-23 19:14:04.348064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:83:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2019-12-23 19:14:04.354811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2019-12-23 19:14:04.357770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2019-12-23 19:14:04.368166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2019-12-23 19:14:04.374694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2019-12-23 19:14:04.395497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2019-12-23 19:14:04.401722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2019-12-23 19:14:04.421294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-23 19:14:09.099740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2019-12-23 19:14:09.101649: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-12-23 19:14:09.120678: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 2097350000 Hz\r\n2019-12-23 19:14:09.177180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55733782fe30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-12-23 19:14:09.177244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-12-23 19:14:09.311769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5573378979c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2019-12-23 19:14:09.311822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN X (Pascal), Compute Capability 6.1\r\n2019-12-23 19:14:09.313461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:83:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2019-12-23 19:14:09.313511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2019-12-23 19:14:09.313527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2019-12-23 19:14:09.313552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2019-12-23 19:14:09.313565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2019-12-23 19:14:09.313579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2019-12-23 19:14:09.313592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2019-12-23 19:14:09.313606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-23 19:14:09.316271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2019-12-23 19:14:09.316310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2019-12-23 19:14:09.318078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-12-23 19:14:09.318110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2019-12-23 19:14:09.318141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2019-12-23 19:14:09.320811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11448 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)\r\nstep[0] inputs=[[b'A' b'C' b'F']]\r\nstep[1] inputs=[[b'' b'D' b'A']]\r\nstep[2] inputs=[[b'B' b'A' b'']]\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 46, in <module>\r\n    for i, inputs in enumerate(ds):\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 249, in __next__\r\n    return self.get_next()\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 281, in get_next\r\n    global_has_value, replicas = _get_next_as_optional(self, self._strategy)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 177, in _get_next_as_optional\r\n    iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 905, in get_next_as_list\r\n    strict=True,\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1207, in cond\r\n    result = false_fn()\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 904, in <lambda>\r\n    lambda: _dummy_tensor_fn(data.value_structure),\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 818, in _dummy_tensor_fn\r\n    return nest.map_structure(create_dummy_tensor, value_structure)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\", line 568, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\", line 568, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\", line 808, in create_dummy_tensor\r\n    dummy_tensor = array_ops.zeros(tensor_shape.TensorShape(dims), feature_type)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 2716, in zeros\r\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\", line 258, in constant\r\n    allow_broadcast=True)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\", line 266, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/home/anaconda3/envs/tf21_nt/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nRuntimeError: Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.\r\n```\r\n", "comments": ["Issue is replicating on colab with Tensorflow 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/f1564399c48a5f0e28eafcbd3ab0979f/untitled321.ipynb). Thanks!", "Duplicate of #30847", "Closing this thread as we have tracker placed to capture this. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35356\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35356\">No</a>\n", "Just tried the code on Tensorflow 2.1 inside a Nvdia NGC docker image `20.03-tf2-py3`, which was released on 3/25/2020. Unfortunately, in both Strategy conditions, I always met the runtime error.\r\n\r\nWhen tested on a local installation (TF 2.1) using pip, `OneDevice` passes while `Mirror` fails.\r\n"]}, {"number": 35355, "title": "Load Image Not RUN", "body": "Yout Tutorial Link: https://www.tensorflow.org/tutorials/load_data/images?hl=ko\r\n\r\nIn Load using tf.data Section Code Error occur....\r\n\r\nmy Tensorflow Version: '2.0.0-beta1'\r\n\r\nCode Here:\r\n```python\r\ndef get_label(file_path):\r\n    parts = tf.strings.split(file_path, os.path.sep)\r\n    tf.print(parts, output_stream=sys.stderr)\r\n    tf.print(parts[-2], output_stream=sys.stderr)\r\n    \r\n    return CLASS_NAMES == parts[-2]\r\n\r\ndef decode_img(img):\r\n    # convert the compressed string to a 3D uint8 tensor\r\n    img = tf.image.decode_jpeg(img, channels=3)\r\n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\r\n    img = tf.image.convert_image_dtype(img, tf.float32)\r\n    # resize the image to the desired size.\r\n    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\r\n\r\ndef process_path(file_path):\r\n    label = get_label(file_path)\r\n    # load the raw data from the file as a string\r\n    img = tf.io.read_file(file_path)\r\n    img = decode_img(img)\r\n    return img, label\r\n\r\n#AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\n# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\r\nlabeled_ds = list_ds.map(process_path)\r\n\r\nfor image, label in labeled_ds.take(3):\r\n    print(\"Image shape: \", image.numpy().shape)\r\n    print(\"Label: \", label.numpy())\r\n```\r\n\r\nThe result is\r\n```code\r\n[\"\" \"root\" \".keras\" ... \"flower_photos\" \"dandelion\" \"17457028309_95514c8d02_n.jpg\"]\r\ndandelion\r\nImage shape:  (224, 224, 3)\r\nLabel:  False\r\n[\"\" \"root\" \".keras\" ... \"flower_photos\" \"roses\" \"5537794501_a0767743fd_n.jpg\"]\r\nroses\r\nImage shape:  (224, 224, 3)\r\nLabel:  False\r\n[\"\" \"root\" \".keras\" ... \"flower_photos\" \"dandelion\" \"4632235020_d00ce1e497.jpg\"]\r\ndandelion\r\nImage shape:  (224, 224, 3)\r\nLabel:  False\r\n```\r\n\r\n**It's Version Mismatch or something wrong**", "comments": ["I assume this is not an error. In my system and on colab, whole tutorial works great. The result you've uploaded is due to two print lines you've put in your `get_label` function. Essentially `parts` contains different parts of location of different images of your datasets. We are only interested in the labels right (apparent from the name of the function `get_label`) , which are names of parent directory of every file. So, for example every file have some name like `16149016979_23ef42b642_m.jpg`  and if it is image of rose then it is stored in `roses` directory.\r\n\r\nNow following line is path to image file stored in list,\r\n`parts = tf.strings.split(file_path, os.path.sep)` \r\n\r\n e.g. if `/home/.keras/datasets/flower-photos/roses/1.png` is location of image, then `parts` will be `[\"\", \"home\", \".keras\", \"datasets\", \"flower-photos\" ,\"roses\", \"1.png\"]`\r\n\r\nSince we are interested in label, we choose `parts[-2]`. Since you are printing parts and parts[-2], you are getting an output out of this print statement every time `get_label` is called(So many lines). So, you just need to remove those two print statements from `get_label`, and code works great. \r\n@wjddyd66 \r\n", "@ruchit2801 \r\nThanks for your answer.\r\nBut there is still a problem.....\r\n\r\nFirst, <code>tf.print()</code> in <code>get_label</code> is just check it works....\r\nI wrote the code again as your answer.\r\n\r\nCode is \r\n```python\r\ndef get_label(file_path):\r\n  # convert the path to a list of path components\r\n  parts = tf.strings.split(file_path, os.path.sep)\r\n  # The second to last is the class-directory\r\n  return parts[-2] == CLASS_NAMES\r\n\r\ndef decode_img(img):\r\n  # convert the compressed string to a 3D uint8 tensor\r\n  img = tf.image.decode_jpeg(img, channels=3)\r\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\r\n  img = tf.image.convert_image_dtype(img, tf.float32)\r\n  # resize the image to the desired size.\r\n  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\r\n\r\ndef process_path(file_path):\r\n  label = get_label(file_path)\r\n  # load the raw data from the file as a string\r\n  img = tf.io.read_file(file_path)\r\n  img = decode_img(img)\r\n  return img, label\r\n\r\n# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\r\nlabeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\r\n\r\nfor image, label in labeled_ds.take(1):\r\n  print(\"Image shape: \", image.numpy().shape)\r\n  print(\"Label: \", label.numpy())\r\n```\r\n\r\nBut the result is \r\n```code\r\nImage shape:  (224, 224, 3)\r\nLabel:  False\r\n```\r\n\r\nIn Upper Code I check  <code>parts[-2]</code> is Flower Directory\r\nAnd Using <code>tf.print</code> Your answer is correct\r\n\r\nSo I Check CLASS_NAMES\r\n```python\r\na = 'tulips'\r\nprint(a == CLASS_NAMES) # [False False False False  True]\r\n```\r\n\r\nWhat is Problem.........\r\nItroduction Output = [False False False False  True]\r\nBut My Code output Just [False]\r\n\r\n![image](https://user-images.githubusercontent.com/37298751/71393074-19c70780-264e-11ea-892b-23d6ce526214.png)\r\n", "@wjddyd66, yes, then it should be a problem. I'm sorry, I did not consider that just `False`, instead of np array of bool labels. I could not reproduce it, works for me. But, just to make sure, you have taken `CLASS_NAMES` as numpy array right? Version I am using is '2.0.0'. ", "@ruchit2801  Hmm.....\r\nYes <code>CLASS_NAMES</code> as numpy array\r\n\r\nHere is My Check Code\r\n```python\r\nprint(tf.__version__)\r\nCLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\r\nprint(CLASS_NAMES)\r\nprint(type(CLASS_NAMES))\r\nprint(type(CLASS_NAMES[0]))\r\n```\r\nThe Result is\r\n```code\r\n2.0.0-beta1\r\n['dandelion' 'sunflowers' 'daisy' 'roses' 'tulips']\r\n<class 'numpy.ndarray'>\r\n<class 'numpy.str_'>\r\n```\r\n<br>\r\n\r\nIn Jupyter Notebook\r\n![image](https://user-images.githubusercontent.com/37298751/71394503-374b9f80-2655-11ea-9384-b93487173871.png)\r\n\r\n", "@wjddyd66 \r\nI have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.However i am not seeing any issue with TF 2.0. Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/2fef781e3672efc80b454acd42e8ddb8/untitled497.ipynb) Thanks!", "@ravikyram, @ruchit2801  \r\nThank you, It resloved...\r\nIt's version probelm.....\r\n\r\nI change Tnesorflow 2.0 beta1 -> Tensorflow 2.0 ... It works!\r\n\r\n![image](https://user-images.githubusercontent.com/37298751/71398149-d62ac880-2662-11ea-90f9-c23caa5257c2.png)\r\n", "/close", "I am closing the issue since its resolved. Thanks!."]}, {"number": 35354, "title": "Contributing a multistep optimizer for training big NNs/batches", "body": "I noticed a high demand in training big NNs/batches is to create a multistep optimizer. This means the optimizer accumulates gradients from batches until it reaches a desire batch and update model parameters. \r\n\r\nThis is similar to [this](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/multistep_optimizer.py), but for file [keras.optimizer_v2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/optimizer_v2.py) instead.\r\n\r\nI can contribute to this. However, I noticed by doing this, the code optimizer_v2.py will need to change a lot. I can create a new similar python file (say, multistep_optimizer_v2.py) to avoid changing in optimizer_v2.py, but the optimizer_v2.py code it self is indeed very long.\r\n\r\nI thus create a discussion here to see whether you (Tensorflow Team and community) feel it is worthy to do so, as well as how to do that, or any better solution for doing that, if there is.\r\n\r\nBest,", "comments": ["FYI: I actually did investigation carefully, and found that we actually don't need to modify optimizer_v2.py at all. We rather just need to create a new optimizer (similar to and could inherit from Adam, RMSProp, SGD, etc).\r\nThis simplifies things a lot, so, again, if you want such a thing, pls let me know.", "Thanks for the report! It might be nice to consider this since we're updating the optimizer interface lately. Would you mind emailing this to developers@tensorflow.org with this idea and see what is the response? We might need a public RFC before implementation.\r\nMeanwhile closing it as this is not a real issue."]}, {"number": 35353, "title": "You tried to call `count_params` on z_input, but the layer isn't built. You can build it manually via: `z_input.build(batch_input_shape", "body": "when saved the model as tf by api  **tf.keras.models.save_model(testmodel, \"./1/\",save_format='tf')**\r\nthen,I load it by tf.keras.models.load_model('1'),however\uff0cI got the issue as title.\r\nIt is worth mentioning that it succed if I saved as .h5\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos7.4\r\n- TensorFlow version (use command below):tensorflow 2.0\r\n- Python version:3.7\r\n-NVIDIA-SMI 418.88\r\n-Driver Version: 418.88\r\n-CUDA Version: 10.1 \r\n- GPU model and memory:12\r\n\r\n", "comments": ["when I change the version to 2.1,it will show:\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (1 total):\r\n    * [<tf.Tensor 'inputs:0' shape=(None, 256, 256, 3) dtype=float32>, <tf.Tensor 'inputs_1:0' shape=(None, 256, 256, 3) dtype=float32>]\r\n  Keyword arguments: {}\r\n\r\nExpected these arguments to match one of the following 1 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (1 total):\r\n    * [TensorSpec(shape=(None, None, None, 512), dtype=tf.float32, name='inputs/0'), TensorSpec(shape=(None, 2, 2, 512), dtype=tf.float32, name='inputs/1')]\r\n  Keyword arguments: {}\r\n", "I use 1.5.0 show same the issue as 2.0", "@JonLeeCSDN ,\r\nCan you please provide code to replicate the issue reported here ?Thanks!", "> @JonLeeCSDN ,\r\n> Can you please provide code to replicate the issue reported here ?Thanks!\u3001\r\n**### train code ref https://tensorflow.google.cn/tutorials/generative/pix2pix**\r\n`from __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nimport  numpy as np\r\nimport os\r\nimport time\r\nfrom tensorflow import keras\r\nfrom matplotlib import pyplot as plt\r\nfrom IPython import display\r\nBUFFER_SIZE = 400\r\nBATCH_SIZE = 1\r\nIMG_WIDTH = 256\r\nIMG_HEIGHT = 256\r\ndef load(image_file):\r\n    image = tf.io.read_file(image_file)\r\n    image = tf.image.decode_jpeg(image)\r\n    w = tf.shape(image)[1]\r\n    w = w // 2\r\n    real_image = image[:,:w, :]\r\n    input_image = image[:, w:, :]\r\n\r\n    input_image = tf.cast(input_image, tf.float32)\r\n    real_image = tf.cast(real_image, tf.float32)\r\n    return input_image, real_image\r\n\r\ndef resize(input_image, real_image, height, width):\r\n    input_image = tf.image.resize(input_image, [height, width],\r\n                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n    real_image = tf.image.resize(real_image, [height, width],\r\n                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n\r\n    return input_image, real_image\r\n\r\ndef random_crop(input_image, real_image):\r\n    stacked_image = tf.stack([input_image, real_image], axis=0)\r\n    cropped_image = tf.image.random_crop(\r\n      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\r\n    return cropped_image[0], cropped_image[1]\r\n\r\ndef normalize(input_image, real_image):\r\n    input_image = (input_image / 127.5) - 1\r\n    real_image = (real_image / 127.5) - 1\r\n\r\n    return input_image, real_image\r\n\r\n\r\n@tf.function()\r\ndef random_jitter(input_image, real_image):\r\n    input_image, real_image = resize(input_image, real_image, 286, 286)\r\n    input_image, real_image = random_crop(input_image, real_image)\r\n\r\n    if tf.random.uniform(()) > 0.5:\r\n        input_image = tf.image.flip_left_right(input_image)\r\n        real_image = tf.image.flip_left_right(real_image)\r\n\r\n    return input_image, real_image\r\n\r\ndef load_image_train(image_file):\r\n    input_image, real_image = load(image_file)\r\n    input_image, real_image = random_jitter(input_image, real_image)\r\n    input_image, real_image = normalize(input_image, real_image)\r\n\r\n    return input_image, real_image\r\ndef load_image_test(image_file):\r\n    input_image, real_image = load(image_file)\r\n    input_image, real_image = resize(input_image, real_image,\r\n                                   IMG_HEIGHT, IMG_WIDTH)\r\n    input_image, real_image = normalize(input_image, real_image)\r\n\r\n    return input_image, real_image\r\nPATH = os.path.join(os.path.dirname('/opt/AI/facades/'), '/opt/AI/facades/')\r\ntrain_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')\r\ntrain_dataset = train_dataset.map(load_image_train,\r\n                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\r\n\r\n\r\ntest_dataset = tf.data.Dataset.list_files(PATH+'val/*.jpg')\r\ntest_dataset = test_dataset.map(load_image_test)\r\ntest_dataset = test_dataset.batch(BATCH_SIZE)\r\n\r\nOUTPUT_CHANNELS = 3\r\n\r\ndef downsample(filters, size, apply_batchnorm=True):\r\n    initializer = tf.random_normal_initializer(0., 0.02)\r\n\r\n    result = tf.keras.Sequential()\r\n    result.add(\r\n      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\r\n                             kernel_initializer=initializer, use_bias=False))\r\n\r\n    if apply_batchnorm:\r\n        result.add(tf.keras.layers.BatchNormalization())\r\n\r\n        result.add(tf.keras.layers.LeakyReLU())\r\n\r\n    return result\r\n    \r\n    \r\ndef upsample(filters, size, apply_dropout=False):\r\n    initializer = tf.random_normal_initializer(0., 0.02)\r\n\r\n    result = tf.keras.Sequential()\r\n    result.add(\r\n    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\r\n                                    padding='same',\r\n                                    kernel_initializer=initializer,\r\n                                    use_bias=False))\r\n\r\n    result.add(tf.keras.layers.BatchNormalization())\r\n\r\n    if apply_dropout:\r\n        result.add(tf.keras.layers.Dropout(0.5))\r\n\r\n    result.add(tf.keras.layers.ReLU())\r\n\r\n    return result\r\n    \r\n    \r\ndef Generator():\r\n    inputs = tf.keras.layers.Input(shape=[256,256,3])\r\n\r\n    down_stack = [\r\n    downsample(64, 4, apply_batchnorm=True), # (bs, 128, 128, 64)\r\n    downsample(128, 4), # (bs, 64, 64, 128)\r\n    downsample(256, 4), # (bs, 32, 32, 256)\r\n    downsample(512, 4), # (bs, 16, 16, 512)\r\n    downsample(512, 4), # (bs, 8, 8, 512)\r\n    downsample(512, 4), # (bs, 4, 4, 512)\r\n    downsample(512, 4), # (bs, 2, 2, 512)\r\n    downsample(512, 4), # (bs, 1, 1, 512)\r\n  ]\r\n\r\n    up_stack = [\r\n    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\r\n    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\r\n    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\r\n    upsample(512, 4), # (bs, 16, 16, 1024)\r\n    upsample(256, 4), # (bs, 32, 32, 512)\r\n    upsample(128, 4), # (bs, 64, 64, 256)\r\n    upsample(64, 4), # (bs, 128, 128, 128)\r\n  ]\r\n\r\n    initializer = tf.random_normal_initializer(0., 0.02)\r\n    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\r\n                                          strides=2,\r\n                                         padding='same',\r\n                                         kernel_initializer=initializer,\r\n                                         activation='tanh') # (bs, 256, 256, 3)\r\n\r\n    x = inputs\r\n\r\n    skips = []\r\n    for down in down_stack:\r\n        x = down(x)\r\n        skips.append(x)\r\n\r\n    skips = reversed(skips[:-1])\r\n    for up, skip in zip(up_stack, skips):\r\n        x = up(x)\r\n        x = tf.keras.layers.Concatenate()([x, skip])\r\n\r\n    x = last(x)\r\n\r\n    return tf.keras.Model(inputs=inputs, outputs=x)\r\n\r\n\r\nLAMBDA = 200\r\n\r\ngenerator = Generator()\r\ntf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\r\n    \r\n\r\ndef generator_loss(disc_generated_output, gen_output, target):\r\n    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\r\n\r\n    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\r\n\r\n    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\r\n\r\n    return total_gen_loss, gan_loss, l1_loss\r\n\r\n\r\ndef Discriminator():\r\n    initializer = tf.random_normal_initializer(0., 0.02)\r\n\r\n    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\r\n    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\r\n\r\n    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\r\n\r\n    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\r\n    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\r\n    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\r\n\r\n    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\r\n    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\r\n                                kernel_initializer=initializer,\r\n                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\r\n\r\n    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\r\n\r\n    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\r\n\r\n    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\r\n\r\n    last = tf.keras.layers.Conv2D(1, 4, strides=1,\r\n                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\r\n\r\n    return tf.keras.Model(inputs=[inp, tar], outputs=last)\r\n    \r\ndiscriminator = Discriminator()\r\ntf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)    \r\nloss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \r\n\r\ndef discriminator_loss(disc_real_output, disc_generated_output):\r\n    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\r\n\r\n    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\r\n\r\n    total_disc_loss = real_loss + generated_loss\r\n\r\n    return total_disc_loss\r\n    \r\ngenerator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\r\ndiscriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)    \r\n    \r\ncheckpoint_dir = './training_checkpoints'\r\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\r\n                                 discriminator_optimizer=discriminator_optimizer,\r\n                                 generator=generator,\r\n                                 discriminator=discriminator)\r\n\r\n\r\ndef generate_images(model, test_input, tar):\r\n    prediction = model(test_input, training=True)\r\n    plt.figure(figsize=(15,15))\r\n\r\n    display_list = [test_input[0], tar[0], prediction[0]]\r\n    title = ['Input Image', 'Ground Truth', 'Predicted Image']\r\n\r\n    for i in range(3):\r\n        plt.subplot(1, 3, i+1)\r\n        plt.title(title[i])\r\n    # getting the pixel values between [0, 1] to plot it.\r\n        plt.imshow(display_list[i] * 0.5 + 0.5)\r\n        plt.axis('off')\r\n    plt.show()\r\n\"\"\"\r\nfor example_input, example_target in test_dataset.take(1):\r\n    generate_images(generator, example_input, example_target)    \r\n\"\"\"    \r\n    \r\n\r\nEPOCHS =30\r\nimport datetime\r\n\r\nlog_dir=\"logs/\"\r\nsummary_writer = tf.summary.create_file_writer(\r\n  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n\r\n\r\nsummary_writer = tf.summary.create_file_writer(\r\n  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n\"\"\"\r\n@tf.function\r\ndef train_step(input_image, target, epoch):\r\n    with tf.GradientTape() as gen_tape, tf.GradientTap() as disc_tape:\r\n        \r\n        gen_output = generator(input_image, training=True)\r\n        disc_real_output = discriminator([input_image, target], training=True)\r\n        disc_generated_output = discriminator([input_image, gen_output], training=True)\r\n        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\r\n        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\r\n        \r\n        print(\"kkkk\")\r\n        generator_gradients = gen_tape.gradient(gen_total_loss,\r\n                                          generator.trainable_variables)\r\n        discriminator_gradients = disc_tape.gradient(disc_loss,\r\n                                               discriminator.trainable_variables)\r\n        \r\n        generator_optimizer.apply_gradients(zip(generator_gradients,\r\n                                          generator.trainable_variables))\r\n        discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\r\n                                              discriminator.trainable_variables))\r\n    print(\"wuwuuwuwu\")\r\n    for inp, tar in test_dataset.take(5):\r\n        generate_images(generator, inp, tar)\r\n\"\"\"\r\n@tf.function\r\ndef train_step(input_image, target, epoch):\r\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n        \r\n        gen_output = generator(input_image, training=True)\r\n        disc_real_output = discriminator([input_image, target], training=True)\r\n        disc_generated_output = discriminator([input_image, gen_output], training=True)\r\n        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\r\n        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\r\n       \r\n        generator_gradients = gen_tape.gradient(gen_total_loss,\r\n                                          generator.trainable_variables)\r\n        discriminator_gradients = disc_tape.gradient(disc_loss,\r\n                                               discriminator.trainable_variables)\r\n        \r\n        generator_optimizer.apply_gradients(zip(generator_gradients,\r\n                                          generator.trainable_variables))\r\n        discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\r\n                                              discriminator.trainable_variables))\r\n\r\n    with summary_writer.as_default():\r\n        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\r\n        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\r\n        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\r\n        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\r\n    print(\"-----\")\r\n    \r\ndef fit(train_ds, epochs, test_ds):\r\n    for epoch in range(epochs):\r\n       \r\n        start = time.time()\r\n        for n,(input_image, target) in train_ds.enumerate():\r\n            print('.', end='')\r\n            if (n+1) % 100 == 0:\r\n                print()\r\n                train_step(input_image, target, epoch)\r\n        print(epoch)\r\n    \r\n        if (epoch + 1) % 30 == 0:\r\n            checkpoint.save(file_prefix = checkpoint_prefix)\r\n        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\r\n                                                        time.time()-start))\r\n    checkpoint.save(file_prefix = checkpoint_prefix)\r\n    tf.keras.models.save_model(generator, \"./1/\",save_format='tf')\r\n    \r\n    for inp, tar in test_dataset.take(1):\r\n        generate_images(generator, inp, tar)                             \r\nfit(train_dataset, EPOCHS, test_dataset)`\r\n\r\n### **load model code:**\r\n`from __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nimport  numpy as np\r\nimport os\r\nimport time\r\n\r\nfrom matplotlib import pyplot as plt\r\nfrom IPython import display\r\nBUFFER_SIZE = 400\r\nBATCH_SIZE = 1\r\nIMG_WIDTH = 256\r\nIMG_HEIGHT = 256\r\n\r\n\r\ndef load(image_file):\r\n    image = tf.io.read_file(image_file)\r\n    image = tf.image.decode_jpeg(image)\r\n    w = tf.shape(image)[1]\r\n    w = w // 2\r\n    real_image = image[:,:w, :]\r\n    input_image = image[:, w:, :]\r\n\r\n    input_image = tf.cast(input_image, tf.float32)\r\n    real_image = tf.cast(real_image, tf.float32)\r\n    return input_image, real_image\r\n\r\ndef resize(input_image, real_image, height, width):\r\n    input_image = tf.image.resize(input_image, [height, width],\r\n                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n    real_image = tf.image.resize(real_image, [height, width],\r\n                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n\r\n    return input_image, real_image\r\n\r\ndef random_crop(input_image, real_image):\r\n    stacked_image = tf.stack([input_image, real_image], axis=0)\r\n    cropped_image = tf.image.random_crop(\r\n      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\r\n\r\n    return cropped_image[0], cropped_image[1]\r\n\r\ndef normalize(input_image, real_image):\r\n    input_image = (input_image / 127.5) - 1\r\n    real_image = (real_image / 127.5) - 1\r\n    return input_image, real_image\r\n\r\n\r\n@tf.function()\r\ndef random_jitter(input_image, real_image):\r\n    input_image, real_image = resize(input_image, real_image, 286, 286)\r\n    input_image, real_image = random_crop(input_image, real_image)\r\n    if tf.random.uniform(()) > 0.5:\r\n    # random mirroring\r\n        input_image = tf.image.flip_left_right(input_image)\r\n        real_image = tf.image.flip_left_right(real_image)\r\n    return input_image, real_image\r\n\r\ndef load_image_train(image_file):\r\n    input_image, real_image = load(image_file)\r\n    input_image, real_image = random_jitter(input_image, real_image)\r\n    input_image, real_image = normalize(input_image, real_image)\r\n\r\n    return input_image, real_image\r\n\r\ndef load_image_test(image_file):\r\n    input_image, real_image = load(image_file)\r\n    input_image, real_image = resize(input_image, real_image,\r\n                                   IMG_HEIGHT, IMG_WIDTH)\r\n    input_image, real_image = normalize(input_image, real_image)\r\n\r\n    return input_image, real_image\r\nPATH = os.path.join(os.path.dirname('/opt/AI/facades/'), '/opt/AI/facades/')\r\ntrain_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')\r\ntrain_dataset = train_dataset.map(load_image_train,\r\n                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\r\ntest_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\r\ntest_dataset = test_dataset.map(load_image_test)\r\ntest_dataset = test_dataset.batch(BATCH_SIZE)\r\nimport numpy as np\r\nimport cv2\r\nfrom tensorflow import keras\r\nnew_model = tf.keras.models.load_model('22')\r\nnew_model.summary()\r\nnum=1\r\ni=0\r\nfor inp, tar in test_dataset.take(num):\r\n    \r\n    print(inp.numpy()[0])\r\n    prediction= new_model.predict(inp.numpy())\r\n    print(prediction)\r\n    tmp=np.ones((256, 256,3))\r\n    prediction=127.5*(prediction+tmp)\r\n    print(prediction[0])\r\n    cv2.imwrite('./md'+str(i)+'.jpg',prediction[0])\r\n    i=i+1\r\n`\r\n", "@JonLeeCSDN ,\r\nThank you for the response, can you please provide a minimal code snippet to reproduce the issue?Thanks!", "@JonLeeCSDN I agree with you. This has already been discussed in the following [comment](https://github.com/tensorflow/tensorflow/issues/33454#issuecomment-544831464). As of now saving the model in `.hdf5 ` format is the way to go.\r\n\r\nSimilar to #33454 ", "@TomatoBoy90 this issue of \"layer not built\" on model loading with TF saved model format should be fixed starting TF 2.2.0 verison.  the corresponding issue #33454 has been marked as fixed. Can you please try with a TF version after 2.2.0  ?", "Has anyone solved this?", "@TomatoBoy90 @LeparaLaMapara Can you please share a standalone code to reproduce the issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35353\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35353\">No</a>\n"]}, {"number": 35352, "title": "Go TensorFlow 1.15.0: DataType 20 is not supported", "body": "**System information**\r\n\r\n- OS Platform and Distribution : mcOS HighSierra Version 10.13.2\r\n- TensorFlow version: 1.15.0\r\n\r\nTried to load model from python (TF 2) on my go (TF 1.15.0) and i got error when accessing the value of the result. The error message I got was:\r\n\r\n`panic: BUG: Please report at https://github.com/tensorflow/tensorflow/issues with the note: Go TensorFlow 1.15.0: DataType 20 is not supported (see https://www.tensorflow.org/code/tensorflow/core/framework/types.proto)`\r\n\r\nis there any solution for this?", "comments": ["@hamdimuzakkiy \r\nRequest you to provide simple standalone code to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 35351, "title": "Adding an support for python 3.8 version", "body": "I am not sure about this change , but can we simply give support on 3.8 version by making this small change?", "comments": []}, {"number": 35350, "title": "Fix for compute_capability_from_device_desc on AMD cards", "body": "At present, compute_capability_from_device_desc causes an unhandled error on AMD cards.\r\nI am seeing the following:\r\n\r\nphysical_device_desc is \"device: 0, name: Vega 20, pci bus id: 0000:2b:00.0\"\r\nmatch.groups() is (u'Vega 20', None, None)\r\n\r\nWhich results in int(match.group(2)) throwing a \"TypeError: int() argument must be a string or a number, not 'NoneType'\".\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35350) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35350) for more info**.\n\n<!-- need_author_cla -->", "@ekuznetsov139  thank you for your contribution, please sign CLA.", "I probably need to be on the AMD corporate CLA, I'll check how to get on it", "Duplicate of PR #35360 ", "@googlebot I fixed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35350) for more info**.\n\n<!-- ok -->"]}, {"number": 35349, "title": "Return predictions with .evaluate()", "body": "I work with several custom metrics I compute from model's inference-mode predictions; problem is, this requires me to hand-code loss computation to avoid running `.evaluate()` along `.predict()` (doubling validation time), which may include weight and activity regularizers. \r\n\r\nIt'd be quite helpful to have an option for `model.evaluate()` to return predictions along computed metrics (e.g. `evaluate(return_predictions=True)`).\r\n\r\n*NOTE*: this is a **feature request**, concerning the [`evaluate`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training.py#L730) method of `keras.Model` or `tf.keras.Model`.", "comments": ["@OverLordGoldDragon, Could you provide the Tensorflow version that you are using and also provide if any code snippet. Thanks!", "@gadagashwini This is a feature request, not a bug report - `model` is a `keras.Model` or a `tensorflow.keras.Model` instance, which has the `evaluate()` method defined [here](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training.py#L730)", "Thank you for the request @OverLordGoldDragon. We do not plan to add this to the built in loops. You can implement this in a custom evaluate loop by keeping track of the batch prediction values. "]}, {"number": 35348, "title": "Added Usage Example for MobileNetV2", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35348) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@akalakheti thank you for your contribution, please sign CLA.", "@gbaned I have already signed the CLA but i don't know why it's not showing in here", "@googlebot I signed it! "]}, {"number": 35347, "title": "Unnecessary synchronization of deterministic variable in Mirrored Distributed mode", "body": "**System information**\r\n* Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n* TensorFlow installed from (source or binary): binary\r\n* TensorFlow version (use command below): v2.1.0-rc0-47-g064e153 2.1.0-rc1 (python3 -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\")\r\n* Python version: Python 3.6.8\r\n* CUDA/cuDNN version: Driver Version: 440.33.01, CUDA Version: 10.2, cuDNN 7.6.2\r\nGPU model and memory: Tesla V100-SXM2-16GB\r\n\r\n**Describe the current behavior**\r\nI have a custom implementation of spectral normalization:\r\nhttps://github.com/olegmyrk/SPADE-Tensorflow/blob/4203f30b6253a9d4743962087896fab26381c67b/ops.py#L579\r\n\r\nIt defines a non-trainable variable\r\n```\r\nu = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.compat.v1.random_normal_initializer(), trainable=False, aggregation=tf.compat.v2.VariableAggregation.ONLY_FIRST_REPLICA)\r\n```\r\nthat is used for power iteration\r\nhttps://en.wikipedia.org/wiki/Power_iteration\r\nIt is updated using deterministic computation (ie it depends only on weight matrix, but not batch inputs) at each gradient step:\r\nhttps://github.com/olegmyrk/SPADE-Tensorflow/blob/4203f30b6253a9d4743962087896fab26381c67b/ops.py#L606\r\n\r\nCurrently in mirrored distributed mode this adds a very expensive synchronization step for this variable.\r\n\r\nI could set \r\n```\r\naggregation=tf.compat.v2.VariableAggregation.NONE\r\n```\r\nbut that doesn't work in distributed mode, according to manual:\r\nhttps://www.tensorflow.org/api_docs/python/tf/VariableAggregation\r\n> NONE: This is the default, giving an error if you use a variable-update operation with multiple replicas.\r\n\r\nAdditionally it takes ~40 minutes to build the graph with spectral normalization in distributed mirrored mode (with multiple GPUs) as opposed to 20 minutes without spectral normalization enabled.\r\n\r\nAlthough this might be a generic issue related to slow AutoGraph in Mirrored Distributed mode:\r\nhttps://github.com/tensorflow/tensorflow/issues/35346\r\n\r\n**Describe the expected behavior**\r\nI need to specify that there is no need to synchronize this variable as it has the same deterministic value on all replicas.\r\n\r\n**Code to reproduce the issue**\r\nhttps://github.com/olegmyrk/SPADE-Tensorflow/blob/4203f30b6253a9d4743962087896fab26381c67b/ops.py#L606\r\n\r\n**Other info / logs**\r\nUsing `NCCL_DEBUG=INFO NCCL_DEBUG_SUBSYS=ALL`:\r\n\r\n*Without spectral norm*\r\nINFO:tensorflow:batch_all_reduce: 219 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 1058 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 2150 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 4402 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\n\r\nINFO:tensorflow:batch_all_reduce: 219 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 1058 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 2150 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 4402 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\n\r\n*With spectral norm*\r\nINFO:tensorflow:batch_all_reduce: 459 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 1666 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 2662 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 6610 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\n\r\nINFO:tensorflow:batch_all_reduce: 459 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 1666 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 2662 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 6610 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10", "comments": ["olegmyrk@ Can you create a variable with synchronization=ON_READ and aggregation=ONLY_FIRST_REPLICA? This will allow you to create variables that are not synchronized every time you update them. They are called SyncOnRead variables and are synchronized when you read the variable. By specifying ONLY_FIRST_REPLICA you can ensure that you only read from the first device. An example of this can be found in TF [metrics](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py#L245). It uses a different aggregation though. ", "Do you think it will help if I read and update the variables on every training step? It's just that the variables are deterministic functions of network weights, but not inputs. So I'd rather compute the variables on each GPU separately without ever syncing them. Hopefully it is also better for GPU memory usage. Not sure how it works with checkpointing though.", "olegmyrk@ Using MirroredVariables with ONLY_FIRST_REPLICA should have resulted in a broadcast of values from the first replica to all other replicas when you called `u.assign(u_hat)`. Using SyncOnRead variables will help you avoid this broadcast of values. However I think I am not sure how this is resulting in additional allreduce calls. Are we increasing the number of trainable variables somehow or taking additional gradients? can we confirm that the set of trainable variables remain the same?", "Thanks, this resolved this issue for me.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35347\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35347\">No</a>\n", "@olegmyrk How did you resolve the additional allreduce calls? Did you have additional trainable variables?", "I just applied your suggested change and empirically I don't see performance issues with spectral norm anymore. To be fair I also did a bunch of other changes in between. Anyway, thanks!", "@olegmyrk Thanks for responding and letting me know. Glad the issue is fixed!"]}, {"number": 35345, "title": "Usage examples", "body": "", "comments": ["[@kyscg](https://github.com/kyscg) Please what else is needed for this PR to be merged?", "We need a review from @alextp first. Maybe after the hols? I don't know", "Okay and thanks for your reply", "@yashk2810  please is there any other thing that I need to do before this PR can be merged?  ", "@mihaimaruseac are the changes okay?\r\n", "Can you please resolve conflicts and rebase on master?", "> Can you please resolve conflicts and rebase on master?\r\n\r\n@mihaimaruseac Ya I have resolved the conflicts", "This will get rolled back as it breaks internal tests\r\n\r\n```\r\nFailed example:\r\n    tf.image.rgb_to_yuv(image)\r\nExpected:\r\n    <tf.Tensor: shape=(3, 2, 3), dtype=float32, numpy=\r\n    array([[[ 1.815     ,  0.5831516 , -0.7149856 ],\r\n          [ 4.815     ,  0.5831516 , -0.7149855 ]],\r\n         [[ 7.815     ,  0.5831516 , -0.7149856 ],\r\n          [10.815001  ,  0.5831518 , -0.7149852 ]],\r\n         [[13.815001  ,  0.58315134, -0.7149857 ],\r\n          [16.815     ,  0.58315134, -0.7149854 ]]], dtype=float32)> \r\nGot:\r\n    <tf.Tensor: shape=(3, 2, 3), dtype=float32, numpy=\r\n    array([[[ 1.815     ,  0.5831516 , -0.7149856 ],\r\n            [ 4.815     ,  0.5831516 , -0.7149856 ]],\r\n\r\n           [[ 7.815     ,  0.5831516 , -0.7149856 ],\r\n            [10.815001  ,  0.58315134, -0.7149854 ]],\r\n\r\n           [[13.815     ,  0.58315134, -0.7149856 ],\r\n            [16.815     ,  0.58315134, -0.7149854 ]]], dtype=float32)>\r\n```", "@mihaimaruseac That should be because of the spacing between the arrays right?"]}, {"number": 35344, "title": "Added usage examples to some APIs", "body": "Added usage examples to these APIs\r\n- image.random_flip_up_down\r\n- image.flip_up_down\r\n- image.random_flip_left_right\r\n- image.flip_left_right\r\n- image.transpose\r\n- image.random_brightness\r\n- image.random_contrast\r\n- image.random_hue\r\n- image.random_jpeg_quality\r\n- image.random_saturation", "comments": ["Please reopen against master, not against release branches"]}, {"number": 35343, "title": "Is it a bug with tf.cond?", "body": "Greetings,\r\n\r\nI have a code that uses tf.conds as follows:\r\n\r\nimport tensorflow as tf\r\n\r\n```\r\ndef func():\r\n\taa = 0\r\n\tdef abc():\r\n\t\taa = [0]\r\n\t\treturn tf.convert_to_tensor(True, dtype=bool)\r\n\tdef ghi():\r\n\t\tb = aa[0]\r\n\t\treturn tf.convert_to_tensor(False, dtype=bool)\r\n\treturn a = tf.cond(tf.convert_to_tensor(True, dtype=bool), abc(), ghi())\r\na = func()\r\n```\r\n\r\nI suppose function ghi() should not be run (as it should runs func abc()). But somehow the code there is still running, resulting in an error of 'int' object is not subscriptable (from b = aa[0]).\r\n\r\nIs it a bug? If not, could you explain more about this?\r\n\r\nThx.", "comments": ["Closed after some investigation. While tf.cond is great, it is indeed a bit counterintuitive!"]}, {"number": 35342, "title": "Support other types of Tensors in tf.data.Dataset.from_generator", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.15.2 (19C57)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- **Python version**:3.7.5 (default, Oct 25 2019, 18:18:54) \\n[Clang 11.0.0 (clang-1100.0.33.8)]\r\n\r\n### Describe the problem\r\n\r\n`tf.data.Dataset` supports RaggedTensor and SparseTensor but `tf.data.Dataset.from_generator` is limited to Tensors only. Please support other types of Tensors. \r\n\r\n### Source code / logs\r\n\r\n```\r\n    def data_get():\r\n        for i in range(5):\r\n            yield tf.ragged.constant([[i, i], [i]])\r\n\r\n    ds = tf.data.Dataset.from_generator(data_get, tf.int32)\r\n\r\n    for sample in ds:\r\n        print(sample)\r\n```\r\n\r\nproduces:\r\n\r\nTraceback (most recent call last):\r\n\r\n```\r\n  File \"/Users/peak/IdeaProjects/TFmodels/venv-tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 221, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/Users/peak/IdeaProjects/TFmodels/venv-tf2/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 606, in generator_py_func\r\n    \"element was %s.\" % (dtype.name, ret))\r\n\r\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was <tf.RaggedTensor [[0, 0], [0]]>.\r\n```\r\n\r\n\r\n", "comments": ["This would indeed be useful. My preference for the API would be to add an optional `output_spec` argument which -- when set -- would be used in place of `output_types` and `output_shapes` to identify the output signature of the generator.\r\n\r\nThis is also a good candidate for external contribution as it is narrowly scoped, so I am marking it as \"contributions welcome\".", "Hey! I would love to work on this. Any guidance would be appreciated.", "Is anyone working on this? If not, I would like to work on this", "@SSaishruthi I'm trying to work on it at the moment.", "This is supported in tf 2.5 (maybe 2.4?) with the output_signature argument of from_generator", "@JulesGM yes", "@gowthamkpr @jsimsa We implemented and merged this, so this issues can be closed )"]}, {"number": 35341, "title": "'ImportError' object has no attribute '_render_traceback_'", "body": "\u4f7f\u7528 jupyter \u65f6\u5019\u62a5\u9519\uff0c\r\n\r\nimport tensorflow as tf\r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-8eea31c9b10b>\", line 2, in <module>\r\n    tf.keras.datasets.mnist.load_data(path='mnist.npz')\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 1495, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 1453, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-8eea31c9b10b>\", line 2, in <module>\r\n    tf.keras.datasets.mnist.load_data(path='mnist.npz')\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-8eea31c9b10b>\", line 2, in <module>\r\n    tf.keras.datasets.mnist.load_data(path='mnist.npz')\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2037, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 1495, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 1453, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-8eea31c9b10b>\", line 2, in <module>\r\n    tf.keras.datasets.mnist.load_data(path='mnist.npz')\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2037, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2033                         # in the engines. This should return a list of strings.\r\n-> 2034                         stb = value._render_traceback_()\r\n   2035                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3334             if result is not None:\r\n   3335                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3336             self.showtraceback(running_compiled_code=True)\r\n   3337         else:\r\n   3338             outflag = False\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2035                     except Exception:\r\n   2036                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2037                                             value, tb, tb_offset=tb_offset)\r\n   2038 \r\n   2039                     self._showtraceback(etype, value, stb)\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1383         self.tb = tb\r\n   1384         return FormattedTB.structured_traceback(\r\n-> 1385             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1386 \r\n   1387 \r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1286             # Verbose modes need a full traceback\r\n   1287             return VerboseTB.structured_traceback(\r\n-> 1288                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1289             )\r\n   1290         elif mode == 'Minimal':\r\n\r\nD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1148         exception = self.get_parts_of_chained_exception(evalue)\r\n   1149         if exception:\r\n-> 1150             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1151             etype, evalue, etb = exception\r\n   1152         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str\r\n", "comments": ["@miaoweiwei, Looks like Tensorflow has not installed properly. \r\nBelow are the instructions to install Tensorflow 2.0 using PIP\r\n\r\n```\r\n#Install tensorflow using pip virtual env \r\n$pip install virtualenv\r\n$virtualenv tf_2.0.0   # tf_2.0.0 is virtual env name\r\n$source tf_2.0.0/bin/activate\r\ntf_2.0.0 $ pip install tensorflow==2.0.0\r\ntf_2.0.0 $ python\r\n>>import tensorflow as tf\r\n>>tf.__version__\r\n2.0.0\r\n```\r\nPlease let us know how it progresses. Thanks!", "@miaoweiwei, Is this still an issue!", "That's done. Thanks", "Whenever I imported these always the same issue\r\nimport os\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.image as mpimg\r\nfrom keras.models import Sequential\r\nfrom keras.optimizers import Adam\r\nfrom keras.layers import Convolution2D,Dense,MaxPooling2D,Dropout,Flatten\r\nimport cv2\r\nfrom sklearn.utils import shuffle\r\nfrom sklearn.model_selection import train_test_split\r\nimport pandas as pd\r\nimport random\r\nimport ntpath\r\n\r\n\r\n\r\nERROR : \r\n\r\nTensorFlow backend.\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-2d022dbfbc26>\", line 5, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-2d022dbfbc26>\", line 5, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-2d022dbfbc26>\", line 5, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3342, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2042, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-2d022dbfbc26>\", line 5, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3342, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2042, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Saheel Bobde\\Anaconda\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n~\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2038                         # in the engines. This should return a list of strings.\r\n-> 2039                         stb = value._render_traceback_()\r\n   2040                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n~\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3340             if result is not None:\r\n   3341                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3342             self.showtraceback(running_compiled_code=True)\r\n   3343         else:\r\n   3344             outflag = False\r\n\r\n~\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2040                     except Exception:\r\n   2041                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2042                                             value, tb, tb_offset=tb_offset)\r\n   2043 \r\n   2044                     self._showtraceback(etype, value, stb)\r\n\r\n~\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1383         self.tb = tb\r\n   1384         return FormattedTB.structured_traceback(\r\n-> 1385             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1386 \r\n   1387 \r\n\r\n~\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1286             # Verbose modes need a full traceback\r\n   1287             return VerboseTB.structured_traceback(\r\n-> 1288                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1289             )\r\n   1290         elif mode == 'Minimal':\r\n\r\n~\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1148         exception = self.get_parts_of_chained_exception(evalue)\r\n   1149         if exception:\r\n-> 1150             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1151             etype, evalue, etb = exception\r\n   1152         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str", "Why this issue is closed? I can't see the solution here and the error's raising."]}, {"number": 35340, "title": "infer profiler_outdir for tf.summary.trace_export from SummaryWriter", "body": "First of all, I want to thank everyone who develops tensorflow.\r\nI really like tensorflow because it is very easy to use and powerful.\r\n\r\n---\r\n`trace_export` is required to set `profiler_outdir`.\r\nHowever, in many cases the `profiler_outdir` and the directory set by `tf.summary.create_file_writer` are the same.\r\nSo, I thought that if the `SummaryWriter` was set, it should use the `logdir` set here.\r\nplease confirm.", "comments": []}, {"number": 35339, "title": "Tensorflow-lite gpu output is corrupted when using opencl backend", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android version:9, Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: OnePlus3, GPU:Adreno 530\r\n- TensorFlow installed from (source or binary): tensorflow-lite-gpu 1.15, tensorflow-lite-gpu:0.0.0-nightly from 'https://mvnrepository.com'\r\n- TensorFlow version (use command below): 1.14, 1.15\r\n\r\n\r\n**Describe the current behavior**\r\nI'm using tflite-gpu in my android application for semantic segmentation. Using my tflite model(all gpu supported ops) i'am able to get proper output with CPU version and tensorflow-lite-gpu 1.14 ;but when i use nightly or 1.15 it loads up opencl backend and gives corrupted output. This backend seems to take longer time to start up(5-10s); however it seems to be faster than corresponding opengl version. When i run the model to get a image output (float:0-1) there seems to be random rectangular blanks within the output. The input is 256x256x3(float) and output os 256x256x1(float). However.  i 'am not facing this issue using a different model with input size 128; even though i use the same back-end.\r\n**Describe the expected behavior**\r\nThe tflite model should produce correct output with opencl backend like the  opengl version, regardless of input size.\r\n\r\n**Other info / logs**\r\nI'am getting correct output for model with 128 input size regardless of backends and devices; but for the model with 256 output size i'am not getting proper output with opencl backend (gpu-nightly and gpu-1.15)\r\n[Models.zip](https://github.com/tensorflow/tensorflow/files/3992313/Models.zip)\r\n\r\nOnly the '**opencl gpu delegate with this 256 input sized-model**' produces this corrupted output; other versions (CPU, Opengl-GPU, 128 input-model with Opencl etc.) seems to produce correct result without the rectangular blanks.\r\n![tmap54](https://user-images.githubusercontent.com/1130185/71320296-57515680-24cf-11ea-8c26-66f62c948e94.PNG)\r\n", "comments": ["I forwarded this to our OpenCL engineer.  He's looking.", "Btw, I spy 3 black rectangles (1 in the background).  Is it always the same location, or is it random?", "Hm, we cannot reproduce this bug with Adreno 530 (Samsung S7 Edge; sorry, we don't have OnePlus3).  Do you see this on every frame or only occasionally?", "It appears randomly on most of the frames. I'am able to run it at around 12 fps using opencl backend.The phone uses OxygenOS 9.0.6 and is based on android Pie.These rectangles appears  in both  foreground and background regions of the segmentation map(the 'prisma-trinet.tflite' 'model does portrait segmentation) .Also, is it normal for the model to take this much time for initialization?", "@anilsathyan7 \r\n\r\nEngineer suspects some problems in GPU/CPU synchronization when fetching output.  Unfortunately, he wasn't able to reproduce the problem on his device and is now on vacation until mid Jan.  Do you have the luxury of checking things on another device?\r\n\r\nBy the way, I heard your network has transpose convs in them.  There's been a commit 020e0de6b0c6741acae0735c41f9dff463230aa8 which should speed things up a bit.", "Sure, i will check it on other devices. Currently i'am using java float array of shape [1][257*257] to get the flattened output from model. I also saw the recent android [support library](https://github.com/tensorflow/tensorflow/blob/764a3ab93ac7425b49b9c13dc151bc9c2f2badf6/tensorflow/lite/experimental/support/java/README.md) that tf has released, for handling I/O. Is it still in development phase or can we use it for  production?\r\n\r\nThanks", "@anilsathyan7 \r\n\r\nWhile I don't have experience with the android support library you linked, things under experimental  are... well... experimental.\r\n\r\nThe APIs and/or implementation details may change, and in worst case, they may not survive experimental and may be killed.  In that sense, I wouldn't say it's safe to use it for production.  But if you're willing to eat up that development cost, go ahead :P  Sorry for not being able to give you a definitive answer there; I'm not directly part of the TFLite org and don't know their plans at the sub project level.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35339\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35339\">No</a>\n"]}, {"number": 35338, "title": "add usage example to vgg16.py", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35338) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35338) for more info**.\n\n<!-- ok -->"]}, {"number": 35337, "title": "ValueError: name for name_scope must be a string when Building up a Custom Model", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nHi,\r\n\r\nI tried to follow tf's doc to build up a model as follows:\r\nhttps://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n\r\n`\r\n\t\t\t\t\t\r\n\tclass CBR(layers.Layer):\r\n\t\t'''\r\n\t\tConvolution + Batch normalisation + Relu\r\n\t\t'''\r\n\t\tdef __int__(self, filterNum, kSize, strSize, padMode, name='cbr', **kwargs):\r\n\t\t\tsuper(CBR, self).__init__(name=name, **kwargs)\r\n\t\t\tself.conv3D = layers.Conv3D(filters=filterNum, kernel_size=kSize, strides=strSize, padding=padMode, data_format='channels_first')\r\n\t\t\tself.BN = layers.BatchNormalization(axis=1)\r\n\t\tdef call(self, inputs):\r\n\t\t\tx = self.conv3D(inputs)\r\n\t\t\tx=self.BN(x)\r\n\t\t\treturn layers.Relu(x)\r\n\t\t\t\r\n\tclass SimpleUNet(tf.keras.Model, layers.Layer):\r\n\t\t'''\r\n\t\tSerialise basic units so as to build up a double-layered encoder-decoder U-Net\r\n\t\tInput:\r\n\t\t\tinDim: [mbSize, modaility/channel, tensor dimensions]\r\n\t\t\tclassNum: background included\r\n\t\t\tname: name for the net\r\n\t\t\tinputs: 5D tf tensor of [mbSize, modaility/channel, tensor dimensions]. Inputs must be organised into channel first\r\n\t\tReturns:\r\n\t\t\toutputs: 5D tf tensor of [mbSize, classNum, tensor dimensions]\r\n\t\t'''\r\n\t\tdef __init__(self, inDim, classNum, name='SimpleUNet', **kwargs):\r\n\t\t\tsuper(SimpleUNet, self).__init__(name=name, **kwargs)\r\n\t\t\tself.inDim = inDim\r\n\t\t\tself.classNum = classNum\r\n\t\t\tdimEnSt1End = np.array(inDim[1:])-2-2\r\n\t\t\tdimEnSt2Ed = dimEnSt1End/2-2-2\r\n\t\t\tdimBridgeEnd = (dimEnSt2Ed/2-2-2)*2\r\n\t\t\tdimDEStd1End = (dimBridgeEnd-2-2)*2\r\n\t\t\toutDim = dimDEStd1End-2-2-2\r\n\t\t\ttemp = ((dimEnSt2Ed - dimBridgeEnd)/2).astype('int32')\r\n\t\t\tcrop3d1 = tuple(np.tile(temp, (2, 1)).T)\r\n\t\t\ttemp = ((dimEnSt1End - dimDEStd1End)/2).astype('int32')\r\n\t\t\tcrop3d2 = tuple(np.tile(temp, (2, 1)).T)\r\n\t\t\t# list of basic units used in the model\r\n\t\t\tself.en_st1_cbr1 = CBR(32, 3, 1, 'valid')\r\n\t\t\tself.en_st1_cbr2 = CBR(64, 3, 1, 'valid')\r\n\t\t\tself.en_st2_mp = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', data_format='channels_first')\r\n\t\t\tself.en_st2_cbr1 = CBR(64, 3, 1, 'valid')\r\n\t\t\tself.en_st2_cbr2 = CBR(128, 3, 1, 'valid')\r\n\t\t\tself.bridge_mp = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', data_format='channels_first')\r\n\t\t\tself.bridge_cbr1 = CBR(128, 3, 1, 'valid')\r\n\t\t\tself.bridge_cbr2 = CBR(256, 3, 1, 'valid')    \r\n\t\t\tself.bridge_tconv1 = layers.Conv3DTranspose(256, 2, strides=2, padding='valid', data_format='channels_first')\r\n\t\t\tself.de_3dcrop1 = layers.Cropping3D(crop3d1, data_format='channels_first')\r\n\t\t\tself.de_st1_cbr1 = CBR(256, 3, 1, 'valid')\r\n\t\t\tself.de_st1_cbr2 = CBR(128, 3, 1, 'valid')    \r\n\t\t\tself.de_st1_tconv1 = layers.Conv3DTranspose(128, 2, strides=2, padding='valid', data_format='channels_first')\r\n\t\t\tself.de_3dcrop2 = layers.Cropping3D(crop3d2, data_format='channels_first')\r\n\t\t\tself.de_st2_cbr1 = CBR(64, 3, 1, 'valid')\r\n\t\t\tself.de_st2_cbr2 = CBR(64, 3, 1, 'valid') \r\n\t\t\tself.final_conv3D = layers.Conv3D(filters=self.classNum, kernel_size=3, strides=1, padding='valid', data_format='channels_first')\r\n\t\t\t\t\t\r\n\t\tdef call(self, inputs):\r\n\t\t\tx = self.en_st1_cbr1(inputs)\r\n\t\t\txEnSt1End = self.en_st1_cbr2(x)\r\n\t\t\tx= self.en_st2_mp(xEnSt1End)\r\n\t\t\tx= self.en_st2_cbr1(x)\r\n\t\t\txEnSt2Ed = self.en_st2_cbr2(x)\r\n\t\t\tx = self.bridge_mp(xEnSt2Ed)\r\n\t\t\tx = self.bridge_cbr1(x)\r\n\t\t\tx = self.bridge_cbr2(x)\r\n\t\t\txBridgeEnd = self.bridge_tconv1(x)\r\n\t\t\txCrop1 = self.de_3dcrop1(xEnSt2Ed)\r\n\t\t\tx = layers.Concatenate([xBridgeEnd, xCrop1], axis=1)\r\n\t\t\tx = self.de_st1_cbr1(x)\r\n\t\t\tx = self.de_st1_cbr2(x)\r\n\t\t\txDeSt1End = self.de_st1_tconv1(x)\r\n\t\t\txCrop2 = self.de_3dcrop2(xEnSt1End)\r\n\t\t\tx = layers.Concatenate([xDeSt1End, xCrop2], axis=1)\r\n\t\t\tx = self.de_st2_cbr1(x)\r\n\t\t\tx = self.de_st2_cbr2(x)\r\n\t\t\tx = self.final_conv3D(x)\r\n\t\t\toutputs = activations.softmax(x, axis=1)\r\n\t\t\t\r\n\t\t\treturn outputs\r\n\r\n`\r\n\r\nThen I initialised it, and tried to build it by calling SUNet.build\r\n`\r\n\tclassNum = 3 \r\n\tmbSize = 16 \r\n\tinDim = [4, 64, 64, 64] \r\n\tSUNet = SimpleUNet(inDim, classNum) \r\n\tSUNet.build(input_shape=inDim)\r\n`\r\nI strictly followed the example given in tf's doc, but an error was raised when building up it\r\nValueError: name for name_scope must be a string.\r\nIt occurred here when CBR is called for the first time:\r\n\r\n`\r\ndef __int__(self, filterNum, kSize, strSize, padMode, name='cbr', **kwargs): \r\n\tsuper(CBR, self).__init__(name=name, **kwargs)\r\n`\r\n\r\nI cannot figure out any syntactic mistake. Could anyone give me a hand? Thanks a lot.\r\nOr, is the model cannot be built at this moment until it is actually used when being called in the training?", "comments": ["@yourtheron Can you please provide simple standalone code to reproduce the issue? Thanks!", "@jvishnuvardhan Sure. The following is a fairly simple class of TestNet invovling class CBR\r\n\r\n`\r\n\t\tfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\t\timport functools\r\n\r\n\t\timport numpy as np\r\n\t\timport tensorflow as tf\r\n\t\tfrom tensorflow.keras import layers, activations\r\n\r\n\t\tclass CBR(layers.Layer):\r\n\t\t\t\"\"\"Convolution + Batch normalisation + Relu\"\"\"\r\n\t\t#    def __int__(self, filterNum, kSize, strSize, padMode):\r\n\t\t\tdef __int__(self, filterNum, kSize, strSize, padMode, name='cbr', **kwargs):\r\n\t\t\t\tsuper(CBR, self).__init__(name=name, **kwargs)\r\n\t\t\t\tself.conv3D = layers.Conv3D(filters=filterNum, kernel_size=kSize, strides=strSize, padding=padMode, data_format='channels_first')\r\n\t\t\t\tself.BN = layers.BatchNormalization(axis=1)\r\n\t\t\tdef call(self, inputs):\r\n\t\t\t\tx = self.conv3D(inputs)\r\n\t\t\t\tx=self.BN(x)\r\n\t\t\t\treturn activations.relu(x)\r\n\r\n\t\tclass TestNet(tf.keras.Model):\r\n\t\t\tdef __init__(self, inDim, classNum, name='testNet', **kwargs):        \r\n\t\t\t\tsuper(TestNet, self).__init__(name=name, **kwargs)\r\n\t\t\t\tself.inDim = inDim\r\n\t\t\t\tself.classNum = classNum\r\n\t\t\t\tself.en_st1_cbr1 = CBR(32, 3, 1, 'valid')\r\n\t\t\tdef call(self, inputs):\r\n\t\t\t\tx = layers.Input(shape=self.inDim)\r\n\t\t\t\tx = self.en_st1_cbr1(x)\r\n\t\t\t\toutputs = activations.softmax(x, axis=1)        \r\n\t\t\t\treturn outputs\r\n\t\t\t\r\n\r\n\t\tclassNum = 2\r\n\t\tinDim = [4, 64, 64, 64]\r\n\t\tTNet = TestNet(inDim, classNum)\r\n\t\t# Whethere calling build() or call(), the bug occurs\r\n\t\tTNet.build(input_shape=inDim)\r\n\t\tTestSignal = tf.random.uniform((10, 4, 64, 64, 64))\r\n\t\tTNet.call(TestSignal)\r\n`", "@jvishnuvardhan I think I found a work-around. If I do not define CBR as a custom layer class as paraphrased in the tf's doc, but a custom model instead, it works. But it might still be better to figure out why defining it as a layer class does not, thanks.\r\n```\r\n\t\tclass C3BR(tf.keras.Model):\r\n\r\n\t\t\tdef __init__(self, filterNum, kSize, strSize, padMode):\r\n\t\t\t\tsuper(C3BR, self).__init__()\r\n\t\t\t\tself.conv = layers.Conv3D(filters=filterNum, kernel_size=kSize, strides=strSize, padding=padMode, data_format='channels_first')\r\n\t\t\t\tself.BN = layers.BatchNormalization(axis=1)\r\n\t\t\t\r\n\t\t\tdef call(self, inputs):\r\n\t\t\t\tx = self.conv(inputs)\r\n\t\t\t\tx= self.BN(x)\r\n\t\t\t\treturn activations.relu(x)\r\n```", "Getting the same error.", "In case this helps someone, I was getting the same error because I removed a no-longer-required positional argument (integer) from my custom model's `__init__` signature without updating the code that instantiated the model. In practice, the integer was getting passed to the only remaining argument: the `name=` kwarg.\r\n\r\nI think it's not the same problem OP is experiencing but probably related. I notice that in the working tf.keras.Model subclass version there is no longer a 'name' kwarg. I would also check the contents of **kwargs, and check what is being passed to the super(CBR, self).__init__(name=name).", "@yourtheron,\r\nCould you please update TensorFlow to v2.3 and check if you are still facing the same issue. \r\n\r\nAlso, please take a look at @cboulay's workaround and let us know if it helps. Thanks!", "@amahendrakar\r\nIf I run the simple code I posted on 24/12/2019 on tf 2.3, Windows 7, Python 3.8.3, the error occurred on the following line\r\n`\r\nsuper(TestNet, self).__init__(name=name, **kwargs)\r\n`\r\nThen the error info reads\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 244, in _variable_v2_call\r\n    return previous_getter(\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2633, in default_variable_creator_v2\r\n    return resource_variable_ops.ResourceVariable(\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 1507, in __init__\r\n    self._init_from_args(\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 1661, in _init_from_args\r\n    handle = eager_safe_variable_handle(\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 242, in eager_safe_variable_handle\r\n    return _variable_handle_from_shape_and_dtype(\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 174, in _variable_handle_from_shape_and_dtype\r\n    gen_logging_ops._assert(  # pylint: disable=protected-access\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 49, in _assert\r\n    _ops.raise_from_not_ok_status(e, name)\r\n\r\n  File \"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n\r\n  File \"<string>\", line 3, in raise_from\r\n\r\nInvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse\r\n\r\nWhether I use\r\n`\r\nsuper(TestNet, self).__init__()\r\n`\r\nor\r\n`\r\nsuper(TestNet, self).__init__(name=name)\r\n`\r\nThe error remains the same.\r\nIn tf2.0, that line of code worked at least.", "@amahendrakar \r\n`\r\nsuper(TestNet, self).__init__()\r\n`\r\nworks in tf 2.1, Python 3.7.7 though, together with the workaround in CBR above,\r\n", "@yourtheron,\r\nIn order to expedite the trouble-shooting process, could you please provide the latest minimal reproducible code which you are running.\r\n\r\n>works in tf 2.1, Python 3.7.7 though, together with the workaround in CBR above,\r\n\r\nAlso, could you please check if the same works with TF v2.3 and TF-nightly. Thanks!", "@amahendrakar \r\nIt is just the code I posted in this thread on 26/12/2019", "Running the code with [TF v2.3](https://colab.sandbox.google.com/gist/amahendrakar/4066bf4a3a843684e96e2397c92af2d5/35337-2-3.ipynb) throws an error stating \r\n`ValueError: You cannot build your model by calling build if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).`\r\n\r\nWhereas, on running the code with [TF-nightly](https://colab.sandbox.google.com/gist/amahendrakar/18b82e148ec042801c9fa2aea2525379/35337-tf-nightly.ipynb#scrollTo=gYM2rfzl4v1S), the error is\r\n`NotImplementedError: Please run in eager mode or implement the compute_output_shape method on your layer (CBR).`\r\n\r\nPlease find the attached gist. Thanks!", "@amahendrakar When I ran it with tf2.3, those errors I printed above have occurred after the following line was executed.\r\n`\r\nTNet = TestNet(inDim, classNum)\r\n`\r\nbefore the building stage.\r\n\r\n\r\nBy the way, I applied a work-around as follows. The same error as I gave persists.\r\n\r\n`\r\n\timport numpy as np\r\n\timport tensorflow as tf\r\n\tfrom tensorflow.keras import layers, activations\r\n\r\n\tclass CBR(layers.Layer):\r\n\t\tdef __int__(self, filterNum, kSize, strSize, padMode, **kwargs):\r\n\t\t\tsuper(CBR, self).__init__(**kwargs) \r\n\t\t\tself.conv = layers.Conv3D(filters=filterNum, kernel_size=kSize, strides=strSize, padding=padMode, data_format='channels_first') \r\n\t\t\tself.BN = layers.BatchNormalization(axis=1)\r\n\t\tdef call(self, inputs):\r\n\t\t\tx = self.conv(inputs)\r\n\t\t\tx=self.BN(x)\r\n\t\t\treturn activations.relu(x)\r\n\t\t\r\n\t\tdef build_model(self, input_shape):\r\n\t\t\r\n\t\t\t''' A work-around to define dimensions of signals through the NN'''\r\n\t\t\tself.build(input_shape)\r\n\t\t\tinputs = tf.keras.Input(shape=input_shape[1:])\r\n\t\t\t_ = self.call(inputs) \r\n\t\t\t\r\n\t\t\t\r\n\tclass TestNet(tf.keras.Model):\r\n\t\tdef __init__(self, inDim, classNum, **kwargs):        \r\n\t\t\tsuper(TestNet, self).__init__(**kwargs)\r\n\t\t\tself.inDim = inDim\r\n\t\t\tself.classNum = classNum\r\n\t\t\tself.en_st1_cbr1 = CBR(32, 3, 1, 'valid')\r\n\t\tdef call(self, inputs):\r\n\t\t\tx = layers.Input(shape=self.inDim)\r\n\t\t\tx = self.en_st1_cbr1(x)\r\n\t\t\toutputs = activations.softmax(x, axis=1)        \r\n\t\t\treturn outputs\r\n\t\t\r\n\t\tdef build_model(self, input_shape):\r\n\t\t\t''' A work-around to define dimensions of signals through the NN'''\r\n\t\t\tself.build(input_shape)\r\n\t\t\tinputs = tf.keras.Input(shape=input_shape[1:])\r\n\t\t\t_ = self.call(inputs) \t\r\n\r\n\tclassNum = 2\r\n\tinDim = [4, 64, 64, 64]\r\n\tTNet = TestNet(inDim, classNum)\r\n\t# Whethere calling build() or call(), the bug occurs\r\n\tTNet.build_model(input_shape=((1,) + tuple(inDim)))\r\n\r\n`\r\n", "Running the code on colab with TF 2.6.0-dev20210606 throws the error stating\r\n`NotImplementedError: Please run in eager mode or implement the compute_output_shape method on your layer (CBR)`,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/19da9e3d073fb24d94e6f981e85992a0/untitled220.ipynb#scrollTo=mvnkn7P5BHVG)..Thanks !", "Hi @yourtheron .I think  I found a typo  here  in this line                                                                                                                     \r\n  ` def __int__(self, filterNum, kSize, strSize, padMode, name='cbr', **kwargs):  `                                                                                Was able to resolve the issue with TF v2.5 and v2.3 `after replacing __int__ with __init__ `,please find the gist [here ](https://colab.research.google.com/gist/mohantym/6d92241371703e7957b3141fa6c71bdb/35337.ipynb).Thanks!", "@mohantym Got it, thanks a lot!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35337\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35337\">No</a>\n"]}, {"number": 35336, "title": "No clear document explains how to use pre-trained model", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/applications\r\n\r\n## Description of issue (what needs changing):\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 in Docker\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: 10.0 / 7\r\n- GPU model and memory: GTX 1080Ti / 11175MiB\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nHi authors and developers,\r\n\r\nI noticed that tensorflow doesn't provide a clear document explain how to use pre-trained model.\r\n\r\nSo, I wrote a benchmark which showed the accuracy of pre-trained model with applying imageNet' validation set.\r\n\r\nThe following is the result:\r\n\r\n```\r\n[Testing][pixel vales are from (0,255)][model:ResNet50] - loss: 2.711 - accuracy: 0.457\r\n[Testing][pixel vales are from (0,255)][model:DenseNet121] - loss: 39.000 - accuracy: 0.006\r\n[Testing][pixel vales are from (0,255)][model:MobileNetV2] - loss: 9.979 - accuracy: 0.003\r\n\r\n[Testing][pixel vales are from (0,1)][model:ResNet50] - loss: 8.535 - accuracy: 0.001\r\n[Testing][pixel vales are from (0,1)][model:DenseNet121] - loss: 1.895 - acc: 0.599\r\n[Testing][pixel vales are from (0,1)][model:MobileNetV2] - loss: 2.283 - accuracy: 0.523\r\n\r\n[Testing][pixel vales are normalized from (-1,1)][model:ResNet50] - loss: 8.313 - acc: 0.001\r\n[Testing][pixel vales are normalized from (-1,1)][model:DenseNet121] - loss: 1.896 - acc: 0.599\r\n[Testing][pixel vales are normalized from (-1,1)][model:MobileNetV2] - loss: 2.287 - acc: 0.524\r\n\r\n```\r\n\r\nFirst, we can see the accuracy is not comparable with the original result(Top-1 accuracy is 70% up).\r\n\r\nI thought that this issue is I'm not sure which crop and pad method is applied in the original result.\r\n\r\nTherefore, I defined a custom function `CenterCrop` to fit the model's input size.\r\n\r\nBut, we can skip this issues there.\r\n\r\nWhat I want to mention is normalization issue.\r\n\r\nIf I don't apply any normalization(run_aug=1 in code), pixel's values are defined in **(0, 255)**.\r\n\r\nAll models' accuracy are near 0.001, except for resNet50 which achieves a meaningful accuracy.\r\n\r\nIf I do normalization(run_aug=2 in code), pixel's values are defined in **(0, 1)**.\r\n\r\nThis time, DenseNet121 and MobileNetV2 have a meaningful accuracy.\r\n\r\nIf I do standard normalization(run_aug=3 in code), pixel's values are defined in **(-1, 1)**.\r\n\r\nThe results are similar to previous case. But I'm sure why those two cases have same accuracy.\r\n\r\nThose behavior let me confused.\r\n\r\nBefore applying pre-trained model, I have to which normalization method should be applied.\r\n\r\nAfter reading the source code, I found that those applications are import from `keras_application` in `tensorflow`.\r\n\r\n[keras-applications](https://github.com/keras-team/keras-applications)\r\n\r\n[weight download](https://github.com/fchollet/deep-learning-models)\r\n\r\n---\r\n\r\nI didn't test other models, such as `ResNet50V2`, `InceptionV3` and `Xception` because their input size are `299` instead of `244` and this is a time consuming task.\r\n\r\nHowever, anyone can modify the test case and do the benchmark.\r\n\r\n---\r\n\r\nBecause of licence issue for ImageNet, I can't provide imagenet in public.\r\n\r\nBut the following is the minimal test case:\r\n\r\n```python\r\n# pip install tensorflow-gpu==1.14.0\r\n# pip pandas\r\n#%%\r\nimport time\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nfrom glob import glob\r\n\r\n#%%\r\n# input image dimensions\r\nimg_h = 224\r\nimg_w = 224\r\nchannels = 3\r\n\r\n# information for dataset\r\ndataset_path = \"dataset-imagenet/\"\r\nnum_classes = 1000\r\nnum_testing = 50000\r\n\r\n#%%\r\nclass DataGenerator:\r\n\r\n    def __init__(self, dataframe, batch_size, run_aug = True):\r\n\r\n        self.total_len  = len(dataframe.index)\r\n        self.batch_size = batch_size\r\n        self.run_aug = run_aug\r\n        self.dataframe  = dataframe\r\n        self.on_epoch_end()\r\n\r\n    def __build_pipeline(self, file_path, labelY):\r\n\r\n        # mapping function in tf\r\n        def preprocess_fn(file_path, labelY):\r\n\r\n            def fn_x(img_array):\r\n\r\n                img_array = img_array.numpy()\r\n\r\n                if self.run_aug == 1:\r\n                    # image's range is [0,255]\r\n                    image = img_array\r\n\r\n                if self.run_aug >= 2:\r\n                    # image's range is [0,1]\r\n                    image = img_array / 255.0\r\n\r\n                if self.run_aug == 3:\r\n                    # std normalization\r\n                    image[0,:,:] -= 0.485\r\n                    image[1,:,:] -= 0.456\r\n                    image[2,:,:] -= 0.406\r\n                    image[0,:,:] /= 0.229\r\n                    image[1,:,:] /= 0.224\r\n                    image[2,:,:] /= 0.225\r\n\r\n                return image\r\n\r\n            def fn_y(label):\r\n                return tf.keras.utils.to_categorical(label , num_classes)\r\n\r\n            # read image from files\r\n            image = tf.io.read_file(file_path)\r\n            image = tf.image.decode_image(image, channels=channels)\r\n            aug_size = 256\r\n            imageX = tf.compat.v1.image.resize_image_with_pad(image, aug_size, aug_size)\r\n            imageX = tf.image.resize_with_crop_or_pad(image, img_h, img_w)\r\n\r\n            # do normalizarion\r\n            [imageX] = tf.py_function(fn_x, [imageX], [tf.float32])\r\n            imageX.set_shape([img_h, img_w, channels])\r\n            imageX = tf.image.random_flip_left_right(imageX)\r\n\r\n            [labelY] = tf.py_function(fn_y, [labelY], [tf.float32])\r\n            labelY.set_shape([num_classes])\r\n\r\n            return imageX, labelY\r\n\r\n        dataset = tf.data.Dataset.from_tensor_slices( (file_path, labelY) )\r\n        dataset = dataset.shuffle(batch_size * 8)\r\n        dataset = dataset.repeat()\r\n        dataset = dataset.map(preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n        dataset = dataset.batch(self.batch_size)\r\n        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n        self.dataset   = dataset\r\n\r\n    def  __len__(self):\r\n\r\n        return self.total_len // self.batch_size\r\n\r\n    def on_epoch_end(self):\r\n\r\n        cleanX = np.array(self.dataframe[\"File\"])\r\n        totalY = np.array(self.dataframe[\"One-hot\"])\r\n\r\n        # run permutation\r\n        rand_idx = np.random.permutation(self.total_len)\r\n        cleanX = cleanX[rand_idx]\r\n        totalY = totalY[rand_idx]\r\n\r\n        self.__build_pipeline(cleanX, totalY)\r\n\r\n#%%\r\ndef build_clf(model_name):\r\n\r\n    if model_name == \"ResNet50\":\r\n        clf_model = tf.keras.applications.ResNet50(include_top=True, pooling='max', weights='imagenet')\r\n\r\n    if model_name == \"DenseNet121\":\r\n        clf_model = tf.keras.applications.DenseNet121(include_top=True, pooling='max', weights='imagenet')\r\n\r\n    if model_name == \"MobileNetV2\":\r\n        clf_model = tf.keras.applications.MobileNetV2(include_top=True, pooling='max', weights='imagenet')\r\n\r\n    if model_name == \"InceptionV3\":\r\n        clf_model = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet')\r\n\r\n\r\n    clf_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\n    return clf_model\r\n\r\n#%%\r\ndef list_testing_data(classes, file_path, onehot_map):\r\n\r\n    try:\r\n        testing_data = pd.read_pickle('imagenet_test_list.pkl')\r\n        print('[Successful] Testing_data loaded from pickle ...')\r\n    except:\r\n        testing_image_info = []\r\n        for iter_class in classes:\r\n            files = glob(os.path.join(file_path, iter_class, '*.JPEG'))\r\n            for iter_img in files:\r\n                data_info = [iter_img, iter_class]\r\n                testing_image_info.append(data_info)\r\n\r\n        testing_data = pd.DataFrame(testing_image_info, columns=['File', 'Class'])\r\n        testing_data[\"One-hot\"] = testing_data[\"Class\"].replace(onehot_map, inplace=False)\r\n\r\n        testing_data.to_pickle('imagenet_test_list.pkl')\r\n\r\n    assert(testing_data.shape[0] == num_testing, \"[Fatal] Mismatched total length of testing data\")\r\n    return testing_data\r\n\r\n#%%\r\nif __name__ == '__main__':\r\n\r\n    # set GPU\r\n    import os\r\n    if os.environ.get(\"CUDA_VISIBLE_DEVICES\") is None:\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\n    # Hyperparameters\r\n    batch_size = 100\r\n    epochs = 5\r\n\r\n    # load one-hot labels\r\n    file_path = dataset_path + 'val'\r\n    classes = os.listdir(file_path)\r\n    list_class = sorted( list( set(classes) ) )\r\n    onehot_map = dict( zip( list_class, list(range(0, num_classes)) ))\r\n\r\n    # load list of validation data, those data should be considered as testing data\r\n    testing_data = list_testing_data(classes, file_path, onehot_map)\r\n\r\n    # build data generator\r\n    gen_type1 = DataGenerator(testing_data, batch_size, run_aug=1)\r\n    gen_type2 = DataGenerator(testing_data, batch_size, run_aug=2)\r\n    gen_type3 = DataGenerator(testing_data, batch_size, run_aug=3)\r\n    gen_list = [gen_type1, gen_type2, gen_type3]\r\n\r\n    # build model\r\n    model_list = [\"ResNet50\", \"DenseNet121\", \"MobileNetV2\"]\r\n    \r\n    # print result for type1\r\n    test_gen = gen_type1\r\n    for model_name in model_list:\r\n        model = build_clf(model_name)\r\n        meta_string = '[Testing][pixel vales are from (0,255)][model:{:s}] '.format(model_name)\r\n        prefix_string = ''\r\n        output = model.evaluate(test_gen.dataset, steps = test_gen.__len__())\r\n        for ii in range( len( model.metrics_names) ):\r\n            meta_string = meta_string + '- {:s}{:s}: {:.3f} '.format(prefix_string, model.metrics_names[ii], output[ii])\r\n\r\n        print(meta_string)\r\n\r\n    # print result for type2\r\n    test_gen = gen_type2\r\n    for model_name in model_list:\r\n        model = build_clf(model_name)\r\n        meta_string = '[Testing][pixel vales are from (0,1)][model:{:s}] '.format(model_name)\r\n        prefix_string = ''\r\n        output = model.evaluate(test_gen.dataset, steps = test_gen.__len__())\r\n        for ii in range( len( model.metrics_names) ):\r\n            meta_string = meta_string + '- {:s}{:s}: {:.3f} '.format(prefix_string, model.metrics_names[ii], output[ii])\r\n\r\n        print(meta_string)\r\n\r\n    # print result for type3\r\n    test_gen = gen_type3\r\n    for model_name in model_list:\r\n        model = build_clf(model_name)\r\n        meta_string = '[Testing][pixel vales are normalized from (-1,1)][model:{:s}] '.format(model_name)\r\n        prefix_string = ''\r\n        output = model.evaluate(test_gen.dataset, steps = test_gen.__len__())\r\n        for ii in range( len( model.metrics_names) ):\r\n            meta_string = meta_string + '- {:s}{:s}: {:.3f} '.format(prefix_string, model.metrics_names[ii], output[ii])\r\n\r\n        print(meta_string)\r\n```\r\n\r\n", "comments": ["@CNOCycle,\r\nCould you please take a look at this [link](https://www.tensorflow.org/tutorials/images/transfer_learning) and check if it helps. Thanks!", "@amahendrakar \r\n\r\nThank for your reply. I'm not want to do transfer learning. What I want to do is reproduce the result of pre-trained model.\r\n\r\nThose pre-trained model's weight are from imagenet dataset, so those models' top-1 accuracy on imagenet should be 70% up.\r\n\r\nAlso, from result which I posted, the behavior of those models are not unified.\r\n\r\nSo, my suggestion is that tf should mentioned input image should do normalization manually or not before feeding input image into pre-trained model.", "Oh, there is still no clear document in tensorflow=2.0.0\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications", "All pre-trained modes using TF mode expect the input channels to be in range of [-1,1]\r\nhttps://github.com/tensorflow/tensorflow/blob/23c3bdaacdc27bb82dfd1772efefad687508923a/tensorflow/python/keras/applications/imagenet_utils.py#L36", "@ymodak \r\n\r\nThank your reply.  I found that a clear comment have been added in the `master` branch.\r\n\r\nBut, I still doubt whether this description is correct or not.\r\n\r\nBecause in my test case, ResNet50 model's accuracy is near 0.001 if we normalize the value range to [-1, 1].\r\n\r\nIn the tutorial(https://www.tensorflow.org/tutorials/generative/adversarial_fgsm),\r\n\r\n```python\r\n# Helper function to preprocess the image so that it can be inputted in MobileNetV2\r\ndef preprocess(image):\r\n  image = tf.cast(image, tf.float32)\r\n  image = image/255\r\n  image = tf.image.resize(image, (224, 224))\r\n  image = image[None, ...]\r\n  return image\r\n```\r\n\r\nIt only rescales data to range [0, 1] instead of [-1, 1].\r\n", "@CNOCycle , Please try to see Nightly it shows the arguments and returned params if it helps.", "@ashutosh1919 , Thanks your comment. I saw the parameters' usage in the function on the lastest master branch.\r\n\r\nBut, I still have two main concerns.\r\n\r\n1. The input range for pre-trained weights: Not all pre-trained weights require the input range to be [0,1]. It should be highlighted.\r\n\r\n2. The accuracy for pre-trained weights: I have shown the experimental results. All tests' accuracy are under 70%. It means that pre-trained weights are not good enough.", "For anyone else finding this: TensorFlow requires images to be in range [0,1), see https://www.tensorflow.org/api_docs/python/tf/image/convert_image_dtype\r\n\r\n> Images that are represented using floating point values are expected to have values in the range [0,1). Image data stored in integer data types are expected to have values in the range [0,MAX], where MAX is the largest positive representable number for the data type.", "> All pre-trained modes using TF mode expect the input channels to be in range of [-1,1]\r\n> https://github.com/tensorflow/tensorflow/blob/23c3bdaacdc27bb82dfd1772efefad687508923a/tensorflow/python/keras/applications/imagenet_utils.py#L36\r\n\r\nI think this is the right approach, i.e., using keras-application preprocess_input to get meaningful results, regardless of convert_image_dtype. This should have already been tested.", "Closing this issue now. Thanks!"]}, {"number": 35335, "title": "Dataset scan loses variable modifications", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, providing source.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.15.2, most likely irrelevant.\r\n- TensorFlow installed from (source or binary): binary from pip\r\n- TensorFlow version (use command below): v1.12.1-21171-g9798f84fa9 2.1.0-dev20191221 (installed via pip install tf-nightly==2.1.0dev20191221)\r\n- Python version: 3.7.2\r\n- CUDA/cuDNN version: using CPU only.\r\n\r\n**Describe the current behavior**\r\nWhile writing a unit test I created a function that iterates a tf.data.Dataset and accumulates the values in a local variable. This worked fine using eager mode, but then I noticed that the returned result was zero when using tf.function.\r\n\r\nI've produced a small simple code that reproduces the problem. In particular, returning the accumulator variable produces a result of 0, but accessing the variable directly works fine. Also, using tf.print on the accumulator while iterating the dataset shows the correct value, but printing it after the iteration still within the method shows 0, suggesting perhaps some kind of scoping problem.\r\n\r\nPlease see the attached source to understand better what I mean.\r\n\r\n**Describe the expected behavior**\r\nThe result should be the same when using eager mode and tf.function. Also, when using tf.function the result should be the same when returning the variable and when accessing it directly.\r\n\r\n**Code to reproduce the issue**\r\n[tf_function_variable.py.txt](https://github.com/tensorflow/tensorflow/files/3992032/tf_function_variable.py.txt)", "comments": ["I could replicate the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/70fca4acb63107bfdb216b4024f57373/untitled319.ipynb). Thanks!", "@leandro-gracia-gil Please use the following workaround until we get this fixed: `for t in iter(dataset):`.\r\n\r\n@jsimsa it looks like `scan` loses variable updates. Repro below. Note that `reduce` alone works, but we need the `scan` addition due to #32138. I'm tempted to drop the use of `reduce+scan` altogether and use iterators throughout, since they seem to be more stable.\r\n\r\n```\r\nacc = tf.Variable(0.0, dtype=tf.float32, trainable=False)\r\n\r\n@tf.function(autograph=False)\r\ndef sum_dataset(dataset):\r\n  def body(dummy, t):\r\n    acc.assign_add(t)\r\n\r\n    # Prints the actual value in all cases.\r\n    tf.print('in loop', acc)\r\n\r\n    return (dummy, dummy)\r\n\r\n  def reduce_body(_, scan_outputs):\r\n    return scan_outputs\r\n\r\n  tr = tf.data.experimental.scan((tf.constant(0),), body)\r\n  dataset = dataset.apply(tr)\r\n  dataset.reduce((tf.constant(0),), reduce_body)\r\n\r\n  # Prints 0.0 when tf.function is used, but the actual value in eager mode.\r\n  tf.print('after loop', acc)\r\n\r\n  return acc\r\n\r\nrecords = np.random.uniform(size=(10,)).astype(np.float32)\r\ndataset = tf.data.Dataset.from_tensor_slices(records)\r\nresult = sum_dataset(dataset)\r\n\r\n# Fails when tf.function is used in sum_dataset because result is 0.0.\r\nassert result.numpy() == acc.numpy()\r\n```", "I believe that this is another instance of the \"datasets do not propagate\" control dependencies bug (b/142341957) that and I plan to fix as soon as possible.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35335\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35335\">No</a>\n"]}, {"number": 35334, "title": "Question about tf.keras.backend switch in lambda layer for short circuit computation", "body": "I am using tf.keras.backend.switch inside of a lambda layer in order to swap between multiple different \"expert\" layers based on the output of a \"gating\" layer. When the entire model is used to predict an output, does it evaluate the gating layer first and then \"short circuit\" to only evaluate the single selected expert layer (to save computation time)? If not, how could I implement this?\r\n\r\nI am using tensorflow 2.0 gpu and the keras functional api\r\n\r\nUpdate: I created a custom layer with multiple input/output tensors rather than using a Lambda layer, but the question above still stands.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n Thanks!\r\n"]}, {"number": 35332, "title": "Update math_ops.py with additional usage examples", "body": "Added usage examples for tf.math (subtract, scalar_mul, truediv, divide_no_nan, multiply_no_nan, floordiv, reduce_prod, reduce_min, reduce_max, sigmoid, log_sigmoid, unsorted_segmentation, unsorted_segment_sqrt_n, polyval)", "comments": ["@alextp can you take a look at the changes I made?", "@anigasan Can you please check mihaimaruseac's comments and keep us posted? Thanks!", "Sorry about the lack of response, I am a little pressed with time at the moment. I will get to making the respective changes once I get time\r\n\r\nThanks!", "Also, please rebase on master again to solve conflicts", "@anigasan Can you please check mihaimaruseac's comments and keep us posted? Thanks!", "Apologies! Was busy with various school engagements, but I should be able to work on the changes. ", "@anigasan can you please resolve conflicts ?", "Thanks for the advice @mihaimaruseac, I will make the changes promptly", "@anigasan Can you please check mihaimaruseac's comments and keep us posted? Thanks!", "Yes, this is still being worked on, haven't had time to work on it due to numerous school exams. Will get to it soon", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Yes this is still being worked on, will let you know if other changes need to be made", "@anigasan  Any update on this PR, please. Thanks!", "I will see whether I have time to work on this, I apologize for the delay. I have been very busy with schoolwork and exams. Will let you know and make changes accordingly", "We'll be closing the PR for now to let others also work on it. When you get a chance to work on it please reopen"]}]