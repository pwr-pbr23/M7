[{"number": 45438, "title": "Refactor Transpose reference op for port to TFLu", "body": "Move out Transpose reference op to transpose.h to prepare for porting kernel to TFLu", "comments": ["@patriklaurell  Can you please check @thaink's comments and keep us posted ? Thanks!", "@patriklaurell  Can you please resolve conflicts? Thanks!", "I will resolve the conflicts shortly", "@patriklaurell can you please rebase your branch to latest ", "Rebased on master @rthadur ", "@patriklaurell can you please check sanity build failures ?", "The existing failures seems to be non-related to this PR"]}, {"number": 45437, "title": "Keras: inconsistent behavior of \"embedded\" models", "body": "Not sure if this a bug (I am inclined to believe so) or not, but it looks strange/inconsistent to me...\r\nConsider the following scenario (a simple \"embedded\" model case):\r\n```python\r\nm1 = Sequential([\r\n    Input((100,)),\r\n    Dense(20),\r\n    Dense(10),\r\n])\r\n\r\nm2 = Sequential([\r\n    Input((100,)),\r\n    m1,\r\n    Dense(5),\r\n])\r\n```\r\n\r\nNow, assume that I would like to extract features from an internal layer of the models.\r\nThe following example works as expected:\r\n\r\n```python\r\ntest1 = Model(m1.input, m1.layers[1].output)\r\ntest2 = Model(m2.input, m2.layers[1].output)\r\n```\r\n\r\nHowever, this one fails, even though I would expect it to be equivalent to `test1` above:\r\n```python\r\ntest3 = Model(m2.input, m2.layers[0].layers[1].output)\r\n```\r\nThe error is:\r\n```python\r\nValueError: Graph disconnected: cannot obtain value for tensor Tensor(\"input_3:0\", shape=(None, 100), dtype=float32) at layer \"dense_3\". The following previous layers were accessed without issue: []\r\n```\r\n\r\nIt seems that the following \"trick\" does the job:\r\n```python\r\ntest4 = Model(m2.layers[0].input, m2.layers[0].layers[1].output)\r\n```\r\n\r\nNow, there is another peculiarity, which seems rather annoying to me:\r\n```python\r\nm1.summary()\r\n\r\nModel: \"sequential_2\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense_3 (Dense)              (None, 20)                2020      \r\n_________________________________________________________________\r\ndense_4 (Dense)              (None, 10)                210       \r\n=================================================================\r\nTotal params: 2,230\r\nTrainable params: 2,230\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n\r\n```\r\nThe model has two layers (no input layer), whereas this one has three layers...\r\n\r\n```python\r\ntest4.summary()\r\n\r\nModel: \"functional_19\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_3 (InputLayer)         [(None, 100)]             0         \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 20)                2020      \r\n_________________________________________________________________\r\ndense_4 (Dense)              (None, 10)                210       \r\n=================================================================\r\nTotal params: 2,230\r\nTrainable params: 2,230\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\n\r\nWhat is interesting `tf.keras.utils.plot_model` produces identical graphs (with input layers) for both `m1` and `test4`.\r\n", "comments": ["@eli-osherovich \r\n\r\nPlease, let us know which TF version you are using.You are seeing the same behavior with recent TF versions like 2.4-rc3 and nightly versions?\r\n\r\nThanks!", "This is TF 2.3.0. ", "The results are reproducible in tf-nightly\r\n```\r\nIn [14]: tf.__version__\r\nOut[14]: '2.5.0-dev20201207'\r\n\r\nIn [15]: tf.__git_version__\r\nOut[15]: 'v1.12.1-47044-gfefcd5704ba'\r\n```", "@eli-osherovich About the summary It Is ok to have this different behaviour. Input https://github.com/tensorflow/tensorflow/issues/35515#issuecomment-571266052\n\nSee also the difference between Input and InputLayer https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer", "@bhack \r\nWhy is it okay to have InputLayer in models created via functional API but not in models created with the Sequential API? \r\nIn case one wants to access, say, third layer in the network he/she will have to check whether it is sequential or functional?\r\n", "It is in the doc link:\r\n> It is generally recommend to use the functional layer API via Input, (which creates an InputLayer) without directly using InputLayer.\r\nWhen using InputLayer with Keras Sequential model, it can be skipped by moving the input_shape parameter to the first layer after the InputLayer.\r\n\r\n\r\nYou can still access to layer by name as in https://keras.io/getting_started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction", "@bhack It might be that I do not understand something... `m1` and `m2` do use `keras.Input`, however their summary (and more importantly: `.layers` property) does not have `InputLayer`.  \r\n\r\nI would expect these two examples to provide identical results:\r\n```python\r\nx = Input((128,))\r\ny = Dense(64)(x)\r\nm1 = Model(x, y)\r\n\r\nm2 = Sequential([Input((128,1)), Dense(64)])\r\n```\r\n\r\nHowever `m1` has two layers, whereas `m2` has only one. \r\n", "Yes but as you see `m1` and `m2` are sequential and you are using `Input` not `InputLayer`\r\n\r\ntest4 is implicit functional (see the autoname of the model `Model: \"functional_19\"`)\r\n\r\n> **functional layer API** via Input, (which creates an InputLayer) without directly using InputLayer.", "@bhack please see my updated response above yours. \r\nIsn't it reasonable to expect identical models in these two cases?", "Yes exactly, again:\r\n> functional layer API via Input, (which creates an InputLayer) without directly using InputLayer.\r\n\r\nAnd you first model in our last example `m1` is functional.", "Sorry for being \"dumb\". My main point is not what documentation says, but how things behave (and whether people *expect* this behavior). I would expect (and probably more people) that these three models would be identical. Note that the difference is not about Input or InputLayer, the difference is Functional vs Sequential. \r\n\r\n```python\r\nx = Input((128,))\r\ny = Dense(64)(x)\r\nm1 = Model(x, y)\r\n\r\nm2 = Sequential([Input((128,)), Dense(64)])\r\n\r\nm3 = Sequential([InputLayer((128,)), Dense(64)])\r\n```\r\n\r\nHowever, they are not\r\n`m1` has *two* layers, whereas `m2` and `m3` both have only one layer.\r\n\r\n\r\nP. S.\r\nWith that said, I do not see how the documentation part you cited explains this behavior... ", "The documentation source is https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer\r\n\r\nIf you want the historical motivation about Sequential summary see:\r\nhttps://github.com/tensorflow/tensorflow/blob/42c2ae60913b517a5c345bf35185afe412f587ee/tensorflow/python/keras/engine/sequential.py#L148-L157\r\n", "Thanks, @bhack! \r\nSo, there is difference between Sequential and Functional. Wouldn't it be correct to \"fix\" the way Sequential \"hides\" its input layer? \r\n\r\n", "It was accepted in 2019 for `model_to_dot` with https://github.com/tensorflow/tensorflow/pull/24637\r\nBut rejected for `summary` with https://github.com/keras-team/keras/pull/12388#issuecomment-469348981\r\n\r\n@Wiki-fan asked about inconsistency at https://github.com/keras-team/keras/pull/12388#issuecomment-469351075 but without any reply.\r\n\r\n/cc @fchollet If he want to add something more, by an historical point of view, about the divergence between `model_to_dot` and `summary`?\r\n", "Please note, that printing or drawing is not the biggest problem. At least for me, accessing layers' outputs may be problematic since the number of layers is different. \r\n\r\nWhich brings me back to the original topic of this question: how one can access (the output of) an \"internal\" layers (from a nested model)?\r\n", "If you don't like layers names you can still access with `index` when you create the functional model (your Model() calls examples):\r\n\r\n`keras.Model(m2.get_layer(index=0).input, m2.get_layer(index=0).output)`", "@bhack \r\nI love layers names. I want the following code to work as expected:\r\n\r\n```python\r\nm1 = Sequential([\r\n    Input((100,)),\r\n    Dense(20),\r\n    Dense(10),\r\n])\r\n\r\nm2 = Sequential([\r\n    Input((100,)),\r\n    m1,\r\n    Dense(5),\r\n])\r\n\r\ntest3 = Model(m2.input, m2.layers[0].layers[1].output)\r\n```", "I don't know what do you expect but that will not work.\r\nPlease give two different names to `m1` input and `m2` input:\r\n\r\n```\r\nprint(m2.get_layer(index=0).input.name)\r\nprint(m2.input.name)\r\ntest3 = keras.Model(m2.get_layer(index=0).input,m2.layers[0].layers[1].output)\r\n```\r\n\r\n", "Honestly, I do not get it. This is the canonical way to extract features from an intermediate layer: one uses model's input and that layer output. It works with usual networks, but not with \"embedded\" ones. \r\n", "I don't understand what you want to do:\r\n\r\n```python\r\nfrom tensorflow import keras\r\nm1 = keras.Sequential([\r\n    keras.layers.Input((100,),name=\"m1_input\"),\r\n    keras.layers.Dense(20),\r\n    keras.layers.Dense(10),\r\n])\r\n\r\nm2 = keras.Sequential([\r\n    keras.layers.Input((100,),name=\"m2_input\"),\r\n    m1,\r\n    keras.layers.Dense(5,name=\"bni\"),\r\n])\r\ntest1 = keras.Model(m1.input, m1.layers[1].output)\r\ntest2 = keras.Model(m2.get_layer(index=0).input, m2.get_layer(index=0).output)\r\ntest3 = keras.Model(m2.get_layer(index=0).input, outputs=m2.layers[0].layers[1].output)\r\ntest4 = keras.Model(m2.layers[0].input, m2.layers[0].layers[1].output)\r\n\r\nprint(m2.get_layer(index=0).input.name)\r\nprint(m2.input.name)\r\ntest3 = keras.Model(m2.get_layer(index=0).input,m2.layers[0].layers[1].output)\r\n```\r\n\r\n```\r\nm1_input:0\r\nm2_input:0\r\n```\r\n\r\nSo with your `test3 = Model(m2.input, m2.layers[0].layers[1].output)` you are trying to connect `m2_input`", "@bhack I want to extract features from a layer in `m2`, which is inside the embedded `m1`.", ">  love layers names. I want the following code to work as expected:\r\n....\r\ntest3 = Model(m2.input, m2.layers[0].layers[1].output)\r\n\r\nThis is exactly the same as:\r\n`test3 = keras.Model(m2.input, m1.layers[1].output)`\r\n\r\nAnd this doesn't work also for not nested models. \r\nAs this is not a bug you need to close this and ask as a support questions to our stackoverflow space at https://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nThanks\r\n\r\n", "@bhack  can you please explain why?\r\n\r\nI do not agree that this is the same: both inputs and outputs belong to `m2`. Furthermore, the following code does not generate an error:\r\n```python\r\ntest4 = Model(m2.layers[0].input, m2.layers[0].layers[1].output)\r\n```\r\nP. S.\r\nCan you please show the right way to extract features from internal layers of an embedded network?\r\n", "Is the same cause If you start to give to  all the layers an unique name and you start to print the names of the layers that you get you can verify yourself that `m1.layers[1].output` is exactly `m2.layers[0].layers[1].output`.\n\nAs It Is not a bug or a feature request if you need support use Stackoverflow.", "I meant this is not the same since `m1` is embedded into `m2` (unlike the case, where these two models are unrelated). Hence, there is a path from `m2.input` into `m1`.\r\n\r\n Can you please show the right way to extract features from internal layers of an embedded network?", "> I meant this is not the same since m1 is embedded into m2 (unlike the case, where these two models are unrelated)\r\n\r\nThis is your interpretation but it doesn't work like you are expecting and if you check you have exactly the same error as `test3 = keras.Model(m2.input, m1.layers[1].output)`.\r\n\r\n> Can you please show the right way to extract features from internal layers of an embedded network?\r\n\r\nThis part is just a support request and you need to post that on our Stackoverflow  space.", "Thanks @bhack for answering the question.\r\n\r\nTo echo some of the response and providing more context here:\r\n\r\n1. keras.layers.InputLayer is a Layer and should be used with Sequential model, which stacks layer one by one. It is mainly used to define the input shapes, which is needed by following layers to build its weights.\r\n2. keras.Input is NOT a Layer, and should be used with functional model. The functional model provides more freedom to build the model structure, eg multiple input/output, rather than just linear structure in sequential model.\r\n3. Historically user was passing keras.Input to sequential model, which is kind of discouraged. We still allow it to avoid breaking too many existing use case.\r\n4. We add a dummy InputLayer to sequential model if user doesn't provide any. This is also why we don't show any InputLayer in the sequential model summary.\r\n5. For functional model, since user has to provide input/output, we show all the input/output in the model summary, which is why you see it (and confused you with sequential model summary).\r\n\r\nOverall, I think using Input with sequential model is not encourage, and should be replaced with InputLayer. In the meantime, please also forward any request for feature extraction to Stackoverflow to get more help from community.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45437\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45437\">No</a>\n", "@qlzh727 Probably, If we want to take something good from this ticket handlig,  maybe we could add a warning somewhere in the code for Sequential + Input what do you think?", "> @qlzh727 Probably, If we want to take something good from this ticket hanldlig, maybe we could add a warning somewhere in the code for Sequential + Input what do you think?\r\n\r\nSure, will send a change soon.", "Please update the documentation too. Today it is exactly how Sequential is demonstrated (with kearas.Input):\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Sequential"]}, {"number": 45436, "title": "Sparse.Softmax Example", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version:3.8\r\n- CUDA/cuDNN version: unsure\r\n- GPU model and memory: unsure\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\nExecuting code at the tensorflow example does not work as described.\r\nhttps://www.tensorflow.org/api_docs/python/tf/sparse/softmax#returns\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nshape = [2, 2, 2]  # 3-D SparseTensor\r\nvalues = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])\r\nindices = np.vstack(np.where(values)).astype(np.int64).T\r\nresult = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape))\r\n```\r\n\r\nOutput:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/pycharm-2020.1.2/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py\", line 3, in Exec\r\n    exec(exp, global_vars, local_vars)\r\n  File \"<string>\", line 7, in <module>\r\n  File \"/home/jsidhom1/DeepTCR/venv/lib/python3.8/site-packages/tensorflow/python/framework/sparse_tensor.py\", line 145, in __init__\r\n    values_shape = values.shape.with_rank(1)\r\n  File \"/home/jsidhom1/DeepTCR/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\", line 1034, in with_rank\r\n    raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\r\nValueError: Shape (2, 2, 2) must have rank 1\r\n\r\nExpected behavior from website above.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nshape = [2, 2, 2]  # 3-D SparseTensor\r\nvalues = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])\r\nindices = np.vstack(np.where(values)).astype(np.int64).T\r\nresult = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape))\r\n```\r\n", "comments": ["Hi @sidhomj \r\n\r\nI tried this out, I too got the same error. \r\nThe reason for the error is SparseTensor accepts only 1-D tensor as values but in the docs a 3-D tensor is passed. So, to solve this you can get the non zero values from the tensor and store it in a list and then pass it to the SparseTensor.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nshape = [2, 2, 2]  # 3-D SparseTensor\r\nvalues = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])\r\nindices = np.vstack(np.where(values)).astype(np.int64).T\r\n\r\nflat_values = tf.reshape(values,[-1])\r\nval = [flat_values[i] for i in np.nonzero(flat_values)[0].tolist()]\r\n\r\nresult = tf.sparse.softmax(tf.sparse.SparseTensor(indices, val, shape))\r\ntf.sparse.to_dense(result)\r\n```\r\nThis is how I implemented it \r\n\r\n\r\n\r\n\r\n", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/17622f98bd68a4d0b489d5e41b2c1564/45436.ipynb). Thanks!", "@sidhomj Agree that the code on that page is not working as `values` supposed to be a 1-D tensor of any type and shape [N]. Please check the [`tf.sparse.SparseTensor`](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor).\r\n\r\nI tried the following which works and the result is of shape (5,3). Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/ecb8f343e78d8a6b51959f925fdcd431/untitled68.ipynb).\r\n\r\n```\r\nshape = [2, 2, 2]  # 3-D SparseTensor\r\ndense_values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])\r\nvalues= [np.e, 1, np.e, np.e, np.e]\r\nindices = np.vstack(np.where(dense_values)).astype(np.int64).T\r\n\r\nresult = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape))\r\n```\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45436\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45436\">No</a>\n"]}, {"number": 45435, "title": "ImportError: Traceback (most recent call last):   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>     from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed: The specified module could not be found.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nImportError                               Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     63   try:\r\n---> 64     from tensorflow.python._pywrap_tensorflow_internal import *\r\n     65   # This try catch logic is because there is no bazel equivalent for py_extension.\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\r\n     39 \r\n---> 40 from tensorflow.python.eager import context\r\n     41 \r\n     42 # pylint: enable=wildcard-import\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py in <module>\r\n     33 from tensorflow.core.protobuf import config_pb2\r\n     34 from tensorflow.core.protobuf import rewriter_config_pb2\r\n---> 35 from tensorflow.python import pywrap_tfe\r\n     36 from tensorflow.python import tf2\r\n     37 from tensorflow.python.client import pywrap_tf_session\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py in <module>\r\n     26 \r\n     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\r\n---> 28 from tensorflow.python import pywrap_tensorflow\r\n     29 from tensorflow.python._pywrap_tfe import *\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     81 for some common reasons and solutions.  Include the entire stack trace\r\n     82 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 83   raise ImportError(msg)\r\n     84 \r\n     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ahsanrossi \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167, #42367\r\n\r\nIf the issue still persists please post it on [Anaconda repo ](https://github.com/ContinuumIO/anaconda-issues/issues)as we do not support conda environment.\r\nThis issue is more suitable on Continuum Anaconda repo since its related to TF installation with Anaconda.\r\nPlease post it on Continuum Anaconda.\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45435\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45435\">No</a>\n"]}, {"number": 45434, "title": "Whl package not building due with a issue with sed - MacOS 11", "body": "**System information**\r\n- OS Platform and Distribution: Mac OS 11.0.1 Big Sur\r\n- TensorFlow installed from (source or binary): Source - git\r\n- TensorFlow version: 2.4.0-rc4\r\n- Python version: 3.8.6 (macports)\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.27) XCode 12.2\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: AMD Radeon Pro 555X - 4GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nTensorflow compiles correctly. However, when using the command:\r\n\r\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package`\r\n\r\nthe whl package is not produced and rather the following error is shown:\r\n\r\n`sed: /var/folders/y4/85hx48054tbd2y04jkf3l6880000gn/T/tmp.XXXXXXXXXX.Ty6dzcrU/tensorflow/__init__.py: in-place editing only works for regular files`\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Compile from source as indicated in the tensorflow manual. \r\n2. Run the command to build the whl package:\r\n\r\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package ..`\r\n\r\n**Any other info / logs**\r\nThis error is not present in MacOS 10.15. All proceed as it should\r\n", "comments": ["When replacing `sed` with `gsed` (from macports) in the following:\r\n\r\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package`\r\n\r\nin line 219:\r\n\r\n`gsed -i'.original' -e 's/.python.keras.api._v1/tensorflow/g' ${TMPDIR}/tensorflow/__init__.py`\r\n\r\nand line 222:\r\n    `gsed -i'.original' -e 's/.python.keras.api._v2/tensorflow/g' ${TMPDIR}/tensorflow/__init__.py`\r\n  \r\nthe whl package is produced correctly. ", "@feranick \r\n\r\nGlad to know issue was resolved. Please, close this issue as your issue was resolved. Thanks!", "Well, the issue is only partially resolved, as the solution requires the use of a non standard feature (i.e. `gsed` from macports). I think it would be wise to add a note on the \"known issues\" for others to follow...", "@feranick \r\n\r\nAre you willing to contribute PR for this?\r\nThanks!", "How about something like this:\r\n\r\nWhen compiling from source in MacOS 11 Big Sur, a known issue with the command `sed` in MacOS prevents the creation of a wheel package. As a workaround, `gsed` from macports can be used instead. These are the required steps:\r\n1. Install `gsed` from macports: \r\n`sudo port install gsed`\r\n2. After compilation is successfully completed, edit lines 219 and 222 in:\r\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package`\r\nto replace `sed`with `gsed`. \r\n3. Run the package maker script:\r\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package`\r\n\r\nMore details: https://github.com/tensorflow/tensorflow/issues/45434", "I think #46147 fixes this", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45434\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45434\">No</a>\n"]}, {"number": 45433, "title": "Tensorflow/Keras Endpoint layer does not work with Tensorflow dataset in eager mode", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nGoogle Colab, Mac OS\r\n- TensorFlow version:\r\n2.3.1\r\n- Python version:\r\n3.6.9\r\n\r\n**Describe the current behavior**\r\nThe Endpoint layer pattern described in Tensorflow documents only works with Numpy arrays and it does not work with Tensorflow dataset\r\n**Describe the expected behavior**\r\nThe Endpoint layer is expected to work with Tensorflow dataset as well\r\n\r\n**Standalone code to reproduce the issue**\r\n This code is from Tensorflow documents that works only with Numpy arrays:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nclass LogisticEndpoint(keras.layers.Layer):\r\n    def __init__(self, name=None):\r\n        super(LogisticEndpoint, self).__init__(name=name)\r\n        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\r\n        self.accuracy_fn = keras.metrics.BinaryAccuracy()\r\n\r\n    def call(self, targets, logits, sample_weights=None):\r\n        # Compute the training-time loss value and add it\r\n        # to the layer using `self.add_loss()`.\r\n        loss = self.loss_fn(targets, logits, sample_weights)\r\n        self.add_loss(loss)\r\n\r\n        # Log accuracy as a metric and add it\r\n        # to the layer using `self.add_metric()`.\r\n        acc = self.accuracy_fn(targets, logits, sample_weights)\r\n        self.add_metric(acc, name=\"accuracy\")\r\n\r\n        # Return the inference-time prediction tensor (for `.predict()`).\r\n        return tf.nn.softmax(logits)\r\n\r\ninputs = keras.Input(shape=(3,), name=\"inputs\")\r\ntargets = keras.Input(shape=(10,), name=\"targets\")\r\nlogits = keras.layers.Dense(10)(inputs)\r\npredictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\r\n\r\nmodel = keras.Model(inputs=[inputs, targets], outputs=predictions)\r\nmodel.compile(optimizer=\"adam\")\r\n\r\ndata = {\r\n    \"inputs\": np.random.random((3, 3)),\r\n    \"targets\": np.random.random((3, 10)),\r\n}\r\nmodel.fit(data)\r\n```\r\n**Experiment 1: Using TF dataset in a dictionary**\r\n```\r\ntf_data = {\r\n    'inputs': tf.data.Dataset.from_tensor_slices(np.random.random((3, 3))), \r\n    'targets': tf.data.Dataset.from_tensor_slices(np.random.random((3, 10)))\r\n}\r\n\r\nmodel.fit(tf_data)\r\n```\r\n\r\n![tf1](https://user-images.githubusercontent.com/62025982/101292041-09feef80-37db-11eb-8eb7-2047cde45647.png)\r\n\r\n**Experiment 2: TF dataset that contains tuples**\r\n```\r\ndata = {\r\n    \"inputs\": np.random.random((3, 3)),\r\n    \"targets\": np.random.random((3, 10)),\r\n}\r\ntuple_data = []\r\nfor i in range(3):\r\n  tuple_data.append((data['inputs'][i, :], data['targets'][i, :]))\r\n\r\ndataset = tf.data.Dataset.from_generator(lambda: tuple_data, (tf.float32, tf.float32))\r\n\r\n# to show the dataset content\r\nfor x in dataset:\r\n  print(x)\r\n\r\nmodel.fit(dataset)\r\n```\r\n![tf2](https://user-images.githubusercontent.com/62025982/101292452-8397dd00-37dd-11eb-871d-71bd1c113727.png)\r\n\r\n**Colab link:**\r\n[https://colab.research.google.com/drive/1zaAgPZ4U49t2PkIl7qdm348ayt7Z5O-0](url)", "comments": ["Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/c339a19b43ebd9e7a83be67405b2870d/45433.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/1db7335dc8bde1e3e2c23cb44fdfc1a3/45433-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@amahendrakar Thanks.\r\n\r\n@soroosh-rzh \r\nCan you try with:\r\n```\r\ninput = tf.random.uniform([3, 3])\r\ntargets = tf.random.uniform([3, 10])\r\ntf_data = tf.data.Dataset.from_tensor_slices({'inputs': input, 'targets': targets})\r\ntf_data = tf_data.batch(2)\r\nmodel.fit(tf_data)\r\n```", "@bhack \r\n\r\nI tried it, it works! Thanks for the suggestion. The loss is a little bit different from what is gained using numpy but I believe it should be Ok! \r\nDo you have any idea how it might work without dictionary and using tuples as input/outputs? The real use case for me would be multiple inputs/outputs. I mean something close to what I have mentioned in experiment 2. \r\nThanks", "We use our stackoverflow space for this kind of support.\nPlease submit at https://stackoverflow.com/questions/tagged/tensorflow and close this.", "Correct. Forgetting what would be my use case, I still think the endpoint pattern is not working without a dictionary as input so that may be a still a bug not a question! Thank you for your reply.", "Can you reformulate your code with your bug hypotesis?", "@soroosh-rzh,\r\nCan you please respond to the above comment. Thanks! ", "@bhack @rmothukuru I will reformulate the code and add a comment over my weekend! Please do not close this issue for now. Thanks ", "@soroosh-rzh,\r\nCan you please respond to the above comment. Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@soroosh-rzh,\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\nThe issue is resolved by using `tf.data.Dataset.from_tensor_slices` and `tf_data.batch(2)` as mentioned in [bhack's answer](https://github.com/tensorflow/tensorflow/issues/45433#issuecomment-740117545). \r\n\r\nPlease raise a new issue with your reformulated code. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45433\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45433\">No</a>\n"]}, {"number": 45431, "title": "micro: port op DIV from lite", "body": "@tensorflow/micro\r\n\r\nThis issue tracks my work porting operator DIV from lite to micro.\r\n\r\nThe port will be submitted in a number of PRs. Here's a rough flight plan per @advaitjain and @petewarden:\r\n\r\nPR 1: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver\r\nPR 2: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences\r\nPR 3: Copy operator from lite to micro without making any changes or including in the build\r\nPR 4: Delete extra code from the micro copy of the operator\r\nPR 5: Port micro copy of operator as necessary and add a corresponding test\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45431\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45431\">No</a>\n"]}, {"number": 45430, "title": " After installing tf-nightly tensorflow is not working on GPU", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@supradeepdanturti,\r\nThe latest TF-nightly requires CUDA 11 and cuDNN 8. Could you please check if you are facing the same issue with CUDA 11 and cuDNN 8 as well?\r\n\r\nAlso in order to expedite the trouble-shooting process, could you please provide the the following information\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nThanks!", "@amahendrakar ,\r\nYes I'm running CUDA 11 and CuDNN 8. This problem started from yesterday when I used keras.preprocessing.image_dataset_from_directory It worked till yesterday and then suddenly it said No attribute 'keras.preprocessing.image_dataset_from_directory ' then I found a thread and people said  installing tf-nightly will fix it. It fixed the error and after that my code is working on CPU instead of GPU. It says GPU not found.\r\n", "@amahendrakar ,\r\nI changed my tensorflow version to 2.3.1. My problem is solved Thank you.! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45430\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45430\">No</a>\n"]}, {"number": 45429, "title": "Page is not visible in Desktops ", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/hub/tutorials/tf2_object_detection#utilities\r\n\r\n## Description of the issue (what needs changing):\r\n- The `Toggle-code` button is not working.\r\n- Below page is cut from the left side\r\n- Screenshot from crome\r\n![Screenshot (96)](https://user-images.githubusercontent.com/43227010/101273854-36a50e00-37bf-11eb-8a9a-a5dd318612ea.png)\r\n- Screenshot from firefox\r\n![Screenshot (97)](https://user-images.githubusercontent.com/43227010/101273857-3b69c200-37bf-11eb-9e42-ef93c9d0bfeb.png)\r\n\r\n\r\n", "comments": ["Thanks for the report and tracking internally b/175229423\r\n", "Should be fixed now: https://www.tensorflow.org/hub/tutorials/tf2_object_detection\r\n"]}, {"number": 45428, "title": "Tensorflow Estimator passes train data through some weird normalization before entering net", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: anaconda\r\n- TensorFlow version: 2.2, but some parts of the networks use tf.compat.v1\r\n- Python version: 3\r\n\r\n**Describe the current behavior**\r\n\r\nI am using tensorflow Estimator API, and have encountered a weird phenomenon. I am passing the exact same input_fn to both training and evaluation, and for some reason the images which are provided to the network are not identical. I use the tf.Estimator.train_and_evaluate, and use tensorboard to display the images that are passed to the model_fn. This means that these images are those that are later fed into the network, and are not an intermediate result from the network. The two images seem similar, but after taking a closer look, it seems that evaluation images are ok, but train images are somewhat distorted.\r\n\r\nAfter loading them both, I noticed that for some reason the training images go through some kind of ReLu. I affirmed it with this code:\r\n\r\nspecial_relu = lambda mat: ((mat - 0.5) / 0.5) * ((mat - 0.5) / 0.5 > 0)\r\nnp.allclose(mat_train, special_relu(mat_eval))\r\n>>> True\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behaviour is that the evaluation images should be the same as the train images, such that:\r\nnp.allclose(mat_train, mat_eval)\r\n>>> True\r\n\r\nClarification: The input_fn I provided is one that yields the exact same image over and over again, so the images that are drawn should all be the same, theoretically.\r\n\r\n**What I thought and tried**\r\n\r\nMy initial thought was that it is some form of BatchNormalization. But BatchNormalization is supposed to happen within the network, and not as some preprocess, shouldn't it? What I recorded (using tf.summary.image) was the features['image'] object, passed to my model_fn. And if I understand correctly, the features object is passed to model_fn by the input_fn called by the Estimator object.\r\n\r\nRegardless, I tried to remove the parts in the code which are supposed to call the BatchNormalization. This had no effect. Of course, I might have not done that in the right way, but as I said it I don't really think it is BatchNormalization.", "comments": ["@yonatansc97 \r\n\r\nPlease, share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "Hi, @ravikyram\r\nThank you for the response!\r\nI could not get it to run on a colab environment, so I am uploading the following files of code:\r\n- inception_v3.py - this is the CNN.\r\n- modeling.py - this module implements the tf.Estimator API, and is responsible for handling tensorboard summaries (those that are not taken care of by the Estimator itself).\r\n\r\n- main.py - this creates the estimator and runs it, with different input functions that you can play with. I implemented a couple of input functions which generate fake images in various patterns ('steps', 'zebra', 'arange', 'arange_mod_10') and another input function that loads an image similar to the actual scenario ('load_img'). You can pick and choose the input_fn to use by changing the variable input_fn_mode to any of the above.\r\n\r\nI am also attaching the two files:\r\n- my_img.npy - the image which I load when the input_fn_mode='load_img'\r\n- environment.yml - my conda environment\r\n\r\nThe behaviour I mentioned (with the special relu) happens on the 'load_img' input_fn, and in the other input_fn_mode's other weird things happen, which make the eval images look different than train images.\r\n\r\n[all_files.zip](https://github.com/tensorflow/tensorflow/files/5651109/all_files.zip)\r\n\r\nShould any additional information/clarification be needed, please let me know.\r\nThanks in advance!", "@yonatansc97 It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest  stable Version of TF 2.5 and let us know if the issue still persists? Thanks!", "Actually, I have since then moved to pytorch. No such problems now, I'm afraid.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45428\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45428\">No</a>\n"]}, {"number": 45427, "title": "[pylintrc] Enforce Google docstring format", "body": "Related: #45420 \r\nRequested by: @bhack", "comments": ["@mihaimaruseac @av8ramit Do you know if we have a similar lint (See #45420) available internally as well?  Linting only for public CI doesn't seem like a good idea.", "@kkimdev Can you invoke Kokoro with a label in the meantime?", "@SamuelMarks It Is not working you need one of these solutions https://github.com/PyCQA/pylint/issues/735#issuecomment-164144803", "@SamuelMarks  Can you please check @bhack's comments and keep us posted ? Thanks!", "> @SamuelMarks  Can you please check @bhack's comments and keep us posted ? Thanks!\n\nYes this PR needs to fail tests now and then It need to pass tests after #45420.", "@gbaned Can you add the kokoro label so that we can check tests?", "The check Is not working", "@bhack If you're talking about the CI, looks like a different issue:\r\n> Executed 2192 out of 2397 tests: 2397 tests pass.\r\nThere were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.\r\nAll tests passed but there were other errors during the build.\r\n\r\nSpecifically:\r\n> ERROR: /Volumes/BuildData/tmpfs/src/github/tensorflow/tensorflow/lite/python/BUILD:31:1: in deps attribute of py_test rule //tensorflow/lite/python:interpreter_test: '//tensorflow/lite/kernels:deprecated_backends' does not have mandatory providers: 'py' or 'PyInfo'", "I am talking about that that tests are passing. They need to fail if we need to enforce `arg:`.", "\ud83e\udd14\r\n```\r\n$ pylint --rcfile='tensorflow/tools/ci_build/pylintrc' 'tensorflow/compiler/xla/python/xla_client.py'\r\n************* Module python.xla_client\r\ntensorflow/compiler/xla/python/xla_client.py:66:0: W9015: \"distributed_client, node_id\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:66:0: W9016: \"distributed_client, node_id\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:125:6: R1720: Unnecessary \"else\" after \"raise\" (no-else-raise)\r\ntensorflow/compiler/xla/python/xla_client.py:137:0: W9016: \"name\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:137:0: W9012: Missing return type documentation (missing-return-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:137:0: W9006: \"RuntimeError\" not documented as being raised (missing-raises-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:153:6: W0707: Consider explicitly re-raising using the 'from' keyword (raise-missing-from)\r\ntensorflow/compiler/xla/python/xla_client.py:137:0: W9012: Missing return type documentation (missing-return-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:159:0: R0205: Class 'OpMetadata' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:159:0: W9015: \"op_name, op_type, source_file, source_line\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:159:0: W9016: \"op_name, op_type, source_file, source_line\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:170:0: W9015: \"op_name, op_type, skip_frames\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:170:0: W9016: \"op_name, op_type, skip_frames\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:213:0: W9015: \"dtype\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:213:0: W9016: \"dtype\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:279:0: W9015: \"pyval\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:279:0: W9016: \"pyval\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:283:4: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\ntensorflow/compiler/xla/python/xla_client.py:341:0: W9015: \"arguments, backend, executable\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:341:0: W9016: \"arguments, backend, executable\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:352:0: W9016: \"arguments, backend, executable\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:352:0: W9012: Missing return type documentation (missing-return-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:386:0: W9015: \"lhs_dims, padding_type, rhs_dims, window_strides\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:386:0: W9016: \"lhs_dims, padding_type, rhs_dims, window_strides\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:402:2: R1705: Unnecessary \"elif\" after \"return\" (no-else-return)\r\ntensorflow/compiler/xla/python/xla_client.py:426:0: W9016: \"fn, name, platform\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:441:0: R0205: Class 'PaddingConfigDimension' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:451:0: R0205: Class 'PaddingConfig' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:472:5: R1701: Consider merging these isinstance calls to isinstance(padding_config, (list, tuple)) (consider-merging-isinstance)\r\ntensorflow/compiler/xla/python/xla_client.py:484:0: R0205: Class 'DotDimensionNumbers' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:512:2: R1705: Unnecessary \"else\" after \"return\" (no-else-return)\r\ntensorflow/compiler/xla/python/xla_client.py:524:0: R0205: Class 'ConvolutionDimensionNumbers' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:608:0: R0205: Class 'OpSharding' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:623:0: R0205: Class 'PrecisionConfig' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:633:0: R0205: Class 'GatherDimensionNumbers' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:645:0: R0205: Class 'ScatterDimensionNumbers' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:657:0: R0205: Class 'ReplicaGroup' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\ntensorflow/compiler/xla/python/xla_client.py:686:0: W9015: \"enabled\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:686:0: W9016: \"enabled\" missing in parameter type documentation (missing-type-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:696:0: W9015: \"client\" missing in parameter documentation (missing-param-doc)\r\ntensorflow/compiler/xla/python/xla_client.py:33:0: C0411: third party import \"from absl import logging\" should be placed before \"from . import xla_extension as _xla\" (wrong-import-order)\r\ntensorflow/compiler/xla/python/xla_client.py:34:0: C0411: third party import \"import numpy as np\" should be placed before \"from . import xla_extension as _xla\" (wrong-import-order)\r\n\r\n------------------------------------------------------------------\r\nYour code has been rated at 8.47/10 (previous run: 8.47/10, +0.00)\r\n```", "The lint script that runs in the CI Is https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_sanity.sh", "Probably we need to extend the pattern at https://github.com/tensorflow/tensorflow/blob/84de9ebadc5d8366ce26980241ebe6e2ca1ad391/tensorflow/tools/ci_build/ci_sanity.sh#L203:L213", "@mihaimaruseac If we approve #45420 do we want to expand the pattern matching string here over the error list that we care?\n\n/cc @MarkDaoust as it is a doc topic."]}, {"number": 45426, "title": "keras.model.predict doesn't work when using multiprocessing", "body": "I am using scipy.optimize.differential_evolution to optimize my autoencoder weights. The individuals are 20 combination of weights.\r\n\r\n`result = differential_evolution(obj_func, bounds, args=args, strategy='best1bin', maxiter=2, popsize=20, tol=1e-6, mutation=(0.5, 1), recombination=0.3, seed=None, callback=printCurrentIteration, disp=True, polish=False, init=pop, atol=0, updating='deferred', workers=5)`\r\n\r\nIn my obj_func there is a part to get output from keras.model.predict(), here is my naive code:\r\n\r\n```\r\ndef obj_func(x, *args):\r\n         final_output = predict(x, data_p)\r\n         \u2026\u2026\r\n```\r\n\r\n```\r\ndef predict(para, data_p): \r\n    new_weight_e1 = para[0:352].reshape(22, 16)\r\n    new_weight_b1 = para[352:368].reshape(16, )\r\n    new_weight_e2 = para[368:496].reshape(16, 8)\r\n    new_weight_b2 = para[496:504].reshape(8, )\r\n    new_weight_e3 = para[504:520].reshape(8, 2)\r\n    new_weight_b3 = para[520:522].reshape(2, )\r\n    new_weight_d1 = para[522:538].reshape(2, 8)\r\n    new_weight_b4 = para[538:546].reshape(8, )\r\n    new_weight_d2 = para[546:674].reshape(8, 16)\r\n    new_weight_b5 = para[674:690].reshape(16, )\r\n    new_weight_d3 = para[690:1042].reshape(16, 22)\r\n    new_weight_b6 = para[1042:1064].reshape(22, )\r\n    autoencoder.get_layer('e1').set_weights([(new_weight_e1), (new_weight_b1)])\r\n    autoencoder.get_layer('e2').set_weights([(new_weight_e2), (new_weight_b2)])\r\n    autoencoder.get_layer('out').set_weights([(new_weight_e3), (new_weight_b3)])\r\n    autoencoder.get_layer('d1').set_weights([(new_weight_d1), (new_weight_b4)])\r\n    autoencoder.get_layer('d2').set_weights([(new_weight_d2), (new_weight_b5)])\r\n    autoencoder.get_layer('d3').set_weights([(new_weight_d3), (new_weight_b6)])\r\n\r\n    output_layer_model = Model(inputs=autoencoder.input, outputs=decoded)\r\n    final_output = output_layer_model.predict(data_p)\r\n    \r\n    return final_output\r\n```\r\n\r\nIn function `predict()` I reshape the individual(weights), build the model and predict. \r\nIn differential_evolution people can easily implement multiprocessing by setting 'workers' to more than 1. \r\nWhen I set it to 1, there is no problem. But when I set it to e.g. 5, want to predict parallel, the progress stopped here:\r\n\r\n` final_output = output_layer_model.predict(data_p)`\r\n\r\nNo errors, it was still running but did not go further (didn't get the `final_ouput`). (The code before this line goes parallel without problem)\r\n\r\nWhat I've tried:\r\n1.\r\nadd` os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"`, only use multiple CPUs to predict, didn't work for me.\r\n2.\r\ncompile the model inside the function, also didn't work.\r\n3.\r\nsave the weights as .h5 file and load, also didn't work.\r\n\r\nAgain, it works well when only using 1 CPU. So I think the problem might be `keras.model.predict()` and `multiprocessing` but I didn't figure it out. I've done some search but didn't find a solution, maybe I didn't grasp the point because my English is not good. So any suggestions or guidance will be appreciated!\r\n", "comments": ["@u1s1QS,\r\nIn order to expedite the trouble-shooting process, please provide the following details\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nand also a minimal code snippet, so that we can reproduce the issue on our end. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45426\">No</a>\n"]}, {"number": 45424, "title": "Traceback (most recent call last):", "body": "can any one tell what has happen here \r\n![Capturea](https://user-images.githubusercontent.com/75528881/101243050-9057fa80-3723-11eb-977e-fcceef6f654c.JPG)\r\n", "comments": ["pip install Pillow", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45424\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45424\">No</a>\n"]}, {"number": 45423, "title": "cuDNN issue in TF", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- I use custom code\r\n- Windows 10 Pro\r\n- TensorFlow installed from pip\r\n- TensorFlow version == 2.3.1\r\n- python == 3.8.6\r\n- CUDA/cuDNN version: 10.1 / 7.6.5\r\n- GPU model and memory: GeForce RTX 2080 SUPER\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n**Other info / logs**\r\n\r\n```python\r\nD:\\00.dev\\Anaconda\\envs\\jh-ip\\python.exe D:/02.users/jaehochang/gits/Autoencoders/main.py\r\n2020-12-05 14:22:07.727822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\nNVIDIA GPU info.:\r\n[{'index': '0',\r\n  'mem_total': 8192,\r\n  'mem_used': 2475,\r\n  'mem_used_percent': 30.21240234375,\r\n  'type': 'GeForce RTX 2080 SUPER',\r\n  'uuid': '...'}]\r\n\r\n{'videos': ['D:/20.share/jaehochang/SP2Robotics/videos\\\\vid1.mp4',\r\n            'D:/20.share/jaehochang/SP2Robotics/videos\\\\vid2.mkv',\r\n            'D:/20.share/jaehochang/SP2Robotics/videos\\\\vid3.mkv']}\r\nVideos found correctly? */n: \r\nWhich video? 1/2/3/...: 3\r\nCapturing vid3.mkv ...\r\nVolume shape: (165, 1088, 1920, 3)\r\nWrite volume array? */n: \r\n\r\nCapturing vid3_AGN.avi ...\r\nVolume shape: (165, 1088, 1920, 3)\r\nWrite volume array? */n: \r\n\r\n2020-12-05 14:22:40.544902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-12-05 14:22:40.605546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5\r\ncoreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s\r\n2020-12-05 14:22:40.605721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-12-05 14:22:41.024671: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-05 14:22:41.268418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-12-05 14:22:41.292114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-12-05 14:22:41.515595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-12-05 14:22:41.712017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-12-05 14:22:41.917475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-05 14:22:41.917629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-12-05 14:22:41.918243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-05 14:22:41.926740: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26380efa3e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-05 14:22:41.926862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-12-05 14:22:41.927041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5\r\ncoreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s\r\n2020-12-05 14:22:41.927191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-12-05 14:22:41.927267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-05 14:22:41.927337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-12-05 14:22:41.927412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-12-05 14:22:41.927484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-12-05 14:22:41.927554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-12-05 14:22:41.927623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-05 14:22:41.927717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-12-05 14:22:42.588437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-12-05 14:22:42.588531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-12-05 14:22:42.588582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-12-05 14:22:42.588761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6598 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5)\r\n2020-12-05 14:22:42.591519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x263ae5c79c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-12-05 14:22:42.591639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 SUPER, Compute Capability 7.5\r\nTrain volume shape:\r\n   (99, 2, 432, 768, 3)\r\nTest volume shape: \r\n   (66, 2, 432, 768, 3)\r\n\r\n\r\n===== You're trying ...\r\nmname:      vid3-AGN-500epc-1btc\r\n=====\r\n\r\nProceed? */n: \r\nVirtual devices cannot be modified after being initialized\r\nYour model:\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d (Conv2D)              (None, 432, 768, 36)      1008      \r\n_________________________________________________________________\r\nbatch_normalization (BatchNo (None, 432, 768, 36)      144       \r\n_________________________________________________________________\r\nup_sampling2d (UpSampling2D) (None, 864, 1536, 36)     0         \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (None, 864, 1536, 36)     144       \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (None, 864, 1536, 36)     11700     \r\n_________________________________________________________________\r\nbatch_normalization_2 (Batch (None, 864, 1536, 36)     144       \r\n_________________________________________________________________\r\nmax_pooling2d (MaxPooling2D) (None, 432, 768, 36)      0         \r\n_________________________________________________________________\r\nbatch_normalization_3 (Batch (None, 432, 768, 36)      144       \r\n_________________________________________________________________\r\nconv2d_2 (Conv2D)            (None, 432, 768, 3)       975       \r\n=================================================================\r\nTotal params: 14,259\r\nTrainable params: 13,971\r\nNon-trainable params: 288\r\n_________________________________________________________________\r\nNone\r\nFit? */n: \r\nEpoch 1/500\r\n2020-12-05 14:22:51.499832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-05 14:22:52.667191: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-12-05 14:22:52.668713: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-12-05 14:22:52.668804: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_ops_fused_impl.h:642 : Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\nTraceback (most recent call last):\r\n  File \"D:/02.users/jaehochang/gits/Autoencoders/main.py\", line 55, in <module>\r\n    history = my_model.fit(train[:, 1], train[:, 0],  # noisy train, clean train\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 840, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1843, in _filtered_call\r\n    return self._call_flat(\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1923, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 545, in call\r\n    outputs = execute.execute(\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node sequential/conv2d/Relu (defined at /02.users/jaehochang/gits/Autoencoders/main.py:55) ]] [Op:__inference_train_function_2470]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\nProcess finished with exit code 1\r\n```", "comments": ["I'm constantly getting `Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED` issue.", "> I'm constantly getting `Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED` issue.\r\n\r\nhttps://starriet.medium.com/tensorflow-2-0-wanna-limit-gpu-memory-10ad474e2528\r\nThe fix is limiting the VRAM (in my case 512-1024M less than the VRAM capacity, YMMV).", "@jaehochang92,\r\nCould you please try setting a hard limit on the total GPU memory as mentioned in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps. \r\n\r\nAlso, please go through issue [#24496](https://github.com/tensorflow/tensorflow/issues/24496#issuecomment-464909727) with a similar error and check if it works. Thanks!", "> > I'm constantly getting `Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED` issue.\r\n> \r\n> https://starriet.medium.com/tensorflow-2-0-wanna-limit-gpu-memory-10ad474e2528\r\n> The fix is limiting the VRAM (in my case 512-1024M less than the VRAM capacity, YMMV).\r\n\r\nThank you for the aid, but, I'm still getting the same errors and plus `failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED` ; ((", "> @jaehochang92,\r\n> Could you please try setting a hard limit on the total GPU memory as mentioned in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps.\r\n> \r\n> Also, please go through issue [#24496](https://github.com/tensorflow/tensorflow/issues/24496#issuecomment-464909727) with a similar error and check if it works. Thanks!\r\n\r\nThank you. I'm working on a shared GPU and I've added the following as TF documentation is directing on setting a memory limit for a shared GPU:\r\n```python\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n    try:\r\n        tf.config.experimental.set_virtual_device_configuration(\r\n            gpus[0],\r\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5* 1024)]\r\n        )\r\n    except RuntimeError as e:\r\n        print(e)\r\n```\r\nBut I'm still getting `failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED` and `Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED`.", "This reproduces my error:\r\n\r\n```python\r\n# This is a standalone code for reproducing bugs or issues.\r\nimport tensorflow as tf  # tf == 2.3.1\r\nimport numpy as np\r\nimport nvgpu\r\n\r\nfrom pprint import pprint\r\nfrom sklearn import model_selection\r\nfrom tensorflow.keras.layers import Input, BatchNormalization\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dense\r\n\r\ntf.keras.backend.clear_session()\r\n\r\nprint('NVIDIA GPU info.:')\r\npprint(nvgpu.gpu_info())\r\nprint()\r\n\r\n\r\ndef prepare_dataset(volume: np.array, ts_size: float) -> np.array:\r\n    zipped_vol = np.array([*zip(volume[:, 0], volume[:, 1])])\r\n    tr, ts = split_trts(zipped_vol, ts_size)\r\n    print('Train volume shape:')\r\n    print('  ', tr.shape)\r\n    print('Test volume shape: ')\r\n    print('  ', ts.shape)\r\n    print()\r\n    return tr, ts\r\n\r\n\r\ndef split_trts(video_volume, ts_size):\r\n    vol_tr, vol_ts = model_selection.train_test_split(video_volume, test_size=ts_size)\r\n    vol_tr, vol_ts = np.asarray(vol_tr), np.asarray(vol_ts)\r\n    vol_tr = vol_tr.astype(\"float32\") / 255.\r\n    vol_ts = vol_ts.astype(\"float32\") / 255.\r\n    return vol_tr, vol_ts\r\n\r\n\r\ndef config_gpus(memory_limit):\r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    if gpus:\r\n        try:\r\n            tf.config.experimental.set_virtual_device_configuration(\r\n                gpus[0],\r\n                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit * 1024)]\r\n            )\r\n        except RuntimeError as e:\r\n            print(e)\r\n\r\n\r\ndef build_model(input_shape, cnn_filters):\r\n    model = tf.keras.Sequential()\r\n    model.add(Input(input_shape))\r\n    for depth in cnn_filters:\r\n        model.add(Conv2D(depth, (3, 3), activation='relu', padding='same'))\r\n        model.add(BatchNormalization())\r\n    model.add(UpSampling2D((2, 2)))\r\n    model.add(BatchNormalization())\r\n    for depth in cnn_filters[::-1]:\r\n        model.add(Conv2D(depth, (3, 3), activation='relu', padding='same'))\r\n        model.add(BatchNormalization())\r\n    model.add(MaxPooling2D((2, 2), padding='same'))\r\n    model.add(BatchNormalization())\r\n    for depth in cnn_filters:\r\n        model.add(Conv2D(depth, (3, 3), activation='relu', padding='same'))\r\n        model.add(BatchNormalization())\r\n    model.add(Dense(3))\r\n    optmz = tf.keras.optimizers.SGD(momentum=.05)\r\n    loss = tf.keras.losses.MeanSquaredError()\r\n    model.compile(optmz, loss)\r\n    return model\r\n\r\n\r\nfoo_volume = tf.random.uniform(\r\n    (1000, 2, 128, 128, 3), minval=0, maxval=255, dtype=tf.dtypes.int32, seed=None, name=None\r\n)\r\ntrain, test = prepare_dataset(foo_volume, ts_size=0.4)\r\nconfig_gpus(5)\r\ntf.debugging.set_log_device_placement(True)\r\nmy_model = build_model(train.shape[2:], [64, 64, 64])\r\nprint('Your model:'), print(my_model.summary())\r\nif input(\"Proceed? */n: \") != 'n':\r\n    history = my_model.fit(train[:, 1], train[:, 0],  # noisy train, clean train\r\n                           batch_size=4, epochs=20000, verbose=True,\r\n                           validation_data=(test[:, 1], test[:, 0])).history\r\n```\r\n\r\nAnd this results in...\r\n\r\n```\r\nD:\\00.dev\\Anaconda\\envs\\jh-ip\\python.exe D:/02.users/jaehochang/gits/Autoencoders/debugging.py\r\n2020-12-07 12:48:13.226923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\nNVIDIA GPU info.:\r\n[{'index': '0',\r\n  'mem_total': 8192,\r\n  'mem_used': 1620,\r\n  'mem_used_percent': 19.775390625,\r\n  'type': 'GeForce RTX 2080 SUPER',\r\n  'uuid': ...}]\r\n\r\n2020-12-07 12:48:15.909482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-12-07 12:48:15.948027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5\r\ncoreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s\r\n2020-12-07 12:48:15.948351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-12-07 12:48:15.955311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-07 12:48:15.958050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-12-07 12:48:15.959191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-12-07 12:48:15.962691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-12-07 12:48:15.965691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-12-07 12:48:15.972593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-07 12:48:15.972749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-12-07 12:48:15.973284: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-07 12:48:15.983121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x210a1480c90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-07 12:48:15.983253: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-12-07 12:48:15.983451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5\r\ncoreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s\r\n2020-12-07 12:48:15.983590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-12-07 12:48:15.983661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-07 12:48:15.983730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-12-07 12:48:15.983803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-12-07 12:48:15.983877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-12-07 12:48:15.983951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-12-07 12:48:15.984022: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-07 12:48:15.984107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-12-07 12:48:16.594642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-12-07 12:48:16.594732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-12-07 12:48:16.594780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-12-07 12:48:16.594938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6598 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5)\r\n2020-12-07 12:48:16.597744: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x210cf29d150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-12-07 12:48:16.597859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 SUPER, Compute Capability 7.5\r\nTrain volume shape:\r\n   (600, 2, 128, 128, 3)\r\nTest volume shape: \r\n   (400, 2, 128, 128, 3)\r\n\r\nVirtual devices cannot be modified after being initialized\r\nYour model:\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d (Conv2D)              (None, 128, 128, 64)      1792      \r\n_________________________________________________________________\r\nbatch_normalization (BatchNo (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (None, 128, 128, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\nconv2d_2 (Conv2D)            (None, 128, 128, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_2 (Batch (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\nup_sampling2d (UpSampling2D) (None, 256, 256, 64)      0         \r\n_________________________________________________________________\r\nbatch_normalization_3 (Batch (None, 256, 256, 64)      256       \r\n_________________________________________________________________\r\nconv2d_3 (Conv2D)            (None, 256, 256, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_4 (Batch (None, 256, 256, 64)      256       \r\n_________________________________________________________________\r\nconv2d_4 (Conv2D)            (None, 256, 256, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_5 (Batch (None, 256, 256, 64)      256       \r\n_________________________________________________________________\r\nconv2d_5 (Conv2D)            (None, 256, 256, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_6 (Batch (None, 256, 256, 64)      256       \r\n_________________________________________________________________\r\nmax_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \r\n_________________________________________________________________\r\nbatch_normalization_7 (Batch (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\nconv2d_6 (Conv2D)            (None, 128, 128, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_8 (Batch (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\nconv2d_7 (Conv2D)            (None, 128, 128, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_9 (Batch (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\nconv2d_8 (Conv2D)            (None, 128, 128, 64)      36928     \r\n_________________________________________________________________\r\nbatch_normalization_10 (Batc (None, 128, 128, 64)      256       \r\n_________________________________________________________________\r\ndense (Dense)                (None, 128, 128, 3)       195       \r\n=================================================================\r\nTotal params: 300,227\r\nTrainable params: 298,819\r\nNon-trainable params: 1,408\r\n_________________________________________________________________\r\nNone\r\nProceed? */n: \r\nEpoch 1/20000\r\n2020-12-07 12:48:21.149807: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-07 12:48:21.431219: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-12-07 12:48:21.431686: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-12-07 12:48:21.431805: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2020-12-07 12:48:21.440341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-07 12:48:22.542557: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-12-07 12:48:22.545222: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-12-07 12:48:22.545329: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_ops_fused_impl.h:642 : Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\nTraceback (most recent call last):\r\n  File \"D:/02.users/jaehochang/gits/Autoencoders/debugging.py\", line 84, in <module>\r\n    history = my_model.fit(train[:, 1], train[:, 0],  # noisy train, clean train\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 840, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1843, in _filtered_call\r\n    return self._call_flat(\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1923, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 545, in call\r\n    outputs = execute.execute(\r\n  File \"D:\\00.dev\\Anaconda\\envs\\jh-ip\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node sequential/conv2d/Relu (defined at /02.users/jaehochang/gits/Autoencoders/debugging.py:84) ]] [Op:__inference_train_function_10722]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\nProcess finished with exit code 1\r\n```", "@jaehochang92,\r\nThank you for the update. I'm facing issues while running the code, the `prepare_dataset` method seems to run indefinitely. \r\n\r\nCould you please provide a minimal code snippet so that we can reproduce the issue on our end. Thanks!", "> @jaehochang92,\r\n> Thank you for the update. I'm facing issues while running the code, the `prepare_dataset` method seems to run indefinitely.\r\n> \r\n> Could you please provide a minimal code snippet so that we can reproduce the issue on our end. Thanks!\r\n\r\nThank you for the feedback. It is weird since `prepare_dataset` is working well in my machine... By the way, unexpectedly, I found a simple solution. All I needed to do was moving the following code above `foo_volume` declaration:\r\n```python\r\nconfig_gpus(5)\r\ntf.debugging.set_log_device_placement(True)\r\n```\r\nI think the bug appeared because I tried to set the virtual device again after calling `tensorflow` method. This maybe a code design issue when a newbie like me try to configure virtual device in an inappropriate order...", "> By the way, unexpectedly, I found a simple solution. All I needed to do was moving the following code above `foo_volume` declaration\r\n\r\n@jaehochang92,\r\nThank you for the update. Glad its working now. Marking the issue as closed since it is resolved. Please feel free to reopen if necessary.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45423\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45423\">No</a>\n"]}, {"number": 45422, "title": "While running tenosrflow object detection code i got this error.", "body": "\r\n\r\n2020-12-05` 10:41:45.702033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\nTraceback (most recent call last):\r\n  File \"Object_detection_picamera.py\", line 44, in <module>\r\n    od_graph_def.ParseFromString(serialized_graph)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/message.py\", line 199, in ParseFromString\r\n    return self.MergeFromString(serialized)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\", line 1145, in MergeFromString\r\n    if self._InternalParse(serialized, 0, length) != length:\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\", line 1212, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 754, in DecodeField\r\n    if value._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\", line 1212, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 733, in DecodeRepeatedField\r\n    if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\", line 1212, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 888, in DecodeMap\r\n    if submsg._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\", line 1205, in InternalParse\r\n    new_pos = local_SkipField(buffer, old_pos, end, tag_bytes)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 1053, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 952, in _SkipGroup\r\n    new_pos = SkipField(buffer, pos, end, tag_bytes)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 1053, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\", line 1009, in _SkipFixed32\r\n    raise _DecodeError('Truncated message.')\r\ngoogle.protobuf.message.DecodeError: Truncated message.\r\n\r\n", "comments": ["@RD191295 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "1.  Tensorflow 2.0\r\n2. platform : jetson nano board \r\n\r\n\r\n`import os\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom utils import visualization_utils as vis_util\r\nfrom utils import label_map_util\r\n\r\nIM_WIDTH = 1280\r\nIM_HEIGHT = 720\r\n\r\ndef gstreamer_pipeline (capture_width=IM_WIDTH, capture_height=IM_HEIGHT, display_width=IM_WIDTH, display_height=IM_HEIGHT, framerate=60, flip_method=0) :   \r\n    return ('nvarguscamerasrc ! ' \r\n    'video/x-raw(memory:NVMM), '\r\n    'width=(int)%d, height=(int)%d, '\r\n    'format=(string)NV12, framerate=(fraction)%d/1 ! '\r\n    'nvvidconv flip-method=%d ! '\r\n    'video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! '\r\n    'videoconvert ! '\r\n    'video/x-raw, format=(string)BGR ! appsink'  % (capture_width,capture_height,framerate,flip_method,display_width,display_height))\r\n\r\n\r\nMODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09'\r\nLABELS = 'label_map.pbtxt'\r\n\r\nNUM_CLASSES = 1\r\n\r\nCWD_PATH = os.getcwd()\r\n\r\nPATH_TO_CKPT = os.path.join(CWD_PATH, MODEL_NAME, 'frozen_inference_graph.pb')\r\n\r\nPATH_TO_LABELS = os.path.join(CWD_PATH, 'labels', LABELS)\r\n\r\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\ncategory_index = label_map_util.create_category_index(categories)\r\n\r\n\r\ndetection_graph = tf.compat.v1.Graph()\r\nwith detection_graph.as_default():\r\n    od_graph_def = tf.compat.v1.GraphDef()\r\n    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n        serialized_graph = fid.read()\r\n        od_graph_def.ParseFromString(serialized_graph)\r\n        tf.import_graph_def(od_graph_def, name='')\r\n\r\n    TFSess = tf.compat.v1.Session(graph=detection_graph)\r\n\r\nimage_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\r\n\r\ndetection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\r\n\r\n\r\ndetection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\r\ndetection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\r\n\r\n\r\nnum_detections = detection_graph.get_tensor_by_name('num_detections:0')\r\n\r\nframe_rate_calc = 1\r\nfreq = cv2.getTickFrequency()\r\nfont = cv2.FONT_HERSHEY_SIMPLEX\r\n\r\nWIN_NAME = 'To\u00f1ito\\'s Detection'\r\n\r\n\r\ncap = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\r\nif cap.isOpened():\r\n    window_handle = cv2.namedWindow(WIN_NAME, cv2.WINDOW_AUTOSIZE)\r\n\r\nframeCount = 0\r\n\r\nwhile cv2.getWindowProperty(WIN_NAME,0) >= 0:\r\n\r\n    t1 = cv2.getTickCount()\r\n\r\n    ret_val, frame = cap.read();\r\n    frame.setflags(write=1)\r\n    frame_expanded = np.expand_dims(frame, axis=0)#no optimizable\r\n\r\n    (boxes, scores, classes, num) = TFSess.run(\r\n        [detection_boxes, detection_scores, detection_classes, num_detections],\r\n        feed_dict={image_tensor: frame_expanded})\r\n\r\n    vis_util.visualize_boxes_and_labels_on_image_array(\r\n        frame,\r\n        np.atleast_2d(np.squeeze(boxes)),#no optimizable\r\n        np.atleast_1d(np.squeeze(classes).astype(np.int32)),\r\n        np.atleast_1d(np.squeeze(scores)),\r\n        category_index,\r\n        use_normalized_coordinates=True,\r\n        line_thickness=8,\r\n        min_score_thresh=0.50)\r\n\r\n    cv2.putText(frame,\"FPS: {0:.2f}\".format(frame_rate_calc),(30,50),font,1,(255,255,0),2,cv2.LINE_AA)\r\n\r\n    cv2.imshow(WIN_NAME, frame)\r\n\r\n    t2 = cv2.getTickCount()\r\n    time1 = (t2-t1)/freq\r\n    frame_rate_calc = 1/time1\r\n\r\n    frameCount+=1\r\n\r\n    if cv2.waitKey(1) == ord('q'):\r\n        break\r\n\r\ncap.release()\r\n\r\ncv2.destroyAllWindows()\r\n`", "@RD191295 \r\nI ran the code shared and there are too many syntac and indentation issues, please share code that is indented or if possible share a [colab gist](https://colab.research.google.com/gist/Saduf2019/a395a3980a0d7a28e07f5225a284218e/untitled.ipynb)", "can you try to run this code.\r\nhttps://colab.research.google.com/drive/1DAxkDY0hwxra6kSMLIZuTVHO36x4jtIa?usp=sharing", "this require model file and .pbtxt file also. if needed please let me know how can i send this..", "@RD191295 \r\ni ran the code and face different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/573e2f250ad7f52bd8b2b895a2fe6055/untitled479.ipynb), please use the attachment options to share all dependencies.", "PLEASE find gist here. i uploaded all dependencies required to run code.[https://colab.research.google.com/gist/RD191295/8410cd53e88b0a7dbf69297da02fece3/untitled479.ipynb](url)", "@RD191295 \r\nCould you please check the gist once, there is no gist there.", "@Saduf2019 \r\ncan you please check this. \r\nhttps://colab.research.google.com/gist/Saduf2019/573e2f250ad7f52bd8b2b895a2fe6055/untitled479.ipynb", "@RD191295 \r\nCould you please refer to this isse and let us know if [this comment helps](https://github.com/tensorflow/models/issues/4864#issuecomment-407600939).", "Problem is not about any object detection api failed to import.. I am running code on Nvidia gpu board with camera.. But when I run I get above mentioned error.. Still not able to find what this means... If I import object detection api it is working and I can able to import correctly but when I load my newly trained model it is not working.. I tested model on google colab it's working there but not on board.. Can you help me to debug... ", "@RD191295 Can you please try recent TF version and let us know whether the error persists. Thanks!", "As per Nvidia board i have a latest tf version that mention by nvidia . what is mean by this error:\r\n\r\ngoogle.protobuf.message.DecodeError: Truncated message.", "i solved above error but now i got this error.you can check  <a href=\"https://colab.research.google.com/gist/RD191295/8d8221c0682b1824f175613c991a1977/untitled479.ipynb\">Code </a>here.\r\n\r\n<b>Error:</b>\r\n\r\n<code>\r\n2020-12-14 14:04:06.494954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:05:08.574379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-12-14 14:05:08.714733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:08.757362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1742] Found device 0 with properties: \r\npciBusID: 0000:00:00.0 name: NVIDIA Tegra X1 computeCapability: 5.3\r\ncoreClock: 0.9216GHz coreCount: 1 deviceMemorySize: 3.86GiB deviceMemoryBandwidth: 194.55MiB/s\r\n2020-12-14 14:05:08.758517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:05:08.946763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2020-12-14 14:05:09.061552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-12-14 14:05:09.183840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-12-14 14:05:09.337267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-12-14 14:05:09.495107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2020-12-14 14:05:09.585367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-12-14 14:05:09.601846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:09.602445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:09.602687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1884] Adding visible gpu devices: 0\r\n2020-12-14 14:05:10.298923: W tensorflow/core/platform/profile_utils/cpu_utils.cc:108] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\r\n2020-12-14 14:05:10.331369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a13b270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-14 14:05:10.331699: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-12-14 14:05:10.744351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:10.744687: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2907c160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-12-14 14:05:10.744752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tegra X1, Compute Capability 5.3\r\n2020-12-14 14:05:10.780477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:10.780732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1742] Found device 0 with properties: \r\npciBusID: 0000:00:00.0 name: NVIDIA Tegra X1 computeCapability: 5.3\r\ncoreClock: 0.9216GHz coreCount: 1 deviceMemorySize: 3.86GiB deviceMemoryBandwidth: 194.55MiB/s\r\n2020-12-14 14:05:10.781208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:05:10.787810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2020-12-14 14:05:10.788037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-12-14 14:05:10.788197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-12-14 14:05:10.788324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-12-14 14:05:10.788440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2020-12-14 14:05:10.788552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-12-14 14:05:10.788940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:10.789324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:10.789415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1884] Adding visible gpu devices: 0\r\n2020-12-14 14:05:10.789596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:05:42.706472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1283] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-12-14 14:05:42.996207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1289]      0 \r\n2020-12-14 14:05:42.996297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1302] 0:   N \r\n2020-12-14 14:05:44.173179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:45.640780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:05:45.870737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1428] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 156 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X1, pci bus id: 0000:00:00.0, compute capability: 5.3)\r\nalteama@alteama-desktop:~/TensorFlow$ python3 Test_img_detection.py\r\n2020-12-14 14:11:20.442051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:12:11.419538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-12-14 14:12:11.483063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:11.483245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1742] Found device 0 with properties: \r\npciBusID: 0000:00:00.0 name: NVIDIA Tegra X1 computeCapability: 5.3\r\ncoreClock: 0.9216GHz coreCount: 1 deviceMemorySize: 3.86GiB deviceMemoryBandwidth: 194.55MiB/s\r\n2020-12-14 14:12:11.483429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:12:11.659131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2020-12-14 14:12:11.737201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-12-14 14:12:11.847971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-12-14 14:12:11.983642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-12-14 14:12:12.059869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2020-12-14 14:12:12.064247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-12-14 14:12:12.064683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:12.065050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:12.065148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1884] Adding visible gpu devices: 0\r\n2020-12-14 14:12:12.100819: W tensorflow/core/platform/profile_utils/cpu_utils.cc:108] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\r\n2020-12-14 14:12:12.101505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xc590cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-14 14:12:12.101573: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-12-14 14:12:12.269163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:12.269481: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xc57c6d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-12-14 14:12:12.269541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tegra X1, Compute Capability 5.3\r\n2020-12-14 14:12:12.270090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:12.270212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1742] Found device 0 with properties: \r\npciBusID: 0000:00:00.0 name: NVIDIA Tegra X1 computeCapability: 5.3\r\ncoreClock: 0.9216GHz coreCount: 1 deviceMemorySize: 3.86GiB deviceMemoryBandwidth: 194.55MiB/s\r\n2020-12-14 14:12:12.270422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:12:12.270569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2020-12-14 14:12:12.270670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-12-14 14:12:12.270748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-12-14 14:12:12.270825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-12-14 14:12:12.270901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2020-12-14 14:12:12.270983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-12-14 14:12:12.271294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:12.271661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:12.271733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1884] Adding visible gpu devices: 0\r\n2020-12-14 14:12:12.271869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2020-12-14 14:12:17.462880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1283] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-12-14 14:12:17.463028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1289]      0 \r\n2020-12-14 14:12:17.463080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1302] 0:   N \r\n2020-12-14 14:12:17.479345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:17.480109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1046] ARM64 does not support NUMA - returning NUMA node zero\r\n2020-12-14 14:12:17.480443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1428] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 161 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X1, pci bus id: 0000:00:00.0, compute capability: 5.3)\r\n2020-12-14 14:16:33.906521: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 27.85MiB (rounded to 29203200)requested by op SameWorkerRecvDone\r\nCurrent allocation summary follows.\r\n2020-12-14 14:16:33.906672: I tensorflow/core/common_runtime/bfc_allocator.cc:970] BFCAllocator dump for GPU_0_bfc\r\n2020-12-14 14:16:33.906729: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (256): \tTotal Chunks: 59, Chunks in use: 56. 14.8KiB allocated for chunks. 14.0KiB in use in bin. 7.7KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.906771: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (512): \tTotal Chunks: 36, Chunks in use: 35. 18.0KiB allocated for chunks. 17.5KiB in use in bin. 17.1KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.906813: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (1024): \tTotal Chunks: 244, Chunks in use: 244. 244.2KiB allocated for chunks. 244.2KiB in use in bin. 244.0KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.906860: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (2048): \tTotal Chunks: 44, Chunks in use: 44. 88.8KiB allocated for chunks. 88.8KiB in use in bin. 88.0KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.906905: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (4096): \tTotal Chunks: 28, Chunks in use: 28. 113.5KiB allocated for chunks. 113.5KiB in use in bin. 112.0KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.906944: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (8192): \tTotal Chunks: 16, Chunks in use: 16. 128.0KiB allocated for chunks. 128.0KiB in use in bin. 128.0KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.906984: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907019: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (32768): \tTotal Chunks: 2, Chunks in use: 2. 74.2KiB allocated for chunks. 74.2KiB in use in bin. 74.2KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907059: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (65536): \tTotal Chunks: 7, Chunks in use: 7. 508.0KiB allocated for chunks. 508.0KiB in use in bin. 492.0KiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907098: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (131072): \tTotal Chunks: 7, Chunks in use: 7. 1.17MiB allocated for chunks. 1.17MiB in use in bin. 1.15MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907136: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (262144): \tTotal Chunks: 7, Chunks in use: 7. 1.77MiB allocated for chunks. 1.77MiB in use in bin. 1.75MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907174: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (524288): \tTotal Chunks: 7, Chunks in use: 7. 4.74MiB allocated for chunks. 4.74MiB in use in bin. 3.75MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907214: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (1048576): \tTotal Chunks: 13, Chunks in use: 12. 13.88MiB allocated for chunks. 12.07MiB in use in bin. 12.00MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907254: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (2097152): \tTotal Chunks: 21, Chunks in use: 21. 49.71MiB allocated for chunks. 49.71MiB in use in bin. 46.50MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907295: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (4194304): \tTotal Chunks: 6, Chunks in use: 5. 24.32MiB allocated for chunks. 20.04MiB in use in bin. 20.00MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907339: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (8388608): \tTotal Chunks: 6, Chunks in use: 4. 64.38MiB allocated for chunks. 40.05MiB in use in bin. 35.00MiB client-requested in use in bin.\r\n2020-12-14 14:16:33.907374: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-12-14 14:16:33.907453: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-12-14 14:16:33.907496: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-12-14 14:16:33.907535: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-12-14 14:16:33.907572: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-12-14 14:16:33.907616: I tensorflow/core/common_runtime/bfc_allocator.cc:993] Bin for 27.85MiB was 16.00MiB, Chunk State: \r\n2020-12-14 14:16:33.907649: I tensorflow/core/common_runtime/bfc_allocator.cc:1006] Next region of size 168976384\r\n2020-12-14 14:16:33.907696: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00b30000 of size 1280 next 1\r\n2020-12-14 14:16:33.907739: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00b30500 of size 256 next 466\r\n2020-12-14 14:16:33.907771: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00b30600 of size 110592 next 2\r\n2020-12-14 14:16:33.907804: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00b4b600 of size 256 next 467\r\n2020-12-14 14:16:33.907839: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00b4b700 of size 1024 next 469\r\n2020-12-14 14:16:33.907868: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00b4bb00 of size 2468608 next 4\r\n2020-12-14 14:16:33.907898: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da6600 of size 1024 next 5\r\n2020-12-14 14:16:33.907931: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da6a00 of size 1024 next 6\r\n2020-12-14 14:16:33.907959: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da6e00 of size 1024 next 7\r\n2020-12-14 14:16:33.907990: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da7200 of size 1024 next 8\r\n2020-12-14 14:16:33.908024: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da7600 of size 1024 next 9\r\n2020-12-14 14:16:33.908053: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da7a00 of size 1024 next 10\r\n2020-12-14 14:16:33.908080: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da7e00 of size 1024 next 11\r\n2020-12-14 14:16:33.908113: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da8200 of size 1024 next 12\r\n2020-12-14 14:16:33.908141: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da8600 of size 1024 next 13\r\n2020-12-14 14:16:33.908177: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da8a00 of size 1024 next 14\r\n2020-12-14 14:16:33.908211: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da8e00 of size 1024 next 15\r\n2020-12-14 14:16:33.908243: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da9200 of size 1024 next 16\r\n2020-12-14 14:16:33.908276: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da9600 of size 1024 next 17\r\n2020-12-14 14:16:33.908309: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da9a00 of size 1024 next 18\r\n2020-12-14 14:16:33.908342: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00da9e00 of size 1024 next 19\r\n2020-12-14 14:16:33.908373: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00daa200 of size 1024 next 20\r\n2020-12-14 14:16:33.908406: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00daa600 of size 1024 next 21\r\n2020-12-14 14:16:33.908439: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00daaa00 of size 1024 next 22\r\n2020-12-14 14:16:33.908472: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00daae00 of size 1024 next 23\r\n2020-12-14 14:16:33.908505: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dab200 of size 1024 next 24\r\n2020-12-14 14:16:33.908540: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dab600 of size 1024 next 25\r\n2020-12-14 14:16:33.908573: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00daba00 of size 1024 next 26\r\n2020-12-14 14:16:33.908606: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dabe00 of size 1024 next 27\r\n2020-12-14 14:16:33.908638: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dac200 of size 1024 next 28\r\n2020-12-14 14:16:33.908671: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dac600 of size 1024 next 29\r\n2020-12-14 14:16:33.908703: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00daca00 of size 1024 next 30\r\n2020-12-14 14:16:33.908736: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dace00 of size 1024 next 31\r\n2020-12-14 14:16:33.908768: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dad200 of size 1024 next 32\r\n2020-12-14 14:16:33.908802: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dad600 of size 1024 next 33\r\n2020-12-14 14:16:33.908835: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dada00 of size 1024 next 34\r\n2020-12-14 14:16:33.908868: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dade00 of size 1024 next 35\r\n2020-12-14 14:16:33.908900: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dae200 of size 1024 next 36\r\n2020-12-14 14:16:33.908934: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00dae600 of size 2359296 next 37\r\n2020-12-14 14:16:33.908966: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fee600 of size 1024 next 38\r\n2020-12-14 14:16:33.908999: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00feea00 of size 1024 next 39\r\n2020-12-14 14:16:33.909031: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00feee00 of size 1024 next 40\r\n2020-12-14 14:16:33.909065: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fef200 of size 1024 next 41\r\n2020-12-14 14:16:33.909098: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fef600 of size 1024 next 42\r\n2020-12-14 14:16:33.909131: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fefa00 of size 1024 next 43\r\n2020-12-14 14:16:33.909164: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fefe00 of size 1024 next 44\r\n2020-12-14 14:16:33.909198: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff0200 of size 1024 next 45\r\n2020-12-14 14:16:33.909230: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff0600 of size 1024 next 46\r\n2020-12-14 14:16:33.909262: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff0a00 of size 1024 next 47\r\n2020-12-14 14:16:33.909294: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff0e00 of size 1024 next 48\r\n2020-12-14 14:16:33.909327: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff1200 of size 1024 next 49\r\n2020-12-14 14:16:33.909360: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff1600 of size 1024 next 50\r\n2020-12-14 14:16:33.909393: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff1a00 of size 1024 next 51\r\n2020-12-14 14:16:33.909425: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff1e00 of size 1024 next 52\r\n2020-12-14 14:16:33.909458: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff2200 of size 1024 next 53\r\n2020-12-14 14:16:33.909491: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff2600 of size 1024 next 54\r\n2020-12-14 14:16:33.909524: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff2a00 of size 1024 next 55\r\n2020-12-14 14:16:33.909557: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff2e00 of size 1024 next 56\r\n2020-12-14 14:16:33.909589: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff3200 of size 1024 next 57\r\n2020-12-14 14:16:33.909621: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff3600 of size 1024 next 58\r\n2020-12-14 14:16:33.909653: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff3a00 of size 1024 next 59\r\n2020-12-14 14:16:33.909686: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff3e00 of size 1024 next 60\r\n2020-12-14 14:16:33.909719: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff4200 of size 1024 next 61\r\n2020-12-14 14:16:33.909752: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff4600 of size 1024 next 62\r\n2020-12-14 14:16:33.909784: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff4a00 of size 1024 next 63\r\n2020-12-14 14:16:33.909817: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff4e00 of size 1024 next 64\r\n2020-12-14 14:16:33.909850: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff5200 of size 1024 next 65\r\n2020-12-14 14:16:33.909883: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff5600 of size 1024 next 66\r\n2020-12-14 14:16:33.909915: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff5a00 of size 1024 next 67\r\n2020-12-14 14:16:33.909946: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff5e00 of size 1024 next 68\r\n2020-12-14 14:16:33.909979: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff6200 of size 1024 next 69\r\n2020-12-14 14:16:33.910012: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff6600 of size 1024 next 70\r\n2020-12-14 14:16:33.910045: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff6a00 of size 1024 next 71\r\n2020-12-14 14:16:33.910078: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff6e00 of size 1024 next 72\r\n2020-12-14 14:16:33.910112: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff7200 of size 1024 next 73\r\n2020-12-14 14:16:33.910145: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff7600 of size 1024 next 74\r\n2020-12-14 14:16:33.910178: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff7a00 of size 1024 next 75\r\n2020-12-14 14:16:33.910211: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff7e00 of size 1024 next 76\r\n2020-12-14 14:16:33.910244: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff8200 of size 1024 next 77\r\n2020-12-14 14:16:33.910276: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff8600 of size 1024 next 78\r\n2020-12-14 14:16:33.910308: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff8a00 of size 1024 next 79\r\n2020-12-14 14:16:33.910341: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff8e00 of size 1024 next 80\r\n2020-12-14 14:16:33.910374: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff9200 of size 1024 next 81\r\n2020-12-14 14:16:33.910407: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff9600 of size 1024 next 82\r\n2020-12-14 14:16:33.910440: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff9a00 of size 1024 next 83\r\n2020-12-14 14:16:33.910472: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ff9e00 of size 1024 next 84\r\n2020-12-14 14:16:33.910505: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffa200 of size 1024 next 85\r\n2020-12-14 14:16:33.910538: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffa600 of size 1024 next 86\r\n2020-12-14 14:16:33.910571: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffaa00 of size 1024 next 87\r\n2020-12-14 14:16:33.910602: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffae00 of size 1024 next 88\r\n2020-12-14 14:16:33.910634: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffb200 of size 1024 next 89\r\n2020-12-14 14:16:33.910667: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffb600 of size 1024 next 90\r\n2020-12-14 14:16:33.910700: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffba00 of size 1024 next 91\r\n2020-12-14 14:16:33.910732: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffbe00 of size 1024 next 92\r\n2020-12-14 14:16:33.910765: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffc200 of size 1024 next 93\r\n2020-12-14 14:16:33.910798: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffc600 of size 1024 next 94\r\n2020-12-14 14:16:33.910830: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffca00 of size 1024 next 95\r\n2020-12-14 14:16:33.910863: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffce00 of size 1024 next 97\r\n2020-12-14 14:16:33.910897: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffd200 of size 1024 next 98\r\n2020-12-14 14:16:33.910929: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffd600 of size 1024 next 99\r\n2020-12-14 14:16:33.910961: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffda00 of size 1024 next 100\r\n2020-12-14 14:16:33.910993: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffde00 of size 1024 next 101\r\n2020-12-14 14:16:33.911027: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffe200 of size 1024 next 102\r\n2020-12-14 14:16:33.911059: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffe600 of size 1024 next 103\r\n2020-12-14 14:16:33.911092: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffea00 of size 1024 next 104\r\n2020-12-14 14:16:33.911124: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00ffee00 of size 1024 next 105\r\n2020-12-14 14:16:33.911158: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fff200 of size 1024 next 106\r\n2020-12-14 14:16:33.911190: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fff600 of size 1024 next 116\r\n2020-12-14 14:16:33.911223: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fffa00 of size 1024 next 117\r\n2020-12-14 14:16:33.911255: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f00fffe00 of size 1024 next 120\r\n2020-12-14 14:16:33.916608: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01000200 of size 1024 next 121\r\n2020-12-14 14:16:33.916658: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01000600 of size 1024 next 122\r\n2020-12-14 14:16:33.916692: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01000a00 of size 1024 next 124\r\n2020-12-14 14:16:33.916727: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01000e00 of size 1024 next 125\r\n2020-12-14 14:16:33.916752: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01001200 of size 1024 next 127\r\n2020-12-14 14:16:33.916776: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01001600 of size 1024 next 128\r\n2020-12-14 14:16:33.916802: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01001a00 of size 1024 next 174\r\n2020-12-14 14:16:33.916832: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01001e00 of size 37632 next 96\r\n2020-12-14 14:16:33.916858: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100b100 of size 2048 next 461\r\n2020-12-14 14:16:33.916882: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100b900 of size 2048 next 462\r\n2020-12-14 14:16:33.916912: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100c100 of size 512 next 463\r\n2020-12-14 14:16:33.916937: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100c300 of size 512 next 177\r\n2020-12-14 14:16:33.916962: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100c500 of size 512 next 178\r\n2020-12-14 14:16:33.916991: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100c700 of size 512 next 179\r\n2020-12-14 14:16:33.917021: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100c900 of size 512 next 181\r\n2020-12-14 14:16:33.917052: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100cb00 of size 512 next 182\r\n2020-12-14 14:16:33.917084: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100cd00 of size 512 next 183\r\n2020-12-14 14:16:33.917116: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100cf00 of size 512 next 184\r\n2020-12-14 14:16:33.917150: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100d100 of size 2048 next 180\r\n2020-12-14 14:16:33.917183: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100d900 of size 2048 next 188\r\n2020-12-14 14:16:33.917214: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100e100 of size 2048 next 189\r\n2020-12-14 14:16:33.917246: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100e900 of size 2048 next 190\r\n2020-12-14 14:16:33.917279: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100f100 of size 512 next 191\r\n2020-12-14 14:16:33.917312: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100f300 of size 512 next 193\r\n2020-12-14 14:16:33.917345: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100f500 of size 512 next 194\r\n2020-12-14 14:16:33.917377: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100f700 of size 512 next 195\r\n2020-12-14 14:16:33.917410: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100f900 of size 512 next 196\r\n2020-12-14 14:16:33.917442: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100fb00 of size 512 next 199\r\n2020-12-14 14:16:33.917475: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100fd00 of size 512 next 200\r\n2020-12-14 14:16:33.917507: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0100ff00 of size 512 next 201\r\n2020-12-14 14:16:33.917540: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01010100 of size 2048 next 203\r\n2020-12-14 14:16:33.917572: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01010900 of size 2048 next 204\r\n2020-12-14 14:16:33.917606: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01011100 of size 2048 next 205\r\n2020-12-14 14:16:33.917642: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01011900 of size 2048 next 206\r\n2020-12-14 14:16:33.917678: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01012100 of size 1024 next 207\r\n2020-12-14 14:16:33.917712: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01012500 of size 1024 next 210\r\n2020-12-14 14:16:33.917739: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01012900 of size 1024 next 211\r\n2020-12-14 14:16:33.917766: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01012d00 of size 1024 next 212\r\n2020-12-14 14:16:33.917797: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01013100 of size 1024 next 214\r\n2020-12-14 14:16:33.917829: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01013500 of size 1024 next 215\r\n2020-12-14 14:16:33.917862: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01013900 of size 1024 next 216\r\n2020-12-14 14:16:33.917894: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01013d00 of size 1024 next 217\r\n2020-12-14 14:16:33.917928: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01014100 of size 4096 next 221\r\n2020-12-14 14:16:33.917961: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01015100 of size 4096 next 222\r\n2020-12-14 14:16:33.917994: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01016100 of size 4096 next 223\r\n2020-12-14 14:16:33.918026: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01017100 of size 4096 next 224\r\n2020-12-14 14:16:33.918059: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01018100 of size 4096 next 225\r\n2020-12-14 14:16:33.918092: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01019100 of size 5632 next 107\r\n2020-12-14 14:16:33.918127: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0101a700 of size 2359296 next 108\r\n2020-12-14 14:16:33.918161: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125a700 of size 1024 next 109\r\n2020-12-14 14:16:33.918195: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125ab00 of size 1024 next 110\r\n2020-12-14 14:16:33.918229: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125af00 of size 1024 next 111\r\n2020-12-14 14:16:33.918262: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125b300 of size 1024 next 112\r\n2020-12-14 14:16:33.918294: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125b700 of size 1024 next 113\r\n2020-12-14 14:16:33.918326: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125bb00 of size 1024 next 114\r\n2020-12-14 14:16:33.918359: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125bf00 of size 1024 next 115\r\n2020-12-14 14:16:33.918392: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0125c300 of size 2361344 next 118\r\n2020-12-14 14:16:33.918427: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0149cb00 of size 1024 next 119\r\n2020-12-14 14:16:33.918461: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0149cf00 of size 2362368 next 123\r\n2020-12-14 14:16:33.918494: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f016ddb00 of size 2361344 next 126\r\n2020-12-14 14:16:33.918527: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0191e300 of size 2361344 next 129\r\n2020-12-14 14:16:33.918559: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b5eb00 of size 1024 next 130\r\n2020-12-14 14:16:33.918592: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b5ef00 of size 1024 next 131\r\n2020-12-14 14:16:33.918624: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b5f300 of size 1024 next 132\r\n2020-12-14 14:16:33.918656: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b5f700 of size 1024 next 133\r\n2020-12-14 14:16:33.918689: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b5fb00 of size 1024 next 134\r\n2020-12-14 14:16:33.918723: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b5ff00 of size 1024 next 135\r\n2020-12-14 14:16:33.918757: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b60300 of size 1024 next 136\r\n2020-12-14 14:16:33.919974: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b60700 of size 1024 next 137\r\n2020-12-14 14:16:33.920015: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b60b00 of size 1024 next 138\r\n2020-12-14 14:16:33.920051: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b60f00 of size 1024 next 139\r\n2020-12-14 14:16:33.920074: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b61300 of size 1024 next 140\r\n2020-12-14 14:16:33.920097: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01b61700 of size 2359296 next 141\r\n2020-12-14 14:16:33.920120: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da1700 of size 1024 next 142\r\n2020-12-14 14:16:33.920143: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da1b00 of size 1024 next 143\r\n2020-12-14 14:16:33.920167: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da1f00 of size 1024 next 144\r\n2020-12-14 14:16:33.920192: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da2300 of size 1024 next 145\r\n2020-12-14 14:16:33.920217: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da2700 of size 1024 next 146\r\n2020-12-14 14:16:33.920243: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da2b00 of size 1024 next 147\r\n2020-12-14 14:16:33.920270: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da2f00 of size 1024 next 148\r\n2020-12-14 14:16:33.920297: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da3300 of size 1024 next 149\r\n2020-12-14 14:16:33.920325: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da3700 of size 1024 next 150\r\n2020-12-14 14:16:33.920354: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da3b00 of size 1024 next 151\r\n2020-12-14 14:16:33.920382: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da3f00 of size 1024 next 152\r\n2020-12-14 14:16:33.920428: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da4300 of size 1024 next 153\r\n2020-12-14 14:16:33.920459: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da4700 of size 1024 next 154\r\n2020-12-14 14:16:33.920537: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da4b00 of size 1024 next 155\r\n2020-12-14 14:16:33.920567: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da4f00 of size 1024 next 156\r\n2020-12-14 14:16:33.920592: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da5300 of size 1024 next 157\r\n2020-12-14 14:16:33.920618: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da5700 of size 1024 next 158\r\n2020-12-14 14:16:33.920641: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da5b00 of size 1024 next 159\r\n2020-12-14 14:16:33.920665: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da5f00 of size 1024 next 160\r\n2020-12-14 14:16:33.920688: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da6300 of size 1024 next 161\r\n2020-12-14 14:16:33.920711: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da6700 of size 1024 next 162\r\n2020-12-14 14:16:33.920734: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da6b00 of size 1024 next 163\r\n2020-12-14 14:16:33.920757: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da6f00 of size 1024 next 164\r\n2020-12-14 14:16:33.920781: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da7300 of size 1024 next 165\r\n2020-12-14 14:16:33.920804: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da7700 of size 1024 next 166\r\n2020-12-14 14:16:33.920827: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da7b00 of size 1024 next 167\r\n2020-12-14 14:16:33.920851: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da7f00 of size 1024 next 168\r\n2020-12-14 14:16:33.920875: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da8300 of size 1024 next 169\r\n2020-12-14 14:16:33.920899: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da8700 of size 1024 next 170\r\n2020-12-14 14:16:33.920924: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da8b00 of size 1024 next 171\r\n2020-12-14 14:16:33.920949: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da8f00 of size 1024 next 172\r\n2020-12-14 14:16:33.920973: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da9300 of size 1024 next 173\r\n2020-12-14 14:16:33.920999: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01da9700 of size 2360320 next 175\r\n2020-12-14 14:16:33.921026: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fe9b00 of size 16384 next 470\r\n2020-12-14 14:16:33.921053: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fedb00 of size 512 next 426\r\n2020-12-14 14:16:33.921079: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fedd00 of size 512 next 427\r\n2020-12-14 14:16:33.921105: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fedf00 of size 512 next 428\r\n2020-12-14 14:16:33.921130: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fee100 of size 512 next 429\r\n2020-12-14 14:16:33.921156: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fee300 of size 512 next 425\r\n2020-12-14 14:16:33.921182: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fee500 of size 512 next 433\r\n2020-12-14 14:16:33.921208: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fee700 of size 512 next 434\r\n2020-12-14 14:16:33.921234: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fee900 of size 512 next 435\r\n2020-12-14 14:16:33.921260: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01feeb00 of size 2048 next 438\r\n2020-12-14 14:16:33.921287: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fef300 of size 2048 next 439\r\n2020-12-14 14:16:33.921314: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01fefb00 of size 2048 next 440\r\n2020-12-14 14:16:33.921340: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff0300 of size 2048 next 441\r\n2020-12-14 14:16:33.921367: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff0b00 of size 512 next 448\r\n2020-12-14 14:16:33.921394: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff0d00 of size 512 next 449\r\n2020-12-14 14:16:33.921420: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff0f00 of size 512 next 450\r\n2020-12-14 14:16:33.921488: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff1100 of size 512 next 451\r\n2020-12-14 14:16:33.921515: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff1300 of size 512 next 393\r\n2020-12-14 14:16:33.921539: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff1500 of size 512 next 455\r\n2020-12-14 14:16:33.921562: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff1700 of size 512 next 456\r\n2020-12-14 14:16:33.921585: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff1900 of size 512 next 457\r\n2020-12-14 14:16:33.921609: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff1b00 of size 2048 next 459\r\n2020-12-14 14:16:33.921633: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff2300 of size 2816 next 176\r\n2020-12-14 14:16:33.921657: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f01ff2e00 of size 262144 next 185\r\n2020-12-14 14:16:33.921682: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02032e00 of size 593920 next 186\r\n2020-12-14 14:16:33.921705: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f020c3e00 of size 256 next 187\r\n2020-12-14 14:16:33.933469: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f020c3f00 of size 270336 next 192\r\n2020-12-14 14:16:33.933513: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02105f00 of size 264192 next 197\r\n2020-12-14 14:16:33.933540: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02146700 of size 256 next 198\r\n2020-12-14 14:16:33.933564: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02146800 of size 862208 next 208\r\n2020-12-14 14:16:33.933587: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02219000 of size 256 next 209\r\n2020-12-14 14:16:33.933611: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02219100 of size 2891776 next 219\r\n2020-12-14 14:16:33.933644: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f024db100 of size 256 next 220\r\n2020-12-14 14:16:33.933670: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f024db200 of size 1048576 next 218\r\n2020-12-14 14:16:33.933694: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f025db200 of size 1048576 next 229\r\n2020-12-14 14:16:33.933717: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f026db200 of size 1081344 next 230\r\n2020-12-14 14:16:33.933742: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e3200 of size 1024 next 473\r\n2020-12-14 14:16:33.933768: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e3600 of size 1024 next 388\r\n2020-12-14 14:16:33.933790: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e3a00 of size 1024 next 389\r\n2020-12-14 14:16:33.933810: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e3e00 of size 1024 next 390\r\n2020-12-14 14:16:33.933841: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4200 of size 1024 next 391\r\n2020-12-14 14:16:33.933867: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4600 of size 256 next 396\r\n2020-12-14 14:16:33.933887: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4700 of size 256 next 400\r\n2020-12-14 14:16:33.933907: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4800 of size 256 next 401\r\n2020-12-14 14:16:33.933937: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4900 of size 256 next 402\r\n2020-12-14 14:16:33.933960: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4a00 of size 1024 next 404\r\n2020-12-14 14:16:33.933980: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e4e00 of size 1024 next 405\r\n2020-12-14 14:16:33.934000: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5200 of size 1024 next 406\r\n2020-12-14 14:16:33.934023: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5600 of size 1024 next 407\r\n2020-12-14 14:16:33.934043: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5a00 of size 256 next 403\r\n2020-12-14 14:16:33.934062: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5b00 of size 256 next 411\r\n2020-12-14 14:16:33.934086: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5c00 of size 256 next 412\r\n2020-12-14 14:16:33.934109: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5d00 of size 256 next 413\r\n2020-12-14 14:16:33.934130: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5e00 of size 256 next 415\r\n2020-12-14 14:16:33.934150: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e5f00 of size 256 next 416\r\n2020-12-14 14:16:33.934176: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e6000 of size 256 next 417\r\n2020-12-14 14:16:33.934198: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e6100 of size 256 next 418\r\n2020-12-14 14:16:33.934219: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e6200 of size 1024 next 414\r\n2020-12-14 14:16:33.934247: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e6600 of size 1024 next 422\r\n2020-12-14 14:16:33.934272: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e6a00 of size 1024 next 423\r\n2020-12-14 14:16:33.934293: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e6e00 of size 1024 next 231\r\n2020-12-14 14:16:33.934315: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f027e7200 of size 3416064 next 241\r\n2020-12-14 14:16:33.934340: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02b29200 of size 256 next 242\r\n2020-12-14 14:16:33.934367: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02b29300 of size 1064960 next 247\r\n2020-12-14 14:16:33.934394: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02c2d300 of size 1052672 next 252\r\n2020-12-14 14:16:33.934421: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02d2e300 of size 256 next 253\r\n2020-12-14 14:16:33.934447: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02d2e400 of size 1048576 next 262\r\n2020-12-14 14:16:33.934473: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f02e2e400 of size 2379776 next 263\r\n2020-12-14 14:16:33.934500: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03073400 of size 256 next 264\r\n2020-12-14 14:16:33.934527: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03073500 of size 1048576 next 273\r\n2020-12-14 14:16:33.934555: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03173500 of size 2367488 next 274\r\n2020-12-14 14:16:33.934585: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f033b5500 of size 256 next 275\r\n2020-12-14 14:16:33.934611: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f033b5600 of size 1064960 next 280\r\n2020-12-14 14:16:33.934636: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f034b9600 of size 1052672 next 285\r\n2020-12-14 14:16:33.934659: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f035ba600 of size 1024 next 286\r\n2020-12-14 14:16:33.934682: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f035baa00 of size 65536 next 472\r\n2020-12-14 14:16:33.934707: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f035caa00 of size 81920 next 287\r\n2020-12-14 14:16:33.934730: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f035dea00 of size 1048576 next 296\r\n2020-12-14 14:16:33.934753: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f036dea00 of size 2379776 next 297\r\n2020-12-14 14:16:33.934777: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03923a00 of size 256 next 298\r\n2020-12-14 14:16:33.934800: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03923b00 of size 1048576 next 307\r\n2020-12-14 14:16:33.934823: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03a23b00 of size 2367488 next 308\r\n2020-12-14 14:16:33.934847: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03c65b00 of size 256 next 309\r\n2020-12-14 14:16:33.934871: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03c65c00 of size 3170304 next 319\r\n2020-12-14 14:16:33.934894: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03f6bc00 of size 256 next 320\r\n2020-12-14 14:16:33.934919: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f03f6bd00 of size 9445376 next 325\r\n2020-12-14 14:16:33.934946: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0486dd00 of size 4194304 next 324\r\n2020-12-14 14:16:33.934972: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f04c6dd00 of size 4194304 next 202\r\n2020-12-14 14:16:33.934999: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0506dd00 of size 4218880 next 330\r\n2020-12-14 14:16:33.935027: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f05473d00 of size 256 next 331\r\n2020-12-14 14:16:33.935055: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f05473e00 of size 8192 next 332\r\n2020-12-14 14:16:33.935080: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f05475e00 of size 8192 next 333\r\n2020-12-14 14:16:33.935104: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f05477e00 of size 8192 next 334\r\n2020-12-14 14:16:33.994135: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f05479e00 of size 8192 next 335\r\n2020-12-14 14:16:33.994223: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0547be00 of size 4210688 next 341\r\n2020-12-14 14:16:33.994266: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0587fe00 of size 65536 next 342\r\n2020-12-14 14:16:33.994295: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0588fe00 of size 13672448 next 352\r\n2020-12-14 14:16:33.994326: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f06599e00 of size 65536 next 353\r\n2020-12-14 14:16:33.994356: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f065a9e00 of size 4194304 next 362\r\n2020-12-14 14:16:33.994383: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f069a9e00 of size 9453568 next 363\r\n2020-12-14 14:16:33.994412: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f072ade00 of size 1024 next 364\r\n2020-12-14 14:16:33.994441: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f072ae200 of size 1048576 next 370\r\n2020-12-14 14:16:33.994470: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f073ae200 of size 1024 next 373\r\n2020-12-14 14:16:33.994498: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f073ae600 of size 2359296 next 372\r\n2020-12-14 14:16:33.994527: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f075ee600 of size 4490240 next 374\r\n2020-12-14 14:16:33.994555: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07a36a00 of size 1024 next 375\r\n2020-12-14 14:16:33.994584: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07a36e00 of size 1024 next 376\r\n2020-12-14 14:16:33.994610: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07a37200 of size 1024 next 377\r\n2020-12-14 14:16:33.994641: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07a37600 of size 2360320 next 379\r\n2020-12-14 14:16:33.994671: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c77a00 of size 1024 next 378\r\n2020-12-14 14:16:33.994696: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c77e00 of size 1024 next 380\r\n2020-12-14 14:16:33.994723: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c78200 of size 1024 next 381\r\n2020-12-14 14:16:33.994751: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c78600 of size 1024 next 382\r\n2020-12-14 14:16:33.994779: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c78a00 of size 1024 next 383\r\n2020-12-14 14:16:33.994807: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c78e00 of size 1024 next 384\r\n2020-12-14 14:16:33.994836: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07c79200 of size 204800 next 355\r\n2020-12-14 14:16:33.994865: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cab200 of size 256 next 458\r\n2020-12-14 14:16:33.994894: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cab300 of size 512 next 392\r\n2020-12-14 14:16:33.994922: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cab500 of size 256 next 474\r\n2020-12-14 14:16:33.994949: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cab600 of size 256 next 475\r\n2020-12-14 14:16:33.994977: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cab700 of size 256 next 476\r\n2020-12-14 14:16:33.995005: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cab800 of size 512 next 477\r\n2020-12-14 14:16:33.995033: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07caba00 of size 256 next 478\r\n2020-12-14 14:16:33.995061: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cabb00 of size 256 next 479\r\n2020-12-14 14:16:33.995091: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cabc00 of size 256 next 480\r\n2020-12-14 14:16:33.995121: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cabd00 of size 256 next 481\r\n2020-12-14 14:16:33.995152: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cabe00 of size 256 next 482\r\n2020-12-14 14:16:33.995179: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cabf00 of size 256 next 483\r\n2020-12-14 14:16:33.995207: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cac000 of size 256 next 484\r\n2020-12-14 14:16:33.995234: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cac100 of size 256 next 485\r\n2020-12-14 14:16:33.995263: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cac200 of size 256 next 486\r\n2020-12-14 14:16:33.995291: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cac300 of size 204800 next 487\r\n2020-12-14 14:16:33.995321: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cde300 of size 256 next 488\r\n2020-12-14 14:16:33.995349: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cde400 of size 256 next 489\r\n2020-12-14 14:16:33.995377: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cde500 of size 256 next 490\r\n2020-12-14 14:16:33.995469: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cde600 of size 256 next 491\r\n2020-12-14 14:16:33.995498: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f07cde700 of size 256 next 492\r\n2020-12-14 14:16:33.995530: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cde800 of size 256 next 493\r\n2020-12-14 14:16:33.995562: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cde900 of size 256 next 494\r\n2020-12-14 14:16:33.995593: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cdea00 of size 256 next 495\r\n2020-12-14 14:16:33.995619: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f07cdeb00 of size 256 next 496\r\n2020-12-14 14:16:33.995647: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cdec00 of size 256 next 497\r\n2020-12-14 14:16:33.995674: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f07cded00 of size 256 next 498\r\n2020-12-14 14:16:33.995702: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cdee00 of size 256 next 499\r\n2020-12-14 14:16:33.995730: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cdef00 of size 256 next 500\r\n2020-12-14 14:16:33.995758: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f07cdf000 of size 512 next 502\r\n2020-12-14 14:16:33.995785: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cdf200 of size 256 next 503\r\n2020-12-14 14:16:33.995814: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07cdf300 of size 38400 next 501\r\n2020-12-14 14:16:33.995843: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f07ce8900 of size 1901824 next 385\r\n2020-12-14 14:16:33.995871: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07eb8e00 of size 1024 next 386\r\n2020-12-14 14:16:33.995923: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07eb9200 of size 512 next 368\r\n2020-12-14 14:16:33.995974: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07eb9400 of size 256 next 346\r\n2020-12-14 14:16:33.996024: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07eb9500 of size 256 next 387\r\n2020-12-14 14:16:33.996071: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07eb9600 of size 147456 next 471\r\n2020-12-14 14:16:33.996118: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07edd600 of size 147456 next 397\r\n2020-12-14 14:16:33.996150: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07f01600 of size 589824 next 430\r\n2020-12-14 14:16:33.996181: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f07f91600 of size 589824 next 452\r\n2020-12-14 14:16:33.996210: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08021600 of size 8192 next 347\r\n2020-12-14 14:16:33.996240: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08023600 of size 8192 next 348\r\n2020-12-14 14:16:33.996268: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08025600 of size 8192 next 349\r\n2020-12-14 14:16:33.996297: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08027600 of size 8192 next 350\r\n2020-12-14 14:16:33.996326: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08029600 of size 2048 next 356\r\n2020-12-14 14:16:33.996354: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08029e00 of size 2048 next 358\r\n2020-12-14 14:16:33.996383: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0802a600 of size 2048 next 359\r\n2020-12-14 14:16:33.996409: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0802ae00 of size 2048 next 360\r\n2020-12-14 14:16:33.996440: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0802b600 of size 2048 next 361\r\n2020-12-14 14:16:33.996470: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0802be00 of size 8192 next 357\r\n2020-12-14 14:16:33.996500: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0802de00 of size 8192 next 365\r\n2020-12-14 14:16:33.996530: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0802fe00 of size 8192 next 366\r\n2020-12-14 14:16:33.996556: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08031e00 of size 8192 next 367\r\n2020-12-14 14:16:33.996583: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08033e00 of size 1024 next 369\r\n2020-12-14 14:16:33.996611: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08034200 of size 1024 next 371\r\n2020-12-14 14:16:33.996640: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08034600 of size 878592 next 398\r\n2020-12-14 14:16:33.996669: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0810ae00 of size 1024 next 399\r\n2020-12-14 14:16:33.996698: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0810b200 of size 65536 next 408\r\n2020-12-14 14:16:33.996727: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0811b200 of size 152576 next 409\r\n2020-12-14 14:16:33.996757: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08140600 of size 1024 next 410\r\n2020-12-14 14:16:33.996785: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08140a00 of size 65536 next 419\r\n2020-12-14 14:16:33.996814: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08150a00 of size 149504 next 420\r\n2020-12-14 14:16:33.996860: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08175200 of size 1024 next 421\r\n2020-12-14 14:16:33.996906: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08175600 of size 4096 next 227\r\n2020-12-14 14:16:33.996949: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08176600 of size 4096 next 228\r\n2020-12-14 14:16:33.996992: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08177600 of size 1024 next 226\r\n2020-12-14 14:16:33.997024: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08177a00 of size 1024 next 232\r\n2020-12-14 14:16:33.997053: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08177e00 of size 1024 next 233\r\n2020-12-14 14:16:33.997081: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08178200 of size 1024 next 234\r\n2020-12-14 14:16:33.997110: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08178600 of size 1024 next 236\r\n2020-12-14 14:16:33.997138: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08178a00 of size 1024 next 237\r\n2020-12-14 14:16:33.997167: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08178e00 of size 1024 next 238\r\n2020-12-14 14:16:33.997195: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08179200 of size 1024 next 239\r\n2020-12-14 14:16:33.997223: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08179600 of size 4096 next 240\r\n2020-12-14 14:16:33.997252: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817a600 of size 4096 next 243\r\n2020-12-14 14:16:33.997277: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817b600 of size 4096 next 244\r\n2020-12-14 14:16:33.997307: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817c600 of size 4096 next 245\r\n2020-12-14 14:16:33.997337: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817d600 of size 1024 next 246\r\n2020-12-14 14:16:33.997362: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817da00 of size 1024 next 248\r\n2020-12-14 14:16:33.997390: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817de00 of size 1024 next 249\r\n2020-12-14 14:16:33.997418: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817e200 of size 1024 next 250\r\n2020-12-14 14:16:33.997445: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817e600 of size 1024 next 251\r\n2020-12-14 14:16:33.997473: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817ea00 of size 1024 next 254\r\n2020-12-14 14:16:33.997502: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817ee00 of size 1024 next 255\r\n2020-12-14 14:16:33.997530: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817f200 of size 1024 next 256\r\n2020-12-14 14:16:33.997559: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0817f600 of size 4096 next 258\r\n2020-12-14 14:16:33.997588: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08180600 of size 4096 next 259\r\n2020-12-14 14:16:33.997617: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08181600 of size 4096 next 260\r\n2020-12-14 14:16:33.997648: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08182600 of size 4096 next 261\r\n2020-12-14 14:16:33.997677: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08183600 of size 1024 next 257\r\n2020-12-14 14:16:33.997702: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08183a00 of size 1024 next 265\r\n2020-12-14 14:16:33.997733: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08183e00 of size 1024 next 266\r\n2020-12-14 14:16:33.997763: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08184200 of size 1024 next 267\r\n2020-12-14 14:16:33.997792: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08184600 of size 1024 next 269\r\n2020-12-14 14:16:33.997820: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08184a00 of size 1024 next 270\r\n2020-12-14 14:16:33.997848: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08184e00 of size 1024 next 271\r\n2020-12-14 14:16:33.997876: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08185200 of size 1024 next 272\r\n2020-12-14 14:16:33.997905: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08185600 of size 4096 next 268\r\n2020-12-14 14:16:33.997933: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08186600 of size 4096 next 276\r\n2020-12-14 14:16:33.997962: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08187600 of size 4096 next 277\r\n2020-12-14 14:16:33.997989: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08188600 of size 4096 next 278\r\n2020-12-14 14:16:33.998017: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08189600 of size 1024 next 279\r\n2020-12-14 14:16:33.998045: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08189a00 of size 1024 next 281\r\n2020-12-14 14:16:33.998072: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08189e00 of size 1024 next 282\r\n2020-12-14 14:16:33.998100: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818a200 of size 1024 next 283\r\n2020-12-14 14:16:33.998125: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818a600 of size 1024 next 284\r\n2020-12-14 14:16:33.998153: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818aa00 of size 1024 next 288\r\n2020-12-14 14:16:33.998178: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818ae00 of size 1024 next 289\r\n2020-12-14 14:16:33.998209: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818b200 of size 1024 next 290\r\n2020-12-14 14:16:33.998241: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818b600 of size 4096 next 292\r\n2020-12-14 14:16:33.998272: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818c600 of size 4096 next 293\r\n2020-12-14 14:16:33.998301: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818d600 of size 4096 next 294\r\n2020-12-14 14:16:33.998330: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818e600 of size 4096 next 295\r\n2020-12-14 14:16:33.998362: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818f600 of size 1024 next 291\r\n2020-12-14 14:16:33.998393: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818fa00 of size 1024 next 299\r\n2020-12-14 14:16:33.998427: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0818fe00 of size 1024 next 300\r\n2020-12-14 14:16:33.998459: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08190200 of size 1024 next 301\r\n2020-12-14 14:16:33.998488: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08190600 of size 1024 next 303\r\n2020-12-14 14:16:33.998519: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08190a00 of size 1024 next 304\r\n2020-12-14 14:16:33.998551: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08190e00 of size 1024 next 305\r\n2020-12-14 14:16:33.998577: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08191200 of size 1024 next 306\r\n2020-12-14 14:16:33.998611: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08191600 of size 4096 next 302\r\n2020-12-14 14:16:33.998640: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08192600 of size 4096 next 310\r\n2020-12-14 14:16:33.998670: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08193600 of size 4096 next 311\r\n2020-12-14 14:16:33.998699: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08194600 of size 4096 next 312\r\n2020-12-14 14:16:33.998728: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08195600 of size 2048 next 314\r\n2020-12-14 14:16:33.998757: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08195e00 of size 2048 next 315\r\n2020-12-14 14:16:33.998786: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08196600 of size 2048 next 316\r\n2020-12-14 14:16:33.998815: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08196e00 of size 2048 next 317\r\n2020-12-14 14:16:33.998844: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08197600 of size 2048 next 313\r\n2020-12-14 14:16:33.998874: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08197e00 of size 2048 next 321\r\n2020-12-14 14:16:34.035612: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08198600 of size 2048 next 322\r\n2020-12-14 14:16:34.035695: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08198e00 of size 2048 next 323\r\n2020-12-14 14:16:34.035728: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08199600 of size 8192 next 326\r\n2020-12-14 14:16:34.035757: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0819b600 of size 8192 next 327\r\n2020-12-14 14:16:34.035786: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0819d600 of size 8192 next 328\r\n2020-12-14 14:16:34.035814: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0819f600 of size 8192 next 329\r\n2020-12-14 14:16:34.035844: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a1600 of size 2048 next 336\r\n2020-12-14 14:16:34.035872: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a1e00 of size 2048 next 337\r\n2020-12-14 14:16:34.035903: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a2600 of size 2048 next 338\r\n2020-12-14 14:16:34.035933: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a2e00 of size 2048 next 339\r\n2020-12-14 14:16:34.035962: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a3600 of size 2048 next 460\r\n2020-12-14 14:16:34.035989: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a3e00 of size 2048 next 343\r\n2020-12-14 14:16:34.036017: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a4600 of size 2048 next 344\r\n2020-12-14 14:16:34.036044: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a4e00 of size 2048 next 345\r\n2020-12-14 14:16:34.036072: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a5600 of size 2048 next 351\r\n2020-12-14 14:16:34.036099: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a5e00 of size 2048 next 354\r\n2020-12-14 14:16:34.036127: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a6600 of size 2048 next 431\r\n2020-12-14 14:16:34.036155: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a6e00 of size 1024 next 432\r\n2020-12-14 14:16:34.036185: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f081a7200 of size 591872 next 437\r\n2020-12-14 14:16:34.036216: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08237a00 of size 262144 next 436\r\n2020-12-14 14:16:34.036244: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08277a00 of size 262144 next 424\r\n2020-12-14 14:16:34.036326: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082b7a00 of size 268288 next 442\r\n2020-12-14 14:16:34.036366: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082f9200 of size 1024 next 443\r\n2020-12-14 14:16:34.036397: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082f9600 of size 2048 next 444\r\n2020-12-14 14:16:34.036425: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082f9e00 of size 2048 next 445\r\n2020-12-14 14:16:34.036453: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082fa600 of size 2048 next 446\r\n2020-12-14 14:16:34.036480: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082fae00 of size 2048 next 447\r\n2020-12-14 14:16:34.036509: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f082fb600 of size 266240 next 453\r\n2020-12-14 14:16:34.036540: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0833c600 of size 256 next 3\r\n2020-12-14 14:16:34.036568: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0833c700 of size 256 next 394\r\n2020-12-14 14:16:34.036595: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0833c800 of size 256 next 395\r\n2020-12-14 14:16:34.036622: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0833c900 of size 256 next 454\r\n2020-12-14 14:16:34.036650: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0833ca00 of size 862208 next 464\r\n2020-12-14 14:16:34.036677: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f0840f200 of size 221184 next 465\r\n2020-12-14 14:16:34.036710: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08445200 of size 2359296 next 468\r\n2020-12-14 14:16:34.036740: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08685200 of size 2359296 next 213\r\n2020-12-14 14:16:34.036766: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f088c5200 of size 2359296 next 235\r\n2020-12-14 14:16:34.036792: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f08b05200 of size 9437184 next 318\r\n2020-12-14 14:16:34.036817: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at f09405200 of size 9437184 next 340\r\n2020-12-14 14:16:34.036842: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at f09d05200 of size 16059904 next 18446744073709551615\r\n2020-12-14 14:16:34.036865: I tensorflow/core/common_runtime/bfc_allocator.cc:1031]      Summary of in-use Chunks by size: \r\n2020-12-14 14:16:34.036902: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 56 Chunks of size 256 totalling 14.0KiB\r\n2020-12-14 14:16:34.036933: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 35 Chunks of size 512 totalling 17.5KiB\r\n2020-12-14 14:16:34.036961: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 243 Chunks of size 1024 totalling 243.0KiB\r\n2020-12-14 14:16:34.037044: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 1280 totalling 1.2KiB\r\n2020-12-14 14:16:34.037076: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 43 Chunks of size 2048 totalling 86.0KiB\r\n2020-12-14 14:16:34.037105: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 2816 totalling 2.8KiB\r\n2020-12-14 14:16:34.037136: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 27 Chunks of size 4096 totalling 108.0KiB\r\n2020-12-14 14:16:34.037166: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 5632 totalling 5.5KiB\r\n2020-12-14 14:16:34.037196: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 16 Chunks of size 8192 totalling 128.0KiB\r\n2020-12-14 14:16:34.037227: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 16384 totalling 16.0KiB\r\n2020-12-14 14:16:34.037258: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 37632 totalling 36.8KiB\r\n2020-12-14 14:16:34.037293: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 38400 totalling 37.5KiB\r\n2020-12-14 14:16:34.037328: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 5 Chunks of size 65536 totalling 320.0KiB\r\n2020-12-14 14:16:34.037365: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 81920 totalling 80.0KiB\r\n2020-12-14 14:16:34.037395: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 110592 totalling 108.0KiB\r\n2020-12-14 14:16:34.037423: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 147456 totalling 288.0KiB\r\n2020-12-14 14:16:34.037450: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 149504 totalling 146.0KiB\r\n2020-12-14 14:16:34.037477: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 152576 totalling 149.0KiB\r\n2020-12-14 14:16:34.037503: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 204800 totalling 400.0KiB\r\n2020-12-14 14:16:34.037529: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 221184 totalling 216.0KiB\r\n2020-12-14 14:16:34.037555: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 262144 totalling 768.0KiB\r\n2020-12-14 14:16:34.037582: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 264192 totalling 258.0KiB\r\n2020-12-14 14:16:34.037608: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 266240 totalling 260.0KiB\r\n2020-12-14 14:16:34.037634: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 268288 totalling 262.0KiB\r\n2020-12-14 14:16:34.037805: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 270336 totalling 264.0KiB\r\n2020-12-14 14:16:34.037838: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 589824 totalling 1.12MiB\r\n2020-12-14 14:16:34.037867: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 591872 totalling 578.0KiB\r\n2020-12-14 14:16:34.037896: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 593920 totalling 580.0KiB\r\n2020-12-14 14:16:34.037928: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 862208 totalling 1.64MiB\r\n2020-12-14 14:16:34.037962: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 878592 totalling 858.0KiB\r\n2020-12-14 14:16:34.037989: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 7 Chunks of size 1048576 totalling 7.00MiB\r\n2020-12-14 14:16:34.038015: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 1052672 totalling 2.01MiB\r\n2020-12-14 14:16:34.038041: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 1064960 totalling 2.03MiB\r\n2020-12-14 14:16:34.038067: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 1081344 totalling 1.03MiB\r\n2020-12-14 14:16:34.038093: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 7 Chunks of size 2359296 totalling 15.75MiB\r\n2020-12-14 14:16:34.038119: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 2360320 totalling 4.50MiB\r\n2020-12-14 14:16:34.038145: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 2361344 totalling 6.76MiB\r\n2020-12-14 14:16:34.038171: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 2362368 totalling 2.25MiB\r\n2020-12-14 14:16:34.038306: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 2367488 totalling 4.52MiB\r\n2020-12-14 14:16:34.038347: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 2379776 totalling 4.54MiB\r\n2020-12-14 14:16:34.038380: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 2468608 totalling 2.35MiB\r\n2020-12-14 14:16:34.038408: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 2891776 totalling 2.76MiB\r\n2020-12-14 14:16:34.038436: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 3170304 totalling 3.02MiB\r\n2020-12-14 14:16:34.038467: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 3416064 totalling 3.26MiB\r\n2020-12-14 14:16:34.038497: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 4194304 totalling 12.00MiB\r\n2020-12-14 14:16:34.038523: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 4210688 totalling 4.02MiB\r\n2020-12-14 14:16:34.038548: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 4218880 totalling 4.02MiB\r\n2020-12-14 14:16:34.038577: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 9437184 totalling 18.00MiB\r\n2020-12-14 14:16:34.038607: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 9445376 totalling 9.01MiB\r\n2020-12-14 14:16:34.038636: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 13672448 totalling 13.04MiB\r\n2020-12-14 14:16:34.038666: I tensorflow/core/common_runtime/bfc_allocator.cc:1038] Sum Total of in-use chunks: 130.72MiB\r\n2020-12-14 14:16:34.038693: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] total_region_allocated_bytes_: 168976384 memory_limit_: 168976384 available bytes: 0 curr_region_allocation_bytes_: 337952768\r\n2020-12-14 14:16:34.038731: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Stats: \r\nLimit:                       168976384\r\nInUse:                       137069568\r\nMaxInUse:                    144622080\r\nNumAllocs:                        1897\r\nMaxAllocSize:                 13672448\r\nReserved:                            0\r\nPeakReserved:                        0\r\nLargestFreeBlock:                    0\r\n\r\n2020-12-14 14:16:34.038840: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ******************************************************xx***_____***_***********************_________\r\nTraceback (most recent call last):\r\n  File \"Test_img_detection.py\", line 36, in <module>\r\n    detections=detect_fn(input_tensor)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\", line 509, in _call_attribute\r\n    return instance.__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 846, in _call\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\r\n    cancellation_manager=cancellation_manager)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\r\n  (0) Internal:  Dst tensor is not initialized.\r\n\t [[{{node input_tensor/_10}}]]\r\n\t [[StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/unstack/_62]]\r\n  (1) Internal:  Dst tensor is not initialized.\r\n\t [[{{node input_tensor/_10}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_restored_function_body_54433]\r\n\r\nFunction call stack:\r\nrestored_function_body -> restored_function_body\r\n</code>", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45422\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45422\">No</a>\n", "Lack of support on this..."]}, {"number": 45421, "title": "I can build tensorflow.dll  successfully,but not  include SSE4.2,Why?", "body": "python ./configure.py    set:\r\nbuild TensorFlow with ROCm support? [y/N]: n\r\nbuild TensorFlow with CUDA support? [y/N]: n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:SSE4.2]:\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nbuild command:  bazel build --config opt //tensorflow/tools/lib_package:libtensorflow\r\ncan you tell me\r\nbuild successfully,but tensorflow.dll not include SSE4.2,Why?  ", "comments": ["tensorflow version is   tensorflow_r2.3", "@lrb352225 \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nProvide the exact sequence of commands / steps that you executed before running into the problem. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45421\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45421\">No</a>\n"]}, {"number": 45420, "title": "[*] Rename \"Arguments:\" to \"Args:\"", "body": "I've written custom parsers and emitters for everything from docstrings to classes and functions. However, I recently came across an issue with the TensorFlow codebase: inconsistent use of `Args:` and `Arguments:` in its docstrings:\r\n\r\n```sh\r\n(tensorflow#d393534)$ for name in 'Args:' 'Arguments:'; do\r\n    printf '%-10s %04d\\n' \"$name\" \"$(rg -IFtpy --count-matches \"$name\" | paste -s -d+ -- | bc)\"; done\r\nArgs:      5333\r\nArguments: 0820\r\n```\r\n\r\nIt is easy enough to extend my parsers to support both variants, howevever it looks like `Arguments:` is wrong anyway, as per:\r\n\r\n  - https://google.github.io/styleguide/pyguide.html#doc-function-args @ [`ddccc0f`](https://github.com/google/styleguide/blob/ddccc0f/pyguide.md)\r\n  - https://chromium.googlesource.com/chromiumos/docs/+/master/styleguide/python.md#describing-arguments-in-docstrings @ [`9fc0fc0`](https://chromium.googlesource.com/chromiumos/docs/+/9fc0fc0/styleguide/python.md)\r\n  - https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html @ [`c0ae8e3`](https://github.com/sphinx-contrib/napoleon/blob/c0ae8e3/docs/source/example_google.rst)\r\n\r\nTherefore, only `Args:` is valid. This PR replaces them throughout the TensorFlow codebase.\r\n\r\nPS: The trackbacks automatically appearing below are sending the same changes to other repositories in the [TensorFlow](https://github.com/tensorflow/tensorflow) and [keras-team](https://github.com/keras-team) organisations.", "comments": ["I think that without having this in day-by-day linting/sanity CI we will go to diverge again.\r\nDo you think that you can solve this with [`pylint.extensions.docparams`](http://pylint.pycqa.org/en/latest/technical_reference/extensions.html) in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/pylintrc?", "@bhack Hmm, I made those changes in the linter, but it picked up a whole bunch of other changes. Might be worth separating into a separate PR, called \"linting\", and merging this one? - Your call.", "I think that you can open a parallel linter PR without fixes in then meantime so that we could see from the CI what Is failing.", "@SamuelMarks  Can you please resolve conflicts? Thanks!", "@SamuelMarks  Any update on this PR? Please. Thanks!", "The CI builds were failing, so I merged in master and did it again. We've got to be faster with this process, otherwise master will diverge too much.\r\n\r\n@kkimdev @gbaned ", "This PR touches a lot of files, so I won't be surprised if it's difficult to land (passing Github CI is not the end, TF engineers have to approve and land internally.).  Let's give it a shot, but if fails, I think it could be better to split this PR."]}, {"number": 45419, "title": "Refactor for case BuiltinOperator_EXP in flatbuffer_conversions.cc/h;\u2026", "body": "\u2026 1st step to port op EXP for TFLite micro", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45419) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot   I signed it!", "#45415 This PR is filed as the 1st step to solve the issue."]}, {"number": 45418, "title": "Convert float32 Image NdArray to uint8", "body": "## URL(s) with the issue:\r\nCouldn't find a documentation.\r\n\r\n## Description of issue (what needs changing):\r\nI use Tensorflow version 2.3.1 (or Nightly)\r\n\r\nI could find tons of information on how to convert int image to float32. However, not being able to do so for the opposite case.\r\n\r\nHow do convert this normalised ndarray(0 to 1) to a 0-255 ndarray while maintaining the same shape?\r\n![Screenshot 2020-12-04 at 21 48 11](https://user-images.githubusercontent.com/2845708/101218255-a9f13780-367a-11eb-9cb4-622dcc65a863.png)\r\n\r\n\r\nThank you,\r\nSean", "comments": ["You can try,\r\n```python\r\nimport numpy as np\r\nimage  = np.array([255,255,0,0])\r\nimage = image / 255 #normalize\r\nimage = image * 255\r\nimage.astype(np.uint8)\r\n```", "Thank you, @ymodak. It's working.\r\n![Screenshot 2020-12-05 at 10 49 53](https://user-images.githubusercontent.com/2845708/101240546-b19af580-36e7-11eb-9eb1-5901897a4228.png)\r\n\r\nNonetheless, numpy `dtype` is still float32. So, I used. \r\nimg_resized_255.astype(np.uint8)\r\n\r\nIssue solved. So, I close this page."]}, {"number": 45417, "title": "Build TensorFlow Lite for Raspberry Pi: Fails at step 4b", "body": "Attempting steps outlined in [](https://www.tensorflow.org/lite/guide/build_rpi)\r\nhttps://www.tensorflow.org/lite/guide/build_rpi\r\nusing a raspberry pi zero w\r\n\r\n--------------------------------------------------------------------\r\n**$ cat /proc/cpuinfo**\r\nprocessor       : 0\r\nmodel name      : ARMv6-compatible processor rev 7 (v6l)\r\nBogoMIPS        : 697.95\r\nFeatures        : half thumb fastmult vfp edsp java tls\r\nCPU implementer : 0x41\r\nCPU architecture: 7\r\nCPU variant     : 0x0\r\nCPU part        : 0xb76\r\nCPU revision    : 7\r\n\r\nHardware        : BCM2835\r\nRevision        : 9000c1\r\nSerial          : 00000000feea1aa3\r\nModel           : Raspberry Pi Zero W Rev 1.1\r\n------------------------------------------------------\r\n **$ cat /etc/os-release**\r\nPRETTY_NAME=\"Raspbian GNU/Linux 10 (buster)\"\r\nNAME=\"Raspbian GNU/Linux\"\r\nVERSION_ID=\"10\"\r\nVERSION=\"10 (buster)\"\r\nVERSION_CODENAME=buster\r\nID=raspbian\r\nID_LIKE=debian\r\nHOME_URL=\"http://www.raspbian.org/\"\r\nSUPPORT_URL=\"http://www.raspbian.org/RaspbianForums\"\r\nBUG_REPORT_URL=\"http://www.raspbian.org/RaspbianBugs\"\r\n\r\n-------------------------------------------------------------------------- \r\n$ uname -a\r\nLinux pizero 5.4.72+ #1356 Thu Oct 22 13:56:00 BST 2020 armv6l GNU/Linux\r\n----------------------------------------------------------------------\r\n\r\n**At step 4b I get the following error:**\r\npi@pizero:~/src/tensorflow_src $ PATH=../rpi_tools/arm-bcm2708/arm-rpi-4.9.3-linux-gnueabihf/bin:$PATH   ./tensorflow/lite/tools/make/                         build_rpi_lib.sh TARGET_ARCH=armv6\r\n+ set -e\r\n+++ dirname ./tensorflow/lite/tools/make/build_rpi_lib.sh\r\n++ cd ./tensorflow/lite/tools/make\r\n++ pwd\r\n+ SCRIPT_DIR=/home/pi/src/tensorflow_src/tensorflow/lite/tools/make\r\n+ TENSORFLOW_DIR=/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/../../../..\r\n++ awk '/^Mem/ {print $2}'\r\n++ free -m\r\n+ FREE_MEM=368\r\n+ [[ FREE_MEM -gt 2000 ]]\r\n+ NO_JOB=1\r\n+ make -j 1 TARGET=rpi -C /home/pi/src/tensorflow_src/tensorflow/lite/tools/make/../../../.. -f tensorflow/lite/tools/make/Makefile TARGET_ARCH=a                         rmv6\r\nmake: Entering directory '/home/pi/src/tensorflow_src'\r\narm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv6 -mfpu=vfp -funsafe-mat                         h-optimizations -ftree-vectorize -fPIC -I. -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/home/pi/src/tensorflow_src                         /tensorflow/lite/tools/make/../../../../../../ -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/home/pi/src/tensorflow_src/                         tensorflow/lite/tools/make/downloads/eigen -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/home/pi/src/tensorflow_src/                         tensorflow/lite/tools/make/downloads/gemmlowp -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/home/pi/src/tensorflow_sr                         c/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/pi/src/                         tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/i                         nclude -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downlo                         ads/cpuinfo/include -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/home/pi/src/tensorflow_src/tensorflow/lite/                         tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/allocation.cc -o /home/pi/src/tensorflow_src/tensorflow                         /lite/tools/make/gen/rpi_armv6/obj/tensorflow/lite/allocation.o\r\n/bin/bash: ../rpi_tools/arm-bcm2708/arm-rpi-4.9.3-linux-gnueabihf/bin/arm-linux-gnueabihf-g++: cannot execute binary file: Exec format error\r\nmake: *** [tensorflow/lite/tools/make/Makefile:334: /home/pi/src/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv6/obj/tensorflow/lite/allocation.o] Error 126\r\nmake: Leaving directory '/home/pi/src/tensorflow_src'\r\n", "comments": ["My mistake, this issue can be closed.  I was attempting the steps Cross-compile for Raspberry Pi with Make when I think I should be following the steps in the Compile natively on Raspberry Pi section. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45417\">No</a>\n"]}, {"number": 45416, "title": "[ROCm] Populating memory bandwidth information in the DeviceDescription", "body": "Currently when running on the ROCm platform, the `deviceMemoryBandwidth` information displayed is incorrect.\r\nfor e.g\r\n```\r\n2020-12-04 14:13:18.503661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1738] Found device 0 with properties:\r\npciBusID: 0000:1c:00.0 name: Vega 10 [Radeon Instinct MI25]     ROCm AMD GPU ISA: gfx900\r\ncoreClock: 1.5GHz coreCount: 64 deviceMemorySize: 15.98GiB deviceMemoryBandwidth: -1B/s\r\n```\r\n\r\nThis commit fixes that by quering the GPU for that information, and populating it correctly in TF\r\n```\r\n2020-12-04 19:41:12.864439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1745] Found device 0 with properties:\r\npciBusID: 0000:63:00.0 name: Vega 10 [Radeon Instinct MI25]     ROCm AMD GPU ISA: gfx900\r\ncoreClock: 1.5GHz coreCount: 64 deviceMemorySize: 15.98GiB deviceMemoryBandwidth: 450.61GiB/s\r\n```\r\n\r\n\r\n/cc @cheshire @chsigg @nvining-work \r\n", "comments": ["@cheshire @chsigg gentle ping", "@cheshire @chsigg gentle ping", "@cheshire @chsigg gentle ping"]}, {"number": 45415, "title": "Micro: port op EXP from Lite", "body": "@tensorflow/micro  @tensorflow/lite  \r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): master\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Sparkfun Edge\r\n\r\n**Describe the problem**\r\nI am about to port The TF Lite kernel op EXP to TF Lite Micro.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nBelow are the first steps I will take to port the op EXP:\r\n- PR 1: refactor flatbuffer_conversions parsing function\r\n- PR 2: refactor reference implementation from lite/kernels/internal/reference/reference_ops.h into its own header without making any changes.\r\n- PR 3: copy the reference kernel from lite to micro without making any changes. At this point the kernel is in micro but it is not part of the build.\r\n\r\n", "comments": ["The operator EXP has been ported into TFLite Micro. This issue has been resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45415\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45415\">No</a>\n", "'lite/micro/tools/make/Makefile' was not updated for micro op EXP, re-opening. ", "The EXP operator has been ported to micro. Closing this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45415\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45415\">No</a>\n", "There is a bug in the micro test code. Re-opening the issue to fix it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45415\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45415\">No</a>\n"]}, {"number": 45414, "title": "Draft PR", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45414) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45414) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 45413, "title": "Model optimization using quantization on desktop PC?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n We are running CNN using tensorflow on desktop PC's GPU, Win 10 64 bit. We would like to do quantization of the trained model to reduce the inference time. But it seems the quantization only works for tensorflow lite. Is there a way to quantitate the model which runs on desktop PC?\r\n\r\n**Will this change the current api? How?**\r\nMaybe. \r\n\r\n**Who will benefit with this feature?**\r\ntensorflow desktop developers\r\n\r\n**Any Other info.**\r\n", "comments": ["@yummychop,\r\nPlease go through [this](https://www.tensorflow.org/model_optimization/guide) TensorFlow model optimization guide and let us know if it helps. Thanks!", "> @yummychop,\r\n> Please go through [this](https://www.tensorflow.org/model_optimization/guide) TensorFlow model optimization guide and let us know if it helps. Thanks!\r\n\r\nThank you for the reply, we tried the weights-based pruning as suggested in the guide, the sparsity of the weights increased but the inference time didn't get improved. As someone raised here: https://github.com/tensorflow/model-optimization/issues/173. The pruning only reduced the model size.\r\nAnd as I indicated above, it seems quantization only works for TF lite and TF lite in only for embedded platforms. We are trying tensorRT\r\nWe are also looking at tensor decomposition... but I do think the quantization should work for a desktop, GPU-based platform. Do you think desktop PC is only for training and evaluation, not for deployment?\r\n", "@yummychop This issue is more related to Model-optimization. It is better if you post this issue in [`Model-optimization`](https://github.com/tensorflow/model-optimization/issues) repo. The issue you share will have more updates in the future as team is working supporting the feature. Thanks!\r\n\r\nPlease open an issue there and close the issue here. Thanks!", "I will raise this issue in the \"model optimization\" section, thank you for your help @jvishnuvardhan "]}, {"number": 45412, "title": "setup.py for object detection installs tensorflow 2.3 which is incompatible and reinstalling tensorflow 2.2 doesn't train through model_main_tf2.py", "body": "The setup.py script installs the false version of packages and rechanging it to Tensorflow 2.2 makes it worse. I can run the inference of pre-trained models but cannot train on custom data. the model_main_tf2.py gives an error always. Please check the packages which are compatible with the Tensorflow version.", "comments": ["@khany27 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45412\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45412\">No</a>\n"]}, {"number": 45411, "title": "Issue in RECURRENT NEURAL NETWORK", "body": "Please let us know anything wrong in below code, not getting desire result -\r\n\r\n```\r\nfrom numpy import sqrt\r\nfrom numpy import asarray\r\nfrom pandas import read_csv\r\nfrom tensorflow.keras import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import LSTM\r\nimport tensorflow as tf\r\nfrom sklearn import metrics\r\nfrom sklearn.model_selection import train_test_split\r\n```\r\n\r\n- Assign the value as 40 to the variabel **RANDOM_SEED** which will be the seed value.\r\n- Set the random seed value using the value stored in the variable **RANDOM_SEED**.\r\n\r\n```\r\nRANDOM_SEED = 40\r\ntf.random.set_seed(RANDOM_SEED)\r\n```\r\n\r\n**# split a univariate sequence into samples**\r\n\r\n```\r\ndef split_sequence(sequence, n_steps):\r\n    X, y = list(), list()\r\n    for i in range(len(sequence)):\r\n        # find the end of this pattern\r\n        end_ix = i + n_steps\r\n        # check if we are beyond the sequence\r\n        if end_ix > len(sequence)-1:\r\n            break\r\n        # gather input and output parts of the pattern\r\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\r\n        X.append(seq_x)\r\n        y.append(seq_y)\r\n    return asarray(X), asarray(y)\r\n```\r\n\r\n- Read the dataset **airline-passengers.csv** and give parameter index_col as 0 and save it in variable df.\r\n\r\n`df = read_csv(\"airline-passengers.csv\", index_col=0)\r\n`\r\n\r\n- Convert the data type of the values dataframe **df** to float32 and save it in variable **values**.\r\n- Assign the value 5 to the variable **n_steps** which is the window size.\r\n- Split the samples using the function **split_sequence** and pass the parameters **values** and **n_steps** and save it in variables **X** and **y**\r\n\r\n```\r\nvalues = df.values.astype('float32')\r\nn_steps = 5\r\nX, y = split_sequence(values, n_steps)\r\n\r\n```\r\n\r\n- Split the data **X**,**y** with the train_test_split function of sklearn with parameters test_size=0.33 and random_state=RANDOM_SEED.**\r\n\r\n`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_SEED)`\r\n\r\nConstruct a fully-connected network structure defined using dense class\r\n- Create a sequential model\r\n- Add a LSTM layer which has 200 nodes with activation function as relu and input shape as (n_steps,1).\r\n- The first hidden layer has 100 nodes and uses the relu activation function.\r\n- The second hidden layer has 50 nodes and uses the relu activation function.\r\n- The output layer has 1 node.\r\n\r\n```\r\nmodel = Sequential()\r\nmodel.add(LSTM(200, activation='relu',  input_shape=(n_steps,1)))\r\nmodel.add(Dense(100, activation='relu'))\r\nmodel.add(Dense(50, activation='relu'))\r\nmodel.add(Dense(1))\r\n```\r\n\r\n- While comipling the model pass the following parameters -\r\n           -optimizer as Adam\r\n           -loss as mse \r\n           -metrics as mae\r\n\r\n`model.compile(optimizer='Adam', loss='mse', metrics=['mae'])`\r\n\r\n- fit the model with X_train, y_train, epochs=350, batch_size=32,verbose=0.\r\n\r\n`model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=0)`\r\n\r\n- Perform prediction on the test data (i.e) on **X_test** and save the predictions in the variable **y_pred**.\r\n\r\n```\r\nrow = ([X_test])\r\ny_pred = model.predict(row)\r\n```\r\n\r\n- Calculate the mean squared error on the variables **y_test** and **y_pred** using the mean_squared_error function in sklearn metrics and save it in variable **MSE**.\r\n- Calculate the Root mean squared error on the variables **y_test** and **y_pred** by performing square root on the above result and save it in variable **RMSE**.\r\n- Calculate the mean absolute error on the variables **y_test** and **y_pred** using the mean_absolute_error function in sklearn metrics and save it in variable **MAE**.\r\n\r\n```\r\nMSE  = metrics.mean_squared_error(y_test,y_pred)\r\nRMSE = sqrt(metrics.mean_squared_error(y_test,y_pred))\r\nMAE  = metrics.mean_absolute_error(y_test,y_pred)\r\nprint('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (MSE, RMSE,MAE))\r\n```\r\n\r\nMSE: 665.522, RMSE: 25.798, MAE: 17.127 ... **this we getting and it is wrong.**\r\n\r\n```\r\nwith open(\"MSE.txt\", \"w\") as text_file:\r\n        MSE=str(MSE)\r\n        text_file.write(MSE)\r\nwith open(\"RMSE.txt\", \"w\") as text_file:\r\n        RMSE=str(RMSE)\r\n        text_file.write(RMSE)\r\nwith open(\"MAE.txt\", \"w\") as text_file:\r\n        MAE=str(MAE)\r\n        text_file.write(MAE)\r\n# serialize model to JSON\r\nmodel_json = model.to_json()\r\nwith open(\"model.json\", \"w\") as json_file:\r\n    json_file.write(model_json)\r\n```\r\n```\r\n\r\n[airline-passengers.zip](https://github.com/tensorflow/tensorflow/files/5646361/airline-passengers.zip)\r\n[airline-passengers.zip](https://github.com/tensorflow/tensorflow/files/5650585/airline-passengers.zip)\r\n\r\n[RNN_Question.zip](https://github.com/tensorflow/tensorflow/files/5650599/RNN_Question.zip)\r\n", "comments": ["Hey @ashishsme14 . I haven't yet run the code , but can you please clear out what you are looking for? What \"desired result(s)\" are you unable get?", "We just need a clarification that we had done coding as per question or not.", "MSE: 665.522, RMSE: 25.798, MAE: 17.127 ... this we getting and it is wrong.", "anything wrong followed for given task?", "please help us\r\n", "@ashishsme14 \r\n\r\nWhich TF version you are using. Can you please share colab link to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "https://www.hackerrank.com/test/3joiio81bhc/questions/ffst10flki5", "tensorflow==2.2.0\r\nnumpy==1.16.0\r\npandas==0.24.2\r\nscipy==1.4.1\r\nscikit-learn==0.19.1\r\npytest==5.4.1\r\nblinker==1.4.0\r\njupyter==1.0.0\r\njupyter-client==6.1.2\r\njupyter-console==6.1.0\r\njupyter-core==4.6.3\r\npickleshare==0.7.5\r\nipynb==0.5.1\r\nkeras==2.3.1\r\nsix==1.14.0\r\nsetuptools==46.1.3", "@ashishsme14 \r\n\r\nCan you please share colab link  or complete code snippet along with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "We already provided complete instructions n cvs file too", "https://serversgxza4en-ws-dev-server-8000.in-rc-3.projects.hackerrank.net/tree?", "https://github.com/tensorflow/tensorflow/files/5650585/airline-passengers.zip", "https://github.com/tensorflow/tensorflow/files/5650599/RNN_Question.zip", "please find all details.. thanks", "details are good?", "After running code then we execute\r\n\r\n```\r\nfrom hashlib import md5\r\nf = open(\"MSE.txt\", \"r\")\r\ns=f.read()\r\ns=float(s)\r\ns=round(s,3)\r\nf1=open(\"RMSE.txt\",\"r\")\r\ns1=f1.read()\r\ns1=float(s1)\r\ns1=round(s1,3)\r\nf2=open(\"MAE.txt\",\"r\")\r\ns2=f2.read()\r\ns2=float(s2)\r\ns2=round(s2,3)\r\nif (md5(str(s).encode()).hexdigest() == '51ad543f7ac467cb8b518f1a04cc06af') and (md5(str(s1).encode()).hexdigest() == '6ad48a76bec847ede2ad2c328978bcfa') and (md5(str(s2).encode()).hexdigest() == '64bd1e146726e9f8622756173ab27831'):\r\n\r\n\tprint(\"Your MSE,RMSE and MAE Scores matched the expected output\")\r\nelse :\r\n\tprint(\"Your MSE,RMSE and MAE Scores does not match the expected output\") \r\n```\r\n\r\nHere our output should be match but coming as unmatched.", "So we need to know given instruction followed perfectly or not", "\r\n@ashishsme14,\r\nOn running the code, I got the values as MSE: 512.102, RMSE: 22.630, MAE: 17.900. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a0b0c21c4bde919d25bde8666aa97c69/45411.ipynb).\r\n\r\nCould you please let us know the expected output / behavior. Thanks!\r\n\r\n", "After running code then we execute\r\n\r\n```\r\nfrom hashlib import md5\r\nf = open(\"MSE.txt\", \"r\")\r\ns=f.read()\r\ns=float(s)\r\ns=round(s,3)\r\nf1=open(\"RMSE.txt\",\"r\")\r\ns1=f1.read()\r\ns1=float(s1)\r\ns1=round(s1,3)\r\nf2=open(\"MAE.txt\",\"r\")\r\ns2=f2.read()\r\ns2=float(s2)\r\ns2=round(s2,3)\r\nif (md5(str(s).encode()).hexdigest() == '51ad543f7ac467cb8b518f1a04cc06af') and (md5(str(s1).encode()).hexdigest() == '6ad48a76bec847ede2ad2c328978bcfa') and (md5(str(s2).encode()).hexdigest() == '64bd1e146726e9f8622756173ab27831'):\r\n\r\n\tprint(\"Your MSE,RMSE and MAE Scores matched the expected output\")\r\nelse :\r\n\tprint(\"Your MSE,RMSE and MAE Scores does not match the expected output\") \r\n```\r\n\r\nHere our output should be match but coming as unmatched.", "with ur output also it is unmatched", "we do not see any difference in ur code and our code still we are getting as -\r\n\r\nMSE: 665.522, RMSE: 25.798, MAE: 17.127", "import hashlib\r\nfrom hashlib import md5\r\nprint(md5(str(512.102).encode()).hexdigest())\r\n\r\ncoming as 8651059a78bff56865b3e2f0322e1cc0  it should be 51ad543f7ac467cb8b518f1a04cc06af", "plz help us", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45411\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45411\">No</a>\n"]}, {"number": 45410, "title": "Incorrect instructions for Tensor RT", "body": "The install instruction: https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101\r\n\r\nHave this code here: \r\n\r\n```\r\n# Install TensorRT\r\nRUN apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```\r\n\r\nWhich returns:\r\n\r\n```\r\nE: Unable to locate package libnvinfer6\r\nE: Unable to locate package libnvinfer-dev\r\nE: Unable to locate package libnvinfer-plugin6\r\n```\r\n", "comments": ["@joehoeller,\r\nI did not face any errors while running the command on Ubuntu 18.04, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3015fd93b2f31caf1265fd8785bbfe2d/45410.ipynb). \r\n\r\nCould you please restart your machine, run all the commands listed in the [guide](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101) and check if it works. Thanks!", "Also in order to expedite the trouble-shooting process, could you please provide the following details\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nand the exact sequence of commands that you executed before running into the error. Thanks!", "It fails in Dockerfile.\n\nOn Mon, Dec 7, 2020 at 3:15 AM Abhilash Mahendrakar <\nnotifications@github.com> wrote:\n\n> Also in order to expedite the trouble-shooting process, could you please\n> provide the following details\n>\n>    - OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n>    - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\n>    happens on mobile device:\n>    - TensorFlow installed from (source or binary):\n>    - TensorFlow version:\n>    - Python version:\n>    - Installed using virtualenv? pip? conda?:\n>    - Bazel version (if compiling from source):\n>    - GCC/Compiler version (if compiling from source):\n>    - CUDA/cuDNN version:\n>    - GPU model and memory:\n>\n> and the exact sequence of commands that you executed before running into\n> the error. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45410#issuecomment-739786128>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABHVQHAWEPXBLIRR2EIFBFTSTSMLTANCNFSM4UNVYD3Q>\n> .\n>\n", "@joehoeller,\r\n> The install instruction: https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101\r\n\r\nThe guide you have linked is for installing TensorFlow pip packages.\r\n\r\nIf you're using Docker containers, please follow the instructions as per [this guide](https://www.tensorflow.org/install/docker). Thanks!\r\n", "Does TF2 work with CUDA 11?\n\nOn Wed, Dec 9, 2020 at 9:04 AM Abhilash Mahendrakar <\nnotifications@github.com> wrote:\n\n> @joehoeller <https://github.com/joehoeller>,\n>\n> The install instruction:\n> https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101\n>\n> The guide you have linked is for installing TensorFlow pip packages.\n>\n> If you're using Docker containers, please follow the instructions as per this\n> guide <https://www.tensorflow.org/install/docker>. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45410#issuecomment-741829385>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABHVQHEFI2QVIKIOBWFHBDTST6GYHANCNFSM4UNVYD3Q>\n> .\n>\n", "@joehoeller,\r\nEvery TensorFlow release is compatible with a certain CUDA and cuDNN version. TF v2.4 and TF-nightly versions are compatible with CUDA 11.\r\n\r\nFor more information, please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "It still doesn\u2019t find GPU on Kubernetes, your suggestions do not solve any\nproblems. I\u2019ve tested this by deploying torch and rapids in same image and\nthey can find the GPU.\n\nOn Mon, Dec 21, 2020 at 1:04 PM tensorflow-butler[bot] <\nnotifications@github.com> wrote:\n\n> This issue has been automatically marked as stale because it has not had\n> recent activity. It will be closed if no further activity occurs. Thank you.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45410#issuecomment-749141986>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABHVQHC2FLBSQCZ2YMYOOCTSV6L3HANCNFSM4UNVYD3Q>\n> .\n>\n", "@joehoeller,\r\nCould you please provide the below information so that we can escalate the issue accordingly\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45410\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45410\">No</a>\n"]}, {"number": 45409, "title": "Cleanup `tensorflow/c/experimental/gradients` Part 1", "body": "@saxenasaurabh \r\n\r\nCommit messages are self-explained.\r\n\r\nIn 5bbdd5b, I add `manual` to `gradient_checker_test` since it depends heavily on `mnist_gradients_testutils` and it should be refactored in a separate PR. ( It doesn't compile right now ).\r\n\r\nRegarding the memory leak:\r\n\r\n---\r\n\r\nOne leak comes from https://github.com/tensorflow/tensorflow/blob/fefcd5704ba4efe873485b981644ce0fb18c2440/tensorflow/c/eager/gradients_util.cc#L130-L138\r\n\r\n`TFE_TensorHandleResolve` returns `new TF_Tensor{t};`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/fefcd5704ba4efe873485b981644ce0fb18c2440/tensorflow/c/eager/c_api.cc#L336-L349\r\n\r\nWe have to manually delete `TF_Tensor*` but sometime, it's not intuitive because we don't see the `new`.\r\nhttps://github.com/tensorflow/tensorflow/blob/fefcd5704ba4efe873485b981644ce0fb18c2440/tensorflow/c/eager/gradient_checker.cc#L81-L83\r\n\r\nWe could delete `TF_Tensor*` manually but I think it's better if we could come up with a more intuitive solution. ( Note that this PR does not address this issue ). WDYT ?\r\n\r\n---\r\n\r\nHere is a full log. I don't have enough time to fully analyse it. However, I think there are 4 causes: `TF_Tensor`, `Tape*`,  `AbstractTensorHandle*` and `AbstractContext*`. And the problem might be caused by not only `gradient_checker` but also other parts of the code. However, I think we could leave it here and we better address it in a different PR.\r\n\r\n[test.log](https://github.com/tensorflow/tensorflow/files/5651693/test.log)\r\n", "comments": ["@saxenasaurabh Could you take a look at this PR? Thank you!", "@saxenasaurabh \r\nI think a cleaner PR is better. Please take a look at #45547 "]}, {"number": 45408, "title": "[ROCm][r2.4]Porting changes from master to switch to ROCm 3.9", "body": "/cc @sunway513 ", "comments": []}, {"number": 45407, "title": "Optimize MutableDenseHashTable's memory usage and performance in case of large value_shape", "body": "When value_shape is very large, we'll store a pointer in key_buckets element, and store table values into a vector of value_buckets, which containers no empty values. This optimize can decrease 15% memory usage in a test case of value_dtype = int64 and value_shape = [16], also get better lookup/insert performance.\r\nIf value_shape is very small or key/value dose not support memcpy, we'll back to the version of single key_buckets and value_buckets_.", "comments": ["@rohan100jain hi, any suggestions ?", "@rangjiaheng  Can you please resolve conflicts? Thanks!", "@rangjiaheng  Any update on this PR? Please. Thanks!", "@rangjiaheng Can you please check @rohan100jain's comments and resolve conflicts?. Thanks!\r\n", "@rangjiaheng Any update on this PR? Please. Thanks!", "It has been 19 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}]