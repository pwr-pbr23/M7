[{"number": 51478, "title": "[TF:TRT:]Remove dangerous const_cast in TRT_ShapedWeights::GetValues", "body": "This PR splits `TRT_ShapedWeights::GetValues()` into const and non-const methods to obey `const` requirements without using`const_cast`. It changes the method to a template which returns a `T*` or `const T*` pointer (rather than void*), \r\neliminating pointer casting throughout code base when using GetValues(). It also renames GetValues to GetPointer as the template actually a pointer not values.\r\n\r\n@bixia1, @tfeher for review", "comments": ["@bixia1, I applied your recommended changes.", "OK I will change from `size_t` to `int` then. Was this caught by internal CI or your build? What is the warning/copt set so this doesn't happen in the future? I am just using default.", "@bixia1 updated from `size_t` to `int64`. I built with GCC option `-Werror=narrowing`, and it appears to be fixed. I think you're on Clang, for which I don't have env setup right now. I can add that to my build setup. Do you have non default `cxxopts/copts` settings for Bazel? Thanks. Let me know if you have any other concerns. "]}, {"number": 51476, "title": "\"UnauthenticatedError: ioctl failed\" when creating tensors, after initializing JAX on a TPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): TPU v3-8 VM (so Ubuntu 20.04.2 LTS)\r\n- TensorFlow installed from (source or binary): Binary (but I'm using what came pre-installed on the VM)\r\n- TensorFlow version (use command below): `unknown 2.6.0` -- when I run `pip freeze` the version is `tf-nightly==2.6.0`.\r\n- Python version: Python 3.8.5\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A (Using a TPU)\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to load a dataset using Tensorflow Datasets, and run code with Jax, on a TPU VM. I'd like to do some preprocessing operations on that dataset in tensorflow. However, after initializing Jax, tensorflow can't seem to create any tensors. Here's a MWE:\r\n\r\n* Setup: First create a [cloud TPU VM](https://cloud.google.com/tpu/docs/jax-quickstart-tpu-vm), ssh into it, and install JAX: `sudo pip3 install \"jax[tpu]==0.2.18\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html`\r\n*  Now I run:\r\n```python\r\nimport jax\r\nimport tensorflow as tf\r\nprint('JAX process: {} / {}. Local devices {}'.format(jax.process_index(), jax.process_count(), jax.local_devices()), flush=True)\r\nX = tf.constant(1.0, dtype=tf.float32)\r\n```\r\nand get\r\n```python\r\n---------------------------------------------------------------------------\r\nUnauthenticatedError                      Traceback (most recent call last)\r\n<ipython-input-2-9895b44de223> in <module>\r\n      2 import tensorflow as tf\r\n      3 print('JAX process: {} / {}. Local devices {}'.format(jax.process_index(), jax.process_count(), jax.local_devices()), flush=True)\r\n----> 4 X = tf.constant(1.0, dtype=tf.float32)\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    262     ValueError: if called on a symbolic tensor.\r\n    263   \"\"\"\r\n--> 264   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n    265                         allow_broadcast=True)\r\n    266\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    274       with trace.Trace(\"tf.constant\"):\r\n    275         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n--> 276     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    277\r\n    278   g = ops.get_default_graph()\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    299 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\r\n    300   \"\"\"Implementation of eager constant.\"\"\"\r\n--> 301   t = convert_to_eager_tensor(value, ctx, dtype)\r\n    302   if shape is None:\r\n    303     return t\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     95     except AttributeError:\r\n     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n---> 97   ctx.ensure_initialized()\r\n     98   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     99\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py in ensure_initialized(self)\r\n    552         pywrap_tfe.TFE_ContextOptionsSetRunEagerOpAsFunction(\r\n    553             opts, self._run_eager_op_as_function)\r\n--> 554         context_handle = pywrap_tfe.TFE_NewContext(opts)\r\n    555       finally:\r\n    556         pywrap_tfe.TFE_DeleteContextOptions(opts)\r\n\r\nUnauthenticatedError: ioctl failed\r\n```\r\n\r\n*My hunch about what is going on*\r\n\r\nI suspect, but am not sure, that the problem is that Tensorflow is trying to create tensors on the TPU. This isn't intended because I'd like it to create tensors on the CPU instead. I've tried looking through [this guide](https://www.tensorflow.org/api_docs/python/tf/config/set_visible_devices) and also adding this line of code right after importing tensorflow:\r\n```\r\ntf.config.experimental.set_visible_devices([], 'GPU')\r\n```\r\nwhich I saw in a bunch of tutorials, but it doesn't help. (Which is perhaps not surprising because there aren't any GPUs on a TPU VM). When I run `tf.config.list_logical_devices()` afterwards I get\r\n\r\n```python\r\n[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\r\n LogicalDevice(name='/device:TPU_SYSTEM:0', device_type='TPU_SYSTEM'),\r\n LogicalDevice(name='/device:TPU:0', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:1', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:2', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:3', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:4', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:5', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:6', device_type='TPU'),\r\n LogicalDevice(name='/device:TPU:7', device_type='TPU')]\r\n```\r\n\r\nMore surprisingly though, for some reason, even when I run \r\n```python\r\ntf.config.experimental.set_visible_devices([], 'GPU')\r\ntf.config.experimental.set_visible_devices([], 'TPU_SYSTEM')\r\ntf.config.experimental.set_visible_devices([], 'TPU')\r\n```\r\n\r\nI get the same result. so I'm not quite sure how to hide TPUs from tensorflow, or, for that matter, how anyone else is able to do so \ud83d\ude05 \r\n\r\n**Describe the expected behavior**\r\n\r\nI'd like the tensor to be initialized (a constant value of 1.0), and on the CPU. The reason I'm creating a tensor here is to do some data preprocessing and augmentation, like [what was used for the flax ImageNet examples](https://github.com/google/flax/blob/main/examples/imagenet/input_pipeline.py), and that augmentation should live on CPU.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no (I'm not sure what the fix is or what I'm doing wrong).\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nSee above.\r\n\r\n**Other info / logs**\r\n\r\nInspecting the logs in `/tmp/tpu_logs/` I found:\r\n\r\n```\r\ncat /tmp/tpu_logs/tpu_driver.t1v-n-e14a9395-w-0.rowanz.log.ERROR.20210812-234557.16896\r\nLog file created at: 2021/08/12 23:45:57\r\nRunning on machine: t1v-n-e14a9395-w-0\r\nBinary: Built on May 19 2021 03:34:24 (1621420438)\r\nBinary: Built at cloud-tpus-runtime-release-tool@a3446e09a7af769-324b9e30725.borgtask.google.com:/google/src/cloud/buildrabbit-username/buildrabbit-client/g3\r\nBinary: Built for gcc-4.X.Y-crosstool-v18-llvm-grtev4-k8\r\nLog line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg\r\nE0812 23:45:57.936586   18120 kernel_dma_mapper.cc:88] Error setting number simples with FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']\r\nE0812 23:45:57.936686   18119 kernel_dma_mapper.cc:88] Error setting number simples with FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']\r\nE0812 23:45:57.936775   18120 tensor_node.cc:436] [0000:00:05.0 PE0 C1 MC-1 TN0] Failed to set number of simple DMA addresses: FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']\r\nE0812 23:45:57.936795   18119 tensor_node.cc:436] [0000:00:07.0 PE0 C3 MC-1 TN0] Failed to set number of simple DMA addresses: FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']\r\n```", "comments": ["hey all! update: I figured it out and am closing this issue (but maybe debugging it is helpful for others)?\r\n\r\nEssentially the issue is that my setup command wasn't installing `tensorflow-cpu==2.6.0`. I also had to install everything not using \"sudo pip\" (which is probably the way to go), as when I installed via sudo, I got a segfault when trying to run `python3 -c \"import tensorflow\"`.\r\n\r\nhope this helps someone else \ud83d\ude04 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51476\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51476\">No</a>\n"]}, {"number": 51475, "title": "[TF:TRT] Enable dynamic shape for \"slice\" and \"strided slice\" operations.", "body": "Enables dynamic shape support during conversion of Tensorflow \"slice\" and \"strided slice\" operations to TensorRT ISliceLayer.\r\n\r\nMoves existing `StridedSliceHelper` function to dedicated `ops/slice_ops.[h|cc]` file and refactors it extensively to support dynamic shape requirements.\r\nTo support the creation of ancillary graphs in the TensorRT network, a helper class TRTNetworkBuilder is added to quickly create familiar operations  (e.g. Nonzero, Sign, ZerosLike) via composition of those layers exposed by TensorRT.\r\nConverter functions which utilize StridedSliceHlper (ConvertStridedSlice, ConvertSlice, ConvertSplit) are updated to use the new helper and gain dynamic shape support.\r\nTests for ConvertStridedSlice are updated to include better documentation and additional tests for dynamic shape. A negative test for new_axis_mask is added.\r\n", "comments": [" @christopherbate is this ready to review, or is it still in a draft state?", "Still in draft, will be ready by end of week", "@bixia1 This is ready for review", "I only reviewed part of the change in the tests and I am still working on reviewing the change to the converter.\r\n\r\nIt would be nice if you can add some details to the PR description to describe the change in this PR, such as how you extend the converter to support dynamic shapes and the tests you added.", "@bixia1 I applied changes to address your comments as additional commits for readability, will squash once approved", "rebased on TOT and fixed preprocessor guard issue", "@bixia1 I applied all your suggestions/feedback. The only things I disagreed with are the weight store and return type of functions in the network builder utility class. Let me know if you'd like to discuss further.", "Thank you for the revision and pointing out the two things that you don't agree with. Next time, can you leave the comments that you don't agree with as \"unresolved\" so I won't miss them? We will need to discuss those further.", "@bixia1 I applied your suggestions.", "Can you address [this request](https://github.com/tensorflow/tensorflow/pull/51475#issuecomment-908025859) for adding more detail description to the PR description?\r\n\r\nCan you also review the guideline for using \"auto\" for type deduction [here](https://google.github.io/styleguide/cppguide.html#Type_deduction) to fix the place where we should not use \"auto\"?\r\n", "> Can you address [this request](https://github.com/tensorflow/tensorflow/pull/51475#issuecomment-908025859) for adding more detail description to the PR description?\r\n\r\nI updated the PR description\r\n\r\n", "I added a commit to completely remove usage of TensorRT ISelectLayer as it is not supported with static version of TensorRT. Was able to work around it by replacing implementation of NonZero and AbsInt operations with slightly different implementations.", "I went through once again and have pushed fixes for all comments minus the comment about scoping where I have asked for clarification on the style/rules.", "Googler refactored int64's to int64_t's, creating conflict just now. Do I need to rebase or do you guys handle this internal?", "Please rebase.", "rebased"]}, {"number": 51474, "title": "update `@pasta` to work when `@org_tensorflow` is *not* the main repo", "body": "`@pasta`'s BUILD file uses a helper macro (in `build_defs.bzl`) that lives in `@org_tensorflow` which it references using `@//` (the main repo). This breaks when `@org_tensorflow` isn't the main repo; i.e. if it's a dependency in another workspace.\r\n\r\nThis PR changes the setup for the `@pasta` repo to symlink `build_defs.bzl` into the `@pasta` repo.", "comments": []}, {"number": 51473, "title": "tf.stop_gradient sometimes does not work as expected when called from a @tf.function ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary. \r\n- TensorFlow version (use command below): Tested with 2.4 and 2.6\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 11.0 / cuDNN 8.0.4\r\n- GPU model and memory: 1080 ti\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe command \r\n\r\nquantized_grad_stop = z + tf.stop_gradient(quantized - z)\r\n\r\ndoes not work as expected when it is called from a decorated function @tf.function\r\n\r\nIt works as it is expected when the @tf.function is removed (e.g. #@tf.function)\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behavior is to pass the value of quantized during the forward pass and use the value of z in the calculation of derivatives \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nThe following code demonstrates the problem. Run the code once with #@tf.function and once with @tf.function\r\n[vector_quantizer.py.zip](https://github.com/tensorflow/tensorflow/files/6978589/vector_quantizer.py.zip)\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@tsiaras ,\r\n\r\nI was tried to execute the given code,but it is taking long time interval for the execution.To debug the issue,can you please provide the  simple code snippet which pinpoints the issue or error you are facing while execution.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51473\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51473\">No</a>\n"]}, {"number": 51472, "title": "OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.", "body": "I'm Trying to implement a Triplet lose based NN, and for this cause I have implemented a custom Image Generator.\r\nWhen I start the ```model.fit()``` I get the following error:\r\n```\r\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n```\r\nEven Though I'm not even iterating a single tensor in My code.\r\nMy code is listed here below:\r\n\r\nthe Image Generator:\r\n```python\r\nclass TripletDataGenerator(tf.keras.utils.Sequence):\r\n    \"\"\"\r\n    NOTE: ON model.fit(SHUFFLE=FALSE) -> MUST BE FALSE!\r\n    \"\"\"\r\n\r\n    def __init__(self,\r\n                 df: pd.DataFrame,\r\n                 batch_size=256,\r\n                 shuffle=True,\r\n                 rescale: {float, None} = 1. / 255.,\r\n                 target_img_size=(128, 128),\r\n                 preprocess_function=None,\r\n                 rand_preproc_single: {ImageDataGenerator, dict} = None,\r\n                 rand_preproc_batch: list = None):\r\n        self.batch_counter = 0\r\n        self.last_batch_index = 0\r\n        if shuffle:\r\n            self.triplets_df = df.sample(frac=1).reset_index(drop=True)  # randomizing it\r\n        else:\r\n            self.triplets_df = df.reset_index(drop=True)  # randomizing it\r\n        self.preprocess_function = preprocess_function\r\n        self.rescale = rescale\r\n        self.target_img_size = target_img_size\r\n\r\n        assert batch_size > 0, \"Minimum batch size is 1, must be positive.\"\r\n        self.batch_size = batch_size\r\n        self.shuffle = shuffle\r\n        # indexes of rows. every batch we draw 2 samples. 1 similar and 1 dissimilar\r\n        self.indexes = np.arange(len(self.triplets_df))\r\n        if self.shuffle:\r\n            np.random.shuffle(self.indexes)\r\n\r\n        self.rand_preproc_single = rand_preproc_single\r\n        self.rand_preproc_batch = rand_preproc_batch\r\n\r\n    def __len__(self):\r\n        \"\"\"Denotes the number of batches per epoch\"\"\"\r\n        return len(self.triplets_df) // self.batch_size\r\n\r\n    def __getitem__(self, index):\r\n        \"\"\"Generate one batch of data\"\"\"\r\n        # Generate indexes of the batch\r\n        indexes = self.indexes[index * self.batch_size:\r\n                               (index + 1) * self.batch_size]\r\n        self.last_batch_index = index\r\n\r\n        anchors = []\r\n        positives = []\r\n        negatives = []\r\n        for idx in indexes:\r\n            a, p, n = self.triplets_df.iloc[idx]\r\n            anchors.append(self.load_image(a))\r\n            positives.append(self.load_image(p))\r\n            negatives.append(self.load_image(n))\r\n\r\n        anchors = np.array(anchors, dtype='float32')\r\n        positives = np.array(positives, dtype='float32')\r\n        negatives = np.array(negatives, dtype='float32')\r\n        labels = np.zeros(self.batch_size)\r\n        if self.rand_preproc_batch is not None:\r\n            for func in self.rand_preproc_batch:\r\n                anchors = func(anchors)\r\n                positives = func(positives)\r\n                negatives = func(negatives)\r\n\r\n        return [anchors, positives, negatives], labels\r\n\r\n    def on_epoch_end(self):\r\n        \"\"\"Updates indexes after each epoch\"\"\"\r\n\r\n        self.batch_counter += self.last_batch_index + 1  # indices starts from 0\r\n        if self.batch_counter >= len(self):\r\n            if self.shuffle:\r\n                np.random.shuffle(self.indexes)\r\n                self.triplets_df = self.triplets_df.sample(frac=1).reset_index(drop=True)\r\n            self.batch_counter = 0\r\n        else:\r\n            self.indexes = np.append(self.indexes[self.last_batch_index + 1:],\r\n                                     self.indexes[: self.last_batch_index + 1])\r\n\r\n    def load_image(self, path):\r\n        \"\"\"\r\n        loads an image using tensorflow tools\r\n        :param path: absolute path (refers to the project's folder) to the image\r\n        :return: an image array.\r\n        \"\"\"\r\n        if self.rand_preproc_single is not None:\r\n            if isinstance(self.rand_preproc, ImageDataGenerator):\r\n                img_arr = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\r\n                img_arr = self.rand_preproc.random_transform(img_arr)\r\n                img_arr = cv2.resize(img_arr, self.target_img_size)\r\n            else:\r\n                img_arr = my_utils.image_augmentations(path, **self.rand_preproc)\r\n        else:\r\n            img_arr = cv2.imread(path)\r\n            img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\r\n            img_arr = cv2.resize(img_arr, self.target_img_size)\r\n        if self.preprocess_function is not None:\r\n            img_arr = self.preprocess_function(img_arr)\r\n        elif self.rescale is not None:\r\n            img_arr = img_arr * self.rescale\r\n        return img_arr\r\n\r\n```\r\n\r\nThe model's Architecture is as follows:\r\n```python\r\ndef get_siamese_model(input_shape, conv2d_filters):\r\n    # Define the tensors for the two input images\r\n    anchor_input = Input(input_shape, name=\"Anchor_Input\")\r\n    positive_input = Input(input_shape, name=\"Positive_Input\")\r\n    negative_input = Input(input_shape, name=\"Negative_Input\")\r\n\r\n    body = build_body(input_shape, conv2d_filters)\r\n\r\n    # Generate the encodings (feature vectors) for the two images\r\n    encoded_a = body(anchor_input)\r\n    encoded_p = body(positive_input)\r\n    encoded_n = body(negative_input)\r\n\r\n    ap_distance = tf.reduce_sum(tf.square(encoded_a - encoded_p), axis=-1, keepdims=True)\r\n    an_distance = tf.reduce_sum(tf.square(encoded_a - encoded_n), axis=-1, keepdims=True)\r\n    # Connect the inputs with the outputs\r\n    siamese_net = Model(inputs=[anchor_input, positive_input, negative_input],\r\n                        outputs=[ap_distance, an_distance])\r\n    return siamese_net\r\n```\r\nand loss is:\r\n```python\r\ndef get_loss(margin=1.0):\r\n    def triplet_loss(y_true, y_pred):\r\n        # The output of the network is a tuple containing the distances\r\n        # between the anchor and the positive example, and the anchor and\r\n        # the negative example.\r\n        ap_distance, an_distance = y_pred\r\n\r\n        # Computing the Triplet Loss by subtracting both distances and\r\n        # making sure we don't get a negative value.\r\n        loss = ap_distance - an_distance\r\n        loss = tf.maximum(loss + margin, 0.0)\r\n        return loss\r\n\r\n    return triplet_loss\r\n```\r\nMain:\r\n```python\r\nif __name__ == '__main__':\r\n\r\n    EPOCHS = configurations.EPOCHS\r\n    BATCH_SIZE = configurations.BATCH_SIZE\r\n    IMG_SIZE = configurations.IMG_SIZE\r\n    MONITOR = configurations.MONITOR\r\n    PATIENCE = configurations.PATIENCE\r\n    EMBEDDING_NODES = configurations.EMBEDDING_NODES\r\n    LEARNING_RATE = configurations.LEARNING_RATE\r\n    STEPS_PER_EPOCH = configurations.STEPS_PER_EPOCH\r\n    VALIDATION_STEPS = configurations.VALIDATION_STEPS\r\n    CONV2D_FILTERS = configurations.CONV2D_FILTERS\r\n    MARGIN = configurations.MARGIN\r\n    DATA_FILE = 'LFW_triplets.csv'\r\n    augment_params = None\r\n    # augment_params = dict(\r\n    #     resize=IMG_SIZE[:-1],\r\n    #     random_gray_scale=0.2,\r\n    #     random_contrast_range=[0.65, 1.5],\r\n    #     hsv_noise_max_amps=[0.02, 0.2, 0],\r\n    #     max_brightness_delta=0.15,\r\n    #     LR_flip=True,\r\n    #     UD_flip=False,\r\n    #     rotate_range=30,\r\n    #     random_shift=[0.1, 0.1],\r\n    #     random_zoom_range=0.3,\r\n    #     rescale=1. / 255.)\r\n\r\n    NOTES = '\\n'.join([\r\n        f\"batch size={BATCH_SIZE}\",\r\n        f\"learning_rate={LEARNING_RATE}\",\r\n        f\"embedding_nodes={EMBEDDING_NODES}\",\r\n        f\"DataFilePath={DATA_FILE}\",\r\n        f\"BatchNormalization_used={configurations.ADD_BATCHNORM}\",\r\n        f\"Conv2D_filters_count={CONV2D_FILTERS}\",\r\n        f\"Loss=triplet_loss\",\r\n        \"Augmentations with: HSV, Brightness, Contrast.\"\r\n    ])\r\n\r\n    np.random.seed(42)\r\n    tf.random.set_seed(42)\r\n\r\n    t = time.time()\r\n    train_gen, test_gen = DataFrameGeneratorClass.create_train_test_generators(csv_path=DATA_FILE, pair_gen=False,\r\n                                                                               validation_split=0.3, shuffle=True,\r\n                                                                               batch_size=configurations.BATCH_SIZE,\r\n                                                                               rescale=1. / 255.,\r\n                                                                               img_size=configurations.IMG_SIZE[:-1],\r\n                                                                               preprocess_func=None,\r\n                                                                               rand_preproc_single=None,\r\n                                                                               rand_preproc_batch=None)\r\n\r\n    dt = time.time() - t\r\n    print(f\"TOOK {dt} seconds to create Train Generator with {len(train_gen)} Batches\"\r\n          f\" and Test Generator with {len(test_gen)} Batches\")\r\n\r\n    siamese_model = get_siamese_model(input_shape=IMG_SIZE, conv2d_filters=CONV2D_FILTERS)\r\n    siamese_model.summary()\r\n    loss_func = get_loss(margin=MARGIN)\r\n    siamese_model.compile(optimizer=Adam(learning_rate=0.0001),\r\n                          loss=loss_func)\r\n\r\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor=MONITOR,\r\n                                                  min_delta=1e-5,\r\n                                                  patience=PATIENCE,\r\n                                                  verbose=1,\r\n                                                  mode='auto',\r\n                                                  restore_best_weights=True)\r\n\r\n    date_string = datetime.datetime.today().strftime(\"%d-%m-%y_%H%M%S\")\r\n    os.mkdir(f'check_points/{date_string}/')\r\n    chk_point = tf.keras.callbacks.ModelCheckpoint(f'check_points/{date_string}/',\r\n                                                   monitor=configurations.MONITOR,\r\n                                                   verbose=1,\r\n                                                   save_best_only=True,\r\n                                                   save_weights_only=True)\r\n\r\n    call_backs = [early_stop, chk_point, tf.keras.callbacks.TensorBoard(log_dir=f'logs/TRIPLET_{date_string}', write_images=True)]\r\n\r\n    history = siamese_model.fit(train_gen,\r\n                                shuffle=False,  # ITS MANDATORY WHEN USING MY CUSTOM GENERATOR\r\n                                epochs=EPOCHS,\r\n                                steps_per_epoch=STEPS_PER_EPOCH,\r\n                                validation_steps=VALIDATION_STEPS,\r\n                                callbacks=call_backs,\r\n                                validation_data=test_gen)\r\n\r\n    NOTES += f\"\\n\\n{chk_point.monitor}={chk_point.best}\"\r\n    my_utils.save_results(notes=NOTES,\r\n                          history_obj=history,\r\n                          directory_dst='results',\r\n                          model=siamese_model,\r\n                          date_str=\"TRIPLET_\" + date_string)\r\n```", "comments": ["@JJKK1313,\r\n\r\nCan you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) for us to expedite the trouble-shooting process. Thanks!", "I have found the issue.\r\nthis:\r\n``` a,b = some_tensor```\r\nis not supported.", "@JJKK1313,\r\n\r\nRegarding your comment `a,b = some_tensor` is not supported,\r\n\r\nIt can work when the tensor has shape of `(2,N)`. Take a look at [gist here](https://colab.research.google.com/gist/sanatmpa1/48ff9ee5e3013dcf66cdcbefb74a26f5/51472.ipynb). Let me know if it helps. Thanks!", "Oh, so Maybe I have tried doing it on tensor of shape (2,). Thanks", "@JJKK1313,\r\n\r\nPlease let me know if it helps in resolving your issue. Thanks!", "Yes, it did. Thanks. @sanatmpa1 ", "Thanks for the confirmation @JJKK1313  and I am closing this issue!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51472\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51472\">No</a>\n"]}, {"number": 51471, "title": "TF-TRT MNIST test with V2 converter", "body": "This PR extends the MNIST test to use the V2 converter. We create a saved model, and convert it both with and without dynamic shape mode.\r\n\r\nTagging @bixia1 for review. Tracker #45481", "comments": ["@bixia1 this is ready for review", "@tfeher Can you please resolve conflicts? Thanks!", "@gbaned I have resolved the conflicts."]}, {"number": 51470, "title": "[ROCM] enable some multigpu tests", "body": "This PR enables some of the multi-gpu tests that were disabled in a previous pr https://github.com/tensorflow/tensorflow/pull/50331", "comments": ["@micmelesse thank you for the PR, please let us know when it is ready for review , also add some description for PR.", "@rthadur This pr is ready for review. Sorry about that. ", "@gbaned @cheshire I am not sure the Windows Bazel failures have anything to do with my changes. I cannot access the feedback/copybara page.", "Sometimes this requires a couple of runs.", "@micmelesse  Can you please resolve conflicts? Thanks!\r\n", "@gbaned Just merged from main. It should resolve the merge conflicts", "@gbaned @cheshire Is there something that I should address in the \"feedback/copybara\" failure  or is it a ci issue? I cannot access the details of the test", "Sometimes trying multiple times also helps.", "@gbaned @cheshire  All the tests pass is it possible to merge this now", "@micmelesse Can you please resolve conflicts? Thanks!", "@gbaned  conflicts resolved.", "@micmelesse Can you please resolve conflicts? Thanks!", "@gbaned sorry for the delayed response. Conflicts are resolved.", "@cheshire Can you please review this PR ? Thanks!", "@cheshire Can you please review this PR ? Thanks!", "@micmelesse Can you please resolve conflicts? Thanks!", "@micmelesse Any update on this PR? Please. Thanks!", "@gbaned Apologies I have resolved the conflicts.", "@gbaned @cheshire I am not sure the failures have anything to do with the changes in this pr. It just enables tests on rocm. The ROCM ci passes."]}, {"number": 51469, "title": "[TF-TRT] Fix an uninitialized variable in ConvertEinsum.", "body": "Uninitialized variable `output_has_ellipsis` would periodically result in test failure due to undefined behavior. `EinsumHelper::ParseEquation` apparently does not set this variable under certain parsing conditions.\r\n\r\nRemoved `#if` guard on test as test failure seems unrelated to TRT8.\r\n\r\nFormatting applied after `#if` guard removed.\r\n\r\n@tfeher \r\n@bixia1 ", "comments": ["Thanks for catching the unitialization bug in the Einsum parser. Since input_has_ellipsis also has the bug, I already merged a fix to the Einsum parser.\r\n\r\nYou have this in your PR description:\r\nRemoved #if guard on test as test failure seems unrelated to TRT8.\r\n\r\nYour change enables the test for TRT8. Do you actually mean the test passes with TRT8? If that is the case, can you revise the PR title and the PR description so that I can approve the change for the test?\r\n\r\n", "I think the bug is fixed. Let me double-check as this was a week ago.", "Is this still an issue? I think this should be fixed."]}, {"number": 51468, "title": "[TF:TRT] Enable dynamic batch dim for Conv2dBackpropInput", "body": "This PR enables dynamic batch dimension for Conv2dBackpropInput.\r\n\r\nWe enable dynamic batch dimension for Conv2DBackpropInput simply by relaxing the check to allow dynamic batch dimension in the converter. We also add positive and negative tests.\r\n\r\nThe support for dynamic height and width will come later. This is because we will need to add an additional dynamic padding operation in order to support dynamic height and width for Conv2dBackpropinput.", "comments": ["@bixia1 \r\n@tfeher ", "Thanks @christopherbate for this PR! I had a quick look at the changes, it looks good overall.", "This is what you have for the PR description:\r\nThis PR enables dynamic batch dimension for Conv2dBackpropInput.\r\n\r\nFull dynamic shape for height and width will come later. We first need to add an additional dynamic padding operation support in order to handle the case where the input_shapes operation argument is non-constant.\r\n\r\nHere is my suggestion to revise it. Do you see any problem?\r\nThis PR enables dynamic batch dimension for Conv2dBackpropInput.\r\n\r\nWe enable dynamic batch dimension for Conv2DBackpropInput simply by relaxing the check to allow dynamic batch dimension in the converter. We also add positive and negative tests.\r\n\r\nThe support for dynamic height and width will come later. This is because we will need to add an additional dynamic padding operation in order to support dynamic height and width for Conv2dBackpropinput.\r\n\r\n", "> This is what you have for the PR description:\r\n> This PR enables dynamic batch dimension for Conv2dBackpropInput.\r\n> \r\n> Full dynamic shape for height and width will come later. We first need to add an additional dynamic padding operation support in order to handle the case where the input_shapes operation argument is non-constant.\r\n> \r\n> Here is my suggestion to revise it. Do you see any problem?\r\n> This PR enables dynamic batch dimension for Conv2dBackpropInput.\r\n> \r\n> We enable dynamic batch dimension for Conv2DBackpropInput simply by relaxing the check to allow dynamic batch dimension in the converter. We also add positive and negative tests.\r\n> \r\n> The support for dynamic height and width will come later. This is because we will need to add an additional dynamic padding operation in order to support dynamic height and width for Conv2dBackpropinput.\r\n\r\nNo problem,  I updated the description.\r\n", "I updated test parameter naming to be inline with other dynamic shape developments.\r\n\r\nI've rebased on master, but it still it shows difference between `third_party/tf_runtime/workspace.bzl`. Any ideas on why this is?"]}, {"number": 51466, "title": "TF2.6 How to avoid UnimplementedError error for non-deterministic ops?", "body": "After I upgarde from 2.5 to 2.6, the non-deterministic ops will throw UnimplementedError after set TF_DETERMINISTIC_OPS = 1. \r\n\r\nHowever, I still want to use the exist implemented deterministic ops and keep unimplemented ops non-deterministic. \r\n\r\nWhat should I do to avoid UnimplementedError error for non-deterministic ops", "comments": ["@edwardyehuang ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51466\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51466\">No</a>\n", "TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS"]}, {"number": 51464, "title": "ResNetV2 implementation problem", "body": "**System information**\r\n(not related to installation)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.5.0 GPU\r\n- Python version: 3.8\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nAs shown in the image below from **Identity Mappings in Deep Residual Networks** by He et al.\\\r\nResNetV2 block has its preactivation **after** branching (bn-relu-conv-bn-relu-conv are all in contained in residual)\r\n![image](https://user-images.githubusercontent.com/49250812/129236962-d30af2fc-8bac-4ddf-a951-6d986d25bef3.png)\r\nthe **only** exception on preactivation is the first block of the first stage\\\r\nquote from the original paper:\r\n> For the first Residual Unit (that follows a stand-alone convolutional layer,\r\n> conv1), we adopt the first activation right after conv1 and before splitting into\r\n> two paths\r\n\r\n**Describe the current behavior**\r\nResNetV2 Falsefully put preactivation before branching when channel increases for **all stages**\r\n![image](https://user-images.githubusercontent.com/49250812/129238244-89917129-a60f-45a0-a29c-26cd3134a249.png)\r\nAs shown in above image, the output of `ResNet50V2(weights=None).summary()`\\\r\nthe red arrow I added points to the shortcut path, it is connected to preact_relu, which means the preactivation is done **before** branching to residual and shortcut, which is not true according to the original paper\\\r\na simple drawing representing the first block of each stage in current implementation, which is obviously not equivalent to the image from the original paper:\r\n![image](https://user-images.githubusercontent.com/49250812/129239135-4cf8449e-87c8-439a-89c1-070ccd09411f.png)\r\n\r\n\r\n\r\n", "comments": ["@seermer In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "> @seermer In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n\r\nThanks for replying, I am not sure what you mean by \"provide a code snippet to reproduce the issue\", it doesn't cause error or unexpected behavior, so you can't reproduce it, it is an implementation problem on model architecture. You can find the problem by reading the output from the below code if this is what you mean:\r\n```\r\nfrom tensorflow.keras import applications\r\napplications.ResNet50V2(weights=None).summary()\r\n```", "@seermer Thank you for the update! We see that this is ResNetv2 implementation issue which is more specific to Keras api application.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues), you will get the right help there.\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Thanks for notifying, sorry that I did not notice the repo has been split. I am closing this one and will open a new one on that repo.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51464\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51464\">No</a>\n"]}, {"number": 51462, "title": "[TF:TRT] Enable Dynamic Shape Support for ConvertResize", "body": "The Resize operation now supports full dynamic shapes. This is done by slicing the input tensor's shape, replacing the H and W dims with the corresponding Resize op scales, and concatenating the dims back to a shape tensor that can then be given as a second input to the TRT Resize layer.\r\n\r\nIn case of static shapes, the previous method remains, where the output dims are simply given as a parameter to the TRT Resize layer instead.\r\n\r\nA new use case is now also supported, where the \"size\" may now be given as a tensor input instead of constant weights. This would often happen when working with dynamic shapes, as the output size may need to be calculated on the fly through shape ops. E.g., resizing a tensor by a scale factor of 2 would require the size to be calculated dynamically in the graph based on the input tensor's shape, thus not a constant input that is known during building.\r\n\r\nThe corresponding test was also updated to now expect all 3 TRT modes to pass: kImplicitBatch, kExplicitBatch and kDynamicShape.\r\n\r\nTracker: #45481", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51462) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51462) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "I couldn't figure out a way to reply to https://github.com/tensorflow/tensorflow/pull/51462#discussion_r693990638, so I am putting my response here. I don't feel you have answered my two questions, we need to schedule a meeting to discuss this.", "Looks good to me. Thanks for working on this!\r\nWhen you address the last minor comment, please also squash the commits into one as request [here](https://github.com/tensorflow/tensorflow/pull/51462#pullrequestreview-736649531).\r\n", "> Looks good to me. Thanks for working on this!\r\n> When you address the last minor comment, please also squash the commits into one as request [here](https://github.com/tensorflow/tensorflow/pull/51462#pullrequestreview-736649531).\r\n\r\n@bixia1 : Ok great. I think I updated everything as per all the comments. Please let me know if anything else is still needed.\r\n\r\nAs for squashing, because I had to merge master into my branch to handle a conflict, squashing the commits now would require me to do a force push of the branch I think. Is that ok? Otherwise, I think github always allows the option to squash before merging once the review is complete.", "Is this something I have a way to indicate on github \"I think github always allows the option to squash before merging once the review is complete\" ? I don't actually do anything to merge, but let the \"automatic process to do the job\".\r\n\r\nIf I can't  figure out how to indicate \"squash before merging\", I need you to squash your commits. I have reviewed your new changes, you are free to do the merge and squash.", "Ok, all good now, commits have been squashed."]}, {"number": 51461, "title": "Grouped convolutions don't work in TensorFlow 2.6.0", "body": "I am trying to implement [RegNetY](https://arxiv.org/abs/2003.13678) in TensorFlow. It uses grouped convolutions. I had developed and trained the models using TF 2.5. I am aware that grouped convs aren't supported on CPUs as of yet for batch size > 1 ([source](https://github.com/tensorflow/tensorflow/issues/29005#issuecomment-886029670)).  \r\nBut as of 2.6.0, grouped convs are *not* working on either CPU or GPU. Following is the minimum reproducible code\r\n\r\n``` python\r\n!pip uninstall tensorflow keras \r\n!pip install tensorflow==2.6.0\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Conv2D( 8, 3, groups=4),\r\n    tf.keras.layers.GlobalAveragePooling2D(),\r\n    tf.keras.layers.Dense(5)\r\n])\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(0.0001),\r\n    loss= tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n    metrics=[\"accuracy\"]    \r\n)\r\nrandx = tf.random.uniform((20, 30, 30, 4))\r\nrandy = tf.random.uniform((20, 5))\r\nmodel.fit(\r\n    randx,\r\n    randy,\r\n    epochs=10,\r\n)\r\n```\r\nError trace:\r\n```\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\n<ipython-input-15-90a8900d1ed2> in <module>()\r\n     14     randx,\r\n     15     randy,\r\n---> 16     epochs=10,\r\n     17 )\r\n\r\n6 frames\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1182                 _r=1):\r\n   1183               callbacks.on_train_batch_begin(step)\r\n-> 1184               tmp_logs = self.train_function(iterator)\r\n   1185               if data_handler.should_sync:\r\n   1186                 context.async_wait()\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    883 \r\n    884       with OptionalXlaContext(self._jit_compile):\r\n--> 885         result = self._call(*args, **kwds)\r\n    886 \r\n    887       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    948         # Lifting succeeded, so variables are initialized and we can run the\r\n    949         # stateless function.\r\n--> 950         return self._stateless_fn(*args, **kwds)\r\n    951     else:\r\n    952       _, _, _, filtered_flat_args = \\\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   3038        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n   3039     return graph_function._call_flat(\r\n-> 3040         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   3041 \r\n   3042   @property\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1962       # No tape is watching; skip to running the function.\r\n   1963       return self._build_call_outputs(self._inference_function.call(\r\n-> 1964           ctx, args, cancellation_manager=cancellation_manager))\r\n   1965     forward_backward = self._select_forward_and_backward_functions(\r\n   1966         args,\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    594               inputs=args,\r\n    595               attrs=attrs,\r\n--> 596               ctx=ctx)\r\n    597         else:\r\n    598           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nUnimplementedError:  Fused conv implementation does not support grouped convolutions for now.\r\n\t [[node sequential_2/conv2d_1/BiasAdd (defined at <ipython-input-15-90a8900d1ed2>:16) ]] [Op:__inference_train_function_49676]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\nColab gist [here](https://colab.research.google.com/gist/AdityaKane2001/369fd6f2a6a737a7449bd9449f6ac1ca/groupedconvissue.ipynb).\r\n\r\n/cc @sayakpaul @MorganR", "comments": ["@sanatmpa1 \r\n\r\nShould I open this in keras-team/keras as well?", "@AdityaKane2001,\r\n\r\nYes it seems like an issue with keras component. Can you please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues),To know more see;[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)", "@sanatmpa1 \r\nYeah, I'm doing that as we speak. Thanks.\r\n\r\nEdit:\r\nOpened [#15162](https://github.com/keras-team/keras/issues/15162) in keras-team/keras. ", "@AdityaKane2001,\r\n\r\nCan you confirm if we close the issue here? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51461\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51461\">No</a>\n"]}, {"number": 51460, "title": "Add tensorflow-io-gcs-filesystem dependency", "body": "This PR is part of the effort to migrate to modular file systems.\r\nThis PR add the dependency of tensorflow-io-gcs-filesystem package\r\nwhile at the same time, only enable using it with\r\n`TF_USE_MODULAR_FILESYSTEM=1`.\r\n\r\nThis allows end user to not getting impacted by default.\r\n\r\nThe switch off will happen after a period of transition time.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["cc @kvignesh1420  @burgerkingeater  @terrytangyuan  FYI"]}, {"number": 51459, "title": "'tf.Roll' op is neither a custom op nor a flex op", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n- TensorFlow installed from (source or binary): conda install\r\n- TensorFlow version (or github SHA if from source): 2.4.0\r\n\r\nHello,\r\n\r\nI am facing similr issue with tf.Roll function. Although I see the exhaustive list of tf.ops support by tf.Lite includes the Roll operation. My code looks like this for tfLite:\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\ntf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nException: /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/signal/fft_ops.py:459:0: error: 'tf.Roll' op is neither a custom op nor a flex op\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from\r\n/global/cscratch1/sd/jmunshi/4DCrystal/CNNTrainingNetwork/Crystal4d/utils/conv_utils.py:26:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/core.py:917:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:560:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:424:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/saving_utils.py:135:0: note: called from\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:634:0: note: called from\r\n:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\ntf.Roll {device = \"\"}\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["tf.Roll op is included as the Select TF op in the recent version. Please use the recent TF version, for example, TF 2.5."]}, {"number": 51458, "title": "high vram usage when setting architecture on rtx3090? ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10\r\n- TensorFlow installed from (source or binary): conda\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: CUDA11.2/cuDNN8.2.1 for rtx3090, CUDA10.1/cuDNN7.6.5 for rtx2080ti\r\n- GPU model and memory: rtx3090 24GB, rtx2080ti 11GB\r\n\r\n\r\n**Describe the current behavior**\r\nUse the same code below in a compatible environment,\r\nthe code was executed successfully on rtx2080ti but failed on rtx3090.\r\nAnd I check the code step by step,\r\nand this line will make the rtx3090 vram usage full.\r\n`c1 = Conv2D(48, (3, 3), activation=None, kernel_initializer='he_normal', padding='same')(s)`\r\n\r\nwhy rtx3090 using all vram when setting the architecture?\r\n\r\n**Standalone code to reproduce the issue**\r\nUse the following code:\r\n```python\r\nimport os\r\nimport sys\r\nimport random\r\nimport warnings\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport cv2\r\n\r\nimport matplotlib.pyplot as plt\r\nfrom PIL import Image\r\nfrom tqdm import tqdm\r\nfrom itertools import chain\r\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\r\nfrom skimage.transform import resize\r\nfrom skimage.morphology import label\r\nfrom PIL import ImageFile\r\nimport SimpleITK as sitk\r\n\r\nfrom tensorflow.keras.models import Model, load_model\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.layers import Dropout, Lambda,Activation\r\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\r\nfrom tensorflow.keras.layers import MaxPooling2D\r\nfrom tensorflow.keras.layers import concatenate\r\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\nfrom tensorflow.keras import backend as K\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.optimizers import RMSprop,Adam,SGD,Adadelta\r\n\r\n\r\nIMG_WIDTH = 512\r\nIMG_HEIGHT = 512\r\nIMG_CHANNELS = 3\r\n\r\n\r\nDATA_PATH = 'G:/DenseUnet/input/test/'\r\nnp.random.seed = 42\r\n\r\nsub_dir = 'image/'\r\nimage_ids =  next(os.walk(DATA_PATH + sub_dir))[2]\r\n\r\nX = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH,3))\r\nY = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH,1))\r\nmask = np.zeros((IMG_WIDTH, IMG_HEIGHT),dtype=np.bool)\r\nfor n, id_ in tqdm(enumerate(image_ids), total=len(image_ids)):\r\n    path = DATA_PATH +sub_dir + id_\r\n    img = sitk.ReadImage(path)\r\n    img = sitk.GetArrayFromImage(img)\r\n    #img = cv2.resize(img, (256, 256))\r\n    X[n] = img\r\n    \r\n    mask = sitk.ReadImage(DATA_PATH + 'label/'+id_[:-8]+'gt.tiff')\r\n    mask = sitk.GetArrayFromImage(mask)\r\n    mask = np.expand_dims(mask, axis=2)\r\n    Y[n] = mask\r\n\r\nprint('load files finished')\r\ngc.collect()\r\nX = (X-np.min(X))/(np.max(X)-np.min(X))\r\nx_train = X\r\nY=Y.astype(bool)\r\ny_train = Y\r\n\r\ndef mean_iou(y_true, y_pred):\r\n    prec = []\r\n    for t in np.arange(0.5, 1.0, 0.05):\r\n        y_pred_ = tf.to_int32(y_pred > t)\r\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 4)\r\n        tf.compat.v1.keras.backend.get_session().run(tf.local_variables_initializer())\r\n        with tf.control_dependencies([up_opt]):\r\n            score = tf.identity(score)\r\n        prec.append(score)\r\n    return tf.keras.backend.mean(tf.keras.backend.stack(prec), axis=0)\r\n\r\n\r\n# COMPETITION METRIC\r\ndef dice_coeff(y_true, y_pred, smooth=1):\r\n    y_true_f = K.flatten(y_true)\r\n    y_pred_f = K.flatten(y_pred)\r\n    intersection = K.sum(y_true_f * y_pred_f)\r\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\r\n\r\n\r\n#%% (Architecture)\r\n\r\ndef dense_block(inputs,growth_rate,n_layers):\r\n    total_features=[]\r\n    ini = inputs\r\n    for i in range(n_layers):\r\n        x = BatchNormalization()(ini)\r\n        x = Activation('relu')(x)\r\n        x = Conv2D(growth_rate, (3, 3),activation=None, kernel_initializer='he_normal', padding='same')(x)\r\n        x = Dropout(0.2)(x)\r\n        total_features.append(x)\r\n        ini = concatenate([x,ini],axis=3)\r\n        \r\n        dense_out = total_features[0]\r\n        for j in range(len(total_features)-1):\r\n            dense_out = concatenate([dense_out,total_features[j+1]],axis=3)\r\n        \r\n    return dense_out,ini\r\n       \r\ndef trans_down(inputs,filters):\r\n\r\n    x = BatchNormalization()(inputs)\r\n    x = Activation('relu')(x)\r\n    \r\n    x = Conv2D(filters, (1, 1), activation=None, kernel_initializer='he_normal', padding='same')(x)\r\n    x = Dropout(0.2)(x)\r\n    x = MaxPooling2D((2, 2))(x)\r\n    \r\n    return x\r\n\r\ndef trans_up(inputs,filters):\r\n    x = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding='same')(inputs)\r\n    return x\r\n\r\ninputs = Input((IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS))\r\ns = Lambda(lambda x: x / 1) (inputs)\r\nc1 = Conv2D(48, (3, 3), activation=None, kernel_initializer='he_normal', padding='same')(s)\r\nc1 = BatchNormalization()(c1)\r\nc1 = Activation('relu')(c1)\r\n\r\nb1,_ = dense_block(c1,16,4)\r\ncon1 = concatenate([b1,c1],axis=3)\r\nd1 = trans_down(con1,112)\r\n\r\nb2,_ = dense_block(d1,16,5)\r\ncon2 = concatenate([b2,d1],axis=3)\r\nd2 = trans_down(con2,192)\r\n\r\nb3,_ = dense_block(d2,16,7)\r\ncon3 = concatenate([b3,d2],axis=3)\r\nd3 = trans_down(con3,304)\r\n\r\nb4,_ = dense_block(d3,16,10)\r\ncon4 = concatenate([b4,d3],axis=3)\r\nd4 = trans_down(con4,464)\r\n\r\nb5,_ = dense_block(d4,16,12)\r\ncon5 = concatenate([b5,d4],axis=3)\r\nd5 = trans_down(con5,656)\r\n\r\nb6,block_to_up6 = dense_block(d5,16,15)\r\n\r\nu7 = trans_up(block_to_up6,240)\r\ncon7 = concatenate([u7,con5],axis=3)\r\nb7,block_to_up7 = dense_block(con7,16,12)\r\n\r\nu8 = trans_up(block_to_up7,192)\r\ncon8 = concatenate([u8,con4],axis=3)\r\nb8,block_to_up8 = dense_block(con8,16,10)\r\n\r\nu9 = trans_up(block_to_up8,160)\r\ncon9 = concatenate([u9,con3],axis=3)\r\nb9,block_to_up9 = dense_block(con9,16,7)\r\n\r\n\r\nu10 = trans_up(block_to_up9,112)\r\ncon10 = concatenate([u10,con2],axis=3)\r\nb10,block_to_up10 = dense_block(con10,16,5)\r\n\r\n\r\nu11 = trans_up(block_to_up10,80)\r\ncon11 = concatenate([u11,con1],axis=3)\r\nb11,block_to_up11 = dense_block(con11,16,4)\r\noutputs = Conv2D(1, (1, 1), activation='sigmoid')(block_to_up11)\r\n\r\nmodel = Model(inputs=[inputs], outputs=[outputs],name='DenseUNet')\r\nmodel.compile(optimizer=RMSprop(1e-4),loss='binary_crossentropy', metrics=[dice_coeff])\r\nmodel.summary()\r\n\r\nfilepath=\"G:/DenseUnet/model/20210812/0812-{epoch:02d}-{val_dice_coeff:.4f}.h5\" \r\nearlystopper = EarlyStopping(patience=350, verbose=1)\r\ncheckpointer = ModelCheckpoint(filepath,monitor='val_loss', verbose=1, save_best_only=False)\r\nresults = model.fit(x_train, y_train, validation_split=0.2, batch_size=3, epochs=100, \r\n                    callbacks=[earlystopper,checkpointer])\r\n\r\nimport pickle\r\nwith open('G:/DenseUnet/0810_100e.txt', 'wb') as file_txt:\r\n    pickle.dump(results.history, file_txt)\r\n```\r\n", "comments": ["@m0705327 ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51458\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51458\">No</a>\n"]}, {"number": 51456, "title": "Default values of mean and standard deviation for TFLite RNN Models.", "body": "Using TensorFlow version 2.4.1 ,\r\n\r\nDefault values for Mean and standard deviation for classification models is Mean - 127.5 and Std Deviation 127.5 .\r\n\r\nReference - https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/lite/examples/label_image/label_image.h \r\n\r\n![Capturedvdvrvrv](https://user-images.githubusercontent.com/47776253/129203242-fee6ea68-4a85-4a07-967a-7910075694c9.JPG)\r\n\r\nWhat are the default values for RNN models?\r\n\r\nIs Mean and Standard deviation the same?\r\n\r\n(or)\r\n\r\nIs Mean - 0 and Standard deviation 1 by default for RNN?", "comments": ["if you are using float model, you don't need to worry about mean and std dev", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51456\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51456\">No</a>\n"]}, {"number": 51455, "title": "Extend cmake-based build of tf lite to support metal delegates and related libraries for iOs target", "body": "- **tensorflow/lite/CMakeLists.txt**  - add new option **_TFLITE_ENABLE_METAL_** to enable compilation of all libraries required for metal delegate\r\n- **tensorflow/lite/tools/cmake/modules/ruy/CMakeLists.txt** - in case option above will be enabled we will end up with project with 3 different languages - C, CPP and OBJCPP, in such case CMake not smart enough to handle files with **_cc_** extensions - so in case of ruy library we have to mark source files to be treated as CPP explicitly and filter out gtest-based file.   \r\nNOTE 1: it will lead to number of:   \r\n`clang: warning: treating 'c-header' input as 'c++-header' when in C++ mode, this behavior is deprecated [-Wdeprecated]`. \r\n warning during compilations as source list wihin ruy's srcs list that have headers included\r\nNOTE 2: I have to adjust regex to exclude test.h, otherwise master version failed for me with:   \r\n`In file included from /tensorflow_src/tensorflow/lite/qqq_build/ruy/ruy/test.h:44:\r\n/tensorflow_src/tensorflow/lite/qqq_build/ruy/ruy/gtest_wrapper.h:23:10: fatal error: 'gtest/gtest.h' file not found\r\n#include \"gtest/gtest.h\"  // IWYU pragma: export\r\n`\r\n- **tensorflow/lite/delegates/gpu/CMakeLists.txt** - to generate build scripts for **_libdelegate_metal.a_**\r\n- **_tensorflow/lite/delegates/gpu/metal/CMakeLists.txt_** - to generate build scripts for following libraries, that would be necessary to link with **_libdelegate_metal.a_** in order to use metal delegate:\r\n  - libbuffer.a\r\n  - libbuffer_convert.a\r\n  - libcommon.a\r\n  - libcompute_task.a\r\n  - libinference_context.a\r\n  - liblinear_storage.a\r\n  - libmetal_arguments.a\r\n  - libmetal_device.a\r\n  - libmetal_spatial_tensor.a\r\n  - libtexture2d.a\r\n\r\nNote: I am not sure why some *.mm files we renamed to cc in this [pr](https://github.com/tensorflow/tensorflow/commit/b83ffd2602edef1dbd2bf1722ecc7e423f3d60be#diff-4ad734053f51aefe42a2bc46e23cd8a959f85b609ef25c7f66b20d2d5dc8e635), so I have to mark them as **objcxx** explicitly to have proper compile flags.", "comments": [" Thank you for the PR. Though the changes look good, it looks like TFLite uses several custom macros defined in `tensorflow/lite/CMakeLists.txt` instead of conventional CMake methods/macros (eg: using `populate_tflite_source_vars` to build the TFLite library). \r\n\r\nWill defer the review/approval to @terryheo who initially added cmake support to TFLite.", "@kruglov-dmitry  Can you please check @terryheo's comments and keep us posted ? Thanks!\r\n", "I am sorry for delay with update. I've made necessary adjustments.\r\n\r\nFew notes to explain changes:\r\n\r\nUsually, it is [recommended](https://cmake.org/examples/) to [structure](https://cliutils.gitlab.io/modern-cmake/chapters/basics/structure.html ) cmake based project by having CMakefile per folder. \r\n\r\nAfter I have migrated changes into root CMakefile and it lead to following:\r\n- There are number of small libraries - for each of it required to specify include path\r\n(as opposed to situation when CMakefiles are spread throughout folder structure, when higher level includes will be forwarded into subfolder's includes) - hence include path have to be specified per target\r\n- `populate_tflite_source_vars` doesn't look handy for cases of libraries that are compiled from single source file. If it required - I can change it, but I am not sure that I understand clear benefits of it \r\n\r\n**Side note:** for libraries usage, I didn't have situations where I need only one exact libraries from gpu/metal, so find it more convenient in our project to bundle everything into single library - it will allow to simplify CMakefile, if it make sense - I can add it here as well.", "@terryheo  Can you please review this PR ? Thanks!"]}, {"number": 51452, "title": "Only preload kernels from running TF instance", "body": "Previously, kernels from every installed instance of TensorFlow would be\r\npreloaded, causing potential ABI conflicts.\r\n\r\nFixes #51451", "comments": []}, {"number": 51451, "title": "Multiple versions of TensorFlow co-installed potentially cause ABI mismatch", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): both\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nWhen multiple tensorflow instances are installed in different parts of your python path, TensorFlow will attempt to load kernel libraries from all of them, potentially resulting in an ABI mismatch.\r\n\r\n```\r\n$ python3 -c \"import tensorflow\"\r\nNo protocol specified\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 438, in <module>\r\n    _ll.load_library(_main_dir)\r\n  File \"/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 154, in load_library\r\n    py_tf.TF_LoadLibrary(lib)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /usr/lib/python3/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringB5cxx11ERKNS_15OpKernelContextEb\r\n\r\n```\r\n\r\nObserve above, the TensorFlow instance in `~/.local/lib/python3/` attempting to load a shared library from `/usr/lib/python3/`. Because of different compilation options, the library from the system-wide install is expecting symbols that do not exist in the pip install.\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorFlow should only load kernels from its own install.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing): modify kernel preloading to only use its own install\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nCompile TensorFlow from source and install system-wide.\r\nInstall TensorFlow from pip with `pip install --user tensorflow`\r\nThen run `python -c \"import tensorflow\"`\r\n\r\n**Other info**\r\n\r\nThis is a continuation of #42978", "comments": ["@sclarkson The issue will move to closed status once the PR is merged.Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51451\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51451\">No</a>\n"]}, {"number": 51450, "title": "Fix protobuf errors when using system protobuf", "body": "When tensorflow and python protobuf use the same instance of\r\nlibprotobuf, pywrap_tensorflow must be imported before anything\r\nelse that would import protobuf definitions.\r\n\r\nFixes #50545. See that thread for a Dockerfile with a reproduction\r\nof the error.", "comments": ["Assign to Mihai from Infra team."]}, {"number": 51449, "title": "dtype of RNN cell's state is changed to tf.float32 during reset_states", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: both win10 and CentOS Linux\r\n-   **TensorFlow installed from (source or binary)**: pip\r\n-   **TensorFlow version (use command below)**: 2.6.0\r\n-   **Python version**: 3.8\r\n-   **Bazel version (if compiling from source)**:\r\n-   **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nI have implemented a recurrent cell which is to be wrapped within a `tf.keras.layers.RNN.` The cell has a state whose data type is not `tf.float32` but `tf.complex64`. However, each time when `layer.reset_states()` is invoked, the data type of the state is changed to `tf.float32`. \r\n\r\nI assume, a reason for this issue is line 933, 934 in keras/layers/recurrent.py\r\n```\r\n      flat_states_variables = tf.nest.map_structure(\r\n          backend.variable, flat_init_state_values)\r\n```\r\nHere, the initialized state values are stored in `flat_init_state_values` and `backend.variable` is called on each of the states. However, no `dtype` argument is passed to `backend.variable`. As a consequence it defaults to `tf.float32` for all states. Then a value error is thrown during the initial symbolic call. See attached stack trace. \r\n\r\nI would recommend the following patch, which solves the issue for me\r\n```\r\n      flat_states_variables = tf.nest.map_structure(\r\n    lambda var: backend.variable(var, var.dtype), flat_init_state_values)\r\n```\r\n\r\n### Source code / logs\r\nCurrently, the example fails at the construction of the RNN layer.\r\n```\r\nimport tensorflow as tf\r\n\r\nclass RecurrentCell(tf.keras.layers.Layer):\r\n    def __init__(self, state_size):\r\n        super(RecurrentCell, self).__init__()\r\n        self.state_size = state_size\r\n\r\n    def build(self, input_shape):\r\n        super(RecurrentCell, self).build(input_shape)\r\n\r\n    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\r\n        # explicit initialization with tf.complex64\r\n        return tf.zeros((self.state_size, ), dtype=tf.complex64)\r\n\r\n    @tf.function\r\n    def call(self, inputs, states):\r\n        # toy example\r\n        x = inputs\r\n        xfd = tf.signal.rfft(x)[..., :self.state_size]\r\n        yfd = tf.multiply(xfd, states)\r\n        return tf.signal.irfft(yfd), states\r\n\r\n\r\nrecCell = RecurrentCell(state_size=5)\r\n\r\ninp = tf.keras.Input(shape=(None, 8),\r\n                     batch_size=32)\r\nout = tf.keras.layers.RNN(recCell,\r\n                          return_sequences=True,\r\n                          stateful=True,\r\n                          return_state=False)(inp)\r\nmodel = tf.keras.Model(inputs=[inp], outputs=[out])\r\n\r\ny = model.predict(tf.random.normal((32, 16, 8)))\r\n```\r\n\r\nStack trace:\r\n[stacktrace.txt](https://github.com/tensorflow/tensorflow/files/6975576/stacktrace.txt)\r\n", "comments": ["@TillHa ,\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue.Thanks!", "Hello @tilakrayal, From the templates I see that keras related issues belong to the keras repository. Hence I [raised the issue there](https://github.com/keras-team/keras/issues/15164).\r\nThanks a lot!  "]}, {"number": 51448, "title": "saved_model  bug", "body": "tf version 2.3.2\r\n\r\nwhen  train the model,some features is multi hot,use the split func like this:\r\n```\r\n        def split(x):\r\n            x['seq_grade_clicks'] = tf.strings.split(x['seq_grade_clicks'], sep=\":\").to_sparse()\r\n            x['seq_subject_clicks'] = tf.strings.split(x['seq_subject_clicks'], sep=\":\").to_sparse()\r\n            x['seq_course_clicks'] = tf.strings.split(x['seq_course_clicks'], sep=\":\").to_sparse()\r\n            return x\r\n```\r\n\r\nbut saved model,and load model\r\n`model = tf.keras.models.load_model(saved_model_dir)`\r\nthe errors is\r\n![image](https://user-images.githubusercontent.com/7404433/129173015-dc7a033a-c145-4801-a334-27e6fb88a775.png)\r\n\r\nalthough I specified the name of to_sparse(name=\"features\"),it also report the above error,\r\n\r\nwhen use `tf.saved_model.load(saved_model_dir)` is ok,but lose the feature name like this:\r\n\r\n![image](https://user-images.githubusercontent.com/7404433/129173426-8f7b857c-4c0e-4688-b643-73811726cf41.png)\r\n\r\n\r\nwhen use the tf serving ,serving the model ,it also can not konwn the feature name,\r\n\r\nwhen  train the model,some features is multi hot,use the split func like this:\r\n```\r\n        def split(x):\r\n            x['seq_grade_clicks'] = tf.strings.split(x['seq_grade_clicks'], sep=\":\").to_tensor()\r\n            x['seq_subject_clicks'] = tf.strings.split(x['seq_subject_clicks'], sep=\":\").to_tensor()\r\n            x['seq_course_clicks'] = tf.strings.split(x['seq_course_clicks'], sep=\":\").to_tensor()\r\n            return x\r\n```\r\n![image](https://user-images.githubusercontent.com/7404433/129179798-70a5974d-7025-4d02-9418-c76f3c344b85.png)\r\n\r\neverything is ok ,but when use the tf serving ,serving the model or predict, it can not batch infer ,because some features is multi hot and is variable length, but the tensor is fixed length\r\n\r\n", "comments": ["@gao8954,\r\n\r\nCan you kindly provide standalone code with sample data, for us to reproduce the issue and expedite the trouble-shooting process? Thanks!", "> @gao8954,\r\n> \r\n> Can you kindly provide standalone code with sample data, for us to reproduce the issue and expedite the trouble-shooting process? Thanks!\r\n\r\nmy code is a bit messy, but the issue is almost about use the feature_column embedding\r\n\r\n```\r\n        combiner = feature_conf.get(\"combiner\", \"mean\")\r\n        id_feature = tf.feature_column.categorical_column_with_hash_bucket(key=name,\r\n                                                                           hash_bucket_size=feature_conf[\r\n                                                                               'hash_bucket_size'], dtype=dtype)\r\n        emb_col = tf.feature_column.embedding_column(id_feature, dimension=feature_conf['embedding_dimension'],\r\n                                                     combiner=combiner)\r\n```\r\n\r\nthe train data  is a csv file,and some feature is a sequence\uff0cso i organize data like this:\r\n`4:5:6,1:2:23:59`\r\n\r\nwhen train the model,the input is like this:\r\n\r\n```\r\n    def input_fn():\r\n        df_train = pd.read_csv(FLAGS.record_train, header=0)\r\n        df_test = pd.read_csv(FLAGS.record_test, header=0)\r\n        y_train = df_train.pop('is_trans')\r\n        y_test = df_test.pop('is_trans')\r\n\r\n        train_dataset = tf.data.Dataset.from_tensor_slices((dict(df_train), y_train))\r\n        test_dataset = tf.data.Dataset.from_tensor_slices((dict(df_test), y_test))\r\n\r\n        def split(x):\r\n            x['seq_grade_clicks'] = tf.strings.split(x['seq_grade_clicks'], sep=\":\").to_sparse()\r\n            x['seq_subject_clicks'] = tf.strings.split(x['seq_subject_clicks'], sep=\":\").to_sparse()\r\n            x['seq_course_clicks'] = tf.strings.split(x['seq_course_clicks'], sep=\":\").to_sparse()\r\n            return x\r\n\r\n        train_dataset = train_dataset.shuffle(buffer_size=2048).batch(2048).prefetch(buffer_size=2048 * 2)\r\n        train_dataset = train_dataset.map(lambda x, y: (split(x), y))\r\n        test_dataset = test_dataset.batch(2048)\r\n        test_dataset = test_dataset.map(lambda x, y: (split(x), y))\r\n        return train_dataset, test_dataset\r\n```\r\n\r\nbecause have seq features,and did not find a better way,so use the dataset map func to transform the data, tf.strings.split() func  return  a type of   tf.RaggedTensor ,it can not fit to the model,export the error of RaggedTensorSpec can not conver to tensor, so call the to_sparse()  then all the problems can be reproduced above\r\n\r\n\r\n", "@gao8954,\r\n\r\nAs I can see you are using `TF 2.3.2`, Could you try updating to latest stable version `TF 2.5` and let us know if this issue still persists? Thanks!", "> @gao8954,\r\n> \r\n> As I can see you are using `TF 2.3.2`, Could you try updating to latest stable version `TF 2.5` and let us know if this issue still persists? Thanks!\r\n\r\nupdate to TF 2.5, this issue still persists", "@gao8954,\r\n\r\nThanks for the update, In this case, we may need the reproducible code to analyze the issue properly. Can you share the standalone code or colab gist to expedite the troubleshooting process? ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51448\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51448\">No</a>\n"]}, {"number": 51447, "title": "Error initializing parameters when inheriting from tf.keras.model\uff01\uff01\uff01\uff01", "body": "env: tf2.2,  linux\r\n\r\n**If there are two input parameters inherited from the tf.keras.model class and one of them is of bool type, it will directly report an error like this:**\r\n![1628757059(1)](https://user-images.githubusercontent.com/34124260/129164925-5ca64255-cd04-45fe-978d-1cf8f4d42a27.png)\r\n\r\n**However, the interesting thing is that if there are three input parameters and the third parameter has no effect, it will be correct\uff0clike this\uff1a**\r\n![1628757177(1)](https://user-images.githubusercontent.com/34124260/129165214-ffe000af-e70a-46bd-bb78-2f11694680da.png)\r\n![1628757205(1)](https://user-images.githubusercontent.com/34124260/129165314-a2ff8e99-45a0-4634-bb44-5eb6c7efb33b.png)\r\n**If it has only one initial input, there will be no error if it is of bool type**\r\n\r\nThis is an interesting question. I don't know whether there is a problem with my environment or whether there is a small bug in the code", "comments": ["@1148330040 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Could you please try on latest stable version of TF 2.5  and let us know if this is still an issue.Thanks!", "this is my complete code, my tf is tf2.2, tf2.5 need wait a moment\uff0cthanks\uff01\r\n`\r\nclass ModelBertCrf4Sub(tf.keras.Model):\r\n    def __init__(self, output_dim, use_crf):\r\n        super(ModelBertCrf4Sub, self).__init__(output_dim, use_crf)\r\n        self.use_crf = use_crf\r\n        self.bert = TFBertModel.from_pretrained('hfl/chinese-bert-wwm-ext')\r\n        self.dropout = tf.keras.layers.Dropout(0.3)\r\n        self.dense = tf.keras.layers.Dense(output_dim)\r\n        self.other_params = tf.Variable(tf.random.uniform(shape=(output_dim, output_dim)))\r\n\r\n    @tf.function\r\n    def call(self, batch_data):\r\n        ids, masks, tokens, subject_target = batch_data\r\n        input_seq_len = tf.cast(tf.reduce_sum(masks, axis=1), dtype=tf.int32)\r\n        hidden = self.bert(ids, masks, tokens)[0]\r\n        dropout_inputs = self.dropout(hidden, 1)\r\n        sub_predict = self.dense(dropout_inputs)\r\n        log_likelihood = None\r\n        if self.use_crf:\r\n            log_likelihood, self.other_params = tfa.text.crf.crf_log_likelihood(sub_predict,\r\n                                                                                subject_target,\r\n                                                                                input_seq_len,\r\n                                                                                self.other_params)\r\n            sub_predict, _ = tfa.text.crf_decode(sub_predict, self.other_params , input_seq_len)\r\n\r\n        return sub_predict, hidden, log_likelihood\r\n`", "> @1148330040 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Could you please try on latest stable version of TF 2.5 and let us know if this is still an issue.Thanks!\r\n\r\nIn tf2.5 and tf2.4 environments\uff1a\r\nSince it is not necessary to declare the two input parameters (use_crf and input_dim) in super(ModelBertCrf4Sub, self).__init__(), so the above error does not occur\uff1a\r\n\r\n![1628761526(1)](https://user-images.githubusercontent.com/34124260/129176044-bd660108-416a-45f3-a75f-bf6ec9c30ac1.png)\r\n", "@1148330040 Thank you for the update ! Could you please let us know if this issue is resolved for you ? Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51447\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51447\">No</a>\n"]}, {"number": 51446, "title": "AttributeError: 'Operation' object has no attribute '_c_op'", "body": "tensorflow2.1\r\nFile \"run.py\", line 118, in <module>\r\n    imgs_mask_test = model.predict(imagestest, verbose=1)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1013, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 498, in predict\r\n    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 475, in _model_iteration\r\n    total_epochs=1)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 615, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 497, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 85, in distributed_function\r\n    per_replica_function, args=args)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 763, in experimental_run_v2\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1819, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 2164, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 292, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 212, in _predict_on_batch\r\n    result = predict_on_batch(model, x)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 556, in predict_on_batch\r\n    return predict_on_batch_fn(inputs)  # pylint: disable=not-callable\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 778, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 717, in call\r\n    convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 891, in _run_internal_graph\r\n    output_tensors = layer(computed_tensors, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 778, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 209, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1135, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 640, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 616, in _with_space_to_batch_call\r\n    block_shape=self.dilation_rate)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3303, in required_space_to_batch_paddings\r\n    const_block_shape = tensor_util.constant_value(block_shape)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 827, in constant_value\r\n    ret = _ConstantValue(tensor, partial)\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 673, in _ConstantValue\r\n    if tensor.op.type == \"Const\":\r\n  File \"/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 2220, in type\r\n    return c_api.TF_OperationOpType(self._c_op)\r\nAttributeError: 'Operation' object has no attribute '_c_op'\r\nI got this error, how to solve it?thank you.", "comments": ["@888yyh ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.Also please try to execute the code using stable tf v2.5 and let us know if you are facing same issue.Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51446\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51446\">No</a>\n", "@tilakrayal @888yyh Has there been resolution to this issue?\r\nI am getting this error with TF2.1.0 randomly. With 2.7.0 this never happens.\r\nIn order to be compatible with other things, we are not yet ready to do an upgrade to 2.7.0"]}, {"number": 51445, "title": "DLPack Tensor is only supported in TF Eager Mode now right? ", "body": null, "comments": ["@eedalong,\r\n\r\nCan you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) for us to expedite the trouble-shooting process? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51444, "title": "Incorrect metrics for ragged tensor as output", "body": "**System information**\r\n- OS Platform: Windows 10\r\n- TensorFlow installed from pip, version 2.5.0\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\nThe metrics for the ragged tensors are calculating incorrectly. \r\n\r\n**Standalone code to reproduce the issue**\r\nThe model:\r\n\r\n```\r\nclass dummy(tf.keras.Model):\r\n    def __init__(self):\r\n        super(dummy, self).__init__()\r\n\r\n    def call(self, inputs):\r\n        lens = tf.map_fn(lambda x: len(x), inputs, fn_output_signature=tf.int32, name='get_lengths')\r\n        tensored_input = inputs.to_tensor(0, shape=[None, 10])\r\n        x = Lambda(lambda x: tf.cast(x, dtype=tf.float32))(tensored_input)\r\n        outputs = tf.RaggedTensor.from_tensor(x, lengths=lens)\r\n        return outputs\r\n```\r\n\r\nRunning:\r\n```\r\nx_dataset = tf.data.Dataset.from_tensor_slices( tf.ragged.constant([[0,0,0,0,0],[0],[0,0,0],[0,0,0,0]]))\r\ny_dataset = tf.data.Dataset.from_tensor_slices( tf.ragged.constant([[1,1,1,1,1],[1],[1,1,1],[1,1,1,1]]))\r\ntensor_dataset = tf.data.Dataset.zip((x_dataset, y_dataset))\r\n# Create batches\r\nbatched_ds = tensor_dataset.batch(2, drop_remainder=True)\r\n\r\nmodel = dummy()\r\nmodel.compile(loss='binary_crossentropy',metrics=['accuracy'])\r\nhistory = model.fit(batched_ds,epochs=2)\r\n```\r\nResult (history.history) - 100% accuracy despite clear dismatches.\r\n\r\n`\r\n{'loss': [15.424947738647461, 15.424947738647461], 'accuracy': [1.0, 1.0]}\r\n`\r\n", "comments": ["@HannaLochOlszewska In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Lambda\r\n\r\nclass dummy(tf.keras.Model):\r\n    def __init__(self):\r\n        super(dummy, self).__init__()\r\n\r\n    def call(self, inputs):\r\n        lens = tf.map_fn(lambda x: len(x), inputs, fn_output_signature=tf.int32, name='get_lengths')\r\n        tensored_input = inputs.to_tensor(0, shape=[None, 10])\r\n        x = Lambda(lambda x: tf.cast(x, dtype=tf.float32))(tensored_input)\r\n        outputs = tf.RaggedTensor.from_tensor(x, lengths=lens)\r\n        return outputs\r\n\r\nx_dataset = tf.data.Dataset.from_tensor_slices( tf.ragged.constant([[0,0,0,0,0],[0],[0,0,0],[0,0,0,0]]))\r\ny_dataset = tf.data.Dataset.from_tensor_slices( tf.ragged.constant([[1,1,1,1,1],[1],[1,1,1],[1,1,1,1]]))\r\ntensor_dataset = tf.data.Dataset.zip((x_dataset, y_dataset))\r\n# Create batches\r\nbatched_ds = tensor_dataset.batch(2, drop_remainder=True)\r\n\r\nmodel = dummy()\r\nmodel.compile(loss='binary_crossentropy',metrics=['accuracy'])\r\nhistory = model.fit(batched_ds,epochs=2)\r\n# Accuracy should be 0 here obviously and it's not\r\nprint(history.history)\r\n```", "@HannaLochOlszewska Could you please take a look on the[ link1](https://www.tensorflow.org/guide/ragged_tensor) , [link2](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor?version=nightly) and let us know if it helps ? Thank you! ", "Hi @sushreebarsa, the links didn't help much. But I managed to find out that \r\n`model.compile(loss='binary_crossentropy',metrics=['accuracy'])` yields incorrect accuracy results, while\r\n`model.compile(loss='binary_crossentropy',metrics=[tf.keras.metrics.Accuracy()])` seems to work fine.", "@HannaLochOlszewska Thank you for the update! I also tried to reproduce it in colab using TF v2.5, please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/2200d5d521619776ea308a12eb82b558/51444.ipynb) and confirm the same .Kindly move this issue to closed status if it is resolved for you ? Thanks!", "Yes, indeed, it's resolved - thanks a lot for your assistance!\r\n\r\nFor the future reference - the problem was only in the accuracy metric that was passed, not ragged tensors at all, my bad.\r\nAccording to tf.keras.Model.compile() documentation:\r\n>  When you pass the strings 'accuracy' or 'acc', we convert this to one of tf.keras.metrics.BinaryAccuracy, tf.keras.metrics.CategoricalAccuracy, tf.keras.metrics.SparseCategoricalAccuracy based on the loss function used and the model output shape. We do a similar conversion for the strings 'crossentropy' and 'ce' as well.", "@HannaLochOlszewska Glad that it worked for you .Could you please close this issue as it is resolved ?Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51444\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51444\">No</a>\n"]}, {"number": 51443, "title": "n-api supports automatic downgrade instead of hard-coded", "body": "### background\r\nI used @tensorflow/tfjs-node to build a coding service, but the deployment failed due to the inconsistency of the node version during build and runtime.\r\n\r\nUncontrollable node version during build and runtime\r\n\r\n### for example\uff1a\r\n\r\nbuild\uff1anode v12.19.1 corresponds to N-API 7\r\nruntime \uff1anode v12.22.3 corresponds to N-API 8\r\n\r\n### result\uff1a\r\n\"The Node.js native addon module (tfjs_binding.node) can not be found at path: /code/node_modules/_@tensorflow_tfjs-node@3.8.0@@tensorflow/tfjs-node/lib/napi-v8/tfjs_binding.node.\"\r\n\r\n### feature Request\uff1a\r\n\r\nThe higher version of n-api will automatically be compatible with the lower version, but [here](https://github.com/tensorflow/tfjs/blob/e36545270e8176aa14d03e82ccf2baf6e9693f69/tfjs-node/package.json#L84) is hard to write \r\n\r\n\r\n\r\n\r\n", "comments": ["@yangshengdong ,\r\nThis issue is more suitable for TensorFlow JS repo. Please post it on Tensorflow/tfjs repo from [here](https://github.com/tensorflow/tfjs/issues). Thanks!", "Have moved [here](https://github.com/tensorflow/tfjs/issues/5484)"]}, {"number": 51441, "title": "dlopen/dlclose a so file which contain tensorflow static library cause memory leak", "body": "In our scenario, there is only one process to serve the request, and the process will be closed only when an exception occurs. Each model inference algorithm is complied into a so file and loaded into this process.  Multiple model inference algorithms will be loaded in this process. Each so file contain a tensorflow static library.\r\n\r\nIn the service, the so file of different model inference algorithms (model _ 1.so...) will often be loaded and closed through dlopen and dlclose. Because some static variables in tensorflow are created through the \u201cnew\u201d method , as shown below. When closing the \u201cso\u201d with dlclose\uff0cthese static variables will not be released\uff0c which will cause memory leaks.\r\n```\r\n    typedef std::unordered_map<string, SessionFactory*> SessionFactories;     \r\n    SessionFactories* session_factories() {\r\n        static SessionFactories* factories = new SessionFactories;\r\n        return factories;\r\n    }\r\n```\r\n\r\n```\r\n    DirectSession* session = new DirectSession(options, new StaticDeviceMgr(std::move(devices)), this);\r\n    {\r\n        mutex_lock l(sessions_lock_);\r\n        sessions_.push_back(session);\r\n    }\r\n    *out_session = session;\r\n    return Status::OK();\r\n```\r\n\r\nWhat is the purpose of tensorflow designed like this\uff1fWill it be optimized for this problem in the future?\r\n", "comments": ["@erizen  In order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51441\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51441\">No</a>\n"]}]