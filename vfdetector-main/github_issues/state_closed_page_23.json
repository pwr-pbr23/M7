[{"number": 54769, "title": "[XLA] Cache both positive and negative instruction reuse information, and update it online as fusions occur.", "body": "[XLA] Cache both positive and negative instruction reuse information, and update it online as fusions occur.\n\nThe object of this change is to avoid quadratic behaviors in computing operand reuse: after this change, we should not repeatedly revisit operators in fusion computations.\n", "comments": []}, {"number": 54768, "title": "[XLA] Remove `ChunkCandidate` class, as it stores redundant data.", "body": "[XLA] Remove `ChunkCandidate` class, as it stores redundant data.\n", "comments": []}, {"number": 54767, "title": "[HLO] Remove signless conversion from bufferization passes and HLO->MemRef.", "body": "[HLO] Remove signless conversion from bufferization passes and HLO->MemRef.\n\nIt looks like now we can perform signless conversion right after HLO->Linalg.\n", "comments": []}, {"number": 54766, "title": "[KERNEL_GEN] Simplify bufferization pattern for gml_st.loop.", "body": "[KERNEL_GEN] Simplify bufferization pattern for gml_st.loop.\n", "comments": []}, {"number": 54765, "title": "[tf.data] Add `GetDatasetNodeDef` helper.", "body": "[tf.data] Add `GetDatasetNodeDef` helper.\n", "comments": []}, {"number": 54764, "title": "[ROCm] Fixes to enable triangular solve unit test for BEF thunk on ROCm.", "body": "Not sure if these changes are necessary, but...\r\n\r\n/cc @chsigg @hanbinyoon ", "comments": ["This looks good and clean, but I'm missing where these constants are defined. Was there another PR that I missed?", "> This looks good and clean, but I'm missing where these constants are defined. Was there another PR that I missed?\r\n\r\nSorry for the confusion, but the constants are defined in a separate commit as part of: https://github.com/tensorflow/tensorflow/pull/54926", "Hi Rohit, would you mind to rebase this change? Thanks!", "> Hi Rohit, would you mind to rebase this change? Thanks!\r\n\r\nDone.", "I used git rebase instead of git merge - I hope that was the right thing to do.", "No, this PR now touches 200 files.", "Closing this and creating a new PR."]}, {"number": 54763, "title": "Square root symbol Sqrt not displayed correctly", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/sqrt\r\nhttps://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/rsqrt\r\n\r\n## Description of the issue (what needs changing):\r\nThe square root symbol is not displayed in the rendered HTML documentation. Although, the source code includes the appropriate code `\\sqrt{x}`. One would expect a square symbol around the x in the following image:\r\n\r\n![image](https://user-images.githubusercontent.com/12571895/156189226-cc3865fe-cc0e-416d-a3d7-1086c776fdff.png)\r\n\r\n\r\n- https://github.com/tensorflow/tensorflow/blob/e88293b0d59a237af1e2a299048b783f5331b7fb/tensorflow/core/api_def/base_api/api_def_Rsqrt.pbtxt#L5\r\n- https://github.com/tensorflow/tensorflow/blob/e88293b0d59a237af1e2a299048b783f5331b7fb/tensorflow/core/api_def/base_api/api_def_Sqrt.pbtxt#L5\r\n\r\n### Clear description\r\n\r\nThe missing square symbol is confusing for someone reading the documentation.\r\n\r\n### Fix\r\n\r\nOne could change every occurrence of the sqrt symbol to `x^{1/2}`. However, this is not a good solution and we should rather fix the display issue itself. ", "comments": ["yes i also saw in documentation but we can change it by y=1/sqrt{x}=1/(x^2) ,by this we can correct it", "@ScholliYT ,\r\n\r\nThanks for reporting. Created CL's to fix above issues.", "@chunduriv is this still issue still open? As I don't see a pull request for the same", "@ScholliYT,\r\n\r\nThis issue fixed now. Please refer updated api_docs for [sqrt](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/sqrt) and [rsqrt](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/rsqrt). Thanks!", "@chunduriv looks good to me \ud83d\udc4d", "@ScholliYT,\r\n\r\nPlease feel free to close the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 54762, "title": "Ensure kernel targets don't have unnecessary dependencies on", "body": "Ensure kernel targets don't have unnecessary dependencies on\nexperimental targets.\n\nPrevious work had already ensured that the \"framework_stable\"\ntarget doesn't depend on the experimental method definitions\nin interpreter_experimental.cc.   However, the targets\ntensorflow/lite/kernels:builtin_ops and\ntensorflow/lite/kernels:builtin_ops_all_linked still had dependencies\non the default \"framework\" target, which is an alias for\n\"framework_experimental\", and apps using BuiltinOpResolver would need\nto depend on those, so such apps would not be able to get build-time\ndiagnostics if they unintentionally depend on experimental features.\n", "comments": []}, {"number": 54761, "title": "Clean up the BUILD file to remove commented test targets", "body": "Clean up the BUILD file to remove commented test targets\n", "comments": []}, {"number": 54760, "title": "[mlir][linalg] WIP Replace linalg.fill (do not commit).", "body": "[mlir][linalg] WIP Replace linalg.fill (do not commit).\n", "comments": []}, {"number": 54759, "title": "Ensure that the \"graph_info\" target is a fully self-contained library", "body": "Ensure that the \"graph_info\" target is a fully self-contained library\nthat contains definitions of all of the entities that it declares.\n", "comments": []}, {"number": 54758, "title": "Convert HLOToMemrefConversionPatterns into RewritePatterns", "body": "Convert HLOToMemrefConversionPatterns into RewritePatterns\n", "comments": []}, {"number": 54757, "title": "[XLA] Cleanup / optimizations to `GlobalDecreasingSizeBestFitHeap::FindChunkCandidate`.", "body": "[XLA] Cleanup / optimizations to `GlobalDecreasingSizeBestFitHeap::FindChunkCandidate`.\n", "comments": []}, {"number": 54756, "title": "Added new type of generic test that uses TensorDescriptors.", "body": "Added new type of generic test that uses TensorDescriptors.\n", "comments": []}, {"number": 54755, "title": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.", "body": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.\n\nThis is unused as of cl/240419515 (then in third_party/tensorflow/core/kernels/data/dataset_utils.cc).\n", "comments": []}, {"number": 54754, "title": "Don't register the complex dialect as part of Tensorflow dialects.", "body": "Don't register the complex dialect as part of Tensorflow dialects.\n\nPasses that use it (HloLegalizeToLinalgPass) already specify it as dependent dialect.\n", "comments": []}, {"number": 54753, "title": "model.save fails with ValueError __inference_conv2d_transpose_layer_call_fn_4530 when Conv2DTranspose is quantization aware", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):  pip install\r\n- TensorFlow version: \r\n        tf=2.7.0, tensorflow_model_optimization=0.7.1\r\n\ttf=2.8.0, tensorflow_model_optimization=0.7.1\r\n\ttf-nightly=2.9.0dev20211222, tensorflow_model_optimization=0.7.1\r\n- Python version: 3.7.12\r\n\r\n**Describe the current behavior**\r\nWe save a quantization-aware keras-model in a .pb model format using `model.save()`. This operation fails with `ValueError: __inference_conv2d_transpose_layer_call_fn_4530` when our model contains a `Conv2DTranspose` layer. \r\n- The error is reproducible when we quantize the entire model using `tfmot.quantization.keras.quantize_model()`\r\n- The error is also reproducible when we annotate layers using `tf.keras.models.clone_model()` apply quantization using `tfmot.quantization.keras.quantize_apply()`. Our current workaround is to not annotate `Conv2DTranspose` but this prevents us from having a fully quantization-aware model. \r\n - The error is reproducible in  tf2.7.0, tf2.8.0 and tf-nightly\r\n\r\nSaving the same model as .h5 works (unfortunately this workaround this is not suitable for us because our technical requirement is that we save a .pb-model)\r\n\r\n**Describe the expected behavior**\r\n`model.save()` saves a QAT  model with a  Conv2DTranspose layer in a .pb-format successfully. \r\n\r\n**Standalone code to reproduce the issue**\r\nHere are collabs to reproduce the issue using a very simple model with a Conv2DTranspose layer and two ways to make a model quantization aware mentioned above:\r\n     - [ Collab with tf2.7.0](https://colab.research.google.com/drive/1BHQeFMd0Pc8qtfjY3FBBZ2rM1m2tqs23?usp=sharing)\r\n     - [ Collab with tf2.8.0](https://colab.research.google.com/drive/1zTzM9nJnY0NagzAcnZSlUgKW-vTUsL4F?usp=sharing)\r\n\r\n\t\r\n**Other info / logs** \r\nSimilar issue [#868](https://github.com/tensorflow/model-optimization/issues/868 )\r\n\r\n```\r\nTraceback\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-7-dc1f93a93afb> in <module>()\r\n      2 annotated_model = tf.keras.models.clone_model(base_model, clone_function=apply_quantization)\r\n      3 q_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\r\n----> 4 q_aware_model.save('D:/output_folder/q_aware_model') # save keras model as .pb, fails\r\n\r\n1 frames\r\n/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py in map_resources(self)\r\n    402           if capture_constant_value is None:\r\n    403             raise ValueError(\r\n--> 404                 f\"Unable to save function {concrete_function.name} because it \"\r\n    405                 f\"captures graph tensor {capture} from a parent function which \"\r\n    406                 \"cannot be converted to a constant with `tf.get_static_value`.\")\r\n\r\nValueError: Unable to save function b'__inference_conv2d_transpose_layer_call_fn_4530' because it captures graph tensor \r\nTensor(\"model/quant_conv2d_transpose/transpose_1:0\", shape=(3, 3, 16, 16), dtype=float32) from a parent function which \r\ncannot be converted to a constant with `tf.get_static_value`.\r\n```\r\n", "comments": ["**f**", "I followed this guide and it worked for me: https://www.tensorflow.org/guide/saved_model#exporting_custom_models\r\n\r\nIn other words, the below code should work. That said, I do agree that an explicit example for exporting a sub-classed keras model with a custom training loop is missing on the tf page.\r\n\r\nimport tensorflow as tf\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.d = tf.keras.layers.Dense(2)\r\n\r\n    @tf.function(input_signature=[tf.TensorSpec([2, 3], tf.float32)])\r\n    def call(self, x, training=True, mask=None):\r\n        return self.d(x)\r\n\r\n\r\nmodel = Model()\r\nmodel(tf.random.normal((2, 3)))\r\n\r\ntf.saved_model.save(model, '/tmp/serving_path')", "@pat749 could it be that you accidentally posted a reply to a wrong issue? \r\n\r\nThe current issue is about quantization aware models and a `Conv2DTranspose`  layer.  You seem to be referring to saving a sub-classed model which is discussed in  issue [ #54681](https://github.com/tensorflow/tensorflow/issues/54681).  If I am wrong and your reply was meant for the current issue, could you please elaborate on how using a sub-classed keras model can help us to solve the `Conv2DTranspose` and QAT problem?\r\n", "@ypsilon-elle \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThanks!", "Hey @sushreebarsa, thank you for your suggestion. I have reposted this issue to [keras-team/keras](https://github.com/keras-team/keras/issues): [#16152](https://github.com/keras-team/keras/issues/16152)", "@ypsilon-elle Thanks for the update!\r\nPlease move this issue to closed status as we will track the other ticket .Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54753\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54753\">No</a>\n"]}, {"number": 54752, "title": "Change filemode of algebraic_simplifier.cc", "body": "Change filemode of algebraic_simplifier.cc\n\nIt should not be executable.\n", "comments": []}, {"number": 54750, "title": "Tensorflow Lite iOS framework- info.plist file missing", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Iphone 13 mini\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.7r\r\n- Python version: 3.9.5\r\n- Installed using virtualenv? pip? conda?: venv\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): compilation is fine.\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n**Problem description**\r\nBuilding an iOS framework does not generate info.plist which is needed when the library is used as an embed framework. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n./configure -> use iOS\r\nbazel build --config=ios_arm64 -c opt //tensorflow/lite/ios:dvdnr_framework\r\n\r\n**Any other info / logs**\r\nthe framework generates fine, but info.plist should be included in the framework.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54750\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54750\">No</a>\n", "nvm.", "Hi @dtomarepo  ! Did it get resolved?"]}, {"number": 54749, "title": "LLVM component error.", "body": "**System information**\r\n\r\nOS Platform : Windows 11\r\nTensorFlow version: 2.8\r\nPython version: 3.9.9\r\nBazel version : 421\r\nGPU model and memory: GTX1650\r\nCUDA/CUdnn: 11.5/8.3.1\r\n\r\n**Describe the problem**\r\nProblem when build from source. LLVM component.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=156\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=E:/Python3/python.exe\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=E:/Python3/python.exe --action_env PYTHON_LIB_PATH=E:/Python3/lib/site-packages --python_path=E:/Python3/python.exe --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.5 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --config=cuda --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --define=override_eigen_strong_inline=true\r\nINFO: Reading rc options for 'build' from c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:cuda in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:opt in file c:\\users\\dubli\\downloads\\tensorflow\\.tf_configure.bazelrc: --copt=/arch:FMA3 --host_copt=/arch:FMA3\r\nINFO: Found applicable config definition build:windows in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --verbose_failures --features=compiler_param_file --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\users\\dubli\\downloads\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository llvm-project instantiated at:\r\n  C:/users/dubli/downloads/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  C:/users/dubli/downloads/tensorflow/tensorflow/workspace2.bzl:888:21: in workspace\r\n  C:/users/dubli/downloads/tensorflow/tensorflow/workspace2.bzl:526:15: in _tf_repositories\r\n  C:/users/dubli/downloads/tensorflow/third_party/llvm/setup.bzl:22:19: in llvm_setup\r\nRepository rule llvm_configure defined at:\r\n  C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/configure.bzl:83:33: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'llvm-project':\r\n   Traceback (most recent call last):\r\n        File \"C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/configure.bzl\", line 73, column 25, in _llvm_configure_impl\r\n                _overlay_directories(repository_ctx)\r\n        File \"C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/configure.bzl\", line 62, column 13, in _overlay_directories\r\n                fail((\"Failed to execute overlay script: '{cmd}'\\n\" +\r\nError in fail: Failed to execute overlay script: 'E:/Python3/python.exe C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw --overlay C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n\r\nstderr:\r\nTraceback (most recent call last):\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 92, in <module>\r\n    main(parse_arguments())\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 80, in main\r\n    _symlink_abs(os.path.join(args.overlay, relpath),\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 64, in _symlink_abs\r\n    os.symlink(os.path.abspath(from_path), os.path.abspath(to_path))\r\nOSError: [WinError 1314] \u2569\u044b\u0448\u0445\u044d\u0404 \u044d\u0445 \u044e\u0441\u044b\u0440\u0444\u0440\u0445\u0404 \u0404\u0401\u0445\u0441\u0454\u0445\u044c\u221a\u044c\u0448 \u044f\u0401\u0440\u0442\u0440\u044c\u0448: 'C:\\\\users\\\\dubli\\\\_bazel_dubli\\\\mnmgdhl7\\\\external\\\\llvm-raw\\\\utils\\\\bazel\\\\llvm-project-overlay\\\\.bazelignore' -> 'C:\\\\users\\\\dubli\\\\_bazel_dubli\\\\mnmgdhl7\\\\external\\\\llvm-project\\\\.bazelignore'\r\n\r\nERROR: Error fetching repository: Traceback (most recent call last):\r\n        File \"C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/configure.bzl\", line 73, column 25, in _llvm_configure_impl\r\n                _overlay_directories(repository_ctx)\r\n        File \"C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/configure.bzl\", line 62, column 13, in _overlay_directories\r\n                fail((\"Failed to execute overlay script: '{cmd}'\\n\" +\r\nError in fail: Failed to execute overlay script: 'E:/Python3/python.exe C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw --overlay C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n\r\nstderr:\r\nTraceback (most recent call last):\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 92, in <module>\r\n    main(parse_arguments())\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 80, in main\r\n    _symlink_abs(os.path.join(args.overlay, relpath),\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 64, in _symlink_abs\r\n    os.symlink(os.path.abspath(from_path), os.path.abspath(to_path))\r\nOSError: [WinError 1314] \u2569\u044b\u0448\u0445\u044d\u0404 \u044d\u0445 \u044e\u0441\u044b\u0440\u0444\u0440\u0445\u0404 \u0404\u0401\u0445\u0441\u0454\u0445\u044c\u221a\u044c\u0448 \u044f\u0401\u0440\u0442\u0440\u044c\u0448: 'C:\\\\users\\\\dubli\\\\_bazel_dubli\\\\mnmgdhl7\\\\external\\\\llvm-raw\\\\utils\\\\bazel\\\\llvm-project-overlay\\\\.bazelignore' -> 'C:\\\\users\\\\dubli\\\\_bazel_dubli\\\\mnmgdhl7\\\\external\\\\llvm-project\\\\.bazelignore'\r\n\r\nERROR: C:/users/dubli/downloads/tensorflow/tensorflow/tools/pip_package/BUILD:273:10: //tensorflow/tools/pip_package:build_pip_package depends on //tensorflow/compiler/mlir/tensorflow:gen_mlir_passthrough_op_py in repository @ which failed to fetch. no such package '@llvm-project//mlir': Failed to execute overlay script: 'E:/Python3/python.exe C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw --overlay C:/users/dubli/_bazel_dubli/mnmgdhl7/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n\r\nstderr:\r\nTraceback (most recent call last):\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 92, in <module>\r\n    main(parse_arguments())\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 80, in main\r\n    _symlink_abs(os.path.join(args.overlay, relpath),\r\n  File \"C:\\users\\dubli\\_bazel_dubli\\mnmgdhl7\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 64, in _symlink_abs\r\n    os.symlink(os.path.abspath(from_path), os.path.abspath(to_path))\r\nOSError: [WinError 1314] \u2569\u044b\u0448\u0445\u044d\u0404 \u044d\u0445 \u044e\u0441\u044b\u0440\u0444\u0440\u0445\u0404 \u0404\u0401\u0445\u0441\u0454\u0445\u044c\u221a\u044c\u0448 \u044f\u0401\u0440\u0442\u0440\u044c\u0448: 'C:\\\\users\\\\dubli\\\\_bazel_dubli\\\\mnmgdhl7\\\\external\\\\llvm-raw\\\\utils\\\\bazel\\\\llvm-project-overlay\\\\.bazelignore' -> 'C:\\\\users\\\\dubli\\\\_bazel_dubli\\\\mnmgdhl7\\\\external\\\\llvm-project\\\\.bazelignore'\r\n\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 2.208s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)\r\n    currently loading: tensorflow/compiler/mlir/tensorflow\r\n", "comments": ["Try to [Activate Developer Mode](https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development) - this did the trick for me.\r\n\r\nThe error occurs if Windows couldn't create a symbolic link. The `mklink`-command requires administrator privileges for some reason unless dev mode is enabled.\r\n", "@DublikuntMux, This issue seems to be Bazel version problem. Latest Tensorflow version supports Bazel version 5.0.0. Thanks!", "> Try to [Activate Developer Mode](https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development) - this did the trick for me.\r\n> \r\n> The error occurs if Windows couldn't create a symbolic link. The `mklink`-command requires administrator privileges for some reason unless dev mode is enabled.\r\n\r\nThank you, you were right. The problem was solved as soon as I turned on developer mode.", "> @DublikuntMux, This issue seems to be Bazel version problem. Latest Tensorflow version supports Bazel version 5.0.0. Thanks!\r\n\r\n_TF_MAX_BAZEL_VERSION = '4.99.0'\r\nThe settings do not allow you to use any more than this version.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54749\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54749\">No</a>\n"]}, {"number": 54748, "title": "AttributeError: module 'tensorflow' has no attribute 'reduce_sum'", "body": "Hi while running \r\n\r\npython -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n\r\nTo verify my Tensorflow installation I get AttributeError;\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'reduce_sum'\r\n\r\ntensorflow version: Version: 2.5.0", "comments": ["@CL500Coupe ,\r\nI haven't found any issue while executing the provided code.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/8deba244497ee68bda6b3b52e713618f/54748.ipynb).We request please re-install the tensorflow with latest version 2.8 and test your code.It helps.Thanks!", "you could try tf.math.reduce_sum()", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54748\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54748\">No</a>\n"]}, {"number": 54747, "title": "Segmentation Fault (core dumped) Issue", "body": "**System information**\r\n- I have written custom code\r\n- OS Platform and Distribution: CentOS Linux release 7.7.1908 (AltArch), Power9 PC with 4 GPU nodes, 1 login node and 1 compute node and it has little endian architecture\r\n- TensorFlow installed from (source or binary): https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\r\n- TensorFlow version (use command below): 2.1.3 (tensorflow-gpu)\r\n- Python version:3.6.13\r\n- Bazel version (if compiling from source):\r\n-  python compiler version: GCC 7.3.0\r\n- CUDA/cuDNN version:10.2\r\n- GPU model and memory: NVIDIA Tesla V100, Total memory: 379140608 kB =379.140608 GB (in one of the node)\r\n\r\n\r\n\r\nI use Supercomputer at our organization for training. I am facing the Segmentation Fault (core dumped) Issue, when I attempt to train a CNN model. The model gets trained for a smaller number of Epochs. Eg if epochs=50 the model runs fine and outputs the trained model file (using callbacks in model.fit). But when epochs are increased, to 75 then segmentation fault occurs at 54th epoch for the same dataset. I ran .py file by submitting it as a job through slurm script. Dataset size is 80,000*5600, around 9GB.\r\n\r\n**Code**\r\n```\r\nimport os\r\nimport os.path\r\nimport sys\r\n\r\nimport h5py\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ndef load_file(database_file, load_data=False):\r\n    in_file  = h5py.File(database_file, \"r\")\r\n    X_train = np.array(in_file['training/data'],dtype=np.int8)\r\n    Y_train = np.array(in_file['training/label'])\r\n    X_test = np.array(in_file['testing/data'], dtype=np.int8)\r\n    Y_test = np.array(in_file['testing/label'])\r\n    if load_data == False:\r\n        return (X_train, Y_train), (X_test, Y_test)\r\n    else:\r\n        return (X_train, Y_train), (X_test, Y_test), (in_file['train/data'], in_file['test/data'])\r\n\r\ndatabase = \"/home/..../dataset.h5\"\r\ntrained_model = \"/home..../trained_epoch_test.h5\"\r\n  \r\n(X_train, Y_train), (X_test, Y_test) = load_file(database_file)\r\n\r\nX_train_scaled = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\r\nX_test_scaled = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\r\n\r\ny_train_categorical = keras.utils.to_categorical(Y_train, num_classes=256)\r\ny_test_categorical    = keras.utils.to_categorical(Y_test, num_classes=256)\r\n\r\nbatch_size = 300 \r\nepochs = 100\r\n   \r\nclasses=256\r\ninput_shape = (5600,1)     \r\nimg_input = keras.layers.Input(shape=input_shape)\r\n\r\nx = keras.layers.Conv1D(64, 11, activation='relu', padding='same', name='block1_conv1')(img_input)\r\nx = keras.layers.AveragePooling1D(2, strides=2, name='block1_pool')(x)\r\n\r\nx = keras.layers.Conv1D(128, 11, activation='relu', padding='same', name='block2_conv1')(x)\r\nx = keras.layers.AveragePooling1D(2, strides=2, name='block2_pool')(x)\r\n\r\nx = keras.layers.Conv1D(256, 11, activation='relu', padding='same', name='block3_conv1')(x)\r\nx = keras.layers.AveragePooling1D(2, strides=2, name='block3_pool')(x)\r\n\r\nx = keras.layers.Conv1D(512, 11, activation='relu', padding='same', name='block4_conv1')(x)\r\nx = keras.layers.AveragePooling1D(2, strides=2, name='block4_pool')(x)\r\n\r\nx = keras.layers.Conv1D(512, 11, activation='relu', padding='same', name='block5_conv1')(x)\r\nx = keras.layers.AveragePooling1D(2, strides=2, name='block5_pool')(x)\r\n\r\nx = keras.layers.Flatten(name='flatten')(x)\r\nx = keras.layers.Dense(4096, activation='relu', name='fc1')(x)\r\nx = keras.layers.Dense(4096, activation='relu', name='fc2')(x)\r\nx = keras.layers.Dense(classes, activation='softmax', name='predictions')(x)\r\n  \r\nmodel = keras.models.Model(img_input, x, name='cnn_best')\r\noptimizer = keras.optimizers.RMSprop(lr=0.00001)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n    \r\nsave_model = keras.callbacks.ModelCheckpoint(trained_model)\r\ncallbacks=[save_model]\r\n    \r\nmodel.fit(x=X_train_scaled, y=y_train_categorical, batch_size=batch_size, verbose = 1, epochs=epochs, callbacks=callbacks)\r\n```\r\n**Following is the logs generated after enabling fault handler() function:**\r\n![fault handler](https://user-images.githubusercontent.com/70361953/156146446-230da029-000b-4c0f-9911-90ff9c51276e.png)\r\n\r\n**Slurm Script used to submit the job**\r\n#!/bin/bash\r\n#SBATCH --partition=GPU_three\r\n#SBATCH --nodelist=Node_03\r\n#SBATCH --output=output\r\npython3 train.py\r\n\r\n", "comments": ["Hi @peter-jp! Thanks for reporting this issue. You can reduce reduce the batch size to 30 or 60  and input size to (100,1) to see the difference in TF  2.8 version. You can also use [tf.device](https://www.tensorflow.org/guide/gpu) to force run the entire process in GPU mode. \r\n\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) for further assistance.\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "I can reduce the batch size but cannot reduce the input size (as it must be equal to the number of columns in the dataset). \r\nIn IBM conda, the latest version available for Tensorflow-gpu is 2.1.3, no other versions like TF 2.8 is available for ppcle64 arch.\r\nI will use tf.device and will update the result.\r\n\r\nFYI: Meanwhile, I used Tensorflow Mirrored strategy within one GPU, but that also resulted in segmentation fault after some more epochs than normal implementation.", "@peter-jp ! Did it get resolved in GPU mode in 2.8 version?", "There is no TF2.8 version available for IBM power 9 PPCLE64 architecture. I use the following channel for installing packages\r\n\r\nconda config --prepend channels \\\r\nhttps://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/", "Ok @PeterisP ! Please let us know after reducing batch size to 30 in GPU mode .Hi @chunduriv ! Could you please look at this issue?", "yes sure", "Thanks for opening this issue. Development of keras moved to separate repository https://github.com/keras-team/keras/issues\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\nThank you!", "@mohantym I tried with 30 as batch size for 400 epochs but it also resulted in segmentation fault at 130th epoch.\r\n\r\nFollowing is the result of enabling fault handler\r\n\r\n\r\n\r\nCurrent thread 0x0000200000044cd0 (most recent call first):\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/h5py/_hl/files.py\", line 443 in close\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 120 in save_model_to_hdf5\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\", line 112 in save_model\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1011 in save\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 1040 in _save_model\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 992 in on_epoch_end\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 302 in on_epoch_end\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 771 in on_epoch\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/contextlib.py\", line 88 in __exit__\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397 in fit\r\n  File \"/home/peter/.conda/envs/peter_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819 in fit\r\n  File \"/home/peter/analysis/for_Training_gpu.py\", line 100 in <module>\r\n/var/spool/slurm/d/job03321/slurm_script: line 8:  3921 Segmentation fault      (core dumped) python3 ~/analysis/for_Training_gpu.py", "Hi, Could you please refer this comment and post the issue in Keras repo for faster resolution. Thanks!\r\n\r\n> Thanks for opening this issue. Development of keras moved to separate repository https://github.com/keras-team/keras/issues\r\n> \r\n> Please post this issue on keras-team/keras repo. To know more see; https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999 Thank you!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54746, "title": "[PluggableDevice] Add int32 DEVICE_DEFAULT registration for Where", "body": null, "comments": []}, {"number": 54745, "title": "Drive ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54745\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54745\">No</a>\n", "Test "]}, {"number": 54744, "title": "Change driver wrapper enums from platform agnostic to platform discriminated.", "body": "Change driver wrapper enums from platform agnostic to platform discriminated.\n", "comments": []}, {"number": 54743, "title": "Modify verifier to allow stateful ops such as CIRCULAR_BUFFER to be variable.", "body": "Modify verifier to allow stateful ops such as CIRCULAR_BUFFER to be variable.\n", "comments": []}, {"number": 54742, "title": "Skip setting up captures for functions that have already been restored.", "body": "Skip setting up captures for functions that have already been restored.\n\nA concrete function could be set up by either or both `_recreate_function` and `_recreate_bare_concrete_function`.\n", "comments": []}, {"number": 54741, "title": "Fix spelling of \"saveable\".", "body": "Fix spelling of \"saveable\".\n", "comments": []}, {"number": 54740, "title": "Updated arguments of acos function", "body": "String is not supported as an argument of `acos` function. So, removed it from the arguments.\r\n\r\nFixes https://github.com/tensorflow/tensorflow/issues/54545", "comments": []}, {"number": 54739, "title": "Some cleanup work for `Trackable` methods and arguments (and mirroring onto DelegateMixin).", "body": "Some cleanup work for `Trackable` methods and arguments (and mirroring onto DelegateMixin).\n", "comments": []}]