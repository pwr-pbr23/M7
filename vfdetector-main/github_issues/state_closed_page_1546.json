[{"number": 6543, "title": "Reenable building depthwise_conv_op and depthwise_conv_grad_op on windows.", "body": "", "comments": ["Jenkins, test this please.", "Verified windows bazel build for this PR."]}, {"number": 6542, "title": "Merge release branch back into master.", "body": "", "comments": []}, {"number": 6540, "title": "`easy_install tensorflow-gpu` fails", "body": "A pip install of tensorflow-gpu and tensorflow works great.\r\n\r\n```bash\r\n$ pip install tensorflow-gpu\r\n```\r\n\r\nHowever, when one is trying to create a package with a dependency on tensorflow, one usually has to do the following in `setup.py`:\r\n\r\n```python\r\nfrom setuptools import setup\r\n\r\nsetup(name='mypkg',\r\n    setup_requires=[\"tensorflow-gpu == 0.12.0\", ...],\r\n    install_requires=[\"tensorflow-gpu == 0.12.0\", ...],\r\n)\r\n```\r\n\r\nUnfortunately, using the above as dependencies fail because setuptools defers to `easy_install` rather than `pip`.\r\n\r\n```python\r\nSearching for tensorflow-gpu\r\nReading https://pypi.python.org/simple/tensorflow-gpu/\r\nNo local packages or working download links found for tensorflow-gpu\r\nerror: Could not find suitable distribution for Requirement.parse('tensorflow-gpu')\r\n```\r\n\r\neasy_install doesn't seem to be able to recognise the wheels found at https://pypi.python.org/simple/tensorflow-gpu/\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n```bash\r\n$ ls -l /usr/local/cuda/lib64/libcud*\r\n-rw-r--r-- 1 root root 558720 Sep 15 01:02 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Sep 15 01:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root     19 Sep 15 01:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root 415432 Sep 15 01:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root 775162 Sep 15 01:02 /usr/local/cuda/lib64/libcudart_static.a\r\n\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: N/A\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. 0.12.0\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`): N/A\r\n2. The output of `bazel version`: N/A\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n```bash\r\n$ easy_install tensorflow-gpu\r\nSearching for tensorflow-gpu\r\nReading https://pypi.python.org/simple/tensorflow-gpu/\r\nNo local packages or working download links found for tensorflow-gpu\r\nerror: Could not find suitable distribution for Requirement.parse('tensorflow-gpu')\r\n```\r\n\r\nBut inspection of https://pypi.python.org/simple/tensorflow-gpu/ shows:\r\n\r\n```\r\nLinks for tensorflow-gpu\r\ntensorflow_gpu-0.12.0-cp34-cp34m-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0-cp35-cp35m-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0rc1-cp35-cp35m-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl\r\ntensorflow_gpu-0.12.0rc1-cp34-cp34m-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0rc1-cp27-cp27m-macosx_10_11_intel.whl\r\ntensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl\r\ntensorflow_gpu-0.12.0-cp27-cp27mu-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0rc1-cp35-cp35m-macosx_10_11_x86_64.whl\r\ntensorflow_gpu-0.12.0-cp27-cp27m-macosx_10_11_intel.whl\r\ntensorflow_gpu-0.12.0rc1-cp27-cp27mu-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0-cp35-cp35m-macosx_10_11_x86_64.whl\r\ntensorflow_gpu-0.12.0rc0-cp27-cp27mu-manylinux1_x86_64.whl\r\ntensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["@yifeif Is this because we are hosting tensorflow gpu pip package at the new pypi backend?\r\nOr maybe easy_install uses some workflow similar to old pip versions?\r\n\r\n@sjperkins for context, tensorflow pip packages exceed the old pypi package size limit.\r\nTherefore, they have to be hosted in their new datastore. This makes our packages uninstallable using old versions of pip. So maybe this is an issue with the way easy_install tries to fetch the package?", "It could be something with the '_' and '-' replacement. https://pypi.python.org/simple/tensorflow_gpu/  seems to work as well. @sjperkins do you mind try replacing tensorflow-gpu with tensorflow_gpu?", "Sorry should have mentioned, underscore also does not work.\n\nOn 28 Dec 2016 9:44 p.m., \"Yifei Feng\" <notifications@github.com> wrote:\n\n> It could be something with the '_' and '-' replacement.\n> https://pypi.python.org/simple/tensorflow_gpu/ seems to work as well.\n> @sjperkins <https://github.com/sjperkins> do you mind try replacing\n> tensorflow-gpu with tensorflow_gpu?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6540#issuecomment-269529543>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADXd5JjiRCqjoF_WsM-5Le2y2O_VfAJAks5rMrwggaJpZM4LW8Y2>\n> .\n>\n", "According to [this page](https://packaging.python.org/pip_easy_install/), easy_install does not install from wheels, and it only installs from egg. We currently only build wheel packages. Looks like setup_requires section of setup.py is always fulfilled by easy_install http://pip.readthedocs.io/en/latest/reference/pip_install/#controlling-setup-requires. Do you need tensorflow in both setup_requires and install_requires, or would install_requires be sufficient?\r\n\r\nFYI @martinwicke", "**tl;dr** Just use `pip` for everything, rather than `python setup.py ...` (a.k.a. `easy_install`) which is deprecated\r\n\r\nFeel free to close if you don't want to support the legacy `easy_install` stuff.\r\n\r\n@yifeif My use case for placing `tensorflow-gpu` in `setup_requires` is compiling custom ops into a shared library (python extension) during the installation process of a module I'm building. So I wanted  tensorflow to be installed after the setup.py is run but before the extension was compiled.\r\n\r\nFor others encountering this issue, just use pip. I was using  `python setup.py ...` calls which invoke easy_install (see below), but this is [legacy](https://docs.python.org/2/install/) behaviour and [pip](https://docs.python.org/2/installing/index.html) is now the way forward. So this issue arose out of different module install methods.\r\n\r\nI made a small module [(testsetup.zip)](https://github.com/tensorflow/tensorflow/files/677030/testsetup.zip)  to test things out for future reference:\r\n\r\n```python\r\nimport ez_setup\r\nez_setup.use_setuptools()\r\n\r\nfrom setuptools import setup, find_packages\r\nfrom setuptools.command.install import install\r\nfrom setuptools.command.develop import develop\r\n\r\nclass DevelopCommand(develop):\r\n    def run(self):\r\n        #import tensorflow\r\n        develop.run(self)\r\n\r\nclass InstallCommand(install):\r\n    def run(self):\r\n        #import tensorflow\r\n        install.run(self)\r\n\r\nsetup(name=\"testsetup\",\r\n    #setup_requires=['tensorflow-gpu'],\r\n    install_requires=['tensorflow-gpu'],\r\n    packages=find_packages(),\r\n    cmdclass={\r\n        'install' : InstallCommand,\r\n        'develop' : DevelopCommand,\r\n     },\r\n)\r\n\r\n```\r\n\r\nWithin the install directory if one calls:\r\n\r\n- `python setup.py install` it succeeds without installing dependencies!\r\n- `python setup.py develop` it defers to easy_install and fails because `easy_install` can't find an egg.\r\n- `pip install .` it succeeds if setup_requires is commented out, but fails otherwise. However, `setup_requires` isn't strictly required since `install_requires` will be run before it and the tensorflow dependency will be inplace before the bulk of the setup() code is run. Its certainly installed before InstallCommand.run() is called.\r\n- `pip install -e .` it succeeds if setup_requires is commented out, but fails otherwise.\r\n\r\n", "Building and distributing an `egg` file is not planned for tensorflow, as it is the old deprecated standard.\r\nI will close this issue now."]}, {"number": 6539, "title": "better Variable.__repr__", "body": "Right now, I get sth like:\r\n\r\n    <tensorflow.python.ops.variables.Variable object at 0x2b9c67daae10>\r\n\r\nIt would be nice if it would show sth like\r\n\r\n    <Variable name=\"foo\" shape=(100,200) dtype=\"float32\">\r\n\r\nor so.\r\n", "comments": ["Maybe something like this: https://github.com/yaroslavvb/tensorflow/commit/de542371f05148641b33a1dcf4c25cc3c0cdd1c5", "@albertz would you like to send a PR to fix this? :)", "BTW, PR for such small change is quite easy and you can do it mostly from browser:\r\n\r\nFirst, click \"Fork\" on github tensorflow page\r\n\r\nThen in Terminal:\r\n\r\n```\r\ngit remote add mine https://github.com/<username>/tensorflow\r\ngit remote add tfmain https://github.com/tensorflow/tensorflow.git\r\ngit fetch tfmain\r\ngit checkout tfmain/master -b bugfix\r\ngit push --set_upstream mine\r\n\r\n```\r\nThen in bugfix branch on /tensorflow on Github, find file, click \"Edit\" button, edit file, then click commit, then click \"Pull Requests\" and select tensorflow/master on left and <username>/tensorflow:bugfix on right. If master head moves while the PR is going through, you can do\r\n\r\n```\r\ngit rebase origin/master\r\ngit push -f mine\r\n```", "Do you guys mind if I try my hand at it? I'll have a PR soon"]}, {"number": 6538, "title": "Missing GRPC information on Documentation", "body": "Both the site and the Git does not say that it is necessary to have GRPC installed to run distributed TensorFlow.", "comments": ["There is no separate installation step for gRPC when using distributed TensorFlow. It is linked statically into the Python extension `_pywrap_tensorflow.so` (or `_pywrap_tensorflow.pyd`) that is installed as part of the PIP package."]}, {"number": 6537, "title": "file_io.get_matching_files fails if any unrelated (non-matching) sub-directory is non-readable", "body": "Let `filename = \"/tmp/mymodel.005\"`.\r\n\r\n`file_io.get_matching_files(filename)` will raise an exception like\r\n\r\n    PermissionDeniedError: /tmp/.xrdp/xrdp-sesman-jjz1ox\r\n\r\nfor me. I think this is a bug as this is an unrelated (non-matching) directory, so it does not matter and it will anyway not match the `filename`, thus it should not raise an exception.\r\n\r\nI get this via `saver.restore(sess=..., save_path=filename)` where `saver = tf.train.Saver(...)`.\r\n", "comments": ["@albertz The underlying `GetMachingFiles` performs a pattern matching on all files in the directory. ", "Yes I see that it does that (and even for all sub directories) but it shouldn't break on sub directories which do not match anyway.", "It add all sub folders before doing the match, and the error is thrown when checking if it is a directory. ", "I know. And I say that this should not fail if it does not match the pattern anyway.", "yup you're right... the directory check shouldn't need to be done on children that don't match the pattern. That check is done for adding stuff to the queues but not for the IsDirectory check. I'll fix this.", "I believe commit https://github.com/tensorflow/tensorflow/pull/6719/commits/493188ebe0f68ace157bd97453c41e2cb0d642c8 should have fixed this issue. \r\n\r\nCan you verify and make sure things work fine now?"]}, {"number": 6536, "title": "Pull in test fixes and API changes to 1.0 branch.", "body": "", "comments": ["Merge PR, CLA ok.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Note we're not quite done. Of course. :/"]}, {"number": 6535, "title": "Fix an error in depth_to_space doc", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks @gaohuazuo for spotting this!"]}, {"number": 6534, "title": "InvalidArgumentError (see above for traceback): Nan in summary histogram for: dnn/hiddenlayer_0_activation", "body": "I am trying to do regression for my own data following the example of [Deep Neural Network Regression with Boston Data](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/boston.py).\r\n\r\nFollowing is my code.\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom sklearn import cross_validation\r\nfrom sklearn import metrics\r\nfrom sklearn import preprocessing\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import learn\r\nfrom numpy import genfromtxt\r\nimport numpy as np\r\n\r\n\r\ndef main():\r\n  # Load dataset\r\n  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_x.csv\r\n  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_y.csv\r\n\r\n  x_test = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_x.csv', delimiter=',')\r\n  y_test = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_y.csv', delimiter=',')\r\n  x_test = x_test.astype(np.float32, copy=False)\r\n  y_test = y_test.astype(np.float32, copy=False)\r\n  \r\n  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_x.csv\r\n  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_y.csv\r\n\r\n  x_train = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_x.csv', delimiter=',')\r\n  y_train = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_y.csv', delimiter=',')\r\n  x_train = x_train.astype(np.float32, copy=False)\r\n  y_train = y_train.astype(np.float32, copy=False)\r\n  \r\n  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_validate_data_x.csv\r\n  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_validate_data_y.csv\r\n\r\n  # Scale data (training set) to 0 mean and unit standard deviation.\r\n  # scaler = preprocessing.StandardScaler()\r\n  # x_train = scaler.fit_transform(x_train)\r\n\r\n  # Build 2 layer fully connected DNN with 10, 10 units respectively.\r\n  feature_columns = learn.infer_real_valued_columns_from_input(x_train)\r\n  regressor = learn.DNNRegressor(\r\n      feature_columns=feature_columns, hidden_units=[10, 10],optimizer=tf.train.GradientDescentOptimizer(\r\n      learning_rate=0.1))\r\n\r\n  # Fit\r\n  regressor.fit(x_train, y_train, steps=5000, batch_size=1)\r\n\r\n  # Predict and score\r\n  y_predicted = list(\r\n      regressor.predict(scaler.transform(x_test), as_iterable=True))\r\n  score = metrics.mean_squared_error(y_predicted, y_test)\r\n\r\n  print('MSE: {0:f}'.format(score))\r\n\r\n\r\nif __name__ == '__main__':\r\n  tf.app.run()\r\n```\r\n\r\nI am getting the following error.\r\n\r\n> >>> arm_data_regression.main()\r\n> WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpIda516\r\n> INFO:tensorflow:Using default config.\r\n> INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5464bf7a10>, 'tf_config': gpu_options {\r\n>   per_process_gpu_memory_fraction: 1\r\n> }\r\n> , '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}\r\n> WARNING:tensorflow:From arm_data_regression.py:45 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\n> Instructions for updating:\r\n> Estimator is decoupled from Scikit Learn interface by moving into\r\n> separate class SKCompat. Arguments x, y and batch_size are only\r\n> available in the SKCompat class, Estimator will only accept input_fn.\r\n> Example conversion:\r\n>   est = Estimator(...) -> est = SKCompat(Estimator(...))\r\n> WARNING:tensorflow:From arm_data_regression.py:45 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\n> Instructions for updating:\r\n> Estimator is decoupled from Scikit Learn interface by moving into\r\n> separate class SKCompat. Arguments x, y and batch_size are only\r\n> available in the SKCompat class, Estimator will only accept input_fn.\r\n> Example conversion:\r\n>   est = Estimator(...) -> est = SKCompat(Estimator(...))\r\n> WARNING:tensorflow:From arm_data_regression.py:45 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\r\n> Instructions for updating:\r\n> Estimator is decoupled from Scikit Learn interface by moving into\r\n> separate class SKCompat. Arguments x, y and batch_size are only\r\n> available in the SKCompat class, Estimator will only accept input_fn.\r\n> Example conversion:\r\n>   est = Estimator(...) -> est = SKCompat(Estimator(...))\r\n> INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\r\n> INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\r\n> INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\r\n> INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\r\n> INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.\r\n> INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.\r\n> INFO:tensorflow:Create CheckpointSaverHook.\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"arm_data_regression.py\", line 45, in main\r\n>     regressor.fit(x_train, y_train, batch_size=1)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 191, in new_func\r\n>     return func(*args, **kwargs)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 355, in fit\r\n>     max_steps=max_steps)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 733, in _train_model\r\n>     max_steps=max_steps)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 301, in _monitored_train\r\n>     None)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 473, in run\r\n>     run_metadata=run_metadata)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 628, in run\r\n>     run_metadata=run_metadata)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 595, in run\r\n>     return self._sess.run(*args, **kwargs)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 729, in run\r\n>     run_metadata=run_metadata)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 595, in run\r\n>     return self._sess.run(*args, **kwargs)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\n>    run_metadata_ptr)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n>     feed_dict_string, options, run_metadata)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n>     target_list, options, run_metadata)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Nan in summary histogram for: dnn/hiddenlayer_0_activation\r\n> \t [[Node: dnn/hiddenlayer_0_activation = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](dnn/hiddenlayer_0_activation/tag, dnn/hiddenlayer_0/hiddenlayer_0/Relu)]]\r\n> \r\n> Caused by op u'dnn/hiddenlayer_0_activation', defined at:\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"arm_data_regression.py\", line 45, in main\r\n>     regressor.fit(x_train, y_train, batch_size=1)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 191, in new_func\r\n>     return func(*args, **kwargs)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 355, in fit\r\n>     max_steps=max_steps)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 699, in _train_model\r\n>     train_ops = self._get_train_ops(features, labels)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 219, in _get_train_ops\r\n>     logits = self._logits(features, is_training=True)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 312, in _logits\r\n>     logits = self._dnn_logits(features, is_training)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 295, in _dnn_logits\r\n>     features, self._dnn_feature_columns, is_training)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.py\", line 360, in build_model\r\n>     self._add_hidden_layer_summary(net, scope.name)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.py\", line 322, in _add_hidden_layer_summary\r\n>     summary.histogram(\"%s:activation\" % tag, value)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 205, in histogram\r\n>     tag=scope.rstrip('/'), values=values, name=scope)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\r\n>     name=name)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n>     op_def=op_def)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n>     original_op=self._default_original_op, op_def=op_def)\r\n>   File \"/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n>     self._traceback = _extract_stack()\r\n> \r\n> InvalidArgumentError (see above for traceback): Nan in summary histogram for: dnn/hiddenlayer_0_activation\r\n> \t [[Node: dnn/hiddenlayer_0_activation = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](dnn/hiddenlayer_0_activation/tag, dnn/hiddenlayer_0/hiddenlayer_0/Relu)]]\r\n\r\n\r\nAm I passing any deprecated argument to DNNRegressor.fit()?\r\n\r\n\r\n", "comments": ["This type of usage question is better asked on [Stackoverflow](http://stackoverflow.com/questions/tagged/tensorflow). Github issues are for bug reports and installation issues."]}, {"number": 6533, "title": "Python 3.6 support [feature requests]", "body": "I'm sure that you are aware that Python 3.6 is available and TensorFlow is still not available for this version. Hope next update will cover the cp36 Python version.", "comments": ["You can install it manually (worked for me - on MacOS): \r\n\r\n```bash\r\npython3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n```", "there is a Tensorflow-0.12 Python-3.6 version for windows on cgohlke page", "I'm aware of workarounds, but the code we are using is `pip install -r requirements.txt` and will be nice to make it work in all the environments, not fan of creating several requirements.txt per operating system, Python version, etc.", "We usually follow ubuntu LTS versions to build our packages.\r\nLatest ubuntu LTS (16.04) still seems to not have python 3.6.\r\n\r\nI will reevaluate our resources, but for now I cannot promise quickly delivering this package.", "For Linux with Python 3.6 it worked for me (Arch Linux, CPU and GPU versions) to download the Python 3.5 version and simply rename it (adapting for CPU vs. GPU and tf version used) from 35 to 36 (2x):\r\n\r\nExample for CPU version:\r\n`mv tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl tensorflow-0.12.1-cp36-cp36m-linux_x86_64.whl`\r\n\r\nfollowed by\r\n\r\n`pip install tensorflow-0.12.1-cp36-cp36m-linux_x86_64.whl`", "@MichaelCaraccio Is that safe for linux 64 bit to install? ", "@ehzShelter I did not test on linux. Check this page : [Download and Setup](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#pip-installation) and choose the whl files corresponding to your distribution and architecture.\r\n\r\nTake a look at @domschl answer.\r\n", "Thank you @MichaelCaraccio ! @domschl solution is working, But I am not sure why it is working. If renaming the .whl is just fine, why maintainer not updating their source repo or readme..", "The reason so far is we have not tested it using python 3.6.\r\nWe are currently considering our options.\r\n", "@gunan got it. Anyway, tensorflow build from source documentation is not comprehensive. I cannot able to .whl file using bazel. Reading Readme file is little bit anecdotal. Maybe I am noob to understand.", "@MichaelCaraccio, your solution works flawlessly.  Thanks.", "For automatic testing and deployment, we need `pip install -r requirements.txt`.\r\nWe are working on very different configurations.\r\nFor us, building workarounds it is not the expected solution.", "@domschl Can confirm this works on Arch Linux. TensorBoard no longer throws a fit when it's asked to import TensorFlow. CPU & GPU, 64-bit, Python 3.6", "We decided we will rename and upload our binaries to pypi, to make them available for python 3.3 and 3.6.\r\nThey wont be as well tested as 3.4 and 3.5 binaries, but there should not be big differences in minor python versions.", "Great!", "@gunan Python 3.3 is now available on https://pypi.python.org/pypi/tensorflow/0.12.1, but still no Python 3.6 version on PyPI", "No python 3.6 version ..@gunan", "I would really appreciate 3.6 version being uploaded.", "Python 3.6 version is available on pypi now. Please give it a try.", "On my Mac is not working, I see the Linux version on PyPI:\r\n```\r\nCollecting tensorflow==0.12.1 (from -r requirements.txt (line 17))\r\n  Could not find a version that satisfies the requirement tensorflow==0.12.1 (from -r requirements.txt (line 17)) (from versions: )\r\nNo matching distribution found for tensorflow==0.12.1 (from -r requirements.txt (line 17))\r\n```\r\n\r\nAny plan to move to Python 3.6 for Mac and Win?", "It is perfectly working in Linux..\r\n![tensorflow](https://cloud.githubusercontent.com/assets/12381692/22120722/1a63a894-deab-11e6-9dbd-56b0d93155f0.png)\r\n", "Mac binary for Python3.6 should be uploaded as well. \r\n\r\nWe still need to do more testing for windows. For anybody feeling adventurous and using python3.6 on windows, could you try `pip install -i https://testpypi.python.org/pypi tensorflow` and let us know if you see any issue?", "As of today, there is both a Linux and Mac version for Python 3.6, which is good enough for my purposes.", "Confirm Python 3.6 is working well on Mac, thanks.", "I am getting this error on Windows 10\r\n\r\n  Could not find a version that satisfies the requirement protobuf>=3.1.0 (from tensorflow) (from versions: )\r\nNo matching distribution found for protobuf>=3.1.0 (from tensorflow)", "That is a separate issue.\r\nPlease file a new issue for that problem, with more information.", "Any word on new packages for `tensorflow-gpu` being pushed to pypi?", "'tensorflow-gpu' for python 3.6 should be now available for 0.12.1. @EntilZha ", "Thanks!", "Could you also add the 3.6-compatible version to conda repo?", "Conda repo is not controlled by us. Therefore, we cannot update it.\r\nWe are working on our installation documents to remove references to conda repos.", "Hi, I see you've added python 3.6 compatibility for Mac & Linux, do you have an ETA for the windows support of python 3.6 ?", "> We are working on our installation documents to remove references to conda repos.\r\n\r\ni wonder how hard it's to add/remove/update some line from the document. so some guys like me don't go through a lot of trouble and need to after hours of googling reach here and see there is no support for python 3.6 under windows ", "@mhamri maybe some guys like you could submit a PR with the required change instead of whining in the comments. Remind yourself that the software is not just free but also open-source.", "Is even website content is considered as open source? Unfortunately there\nis no repo for that. When you publicized it please buzz me. I will be glad\nto contribute,\n\nOn Feb 25, 2017 12:53 AM, \"Egor Panfilov\" <notifications@github.com> wrote:\n\n> @mhamri <https://github.com/mhamri> maybe some guys like you could submit\n> a PR with the required change instead of whining in the comments. Remind\n> yourself that the software is not just free but also open-source.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-282342268>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIk0J7TWF-hb4uJi65-4gKsdDprguuMEks5rfwsggaJpZM4LWtr2>\n> .\n>\n", "It all used to be under g3doc folder. But there seems to be an issue during\nthe website update.\nI will try to see why the new website pages are not there.\n\nOn Sun, Feb 26, 2017 at 9:44 PM, Mohammad Hossein Amri <\nnotifications@github.com> wrote:\n\n> Is even website content is considered as open source? Unfortunately there\n> is no repo for that. When you publicized it please buzz me. I will be glad\n> to contribute,\n>\n> On Feb 25, 2017 12:53 AM, \"Egor Panfilov\" <notifications@github.com>\n> wrote:\n>\n> > @mhamri <https://github.com/mhamri> maybe some guys like you could\n> submit\n> > a PR with the required change instead of whining in the comments. Remind\n> > yourself that the software is not just free but also open-source.\n> >\n> > \u2014\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub\n> > <https://github.com/tensorflow/tensorflow/issues/\n> 6533#issuecomment-282342268>,\n> > or mute the thread\n> > <https://github.com/notifications/unsubscribe-auth/AIk0J7TWF-hb4uJi65-\n> 4gKsdDprguuMEks5rfwsggaJpZM4LWtr2>\n>\n> > .\n> >\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-282633197>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOSKcCVaqec5UBXJgmqTyqKwRxGKmks5rgmKzgaJpZM4LWtr2>\n> .\n>\n", "In windows thr Python 3.6 is not supported yet. Only in linux and mac\n\nIn windows you need earlier version of anaconda or Python 3.5\n\nOn Mar 11, 2017 00:04, \"awwper\" <notifications@github.com> wrote:\n\n> how can I use tensorflow with python3.6 ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-285707775>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIk0J7B0V257JwiQgomP5n2UhaPERh0_ks5rkXRTgaJpZM4LWtr2>\n> .\n>\n", "I didn't try the Linux installation guide myself, but i think the web site\narticle can show you step by step\n\nOn Mar 11, 2017 00:18, \"awwper\" <notifications@github.com> wrote:\n\n> using linux, how can I install tensor flow for python3.6 plz ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-285711918>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIk0J1GPQ876KaMoTRz43TN6EscwF1S2ks5rkXfXgaJpZM4LWtr2>\n> .\n>\n", "Just use pip install tensorflow[-gpu]", "https://www.tensorflow.org/install/install_linux\n\nOn Mar 11, 2017 00:25, \"awwper\" <notifications@github.com> wrote:\n\n> can you link me plz ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-285713822>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIk0J-W0ovPbCnj_ZFy3CVejUl4MwTpLks5rkXlegaJpZM4LWtr2>\n> .\n>\n", "@awwper This isn't intended as your personal tech support. You may also wish to address your etiquette when contributing to issues. The instructions provided work perfectly fine, with a vast majority of us Machine Learning researchers and enthusiasts being able to follow it.  3.6 Support is officially available from repositories. You can use pip to install as @wangg12 has mentioned. Please stop spamming this issue, you have been provided with more than sufficient information to solve your problem.", "@yifeif \r\n\r\n> Mac binary for Python3.6 should be uploaded as well.\r\n> We still need to do more testing for windows. For anybody feeling adventurous and using python3.6 on windows, could you try pip install -i https://testpypi.python.org/pypi tensorflow and let us know if you see any issue?\r\n> \r\n\r\nI tried it on my windows machine but no matching distribution could be found.\r\nAfter looking through the testpypi.python.org I thought I will give this a try:\r\n`pip install https://testpypi.python.org/packages/db/d2/876b5eedda1f81d5b5734277a155fa0894d394a7f55efa9946a818ad1190/tensorflow-0.12.1-cp36-cp36m-win_amd64.whl`\r\n\r\nSo far the installation worked fine.", "Please use our website for instructions to get the latest version.\r\nThese instructions you pasted are months old now.", "I can install the tensorflow with python3.6 on windows properly, but it can't be imported with the error msg below:\r\n File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in sw\r\nig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u7d44\u3002\r\n\r\n....\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\nCould anyone kindly help to resolve this issue? Thank you!", "@rockerUX Yes I've managed to get everything working on windows 7 python 3.6. See [my comment](https://github.com/tensorflow/tensorflow/issues/6999#issuecomment-289280463).", "This work for me for windows 7 and windows 10 py3.\r\n\r\npip install https://testpypi.python.org/packages/db/d2/876b5eedda1f81d5b5734277a155fa0894d394a7f55efa9946a818ad1190/tensorflow-0.12.1-cp36-cp36m-win_amd64.whl", "@Dividedhighway When I install Tensorflow 3.6 on win10 I get a ModuleNotFoundError: No module named '_pywrap_tensorflow' when I import Tensorflow into my scripts.  Any idea how to fix this?", "@BattlestarPegasus See my comment on how to fix it. The problem is the same, whether you install `0.12.1` or not.", "Did you consider providing nightly build for Python 3.6 ? That would be great !", "(step 1) conda create -n py35 python=3.5 \r\n(step 2) activate py35 \r\n(step 3) conda create -n tensorflow \r\n(step 4,only for GPU) pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl", "After installing it on win7 x64 via ```https://testpypi.python.org/packages/db/d2/876b5eedda1f81d5b5734277a155fa0894d394a7f55efa9946a818ad1190/tensorflow-0.12.1-cp36-cp36m-win_amd64.whl```\r\nIt seems to finish installation successfully, however anytime I try to import tensorflow in my python code I see the following error:\r\n```\r\nimport tensorflow as tf\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 21, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow')\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n```", "Great thread, folks. pip install tensorflow (via pypi, I guess) worked for me. Running Python 3.6 on a Ubuntu 16.04 computer. Goodbye PY35 envs :)", "@MichaelCaraccio Since I run my project with python2, I change this command to\r\n```\r\npip2 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.0-py2-none-any.whl\r\n```\r\nand it works well. But according to my test, this only occurs when I use linuxbrew installed python. Everything works fine if I use pyenv installed python even if they are the same version `2.7.14`, weird..\r\n\r\nAnyway, thank you!", "Thanks for the note, Ray.\n\nOn Fri, Nov 3, 2017 at 7:20 AM, Ray Wang <notifications@github.com> wrote:\n\n> @MichaelCaraccio <https://github.com/michaelcaraccio> Since I run my\n> project with python2, I change this command to\n>\n> pip2 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.0-py2-none-any.whl\n>\n> and it works well. But according to my test, this only occurs when I use\n> linuxbrew installed python. Everything works fine if I use pyenv installed\n> python even if they are the same version 2.7.14, weird..\n>\n> Anyway, thank you!\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-341676733>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALBz712vG87hv6-A64gFPV9i27TnN3jGks5syvcLgaJpZM4LWtr2>\n> .\n>\n\n\n\n-- \nClive DaSilva CPA,CMA\nHome:  416-421-2480|Mobile: 416-560-8820\nEmail: clive.dasilva@gmail.com\nLinkedIN:  http://ca.linkedin.com/pub/clive-dasilva/3/197/b89\n", "Hi, I am trying to setup tensorflow with Python 3.6 using this wheel on windows CPU version. tensorflow-1.4.0-cp36-cp36m-win_amd64.whl. But, It is giving an error like  Could not find a version that satisfies the requirement wheel>=0.26 (from tensorflow==0.12.0) (from versions: )\r\no matching distribution found for wheel>=0.26 (from tensorflow==0.12.0).\r\n\r\nI can install on Mac but failing on windows. Can anyone help.?\r\n", "https://www.tensorflow.org/install/install_windows\n\nOn Thu, Nov 9, 2017 at 6:18 PM, abaviska <notifications@github.com> wrote:\n\n> Hi, I am trying to setup tensorflow with Python 3.6 using this wheel on\n> windows CPU version. tensorflow-1.4.0-cp36-cp36m-win_amd64.whl. But, It\n> is giving an error like Could not find a version that satisfies the\n> requirement wheel>=0.26 (from tensorflow==0.12.0) (from versions: )\n> o matching distribution found for wheel>=0.26 (from tensorflow==0.12.0).\n>\n> I can install on Mac but failing on windows. Can anyone help.?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-343323514>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALBz74DZYyx2lja-EJjlVbyng2YcCLBCks5s04hIgaJpZM4LWtr2>\n> .\n>\n\n\n\n-- \nClive DaSilva CPA,CMA\nHome:  416-421-2480|Mobile: 416-560-8820\nEmail: clive.dasilva@gmail.com\nLinkedIN:  http://ca.linkedin.com/pub/clive-dasilva/3/197/b89\n", "Hi Clived2, Thanks for your comments and reply.\r\n\r\nWhat I observed that , if I read my error, it is missing Wheel package in my local libraries. Due to proxy issues, my machine not able to download required packages for installation from Internet.\r\n\r\nAs a workaround, what I did is based on error kept downloading and locally installing number of library packages and finally could install Tensorflow.  Atleast 20 different packages needed to supply. If someone has similar proxy issues. Happy to help.\r\n\r\nThanks & Regards.", "Thanks for your  response. This must have been am old issue as I have\ninstalled Tensorflow without any difficulty on this laptop (Windows 10) and\non my Ubuntu 16.04 desktop both of which have Anaconda 3 installed.\nInstalling Tensorflow on either running either of the two commands in\nterminal :\n1) conda install tensorflow\nor\n2) pip install tensorflow.\n\nso it seems that Tensorflow is now readily available to all\n\nClive\n\n\n\nOn Sun, Nov 12, 2017 at 7:51 PM, abaviska <notifications@github.com> wrote:\n\n> Hi Clived2, Thanks for your comments and reply.\n>\n> What I observed that , if I read my error, it is missing Wheel package in\n> my local libraries. Due to proxy issues, my machine not able to download\n> required packages for installation from Internet.\n>\n> As a workaround, what I did is based on error kept downloading and locally\n> installing number of library packages and finally could install Tensorflow.\n> Atleast 20 different packages needed to supply. If someone has similar\n> proxy issues. Happy to help.\n>\n> Thanks & Regards.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6533#issuecomment-343783032>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALBz75Od4qIivIsd9SEJcquzp7Ub8w5hks5s15KJgaJpZM4LWtr2>\n> .\n>\n\n\n\n-- \nClive DaSilva CPA,CMA\nHome:  416-421-2480|Mobile: 416-560-8820\nEmail: clive.dasilva@gmail.com\nLinkedIN:  http://ca.linkedin.com/pub/clive-dasilva/3/197/b89\n"]}, {"number": 6532, "title": "Feature request: log-log scale for tensorboard", "body": "Would there be interest in adding a log-log display mode to tensorboard? That is, to enable plotting the x-axis in log scale for step count (and maybe relative time as well).\r\n\r\nI find log-log to be very useful for inspecting learning curves (loss vs. iteration). Given a constant learning rate, standard optimization algorithms usually give a straight line in log-log scale. It's really easy to visually spot when the straight line behavior ends, which is generally a sign that the model has almost converged (for its current learning rate). On the other hand, in lin-lin you can't distinguish the two conditions because everything looks vaguely like exponential decay, and log-lin isn't ideal either.", "comments": ["@danmane, could you consider this feature?", "Hi @nikitakit, thanks for the suggestion!\r\n\r\n@bdilday sent a pull request a few months ago (#3876) which added y-axis log scales on a per chart basis. I think it shouldn't be too hard to add x-axis log scales either. The main question in my mind is how to incorporate it into the UI: should it be a per-chart switch (like the y-axis log scales) or a global switch? Right now we coordinate all the x-axes through the global switch on the left, so it might be best to add it through another global setting. (Although I'm reluctant to keep adding checkboxes as a UI paradigm, that might be the right way to accommodate this request.)\r\n\r\nThe core TensorBoard team has other priorities right now, so we won't likely add this ourselves, but given bdilday's PR as a template, it should be feasible for someone in the community to put this in. I'm marking the issue contributions welcome and un-assigning myself.", "I can take this on if no one else is working on it. ", "Go for it :)", "I'm closing this due to inactivity, but if you have a PR, please feel free to submit it to our new repository at https://github.com/tensorflow/tensorboard/pulls! Thanks :-)", "I would love an horizontal log scale, too.", "This would be awesome to check convergence rates."]}, {"number": 6531, "title": "tf.losses.softmax_cross_entropy is deviously inconsistent", "body": "There are at least three variants of `softmax_cross_entropy` in TensorFlow:\r\n\r\n1. `tf.nn.softmax_cross_entropy_with_logits`\r\n\r\nAccepts `logits` as the first argument, and `labels` as the second argument.\r\n\r\n2. `tf.contrib.losses.softmax_cross_entropy`\r\n\r\nAccepts `logits` as the first argument, and `onehot_labels` as the second argument. So far so good. Except this is deprecated, and displays the recommendation `Use tf.losses.softmax_cross_entropy instead`.\r\n\r\n3. `tf.losses.softmax_cross_entropy`\r\n\r\nDecides to switch things around for fun and have `onehot_labels` as the first argument and  `logits` as the second. Since `onehot_labels` and `logits` are identically shaped tensors, the call succeeds without any complaints (until something else fails as a consequence, like the gradient).\r\n\r\nThis inconsistency seems a bit error prone. If nothing else, perhaps the deprecation warning for  `tf.contrib.losses.softmax_cross_entropy` should include a heads up.\r\n\r\n", "comments": ["@dr4b does this need better doc?", "Thank you for the report! Looks like the deprecation warning got updated by @alextp. I'm going to close this, since I don't see anything more we can do here given API compatibility.", "What's about \r\n\r\n```tf.losses.sparse_softmax_cross_entropy(labels,logits, ...)```\r\nvs\r\n```tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)```\r\n?\r\n\r\nIs there any reason to provide both functions? I understand that `tf.losses` also maintains `tf.GraphKeys.LOSSES`. But wouldn't it be more consistent (kwargs vs. args, '_with_logits' vs. '') to only support a mixture by\r\n\r\n```python\r\ntf.metrics.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits, \r\n                                                    ..., use_collection=False)\r\n```\r\n(I really mean `metrics` and not `losses` to have one consistent modul which can also include accuracy.)\r\n\r\nThis way, `tf.nn.sparse_softmax_cross_entropy_with_logits` can be just wrap`tf.metrics.sparse_softmax_cross_entropy_with_logits`.\r\n\r\nIt would be much easier, if it would be possible to just write\r\n```python\r\nprob = tf.nn.softmax(logits, name='prob')\r\npred = tf.arg_max(prob, 1, name='pred')\r\n\r\ncost = tf.metrics.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits)\r\naccuracy = tf.metrics.accuracy(labels=labels,pred=pred) # or even support logits\r\nprecision = tf.metrics.accuracy(labels=labels,pred=pred)\r\n```\r\n"]}, {"number": 6530, "title": "Branch 143061298", "body": "", "comments": []}, {"number": 6529, "title": "Provide a Maven POM", "body": "Closes #6527 \r\n\r\n- POM file for installing libtensorflow into a Maven repository.\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "@asimshankar please review.", "Mind adding instructions to the README?", "Jenkins, test this please", "@EronWright @jhseu : Quick question: How does `libtensorflow-jni.so` get included and linked in for  projects that add the maven dependency?", "Unfortunately Maven doesn't offer much help there.  The native lib is typically assumed to be preinstalled.  \r\n\r\nI have seen instances where libraries tuck away their jni libs (for all supported platforms) into the jar, then extract them at runtime.  Similar to:\r\n\r\nhttps://github.com/nathanmarz/jzmq/commit/e6c3c0b8966180a379b2a4aec64d7fd5fac5db38#\r\n\r\nhttps://github.com/os72/protoc-jar/blob/master/README.md\r\n"]}, {"number": 6528, "title": "Support reference counting on Java Tensor class", "body": "Closes #6524 \r\n\r\n- introduces RefCounted and AbstractRefCounted, with tests\r\n- implements reference counting on Tensor (which no longer implements\r\nAutoCloseable)", "comments": ["Can one of the admins verify this patch?", "@asimshankar please review. \r\nI've been working to integrate TF with another framework and I'd like `Tensor` instances to survive in various caches.   I was finding that reference counting would be needed either in `Tensor` or in a wrapper class, but the latter would be a usability problem.\r\n\r\nLooking at `Graph.Reference` and the like, switching to ref counting for `Graph` and `Session` might work out nicely.   For example, the `Operation` class would hold a ref to the managed `Graph` object and would itself be `RefCounted`.  Happy to help with this in a follow-up.", "Thanks for the suggestion and pull request @EronWright .\r\n\r\nHowever, I'm a bit skeptical on this one. I did consider this but felt that the language support for `AutoCloseable` makes it a more appropriate choice at this lower level. Some reservations:\r\n\r\n- I fear that it will be much easier for developers to forget to `unref()` than forget to close an `AutoCloseable`, mostly because of language support (and implied un-idiomatic nature of reference counting in Java).\r\n- There is asymmetry between creation and cleanup that is very subtle. For example, if `Session.Runner.run()` isn't called after `Session.Runner.feed()` (perhaps because of some exception thrown in intervening code), then the `Tensor`s are not cleaned up. I see that the PR also uses finalizers, but relying on that is generally unadvisable given that there are no guarantees on garbage collection and that `Tensor` objects can have large memory footprints\r\n\r\nA wrapper for reference counting and/or a list of `AutoCloseable`s seems easy enough, but perhaps I'm not fully appreciating the complexity of that. I had thought of something like:\r\n\r\n```java\r\npublic class AutoCloseableList implements List<AutoCloseable>, AutoCloseable {\r\n   // ...\r\n   public void close() {\r\n      for (AutoCloseable c : list) {\r\n         c.close();\r\n      }\r\n   }\r\n}\r\n```\r\n\r\nto make it easier to work with `Session.Runner`, or with reference counting something like:\r\n\r\n```java\r\npublic class RefCounted<E implements AutoCloseable> {\r\n   public E ref() { ... }\r\n   public boolean unref() {\r\n      if (refcnt-- == 0) {\r\n        object.close();\r\n        return true;\r\n     }\r\n    return false;\r\n  }\r\n}\r\n```\r\n\r\nWhich I was hoping would be trivial and easy to incorporate adapters into Netty-like settings (and I'd be happy to add those to `org.tensorflow.util`)\r\n\r\nCould you perhaps elaborate on why you think such wrappers would be burdensome? Is there some example code you can share that can maybe guide us in finding the right balance? For example, I feel `LabelImage.java` is easier to read without the reference counting. But I am wide open to looking at more use cases.\r\n\r\nCC @jhseu ", "Thanks for the feedback!   I'd still like to convince you that reference counting is superior for this library, especially given its power-over-convenience nature (and hopeful foundation for Scala/Kotlin/Closure libraries, which may not support try-with-resources).   Frankly it is more convenient too.\r\n\r\nI've been writing integration code based on this patch, that I'm almost ready to share with folks.   I find it more convenient; input tensors (passed to `feed` or `setAttr`) needn't be dereferenced.  Output tensors must have `unref` or `close` called in any case. \r\n\r\nThis style of reference counting (callee must unref) is familiar to Netty developers.  Any scenario involving chaining, asynchrony, or caching will benefit from this; it simply took Netty a few versions to find this solution.\r\n\r\nI agree with your concern about the runner/builder leaks.  `finalize` was a catch-all solution but the runner should probably be `AutoCloseable`.", "I still feel that this is making the lower level API more complicated and easier to mess up with. I guess I'm not seeing the convenience benefits that you are, particularly those that cannot be achieved with simple wrapper classes.\r\n\r\nI understand we're trying to balance between usability, power and maintainability in any API design. With reference counting here, I feel the latter can suffer quite a bit leading to very subtle bugs if there are `ref()`/`unref()` mismatches and it is easy to end up with them. Without this, it is clearer IMHO since every materialized `Tensor` needs to be `close()`d precisely once.\r\n\r\nReference counting is beneficial when there is \"shared ownership\" of the resource. It isn't clear to me that this should be the default case. I'm thinking of `Tensor` more like a `RandomAccessFile` or `FileChannel` here. I'm not familiar enough with netty, but I'm sure there is a clear pattern to ensure that such objects are created and closed without reference counting support in those classes?\r\n\r\nAdmittedly, this discussion of convenience and power is in the abstract. If there are real examples of code that we can use to iterate on, that might be more productive. Otherwise, I'm tempted to avoid reference counting here.", "I'd favor keeping it as is for the reasons @asimshankar mentioned. I appreciate that the current interface adds difficulty for caches and that it requires a wrapper, but that's true for any `close()`able class (of which many are all applicable to caches).", "Thanks for indulging this conversation, these are reasonable objections to be sure.  Go ahead and close the PR if still not convinced after reading the below.\r\n\r\nMaybe it is a bit counter-intuitive but reference counting as defined in this PR actually leads to less user code in the common case and fewer leaks.  This is because the callee (`OperationBuilder`, `Session.Runner`) dereferences the object.\r\n\r\nMaybe I can strengthen the case by showing how reference counting could simplify the handling of the output tensors.   Imagine that `Session.Runner::run()` returned an object of type `RunResult`.   \r\n\r\n```java\r\nclass RunResult extends AbstractReferenceCounted {\r\n  private RunMetadata metadata;\r\n  private Tensor[] outputTensors;\r\n  \r\n  public List<Tensor> outputTensors() { ... }\r\n\r\n  @Override\r\n  protected void deallocate() {\r\n    for(Tensor t: outputTensors) { t.unref(); }\r\n  }\r\n}\r\n```\r\n\r\nTypical user code need only `unref` the result to cleanup everything.  Any tensors that need be retained may simply be `ref`ed.   In the status-quo, the protocol would be more complex IMO.", "@asimshankar Can we close this PR?", "@EronWright : Thanks for the comments, but I think we feel that being more idiomatic with language support is more suitable at this \"lowest level\" of the API. Closing this PR out. "]}, {"number": 6527, "title": "[Java] provide a Maven POM", "body": "It would be handy to have a POM file for the Java library.\r\n\r\nIn the short-term, having a POM facilitates local development of Java applications (potentially using other build frameworks).  For example, it makes it possible to install the built library into Maven's local repository:\r\n```\r\nmvn install:install-file \\\r\n  -Dfile=bazel-bin/tensorflow/java/libtensorflow.jar \\\r\n  -DpomFile=tensorflow/java/pom.xml\r\n```\r\n\r\nThe POM file should also be useful for eventual publishing of the library.", "comments": ["Loadable jar at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java is well behind the source, more specifically, it does not include SavedModelBundle class supporting recommended way to restore models. It also will be nice to have an example of its usage "]}, {"number": 6526, "title": "Update release to document breaking change 141725777, fixes #6202", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 6525, "title": "Disable some of the failing windows tests.", "body": "", "comments": ["http://ci.tensorflow.org/view/Experimental/job/exp-win-bzl/12/\r\n\r\nNot all the tests are fixed.\r\nWill send other PRs to fix all issues."]}, {"number": 6524, "title": "Feature request: Support reference counting on Java Tensor class", "body": "The `Tensor` class of the new Java library would be more useful and easier to use with built-in reference counting, based on a common interface `RefCounted`.    This would be in lieu of `AutoCloseable`.\r\n\r\nI suggest that reference counting follow the Netty approach as described [in the docs](http://netty.io/wiki/reference-counted-objects.html).   A nice aspect is that it simplifies the common case of supplying an input tensor to `Session.Runner::feed()` or to `OperationBuilder::setAttr` (the caller needn't unref the tensor; the callee will unref it).  At the same time, a reference count is of more general utility than `AutoCloseable`.\r\n\r\nPlease consider applying the idea to `Session` and `Graph` later.\r\n", "comments": ["Discussing this in the pull request thread."]}, {"number": 6523, "title": "possible variable typo in \"Vector Representations of Words\" documentation", "body": "The variables \"training_inputs\" and \"training_labels\" in the section \"[https://www.tensorflow.org/tutorials/word2vec/#training_the_model](https://www.tensorflow.org/tutorials/word2vec/#training_the_model)\":\r\n\r\n```\r\nfor inputs, labels in generate_batch(...):\r\n  feed_dict = {training_inputs: inputs, training_labels: labels}\r\n  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)\r\n```\r\n\r\nappear to be new per the tutorial text.\r\n\r\nWere they supposed to be the previously defined \"train_inputs\" and \"train_labels\"?\r\n\r\nthanks,", "comments": ["I just fixed this but not sure when it will propagate out to the website or back to GH.  Thanks for reporting.  This is one of the tutorials marked to revisit the entire code sample anyway."]}, {"number": 6522, "title": "Fix build error on Windows.", "body": "MSVC cannot resolve the type of `nullptr` in `CHECK_EQ(nullptr, ...)`, so we use a static cast to make it explicit.", "comments": ["Running a build here:\r\nhttp://ci.tensorflow.org/view/Experimental/job/exp-win-bzl-2/1/", "OK, windows failure is a test failure I will investigate.\r\nthe bazel build works on windows with this change."]}, {"number": 6521, "title": "Change dbpedia URL", "body": "Fixes #6174", "comments": []}, {"number": 6520, "title": "Interesting phenomenon when running cifar10_train.py and cifar10_multi_gpu_train.py", "body": "### Environment info\r\nOperating System:\r\n```bash\r\n centos 7 \r\n```\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```bash\r\n$ls -l /usr/local/cuda/lib64/libcud*\r\n```\r\nhere is the result\r\n```bash\r\n  548 -rw-r--r-- 1 root root   558720 Dec  7 21:02 /usr/local/cuda/lib64/libcudadevrt.a\r\n    0 lrwxrwxrwx 1 root root       16 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\n    0 lrwxrwxrwx 1 root root       19 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n  408 -rwxr-xr-x 1 root root   415432 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n  760 -rw-r--r-- 1 root root   775162 Dec  7 21:02 /usr/local/cuda/lib64/libcudart_static.a\r\n    0 lrwxrwxrwx 1 root root       13 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\n    0 lrwxrwxrwx 1 root root       17 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n77480 -rwxr-xr-x 1 root root 79337624 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n68124 -rw-r--r-- 1 root root 69756172 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\nI install tensorflow using pip with command from pypi\r\n```bash\r\n$ pip install tensorflow-gpu \r\n```\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```bash\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.0\r\n```\r\n\r\n### Phenomenon\r\n#### Performance of cifar10 model on GPU\r\nWhen running cifar10_train.py, I tried 2000 steps with batch_size 128\r\n```bash\r\npython cifar10_train.py --data_dir ../datasets/cifar10 --batch_size 128 --max_steps 2000\r\n```\r\nThen elasped time on a Telsa M40 graphics card is \r\n```bash\r\nElasped Time: 167.51s\r\n```\r\nHere is the speed running cifar10_multi_gpu_train.py with different number of GPUs on my machine (max_steps=2000, batch_size=128)\r\n\r\n| System           |   Examples per sec   | Step Time (sec/batch)   |    Elasped Time (sec)  |\r\n| -------------    |  -------------------   |---------------------------|------------------------|\r\n| 1 Tesla M40   |   1300 ~ 2400          |  0.05 ~ 0.10                   |   157.96                      |\r\n| 2 Tesla M40   |   2700 ~ 3700          |  0.03 ~ 0.04                   |   164.49                      |\r\n| 4 Tesla M40   |   3900 ~ 6300          |  0,02 ~ 0.03                   |   231.98                      |\r\n| 8 Tesla M40   |   3700 ~ 6700          |  0.02 ~ 0.04                   |   431.54                      |\r\n\r\nThe performance improves as the number of GPUs increases.\r\n\r\n#### Performance when moving distorted_inputs to cpu\r\nI made some changes on cifar10_train.py and cifar10_muti_gpu_train.py\r\n```python\r\n# cifar10_train.py\r\ndef train():\r\n    with tf.Graph().as_default():\r\n        # Here is what I modified\r\n         with tf.device(\"/cpu:0\"):\r\n            images, labels = cifar10.distorted_inputs()\r\n```\r\nI put function distorted_inputs on cpu, and then the performace is much better than before\r\n```bash\r\nElasped Time: 42.92s\r\n```\r\nI made the same change on cifar10_multi_gpu_train.py\r\n```python\r\n# cifar10_multi_gpu_train.py\r\ndef tower_loss(scope, images, labels):\r\n  # Get images and labels for CIFAR-10.\r\n  # Commented\r\n  #images, labels = cifar10.distorted_inputs()\r\n\r\n  logits = cifar10.inference(images)\r\n\r\n  _ = cifar10.loss(logits, labels)\r\n  losses = tf.get_collection('losses', scope)\r\n  total_loss = tf.add_n(losses, name='total_loss')\r\n\r\n  for l in losses + [total_loss]:\r\n    loss_name = re.sub('%s_[0-9]*/' % cifar10.TOWER_NAME, '', l.op.name)\r\n    tf.scalar_summary(loss_name, l)\r\n\r\n  return total_loss\r\n\r\ndef train():\r\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\r\n  with tf.Graph().as_default(), tf.device('/cpu:0'):\r\n    global_step = tf.get_variable(\r\n        'global_step', [],\r\n        initializer=tf.constant_initializer(0), trainable=False)\r\n\r\n    ...build optimizer...\r\n\r\n    # Calculate the gradients for each model tower.\r\n    tower_grads = []\r\n    for i in xrange(FLAGS.num_gpus):\r\n      # move distorted_inputs to here\r\n      images, labels = cifar10.distorted_inputs()\r\n      with tf.device('/gpu:%d' % i):\r\n          with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:\r\n               loss = tower_loss(scope, images, labels)\r\n```\r\nAnd then the performance is \r\n\r\n| System           |   Examples per sec   | Step Time (sec/batch)   |    Elasped Time (sec)  |\r\n| -------------    |  -------------------   |---------------------------|------------------------|\r\n| 1 Tesla M40   |   6700 ~ 7700          |  0.016 ~ 0.019               |   42.62                       |\r\n| 2 Tesla M40   |   6800 ~ 7600          |  0.016 ~ 0.018               |   78.18                        |\r\n| 4 Tesla M40   |   7000 ~ 7400          |  0,017 ~ 0.018               |   154.88                      |\r\n| 8 Tesla M40   |   6900 ~ 7200          |  0,017 ~ 0.018               |   309.95                      |\r\n\r\nThe performce is much better than the previous table but increaing number of GPUs does not acquire better result. ", "comments": ["Is it possible that when you move the distorted_inputs to CPU, the CPU is spending all its time on the inputs and can only process ~7000 examples/sec? Increasing the number of GPUs would not let the CPU process more inputs.", "Closing due to lack of recent activity. We will reopen when additional information becomes available. Thanks!"]}, {"number": 6519, "title": "Can't output summaries using tensorflow.contrib.slim", "body": "When I run my code, it gives the following warning:\r\n`WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py:344 in __init__.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.`\r\n\r\nAnd It can't output the summaries. Although I think it is training my net. Here's some of my code:\r\n\r\n`summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\r\nfor end_point in end:\r\n    x=end[end_point]\r\n    summaries.add(tf.summary.histogram('activations/' + end_point, x))\r\n    summaries.add(tf.summary.scalar('sparsity/' + end_point,  tf.nn.zero_fraction(x)))\r\nfor loss in tf.get_collection(tf.GraphKeys.LOSSES):\r\n    summaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))\r\nfor variable in slim.get_model_variables():\r\n     summaries.add(tf.summary.histogram(variable.op.name, variable))\r\nsummaries.add(tf.summary.scalar('learning_rate', learning_rate))\r\nsummaries.add(tf.summary.scalar('total_loss', total_loss))\r\n#summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))\r\nsummary_op = tf.summary.merge(list(summaries))\r\nslim.learning.train(train_op, \r\n    model_store_dir, \r\n    init_fn = init_fn,\r\n    summary_op=summary_op,\r\n    number_of_steps=100000,\r\n    save_summaries_secs=300, \r\n    save_interval_secs=600)`", "comments": ["@mxmxlwlw As it said, SummaryWriter has renamed to `tf.summary.FileWriter`", "@inflation I noticed that slim.learning.train has a parameter summary_writer. So I passed the tf.summary.FileWriter to it, and the warning didn't show again. However, the log still did't come up. I think the error may be in other place of my code.\r\nHere's my code:\r\n\r\nimport pickle\r\nimport re\r\nimport random\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom vgg_preprocessing import preprocess_image\r\nslim = tf.contrib.slim\r\n_R_MEAN = 123.68\r\n_G_MEAN = 116.78\r\n_B_MEAN = 103.94\r\ndef vgg16Net(inputs,\r\n           num_classes=1000,\r\n           is_training=True,\r\n           dropout_keep_prob=0.5,\r\n           spatial_squeeze=True,\r\n           scope='vgg_16'):\r\n    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\r\n        end_points_collection = sc.name + '_end_points'\r\n        # Collect outputs for conv2d, fully_connected and max_pool2d\r\n        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\r\n                            outputs_collections=end_points_collection):\r\n          net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool1')\r\n          net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool2')\r\n          net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool3')\r\n          net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool4')\r\n          net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\r\n          net = slim.max_pool2d(net, [2, 2], scope='pool5')\r\n          # Use conv2d instead of fully_connected layers.\r\n          net = slim.conv2d(net, 4096, [7, 10], padding='VALID', scope='fc6')\r\n          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\r\n                             scope='dropout6')\r\n          net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\r\n          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\r\n                             scope='dropout7')\r\n          net = slim.conv2d(net, num_classes, [1, 1],\r\n                            activation_fn=None,\r\n                            normalizer_fn=None,\r\n                            scope='fc8')\r\n          # Convert end_points_collection into a end_point dict.\r\n          end_points = slim.utils.convert_collection_to_dict(end_points_collection)\r\n          if spatial_squeeze:\r\n            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\r\n            end_points[sc.name + '/fc8'] = net\r\n          return net, end_points\r\n\r\ndef getsamples():\r\n    rootpath = 'C:\\\\Users\\\\mx\\\\Desktop\\\\nextLevel\\\\UCF-101'\r\n    with open('res.pickle', 'rb') as f:\r\n        pathdict = pickle.load(f)\r\n    with open('trainlist01.txt', 'r') as f:\r\n        lines=f.readlines()\r\n    samples_all=[]\r\n    labels_all=[]\r\n    for line in lines:\r\n        [videogroup, video, label]=re.split('/| |\\n', line)[0:3]\r\n        samples = [rootpath + '\\\\' + videogroup + '\\\\' + video[:-4] + '\\\\' + i for i in pathdict[videogroup][video]]\r\n        samples_all.extend(samples)\r\n        labels_all.extend([label]*len(samples))\r\n    return samples_all, labels_all\r\n\r\nsamples_all, labels_all = getsamples()\r\n\r\nlabels_one_hot_all = np.zeros((len(labels_all), 101))\r\nindex_offset = np.arange(len(labels_all))*101\r\nind = index_offset + np.array(labels_all, np.int32) - 1\r\nlabels_one_hot_all.flat[ind]=1\r\n#samples_all = tf.constant(samples_all)\r\n#labels_all = tf.constant(labels_all)\r\n[sample, label] = tf.train.slice_input_producer([samples_all, labels_one_hot_all])\r\nimagecontent = tf.read_file(sample)\r\nimage = tf.image.decode_jpeg(imagecontent, channels=3)\r\nimage = tf.cast(image, dtype = tf.float32)\r\nchannels = tf.split(2, 3, image)\r\nchannels[0] -= _R_MEAN\r\nchannels[1] -= _G_MEAN\r\nchannels[2] -= _B_MEAN\r\nimage=tf.concat(2, channels)\r\nimage=tf.reshape(image, [240, 320, 3])\r\nimages, labels = tf.train.batch([image, label], 16, 4, 64)\r\nnet, end = vgg16Net(images, num_classes = 101, is_training=True)\r\n\r\nslim.losses.softmax_cross_entropy(net, labels)\r\ntotal_loss = slim.losses.get_total_loss()\r\nlearning_rate = 0.001\r\noptimizer=slim.train.GradientDescentOptimizer(learning_rate)\r\ntrain_var = slim.get_variables_to_restore(exclude = ['vgg_16/conv1', 'vgg_16/conv2', 'vgg_16/conv2', 'vgg_16/conv3', 'vgg_16/conv4', 'vgg_16/conv5']);\r\ntrain_op=slim.learning.create_train_op(total_loss, optimizer, variables_to_train = train_var)\r\nmodel_store_dir = './log/'\r\ninit_var = slim.get_variables_to_restore(exclude = ['vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8'])\r\ninit_fn = slim.assign_from_checkpoint_fn('./vgg_16.ckpt', init_var)\r\n\r\nsummaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\r\nfor end_point in end:\r\n    x=end[end_point]\r\n    summaries.add(tf.summary.histogram('activations/' + end_point, x))\r\n    summaries.add(tf.summary.scalar('sparsity/' + end_point, tf.nn.zero_fraction(x)))\r\n\r\nfor loss in tf.get_collection(tf.GraphKeys.LOSSES):\r\n    summaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))\r\n\r\nfor variable in slim.get_model_variables():\r\n    summaries.add(tf.summary.histogram(variable.op.name, variable))\r\n\r\nsummaries.add(tf.summary.scalar('learning_rate', learning_rate))\r\n\r\nsummaries.add(tf.summary.scalar('total_loss', total_loss))\r\n\r\n#summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))\r\n\r\nsummary_op = tf.summary.merge(list(summaries))\r\n\r\nsummary_writer = tf.summary.FileWriter(model_store_dir)\r\nslim.learning.train(train_op, \r\n    model_store_dir, \r\n    init_fn = init_fn,\r\n    summary_op=summary_op,\r\n    summary_writer=summary_writer,\r\n    number_of_steps=100000,\r\n    save_summaries_secs=300, \r\n    save_interval_secs=600)\r\n", "@inflation Here's the code.\r\n\r\n[doNet.zip](https://github.com/tensorflow/tensorflow/files/674192/doNet.zip)\r\n", "You can try to add `tf.summary.FileWriter.add_summary` before your training", "@inflation It suggest that I can't pass tensor to the add_summary function...", "Slim uses `supervisor` for training. Do you have the model checkpoint files?", "@inflation Yes, I downloaded it from slim page in tensorflow/models(repository)  \r\ninit_var = slim.get_variables_to_restore(exclude = ['vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8'])\r\ninit_fn = slim.assign_from_checkpoint_fn('./vgg_16.ckpt', init_var)", "No, I mean when you trying to train your model, does it produce anything in the output directory?", "@inflation No. So you mean it didn't train? ", "Yes, checkpoint files should be in the same folder. And they are automatically saved in some period when using supervisor if the path is valid. ", "@inflation I find the problem. I noticed that it's not the problem of summary. The training process can't even do one process step. \r\n[doNet3.zip](https://github.com/tensorflow/tensorflow/files/679508/doNet3.zip)\r\nHere's my new python code. Can you find what's the problem in that file? I really don't know how to fix it. \r\nThe code stuck at sess.run function.\r\n\r\nThe samples_all is a list of files. which contain many image paths. The dim of images are 240 * 320 * 3\r\nThe labels_all is a list of dense labels each of which in the range 0 to 100 (101 classes).\r\nThank you.\r\n", "Problem solved. I loss the code tf.train.start_queue_runners(sess=sess). It needs to run queue manually.\r\n"]}, {"number": 6518, "title": "tf.sequence_mask with int64 does not work", "body": "Given some tensor `x` with shape (batch,time) and `seq_lens` of shape (batch,) of dtype `int64`, I wanted to use this code:\r\n```\r\n    mask = tf.sequence_mask(seq_lens, maxlen=tf.shape(x)[1])\r\n```\r\n\r\nThis fails with `TypeError: Input 'y' of 'Less' Op has type int64 that does not match type int32 of argument 'x'.` in `gen_math_ops._range(0, maxlen, 1) < expand_dims(lengths, 1)`.\r\n\r\nIf I add `seq_lens = tf.cast(seq_lens, \"int32\")` before, then it works.\r\n\r\nCasting `tf.shape(x)[1]` to `int64` does not work (because of `gen_math_ops._range(0, maxlen, 1)` which treats `0` and `1` as `int32` and then raises `TypeError: Input 'limit' of 'Range' Op has type int64 that does not match type int32 of argument 'start'`).\r\n", "comments": ["This is an unfortunate known limitation, and we would welcome a patch that fixes it.", "@aselle I'm working on it.", "@albertz Could you give me a test input and output sample?\r\nI test this sample below with `tf.int64`, and I can get the right mask sequence. While it doesn't output the dtype, compared to `tf.int32`.\r\n```python\r\nIn  [1]:sess.run(tf.sequence_mask(lengths=[1,3,4], maxlen=5, dtype=tf.int64))\r\nOut [1]: array([[1, 0, 0, 0, 0],\r\n       [1, 1, 1, 0, 0],\r\n       [1, 1, 1, 1, 0]])\r\n```\r\n\r\n```python\r\nIn [2]: sess.run(tf.sequence_mask(lengths=[1,3,4], maxlen=5, dtype=tf.int32))\r\nOut[2]: array([[1, 0, 0, 0, 0],\r\n       [1, 1, 1, 0, 0],\r\n       [1, 1, 1, 1, 0]], dtype=int32)\r\n```", "@aselle Could we just convert seq_lens to int32 if its dtype is int64 in tf.sequence_mask implementation?\r\n\r\nHowever since the error occurs due to `less` operation in `gen_math_ops._range(0, maxlen, 1) < expand_dims(lengths, 1)` where the left operand is int32 and the right operand is int64. Maybe we could add `type promotion` mechanisms in these operations.\r\n\r\nIf it's ok by converting seq_lens to int32 in tf.sequence_mask, I can add it as a patch. Wellcome your advice -:)", "@DjangoPeng are you still working on this?\r\n@aselle has this been fixed yet?", "I think this issue has been fixed in the latest version.", "@gunan Sorry for this. I'm leaving for some company things. Now, I would return to community work."]}, {"number": 6517, "title": "no code completion supported in tf0.12.0 ?", "body": "when i typed `tf.contrib.rnn.`, there is no code completion choice with pycharm and ipython.are there some soft reload mechanism ?. what should i do to solve this problem.\r\n", "comments": ["when using `from tensorflow.contrib import rnn` , the code completion works correctly", "having the same issue @KeithYin did you find a solution ?", "pytharm\u7684\u81ea\u52a8\u8865\u5168\u95ee\u9898\uff0c\u697c\u4e3b\u600e\u4e48\u89e3\u51b3\u7684\u554a\uff0c\u770b\u6837\u5b50\u662fcontrib\u7684\u61d2\u52a0\u8f7d\u5bfc\u81f4\u7684\uff0c\u6211\u8fd9\u4e24\u5929\u4e5f\u53d1\u73b0\u4e86\u8fd9\u4e2a\u95ee\u9898", "@sunnysuhappy@jknair  you can try to import tensorflow.contrib explicitly", "`import tensorflow.contrib as contrib`\r\nand then use like this :\r\n`contrib.layers.xxx`\r\n`contrib.xx`\r\n\r\nPycharm autocomplete will be good then. "]}, {"number": 6516, "title": "fix spelling/insert correct reference to udacity notebook", "body": "This pull request corrects the spelling of the notebook *notmist.ipynb* -> `1_notmnist.ipynb` in notebook `3_regularization.ipynb`.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 6515, "title": "tensorboard fail to load summaries", "body": "Enviroment: Ubuntu14.04\r\ntensorflow installed with\r\n`sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl`\r\n\r\ntensorboard fails to load events, even with the tensorflow_root_path/models/image/cifar10/cifar10_train.py.\r\nrun `python cifar10_train.py`, [the event file](https://github.com/tensorflow/tensorflow/files/673591/event.zip)\r\n\r\n`tensorboard --logdir=/tmp/cifar_train` gives\r\n\r\n> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nStarting TensorBoard 39 on port 6006\r\n(You can navigate to http://127.0.1.1:6006)\r\n\r\nBut tensorboard did not load any summary\r\n![image](https://cloud.githubusercontent.com/assets/6497205/21490461/c543dccc-cc2f-11e6-920b-71e61fa20268.png)\r\n\r\n", "comments": ["Does this problem go away if you upgrade to the latest release?", "Solved. Thank you!"]}, {"number": 6514, "title": "tensorflow (0.12.0) doesn't work with libcudart.so.8.0.44", "body": "Hi\uff0c\r\nI'm using cuda-8.0 on centos7.3, and I install tensorflow(0.12.0)  with pip.\r\nwhen I tried to import tensorflow, it report \"ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory\".\r\nI'm sure libcudart.so.8.0 does exist. tensorflow-0.12.0 should works with cuda-8.0 according the docs.\r\n\r\n```\r\n# python -c 'import tensorflow'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\nImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n# ll  /usr/local/cuda/lib64/libcudart.so*\r\nlrwxrwxrwx. 1 root root     16 Dec 20 16:22 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx. 1 root root     19 Dec 20 16:22 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x. 1 root root 415432 Dec 20 16:22 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n# pip list|grep tensorflow\r\ntensorflow (0.12.0)\r\ntensorflow-gpu (0.12.0)\r\n```", "comments": ["TensorFlow only has official Ubuntu support.\r\nFor CentOS, we have not tested our pip packages.\r\n\r\nPossible issues that come to my mind, did you check your LD_LIBRARY_PATH, does it include the directory /usr/local/cuda/lib64/ ?\r\nIf not, could you try adding that folder to your LD_LIBRARY_PATH and try again?", "@gunan \r\nThanks. it's LD_LIBRARY_PATH's problem.\r\nAny plan official support TensorFlow on CentOS? ", "Not in our short term plans, but things may change.\r\nI am glad that we were able to resolve your problem."]}, {"number": 6513, "title": "Tensorboard AttributeError: 'module' object has no attribute 'cpu_count'", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nSome people report having similar problems with 'module' objects having no attribute something-or-other and claim they were solved by upgrading.\r\n\r\n### Environment info\r\nOperating System:\r\nUbuntu 17.04 x64\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n-rw-r--r-- 1 root root   558720 \u0441\u0435\u043d 15 02:02 /usr/local/cuda/lib64/libcudadevrt.a\r\n-rw-r--r-- 1 root root   383336 \u0434\u0435\u043a 23 01:26 /usr/local/cuda/lib64/libcudart.so\r\n-rw-r--r-- 1 root root   383336 \u0434\u0435\u043a 23 01:25 /usr/local/cuda/lib64/libcudart.so.7.5\r\nlrwxrwxrwx 1 root root       19 \u0434\u0435\u043a 23 02:17 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   415432 \u0441\u0435\u043d 15 02:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 \u0441\u0435\u043d 15 02:02 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 \u0434\u0435\u043a 23 02:17 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 \u0434\u0435\u043a 23 02:17 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 \u0434\u0435\u043a 22 04:25 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 \u0434\u0435\u043a 22 04:25 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\n```\r\n(yes, it's an unholy mess, with russian date format. sorry)\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: \r\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl\r\nas per[ instructions](https://www.tensorflow.org/get_started/os_setup)\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.0\r\n```\r\n\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```\r\ncd example; \r\npython /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py --logdir=/home/myname/example/log_simple_graph\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nSee above; I've tried to run the actual `tensorboard.py` instead of just `tensorboard --logdir=`\r\n\r\n### Logs or other output that would be helpful\r\nRunning `cd example; \r\npython /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py --logdir=/home/myname/example/log_simple_graph` results in:\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py\", line 34, in <module>\r\n    from tensorflow.tensorboard.backend import server\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/server.py\", line 37, in <module>\r\n    from tensorflow.tensorboard.backend import handler\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/handler.py\", line 43, in <module>\r\n    from tensorflow.tensorboard.plugins import REGISTERED_PLUGINS\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/__init__.py\", line 20, in <module>\r\n    from tensorflow.tensorboard.plugins.projector.plugin import ProjectorPlugin\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/projector/plugin.py\", line 27, in <module>\r\n    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py\", line 27, in <module>\r\n    from tensorflow.contrib import factorization\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/factorization/__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.factorization.python.ops.gmm import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/factorization/python/ops/gmm.py\", line 30, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/__init__.py\", line 66, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/__init__.py\", line 23, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py\", line 27, in <module>\r\n    from tensorflow.contrib.learn.python.learn import estimators\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py\", line 269, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators.classifier import Classifier\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/classifier.py\", line 25, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 52, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py\", line 26, in <module>\r\n    import dask.dataframe as dd\r\n  File \"/usr/local/lib/python2.7/dist-packages/dask/dataframe/__init__.py\", line 5, in <module>\r\n    from .io import (from_array, from_pandas, from_bcolz,\r\n  File \"/usr/local/lib/python2.7/dist-packages/dask/dataframe/io/__init__.py\", line 6, in <module>\r\n    from .csv import read_csv, to_csv, read_table\r\n  File \"/usr/local/lib/python2.7/dist-packages/dask/dataframe/io/csv.py\", line 147, in <module>\r\n    CPU_COUNT = psutil.cpu_count()\r\nAttributeError: 'module' object has no attribute 'cpu_count'\r\n\r\n```\r\n\r\n\r\nI've been following [this](https://www.oreilly.com/learning/hello-tensorflow) intro, and the code from there worked perfectly for me (apart from some warnings about deprecations).\r\n", "comments": ["As your logs show, the error is thrown due to a missing function call in psutil library.\r\nhttps://github.com/giampaolo/psutil/blob/master/HISTORY.rst#200\r\n\r\ncpu_count seems to be added in version 2.0.0 of psutil.\r\nSo running the following command should fix your problem:\r\n```\r\nsudo pip install --upgrade psutil\r\n```\r\nAlso the stacktrace shows that this is a call in `dask` library. So this issue is better reported to dask library.", "I tried upgrading `psutil`, but somehow that didn't work. Anyway, it does now. Thanks!", "Did you solve the problem? I have upgraded psutil, however, it didn't work. My OS is  ubuntu 14.04.", "@StrangeTcy how did you fix your problem? I came across  the same problem."]}]