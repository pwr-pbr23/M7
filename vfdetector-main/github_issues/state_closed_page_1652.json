[{"number": 3347, "title": "Cuda/Cudnn file name change break ./configure & Bazel build", "body": "- Ubuntu 16.04\n- Gtx 1080\n- Building master (614d4c19fb22df501ba16a3f580f4e3ac1a9df1a)\n- Cudnn 5 (Nvidia site download)\n- Cuda 8\n\nI've got the above mostly installed, except for Tensorflow itself.\n\nBut anyways, Nvidia seems to have changed the file names on this stuff, and it is not what Tensorflow's configure and Bazel are expecting.\n\nActual error message below:\n\n `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`\n\n```\nERROR: /home/john/.cache/bazel/_bazel_john/79381a0230f40e8d23e37c3a71bb0cd2/execroot/tensorflow/third_party/gpus/cuda/lib64/libcublas.so.8 cannot be found\n##############################################################################\nCuda 8 toolkit is missing.\n1. Download and install the CUDA 8 toolkit and CUDNN 5 library;\n```\n\nBut `ls /usr/llocal/cuda-8.0` looks like: \n\n`\nlibcublas.so\nlibcublas.so.8.0\nlibcublas.so.8.0.27\n`\n\nThis is the fourth time there has been a file name change using this Tensorflow commit or perhaps Cuda/Cudnn.\n\nI wouldn't mention this if it was one file change but it's at least 4.  May throw a bunch of beginners off.  Or perhaps I'm the beginner doing something wrong.\n\nJust something I ran into and seems like a Nvidia file naming change.\n", "comments": ["Ok, this seems to be about what I type in `./configure`.  Just change the version numbering when configuring to give Tensorflow what it's looking for.  Will close and maybe someone will run into this.\n"]}, {"number": 3346, "title": "Casting from real to complex lacks gradient", "body": "The operation of casting from `float32` to `complex64` lacks a gradient:\n\n```\n>>> x = tf.Variable(tf.zeros([10]))\n>>> tf.gradients(tf.cast(x, dtype=tf.complex64), x)\n[None]\n```\n\nSurely this is not intentional?\n\n(FWIW, I'm on Tensorflow 0.9.0, running on the CPU on OS X.)\n", "comments": ["I just realized that what I wanted is to be accomplished this way:\n\n```\n>>> x = tf.Variable(tf.zeros([10]))\n>>> tf.gradients(tf.complex(x, tf.zeros([10])), x)\n[<tf.Tensor 'gradients_4/Complex_5_grad/Real:0' shape=(10,) dtype=float32>]\n```\n", "The reason that there is no gradient in your first example is that complex numbers haven't been included in the gradient code for `tf.cast`.\nRight now it only returns a gradient if you convert between floats.\nThis is something that should be fixed, in my opinion.\nHere's the code that would need to be changed: https://github.com/tensorflow/tensorflow/blob/e95f4e760c6b6713b6b686ebeff9a1586a5831dd/tensorflow/python/ops/math_grad.py#L746\n", "Thanks!  I'll use the workaround for now, and if my schedule ever frees up, will try to submit a PR.\n", "Note that I'm not a googler, though (Just wanted to point out where the issue is so others won't have to search for it).\nSo it would be worth waiting until one of the core developers assigns the \"contributions welcome\" label.\n", "@whdc: Are you still planning to have a look at this?\nI can submit a quick fix if you're not planning to work on it.\n", "Please do! I've had too much to do!\n\nOn Monday, August 8, 2016, Igor Babuschkin notifications@github.com wrote:\n\n> @whdc https://github.com/whdc: Are you still planning to have a look at\n> this?\n> I can submit a quick fix if you're not planning to work on it.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3346#issuecomment-238230843,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABN7r9xO6ZXF-JJPJ-dmraZ6X8IWNNGAks5qdyvLgaJpZM4JOFE-\n> .\n", "I just realized that casting from/to complex numbers isn't actually supported by TensorFlow.\nIt will raise an error like\n\n```\nUnimplementedError: Cast float to complex64 is not supported\n```\n\nat runtime if you try to cast from/to complex numbers.\nThat also explains why the gradient for `cast` ignores complex numbers :(\n\n@vrv: Is there interest in supporting casting complex numbers?\nThis would mirror what can be done in `numpy`, for example with\n\n``` python\nIn [24]: np.cast['complex64']([1, 2, 3])\nOut[24]: array([ 1.+0.j,  2.+0.j,  3.+0.j], dtype=complex64)\n```\n\nor\n\n``` python\nIn [25]: np.array([1, 2, 3]).astype(np.complex64)\nOut[25]: array([ 1.+0.j,  2.+0.j,  3.+0.j], dtype=complex64)\n```\n", "Casting to complex numbers like numpy seems like a good idea!\n"]}, {"number": 3345, "title": "GPU implementation for RangeSampler and related samplers", "body": "The implementation for `RangeSampler` currently works only for the CPU, even though the sampling is done using `SimplePhilox` in most cases (which has GPU support). This issue is for tracking all changes to enable GPU support for the samplers.\n\nThis issue came into picture while digging for #1140, and affects it directly. Once GPU implementations are written for the samplers related to `RangeSampler`, float64 can easily be enabled for the `*Sampler` ops mentioned [here](https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-227012645).  Some more context can be found in [this comment](https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-232891827).\n", "comments": ["Automatically closing due to lack of recent activity. Please file a new issue referring to this issue, if the issue is still relevant and important. If this is documenting some kind of bug, be sure to use the latest version of TensorFlow. Thank you so much."]}, {"number": 3344, "title": "Tensorboard is failing to parse tfevents", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System:\nUbuntu 16.04\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nNo Cuda\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n'0.9.0'\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\n1.\n2.\n3.\n### What have you tried?\n\n1.I've followed the instructions on README and verified that tensorboard is pointing to the right directory and the log files are there\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nAs requested, the log file is supplied below\n[log.zip](https://github.com/tensorflow/tensorflow/files/367328/log.zip)\n", "comments": ["@danmane Could you take a look at this please?\n", "Can you run `tensorboard --inspect --logdir=XXXX` and report what it says?\n", "Here is the output from the --inspect command\n\n# \n\n# Processing event files... (this can take a few minutes)\n\nFound event files in:\n/home/bruno/Documents/Machine_Learning/Tensorflow/TensorFlow-Examples/notebooks/tmp/tensorflow_logs\n\nThese tags are in \n/home/bruno/Documents/Machine_Learning/Tensorflow/TensorFlow-Examples/notebooks/tmp/tensorflow_logs:\naudio -\nhistograms -\nimages -\nscalars\n\n#     xentropy_mean\n\nEvent statistics for \n/home/bruno/Documents/Machine_Learning/Tensorflow/TensorFlow-Examples/notebooks/tmp/tensorflow_logs:\naudio -\ngraph\n    first_step           0\n    last_step            0\n    max_step             0\n    min_step             0\n    num_steps            1\n    outoforder_steps     []\nhistograms -\nimages -\nscalars\n    first_step           10\n    last_step            650\n    max_step             650\n    min_step             10\n    num_steps            65\n    outoforder_steps     []\nsessionlog:checkpoint -\nsessionlog:start -\n\n# sessionlog:stop -\n\nOn 18/07/16 20:03, Daniel W Mane wrote:\n\n> Can you run |tensorboard --inspect --logdir=XXXX| and report what it says?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub \n> https://github.com/tensorflow/tensorflow/issues/3344#issuecomment-233425575, \n> or mute the thread \n> https://github.com/notifications/unsubscribe-auth/AGB5YXu30ujJc-obVkxiWLmXyHRuNCz5ks5qW84cgaJpZM4JOB61.\n", "Hmm, TensorBoard should display events when loaded against that directory, can you try again? I just inspected the logs you uploaded, and they contain no scalar summaries, so I think perhaps the situation has changed between when you filed the issue and uploaded logs, and when you ran the inspect command. \n", "Here it is. Looks pretty similar to me anyway\n\n# \n\n# Processing event files... (this can take a few minutes)\n\nFound event files in:\n/home/bruno/Documents/Machine_Learning/Tensorflow/TensorFlow-Examples/notebooks/tmp/tensorflow_logs\n\nThese tags are in \n/home/bruno/Documents/Machine_Learning/Tensorflow/TensorFlow-Examples/notebooks/tmp/tensorflow_logs:\naudio -\nhistograms -\nimages -\nscalars\n\n#     xentropy_mean\n\nEvent statistics for \n/home/bruno/Documents/Machine_Learning/Tensorflow/TensorFlow-Examples/notebooks/tmp/tensorflow_logs:\naudio -\ngraph\n    first_step           0\n    last_step            0\n    max_step             0\n    min_step             0\n    num_steps            1\n    outoforder_steps     []\nhistograms -\nimages -\nscalars\n    first_step           10\n    last_step            650\n    max_step             650\n    min_step             10\n    num_steps            65\n    outoforder_steps     []\nsessionlog:checkpoint -\nsessionlog:start -\n\n# sessionlog:stop -\n\nOn 19/07/16 16:20, Daniel W Mane wrote:\n\n> Hmm, TensorBoard should display events when loaded against that \n> directory, can you try again? I just inspected the logs you uploaded, \n> and they contain no scalar summaries, so I think perhaps the situation \n> has changed between when you filed the issue and uploaded logs, and \n> when you ran the inspect command.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub \n> https://github.com/tensorflow/tensorflow/issues/3344#issuecomment-233666479, \n> or mute the thread \n> https://github.com/notifications/unsubscribe-auth/AGB5YcwJaAjdSwLAE9yzPQU2A18RfbA8ks5qXOtFgaJpZM4JOB61.\n", "No, I mean can you verify that nothing is showing up in TensorBoard UI when loaded on that directory?\n", "To be clear: in the --inspect output you show, TensorBoard discovers scalar summaries, which I expect it would display. In the original log files you uploaded, there are no scalar summaries (and --inspect confirms that). So something has changed since you posted this issue.\n", "Thanks for the clarification and the instructions. As you can see, I'm a \nTensorflow noob. You're right that everything shows up as expected now \nand I'm really puzzled why it does since I changed nothing in the \ngraph/scalars or images but it seems to be working fine. I'm obviously \nmocking things up here and there but I have no idea how; in other words, \nI'm quite dangerous at this stage since I clearly don't know enough how \nto operate Tensorflow.\n\nThanks for you help\n\nOn 19/07/16 18:02, Daniel W Mane wrote:\n\n> To be clear: in the --inspect output you show, TensorBoard discovers \n> scalar summaries, which I expect it would display. In the original log \n> files you uploaded, there are no scalar summaries (and --inspect \n> confirms that). So something has changed since you posted this issue.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub \n> https://github.com/tensorflow/tensorflow/issues/3344#issuecomment-233698361, \n> or mute the thread \n> https://github.com/notifications/unsubscribe-auth/AGB5YfxEHohNX9HhiOLmVw7YwLDgTNbWks5qXQMlgaJpZM4JOB61.\n"]}, {"number": 3343, "title": "Can I export a gpu-trained model to a cpu-only machine for serving/evaluation?", "body": "I trained a model on a GPU machine.\nWhen l load such model on a cpu-only machine, I get the error below.\n![](https://raw.githubusercontent.com/3rduncle/DeepNLP/master/error.png)\n\nThank you for any suggestions!\n", "comments": ["@vrv Could you take a look at this please? Do we have such support now? Thanks.\n", "Yup, you can pass tf.ConfigProto(allow_soft_placement=True) to the tf.Session if you really want to ignore device placement directives in the graph.  I'm not a huge fan of using this option (I'd rather the graph be rewritten to strip out the device fields explicitly), but that should work.\n", "Also, in the future, StackOverflow is the right place to ask these questions.\n"]}, {"number": 3342, "title": "segfault after building from source with cuda 8, cudnn 4.0.7", "body": "### Environment info\n\nOperating System: Ubuntu 16.04 LTS (Linux thinkpad 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux)\n\nInstalled version of CUDA and cuDNN: CUDA 8.0, cuDNN 4.0.7\n\n``` bash\n$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root   560184 Jul 16 08:43 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Jul 16 08:43 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4\nlrwxrwxrwx 1 root root       17 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7\n-rwxr-xr-x 1 root root 61453024 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nIf installed from sources, provide the commit hash: e8aa19bd4fbcbbaeacb1f4f753e6c4f15dee1d9c\n\n``` bash\n~/GitHub/tensorflow $ git rev-parse HEAD\ne8aa19bd4fbcbbaeacb1f4f753e6c4f15dee1d9c\n```\n\nGraphics card: GeForce 940MX\n\nDriver version:  361.42\n### Steps to reproduce\n1. Install from sources with GPU support\n2. `import tensorflow`\n\n``` python\n>>> import tensorflow\n[1]    17461 segmentation fault (core dumped)  python\n```\n\nI'm not sure if it is the same / related to #2034. So I tried:\n\n``` python\n>>> import numpy\n>>> import tensorflow\n*** Error in `python': malloc(): memory corruption: 0x000000000202a2d0 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x77725)[0x7f1cb4ae4725]\n/lib/x86_64-linux-gnu/libc.so.6(+0x819be)[0x7f1cb4aee9be]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_malloc+0x54)[0x7f1cb4af05a4]\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_Znwm+0x18)[0x7f1c962b5e78]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd777a)[0x7f1c984e277a]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd78dc)[0x7f1c984e28dc]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd7a45)[0x7f1c984e2a45]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1cd997c)[0x7f1c984e497c]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1ceca98)[0x7f1c984f7a98]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x1ced92f)[0x7f1c984f892f]\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so(+0x77bee9)[0x7f1c96f86ee9]\n/lib64/ld-linux-x86-64.so.2(+0x104ea)[0x7f1cb50634ea]\n/lib64/ld-linux-x86-64.so.2(+0x105fb)[0x7f1cb50635fb]\n/lib64/ld-linux-x86-64.so.2(+0x15712)[0x7f1cb5068712]\n/lib64/ld-linux-x86-64.so.2(+0x10394)[0x7f1cb5063394]\n/lib64/ld-linux-x86-64.so.2(+0x14bd9)[0x7f1cb5067bd9]\n/lib/x86_64-linux-gnu/libdl.so.2(+0xf09)[0x7f1cb4869f09]\n/lib64/ld-linux-x86-64.so.2(+0x10394)[0x7f1cb5063394]\n/lib/x86_64-linux-gnu/libdl.so.2(+0x1571)[0x7f1cb486a571]\n/lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31)[0x7f1cb4869fa1]\npython(_PyImport_GetDynLoadFunc+0xf3)[0x522aa3]\npython(_PyImport_LoadDynamicModule+0x4f)[0x52264f]\npython[0x5c6815]\npython(PyEval_EvalFrameEx+0x68a)[0x4c41da]\npython(PyEval_EvalFrameEx+0x5dff)[0x4c994f]\npython(PyEval_EvalCodeEx+0x255)[0x4c22e5]\npython(PyEval_EvalCode+0x19)[0x4c2089]\npython(PyImport_ExecCodeModuleEx+0xcb)[0x4c019b]\npython[0x4bd24e]\npython[0x4afd2d]\npython(PyImport_ImportModuleLevel+0xd59)[0x4af969]\npython[0x4b10a8]\npython(PyObject_Call+0x43)[0x4b0de3]\npython(PyEval_CallObjectWithKeywords+0x30)[0x4ce140]\npython(PyEval_EvalFrameEx+0x31b1)[0x4c6d01]\npython(PyEval_EvalCodeEx+0x255)[0x4c22e5]\npython(PyEval_EvalCode+0x19)[0x4c2089]\npython(PyImport_ExecCodeModuleEx+0xcb)[0x4c019b]\npython[0x4bd24e]\npython[0x4be547]\npython[0x4afd2d]\npython(PyImport_ImportModuleLevel+0x8bd)[0x4af4cd]\npython[0x4b10a8]\npython(PyObject_Call+0x43)[0x4b0de3]\npython(PyEval_CallObjectWithKeywords+0x30)[0x4ce140]\npython(PyEval_EvalFrameEx+0x31b1)[0x4c6d01]\npython(PyEval_EvalCodeEx+0x255)[0x4c22e5]\npython(PyEval_EvalCode+0x19)[0x4c2089]\npython(PyImport_ExecCodeModuleEx+0xcb)[0x4c019b]\npython[0x4bd24e]\npython[0x4be547]\npython(PyImport_ImportModuleLevel+0x785)[0x4af395]\npython[0x4b10a8]\npython(PyObject_Call+0x43)[0x4b0de3]\npython(PyEval_CallObjectWithKeywords+0x30)[0x4ce140]\npython(PyEval_EvalFrameEx+0x31b1)[0x4c6d01]\npython(PyEval_EvalCodeEx+0x255)[0x4c22e5]\npython(PyEval_EvalCode+0x19)[0x4c2089]\npython[0x4f1e6f]\npython(PyRun_InteractiveOneFlags+0x199)[0x44c7b0]\npython(PyRun_InteractiveLoopFlags+0xc6)[0x44c575]\npython[0x42e91d]\npython(Py_Main+0x68a)[0x49e36a]\n======= Memory map: ========\n00400000-006e9000 r-xp 00000000 08:01 21502507                           /usr/bin/python2.7\n008e9000-008eb000 r--p 002e9000 08:01 21502507                           /usr/bin/python2.7\n008eb000-00962000 rw-p 002eb000 08:01 21502507                           /usr/bin/python2.7\n00962000-00985000 rw-p 00000000 00:00 0 \n017a3000-02035000 rw-p 00000000 00:00 0                                  [heap]\n7f1c90000000-7f1c90021000 rw-p 00000000 00:00 0 \n7f1c90021000-7f1c94000000 ---p 00000000 00:00 0 \n7f1c96020000-7f1c96027000 r-xp 00000000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so\n7f1c96027000-7f1c96226000 ---p 00007000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so\n7f1c96226000-7f1c96227000 r--p 00006000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so\n7f1c96227000-7f1c96228000 rw-p 00007000 08:01 1708545                    /lib/x86_64-linux-gnu/librt-2.23.so\n7f1c96228000-7f1c9639a000 r-xp 00000000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7f1c9639a000-7f1c9659a000 ---p 00172000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7f1c9659a000-7f1c965a4000 r--p 00172000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7f1c965a4000-7f1c965a6000 rw-p 0017c000 08:01 21503122                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7f1c965a6000-7f1c965aa000 rw-p 00000000 00:00 0 \n7f1c965aa000-7f1c96607000 r-xp 00000000 08:01 26751834                   /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\n7f1c96607000-7f1c96807000 ---p 0005d000 08:01 26751834                   /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\n7f1c96807000-7f1c9680a000 rw-p 0005d000 08:01 26751834                   /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\n7f1c9680a000-7f1c9680b000 rw-p 00000000 00:00 0 \n7f1c9680b000-7f1c9bba5000 r-xp 00000000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n7f1c9bba5000-7f1c9bda5000 ---p 0539a000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n7f1c9bda5000-7f1c9be4b000 r--p 0539a000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n7f1c9be4b000-7f1c9be4f000 rw-p 05440000 08:01 23869804                   /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n7f1c9be4f000-7f1c9c714000 rw-p 00000000 00:00 0 \n7f1c9c74c000-7f1c9c78c000 rw-p 00000000 00:00 0 \n7f1c9c78c000-7f1c9c802000 r-xp 00000000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so\n7f1c9c802000-7f1c9ca02000 ---p 00076000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so\n7f1c9ca02000-7f1c9ca03000 r--p 00076000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so\n7f1c9ca03000-7f1c9ca3e000 rw-p 00077000 08:01 21760526                   /usr/lib/python2.7/dist-packages/numpy/random/mtrand.x86_64-linux-gnu.so\n7f1c9ca3e000-7f1c9ca7f000 rw-p 00000000 00:00 0 \n7f1c9ca7f000-7f1c9ca88000 r-xp 00000000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so\n7f1c9ca88000-7f1c9cc87000 ---p 00009000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so\n7f1c9cc87000-7f1c9cc88000 r--p 00008000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so\n7f1c9cc88000-7f1c9cc89000 rw-p 00009000 08:01 21760740                   /usr/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.x86_64-linux-gnu.so\n7f1c9cc89000-7f1c9ccc9000 rw-p 00000000 00:00 0 \n7f1c9ccc9000-7f1c9ccca000 r-xp 00000000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so\n7f1c9ccca000-7f1c9cec9000 ---p 00001000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so\n7f1c9cec9000-7f1c9ceca000 r--p 00000000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so\n7f1c9ceca000-7f1c9cecb000 rw-p 00001000 08:01 21637140                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so\n7f1c9cecb000-7f1c9ceeb000 r-xp 00000000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so\n7f1c9ceeb000-7f1c9d0ea000 ---p 00020000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so\n7f1c9d0ea000-7f1c9d0eb000 r--p 0001f000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so\n7f1c9d0eb000-7f1c9d0ec000 rw-p 00020000 08:01 21634770                   /usr/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.x86_64-linux-gnu.so\n7f1c9d0ec000-7f1c9d6cc000 r-xp 00000000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3\n7f1c9d6cc000-7f1c9d8cc000 ---p 005e0000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3\n7f1c9d8cc000-7f1c9d8cd000 r--p 005e0000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3\n7f1c9d8cd000-7f1c9d8cf000 rw-p 005e1000 08:01 21508094                   /usr/lib/openblas-base/liblapack.so.3\n7f1c9d8cf000-7f1c9d8d2000 r-xp 00000000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so\n7f1c9d8d2000-7f1c9dad1000 ---p 00003000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so\n7f1c9dad1000-7f1c9dad2000 r--p 00002000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so\n7f1c9dad2000-7f1c9dad3000 rw-p 00003000 08:01 21634771                   /usr/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.x86_64-linux-gnu.so\n7f1c9dad3000-7f1c9db53000 rw-p 00000000 00:00 0 \n7f1c9db53000-7f1c9dd82000 r-xp 00000000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n7f1c9dd82000-7f1c9df81000 ---p 0022f000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n7f1c9df81000-7f1c9df9d000 r--p 0022e000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n7f1c9df9d000-7f1c9dfaa000 rw-p 0024a000 08:01 1708703                    /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\n7f1c9dfaa000-7f1c9dfae000 rw-p 00000000 00:00 0 \n7f1c9dfae000-7f1c9dfb4000 r-xp 00000000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so\n7f1c9dfb4000-7f1c9e1b3000 ---p 00006000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so\n7f1c9e1b3000-7f1c9e1b4000 r--p 00005000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so\n7f1c9e1b4000-7f1c9e1b5000 rw-p 00006000 08:01 21636955                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so\n7f1c9e1b5000-7f1c9e3b6000 rw-p 00000000 00:00 0 \n7f1c9e3b6000-7f1c9e3bd000 r-xp 00000000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4\n7f1c9e3bd000-7f1c9e5bc000 ---p 00007000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4\n7f1c9e5bc000-7f1c9e5bd000 r--p 00006000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4\n7f1c9e5bd000-7f1c9e5be000 rw-p 00007000 08:01 21503706                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4\n7f1c9e5be000-7f1c9e5dc000 r-xp 00000000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\n7f1c9e5dc000-7f1c9e7db000 ---p 0001e000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\n7f1c9e7db000-7f1c9e7dc000 r--p 0001d000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\n7f1c9e7dc000-7f1c9e7e0000 rw-p 0001e000 08:01 21637148                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\n7f1c9e7e0000-7f1c9e820000 rw-p 00000000 00:00 0 \n7f1c9e820000-7f1c9e8d4000 r-xp 00000000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so\n7f1c9e8d4000-7f1c9ead4000 ---p 000b4000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so\n7f1c9ead4000-7f1c9ead5000 r--p 000b4000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so\n7f1c9ead5000-7f1c9eadb000 rw-p 000b5000 08:01 21760674                   /usr/lib/python2.7/dist-packages/numpy/core/umath.x86_64-linux-gnu.so\n7f1c9eadb000-7f1c9eadd000 rw-p 00000000 00:00 0 \n7f1c9eadd000-7f1caaadd000 rw-p 00000000 00:00 0 \n7f1caaadd000-7f1caaade000 ---p 00000000 00:00 0 \n7f1caaade000-7f1cab2de000 rw-p 00000000 00:00 0 \n7f1cab2de000-7f1cad2de000 rw-p 00000000 00:00 0 \n7f1cad2de000-7f1cad2df000 ---p 00000000 00:00 0 \n7f1cad2df000-7f1cadadf000 rw-p 00000000 00:00 0 \n7f1cadadf000-7f1cadae0000 ---p 00000000 00:00 0 \n7f1cadae0000-7f1cae2e0000 rw-p 00000000 00:00 0 \n7f1cae2e0000-7f1cae2e1000 ---p 00000000 00:00 0 \n7f1cae2e1000-7f1caeae1000 rw-p 00000000 00:00 0 \n7f1caeae1000-7f1caeae2000 ---p 00000000 00:00 0 \n7f1caeae2000-7f1caf2e2000 rw-p 00000000 00:00 0 \n7f1caf2e2000-7f1caf2e3000 ---p 00000000 00:00 0 \n7f1caf2e3000-7f1cafae3000 rw-p 00000000 00:00 0 \n7f1cafae3000-7f1cafae4000 ---p 00000000 00:00 0 \n7f1cafae4000-7f1cb02e4000 rw-p 00000000 00:00 0 \n7f1cb02e4000-7f1cb02fa000 r-xp 00000000 08:01 1708431                    /lib/x86_64-linux-gnu/libgcc_s.so.1\n7f1cb02fa000-7f1cb04f9000 ---p 00016000 08:01 1708431                    /lib/x86_64-linux-gnu/libgcc_s.so.1\n7f1cb04f9000-7f1cb04fa000 rw-p 00015000 08:01 1708431                    /lib/x86_64-linux-gnu/libgcc_s.so.1\n7f1cb04fa000-7f1cb0538000 r-xp 00000000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0\n7f1cb0538000-7f1cb0737000 ---p 0003e000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0\n7f1cb0737000-7f1cb0738000 r--p 0003d000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0\n7f1cb0738000-7f1cb0739000 rw-p 0003e000 08:01 21503118                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0\n7f1cb0739000-7f1cb0862000 r-xp 00000000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0\n7f1cb0862000-7f1cb0a61000 ---p 00129000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0\n7f1cb0a61000-7f1cb0a62000 r--p 00128000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0\n7f1cb0a62000-7f1cb0a64000 rw-p 00129000 08:01 21503124                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0\n7f1cb0a64000-7f1cb28c8000 r-xp 00000000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so\n7f1cb28c8000-7f1cb2ac7000 ---p 01e64000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so\n7f1cb2ac7000-7f1cb2acd000 r--p 01e63000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so\n7f1cb2acd000-7f1cb2adf000 rw-p 01e69000 08:01 21508096                   /usr/lib/libopenblasp-r0.2.18.so\n7f1cb2adf000-7f1cb2af8000 rw-p 00000000 00:00 0 \n7f1cb2af8000-7f1cb2b53000 r-xp 00000000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3\n7f1cb2b53000-7f1cb2d53000 ---p 0005b000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3\n7f1cb2d53000-7f1cb2d58000 r--p 0005b000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3\n7f1cb2d58000-7f1cb2d59000 rw-p 00060000 08:01 21508092                   /usr/lib/openblas-base/libblas.so.3\n7f1cb2d85000-7f1cb2eed000 r-xp 00000000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so\n7f1cb2eed000-7f1cb30ec000 ---p 00168000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so\n7f1cb30ec000-7f1cb30ee000 r--p 00167000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so\n7f1cb30ee000-7f1cb30fb000 rw-p 00169000 08:01 21760683                   /usr/lib/python2.7/dist-packages/numpy/core/multiarray.x86_64-linux-gnu.so\n7f1cb30fb000-7f1cb310d000 rw-p 00000000 00:00 0 \n7f1cb310d000-7f1cb3132000 r-xp 00000000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9\n7f1cb3132000-7f1cb3331000 ---p 00025000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9\n7f1cb3331000-7f1cb3335000 r--p 00024000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9\n7f1cb3335000-7f1cb3336000 rw-p 00028000 08:01 1708563                    /lib/x86_64-linux-gnu/libtinfo.so.5.9\n7f1cb3336000-7f1cb3373000 r-xp 00000000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3\n7f1cb3373000-7f1cb3573000 ---p 0003d000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3\n7f1cb3573000-7f1cb3575000 r--p 0003d000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3\n7f1cb3575000-7f1cb357b000 rw-p 0003f000 08:01 1708542                    /lib/x86_64-linux-gnu/libreadline.so.6.3\n7f1cb357b000-7f1cb357c000 rw-p 00000000 00:00 0 \n7f1cb357c000-7f1cb3581000 r-xp 00000000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n7f1cb3581000-7f1cb3781000 ---p 00005000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n7f1cb3781000-7f1cb3782000 r--p 00005000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n7f1cb3782000-7f1cb3784000 rw-p 00006000 08:01 21637152                   /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n7f1cb3784000-7f1cb4143000 r--p 00000000 08:01 21502372                   /usr/lib/locale/locale-archive\n7f1cb4143000-7f1cb424b000 r-xp 00000000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so\n7f1cb424b000-7f1cb444a000 ---p 00108000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so\n7f1cb444a000-7f1cb444b000 r--p 00107000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so\n7f1cb444b000-7f1cb444c000 rw-p 00108000 08:01 1708463                    /lib/x86_64-linux-gnu/libm-2.23.so\n7f1cb444c000-7f1cb4465000 r-xp 00000000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8\n7f1cb4465000-7f1cb4664000 ---p 00019000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8\n7f1cb4664000-7f1cb4665000 r--p 00018000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8\n7f1cb4665000-7f1cb4666000 rw-p 00019000 08:01 1708582                    /lib/x86_64-linux-gnu/libz.so.1.2.8\n7f1cb4666000-7f1cb4668000 r-xp 00000000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so\n7f1cb4668000-7f1cb4867000 ---p 00002000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so\n7f1cb4867000-7f1cb4868000 r--p 00001000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so\n7f1cb4868000-7f1cb4869000 rw-p 00002000 08:01 1708572                    /lib/x86_64-linux-gnu/libutil-2.23.so\n7f1cb4869000-7f1cb486c000 r-xp 00000000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so\n7f1cb486c000-7f1cb4a6b000 ---p 00003000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so\n7f1cb4a6b000-7f1cb4a6c000 r--p 00002000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so\n7f1cb4a6c000-7f1cb4a6d000 rw-p 00003000 08:01 1708417                    /lib/x86_64-linux-gnu/libdl-2.23.so\n7f1cb4a6d000-7f1cb4c2d000 r-xp 00000000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so\n7f1cb4c2d000-7f1cb4e2c000 ---p 001c0000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so\n7f1cb4e2c000-7f1cb4e30000 r--p 001bf000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so\n7f1cb4e30000-7f1cb4e32000 rw-p 001c3000 08:01 1708395                    /lib/x86_64-linux-gnu/libc-2.23.so\n7f1cb4e32000-7f1cb4e36000 rw-p 00000000 00:00 0 \n7f1cb4e36000-7f1cb4e4e000 r-xp 00000000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so\n7f1cb4e4e000-7f1cb504d000 ---p 00018000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so\n7f1cb504d000-7f1cb504e000 r--p 00017000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so\n7f1cb504e000-7f1cb504f000 rw-p 00018000 08:01 1708537                    /lib/x86_64-linux-gnu/libpthread-2.23.so\n7f1cb504f000-7f1cb5053000 rw-p 00000000 00:00 0 \n7f1cb5053000-7f1cb5079000 r-xp 00000000 08:01 1708367                    /lib/x86_64-linux-gnu/ld-2.23.so\n7f1cb5094000-7f1cb5154000 rw-p 00000000 00:00 0 \n7f1cb5185000-7f1cb524a000 rw-p 00000000 00:00 0 \n7f1cb526d000-7f1cb526e000 rw-p 00000000 00:00 0 \n7f1cb526e000-7f1cb526f000 rwxp 00000000 00:00 0 \n7f1cb526f000-7f1cb5276000 r--s 00000000 08:01 21890355                   /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache\n7f1cb5276000-7f1cb5278000 rw-p 00000000 00:00 0 \n7f1cb5278000-7f1cb5279000 r--p 00025000 08:01 1708367                    /lib/x86_64-linux-gnu/ld-2.23.so\n7f1cb5279000-7f1cb527a000 rw-p 00026000 08:01 1708367                    /lib/x86_64-linux-gnu/ld-2.23.so\n7f1cb527a000-7f1cb527b000 rw-p 00000000 00:00 0 \n7fffb822d000-7fffb824e000 rw-p 00000000 00:00 0                          [stack]\n7fffb82ba000-7fffb82bc000 r--p 00000000 00:00 0                          [vvar]\n7fffb82bc000-7fffb82be000 r-xp 00000000 00:00 0                          [vdso]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\n[1]    17517 abort (core dumped)  python\n```\n\n```\n$ gdb python\nrun tf.py\n```\n\nwith `tf.py`:\n\n```\nimport tensorflow as tf\n```\n\ngives\n\n```\n(gdb) run tf.py\nStarting program: /usr/bin/python tf.py\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n[New Thread 0x7ffff3234700 (LWP 17850)]\n[New Thread 0x7ffff2a33700 (LWP 17851)]\n[New Thread 0x7ffff0232700 (LWP 17852)]\n[New Thread 0x7fffeda31700 (LWP 17853)]\n[New Thread 0x7fffe9230700 (LWP 17854)]\n[New Thread 0x7fffe6a2f700 (LWP 17855)]\n[New Thread 0x7fffe422e700 (LWP 17856)]\n\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\n0x00007ffff786f5a1 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n```\n", "comments": ["@martinwicke Could you take a look at this please?\n", "I've just installed CUDA 7.5 and TF rc0.7. So I will not be able to reproduce this error.\n", "With the latest TensorFlow, the safest thing to use is Cuda 7.5 and Cudnn 5.0. \n\nPlease let us know if that works. \n", "I'll close this issue since @MartinThoma has already downgraded. Maybe the combination of cuda 8 + cudnn 4.0.7 may not be safe?\n"]}, {"number": 3341, "title": "undefined reference to `tensorflow::strings::StrAppend", "body": "### Environment info\n\nOperating System: Ubuntu 16.04 LTS (Linux thinkpad 4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux)\n\nInstalled version of CUDA and cuDNN: CUDA 8.0, cuDNN 4.0.7\n\n``` bash\n$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root   560184 Jul 16 08:43 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Jul 16 08:43 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Jul 16 08:43 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4\nlrwxrwxrwx 1 root root       17 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7\n-rwxr-xr-x 1 root root 61453024 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Jul 16 09:02 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nIf installed from sources, provide the commit hash: d2c913aa9b7cb63e466392f76d46ac5fbc1e9825\n\n``` bash\n~/GitHub/tensorflow $ git rev-parse HEAD\nd2c913aa9b7cb63e466392f76d46ac5fbc1e9825\n```\n### Steps to reproduce\n1. Clone the tensorflow repository\n2. `./configure` (with GPU)\n3. `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`\n### What I tried\n\nWhen I tried to build it, I got:\n\n``` bash\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::RecordTensorAllocation(std::string const&, long long, tensorflow::Tensor const&)':\nlog_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x4a): undefined reference to `google::protobuf::internal::empty_string_'\nlog_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x8c): undefined reference to `google::protobuf::Message::GetTypeName() const'\nlog_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x11b): undefined reference to `tensorflow::ProtoShortDebugString(tensorflow::MemoryLogTensorAllocation const&)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_kernel.o): In function `tensorflow::ValidateKernelRegistrations(tensorflow::OpRegistryInterface const&)':\nop_kernel.cc:(.text._ZN10tensorflow27ValidateKernelRegistrationsERKNS_19OpRegistryInterfaceE+0x92): undefined reference to `tensorflow::ProtoShortDebugString(tensorflow::KernelDef const&)'\nop_kernel.cc:(.text._ZN10tensorflow27ValidateKernelRegistrationsERKNS_19OpRegistryInterfaceE+0x2d8): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(types.o): In function `tensorflow::DataTypeString(tensorflow::DataType)':\ntypes.cc:(.text._ZN10tensorflow14DataTypeStringENS_8DataTypeE+0x81): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_gen_lib.o): In function `tensorflow::WordWrap(tensorflow::StringPiece, tensorflow::StringPiece, int)':\nop_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0xde): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'\nop_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0x1bf): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'\nop_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0x242): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'\nop_gen_lib.cc:(.text._ZN10tensorflow8WordWrapENS_11StringPieceES0_i+0x27f): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(tensor_shape.o): In function `tensorflow::TensorShape::DebugString() const':\ntensor_shape.cc:(.text._ZNK10tensorflow11TensorShape11DebugStringEv+0x124): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\ntensor_shape.cc:(.text._ZNK10tensorflow11TensorShape11DebugStringEv+0x178): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\nbazel-out/host/bin/tensorflow/core/libframework_internal.lo(tensor_shape.o): In function `tensorflow::TensorShape::DebugString(tensorflow::TensorShapeProto const&)':\ntensor_shape.cc:(.text._ZN10tensorflow11TensorShape11DebugStringERKNS_16TensorShapeProtoE+0xf6): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'\ntensor_shape.cc:(.text._ZN10tensorflow11TensorShape11DebugStringERKNS_16TensorShapeProtoE+0x11d): undefined reference to `tensorflow::strings::StrAppend(std::string*, tensorflow::strings::AlphaNum const&)'\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n```\n\nAny ideas what the problem could be / why I get this?\n", "comments": ["I just tried it again with e8aa19bd4fbcbbaeacb1f4f753e6c4f15dee1d9c:\n\n``` bash\nINFO: From Compiling tensorflow/cc/tutorials/example_trainer.cc:\nIn file included from bazel-out/local_linux-opt/genfiles/tensorflow/cc/ops/array_ops.h:8:0,\n                 from ./tensorflow/cc/ops/standard_ops.h:19,\n                 from tensorflow/cc/tutorials/example_trainer.cc:21:\n./tensorflow/cc/framework/ops.h: In instantiation of 'tensorflow::ops::Input::Initializer::Initializer(const std::initializer_list<_Tp>&, const tensorflow::TensorShape&) [with T = int; <template-parameter-1-2> = void]':\nbazel-out/local_linux-opt/genfiles/tensorflow/cc/ops/logging_ops.h:192:70:   required from here\n./tensorflow/cc/framework/ops.h:119:27: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n       if (t.NumElements() != v.size()) {\n                           ^\nTarget //tensorflow/cc:tutorials_example_trainer up-to-date:\n  bazel-bin/tensorflow/cc/tutorials_example_trainer\nINFO: Elapsed time: 1579.289s, Critical Path: 1575.08s\n```\n\nI'm not sure what changed, but now it seems to work.\n"]}, {"number": 3340, "title": "cannot save/restore contrib.learn.DNNClassifier", "body": "Hi , i been struggling some days trying to save a contrib.learn.DNNClassifier and im getting desperate can you help me? I tried everything it says in official documentation, but it sees as if the documentation isnt coherent with the API, things i have tried are:\n- rain.Saver() ,but got a \"No variables to save\" error \n- tried https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn this examples, created my DNNClassifier but when trying to call function save() on my classifier , it says 'DNNClassifier' object has no attribute 'save'\n- Tried the deprecated class TensorflowDNNClassifier and it can be saved right ,but when you try to restore it ,it says that theres no model to restore.\n- Tried to restore the saved TensorflowDNNClassifier with Estimator.restore() but it says that Estimator has no attribute restore.\n\nIs there a way to save and restore a DNNClassifier? This question is asked multiple times in stackoverflow and in https://gitter.im/tensorflow/skflow\n\nI would be very thankfull if you can help me.\n", "comments": ["@llealgt Thanks for reporting. I believe you are not able to restore at this moment. There are checkpoint loading util functions but they are not integrated with estimators yet. \n@martinwicke Any ideas on what's the timing on those? Many people are having this issue. \n", "Hello guys , any news on this ? :) \n", "Actually, I missed this earlier but you can restore by specifying same model_dir when you call the constructor and it will load the saved model for you. Let me know if that solves your issue. Thanks. \n", "Similarly trying to figure this one out using the example here using a DNNClassifier:\nhttps://www.tensorflow.org/versions/r0.9/tutorials/tflearn/index.html\n\nIt looks like the answer currently provided is only for deprecated TensorflowDNNClassifier (as it pertained to restore only) and does not address the initial question of saving and restoring the new DNNClassifier.\n\nIs the functionality for the DNNClassifier to be saved and restored currently in place?  If so, could we see an example and/or be pointed to the documentation where this is explained?\n", "Check master version of the doc and use what I described above. \n", "Couldn't find anything in the docs that actually explains the behavior but it looks like as long as you have the model_dir in the constructor it is automatically saved and/or restored with nothing else needing to be done.\n", "Yeah it needs to be updated/clarified\n\nOn Tuesday, July 19, 2016, SuperJonotron notifications@github.com wrote:\n\n> Couldn't find anything in the docs that actually explains the behavior but\n> it looks like as long as you have the model_dir in the constructor it is\n> automatically saved and/or restored with nothing else needing to be done.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3340#issuecomment-233831046,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AEEnSlO3k7YGJfVquvwt6OseW-KJ_Hixks5qXZohgaJpZM4JN8cS\n> .\n", "Thank you guys , i tested it and it seems as it works, my test was: created a DNNClassifier specifiyng model_dir on constructor, fit(), used get_variable_value to wet weights of the last layer , created another DNNClassifier using the same model_dir in constructor, used get_variable_value and the same weights were printed, so i worked as you said, but now i have some additional questions\nin this case from what i saw, you can \"pause\" and \"resume\" training using the files generated, what happens if you are training and power goes off or something happens? does it stores multiple checkpoints and will use last one? Creating a model and traing with for example 100 steps, and then restoring it with this method and training another 100 steps is equivalent to training 200 steps from the beggining?\n\nNow my other question is, i trained using model_dir, then created another model with the same model_dir to restore it, but when tried predict with the restored model i got the eerror : ValueError: Either linear_feature_columns or dnn_feature_columns should be defined.\nSo i had to train 5 steps and then predict, is there a way to restore and predict without having to do this \"dummy training\" ? Can you get the total count of training steps using .get_variable_value () ? And the last one: can you create a multi-output classifier? like sending a list or array of outputs when you train, and then get a list of the same size when you predict?\n", "Right now, there isn't a way to restore and predict without running at least one step of training (which is a missing feature). \n\nYou can get the value of `global_step` (which is the total number of training steps).\n\nWe're working on a multi-headed classififer.\n", "Thank you guys! This answers will help me on my current task. Greetings!\n", "Closing for now. @martinwicke please open a separate issue if you want to track the feature of restoring without predicting.\n", "I am using v0.10 and did learn.DNNRegressor(..., model_dir='some path') and then \nnew_regressor = learn.DNNRegressor('path where the model is') and got the error\n\n```\ntensorflow.contrib.learn.python.learn.estimators._sklearn.NotFittedError: Couldn't find trained model at /var/folders/yf/gdqcvwpd67j98_zn92qy3bl80000gn/T/tmpjp19wmrx.\n```\n\nwhile doing new_regressor.predict(some data). \nI checked the path and the model indeed is saved. \n", "Hi, I've faced with the same problem.\r\nThe only Estimator that have  save/restore methods are TensorFlowEstimator and it is deprecated and restore method throws  `NotImplementedError`\r\n @terrytangyuan Thank you for advising using the same model_dirrectory for restoring model.\r\nBut I've faced with problem, that when restoring model from directory - it is also necessary to set (somehow) `self._targets_info ` to initialize `target` variable in `tensorflow.contrib.learn.python.learn.estimators.estimator.Estimator#_get_predict_ops` method\r\n\r\nI've found the only way how to do it: use  `classifier.fit` method with **step=0**\r\n\r\nSo this is how my restore method looks like:\r\n```\r\nclassifier = learn.Estimator(model_fn=myModel,model_dir=modelPath)\r\nclassifier.fit(train, target , steps=0)\r\nclassifier.predict(textForClassification,  as_iterable=True)\r\n```\r\n`train` can be empty, but dimentional must be equal to initial,  `target`  - must contain target classes for classification\r\n\r\n\r\n\r\n", "I have a extended question: how can i restore a DNNClassifier from a checkpoint", "Just give the directory containing the checkpoint to its constructor.", "using classifier = learn.DNNClassifier how can we get a saved_model.pb instead of grapg.pbtxt ... ?\r\n\r\nIn another words using learn.DNNClassifier how can we save the model in python and then use the files in tensorflow for Java ?  (using SavedModelBundle.load()  )\r\nthis functions require for a \"saved_model.pb\" or saved_model.pbtxt\" to be on the directory.\r\n\r\ndefining a \"model_dir\" in DNNClassifier in python does not produce a saved_model.pbtxt file it generate a graph.pbtxt file but even if I rename it to saved_model.pbtxt it will not open in tensorflow for java.\r\n\r\nI have test saving models in .pbtxt file and the load in Java  worked. But using \r\ntensorflow.contrib.learn.DNNClassifier\r\n\r\nI dont see how to get a model_saved.pbtxt file to load in Java ... \r\n\r\n\r\n", "Use the export_savedmodel method to export a SavedModel. Look at, or post to StackOverflow if you have trouble.", "hello,\r\n\r\nthe problem using export method is understanding what serving_input_fn is and how to define it.\r\n\r\nI still dont know what it is (if there is some documentation about it I would be  grateful).\r\n\r\nI mange to use export using the following lines (dont know for sure is that is correct ...) :\r\n`\r\ntfrecord_serving_input_fn = tf.contrib.learn.build_parsing_serving_input_fn(layers.create_feature_spec_for_parsing(feature_columns))  \r\n\r\nclassifier.export_savedmodel(export_dir_base=\"test\", serving_input_fn = tfrecord_serving_input_fn,as_text=True)\r\n`\r\n\r\nNow the model_saved.pbtxt is loaded in java.\r\n\r\nusing :\r\n\r\n`SavedModelBundle bundle= SavedModelBundle.load(\"/java/workspace/APIJavaSampleCode/tfModels/dnn/ModelSave\",\"serve\");`\r\n\r\nThen I had another problem ... to execute the model we need to pass strings to say what is the input and output \"operation\". \r\n\r\nSomeone told me (on youtube) they are \"input_example_tensor\" and ouput \"dnn/multi_class_head/predictions/probabilities\". Dont know how they discover this (?).\r\n(again if there is some documentation about it I would be  grateful)\r\nSo the code I have in java for the moment is this :\r\n\r\n`\r\n\tSavedModelBundle bundle=SavedModelBundle.load(\"/java/workspace/APIJavaSampleCode/tfModels/dnn/ModelSave\",\"serve\");\r\n\t\tSession s = bundle.session();\r\n\t\t\r\n\t\tdouble[] inputDouble = {1.0,0.7982741870963959,1.0,-0.46270838239235024,0.040320274521029376,0.443451913224413,-1.0,1.0,1.0,-1.0,0.36689718911339564,-0.13577379160035796,-0.5162916256414466,-0.03373651520104648,1.0,1.0,1.0,1.0,0.786999801054777,-0.43856035121103853,-0.8199093927945158,1.0,-1.0,-1.0,-0.1134921695894473,-1.0,0.6420892436196663,0.7871737734493178,1.0,0.6501788845358409,1.0,1.0,1.0,-0.17586627413625022,0.8817194210401085};\r\n\t\tfloat [] inputfloat=new float[inputDouble.length];\r\n\t\tfor(int i=0;i<inputfloat.length;i++)\r\n\t\t{\r\n\t\t\tinputfloat[i]=(float)inputDouble[i];\r\n\t\t}\r\n\t\tTensor inputTensor = Tensor.create(new long[] {35}, FloatBuffer.wrap(inputfloat) );\r\n\t\t\r\n\t\tTensor result = s.runner()\r\n\t            .feed(\"input_example_tensor\", inputTensor)\r\n\t            .fetch(\"dnn/multi_class_head/predictions/probabilities\")\r\n\t            .run().get(0);\r\n\t\t\r\n`\r\n\r\nNow  I have the following error on java side :\r\n\r\n`\r\nException in thread \"main\" org.tensorflow.TensorFlowException: Output 0 of type float does not match declared output type string for node _recv_input_example_tensor_0 = _Recv[_output_shapes=[[-1]], client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-5952653602839817343, tensor_name=\"input_example_tensor:0\", tensor_type=DT_STRING, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()\r\n\tat org.tensorflow.Session.run(Native Method)\r\n\tat org.tensorflow.Session.access$100(Session.java:48)\r\n\tat org.tensorflow.Session$Runner.runHelper(Session.java:285)\r\n\tat org.tensorflow.Session$Runner.run(Session.java:235)\r\n...\r\n`\r\n\r\nAny suggestion to overcame this error (I hope the last challenging problem to execute a  DNNClassifier, made in python, in java )  ?\r\n\r\nthanks in advance \r\n", "Hi\r\n\r\nI've been following the Estimator tutorial https://www.tensorflow.org/extend/estimators and it works, but now that i want to save the model I can\u00b4t find a way to do it.\r\n I am using export_savedmodel but i can't generate a serving input function. I've tried doing it this way:\r\n\r\n```\r\nfrom tensorflow.contrib.layers import create_feature_spec_for_parsing\r\nfeature_spec = create_feature_spec_for_parsing(feature_columns)\r\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils\r\nsif = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\r\nnn.export_savedmodel(export_dir_base='PATH',serving_input_fn=sif)\r\n```\r\nBut i don't know what values to use in feature_columns variable, because the tutorial says that our features are our input data.\r\n\r\nCan you help me figuring this out?\r\n", "on my script I have something like this that I have found on the net (and it works ): \r\n\r\n```\r\n#Save Model into saved_model.pbtxt file (possible to Load in Java)\r\ntfrecord_serving_input_fn = tf.contrib.learn.build_parsing_serving_input_fn(layers.create_feature_spec_for_parsing(feature_columns))  \r\nclassifier.export_savedmodel(export_dir_base=\"test\", serving_input_fn = tfrecord_serving_input_fn,as_text=True)\r\n\r\n```\r\n", "Thanks for the reply\r\n\r\nI checked the code lines but in this one\r\n\r\n`tfrecord_serving_input_fn = tf.contrib.learn.build_parsing_serving_input_fn(layers.create_feature_spec_for_parsing(feature_columns))`\r\n\r\nWhat is the value that 'feature_columns' holds?\r\nThat's what i don't quite understand. In the classifier example we do have a variable called 'feature_columns' and it is the combination of 'wide_columns + deep_columns'.\r\n\r\nNow, for the estimator example we don't have the 'feature_columns' variable.  So i tried to use my input data as my features as it says in the tutorial, but that doesn't seem to be working.\r\n\r\nI also tried using\r\n\r\n `feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input_data)`\r\n\r\nbut that does not work either. I got the following error:\r\n\r\n`TypeError: Expected binary or unicode string, got {'': <tf.Tensor 'ParseExample/ParseExample:0' shape=(?, 9) dtype=float32>}`\r\n\r\nAm I doing something wrong?", "`feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=train_inputs.shape[1])]`\r\n\r\nit's the size of the inputs ", "I also had trouble with save and freeze DNNclassifier model. I try to freeze the model generate in the tensorflow tutorial:\r\nhttps://www.tensorflow.org/get_started/estimator\r\n\r\nThe model generate files in /tmp/iris_model:\r\n\r\n```\r\n    checkpoint\r\n    eval\r\n    events.out.tfevents.1516649318.xavier-OMEN-by-HP-Laptop\r\n    graph.pbtxt\r\n    model.ckpt-10.data-00000-of-00001\r\n    model.ckpt-10.index\r\n    model.ckpt-10.meta\r\n    model.ckpt-1.data-00000-of-00001\r\n    model.ckpt-1.index\r\n    model.ckpt-1.meta\r\n\r\n```\r\n\r\nWhen I try to freeze the model with the tools in tensorflow source I get that error:\r\n\r\n```\r\n`    python3 ./tensorflow/tensorflow/python/tools/freeze_graph.py /tmp/iris_model checkpoint '' doesn't exist!\r\n`\r\n```\r\n\r\n\r\n", "Does anyone know how to restore a trained DNNclassifier and use it on a new data set please? I tried this \r\n\r\n```\r\nx={\"x\": np.array(test_set.data)}\r\n\r\nwith tf.Session() as sess:    \r\n    saver = tf.train.import_meta_graph(base_dir+\"Neural Net Final Dictionary/tmp checkpoints/\"+'model.ckpt-5000.meta')\r\n    saver.restore(sess,tf.train.latest_checkpoint(base_dir+\"Neural Net Final Dictionary/tmp checkpoints/\"))\r\n    graph = tf.get_default_graph()\r\n    sess.run(graph,feed_dict={'x:0':np.array(test_set.data)})\r\n```\r\n\r\n\r\nI got the error saying \r\n\r\n`TypeError: Cannot interpret feed_dict key as Tensor: The name 'x:0' refers to a Tensor which does not exist. The operation, 'x', does not exist in the graph.\u201d \r\n`\r\n\r\nDoes anyone know what's wrong here? \r\n\r\nThanks!", "Assuming you have the following code (or something like it):\n\n...\nestimator = DNNClassifier(model_dir=/path/to/files, ...)\ntf.train_and_evaluate(estimator, ...)\n\nyou can use it on a new dataset using\n\nestimator = DNNClassifier(model_dir=/path/to/files, ...)\nresult = estimator.predict(input_fn=new_dataset_input_fn)\n\nas long as you point it to the same directory, and you use the same\nconstructor arguments, the resulting Estimator will be what you want.\n\nFrom here, you can also take a look at contrib/predictor which makes it\nmore convenient to run inference.\n\nOn Wed, Apr 4, 2018 at 12:27 PM JackKZ <notifications@github.com> wrote:\n\n> Does anyone know how to restore a trained DNNclassifier and use it on a\n> new data set please? I tried this\n>\n> `x={\"x\": np.array(test_set.data)}\n>\n> with tf.Session() as sess:\n> saver = tf.train.import_meta_graph(base_dir+\"Neural Net Final\n> Dictionary/tmp checkpoints/\"+'model.ckpt-5000.meta')\n> saver.restore(sess,tf.train.latest_checkpoint(base_dir+\"Neural Net Final\n> Dictionary/tmp checkpoints/\"))\n> graph = tf.get_default_graph()\n> sess.run(graph,feed_dict={'x:0':np.array(test_set.data)})\n> `\n>\n> I got the error saying\n>\n> TypeError: Cannot interpret feed_dict key as Tensor: The name 'x:0' refers\n> to a Tensor which does not exist. The operation, 'x', does not exist in the\n> graph.\u201d\n>\n> Does anyone know what's wrong here?\n>\n> Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3340#issuecomment-378716437>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAjO_bfKh4DzChN6vFYKpA-6zmDbkzvDks5tlR6YgaJpZM4JN8cS>\n> .\n>\n", "Thanks a lot Martin! That solves my problem perfectly! ", "I went through past comments, but I'm still having trouble trying to save and restore a **trained** model from this tutorial (https://www.tensorflow.org/get_started/get_started_for_beginners) to be used for prediction. \r\n\r\nCould anyone please show the code on how to do it?", "I was facing many issues while restoring and saving , finally here is working Ipython notebook with data\r\nhttps://github.com/monk1337/DNNClassifier-example"]}, {"number": 3339, "title": "Branch 127608996", "body": "", "comments": []}, {"number": 3338, "title": "Tensorflow build error on the Macbook docker ", "body": "In my MacBook(using docker) has a built in Tensorflow source.\nThe error occurred during the build.\n### Environment info\n\nOperating System: OSX, El Capitan\nUsing Docker & tensor flow docker image :  tensorflow/tensorflow:latest-devel\n### Steps to reproduce\n1. checking bazel & update\n2. download a new tensorflow source\n3. ./configure   --> No GPU...\n4. build bazel to pip\n   --> bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\n### Build error\n\n> ERROR: /tensorflow/tensorflow/core/kernels/BUILD:1694:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections ... (remaining 107 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.\n> gcc: internal compiler error: Killed (program cc1plus)\n> Please submit a full bug report,\n> with preprocessed source if appropriate.\n> <img width=\"990\" alt=\"2016-07-16 12 07 46\" src=\"https://cloud.githubusercontent.com/assets/547925/16892518/445d0698-4b50-11e6-946e-36b90c2d8ea6.png\">\n> \n> See file:///usr/share/doc/gcc-4.8/README.Bugs for instructions.\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\n#### Include option(--verbose_failures) build err:\n\n  bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures\n\n> ERROR: /tensorflow/tensorflow/core/kernels/BUILD:1078:1: C++ compilation of rule '//tensorflow/core/kernels:argmax_op' failed: gcc failed: error executing command\n>   (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/tensorflow && \\\n>   exec env - \\\n>     PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\n>   /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -DHAVE_CONFIG_H -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/gif_archive/giflib-5.1.4/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/giflib-5.1.4/lib -isystem external/highwayhash -isystem bazel-out/local_linux-opt/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-b4fa9622b809 -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive/zlib-1.2.8 -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.d -fPIC -c tensorflow/core/kernels/argmax_op.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/argmax_op/tensorflow/core/kernels/argmax_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.\n> gcc: internal compiler error: Killed (program cc1plus)\n> Please submit a full bug report,\n> with preprocessed source if appropriate.\n> See file:///usr/share/doc/gcc-4.8/README.Bugs for instructions.\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\n> INFO: Elapsed time: 3619.233s, Critical Path: 3589.94s\n\n<img width=\"1246\" alt=\"2016-07-16 2 48 52\" src=\"https://cloud.githubusercontent.com/assets/547925/16893041/8d3c4fb8-4b64-11e6-8d8f-0557e9128b1f.png\">\n", "comments": ["can you run it again with `--verbose_failures` ? \n`bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures`\n", "@Mistobaan No, I don't try again ....\nNow, I'm running again. Thank U!!!  \n", "Updated a error log.\nHow do I bug report.\n", "@caisq Could you take a look at this please?\n", "This gcc internal compiler error appears to be an out-of-memory event; I experienced this using Ubuntu 14.04.5 in a VMware Fusion VM on Mac OS X with the default 1024MB of memory assigned. Increasing VM memory to 8192MB yielded a successful build.\n", "Looks like the there is an explanation here.\r\nClosing the issue for now. Please reopen if the above suggestion wont resolve the problem for you.\r\n\r\nAlso, the error message suggests you should report a gcc bug, so I am assuming this is a gcc bug."]}, {"number": 3337, "title": "Added missing files and clarified documentation", "body": "Addresses the confusing documentation that caused #3327, and added new files to the Makefile sources.\n", "comments": ["@tensorflow-jenkins test this please\n"]}, {"number": 3336, "title": "Branch 127592611", "body": "", "comments": ["@tensorflow-jenkins test this please\n"]}, {"number": 3335, "title": "Branch 127588880", "body": "", "comments": []}, {"number": 3334, "title": "tf.case doesn't preserve shape information", "body": "tf.case is a python implementation of a case statement using tf.cond, but unlike cond it doesn't preserve shape information when executing. This is because of this little snippet:\n\n``` python\n...\n    # preds = [p1, p2, p3]\n    # fns = [f1, f2, f3]\n    # not_preds = [~p1, ~p2, ~p3]\n    # and_not_preds = [True, ~p1, ~p1 & ~p2, ~p1 & ~p2 & ~p3]\n    # case_preds = [p1,\n    #               p2 & ~p1,\n    #               p3 & ~p2 & ~p1,\n    #              ~p3 & ~p2 & ~p1]\n\n    case_preds = []\n    for i, (p, and_not_p_prev) in enumerate(zip(preds, and_not_preds[:-1])):\n      with ops.name_scope(\"case_%d\" % i):\n        case_preds.append(math_ops.logical_and(p, and_not_p_prev))\n    with ops.name_scope(\"case_none_are_true\"):\n      case_preds.append(and_not_preds[-1])\n\n    # Create an empty tensor, or list, with the right type and shape\n    with ops.name_scope(\"case_create_empty\"):\n      dummy_value = default()\n      def _correct_empty(v):\n        if isinstance(v, ops.Operation):\n          return no_op()\n        elif v.dtype == dtypes.string:\n          return array_ops.constant(\"\")\n        else:\n          return array_ops.constant(v.dtype.as_numpy_dtype())\n\n      if isinstance(dummy_value, collections.Sequence):\n        dummy_type = type(dummy_value)\n        empty = lambda: dummy_type(_correct_empty(v) for v in dummy_value)\n      else:\n        empty = lambda: _correct_empty(dummy_value)\n\n    # case_sequence = [\n    #   cond(~p3 & ~p2 & ~p1, default, empty),\n    #   cond(p3 & ~p2 & ~p1, f3, lambda: case_sequence[0]),\n    #   cond(p2 & ~p1, f2, lambda: case_sequence[1]),\n    #   cond(p1, f1, lambda: case_sequence[2])\n    # ]\n    #\n    # And the return value will be case_sequence[-1]\n    def _build_case():\n      all_fns = [fn for fn in fns]\n      all_fns.append(default)\n      prev_case = None\n      for i, (cp, fn) in enumerate(list(zip(case_preds, all_fns))[::-1]):\n        prev_case = cond(\n            cp, fn,\n            empty if i == 0 else lambda: prev_case,\n            name=\"If_%d\" % i)\n      return prev_case\n...\n```\n\nThe op works by evaluating a series of predicates (including a predicate for the default value) but it starts off with an empty object. The empty object seems to be designed to pass on correct shape and type information but it fails to do so in my use case. I recommend changing this code to read:\n\n``` python\n...\n    # preds = [p1, p2, p3]\n    # fns = [f1, f2, f3]\n    # not_preds = [~p1, ~p2, ~p3]\n    # and_not_preds = [True, ~p1, ~p1 & ~p2, ~p1 & ~p2 & ~p3]\n    # case_preds = [p1,\n    #               p2 & ~p1,\n    #               p3 & ~p2 & ~p1]\n\n    case_preds = []\n    for i, (p, and_not_p_prev) in enumerate(zip(preds, and_not_preds[:-1])):\n      with ops.name_scope(\"case_%d\" % i):\n        case_preds.append(math_ops.logical_and(p, and_not_p_prev))\n\n    # case_sequence = [\n    #   cond(p3 & ~p2 & ~p1, f3, default),\n    #   cond(p2 & ~p1, f2, lambda: case_sequence[0]),\n    #   cond(p1, f1, lambda: case_sequence[1])\n    # ]\n    #\n    # And the return value will be case_sequence[-1]\n    def _build_case():\n      all_fns = [fn for fn in fns]\n      prev_case = None\n      for i, (cp, fn) in enumerate(list(zip(case_preds, all_fns))[::-1]):\n        prev_case = cond(\n            cp, fn,\n            default if prev_case is None else lambda: prev_case,\n            name=\"If_%d\" % i)\n      return prev_case\n...\n```\n\nThis removes the need not only for creating a dummy empty op, but also removes the need to create a separate predicate for the default op, simplifying the whole op by about 18 lines of code.\n", "comments": ["Assigning to @yuanbyu to take a look (although he's out of office currently).\n", "This is what case originally looked like (look at the git history for the file).  Unfortunately, this has the bad side effect of always executing at least two nodes (default and the one that evaluated to true).  Even if the default node was not actually returned, it was still executed and as a result may have had possible side effects.  Feel free to change the code as you suggested and you'll see a unit test in control_flow_ops start failing.\n\nThe real solution is to factor out cond() into a sequence of internal _if_then; which can be used for case as well.\n", "@yuanbyu another reason to split up cond/case into if_then type statements?\n", "This is on the backburner for a bit; sorry.  No updates on when it'll be done.\n", "ETA on fix?\r\n\r\nI'm currently nestling `tf.cond` but [it looks a little silly](https://github.com/carlthome/tensorflow-convlstm-cell/blob/master/ConvLSTMCell.py#L143).", "The fix for this one is more involved than originally anticipated.  Will update the issue with an ETA once we have an initial fix.", "Ping! Is there work going on to fix this issue?\r\nShould we reassign this?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 3333, "title": "Branch 127578995", "body": "", "comments": []}, {"number": 3332, "title": "Feature Request: Support for depthwise convolution by groups", "body": "As much as I have managed to follow the API section of tensorflow the depthwise_conv2d doesn't fulfill my thoughts on what I would like to do with the input/filters.\n\n```\nshape = (2,5,5,48,128)\ninitializer = tf.truncated_normal_initializer(stddev=1e-2)\nkernel = tf.get_variable(name='weights', shape=shape, initializer=initializer)\n```\n\nConsidering the input is of shape (batch_size, 55, 55, 96),\nthe function definition would be:\n\n```\ndef depthwise_group_conv2d(input, filter, groups, strides, padding, name)\n```\n\nwhich would be able to do\n\n```\nconv = tf.nn.depthwise_group_conv2d(input, kernel, [48,48], strides, padding, name)\n```\n\nthat would split the input depthwise into depths from given 'groups' parameter and perform the convolution with shared parameters (i.e. depths [:48] take weights[0] and depths[48:] take weights[1]) inside a group. Then the outputs of convolutions by groups would be concatenated depthwise.\n\nThis would make it easier to define groups such as one used in AlexNet/CaffeNet architectures.\n\nHopefully I have missed a certain feature already existing for making this easier.\n\nBest regards,\nFilip\n", "comments": ["I am not sure how to read the numbers in your code. Are they matching? \nAre you trying to combine two depthwise conv to one essentially?\n", "What I would basically like to do is use convolution on an input of size (batch_size, 55, 55, 96) such that 1 kernel is shared for the whole input UP TO depth 48, and a different kernel from depth 48. Each convolution should therefore give a result of depth 128 because of the defined weights. Then when the results are concatenated depthwise they would give the depth of 256 such as defined in [(http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf)].\n\nCurrently the implementation of depthwise_conv2d in tensorflow allows for only applying a different filter of depth 1 to each input channel, while I would like to apply a filter of depth 48 to 48 input channels, and then again a different filter of depth 48 for the next 48 input channels.\n\nSuch convolution (splitting the input into 2 groups by depth) is used in AlexNet/CaffeNet and it would be great if such a function would be implemented in TensorFlow.\n\nMy current code is:\n\n```\nkernel = variable_with_weight_decay('weights', [5, 5, 96, 128],\n                                    stddev=1e-2, wd=1e-6)\n\nconv_grp1 = tf.nn.conv2d(pool1[:, :, :, :48], kernel[:, :, :48, :], [1, 1, 1, 1], padding='SAME')\nconv_grp2 = tf.nn.conv2d(pool1[:, :, :, 48:], kernel[:, :, 48:, :], [1, 1, 1, 1], padding='SAME')\n\nbiases = variable_on_device('biases', [256], tf.constant_initializer(1.))\n\nbias_grp1 = tf.nn.bias_add(conv_grp1, biases[:128])\nbias_grp2 = tf.nn.bias_add(conv_grp2, biases[128:])\n\nconv2_grp1 = tf.nn.relu(bias_grp1, name=scope.name)\nconv2_grp2 = tf.nn.relu(bias_grp2, name=scope.name)\n\nconv2 = tf.concat(3, [conv2_grp1, conv2_grp2])\n```\n\nThis code IS working as intended, but it would be nice if I would be able to use convolution like this without explicitly defining 2 groups, but just by definining them in the convolution function.\n", "OK. Depthwise convolution is actually a different type of conv. You can find \"depthwise_conv2d_native\".\n\nFor this, it might be better to just have two separate convs like what inception did to avoid all the slicing operations.\n", "Sorry for misunderstanding the depthwise convolution, I thought the term would just generally describe using different filters for different depths (and therefore include groups).\nThe exact reason to implement a function such as this is to avoid explicit slicing of the kernels, biases and inputs. An additional reason why I thought it might be useful is because Caffe had \"groups\" as a possible parameter in the convolution layer [http://caffe.berkeleyvision.org/tutorial/layers.html](url). I thought it might be nice to have tensorflow support for this behavior.\n", "I think it is actually logically cleaner to have two separate convs just like what's in inception. We might need a strong use case to support another interface for the very popular op so please send this over when it is the case. Thanks.\n", "I implemented this feature in the following PR.\r\nhttps://github.com/tensorflow/tensorflow/pull/10482", "Nvidia has actually started a campaign advertising hardware specifically based on its ability to do groupwise convolutions. If that doesn't mean that these are mainstream enough to desparately warrant inclusion as an op, I don't know what would.\r\n\r\n(I'm sorry if this sounds like whining, my desire is only to point out that it is has gone 'mainstream'! So that when the devs' busy schedules have room, they might prioritize this a bit more. :) Sadly I don't know enough about the internals to contribute, sorry :( )", "The state-of-the-art in image classification (ResNeXt and AttentionNeXt) use grouped convolutions. I think that's a reason enough for them to be added to Tensorflow core.", "There are 3 threads on this topic, all are closed without any proper conclusion. Is there any intention there?", "Group  convolution is implemented in both Caffe and PyTorch. As now it slows down the inference stage when I reproduce them with `tf.split` and `tf.concat`, I think it's reasonable enough to be added as TF kernel.", "Any chance of re-opening this issue? As pointed out, a number of SoTA models use these group convolutions. Further [per this comment](https://github.com/tensorflow/tensorflow/issues/12052#issuecomment-320465264), cuDNN 7 now supports group convolutions as a primitive. It seems like exposing a primitive op that handles these convolutions makes sense.", "I am no longer in this team and not sure if anyone else is looking at this so just reopened it. :)", "@martinwicke, @shlens, @fchollet, is there any interest in defining an api for this?", "I suspect that the API does not need to be expanded. Instead, I would propose the following:\r\n- expose [`depthwise_conv2d`](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/nn_impl.py#L327) in`nn_impl.py`\r\n- offer an optional integer argument named `group` that defaults to 1.\r\n\r\nThis would conceptually group together all of the depthwise convolution operations by offering a single function. In addition, this would be a backward-compatible change but also support the type of grouping proposed in the other work. (Under the hood, `depthwise_conv2d` would have a switch statement that would call the appropriate kernel depending on the value of `group`.)", "Really want a fast group convolution implementation for ResNeXt!", "I also want group convolution in tensorflow. I found that tweet about efficiently implementing ResNeXt:\r\nhttps://twitter.com/D_Berthelot_ML/status/907007235577880576\r\n\"Thanks @VahidK for the solution, using depthwise convolution with a reshape+sum does the trick. It's 4-5x faster now.\"\r\nThat may not be the ideal solution (maybe not as good as calling cudnn's group convolution primitive), but it may help.", "@josh11b @fchollet @asimshankar @sherrym Opinions on grouped convolutions? Maybe especially @sherrym?", "I like Jon's suggestion on expanding the depthwise_conv2d API to support the group functionality. Is that not sufficient?", "API Review Committee is supportive of a new group argument added to the existing depthwise_conv2D API to address this use case. If someone wants to revive #10482, it looks like it changes the API without modifying the underlying kernels (which would be another step needed for full performance).", "Perhaps that PR can be re-opened (CC @jhseu)", "@josh11b I am happy to revive #10482. Please let me know any improvement you'd like to have on that PR.", "The API change is fine, but merging a PR that simply iteratively applies `Conv2D` would result in extremely slow runtime, which would then be misleading. One of the main motivations for using convolution groups is that they should be faster than regular convolutions (separable convolution being the fastest), and in this case we would actually be much slower than regular convolution, by a large factor. \r\n\r\nIn my opinion this change only makes sense if we release a kernel that implements it with decent performance.", "Perhaps using https://github.com/tensorflow/tensorflow/issues/3332#issuecomment-358818076 to minimize speed hit relative to native kernel? ", "@cancan101 yes, that would probably be okay. But would it ever be replaced with a fast native kernel?", "@fchollet I agree. Given CuDNN 7 is being fully adopted by TensorFlow now, we should use its native support for group-based convolution rather than doing things in Python.", "That would be fantastic. If you were to revive #10482, an enhancement to the kernel to actually use the cuDNN primitive would be the way to go.", "I looked a bit into the usage of CuDNN in TensorFlow, especially `cudnnConvolutionForward`. It's a piece of code of modest size and contains complicated logics for algorithm selection. Since not all forward convolution algorithms support group-based convolution, I think it'll be faster for someone who is familiar with that part of code to add this functionality.\r\n\r\nAlso, to support an API change in C++ level, we also need to implement the CPU-only version. I'm afraid I don't have enough time for this in the near term.\r\n\r\nI'm happy to flesh out a pure API change patch in Python (i.e. without the actual C++ impl) based on #10482 if that seems useful. Otherwise, please feel free to use any code in that PR.", "@zheng-xq Are you interested in adding fast implementation of group convolution that maps to CuDNN 7?", "Reassigned to @chsigg as he has been working on this.", "Any news? CUDNN 7.1.1 has even better support for convolution groups:\r\nhttp://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_711.html#rel_711\r\n\"All algorithms for convolutions now support groupCount > 1\"\r\nThis should make things easier.", "We've been getting a lot of mileage out of the MobileNet class of architectures, especially for edge inference. Any updates on this so we can really use separable convs near their theoretical speed?\r\n", "@TylerBalsam I have implemented the CUDNN grouped conv API for DepthwiseConv in https://github.com/tensorflow/tensorflow/pull/17961, you can give it a try if you are willing to compile yourself. I get a significant speed-up for MobileNet (my main application), especially in 16-bit training.", "Many thanks!\n\nOn Fri, Apr 6, 2018, 10:05 PM Wenda Zhou <notifications@github.com> wrote:\n\n> @TylerBalsam <https://github.com/TylerBalsam> I have implemented the\n> CUDNN grouped conv API for DepthwiseConv in #17961\n> <https://github.com/tensorflow/tensorflow/pull/17961>, you can give it a\n> try if you are willing to compile yourself. I get a significant speed-up\n> for MobileNet (my main application), especially in 16-bit training.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3332#issuecomment-379424493>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AF4UH75-5kIRx4W0i-5NAGTFNbjQ0T0sks5tmB74gaJpZM4JNopQ>\n> .\n>\n", "Please add support for group convolutions! Caffe and PyTorch have had an efficient implementation for nearly two years, and the current state of the art models leverage groups. Even though one can use depthwise_conv2d_native followed by a sum, this is a very slow and memory-demanding way to implement it, even with the latest CuDNN optimization.\r\n\r\nI tried a group convolution with 256 channels and 32 groups, 3x3 kernel and in PyTorch it ran x2 the speed of full convolution (groups==1), whereas if I do it in tf with depthwise_conv2d_native it is 5 times slower relative to full convolution -- so PyTorch is 10 times faster in this case, which is very common in ResNeXt style architectures. I am using the latest TF build and have enabled the CuDNN support for it with a kernel label map.\r\n", "Same here, this feature is a blocker for training & deploying many relevant state of the art models on tensorflow. This should seriously be bumped in priority.", "Sorry for the large delay on this issue. I will start working on implementing support for grouped convolutions  very soon.", "I implemented a basic version of grouped convolutions(note these are different than depthwise convolutions) using normal convolutions and splitting the input tensor and weights tensor. The implementation is compatible with slim and accepts the slim argscope. \r\n\r\nIt can be found here: [https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py](https://github.com/Timen/squeezenext-tensorflow/blob/master/tensorflow_extentions/grouped_convolution.py)\r\n\r\nIt mainly relies on this function to split the inputs and filters and applies convolutions to each subset:\r\n```\r\ndef grouped_convolution2D(inputs, filters, padding, num_groups,\r\n                          strides=None,\r\n                          dilation_rate=None):\r\n    \"\"\"\r\n    Performs a grouped convolution by applying a normal convolution to each of the seperate groups\r\n    :param inputs:\r\n        Input of the shape [<batch_size>,H,W,inC]\r\n    :param filters:\r\n        [H,W,inC/num_groups,outC]\r\n    :param padding:\r\n        What padding to use\r\n    :param num_groups:\r\n        Number of seperate groups\r\n    :param strides:\r\n        Stride\r\n    :param dilation_rate:\r\n        Dilation rate\r\n    :return:\r\n        Output of shape [<batch_size>,H/stride,W/stride,outC]\r\n    \"\"\"\r\n    # Split input and outputs along their last dimension\r\n    input_list = tf.split(inputs, num_groups, axis=-1)\r\n    filter_list = tf.split(filters, num_groups, axis=-1)\r\n    output_list = []\r\n\r\n    # Perform a normal convolution on each split of the input and filters\r\n    for conv_idx, (input_tensor, filter_tensor) in enumerate(zip(input_list, filter_list)):\r\n        output_list.append(tf.nn.convolution(\r\n            input_tensor,\r\n            filter_tensor,\r\n            padding,\r\n            strides=strides,\r\n            dilation_rate=dilation_rate,\r\n            name=\"grouped_convolution\" + \"_{}\".format(conv_idx)\r\n        ))\r\n    # Concatenate ouptputs along their last dimentsion\r\n    outputs = tf.concat(output_list, axis=-1)\r\n\r\n    return outputs\r\n```", "I tried something similar but it's too slow.", "It will depend on the number of groups and how big the individual groups are, larger group sizes(>16?) should have no problem running as parallel normal convolutions. But smaller group sizes (<8) (apple uses 4 on mobile) would benefit greatly from a more optimized implementation. (even thought they will always suffer from poor arithmetic intensity (ratio of compute to memory operations)\r\n", "@Timen it seems like you did a simple loop over the inputs. What makes you think your convolutions will run in parallel?", "@michaelklachko The loop is only there to define the convolutional nodes in the graph, during training the loop will not get executed. These convolutions all consume an independent input (after the split) and produce an independent output (with respect to the other convolutions) these outputs are then gathered and combined with a concat. And according to this stackoverflow post https://stackoverflow.com/questions/41233635/meaning-of-inter-op-parallelism-threads-and-intra-op-parallelism-threads tensorflow does attempt to execute nodes that don't have a path linking them in parallel.", "In theory yes they can be run in parallel, but in practice implementing group convolution in this way is very inefficient. I have timed it. This is why NVidia explicitly provided acceleration of group convolutions in CuDNN. There is a [group option](https://blog.yani.io/cudnn-filter-groups) for nearly a year now. All the Tensorflow developers need to do is propagate it to the parameters of conv2d.", "Currently, mobilenetv2 is using this code for split_conv. Hope there will be an op to support group convs.", "How is progress on this coming along?", "Note that GPU ops do *not* run in parallel, even with `inter_op_parallelism_threads > 1`, because currently TF uses only a single CUDA compute stream.\r\nSee [here](https://stackoverflow.com/questions/51494911/will-tensorflow-matmul-run-in-parallel-on-gpu-or-any-gpu-ops) or [here](https://stackoverflow.com/questions/36098947/how-does-tensorflow-support-cuda-streams) for reference.\r\n", "use tf.split  and tf.concat is  very inefficient. I used this\uff0cbut tf cost more time, nearly 10 times slower than mxnet. This is intolerable\uff01What can I do to speed up\uff1f\uff1f\uff1fIs anyone have any suggestions?", "Is someone working on this? I would like to help on it, but I do not want to duplicate the work of someone else", "@vcarpani This issue has been dead for a long time, so I think you're fine.\r\nThanks!", "Any update on this?", "Also need group conv !\r\nTF seems to be outmoded.", "Oh, so this issue has been open for 2.5 years.\r\n\r\nThe only thing needed to enable group convolution in tensorflow is to remove two lines of code:\r\n```diff\r\ndiff --git i/tensorflow/core/framework/common_shape_fns.cc w/tensorflow/core/framework/common_shape_fns.cc\r\nindex 5c974a76ac..aa4a663c5f 100644\r\n--- i/tensorflow/core/framework/common_shape_fns.cc\r\n+++ w/tensorflow/core/framework/common_shape_fns.cc\r\n@@ -495,8 +495,6 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\r\n   // Check that the input tensor and the filter tensor agree on the input\r\n   // channel count.\r\n   DimensionHandle unused;\r\n-  TF_RETURN_IF_ERROR(\r\n-      c->Merge(input_depth_dim, filter_input_depth_dim, &unused));\r\n \r\n   Padding padding;\r\n   TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\r\ndiff --git i/tensorflow/core/grappler/costs/op_level_cost_estimator.cc w/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\r\nindex 1e2e160955..745039bf27 100644\r\n--- i/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\r\n+++ w/tensorflow/core/grappler/costs/op_level_cost_estimator.cc\r\n@@ -616,7 +616,6 @@ OpLevelCostEstimator::ConvolutionDimensionsFromInputs(\r\n   // Only check equality when both sizes are known (in other words, when\r\n   // neither is set to a minimum dimension size of 1).\r\n   if (iz != 1 && filter_shape.dim(in_channel_index).size() != 1) {\r\n-    CHECK_EQ(iz, filter_shape.dim(in_channel_index).size());\r\n   } else {\r\n     iz = std::max<int64>(iz, filter_shape.dim(in_channel_index).size());\r\n   }\r\n```\r\n\r\nIt'll take a lot more to make a PR, with tests, shape checks, flops calculation, etc, and probably handle some more edge cases. I'm not sure I'll have time for that. But in case someone needs it and is OK with building TF from source, here you go.\r\nOn a ResNeXt50-32x4d trained on ImageNet, I observed a 13% overall speed improvement vs a loop-based implementation.", "I AM TOTALLY CONFUSED WHY TENSORFLOW TEAM REJECT TO ADD GROUP CONVOLUTION FOR SUCH A LONG TIME! WHAT ARE YOU THINKING ABOUT!!!!!!", "I already added it in #25818 and this issue can be closed.", "Thank you very much Yuxin for adding grouped convolutions! It is a great feature to have, and we simply didn't have the cycles to do it ourselves.\r\n\r\nI'm closing this issue.", "Would it be possible to upload the files that are changed by changing the two lines of code? That would be super helpful, not everyone wants to install visual 2017 and other stuff just for going around that argument checking in the function\r\n(As far as I understood, the group convolution feature is implemented, but not ready for a public release, which means the dimension check is still active, but can be circumvented by changing c-code and compiling tf oneself.)"]}, {"number": 3331, "title": "Retrofitting: idgi make me smarter :)", "body": "can someone point me to some info on retrofitting?  I don't get it really.  \n\nI'm specifically trying to combine some of my writing with ConceptNet (which I can download in matrix form) in order to generate output that sounds something like me or at least talks about the things i talk about.  Guess I'm not understanding how to align and combine the matrices for the most part but any literature is greatly appreciated.\n\nCheers,\ndi-synthetic-logic\np.s. bless you\n", "comments": ["This is probably a better question for StackOverflow, the people monitoring these issues are only helping with bugs / TensorFlow core features.\n"]}, {"number": 3330, "title": "tensorflow based shared library can't link to other project", "body": "Problem:\nI create a project in tensorflow/tensorflow/my_project. Then create a library by cc_library of bazel. I can compile it and create the library. For example, test.a, test.so in tensorflow/bazel-bin/my_project. But if I use the library in another project by linking it. It would raise a problem of finding the header file.\n\n```\nfatal error: tensorflow/core/framework/graph.pb.h: No such file or directory\n```\n\ntest.h:\n\n```\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/platform/env.h\"\n\nblabla...\n```\n", "comments": ["@martinwicke Do you know what is the recommended way to do such thing?\n", "This is a question best asked on the bazel channels. \n\nAlso, you should include information on how you've set up your other's project's build. It looks like you simply haven't included the correct paths in whatever build system you use there.\n"]}, {"number": 3329, "title": "issue running build_all_ios.sh ?", "body": "On running build_all_ios.sh script, getting folllowing error?\n\nm -lz\n    Undefined symbols for architecture x86_64:\n      \"google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()\", referenced from:\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in test_log.pb.o\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in saved_tensor_slice.pb.o\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in event.pb.o\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in tensorflow_server.pb.o\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in named_tensor.pb.o\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in meta_graph.pb.o\n      google::protobuf::io::CodedInputStream::ReadVarintSizeAsInt(int_) in config.pb.o\n      ...\n      \"google::protobuf::MessageLite::InternalSerializeWithCachedSizesToArray(bool, unsigned char_) const\", referenced from:\n      vtable for google::protobuf::internal::MapEntryBase in test_log.pb.o\n      vtable for google::protobuf::internal::MapEntryBase in tensorflow_server.pb.o\n      vtable for google::protobuf::internal::MapEntryBase in meta_graph.pb.o\n      vtable for google::protobuf::internal::MapEntryBase in config.pb.o\n      vtable for google::protobuf::internal::MapEntryBase in graph.pb.o\n      vtable for google::protobuf::internal::MapEntryBase in function.pb.o\n      vtable for google::protobuf::internal::MapEntryBase in attr_value.pb.o\n      ...\n    ld: symbol(s) not found for architecture x86_64\n    clang: error: linker command failed with exit code 1 (use -v to see invocation)\n    make: **\\* [/Users/jsahil/projects/tensorflow/tensorflow\nmaster/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1\n    + '[' 2 -ne 0 ']'\n    + echo 'armv7 compilation failed.'\n    armv7 compilation failed. \n    + exit 1\n\nLet me know if I am missing something. Thanks\n", "comments": ["@petewarden Could you take a look at this please?\n", "I've looked at it, and wasn't able to reproduce the problem. I did encounter a few missing files from the Makefile that I've added in PR #3337, but after that the build_all_ios.sh script completed successfully.\n\n@sahil912 can you see if there's any mention of missing libprotobuf files in the lines before those linker errors, since it appears that the creation of those failed?\n", "I had the same problem as above and pulling in your changes seems to have fixed the issue\n", "@petewarden \n\nI tried to run this with the latest version, and getting following error:\n\n```\n\"void tensorflow::HandleStridedSliceCase<Eigen::ThreadPoolDevice, int, 3>(tensorflow::OpKernelContext*, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::TensorShape const&, bool, tensorflow::Tensor*)\", referenced from:\n      tensorflow::StridedSliceOp<Eigen::ThreadPoolDevice,     int>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core-armv7.a(strided_slice_op.o)\n  \"void tensorflow::HandleStridedSliceGradCase<Eigen::ThreadPoolDevice, float, 5> (tensorflow::OpKernelContext*, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::TensorShape const&, bool, tensorflow::Tensor*)\", referenced from:\n      tensorflow::StridedSliceGradOp<Eigen::ThreadPoolDevice,  float>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core-armv7.a(strided_slice_op.o)\n  \"void tensorflow::HandleStridedSliceCase<Eigen::ThreadPoolDevice, int, 6>(tensorflow::OpKernelContext*, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::gtl::ArraySlice<long long> const&, tensorflow::TensorShape const&, bool, tensorflow::Tensor*)\", referenced from:\n      tensorflow::StridedSliceOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core-armv7.a(strided_slice_op.o)\nld: symbol(s) not found for architecture armv7\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nmake: *** [/Users/jsahil/projects/tensorflow/tensorflow-    latest/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1\n+ '[' 2 -ne 0 ']'\n+ echo 'armv7 compilation failed.'\narmv7 compilation failed.\n+ exit 1\n```\n", "works good after #3382 commit. Thanks\n"]}, {"number": 3328, "title": "Modified retrain.py: changed import at 80 line.", "body": "Changed import 'tensorflow.python.framework' to 'tensorflow.python.client'.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n", "I think you might be using an older version of the code -- I think it was moved from client to framework, so this is currently correct.\n"]}, {"number": 3327, "title": "Issue running compile_ios_tensorflow.sh?", "body": "On running compile_ios_tensorflow.sh, I am facing the below issue.\n\n**sh compile_ios_tensorflow.sh** \n\n```\nsed: tensorflow/contrib/makefile/downloads/eigen-latest/eigen/src/Core/arch/NEON/Complex.h: No such file or directory\nsed: tensorflow/contrib/makefile/downloads/eigen-latest/eigen/src/Core/arch/NEON/Complex.h: No such file or directory\nsed: tensorflow/contrib/makefile/downloads/eigen-latest/eigen/src/Core/arch/NEON/Complex.h: No such file or directory\nmake: tensorflow/contrib/makefile/Makefile: No such file or directory\nmake: *** No rule to make target `tensorflow/contrib/makefile/Makefile'.  Stop.\nmake: tensorflow/contrib/makefile/Makefile: No such file or directory\nmake: *** No rule to make target `tensorflow/contrib/makefile/Makefile'.  Stop.\n```\n\narmv7 compilation failed.\n\nbecause of this I am unable to proceed with iOS example, cos of missing libtensorflow.a \n\n```\nld: file not found: /Users/jsahil/projects/tensorflow/tensorflow-master/tensorflow/contrib/ios_examples/camera/../../makefile/gen/lib/libtensorflow-core.a\n```\n\nPlease let me know, if I am missing something or this is an issue with the script. Thanks\n", "comments": ["@petewarden Could you take a look at this please?\n", "Sorry you're hitting problems! It looks like your immediate problem is that you're running the script with the working directory set to tensorflow/contrib/makefile, e.g. you've done this:\n\n``` bash\ngit clone https://github.com/tensorflow/tensorflow\ncd tensorflow/tensorflow/contrib/makefile\nsh compile_ios_tensorflow.sh\n```\n\nWhat you should actually do is this:\n\n``` bash\ngit clone https://github.com/tensorflow/tensorflow\ncd tensorflow\ntensorflow/contrib/makefile/compile_all_ios.sh\n```\n\nThe documentation is at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#ios but I realize that is a bit unclear about which directory to run the scripts from, so we should improve that. \n\nDoes that help?\n", "@petewarden  On latest build, I tried to run tensorflow/contrib/makefile/compile_ios_tensorflow.sh\n\n```\nUndefined symbols for architecture armv7:\n  \"tensorflow::OptimizationPassRegistry::Global()\", referenced from:\n  tensorflow::SimpleGraphExecutionState::InitBaseGraph(tensorflow::BuildGraphOptions const&) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)\n  tensorflow::SimpleGraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&,     std::__1::unique_ptr<tensorflow::SimpleClientGraph, std::__1::default_delete<tensorflow::SimpleClientGraph> >*) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)\n  \"tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)\", referenced from:\n  tensorflow::SimpleGraphExecutionState::InitBaseGraph(tensorflow::BuildGraphOptions const&) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)\n  tensorflow::SimpleGraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&,   std::__1::unique_ptr<tensorflow::SimpleClientGraph, std::__1::default_delete<tensorflow::SimpleClientGraph> >*) in libtensorflow-core-armv7.a(simple_graph_execution_state.o)\nld: symbol(s) not found for architecture armv7\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nmake: *** [/Users/jsahil/projects/tensorflow/tensorflow-  latest/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1\narmv7 compilation failed.\n```\n\nThanks\n", "works good after #3382  commit. Thanks\n"]}, {"number": 3326, "title": "classification using tensorflow : word2vec_basic", "body": "Hi,\n\nIn tensorflow, using word2vec_basic, can we have a few fixed buckets and others as custom buckets based on valid_examples ? \n\nI have also raised a similar doubt on[ stack overflow ](http://stackoverflow.com/questions/38295791/classification-using-tensorflow-word2vec-basic) . It will be great to have your feedback on the same !! \n", "comments": ["This is for tensorflow bugs/feature requests/ etc... so this fits better in stackoverflow. Please follow this in the stack overflow.\n"]}, {"number": 3325, "title": "build_pip_package failed", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System:\nRedhat 6.7\nmodule environment\ngcc 6.1.0\n\n`printenv\nMKLROOT=/software/intel/xe2015/composer_xe_2015.1.133/mkl\nFLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64\nMANPATH=/software/python/3.4.5/login/man:/software/intel/xe2015/composer_xe_2015.1.133/man/en_US:/usr/share/man:/usr/man:/usr/local/share/man:/usr/X11R6/man\nMKLLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64\nFDIR=/software/intel/xe2015/composer_xe_2015.1.133\nIPPROOT=/software/intel/xe2015/composer_xe_2015.1.133/ipp\nINTEL_LICENSE_FILE=/software/intel/licenses/server.lic\nTERM=xterm\nSHELL=/bin/bash\nMLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64\nHISTSIZE=1000\nSSH_CLIENT=134.99.4.11 52640 22\nLIBRARY_PATH=/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/ipp/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/tbb/lib/intel64\nFPATH=\nOLDPWD=/root\nSSH_TTY=/dev/pts/3\nUSER=root\nLD_LIBRARY_PATH=/software/gcc/6.1.0/login/lib:/software/gcc/6.1.0/login/lib64:/software/python/install/Python-3.4.5/Include/:/software/python/3.4.5/login/lib:/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/ipp/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/tbb/lib/intel64:/lib64:/usr/lib64:/usr/local/lib64:/usr/X11R6/lib64\nCPATH=/software/intel/xe2015/composer_xe_2015.1.133/mkl/include:/software/intel/xe2015/composer_xe_2015.1.133/tbb/include\nLIBPATH=/software/python/install/Python-3.4.5/Lib/:/software/python/3.4.5/login/lib\nCDIR=/software/intel/xe2015/composer_xe_2015.1.133\nCLIBDIR=/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64\nMAIL=/var/spool/mail/root\nPATH=/software/gcc/6.1.0/login/bin:/software/python/3.4.5/login/bin:/software/intel/xe2015/composer_xe_2015.1.133/bin/intel64:/software/intel/xe2015/composer_xe_2015.1.133/bin/intel64_mic:/software/intel/xe2015/composer_xe_2015.1.133/debugger/gui/intel64:/usr/pbs/bin:.:/bin:/usr/bin:/usr/local/bin:/usr/X11R6/bin\nTBBROOT=/software/intel/xe2015/composer_xe_2015.1.133/tbb\nF90=gfortran\nPWD=/software/tensorflow/install/tensorflow\n_LMFILES_=/software/modules/tools/hpc_basis:/software/modules/compiler/intel/xe2015:/software/modules/tools/Python/3.4.5:/software/modules/compiler/gcc/6.1.0\nF95=gfortran\nLANG=en_US.UTF-8\nMODULEPATH=/software/modules/compiler:/software/modules/software:/software/modules/tools\nLOADEDMODULES=hpc_basis:intel/xe2015:Python/3.4.5:gcc/6.1.0\nPYTHONHOME=/software/python/3.4.5/login\nF77=gfortran\nCXX=g++\nHISTCONTROL=ignoredups\nSHLVL=1\nHOME=/root\nFC=gfortran\nDYLD_LIBRARY_PATH=/software/gcc/6.1.0/login/lib:/software/gcc/6.1.0/login/lib64:/software/intel/xe2015/composer_xe_2015.1.133/compiler/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/ipp/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/mkl/lib/intel64:/software/intel/xe2015/composer_xe_2015.1.133/tbb/lib/intel64\nLOGNAME=root\nCVS_RSH=ssh\nMODULESHOME=/usr/share/Modules\nLESSOPEN=||/usr/bin/lesspipe.sh %s\nARCH=login\nFRTLIB=-lifcore\nCC=gcc\nINCLUDE=/software/intel/xe2015/composer_xe_2015.1.133/mkl/include:/software/intel/xe2015/composer_xe_2015.1.133/tbb/include:/usr/X11R6/include/X11:/usr/include:/usr/local/include\nG_BROKEN_FILENAMES=1\nBASH_FUNC_module()=() {  eval`/usr/bin/modulecmd bash $*`\n}\n_=/usr/bin/printenv\n`\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nls -l /software/CUDA/7.5.18/lib/libcud*\n-rw-r--r-- 1 root users 189170 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudadevrt.a\nlrwxrwxrwx 1 root users     16 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root users     19 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root users 311596 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart.so.7.5.18\n-rw-r--r-- 1 root users 558020 Sep 10  2015 /software/CUDA/7.5.18/lib/libcudart_static.a\n\nIf installed from sources, provide the commit hash:\nd2c913aa9b7cb63e466392f76d46ac5fbc1e9825\n### Steps to reproduce\n1. install gcc in different path and set PATH, LD_LIBRARY_PATH, INCLDUE_PATH\n2. git clone https://github.com/tensorflow/tensorflow.git\n3. ./configure\n4. bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\n### Logs or other output that would be helpful\n\n`[root@hpc-login1 tensorflow]# bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\nWARNING: /software/tensorflow/install/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future.\nINFO: Found 1 target...\nERROR: /root/.cache/bazel/_bazel_root/60e5a3f81176660f3aa05e1fb0a50126/external/zlib_archive/BUILD:7:1: undeclared inclusion(s) in rule '@zlib_archive//:zlib':\nthis rule is missing dependency declarations for the following files included by 'external/zlib_archive/zlib-1.2.8/uncompr.c':\n  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include-fixed/limits.h'\n  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include-fixed/syslimits.h'\n  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include/stddef.h'\n  '/software/gcc/6.1.0/login/lib/gcc/x86_64-pc-linux-gnu/6.1.0/include/stdarg.h'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 3.201s, Critical Path: 1.01s`\n\nI also tried to use the intel compiler but bazel brakes the environment\n", "comments": ["Redhat is not officially supported. But you can move this to Stackoverflow though and people might be able to help there.\n"]}, {"number": 3324, "title": "tensorflow anaconda : pip install fails in newly created python 2.7 environment", "body": "### Environment info\n\nOperating System:\n(tf) :~/anaconda3/bin$ cat /proc/version\nLinux version 4.4.0-31-generic (buildd@lgw01-16) (gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2.1) ) #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016\n### Steps to reproduce\n1. Follow https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#anaconda-installation\n2. :~/anaconda3/bin$ ./conda create --name tf python=2\n   Fetching package metadata .......\n   Solving package specifications: ..........\n\nPackage plan for installation in environment /home/paddlescoot/anaconda3/envs/tf:\n\nThe following packages will be downloaded:\n\n| package | build |\n| --- | --- |\n| python-2.7.12 | 1        12.1 MB |\n| setuptools-23.0.0 | py27_0         455 KB |\n| wheel-0.29.0 | py27_0          81 KB |\n| pip-8.1.2 | py27_0         1.5 MB |\n\n```\n------------------------------------------------------------\n                                       Total:        14.1 MB\n```\n\nThe following NEW packages will be INSTALLED:\n\n```\nopenssl:    1.0.2h-1     \npip:        8.1.2-py27_0 \npython:     2.7.12-1     \nreadline:   6.2-2        \nsetuptools: 23.0.0-py27_0\nsqlite:     3.13.0-0     \ntk:         8.5.18-0     \nwheel:      0.29.0-py27_0\nzlib:       1.2.8-3      \n```\n\nProceed ([y]/n)? y\n\nFetching packages ...\npython-2.7.12- 100% \nsetuptools-23. 100% \nwheel-0.29.0-p 100% \npip-8.1.2-py27 100% \n\nExtracting packages ...\nLinking packages ...\n\n:~/anaconda3/bin$ source activate tf\n(tf) :~/anaconda3/bin$ ./conda info --envs\n# conda environments:\n# \n\ntf                    \\*  /home/paddlescoot/anaconda3/envs/tf\nroot                     /home/paddlescoot/anaconda3\n\n(tf) :~/anaconda3/bin$ python --version\nPython 2.7.12 :: Continuum Analytics, Inc.\n\n(tf) :~/anaconda3/bin$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n\n(tf) :~/anaconda3/bin$ pip install --upgrade $TF_BINARY_URL\nCollecting tensorflow==0.9.0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n  Downloading https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl (27.6MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27.6MB 52kB/s \nCollecting numpy>=1.8.2 (from tensorflow==0.9.0)\n  Downloading numpy-1.11.1-cp27-cp27mu-manylinux1_x86_64.whl (15.3MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15.3MB 90kB/s \nCollecting six>=1.10.0 (from tensorflow==0.9.0)\n  Using cached six-1.10.0-py2.py3-none-any.whl\nCollecting protobuf==3.0.0b2 (from tensorflow==0.9.0)\n  Using cached protobuf-3.0.0b2-py2.py3-none-any.whl\nRequirement already up-to-date: wheel in /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages (from tensorflow==0.9.0)\nCollecting setuptools (from protobuf==3.0.0b2->tensorflow==0.9.0)\n  Downloading setuptools-24.0.3-py2.py3-none-any.whl (441kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 450kB 1.3MB/s \nInstalling collected packages: numpy, six, setuptools, protobuf, tensorflow\n  Found existing installation: setuptools 23.0.0\nCannot remove entries from nonexistent file /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages/easy-install.pth\n\n(tf) :~/anaconda3/bin$ python\nPython 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n\n> > > import tensorflow as tf\n> > > Traceback (most recent call last):\n> > >   File \"<stdin>\", line 1, in <module>\n> > > ImportError: No module named tensorflow\n> > > quit()\n\n(tf) :~/anaconda3/bin$ ls -ali /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages/\nnumpy/                       pip/                         README                       setuptools.pth               six.py                       wheel/\nnumpy-1.11.1.dist-info/      pip-8.1.2-py2.7.egg-info/    setuptools-23.0.0-py2.7.egg  six-1.10.0.dist-info/        six.pyc                      wheel-0.29.0-py2.7.egg-info/\n\n(tf) :~/anaconda3/bin$ ls -ali /home/paddlescoot/anaconda3/envs/tf/lib/python2.7/site-packages/\nnumpy/                       pip/                         README                       setuptools.pth               six.py                       wheel/\nnumpy-1.11.1.dist-info/      pip-8.1.2-py2.7.egg-info/    setuptools-23.0.0-py2.7.egg  six-1.10.0.dist-info/        six.pyc                      wheel-0.29.0-py2.7.egg-info/\n### What have you tried?\n1. Searching for similar issues.\n", "comments": ["This is not a TF bug, it's an anaconda thing. See https://github.com/ContinuumIO/anaconda-issues/issues/542 - this is one of the reasons I don't use anaconda anymore, it doesn't play nice with pip and its main selling points (package management and environments) now come bundled with python ...  \n\nAs a workaround, do `pip install --ignore-installed --upgrade pip setuptools` before installing TF via pip.\n", "Great! Thanks very much @ptc-swalk.\n", "Thanks \r\n"]}, {"number": 3323, "title": "Allow tensorboard to follow symlinks (feature request #2140)", "body": "Fixes #2140\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@vrv Sounds good, done!\n", "Change looks good to me.\n", "@danmane @vrv Done\n", "great, thanks!\n\n@tensorflow-jenkins test this please\n", "@vrv: Do you think the failing rnn test could be related to this change?\n", "No it shouldn't be, I'm going to merge in some newer changes from internal first, and see if the flakiness goes away.\n", "@tensorflow-jenkins test this please\n", "If we discover that the symlink loops are common, which I hope they are not, we can change the function to use the os.walk iterator and check whether a symlink causes a loop.\n", "Any idea on when this will be merged ? I suppose it belongs to the `tensorboard` repo now, right ?"]}, {"number": 3322, "title": "Wrong type in rnn function", "body": "I think the type of `zero_output` in line 135 in [(rnn.py)](https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/python/ops/rnn.py#L135) should be `dtype` and not `inputs[0].dtype` as it is right now. If the cell output is a float, this will trigger an exception in the select statement in `_rnn_step` function in line [(298)](https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/python/ops/rnn.py#L298) of the type \n\n`TypeError: Input 'e' of 'Select' Op has type float32 that does not match type int32 of argument 't'.`\n\nwhen the inputs of the cells are int. I don't have a short piece of code to reproduce this, but if needed I can produce one.\n", "comments": ["I think this has been fixed on `master` (bbdda85344b819ce4db0bab5a9143fe9c4ff1c76).\n", "@raduk Could you try it out and close this if it is fixed?\n", "Looks like it is, thanks !\n"]}, {"number": 3321, "title": "Tensorflow with GPU on Mac OSX: Works in Python but NOT IPython", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Mac OSX 10.11.5\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 7.5\n\nlrwxr-xr-x  1 root  admin    13 Jul 14 13:25 /usr/local/cuda/lib/libcuda.1.dylib -> libcuda.dylib\n-rwxr-xr-x  1 root  wheel  8280 Apr 12 23:02 /usr/local/cuda/lib/libcuda.dylib\nlrwxr-xr-x  1 root  wheel    45 Apr 12 23:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\nlrwxr-xr-x  1 root  wheel    50 Apr 12 23:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\nlrwxr-xr-x  1 root  wheel    46 Apr 12 23:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\nlrwxr-xr-x  1 root  wheel    49 Apr 12 23:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\nlrwxr-xr-x  1 root  admin    47 Jul 14 12:37 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib\nlrwxr-xr-x  1 root  admin    45 Jul 14 12:37 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib\nlrwxr-xr-x  1 root  admin    48 Jul 14 12:37 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.  tensorflow\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.7.5.dylib locally\n0.9.0\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. Install Anaconda 64-bit Python 2.7\n2. Install Tensorflow for Mac with GPU support according to [these instructions](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-mac-os-x). Make sure to fix the [segmentation fault bug](https://github.com/tensorflow/tensorflow/issues/3263) as well.\n3. Open up ipython (not python) and import tensorflow\n\nIt works in Python:\n\n```\nXiaojians-MacBook-Pro:lib xjdeng$ python\nPython 2.7.11 |Anaconda 4.0.0 (x86_64)| (default, Dec  6 2015, 18:57:58) \n[GCC 4.2.1 (Apple Inc. build 5577)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import tensorflow\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.7.5.dylib locally\n>>> \n```\n\nBut not iPython:\n\n```\nXiaojians-MacBook-Pro:lib xjdeng$ ipython\nPython 2.7.11 |Anaconda 4.0.0 (x86_64)| (default, Dec  6 2015, 18:57:58) \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython 4.1.2 -- An enhanced Interactive Python.\n?         -> Introduction and overview of IPython's features.\n%quickref -> Quick reference.\nhelp      -> Python's own help system.\nobject?   -> Details about 'object', use 'object??' for extra details.\n\nIn [1]: import tensorflow\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-1-a649b509054f> in <module>()\n----> 1 import tensorflow\n\n/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()\n     21 from __future__ import print_function\n     22 \n---> 23 from tensorflow.python import *\n\n/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()\n     46 _default_dlopen_flags = sys.getdlopenflags()\n     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)\n---> 48 from tensorflow.python import pywrap_tensorflow\n     49 sys.setdlopenflags(_default_dlopen_flags)\n     50 \n\n/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\n     19         except ImportError:\n     20             return importlib.import_module('_pywrap_tensorflow')\n---> 21     _pywrap_tensorflow = swig_import_helper()\n     22     del swig_import_helper\n     23 elif _swig_python_version_info >= (2, 6, 0):\n\n/Users/xjdeng/anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py in swig_import_helper()\n     18             return importlib.import_module(mname)\n     19         except ImportError:\n---> 20             return importlib.import_module('_pywrap_tensorflow')\n     21     _pywrap_tensorflow = swig_import_helper()\n     22     del swig_import_helper\n\n/Users/xjdeng/anaconda/lib/python2.7/importlib/__init__.pyc in import_module(name, package)\n     35             level += 1\n     36         name = _resolve_name(name[level:], package, level)\n---> 37     __import__(name)\n     38     return sys.modules[name]\n\nImportError: No module named _pywrap_tensorflow\n\nIn [2]: import pywrap_tensorflow\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-2-6e414ae7ae75> in <module>()\n----> 1 import pywrap_tensorflow\n\nImportError: No module named pywrap_tensorflow\n\n\n```\n### What have you tried?\n1. I've googled for the error message `No module named _pywrap_tensorflow` but haven't gotten any useful results.  What's really puzzling is that tensorflow loads in python but not [ipython.]\n2. This error doesn't happen if I import tensorflow in a Jupyter notebook either.  Only iPython from the command line.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["Does your LD_LIBRARY_PATH include \"/usr/local/cuda/lib\"? Is it configured a system-wide, like in /etc/profile?\n", "Same problem on Ubuntu 16.04 when installing TensorFlow tensorflow-0.9.0  with CUDA (17.5) support according to the instructions at the website. Installation for Ubuntu Linux 16.04 64 bit, Anaconda2 64 bit.: https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#anaconda-installation\n\nSteps\n- conda create -n tensorflow python=2.7\n- source activate tensorflow\n- export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n- pip install --upgrade $TF_BINARY_URL\n\nNote that the last step fails initially, complaining about a non-existent file. After touching that file and re-running the pip install command both without and with the --upgrade flag again, the installation succeeds without error. \n\nIn python, import tensorflow works:\n\n```\n$ python\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /home/johann/software/anaconda2/lib/:/home/johann/torch/install/lib:\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:2092] Unable to load cuDNN DSO\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n>>> \n```\n\nBut with ipython tensorflow is not known:\n\n```\n$ ipython\nPython 2.7.12 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:42:40) \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython 4.2.0 -- An enhanced Interactive Python.\n?         -> Introduction and overview of IPython's features.\n%quickref -> Quick reference.\nhelp      -> Python's own help system.\nobject?   -> Details about 'object', use 'object??' for extra details.\n\nIn [1]: \nIn [1]: import tensorflow as tf\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-1-41389fad42b5> in <module>()\n----> 1 import tensorflow as tf\n\nImportError: No module named tensorflow\n\nIn [2]: \n```\n\nMy LD_LIBRARY_PATH is set to where the CUDA libraries are installed (usr/lib/x86_64-linux-gnu in my case). \n\nHowever, since I do not get any error message about a missing .so library when I try to load tensorflow in in ipython, I doubt this is related to LD_LIBRARY_PATH. ipython does not seem to know about tensorflow at all. \n\npython only knows tensorflow if, like shown in the instructions, the command `source activate tensorflow` is executed first. So maybe whatever this command does is not working for ipython? \n", "The solution is simple: when the tensorflow environment is activated, i.e. after running `source activate tensorflow`, ipython needs to get installed (again? specifically for that environment?) using `conda install ipython`. After this, importing tensorflow in ipython works just fine. \n\nThis seems to be a conda-specific procedure or requirement (I do not know that much about conda and simply tried if that would help). \n", "Sorry if I am misunderstanding, but are you saying this is a documentation bug or an installation bug?\n", "From my understanding of the mechanics of anaconda it looks like a documentation bug: apparently, this is how one needs to do things in an environment that gets activated by \"source activate tensorflow\". For example, one also has to install other python packages into that environment before they can be used. So unless this is regarded common knowledge, it would maybe be a good idea to mention that one has to install ipything into the environment in order to use tensorflow from ipython.\n", "Thanks. Would you submit a PR for the doc?\n", "https://github.com/tensorflow/tensorflow/pull/3514\n"]}, {"number": 3320, "title": "CPU vs GPU Performance", "body": "I am working on a reinforcement learning model problem.  I have been working to get the model creation running faster and bumped into a strange issue I cannot explain.  It runs much faster ~50% or so on the CPU vs the GPU.  This was unexpected and I have disabled the GPU using **\"export CUDA_VISIBLE_DEVICES=-1\"** so the learning runs faster.  I have been looking at upgrading my GTX 950, but not sure it makes sense if I don't get a speed improvement.\n\nI ran a profile based upon #1824 and got the following trace files for a single \".run()\" iteration. I am not sure how to read this, but the GPU iteration took over 10ms where the CPU alone is <10ms. I am running the HEAD of TensorFlow (reports 0.9.0) on Ubuntu 15.10 with CUDA 7.5 and cuDNN 4 & 5 (tried both). The CPU is a dual XEON 6 core, 2.66 GHz  processors (24 threads total) with 72 GB or RAM (DDR3).\n\nI have a GTX 950 GPU.  I can't tell if this performance difference is related to the structure of the graph or simply the data set isn't big enough to get a benefit from the GPU given the IO overhead?  I have tested the GPU with TF on a basic \"matmut()\" of a 7000x7000 matrix and it beats the CPU hands down by orders of magnitude.  So I known it is installed correctly.\n\nThen networks runs in this case a Batch of 200 x 189 into 5 layers with Dropout() between each layer. The layers are 140, 120, 100, 80, and 3 as the output.  Any advice or things to try would be much appreciated.\n\n**CPU Timeline:**\n![cpu timeline](https://cloud.githubusercontent.com/assets/18412448/16854147/ad4c8760-49dd-11e6-8919-2c0940322b53.png)\n\n**GPU Timeline:**\n![gpu timeline](https://cloud.githubusercontent.com/assets/18412448/16854181/cfa25844-49dd-11e6-9f20-e2268bdd4299.png)\n\nNOTE: This issue was posted to #2444 but may have got lost.  It might be related to RL performance but feel it is a separate issue.\n\nI have enclosed the TIMELINE trace files for more detail.  If it is of value, I can create a \"tensorboard\" log file so you can review the model in detail.\n[GPU Slowdown.zip](https://github.com/tensorflow/tensorflow/files/364706/GPU.Slowdown.zip)\n", "comments": ["@zheng-xq Could you take a look at this please?\n", "A few observations: \n1. GTX 950 is definitely a low-end card for deep learning. It is roughly 1/4 of a Titan-X, which is a good card. \n2. You have a lot of small GPU kernels, which medium and large gaps in-between them. So the total amount of GPU compute time is probably much smaller than 10ms, but you GPU has a lot of idle time. \n\nA few possible things to try: \n\nA. Each of your kernel is too small, merge them into larger kernels. Use larger batch, and bigger shapes, so each op has more computation to it. For example, 7000 x 7000 matmul is something that is very good for GPU. \nB. Reduce the overhead of each op. Make sure your have as little memory transfer between devices as possible. Make sure you don't have other CPU intensive computation that holds the kernel launch. Also it is possible that you have too many threads launching GPU kernels that are thrashing each other. Play with inter_op_parallelism_threads to a smaller number. \n\nThe best way to get more help is to upload a small repro case so more people can help. \n\nHave fun. \n", "@zheng-xq, sorry for the delay getting back to you but as I was putting the test case together I bumped into some unexpected results.\n\nWhat I did was to take my **Original Solution** and stripped out the \"Game Environment\".  I replaced it with a random data generation.  In this Game Environment, there is no creation/modification of the TensorFlow Graph.  The structure closely follows/leverages [nivwusquorum's Github Reinforcement Learning Example](https://github.com/nivwusquorum/tensorflow-deepq/tree/master).\n\nOn 7/15/2016 I did a \"git pull\" to head for Tensorflow.  I executed the Graph with and without the GPU enabled and recorded the times (see attached chart).  The unexpected result is the GPU outperformed the CPU (which is the initial expectation that wasn't met).  So this code \"cpuvsgpu.py\" with the supporting libraries performs better with the GPU.  So I turned my attention to what may be different between my **Original Solution** and the published code.  I also update the head to 7/17/2016.  Something did improve as the overall difference between the CPU & GPU on the **Original Solution** is much closer than a week again where I was seeing 47s CPU vs 71s GPU .  A quick look at the new Traces vs my initial trace, seems like \"summary's\" may have been changed but there may have been other improvements as well. \n\n![gtx 950 timing](https://cloud.githubusercontent.com/assets/18412448/16904662/0cc86c72-4c68-11e6-9a79-c06bb1565215.png)\n\nI tried 2 other combinations to better reflect how the **Original Solution** functioned.  Those were under heavy CPU load (~60% - 70%) and simulated that with concurrent execution of that script.  The other variation was to increase the \"Data IO\", the **Original Solution** uses lists of observations to randomly select observations for training.  This list has a fixed upper limit and then starts deleting the first item in the list while appending the new.  I figured maybe one of these was slowing down streaming of data to the GPU.  Unfortunately, neither of these version caused the CPU to outperform the GPU.  I also ran a quick GPUTESTER app which does large matrix multiplication to get a feel for timing differences with size of task and are as expected.\n\nI have enclosed the test scripts as well as some of the raw data, Trace Files & TensorBoard log files to speed up any review.\n[CPUvsGPU testing.zip](https://github.com/tensorflow/tensorflow/files/368246/CPUvsGPU.testing.zip)\n\nI am going to keep looking at the **Original Solution** to see if I can figure out what is indirectly causing the GPU to perform poorly (any thoughts you have would be great).  I am going to start at the only real interface between the Game Environment and the graph and that is the \"current_controller.store(observation, action, reward, new_observation)\" line.  The only thing I can figure is maybe \"observation\"'s are not the same as what I think is generated by the Game Environment.  Again, not sure why GPU would perform poorly compared to CPU but would like to understand where this indirect affect on the graph is taking place.  Reinforcement Learning is slow as it is so any performance improvement would be appreciated.\n\nI would like to follow-up with you on your comments from above as I really don't know how to improve this graph or where the small OPS may be hiding.  Also, batch size may affect convergence negatively but I can experiment with that future.  It seems like this is where most of the performance may be going.  Also, if you have any tricks to combine smaller ops into bigger ones without impacting the logic (function) of the graph. \n"]}, {"number": 3319, "title": "TensorFlow Android demo crashes on start", "body": "I installed the TensorFlow on my mac and tried the Android demo. It is confusing that it's all fine with compiling to .apk, but the application crashes as soon as it starts on my Nexus5 cellphone.\n### Environment info\n\nOperating System: Mac OS X\nAndroid SDK: 24.0.0\nAndroid NDK: r10e (will encounter problems when building with bazel if using latest v12)\nBazel: 0.1.4\nCellphone OS: Android 6\n\nI tried using adb to install the application, and everything seems perfectly fine until I launched the application. Before that, I have already checked that the camera permission is fine. As soon as I open the application, it will immediately crash. I grabbed the log from my device. Besides, I also compared the log with those generated by a successfully running demo. The main difference starts from:\n **07-14 14:00:46.044  2754  2754 E tensorflow: CameraConnectionFragment: Couldn't find any suitable preview size**\nCould anyone help me on finding out what cause this problem? The complete log is attached below.\n### Logs or other output that would be helpful\n\n07-14 14:00:45.722   773  1502 I ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=org.tensorflow.demo/.CameraActivity (has extras)} from uid 10022 on display 0\n07-14 14:00:45.735   202   811 D audio_hw_primary: out_set_parameters: enter: usecase(1: low-latency-playback) kvpairs: routing=2\n07-14 14:00:45.767   202   811 D AudioFlinger: mixer(0xb4100000) throttle end: throttle time(9)\n07-14 14:00:45.767  2754  2754 I art     : Late-enabling -Xcheck:jni\n07-14 14:00:45.768   773   947 I ActivityManager: Start proc 2754:org.tensorflow.demo/u0a84 for activity org.tensorflow.demo/.CameraActivity\n07-14 14:00:45.800  2734  2734 W System  : ClassLoader referenced unknown path: /system/priv-app/MediaProvider/lib/arm\n07-14 14:00:45.815  2734  2734 W System  : ClassLoader referenced unknown path: /system/priv-app/DownloadProvider/lib/arm\n07-14 14:00:45.858  2754  2754 W linker  : /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so: unused DT entry: type 0x1d arg 0x10ff60a\n07-14 14:00:45.871  1146  1929 D GCM     : GcmService start Intent { act=com.google.android.checkin.CHECKIN_COMPLETE flg=0x10 cmp=com.google.android.gms/.gcm.GcmService (has extras) } com.google.android.checkin.CHECKIN_COMPLETE\n07-14 14:00:45.875  1566  1566 D ChimeraCfgMgr: Loading module com.google.android.gms.kids from APK com.google.android.gms\n07-14 14:00:45.876  1566  1566 I Kids    : [GCoreUtils] Current gmscore version, 8186438 is smaller than the required version 8400000\n07-14 14:00:45.907  1385  1385 V UserPresentBroadcastReceiver: Received Intent { act=android.intent.action.USER_PRESENT flg=0x24000010 cmp=com.google.android.gms/.auth.trustagent.UserPresentBroadcastReceiver }.\n07-14 14:00:45.937  2754  2788 D OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\n07-14 14:00:45.979  1408  1408 W LocationOracleImpl: Not started: ignore location\n07-14 14:00:45.981  1408  1408 E LocationReceiver: Received bad location: null\n07-14 14:00:45.984  1408  1408 E LocationReceiver: Received bad location: null\n07-14 14:00:45.990  2754  2788 I Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 10/21/15, 369a2ea, I96aee987eb\n07-14 14:00:45.994  2754  2788 I OpenGLRenderer: Initialized EGL, version 1.4\n07-14 14:00:46.025  1258  1258 I Keyboard.Facilitator: onFinishInput()\n07-14 14:00:46.026  2754  2754 I CameraManagerGlobal: Connecting to camera service\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 3264x2448\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 3200x2400\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 2592x1944\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 2048x1536\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1920x1080\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1600x1200\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1280x960\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1280x768\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1280x720\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 1024x768\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 800x600\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 800x480\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 720x480\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 640x480\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 352x288\n07-14 14:00:46.043  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 320x240\n07-14 14:00:46.044  2754  2754 I tensorflow: CameraConnectionFragment: Not adding size: 176x144\n07-14 14:00:46.044  2754  2754 E tensorflow: CameraConnectionFragment: Couldn't find any suitable preview size\n07-14 14:00:46.049   202   887 I CameraService: CameraService::connect call (PID 2754 \"org.tensorflow.demo\", camera ID 0) for HAL version default and Camera API version 2\n07-14 14:00:46.052   202   887 I CameraService: onTorchStatusChangedLocked: Torch status changed for cameraId=0, newStatus=0\n07-14 14:00:46.052   202   887 I Camera2ClientBase: Camera 0: Opened. Client: org.tensorflow.demo (PID 2754, UID 10084)\n07-14 14:00:46.052   202   887 I CameraDeviceClient: CameraDeviceClient 0: Opened\n07-14 14:00:46.057   202   887 D mm-camera-intf: mm_camera_open: dev name = /dev/video1, cam_idx = 1\n07-14 14:00:46.061   217   217 I mm-camera-sensor: module_sensor_start_session:584 session 1\n07-14 14:00:46.074  2696  2732 I MediaStoreImporter: Update: incremental Added music: 0 Updated music: 0 Deleted music: 0 Created playlists: 0 Updated playlists: 0 Deleted playlists: 0 Inserted playlist items: 0 Deleted playlist items: 0 Removed orphaned playlist items: 0\n07-14 14:00:46.075  2696  2696 D MusicLifecycle: com.google.android.music.store.MediaStoreImportService generated event: Service destroyed\n07-14 14:00:46.076   773  1275 I ActivityManager: Killing 2280:com.google.android.configupdater/u0a27 (adj 15): empty #17\n07-14 14:00:46.102   217   217 I mm-camera: gyro_module_start_session: Enter\n07-14 14:00:46.102   217   217 I mm-camera: gyro_module_start_session: Init DSPS\n07-14 14:00:46.103   217   217 E mm-camera: Failed to open sensor1 port\n07-14 14:00:46.103   217   217 I mm-camera: gyro_module_start_session: dsps_proc_init() failed\n07-14 14:00:46.103   217   217 I mm-camera: gyro_module_get_port: Exit failure\n07-14 14:00:46.103   217   217 I mm-camera: cpp_module_start_session:352, info: starting session 1\n07-14 14:00:46.113   773  1275 I ActivityManager: Killing 2255:com.google.android.apps.gcs/u0a25 (adj 15): empty #18\n07-14 14:00:46.122   217  2793 I mm-camera: cpp_thread_func:55: cpp_thread entering the polling loop...\n07-14 14:00:46.122   217   217 I mm-camera: cpp_module_start_session:433, info: cpp_thread created.\n07-14 14:00:46.122   217   217 I mm-camera: cpp_module_start_session:436, info: session 1 started.\n07-14 14:00:46.122   217   217 I mm-camera: c2d_module_start_session:246, info: starting session 1\n07-14 14:00:46.122   217   217 I mm-camera: c2d_module_start_session:284, info: c2d_thread created.\n07-14 14:00:46.122   217  2794 I mm-camera: c2d_thread_func:39: c2d_thread entering the polling loop...\n07-14 14:00:46.124   217   217 I mm-camera: c2d_module_start_session:306, info: session 1 started.\n07-14 14:00:46.125   217   217 I mm-camera-sensor: module_module_set_session_data:2667 max delay 2 report dSelay 1\n07-14 14:00:46.125   217   217 D mm-camera: module_faceproc_set_session_data:1987] Per frame control 2 1\n07-14 14:00:46.125   202   887 D mm-camera-intf: mm_camera_open:  opened, break out while loop\n07-14 14:00:46.125  1872  1878 E ANDR-PERF-LOCK: Failed to apply optimization for resource: 4 level: 0\n07-14 14:00:46.131  2754  2786 I tensorflow: CameraConnectionFragment: Opening camera preview: 3264x2448\n07-14 14:00:46.139   202   887 W CameraDeviceClient: createStream: Camera 0: Forcing asynchronous mode for stream\n07-14 14:00:46.139   202   887 W CameraDeviceClient: createStream: Camera 0: Overriding format 0x1 to IMPLEMENTATION_DEFINED\n07-14 14:00:46.140   202  2542 E CameraDeviceClient: createStream: bufferProducer must not be null\n--------- beginning of crash\n07-14 14:00:46.141  2754  2786 E AndroidRuntime: FATAL EXCEPTION: CameraBackground\n07-14 14:00:46.141  2754  2786 E AndroidRuntime: Process: org.tensorflow.demo, PID: 2754\n07-14 14:00:46.141  2754  2786 E AndroidRuntime: java.lang.IllegalArgumentException: Bad argument passed to camera service\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.utils.CameraBinderDecorator.throwOnError(CameraBinderDecorator.java:114)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.utils.CameraBinderDecorator$CameraBinderDecoratorListener.onAfterInvocation(CameraBinderDecorator.java:73)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.utils.Decorator.invoke(Decorator.java:81)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at java.lang.reflect.Proxy.invoke(Proxy.java:393)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at $Proxy1.createStream(Unknown Source)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl.configureStreamsChecked(CameraDeviceImpl.java:429)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl.createCaptureSessionInternal(CameraDeviceImpl.java:561)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl.createCaptureSession(CameraDeviceImpl.java:476)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment.createCameraPreviewSession(CameraConnectionFragment.java:471)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment.access$400(CameraConnectionFragment.java:63)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment$2.onOpened(CameraConnectionFragment.java:144)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl$1.run(CameraDeviceImpl.java:134)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.Handler.handleCallback(Handler.java:739)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.Handler.dispatchMessage(Handler.java:95)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.Looper.loop(Looper.java:148)\n07-14 14:00:46.141  2754  2786 E AndroidRuntime:    at android.os.HandlerThread.run(HandlerThread.java:61)\n07-14 14:00:46.159   773   792 I ActivityManager: Displayed org.tensorflow.demo/.CameraActivity: +404ms\n07-14 14:00:46.162   773  1503 W ActivityManager:   Force finishing activity org.tensorflow.demo/.CameraActivity\n", "comments": ["Hi, could you please update to bazel 0.3.0 and try again?\n\nThe demo should definitely work on a stock nexus 5. Have you made any changes to the code at all, like modifying the model parameters? It uses the input size to pick preview size.\n", "I used to build with bazel 0.3.0, but it tells me that `ERROR: /tensorflow/WORKSPACE:70:1: new_git_repository rule //external:iron-ajax' s name field must be a legal workspace name.`. According to issue [#1047](https://github.com/tensorflow/tensorflow/issues/1047), I switched back to bazel 0.1.4. \n", "By the way my TensorFlow version is: 0.9.0 mac os x CPU only. I installed using python: `# Mac OS X, CPU only, Python 2.7:\n(tensorflow)$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py2-none-any.whl`\n", "Just git clone the master branch from TensorFlow, and upgrade Bazel to 0.3.0, NDK to v12. The building is still fine without previously appeared errors. However, the app still crash on the phone for a different reason. Attached is the log:\n\n07-14 22:07:56.070  2364  2382 I tensorflow: CameraConnectionFragment: Getting assets.\n07-14 22:07:56.072  2364  2382 E art     : No implementation found for int org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String) (tried Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow and Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow__Landroid_content_res_AssetManager_2Ljava_lang_String_2Ljava_lang_String_2IIIFLjava_lang_String_2Ljava_lang_String_2)\n--------- beginning of crash\n07-14 22:07:56.073  2364  2382 E AndroidRuntime: FATAL EXCEPTION: ImageListener\n07-14 22:07:56.073  2364  2382 E AndroidRuntime: Process: org.tensorflow.demo, PID: 2364\n07-14 22:07:56.073  2364  2382 E AndroidRuntime: java.lang.UnsatisfiedLinkError: No implementation found for int org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String) (tried Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow and Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow__Landroid_content_res_AssetManager_2Ljava_lang_String_2Ljava_lang_String_2IIIFLjava_lang_String_2Ljava_lang_String_2)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(Native Method)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at org.tensorflow.demo.TensorflowImageListener.initialize(TensorflowImageListener.java:84)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment.createCameraPreviewSession(CameraConnectionFragment.java:540)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment.access$400(CameraConnectionFragment.java:63)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at org.tensorflow.demo.CameraConnectionFragment$2.onOpened(CameraConnectionFragment.java:155)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at android.hardware.camera2.impl.CameraDeviceImpl$1.run(CameraDeviceImpl.java:134)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at android.os.Handler.handleCallback(Handler.java:739)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at android.os.Handler.dispatchMessage(Handler.java:95)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at android.os.Looper.loop(Looper.java:148)\n07-14 22:07:56.073  2364  2382 E AndroidRuntime:    at android.os.HandlerThread.run(HandlerThread.java:61)\n", "I'm seeing the same issue except on a stock Nexus 5x. Only difference is I'm using bazel 2.0.\n", "@PatrickGuo initializeTensorflow() is a native method; can you tell if Bazel is building the native libs? Try `unzip -v bazel-bin/tensorflow/examples/android/tensorflow_demo.apk | grep libtensorflow_demo.so` and you should see output like:\n`5163140  Defl:N  1753712  66% 1980-01-01 00:00 7b8de845  lib/armeabi-v7a/libtensorflow_demo.so`\n\nAlso can you build with `-s --verbose_failures` and attach the build log please?\n\n@pkpp1233 Are you seeing the preview size error or the no implementation error?\n", "@andrewharp Attached is the building log. I also tried the `unzip | grep` command and the output is pretty the same as yours `14545924  Defl:N  3554961  76%  01-01-80 00:00  27d80c72  lib/armeabi-v7a/libtensorflow_demo.so`. \n[build-log.txt](https://github.com/tensorflow/tensorflow/files/366201/build-log.txt)\n", "@PatrickGuo Strange, it seems like it's building the native libs just fine. I'd also expect it to fail on the static loadLibrary call if there was a problem loading the .so itself, but it doesn't seem to be doing that.\n\nHave you made any changes at all to the code? Changing package names or method signatures?\n", "Having the same issue.\u2026\n", "@kokozaurz Which issue, are you seeing the preview size error or the no implementation error?\n", "It is adding size fine\u2026 Samsung Galaxy Tab A6, Android 5.1.1, building with bazel version 0.3.0\n\nThe Crash starts here- \n\n...\n\n```\nE/AndroidRuntime(26848): FATAL EXCEPTION: ImageListener\nE/AndroidRuntime(26848): Process: org.tensorflow.demo, PID: 26848\nE/AndroidRuntime(26848): java.lang.UnsatisfiedLinkError: No implementation found for int org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String) (tried Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow and Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow__Landroid_content_res_AssetManager_2Ljava_lang_String_2Ljava_lang_String_2IIIFLjava_lang_String_2Ljava_lang_String_2)\nE/AndroidRuntime(26848):    at org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(Native Method)\nE/AndroidRuntime(26848):    at org.tensorflow.demo.TensorflowImageListener.initialize(TensorflowImageListener.java:84)\nE/AndroidRuntime(26848):    at org.tensorflow.demo.CameraConnectionFragment.createCameraPreviewSession(CameraConnectionFragment.java:540)\nE/AndroidRuntime(26848):    at org.tensorflow.demo.CameraConnectionFragment.access$400(CameraConnectionFragment.java:63)\nE/AndroidRuntime(26848):    at org.tensorflow.demo.CameraConnectionFragment$2.onOpened(CameraConnectionFragment.java:155)\nE/AndroidRuntime(26848):    at android.hardware.camera2.impl.CameraDeviceImpl$1.run(CameraDeviceImpl.java:118)\nE/AndroidRuntime(26848):    at android.os.Handler.handleCallback(Handler.java:739)\nE/AndroidRuntime(26848):    at android.os.Handler.dispatchMessage(Handler.java:95)\nE/AndroidRuntime(26848):    at android.os.Looper.loop(Looper.java:145)\nE/AndroidRuntime(26848):    at android.os.HandlerThread.run(HandlerThread.java:61)\nW/ActivityManager(  735):   Force finishing activity 1 org.tensorflow.demo/.CameraActivity\nD/FocusedStackFrame(  735): Set to : 0\nD/InputDispatcher(  735): Focused application set to: xxxx\nD/InputDispatcher(  735): Focus left window: 26848\nD/PointerIcon(  735): setMouseIconStyle1 pointerType: 1001 iconType:101 flag:0 pid:735 uid:1000\nI/ActivityManager(  735): Skip updateThumbnail for r=ActivityRecord{59212fe u0 org.tensorflow.demo/.CameraActivity t83 f}\nD/PointerIcon(  735): setMouseCustomIcon IconType is same.101\nE/android.os.Debug(  735): ro.product_ship = true\nE/android.os.Debug(  735): ro.debug_level = 0x4f4c\nI/ShotCommon(  177): disableMsgType (0x10)\nI/SprdCameraHardware(  177): 'mLock:disableMsgType E.\nI/SprdCameraHardware(  177): 'mLock:disableMsgType X.\nI/ShotCommon(  177): disableMsgType (0xffffffff)\nI/SprdCameraHardware(  177): 'mLock:disableMsgType E.\nI/SprdCameraHardware(  177): 'mLock:disableMsgType X.\nI/ShotSingle(  177): stopPreview E\n```\n\n....\n", "@kokozaurz Have you checked that the native lib is getting built and put into the APK as well?\n", "built as mentioned above with -s --verbose_failures and this is the log. Interesting enough it's way smaller than previously attached log by @PatrickGuo \n\n[buildlog.txt](https://github.com/tensorflow/tensorflow/files/366735/buildlog.txt)\n\nIs something missing there?\n\nP.S By running `unzip -v bazel-bin/tensorflow/examples/android/tensorflow_demo.apk | grep libtensorflow_demo.so` I get this `14545924  Defl:N  3554945  76%  01-01-80 00:00  ffc64aec  lib/armeabi-v7a/libtensorflow_demo.so`\n", "Also just tried on LG G4 Android 6.0.0 - the same error. \n", "@andrewharp no implementation error for me. Let me know if you need more info, but here's were the error pops in:\n\n```\n07-15 13:50:35.966 20777 20791 E art     : No implementation found for int org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String) (tried Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow and Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow__Landroid_content_res_AssetManager_2Ljava_lang_String_2Ljava_lang_String_2IIIFLjava_lang_String_2Ljava_lang_String_2)\n07-15 13:50:35.967 20777 20791 E AndroidRuntime: FATAL EXCEPTION: ImageListener\n07-15 13:50:35.967 20777 20791 E AndroidRuntime: Process: org.tensorflow.demo, PID: 20777\n07-15 13:50:35.967 20777 20791 E AndroidRuntime: java.lang.UnsatisfiedLinkError: No implementation found for int org.tensorflow.demo.TensorflowClassifier.initializeTensorflow(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String) (tried Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow and Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow__Landroid_content_res_AssetManager_2Ljava_lang_String_2Ljava_lang_String_2IIIFLjava_lang_String_2Ljava_lang_String_2)\n```\n", "@pkpp1233 @kokozaurz @PatrickGuo \n\nOk, the problem is that a recent global renaming for Tensorflow to Tensor**F**low caught the native identifier in [tensorflow_jni.h](https://github.com/tensorflow/tensorflow/blob/aedd2173deef51661ab0cabcb9009d249e744e31/tensorflow/examples/android/jni/tensorflow_jni.h#L31)  but did not correspondingly rename [TensorflowClassifier.java](https://github.com/tensorflow/tensorflow/blob/060484b39d0813a5e209f90d9de81413da310cac/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowClassifier.java).\n\nEither s/TensorFlow/Tensorflow/ in tensorflow_jni.h, or rename and change the class of TensorflowClassifier.java to TensorFlowClassifier. I'll submit a fix to do the latter soon.\n", "@andrewharp hehe this does look like a losing battle (https://github.com/tensorflow/tensorflow/commit/c87a7ca3113c95aaf52de7a094773feb2dba2fa1).\n\nI renamed [TensorflowClassifier.java](https://github.com/tensorflow/tensorflow/blob/060484b39d0813a5e209f90d9de81413da310cac/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowClassifier.java) but then an error tells me to rename [TensorflowImageListener.java#L64](https://github.com/tensorflow/tensorflow/blob/060484b39d0813a5e209f90d9de81413da310cac/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowImageListener.java#L64).\n\n```\n07-15 19:05:50.242 13826 13859 E art     : No implementation found for int org.tensorflow.demo.TensorFlowClassifier.initializeTensorflow(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String) (tried Java_org_tensorflow_demo_TensorFlowClassifier_initializeTensorflow and Java_org_tensorflow_demo_TensorFlowClassifier_initializeTensorflow__Landroid_content_res_AssetManager_2Ljava_lang_String_2Ljava_lang_String_2IIIFLjava_lang_String_2Ljava_lang_String_2)\n07-15 19:05:50.244 13826 13859 E AndroidRuntime: FATAL EXCEPTION: ImageListener\n```\n\nI'll keep going down the rabbit hole and see what I can find...\n", "Easy fix, see commit on my fork - https://github.com/pkpp1233/tensorflow/commit/13be44b9c8fe212ea2408a4c27b21f4092b5437d\n", "@andrewharp Ok, such a tricky one. @pkpp1233 Thanks for your note. Now it works perfectly fine on my android devices.\n", "Fixed in https://github.com/tensorflow/tensorflow/pull/3336/commits/194efde51895e0251d39c72c969dff1a50b67d35. Thanks for the reports!\n", "@andrewharp I have a similar issue, but I cannot figure out how to solve it [gist](https://gist.github.com/erotavlas85/a6adc607f13d6e4a540f5e6da1ec8b2b). Is there any precompiled apk? I'm using the apk found on this blog https://jalammar.github.io/ on cyanogenmod 13 aka android 6.0.1 on samsung s2.\nThank you\n", "@erotavlas85 You can find automated builds of the demo apk on the [TF Android Jenkins](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-android/). Here's a [direct link](https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-android/TF_BUILD_CONTAINER_TYPE=ANDROID,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=NO_PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=android-slave/lastSuccessfulBuild/artifact/bazel-out/local_linux/bin/tensorflow/examples/android/tensorflow_demo.apk) to the latest APK.\n\nI don't see any errors in your gist -- everything seems to be working normally up to the point the log ends. What issues are you experiencing?\n", "@andrewharp Thank you for the link. I tried with another smartphone and it worked. So there should be a problem with my old s2. The application starts well, but it stops and exits automatically. Is there any problem with cyanogenmod? I do not think so.\n"]}, {"number": 3318, "title": "Make the default command use a named container", "body": "It seems that it's a more common workflow than I assumed, and should be relatively foolproof.\n", "comments": []}]