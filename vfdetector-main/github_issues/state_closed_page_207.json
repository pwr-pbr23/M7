[{"number": 48457, "title": "Remove broken link in tf.keras.callbacks.TensorBoard at docs page", "body": "## Description\r\nThis PR fixes #48174 \r\n\r\nThis actually related to docs-error. So, I removed the broken link along with the line. Refer the issue for more details\r\n\r\n## Changes made\r\nRemoved the link along with the line concerned\r\n\r\n## Notes for reviewers\r\nIf any changes are to be made/reverted, please let me know! :)", "comments": ["I didn't check but that link throws a 404 error whenever user clicks it", "Any link is there then to replace it? If such, then I'll replace it instead of removing the line", "Everyone I've changed the issue no referenced"]}, {"number": 48456, "title": "\"OP_REQUIRES failed at conv_grad_input_ops.cc:1103 : Resource exhausted...\" after training for a while", "body": "**System information**\r\n- Windows10\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6.12\r\n- CUDA/cuDNN version: cudatoolkit=10.1, cudnn=7.6\r\n- GPU model and memory: 6GB\r\n\r\n**Describe the current behavior**\r\n- I want to train a model using `GradientTape`. The training went well at the beginning, but **after 27 batches** (`batch_size=4 `in this case) the error report pops out. It's like the memory usage is not released and accumulated, otherwise it's supposed to report this error at the beginning, right? (but I don't know for sure...)\r\n- Reducing `batch_size` fro 4 to 2 doesn't help, only making the progress proceed to 70 batches, then the error appeared again. Therefore I don't think it's about batch_size.\r\n\r\n**Standalone code to reproduce the issue**\r\nSince there are 4 models loaded and the code is massive (many custom loss functions) it's difficult to reproduce the error with minimal implementation. So sorry that I don't know how to reproduce this error with minimal implementation.\r\nBut I used to run the training code bug-free, until I rewrote a part of my **custom loss function**. So it must be something wrong with that part. I will just show that part\r\n\r\n```\r\n\r\ndef project_3d(points, K, T, shape, scale):\r\n    \"\"\"Layer which projects 3D points into a camera with intrinsics K and at position T\r\n    \"\"\"\r\n    batch_size, height, width, _ = shape\r\n    height, width = height // (2 ** scale), width // (2 ** scale)\r\n    eps = 1e-7\r\n\r\n    P = tf.matmul(K, T)[:, :3, :]\r\n\r\n    cam_points = tf.matmul(P, points)\r\n    pix_coords = cam_points[:, :2, :] / (tf.expand_dims(cam_points[:, 2, :], axis=1) + eps)\r\n    pix_coords = tf.reshape(pix_coords, (batch_size, 2, height, width))\r\n    pix_coords = tf.transpose(pix_coords, [0, 2, 3, 1])\r\n    pix_coords = pix_coords.numpy()\r\n    pix_coords[..., 0] /= width - 1\r\n    pix_coords[..., 1] /= height - 1\r\n    pix_coords = (pix_coords - 0.5) * 2\r\n    return pix_coords\r\n\r\n\r\ndef back_proj_depth(depth, inv_K, shape, scale):\r\n    \"\"\"Layer to transform a depth image into a point cloud\r\n    shape_s: scaled shapes, corresponds to scales = [0,1,2,3]\r\n    \"\"\"\r\n\r\n    batch_size, height, width, _ = shape\r\n    height, width = height // (2**scale), width // (2**scale)\r\n\r\n    meshgrid = tf.meshgrid(range(width), range(height), indexing='xy')\r\n    id_coords = tf.stack(meshgrid, axis=0)\r\n\r\n    ones = tf.ones((batch_size, 1, height * width), dtype=tf.int32)\r\n\r\n    pix_coords = tf.expand_dims(\r\n        tf.stack([tf.reshape(id_coords[0], [-1]),\r\n                  tf.reshape(id_coords[1], [-1])], 0), 0)\r\n\r\n    multiples = tf.constant([batch_size, 1, 1])\r\n    pix_coords = tf.tile(pix_coords, multiples)\r\n\r\n    pix_coords = tf.concat([pix_coords, ones], 1)\r\n    pix_coords = tf.cast(pix_coords, tf.float32)\r\n\r\n    ones = tf.cast(ones, tf.float32)\r\n\r\n    cam_points = tf.matmul(inv_K[:,:3, :3], pix_coords)\r\n    cam_points = tf.reshape(depth, (batch_size, 1, -1)) * cam_points\r\n    cam_points = tf.concat([cam_points, ones], 1)\r\n    return cam_points\r\n\r\n\r\ndef bilinear_sampler(img, coords):\r\n    \"\"\" TF-version Bilinear Sampler\r\n    Performs bilinear sampling of the input images according to the\r\n    normalized coordinates provided by the sampling grid. Note that\r\n    the sampling is done identically for each channel of the input.\r\n    To test if the function works properly, output image should be\r\n    identical to input image when theta is initialized to identity transform.\r\n    Input\r\n    -----\r\n    - img: batch of images in (B, H, W, C) layout.\r\n    - grid: x, y which is the output of affine_grid_generator.\r\n    Returns\r\n    -------\r\n    - out: interpolated images according to grids. Same size as grid.\r\n    \"\"\"\r\n\r\n    def get_pixel_value(img, x, y):\r\n        \"\"\"\r\n        Utility function to get pixel value for coordinate\r\n        vectors x and y from a  4D tensor image.\r\n        Input\r\n        -----\r\n        - img: tensor of shape (B, H, W, C)\r\n        - x: flattened tensor of shape (B*H*W,)\r\n        - y: flattened tensor of shape (B*H*W,)\r\n        Returns\r\n        -------\r\n        - output: tensor of shape (B, H, W, C)\r\n        \"\"\"\r\n        shape = tf.shape(x)\r\n        batch_size = shape[0]\r\n        height = shape[1]\r\n        width = shape[2]\r\n\r\n        batch_idx = tf.range(0, batch_size)\r\n        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\r\n        b = tf.tile(batch_idx, (1, height, width))\r\n\r\n        indices = tf.stack([b, y, x], 3)\r\n        res = tf.gather_nd(img, indices)\r\n        return res\r\n\r\n    H = tf.shape(img)[1]\r\n    W = tf.shape(img)[2]\r\n    max_y = tf.cast(H - 1, 'int32')\r\n    max_x = tf.cast(W - 1, 'int32')\r\n    zero = tf.zeros([], dtype='int32')\r\n\r\n    x, y = coords[:, ..., 0], coords[:, ..., 1]\r\n    x = tf.cast(x, 'float32')\r\n    y = tf.cast(y, 'float32')\r\n    x = 0.5 * ((x + 1.0) * tf.cast(max_x - 1, 'float32'))\r\n    y = 0.5 * ((y + 1.0) * tf.cast(max_y - 1, 'float32'))\r\n\r\n    # grab 4 nearest corner points for each (x_i, y_i)\r\n    x0 = tf.cast(tf.floor(x), 'int32')\r\n    x1 = x0 + 1\r\n    y0 = tf.cast(tf.floor(y), 'int32')\r\n    y1 = y0 + 1\r\n\r\n    # clip to range [0, H-1/W-1] to not violate img boundaries\r\n    x0 = tf.clip_by_value(x0, zero, max_x)\r\n    x1 = tf.clip_by_value(x1, zero, max_x)\r\n    y0 = tf.clip_by_value(y0, zero, max_y)\r\n    y1 = tf.clip_by_value(y1, zero, max_y)\r\n\r\n    # get pixel value at corner coords\r\n    Ia = get_pixel_value(img, x0, y0)\r\n    Ib = get_pixel_value(img, x0, y1)\r\n    Ic = get_pixel_value(img, x1, y0)\r\n    Id = get_pixel_value(img, x1, y1)\r\n\r\n    # recast as float for delta calculation\r\n    x0 = tf.cast(x0, 'float32')\r\n    x1 = tf.cast(x1, 'float32')\r\n    y0 = tf.cast(y0, 'float32')\r\n    y1 = tf.cast(y1, 'float32')\r\n\r\n    # calculate deltas\r\n    wa = (x1 - x) * (y1 - y)\r\n    wb = (x1 - x) * (y - y0)\r\n    wc = (x - x0) * (y1 - y)\r\n    wd = (x - x0) * (y - y0)\r\n\r\n    # add dimension for addition\r\n    wa = tf.expand_dims(wa, axis=3)\r\n    wb = tf.expand_dims(wb, axis=3)\r\n    wc = tf.expand_dims(wc, axis=3)\r\n    wd = tf.expand_dims(wd, axis=3)\r\n\r\n    # compute output\r\n    out = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])\r\n    return out\r\n\r\n\r\ndef transformation_from_parameters(axisangle, translation, invert=False):\r\n    \"\"\"Convert the network's (axisangle, translation) output into a 4x4 matrix\r\n    \"\"\"\r\n\r\n    R = rot_from_axisangle(axisangle)\r\n    t = tf.identity(translation)\r\n\r\n    if invert:\r\n        R = tf.transpose(R, (0, 2, 1))\r\n        t *= -1\r\n\r\n    T = get_translation_matrix(t)\r\n\r\n    if invert:\r\n        M = tf.matmul(R, T)\r\n    else:\r\n        M = tf.matmul(T, R)\r\n    return M\r\n\r\n\r\ndef get_translation_matrix(trans_vec):\r\n    \"\"\"Convert a translation vector into a 4x4 transformation matrix\r\n    \"\"\"\r\n    batch_size = trans_vec.shape[0]\r\n    one = tf.ones([batch_size, 1, 1], dtype=tf.float32)\r\n    zero = tf.zeros([batch_size, 1, 1], dtype=tf.float32)\r\n\r\n    T = tf.concat([\r\n        one, zero, zero, trans_vec[:, :, :1],\r\n        zero, one, zero, trans_vec[:, :, 1:2],\r\n        zero, zero, one, trans_vec[:, :, 2:3],\r\n        zero, zero, zero, one\r\n\r\n    ], axis=2)\r\n    T = tf.reshape(T, [batch_size, 4, 4])\r\n    return T\r\n\r\n\r\ndef rot_from_axisangle(vec):\r\n    \"\"\"Convert an axisangle rotation into a 4x4 transformation matrix\r\n    (adapted from https://github.com/Wallacoloo/printipi)\r\n    Input 'vec' has to be Bx1x3\r\n    \"\"\"\r\n    angle = tf.norm(vec, 2, 2, keepdims=True)\r\n    axis = vec / (angle + 1e-7)\r\n\r\n    ca = tf.math.cos(angle)\r\n    sa = tf.math.sin(angle)\r\n    C = 1-ca\r\n\r\n    x = tf.expand_dims(axis[..., 0], 1)\r\n    y = tf.expand_dims(axis[..., 1], 1)\r\n    z = tf.expand_dims(axis[..., 2], 1)\r\n\r\n    xs = x * sa\r\n    ys = y * sa\r\n    zs = z * sa\r\n    xC = x * C\r\n    yC = y * C\r\n    zC = z * C\r\n    xyC = x * yC\r\n    yzC = y * zC\r\n    zxC = z * xC\r\n\r\n    one = tf.ones_like(zxC, dtype=tf.float32)\r\n    zero = tf.zeros_like(zxC, dtype=tf.float32)\r\n    rot_matrix = tf.concat([\r\n        x * xC + ca,\r\n        xyC - zs,\r\n        zxC + ys,\r\n        zero,\r\n        xyC + zs,\r\n        y * yC + ca,\r\n        yzC - xs,\r\n        zero,\r\n        zxC - ys,\r\n        yzC + xs,\r\n        z * zC + ca,\r\n        zero, zero, zero, zero, one\r\n    ], axis=2)\r\n\r\n    rot_matrix = tf.reshape(rot_matrix, [-1, 4, 4])\r\n\r\n    return rot_matrix\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n```\r\nD:\\ProgramData\\Anaconda3\\envs\\movis_sort\\python.exe D:/MA/Recources/monodepth2_tf2/new_trainer.py\r\n2021-04-10 17:39:04.209000: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2021-04-10 17:39:07.330472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2021-04-10 17:39:07.363266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 with Max-Q Design computeCapability: 6.1\r\ncoreClock: 1.3415GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2021-04-10 17:39:07.363687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2021-04-10 17:39:07.371125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2021-04-10 17:39:07.376128: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2021-04-10 17:39:07.378017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2021-04-10 17:39:07.383580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2021-04-10 17:39:07.387137: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2021-04-10 17:39:07.402036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2021-04-10 17:39:07.402410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2021-04-10 17:39:07.409179: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-04-10 17:39:07.420304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2161a5093e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-04-10 17:39:07.420676: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2021-04-10 17:39:07.421217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 with Max-Q Design computeCapability: 6.1\r\ncoreClock: 1.3415GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2021-04-10 17:39:07.421735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2021-04-10 17:39:07.421937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2021-04-10 17:39:07.422110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2021-04-10 17:39:07.422283: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2021-04-10 17:39:07.422491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2021-04-10 17:39:07.422869: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2021-04-10 17:39:07.423133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2021-04-10 17:39:07.423431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2021-04-10 17:39:08.101095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-04-10 17:39:08.101318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2021-04-10 17:39:08.101444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2021-04-10 17:39:08.101845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2021-04-10 17:39:08.105369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21640434780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2021-04-10 17:39:08.105633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 with Max-Q Design, Compute Capability 6.1\r\n2021-04-10 17:39:08.847134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2021-04-10 17:39:09.634403: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2021-04-10 17:39:09.767162: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\ndepth_enc\r\ndepth_dec\r\npose_enc\r\npose_dec\r\nEpoch1/2:   0%|          | 0/52 [00:00<?, ?it/s]Start training...\r\nWARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:   2%|\u258f         | 1/52 [00:06<05:31,  6.50s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:   4%|\u258d         | 2/52 [00:07<02:38,  3.16s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:   6%|\u258c         | 3/52 [00:08<01:44,  2.13s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:   8%|\u258a         | 4/52 [00:09<01:18,  1.64s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  10%|\u2589         | 5/52 [00:10<01:04,  1.38s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  12%|\u2588\u258f        | 6/52 [00:10<00:56,  1.23s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  13%|\u2588\u258e        | 7/52 [00:11<00:50,  1.12s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  15%|\u2588\u258c        | 8/52 [00:12<00:46,  1.05s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  17%|\u2588\u258b        | 9/52 [00:13<00:43,  1.01s/it]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  19%|\u2588\u2589        | 10/52 [00:14<00:40,  1.03it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  21%|\u2588\u2588        | 11/52 [00:15<00:38,  1.06it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  23%|\u2588\u2588\u258e       | 12/52 [00:16<00:37,  1.08it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  25%|\u2588\u2588\u258c       | 13/52 [00:17<00:35,  1.11it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  27%|\u2588\u2588\u258b       | 14/52 [00:18<00:34,  1.12it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  29%|\u2588\u2588\u2589       | 15/52 [00:19<00:33,  1.10it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  31%|\u2588\u2588\u2588       | 16/52 [00:19<00:33,  1.09it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  33%|\u2588\u2588\u2588\u258e      | 17/52 [00:20<00:32,  1.09it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  35%|\u2588\u2588\u2588\u258d      | 18/52 [00:21<00:31,  1.07it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  37%|\u2588\u2588\u2588\u258b      | 19/52 [00:22<00:30,  1.07it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  38%|\u2588\u2588\u2588\u258a      | 20/52 [00:23<00:29,  1.10it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  40%|\u2588\u2588\u2588\u2588      | 21/52 [00:24<00:27,  1.11it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  42%|\u2588\u2588\u2588\u2588\u258f     | 22/52 [00:25<00:26,  1.13it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  44%|\u2588\u2588\u2588\u2588\u258d     | 23/52 [00:26<00:25,  1.12it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  46%|\u2588\u2588\u2588\u2588\u258c     | 24/52 [00:27<00:24,  1.13it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  48%|\u2588\u2588\u2588\u2588\u258a     | 25/52 [00:28<00:24,  1.12it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  50%|\u2588\u2588\u2588\u2588\u2588     | 26/52 [00:28<00:23,  1.12it/s]WARNING:tensorflow:Gradients do not exist for variables ['res_net18_new_1/conv0/kernel:0', 'res_net18_new_1/conv0/BatchNorm/gamma:0', 'res_net18_new_1/conv0/BatchNorm/beta:0', 'basic_block_pad_4/conv1_1/conv_1/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_1/beta:0', 'basic_block_pad_4/conv2d_8/kernel:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/gamma:0', 'basic_block_pad_4/conv1_1/BatchNorm_2/beta:0', 'basic_block_nopad_4/conv1_2/conv_1/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_1/beta:0', 'basic_block_nopad_4/conv2d_9/kernel:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/gamma:0', 'basic_block_nopad_4/conv1_2/BatchNorm_2/beta:0', 'basic_block_pad_5/conv2_1/conv_1/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_1/beta:0', 'basic_block_pad_5/conv2d_10/kernel:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/gamma:0', 'basic_block_pad_5/conv2_1/BatchNorm_2/beta:0', 'basic_block_pad_5/sequential_3/conv2_1/downsample/kernel:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_5/sequential_3/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_5/conv2_2/conv_1/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_1/beta:0', 'basic_block_nopad_5/conv2d_11/kernel:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/gamma:0', 'basic_block_nopad_5/conv2_2/BatchNorm_2/beta:0', 'basic_block_pad_6/conv3_1/conv_1/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_1/beta:0', 'basic_block_pad_6/conv2d_12/kernel:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/gamma:0', 'basic_block_pad_6/conv3_1/BatchNorm_2/beta:0', 'basic_block_pad_6/sequential_4/conv3_1/downsample/kernel:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_6/sequential_4/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_6/conv3_2/conv_1/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_1/beta:0', 'basic_block_nopad_6/conv2d_13/kernel:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/gamma:0', 'basic_block_nopad_6/conv3_2/BatchNorm_2/beta:0', 'basic_block_pad_7/conv4_1/conv_1/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_1/beta:0', 'basic_block_pad_7/conv2d_14/kernel:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/gamma:0', 'basic_block_pad_7/conv4_1/BatchNorm_2/beta:0', 'basic_block_pad_7/sequential_5/conv4_1/downsample/kernel:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/gamma:0', 'basic_block_pad_7/sequential_5/downsample/BatchNorm_3/beta:0', 'basic_block_nopad_7/conv4_2/conv_1/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_1/beta:0', 'basic_block_nopad_7/conv2d_15/kernel:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/gamma:0', 'basic_block_nopad_7/conv4_2/BatchNorm_2/beta:0', 'pose_decoder/Conv_squeeze/kernel:0', 'pose_decoder/Conv_squeeze/bias:0', 'pose_decoder/Conv_pose_0/kernel:0', 'pose_decoder/Conv_pose_0/bias:0', 'pose_decoder/Conv_pose_1/kernel:0', 'pose_decoder/Conv_pose_1/bias:0', 'pose_decoder/Conv_pose_2/kernel:0', 'pose_decoder/Conv_pose_2/bias:0'] when minimizing the loss.\r\nEpoch1/2:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 27/52 [00:29<00:22,  1.12it/s]2021-04-10 17:39:53.874112: W tensorflow/core/common_runtime/bfc_allocator.cc:431] Allocator (GPU_0_bfc) ran out of memory trying to allocate 46.22MiB (rounded to 48470016)requested by op Conv2DBackpropInput\r\nCurrent allocation summary follows.\r\n2021-04-10 17:39:53.874460: I tensorflow/core/common_runtime/bfc_allocator.cc:970] BFCAllocator dump for GPU_0_bfc\r\n2021-04-10 17:39:53.874609: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (256): \tTotal Chunks: 207, Chunks in use: 206. 51.8KiB allocated for chunks. 51.5KiB in use in bin. 29.7KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.874893: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (512): \tTotal Chunks: 104, Chunks in use: 104. 55.2KiB allocated for chunks. 55.2KiB in use in bin. 52.3KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.875191: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (1024): \tTotal Chunks: 109, Chunks in use: 108. 120.0KiB allocated for chunks. 118.2KiB in use in bin. 108.6KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.875481: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (2048): \tTotal Chunks: 98, Chunks in use: 96. 212.2KiB allocated for chunks. 207.2KiB in use in bin. 193.2KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.875767: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (4096): \tTotal Chunks: 6, Chunks in use: 5. 28.8KiB allocated for chunks. 24.5KiB in use in bin. 22.5KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.876050: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (8192): \tTotal Chunks: 8, Chunks in use: 6. 83.2KiB allocated for chunks. 60.2KiB in use in bin. 57.0KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.876339: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (16384): \tTotal Chunks: 7, Chunks in use: 5. 160.0KiB allocated for chunks. 116.0KiB in use in bin. 90.0KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.876616: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (32768): \tTotal Chunks: 10, Chunks in use: 10. 365.2KiB allocated for chunks. 365.2KiB in use in bin. 337.0KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.876899: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (65536): \tTotal Chunks: 13, Chunks in use: 10. 1.17MiB allocated for chunks. 930.0KiB in use in bin. 883.5KiB client-requested in use in bin.\r\n2021-04-10 17:39:53.877182: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (131072): \tTotal Chunks: 27, Chunks in use: 27. 3.84MiB allocated for chunks. 3.84MiB in use in bin. 3.66MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.877457: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (262144): \tTotal Chunks: 19, Chunks in use: 17. 6.35MiB allocated for chunks. 5.62MiB in use in bin. 5.18MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.877732: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (524288): \tTotal Chunks: 31, Chunks in use: 30. 22.16MiB allocated for chunks. 21.50MiB in use in bin. 19.78MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.878019: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (1048576): \tTotal Chunks: 46, Chunks in use: 42. 76.93MiB allocated for chunks. 69.32MiB in use in bin. 62.28MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.878298: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (2097152): \tTotal Chunks: 32, Chunks in use: 30. 89.68MiB allocated for chunks. 83.05MiB in use in bin. 72.52MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.878576: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (4194304): \tTotal Chunks: 79, Chunks in use: 71. 445.02MiB allocated for chunks. 401.48MiB in use in bin. 369.44MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.878858: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (8388608): \tTotal Chunks: 239, Chunks in use: 233. 2.66GiB allocated for chunks. 2.59GiB in use in bin. 2.47GiB client-requested in use in bin.\r\n2021-04-10 17:39:53.879149: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (16777216): \tTotal Chunks: 56, Chunks in use: 31. 1.10GiB allocated for chunks. 597.29MiB in use in bin. 394.20MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.891668: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (33554432): \tTotal Chunks: 7, Chunks in use: 1. 254.57MiB allocated for chunks. 46.22MiB in use in bin. 46.22MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.892079: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 74.38MiB allocated for chunks. 74.38MiB in use in bin. 46.22MiB client-requested in use in bin.\r\n2021-04-10 17:39:53.892351: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2021-04-10 17:39:53.892600: I tensorflow/core/common_runtime/bfc_allocator.cc:977] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2021-04-10 17:39:53.892857: I tensorflow/core/common_runtime/bfc_allocator.cc:993] Bin for 46.22MiB was 32.00MiB, Chunk State: \r\n2021-04-10 17:39:53.893015: I tensorflow/core/common_runtime/bfc_allocator.cc:999]   Size: 32.11MiB | Requested Size: 30.41MiB | in_use: 0 | bin_num: 17, prev:   Size: 20.68MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1, next:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1\r\n2021-04-10 17:39:53.893399: I tensorflow/core/common_runtime/bfc_allocator.cc:999]   Size: 33.75MiB | Requested Size: 30.00MiB | in_use: 0 | bin_num: 17, prev:   Size: 5.62MiB | Requested Size: 5.62MiB | in_use: 1 | bin_num: -1, next:   Size: 5.62MiB | Requested Size: 5.62MiB | in_use: 1 | bin_num: -1\r\n2021-04-10 17:39:53.893755: I tensorflow/core/common_runtime/bfc_allocator.cc:999]   Size: 33.75MiB | Requested Size: 30.00MiB | in_use: 0 | bin_num: 17, prev:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1, next:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1\r\n2021-04-10 17:39:53.894112: I tensorflow/core/common_runtime/bfc_allocator.cc:999]   Size: 33.75MiB | Requested Size: 30.41MiB | in_use: 0 | bin_num: 17, prev:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1, next:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1\r\n2021-04-10 17:39:53.894470: I tensorflow/core/common_runtime/bfc_allocator.cc:999]   Size: 33.75MiB | Requested Size: 30.00MiB | in_use: 0 | bin_num: 17, prev:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1, next:   Size: 11.25MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1\r\n2021-04-10 17:39:53.894830: I tensorflow/core/common_runtime/bfc_allocator.cc:999]   Size: 41.23MiB | Requested Size: 34.81MiB | in_use: 0 | bin_num: 17, prev:   Size: 16.94MiB | Requested Size: 11.25MiB | in_use: 1 | bin_num: -1, next:   Size: 512.0KiB | Requested Size: 512.0KiB | in_use: 1 | bin_num: -1\r\n2021-04-10 17:39:53.895189: I tensorflow/core/common_runtime/bfc_allocator.cc:1006] Next region of size 33554432\r\n2021-04-10 17:39:53.895369: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701400000 of size 147456 next 52\r\n2021-04-10 17:39:53.895559: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701424000 of size 294912 next 59\r\n2021-04-10 17:39:53.895749: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70146c000 of size 589824 next 63\r\n2021-04-10 17:39:53.895941: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7014fc000 of size 32768 next 70\r\n2021-04-10 17:39:53.896130: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701504000 of size 256 next 265\r\n2021-04-10 17:39:53.896318: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701504100 of size 256 next 73\r\n2021-04-10 17:39:53.896504: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701504200 of size 1155584 next 57\r\n2021-04-10 17:39:53.896654: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70161e400 of size 983040 next 217\r\n2021-04-10 17:39:53.896803: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170e400 of size 1024 next 226\r\n2021-04-10 17:39:53.896947: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170e800 of size 1024 next 227\r\n2021-04-10 17:39:53.906290: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170ec00 of size 1024 next 228\r\n2021-04-10 17:39:53.906451: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170f000 of size 1024 next 229\r\n2021-04-10 17:39:53.906601: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170f400 of size 1024 next 231\r\n2021-04-10 17:39:53.906755: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170f800 of size 1024 next 232\r\n2021-04-10 17:39:53.906903: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70170fc00 of size 1024 next 233\r\n2021-04-10 17:39:53.907051: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701710000 of size 1024 next 234\r\n2021-04-10 17:39:53.907210: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701710400 of size 1024 next 236\r\n2021-04-10 17:39:53.907353: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701710800 of size 1024 next 237\r\n2021-04-10 17:39:53.907497: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701710c00 of size 1024 next 238\r\n2021-04-10 17:39:53.907642: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701711000 of size 1024 next 239\r\n2021-04-10 17:39:53.907789: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701711400 of size 368640 next 832\r\n2021-04-10 17:39:53.907937: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70176b400 of size 602112 next 58\r\n2021-04-10 17:39:53.908081: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017fe400 of size 1024 next 83\r\n2021-04-10 17:39:53.908223: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017fe800 of size 1024 next 85\r\n2021-04-10 17:39:53.908366: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017fec00 of size 512 next 350\r\n2021-04-10 17:39:53.908508: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017fee00 of size 256 next 581\r\n2021-04-10 17:39:53.908651: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017fef00 of size 256 next 568\r\n2021-04-10 17:39:53.908794: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017ff000 of size 256 next 1169\r\n2021-04-10 17:39:53.908937: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017ff100 of size 512 next 1370\r\n2021-04-10 17:39:53.909079: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017ff300 of size 256 next 89\r\n2021-04-10 17:39:53.909221: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7017ff400 of size 2359296 next 86\r\n2021-04-10 17:39:53.909369: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a3f400 of size 1024 next 87\r\n2021-04-10 17:39:53.909513: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a3f800 of size 1024 next 90\r\n2021-04-10 17:39:53.909661: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a3fc00 of size 1536 next 728\r\n2021-04-10 17:39:53.909806: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a40200 of size 256 next 1162\r\n2021-04-10 17:39:53.909951: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a40300 of size 256 next 92\r\n2021-04-10 17:39:53.910092: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a40400 of size 131072 next 93\r\n2021-04-10 17:39:53.910238: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a60400 of size 1024 next 94\r\n2021-04-10 17:39:53.910381: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a60800 of size 1024 next 95\r\n2021-04-10 17:39:53.910526: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a60c00 of size 768 next 739\r\n2021-04-10 17:39:53.910682: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a60f00 of size 256 next 989\r\n2021-04-10 17:39:53.910822: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a61000 of size 256 next 325\r\n2021-04-10 17:39:53.910967: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a61100 of size 768 next 97\r\n2021-04-10 17:39:53.911105: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701a61400 of size 2359296 next 98\r\n2021-04-10 17:39:53.922315: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca1400 of size 1024 next 99\r\n2021-04-10 17:39:53.922478: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca1800 of size 1024 next 100\r\n2021-04-10 17:39:53.922623: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca1c00 of size 512 next 1413\r\n2021-04-10 17:39:53.922770: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca1e00 of size 512 next 1234\r\n2021-04-10 17:39:53.922915: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca2000 of size 512 next 1164\r\n2021-04-10 17:39:53.923059: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca2200 of size 256 next 1145\r\n2021-04-10 17:39:53.923202: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca2300 of size 256 next 102\r\n2021-04-10 17:39:53.923345: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ca2400 of size 2359296 next 103\r\n2021-04-10 17:39:53.923492: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee2400 of size 1024 next 104\r\n2021-04-10 17:39:53.923638: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee2800 of size 1024 next 105\r\n2021-04-10 17:39:53.923784: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee2c00 of size 1024 next 132\r\n2021-04-10 17:39:53.923930: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee3000 of size 1024 next 107\r\n2021-04-10 17:39:53.924073: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee3400 of size 256 next 176\r\n2021-04-10 17:39:53.924217: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee3500 of size 256 next 179\r\n2021-04-10 17:39:53.924360: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee3600 of size 256 next 180\r\n2021-04-10 17:39:53.924507: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee3700 of size 256 next 181\r\n2021-04-10 17:39:53.924651: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701ee3800 of size 147456 next 182\r\n2021-04-10 17:39:53.924798: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f07800 of size 256 next 183\r\n2021-04-10 17:39:53.924942: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f07900 of size 256 next 184\r\n2021-04-10 17:39:53.925085: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f07a00 of size 256 next 185\r\n2021-04-10 17:39:53.925228: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f07b00 of size 256 next 186\r\n2021-04-10 17:39:53.925371: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f07c00 of size 147456 next 187\r\n2021-04-10 17:39:53.925518: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2bc00 of size 256 next 188\r\n2021-04-10 17:39:53.925661: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2bd00 of size 256 next 189\r\n2021-04-10 17:39:53.925805: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2be00 of size 256 next 190\r\n2021-04-10 17:39:53.925951: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2bf00 of size 256 next 191\r\n2021-04-10 17:39:53.926097: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2c000 of size 512 next 195\r\n2021-04-10 17:39:53.926240: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2c200 of size 512 next 197\r\n2021-04-10 17:39:53.926384: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2c400 of size 512 next 198\r\n2021-04-10 17:39:53.926526: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2c600 of size 512 next 196\r\n2021-04-10 17:39:53.926670: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2c800 of size 512 next 199\r\n2021-04-10 17:39:53.926815: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2ca00 of size 512 next 200\r\n2021-04-10 17:39:53.926958: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2cc00 of size 512 next 201\r\n2021-04-10 17:39:53.927103: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2ce00 of size 512 next 202\r\n2021-04-10 17:39:53.937629: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 701f2d000 of size 32768 next 203\r\n...\r\n\r\n2021-04-10 17:39:54.017930: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70b7be800 of size 2048 next 242\r\n2021-04-10 17:39:54.018076: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70b7bf000 of size 2048 next 245\r\n2021-04-10 17:39:54.018222: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70b7bf800 of size 2048 next 243\r\n2021-04-10 17:39:54.018368: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70b7c0000 of size 12845056 next 18446744073709551615\r\n2021-04-10 17:39:54.018542: I tensorflow/core/common_runtime/bfc_allocator.cc:1006] Next region of size 2147483648\r\n2021-04-10 17:39:54.018679: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 70c400000 of size 90624 next 1208\r\n2021-04-10 17:39:54.018828: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c416200 of size 256 next 1440\r\n2021-04-10 17:39:54.018974: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c416300 of size 1792 next 1090\r\n2021-04-10 17:39:54.019120: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c416a00 of size 256 next 413\r\n2021-04-10 17:39:54.019263: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c416b00 of size 1024 next 1093\r\n2021-04-10 17:39:54.019424: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c416f00 of size 1280 next 1402\r\n2021-04-10 17:39:54.019570: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c417400 of size 256 next 1353\r\n2021-04-10 17:39:54.019716: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c417500 of size 256 next 658\r\n2021-04-10 17:39:54.019859: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c417600 of size 256 next 850\r\n2021-04-10 17:39:54.020005: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c417700 of size 256 next 1230\r\n2021-04-10 17:39:54.020151: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 70c417800 of size 88832 next 1179\r\n2021-04-10 17:39:54.020298: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c42d300 of size 110592 next 1037\r\n2021-04-10 17:39:54.020447: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c448300 of size 73728 next 1468\r\n2021-04-10 17:39:54.020595: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c45a300 of size 32768 next 982\r\n2021-04-10 17:39:54.020743: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c462300 of size 37632 next 1070\r\n2021-04-10 17:39:54.020889: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c46b600 of size 51712 next 173\r\n2021-04-10 17:39:54.021034: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c478000 of size 2048 next 244\r\n2021-04-10 17:39:54.021178: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c478800 of size 2048 next 246\r\n2021-04-10 17:39:54.021342: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c479000 of size 2048 next 247\r\n2021-04-10 17:39:54.021491: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c479800 of size 2048 next 248\r\n2021-04-10 17:39:54.021636: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c47a000 of size 524288 next 249\r\n2021-04-10 17:39:54.021861: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c4fa000 of size 2048 next 250\r\n2021-04-10 17:39:54.022007: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c4fa800 of size 2048 next 251\r\n2021-04-10 17:39:54.022159: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c4fb000 of size 2048 next 252\r\n2021-04-10 17:39:54.032860: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c4fb800 of size 2048 next 253\r\n2021-04-10 17:39:54.033218: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70c4fc000 of size 9437184 next 254\r\n2021-04-10 17:39:54.033515: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70cdfc000 of size 2048 next 255\r\n2021-04-10 17:39:54.033825: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70cdfc800 of size 2048 next 256\r\n2021-04-10 17:39:54.034058: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70cdfd000 of size 2048 next 257\r\n2021-04-10 17:39:54.034325: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70cdfd800 of size 2048 next 258\r\n2021-04-10 17:39:54.034524: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70cdfe000 of size 9437184 next 259\r\n2021-04-10 17:39:54.034725: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70d6fe000 of size 2048 next 260\r\n2021-04-10 17:39:54.034923: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70d6fe800 of size 2048 next 261\r\n2021-04-10 17:39:54.035156: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70d6ff000 of size 2048 next 262\r\n2021-04-10 17:39:54.035305: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70d6ff800 of size 2048 next 263\r\n2021-04-10 17:39:54.035454: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 70d700000 of size 25952256 next 1332\r\n2021-04-10 17:39:54.035606: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70efc0000 of size 3538944 next 274\r\n2021-04-10 17:39:54.035757: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 70f320000 of size 5898240 next 285\r\n2021-04-10 17:39:54.035904: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 70f8c0000 of size 35389440 next 926\r\n2021-04-10 17:39:54.036054: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 711a80000 of size 5898240 next 958\r\n2021-04-10 17:39:54.036202: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 712020000 of size 11796480 next 813\r\n2021-04-10 17:39:54.036353: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 712b60000 of size 11796480 next 1110\r\n2021-04-10 17:39:54.036506: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7136a0000 of size 13762560 next 267\r\n2021-04-10 17:39:54.036655: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7143c0000 of size 17694720 next 999\r\n2021-04-10 17:39:54.036806: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 7154a0000 of size 13238272 next 537\r\n2021-04-10 17:39:54.036958: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 716140000 of size 14379008 next 1214\r\n2021-04-10 17:39:54.037109: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 716ef6800 of size 18394112 next 326\r\n2021-04-10 17:39:54.037259: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 718081400 of size 11799552 next 717\r\n2021-04-10 17:39:54.037410: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 718bc2000 of size 31457280 next 445\r\n2021-04-10 17:39:54.037561: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 71a9c2000 of size 11796480 next 533\r\n2021-04-10 17:39:54.037714: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 71b502000 of size 19660800 next 561\r\n2021-04-10 17:39:54.037902: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 71c7c2000 of size 15728640 next 1348\r\n2021-04-10 17:39:54.038055: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 71d6c2000 of size 5898240 next 516\r\n... <repeated similar messages> ...\r\n\r\n2021-04-10 17:39:54.269981: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 825046000 of size 5898240 next 1227\r\n2021-04-10 17:39:54.270126: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 8255e6000 of size 11796480 next 1042\r\n2021-04-10 17:39:54.270273: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 826126000 of size 11796480 next 768\r\n2021-04-10 17:39:54.270418: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 826c66000 of size 48470016 next 784\r\n2021-04-10 17:39:54.270564: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 829a9f800 of size 5898240 next 582\r\n2021-04-10 17:39:54.270743: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 82a03f800 of size 11796480 next 1150\r\n2021-04-10 17:39:54.270889: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 82ab7f800 of size 11796480 next 5\r\n2021-04-10 17:39:54.271031: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] Free  at 82b6bf800 of size 5898240 next 1473\r\n2021-04-10 17:39:54.271175: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 82bc5f800 of size 11796480 next 1006\r\n2021-04-10 17:39:54.271320: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 82c79f800 of size 11796480 next 695\r\n2021-04-10 17:39:54.271465: I tensorflow/core/common_runtime/bfc_allocator.cc:1026] InUse at 82d2df800 of size 77993728 next 18446744073709551615\r\n2021-04-10 17:39:54.271628: I tensorflow/core/common_runtime/bfc_allocator.cc:1031]      Summary of in-use Chunks by size: \r\n2021-04-10 17:39:54.271811: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 206 Chunks of size 256 totalling 51.5KiB\r\n2021-04-10 17:39:54.271954: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 91 Chunks of size 512 totalling 45.5KiB\r\n2021-04-10 17:39:54.272096: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 13 Chunks of size 768 totalling 9.8KiB\r\n2021-04-10 17:39:54.272237: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 85 Chunks of size 1024 totalling 85.0KiB\r\n2021-04-10 17:39:54.272380: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 12 Chunks of size 1280 totalling 15.0KiB\r\n2021-04-10 17:39:54.272522: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 4 Chunks of size 1536 totalling 6.0KiB\r\n2021-04-10 17:39:54.272711: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 7 Chunks of size 1792 totalling 12.2KiB\r\n2021-04-10 17:39:54.272866: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 79 Chunks of size 2048 totalling 158.0KiB\r\n2021-04-10 17:39:54.273008: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 7 Chunks of size 2304 totalling 15.8KiB\r\n2021-04-10 17:39:54.273148: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 2816 totalling 2.8KiB\r\n2021-04-10 17:39:54.273289: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 3072 totalling 6.0KiB\r\n2021-04-10 17:39:54.273445: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 3328 totalling 6.5KiB\r\n2021-04-10 17:39:54.273596: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 3584 totalling 7.0KiB\r\n2021-04-10 17:39:54.273743: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 3840 totalling 11.2KiB\r\n2021-04-10 17:39:54.273940: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 4 Chunks of size 4608 totalling 18.0KiB\r\n2021-04-10 17:39:54.284435: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 6656 totalling 6.5KiB\r\n2021-04-10 17:39:54.284660: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 9216 totalling 27.0KiB\r\n2021-04-10 17:39:54.284855: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 2 Chunks of size 10752 totalling 21.0KiB\r\n2021-04-10 17:39:54.285052: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 12544 totalling 12.2KiB\r\n2021-04-10 17:39:54.285249: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 18432 totalling 18.0KiB\r\n2021-04-10 17:39:54.285449: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 19712 totalling 19.2KiB\r\n2021-04-10 17:39:54.285648: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 21248 totalling 20.8KiB\r\n2021-04-10 17:39:54.285847: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 28672 totalling 28.0KiB\r\n2021-04-10 17:39:54.286046: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 30720 totalling 30.0KiB\r\n2021-04-10 17:39:54.286241: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 5 Chunks of size 32768 totalling 160.0KiB\r\n2021-04-10 17:39:54.286461: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 37632 totalling 110.2KiB\r\n2021-04-10 17:39:54.286680: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 45568 totalling 44.5KiB\r\n2021-04-10 17:39:54.286883: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 51712 totalling 50.5KiB\r\n2021-04-10 17:39:54.287089: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 4 Chunks of size 73728 totalling 288.0KiB\r\n2021-04-10 17:39:54.287294: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 92160 totalling 90.0KiB\r\n2021-04-10 17:39:54.287501: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 4 Chunks of size 110592 totalling 432.0KiB\r\n2021-04-10 17:39:54.287708: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 122880 totalling 120.0KiB\r\n2021-04-10 17:39:54.287918: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 4 Chunks of size 131072 totalling 512.0KiB\r\n2021-04-10 17:39:54.288126: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 132608 totalling 129.5KiB\r\n2021-04-10 17:39:54.288329: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 142336 totalling 139.0KiB\r\n2021-04-10 17:39:54.288534: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 16 Chunks of size 147456 totalling 2.25MiB\r\n2021-04-10 17:39:54.288737: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 162304 totalling 158.5KiB\r\n2021-04-10 17:39:54.288945: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 162560 totalling 158.8KiB\r\n2021-04-10 17:39:54.289151: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 168960 totalling 165.0KiB\r\n2021-04-10 17:39:54.289388: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 175616 totalling 171.5KiB\r\n2021-04-10 17:39:54.289689: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 196608 totalling 192.0KiB\r\n2021-04-10 17:39:54.289999: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 9 Chunks of size 294912 totalling 2.53MiB\r\n2021-04-10 17:39:54.290229: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 338176 totalling 330.2KiB\r\n2021-04-10 17:39:54.290430: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 368640 totalling 1.05MiB\r\n2021-04-10 17:39:54.290626: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 406272 totalling \r\n\r\n... <repeated for many times>...\r\n\r\n2021-04-10 17:39:54.320661: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 21073920 totalling 20.10MiB\r\n2021-04-10 17:39:54.320857: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 6 Chunks of size 21626880 totalling 123.75MiB\r\n2021-04-10 17:39:54.321054: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 21680128 totalling 20.68MiB\r\n2021-04-10 17:39:54.321248: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 3 Chunks of size 21683200 totalling 62.04MiB\r\n2021-04-10 17:39:54.321503: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 31457280 totalling 30.00MiB\r\n2021-04-10 17:39:54.321696: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 33423360 totalling 31.88MiB\r\n2021-04-10 17:39:54.321888: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 48470016 totalling 46.22MiB\r\n2021-04-10 17:39:54.322079: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] 1 Chunks of size 77993728 totalling 74.38MiB\r\n2021-04-10 17:39:54.322271: I tensorflow/core/common_runtime/bfc_allocator.cc:1038] Sum Total of in-use chunks: 3.87GiB\r\n2021-04-10 17:39:54.322455: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] total_region_allocated_bytes_: 5060693760 memory_limit_: 5060693856 available bytes: 96 curr_region_allocation_bytes_: 4294967296\r\n2021-04-10 17:39:54.322766: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Stats: \r\nLimit:                      5060693856\r\nInUse:                      4152633344\r\nMaxInUse:                   5019460608\r\nNumAllocs:                       91245\r\nMaxAllocSize:               2325741568\r\nReserved:                            0\r\nPeakReserved:                        0\r\nLargestFreeBlock:                    0\r\n\r\n2021-04-10 17:39:54.323282: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ****************************************************************************************************\r\n2021-04-10 17:39:54.323508: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_input_ops.cc:1103 : Resource exhausted: OOM when allocating tensor with shape[4,96,98,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nEpoch1/2:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 27/52 [00:41<00:38,  1.53s/it]\r\nTraceback (most recent call last):\r\n  File \"D:/MA/Recources/monodepth2_tf2/new_trainer.py\", line 549, in <module>\r\n  File \"D:/MA/Recources/monodepth2_tf2/new_trainer.py\", line 481, in train\r\n    \r\n  File \"D:/MA/Recources/monodepth2_tf2/new_trainer.py\", line 438, in run_epoch\r\n    self.optimizer.apply_gradients(zip(grads, trainable_weights_all))\r\n  File \"D:/MA/Recources/monodepth2_tf2/new_trainer.py\", line 458, in grad\r\n    \r\n  File \"C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 1073, in gradient\r\n    unconnected_gradients=unconnected_gradients)\r\n  File \"C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 77, in imperative_grad\r\n    compat.as_str(unconnected_gradients.value))\r\n  File \"C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 162, in _gradient_function\r\n    return grad_fn(mock_op, *out_grads)\r\n  File \"C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 596, in _Conv2DGrad\r\n    data_format=data_format),\r\n  File \"C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1255, in conv2d_backprop_input\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4,96,98,322] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput]\r\n\r\nProcess finished with exit code 1\r\n\r\n```", "comments": ["@dexter2406 ,\r\n\r\nIn the given code snippet, you have defined the functions but are not calling them anywhere. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/e40fad081c1289f224392a6fe73f03f6/48456.ipynb).\r\n\r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset you are using. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48456\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48456\">No</a>\n"]}, {"number": 48455, "title": "Failed to compile on Linux x86_64", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 20.10\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:master\r\n- Python version:3.8.5\r\n- Bazel version (if compiling from source):3.7.2\r\n- GCC/Compiler version (if compiling from source):10.2.0\r\n- CUDA/cuDNN version:CUDA 11.2.2.1 cuDNN 8.1.1.33\r\n- GPU model and memory:Nvidia RTX2060M 6G\r\n\r\n\r\n\r\n**Describe the problem**\r\nFailed to compile on Linux x86_64 .\r\nConfigure :\r\n```\r\n\u276f ./configure\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.8/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: y\r\nTensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 11.2 in:\r\n    /usr/local/cuda-11.2/targets/x86_64-linux/lib\r\n    /usr/local/cuda-11.2/targets/x86_64-linux/include\r\nFound cuDNN 8 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\nFound TensorRT 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include/x86_64-linux-gnu\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 7.5]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n```\r\nBuild command : `bazel build //tensorflow/tools/pip_package:build_pip_package --config=opt --config=cuda --config=mkl -j 6 --config=noaws`\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nError logs :\r\n[error.txt](https://github.com/tensorflow/tensorflow/files/6289961/error.txt)\r\n\r\n\r\n\r\n\r\n", "comments": ["@ymodak @mihaimaruseac So will this problem be fixed ? Thanks .", "@StarOnTheSky,\r\n\r\nWe are checking to see if this is still an issue, Can you try builiding the latest stable version of TF i.e `2.6.0` using this [guide](https://www.tensorflow.org/install/source) and let us know if the issue still persists? You can also refer to the tested build configurations [here](https://www.tensorflow.org/install/source#tested_build_configurations).Thanks!", "> @StarOnTheSky,\r\n> \r\n> We are checking to see if this is still an issue, Can you try builiding the latest stable version of TF i.e `2.6.0` using this [guide](https://www.tensorflow.org/install/source) and let us know if the issue still persists? You can also refer to the tested build configurations [here](https://www.tensorflow.org/install/source#tested_build_configurations).Thanks!\r\n\r\nOK, I'll try building later.", "@StarOnTheSky,\r\n\r\nThanks for the confirmation and keep us posted if your issue is fixed. ", "> @StarOnTheSky,\r\n> \r\n> Thanks for the confirmation and keep us posted if your issue is fixed.\r\n\r\nDo you know how to fix this problem?\r\nUbuntu clang version 13.0.0-2:\r\n```\r\n\u276f ./configure\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.9/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 11.0 in:\r\n    /usr/local/cuda-11.0/targets/x86_64-linux/lib\r\n    /usr/local/cuda-11.0/targets/x86_64-linux/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 7.5]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: y\r\nClang will be used as CUDA compiler.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: \r\nClang will not be downloaded.\r\n\r\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v1             # Build with TensorFlow 1 API instead of TF 2 API.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\u276f bazel build //tensorflow/tools/pip_package:build_pip_package --config=opt --config=cuda --config=mkl\r\nWARNING: The following configs were expanded more than once: [cuda_clang, cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=86\r\nINFO: Reading rc options for 'build' from /home/zwq/workspace/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/zwq/workspace/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from /home/zwq/workspace/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.0 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/bin/clang --config=cuda_clang\r\nINFO: Found applicable config definition build:short_logs in file /home/zwq/workspace/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/zwq/workspace/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:cuda_clang in file /home/zwq/workspace/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang\r\nINFO: Found applicable config definition build:cuda in file /home/zwq/workspace/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:cuda_clang in file /home/zwq/workspace/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang\r\nINFO: Found applicable config definition build:cuda in file /home/zwq/workspace/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:opt in file /home/zwq/workspace/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare\r\nINFO: Found applicable config definition build:cuda in file /home/zwq/workspace/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:mkl in file /home/zwq/workspace/tensorflow/.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_openmp=true -c opt\r\nINFO: Found applicable config definition build:linux in file /home/zwq/workspace/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/zwq/workspace/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: /home/zwq/.cache/bazel/_bazel_zwq/004cf1a57827e926c0c6bde2a3de4f2d/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /home/zwq/workspace/tensorflow/WORKSPACE:23:14: in <toplevel>\r\n  /home/zwq/workspace/tensorflow/tensorflow/workspace0.bzl:108:34: in workspace\r\n  /home/zwq/.cache/bazel/_bazel_zwq/004cf1a57827e926c0c6bde2a3de4f2d/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /home/zwq/.cache/bazel/_bazel_zwq/004cf1a57827e926c0c6bde2a3de4f2d/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/zwq/.cache/bazel/_bazel_zwq/004cf1a57827e926c0c6bde2a3de4f2d/external/com_google_absl/absl/base/BUILD.bazel:201:11: undeclared inclusion(s) in rule '@com_google_absl//absl/base:base':\r\nthis rule is missing dependency declarations for the following files included by 'com_google_absl/absl/base/internal/cycleclock.cc':\r\n  '/usr/lib/clang/13.0.0/include/stdint.h'\r\n  '/usr/lib/clang/13.0.0/include/limits.h'\r\n  '/usr/lib/clang/13.0.0/include/stddef.h'\r\n  '/usr/lib/clang/13.0.0/include/__stddef_max_align_t.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/zwq/workspace/tensorflow/tensorflow/core/framework/BUILD:1279:31 undeclared inclusion(s) in rule '@com_google_absl//absl/base:base':\r\nthis rule is missing dependency declarations for the following files included by 'com_google_absl/absl/base/internal/cycleclock.cc':\r\n  '/usr/lib/clang/13.0.0/include/stdint.h'\r\n  '/usr/lib/clang/13.0.0/include/limits.h'\r\n  '/usr/lib/clang/13.0.0/include/stddef.h'\r\n  '/usr/lib/clang/13.0.0/include/__stddef_max_align_t.h'\r\nINFO: Elapsed time: 0.641s, Critical Path: 0.35s\r\nINFO: 16 processes: 13 internal, 3 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\nGCC: CUDA reports that it does not support GCC version > 9 (my system GCC version is 11)", "@StarOnTheSky,\r\n\r\nCan you take a look at this [SO thread](https://stackoverflow.com/questions/43921911/how-to-resolve-bazel-undeclared-inclusions-error) and try out if either [suggestion1](https://stackoverflow.com/a/48513577) or [suggestion2](https://stackoverflow.com/a/43923985) works for you? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "I'll try these suggestions later. Now I'm using GCC9 to compile tensorflow and it works.", "@StarOnTheSky,\r\n\r\nIn that case, Can you close this issue now and open a new issue in future if you have any questions. Thanks!", "> @StarOnTheSky,\n> \n> In that case, Can you close this issue now and open a new issue in future if you have any questions. Thanks!\n\nOkay.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48455\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48455\">No</a>\n"]}, {"number": 48453, "title": "Fail to build on Linux aarch64", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu devel 21.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:master \r\n- Python version:3.9.4\r\n- Installed using virtualenv? pip? conda?:N/A\r\n- Bazel version (if compiling from source):3.7.2\r\n- GCC/Compiler version (if compiling from source):GCC 10.2.1\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI want to build tensorflow on Linux aarch64 platform , and it fails .\r\nCommands : \r\n`./configure `\r\n`bazel build //tensorflow/tools/pip_package:build_pip_package`\r\nOutput : \r\n[![asciicast](https://asciinema.org/a/KsEIoMqtDsDvInf0fbPTxBCBs.svg)](https://asciinema.org/a/KsEIoMqtDsDvInf0fbPTxBCBs)\r\nError message : \r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_cc/BUILD:47:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'aarch64'\r\n\r\nCommand : `bazel build //tensorflow/tools/pip_package:build_pip_package --toolchain_resolution_debug`\r\nOutput : [![asciicast](https://asciinema.org/a/hok5YFKqreDYj7X5pLFDIsbVQ.svg)](https://asciinema.org/a/hok5YFKqreDYj7X5pLFDIsbVQ)\r\n\r\nLogs : \r\n`INFO: ToolchainResolution: Target platform @local_config_platform//:host: Selected execution platform @local_execution_config_platform//:platform,                    INFO: ToolchainResolution: Target platform @local_config_platform//:host: Selected execution platform @local_execution_config_platform//:platform,                    INFO: ToolchainResolution:     Type @bazel_tools//tools/cpp:toolchain_type: target @local_config_platform//:host: Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a; mismatching values: arm, android                                        INFO: ToolchainResolution:   Type @bazel_tools//tools/cpp:toolchain_type: target platform @local_config_platform//:host: execution @local_execution_config_platform//:platform: Selected toolchain @local_config_cc//:cc-compiler-piii                   INFO: ToolchainResolution:   Type @bazel_tools//tools/cpp:toolchain_type: target platform @local_config_platform//:host: execution @local_config_platform//:host: Selected toolchain @local_config_cc//:cc-compiler-piii                                 INFO: ToolchainResolution:     Type @bazel_tools//tools/cpp:toolchain_type: target @local_config_platform//:host: Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a; mismatching values: arm, android                                        INFO: ToolchainResolution: Target platform @local_config_platform//:host: Selected execution platform @local_execution_config_platform//:platform, type @bazel_tools//tools/cpp:toolchain_type -> toolchain @local_config_cc//:cc-compiler-piii          INFO: ToolchainResolution:     Type @bazel_tools//tools/python:toolchain_type: target @local_config_platform//:host: Rejected toolchain @local_execution_config_python//:py_runtime_pair; mismatching values: platform_constraint                        INFO: ToolchainResolution:   Type @bazel_tools//tools/python:toolchain_type: target platform @local_config_platform//:host: execution @local_execution_config_platform//:platform: Selected toolchain @local_config_python//:py_runtime_pair             INFO: ToolchainResolution:   Type @bazel_tools//tools/python:toolchain_type: target platform @local_config_platform//:host: execution @local_config_platform//:host: Selected toolchain @local_config_python//:py_runtime_pair                           INFO: ToolchainResolution:     Type @bazel_tools//tools/cpp:toolchain_type: target @local_config_platform//:host: Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a; mismatching values: arm, android                                        INFO: ToolchainResolution:   Type @bazel_tools//tools/cpp:toolchain_type: target platform @local_config_platform//:host: execution @local_execution_config_platform//:platform: Selected toolchain @local_config_cc//:cc-compiler-piii                   INFO: ToolchainResolution:   Type @bazel_tools//tools/cpp:toolchain_type: target platform @local_config_platform//:host: execution @local_config_platform//:host: Selected toolchain @local_config_cc//:cc-compiler-piii                                 INFO: ToolchainResolution:     Type @bazel_tools//tools/cpp:toolchain_type: target @local_config_platform//:host: Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a; mismatching values: arm, android                                        INFO: ToolchainResolution: Target platform @local_config_platform//:host: Selected execution platform @local_execution_config_platform//:platform, type @bazel_tools//tools/cpp:toolchain_type -> toolchain @local_config_cc//:cc-compiler-piii, type @bazel_tools//tools/python:toolchain_type -> toolchain @local_config_python//:py_runtime_pair                                                                            INFO: ToolchainResolution: Removed execution platform @local_config_platform//:host from available execution platforms, it is missing constraint @local_execution_config_platform//:platform_constraint                                                  INFO: ToolchainResolution: Target platform @local_config_platform//:host: Selected execution platform @local_execution_config_platform//:platform,                    INFO: ToolchainResolution: Removed execution platform @local_config_platform//:host from available execution platforms, it is missing constraint @local_execution_config_platform//:platform_constraint`\r\n\r\nP.S. Python 3.9.4 is the default and minimal version available in current Ubuntu repo , and I can't add the older repos or the system will be corrupted . ", "comments": ["I remembered that I had successfully compiled tensorflow on Linux aarch64 several months ago with bazel-3.1.0 Python-3.8 . \nAlso , I have tried to build bazel-3.7.2 with bazel-3.1.0 , but it failed with almost the same error message .\n`ERROR: /root/.cache/bazel/_bazel_root/6171aa1425ff53eef39f25e54576898b/external/local_config_cc/BUILD:47:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'aarch64'`\n So , maybe it's an bazel issue instead of tensorflow ?\nThe bazel binary is download from https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-linux-arm64 \n", "Python 3.9 support is still in progress.\r\nSee https://github.com/tensorflow/tensorflow/issues/44485 for updates", "> Python 3.9 support is still in progress.\r\n> See #44485 for updates\r\n\r\nI have confirmed that it's a bug of bazel's `local_config_cc` . It considers my `aarch64` device as `piii` (maybe Intel's Pentium III?) and then `bazel` cannot find the right toolchain . Temporarily fixed by modifying `bazel-tensorflow/external/local_config_cc/BUILD` .\r\nOriginal file :\r\n```\r\n# Copyright 2016 The Bazel Authors. All rights reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\n# This becomes the BUILD file for @local_config_cc// under non-FreeBSD unixes.\r\n\r\npackage(default_visibility = [\"//visibility:public\"])\r\n\r\nload(\":cc_toolchain_config.bzl\", \"cc_toolchain_config\")\r\nload(\":armeabi_cc_toolchain_config.bzl\", \"armeabi_cc_toolchain_config\")\r\nload(\"@rules_cc//cc:defs.bzl\", \"cc_toolchain\", \"cc_toolchain_suite\")\r\n\r\nlicenses([\"notice\"])  # Apache 2.0\r\n\r\ncc_library(\r\n    name = \"malloc\",\r\n)\r\n\r\nfilegroup(\r\n    name = \"empty\",\r\n    srcs = [],\r\n)\r\n\r\nfilegroup(\r\n    name = \"cc_wrapper\",\r\n    srcs = [\"cc_wrapper.sh\"],\r\n)\r\n\r\nfilegroup(\r\n    name = \"compiler_deps\",\r\n    srcs = glob([\"extra_tools/**\"], allow_empty = True) + [\":builtin_include_directory_paths\"],\r\n)\r\n\r\n# This is the entry point for --crosstool_top.  Toolchains are found\r\n# by lopping off the name of --crosstool_top and searching for\r\n# the \"${CPU}\" entry in the toolchains attribute.\r\ncc_toolchain_suite(\r\n    name = \"toolchain\",\r\n    toolchains = {\r\n        \"piii|compiler\": \":cc-compiler-piii\",\r\n        \"piii\": \":cc-compiler-piii\",\r\n        \"armeabi-v7a|compiler\": \":cc-compiler-armeabi-v7a\",\r\n        \"armeabi-v7a\": \":cc-compiler-armeabi-v7a\",\r\n    },\r\n)\r\n\r\ncc_toolchain(\r\n    name = \"cc-compiler-piii\",\r\n    toolchain_identifier = \"local\",\r\n    toolchain_config = \":local\",\r\n    all_files = \":compiler_deps\",\r\n    ar_files = \":compiler_deps\",\r\n    as_files = \":compiler_deps\",\r\n    compiler_files = \":compiler_deps\",\r\n    dwp_files = \":empty\",\r\n    linker_files = \":compiler_deps\",\r\n    objcopy_files = \":empty\",\r\n    strip_files = \":empty\",\r\n    supports_param_files = 1,\r\n)\r\n\r\ncc_toolchain_config(\r\n    name = \"local\",\r\n    cpu = \"piii\",\r\n    compiler = \"compiler\",\r\n    toolchain_identifier = \"local\",\r\n    host_system_name = \"local\",\r\n    target_system_name = \"local\",\r\n    target_libc = \"local\",\r\n    abi_version = \"local\",\r\n    abi_libc_version = \"local\",\r\n    cxx_builtin_include_directories = [\"/usr/lib/gcc/aarch64-linux-gnu/10/include\",\r\n    \"/usr/local/include\",\r\n    \"/usr/include/aarch64-linux-gnu\",\r\n    \"/usr/include\",\r\n    \"/usr/include/c++/10\",\r\n    \"/usr/include/aarch64-linux-gnu/c++/10\",\r\n    \"/usr/include/c++/10/backward\"],\r\n    tool_paths = {\"ar\": \"/usr/bin/ar\",\r\n        \"ld\": \"/usr/bin/ld\",\r\n        \"cpp\": \"/usr/bin/cpp\",\r\n        \"gcc\": \"/usr/bin/gcc\",\r\n        \"dwp\": \"/usr/bin/dwp\",\r\n        \"gcov\": \"/usr/bin/gcov\",\r\n        \"nm\": \"/usr/bin/nm\",\r\n        \"objcopy\": \"/usr/bin/objcopy\",\r\n        \"objdump\": \"/usr/bin/objdump\",\r\n        \"strip\": \"/usr/bin/strip\"},\r\n    compile_flags = [\"-U_FORTIFY_SOURCE\",\r\n    \"-fstack-protector\",\r\n    \"-Wall\",\r\n    \"-Wunused-but-set-parameter\",\r\n    \"-Wno-free-nonheap-object\",\r\n    \"-fno-omit-frame-pointer\"],\r\n    opt_compile_flags = [\"-g0\",\r\n    \"-O2\",\r\n    \"-D_FORTIFY_SOURCE=1\",\r\n    \"-DNDEBUG\",\r\n    \"-ffunction-sections\",\r\n    \"-fdata-sections\"],\r\n    dbg_compile_flags = [\"-g\"],\r\n    cxx_flags = [\"-std=c++11\"],\r\n    link_flags = [\"-fuse-ld=gold\",\r\n    \"-Wl,-no-as-needed\",\r\n    \"-Wl,-z,relro,-z,now\",\r\n    \"-B/usr/bin\",\r\n    \"-pass-exit-codes\",\r\n    \"-lstdc++\",\r\n    \"-lm\"],\r\n    link_libs = [],\r\n    opt_link_flags = [\"-Wl,--gc-sections\"],\r\n    unfiltered_compile_flags = [\"-fno-canonical-system-headers\",\r\n    \"-Wno-builtin-macro-redefined\",\r\n    \"-D__DATE__=\\\"redacted\\\"\",\r\n    \"-D__TIMESTAMP__=\\\"redacted\\\"\",\r\n    \"-D__TIME__=\\\"redacted\\\"\"],\r\n    coverage_compile_flags = [\"--coverage\"],\r\n    coverage_link_flags = [\"--coverage\"],\r\n    supports_start_end_lib = True,\r\n)\r\n\r\n# Android tooling requires a default toolchain for the armeabi-v7a cpu.\r\ncc_toolchain(\r\n    name = \"cc-compiler-armeabi-v7a\",\r\n    toolchain_identifier = \"stub_armeabi-v7a\",\r\n    toolchain_config = \":stub_armeabi-v7a\",\r\n    all_files = \":empty\",\r\n    ar_files = \":empty\",\r\n    as_files = \":empty\",\r\n    compiler_files = \":empty\",\r\n    dwp_files = \":empty\",\r\n    linker_files = \":empty\",\r\n    objcopy_files = \":empty\",\r\n    strip_files = \":empty\",\r\n    supports_param_files = 1,\r\n)\r\n\r\narmeabi_cc_toolchain_config(name = \"stub_armeabi-v7a\")\r\n```\r\nModified file :\r\n```\r\n# Copyright 2016 The Bazel Authors. All rights reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#    http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\n# This becomes the BUILD file for @local_config_cc// under non-FreeBSD unixes.\r\n\r\npackage(default_visibility = [\"//visibility:public\"])\r\n\r\nload(\":cc_toolchain_config.bzl\", \"cc_toolchain_config\")\r\nload(\":armeabi_cc_toolchain_config.bzl\", \"armeabi_cc_toolchain_config\")\r\nload(\"@rules_cc//cc:defs.bzl\", \"cc_toolchain\", \"cc_toolchain_suite\")\r\n\r\nlicenses([\"notice\"])  # Apache 2.0\r\n\r\ncc_library(\r\n    name = \"malloc\",\r\n)\r\n\r\nfilegroup(\r\n    name = \"empty\",\r\n    srcs = [],\r\n)\r\n\r\nfilegroup(\r\n    name = \"cc_wrapper\",\r\n    srcs = [\"cc_wrapper.sh\"],\r\n)\r\n\r\nfilegroup(\r\n    name = \"compiler_deps\",\r\n    srcs = glob([\"extra_tools/**\"], allow_empty = True) + [\":builtin_include_directory_paths\"],\r\n)\r\n\r\n# This is the entry point for --crosstool_top.  Toolchains are found\r\n# by lopping off the name of --crosstool_top and searching for\r\n# the \"${CPU}\" entry in the toolchains attribute.\r\ncc_toolchain_suite(\r\n    name = \"toolchain\",\r\n    toolchains = {\r\n        \"aarch64|compiler\": \":cc-compiler-aarch64\",\r\n        \"aarch64\": \":cc-compiler-aarch64\",\r\n        \"armeabi-v7a|compiler\": \":cc-compiler-armeabi-v7a\",\r\n        \"armeabi-v7a\": \":cc-compiler-armeabi-v7a\"\r\n    },\r\n)\r\n\r\ncc_toolchain(\r\n    name = \"cc-compiler-aarch64\",\r\n    toolchain_identifier = \"local\",\r\n    toolchain_config = \":local\",\r\n    all_files = \":compiler_deps\",\r\n    ar_files = \":compiler_deps\",\r\n    as_files = \":compiler_deps\",\r\n    compiler_files = \":compiler_deps\",\r\n    dwp_files = \":empty\",\r\n    linker_files = \":compiler_deps\",\r\n    objcopy_files = \":empty\",\r\n    strip_files = \":empty\",\r\n    supports_param_files = 1,\r\n)\r\n\r\ncc_toolchain_config(\r\n    name = \"local\",\r\n    cpu = \"aarch64\",\r\n    compiler = \"compiler\",\r\n    toolchain_identifier = \"local\",\r\n    host_system_name = \"local\",\r\n    target_system_name = \"local\",\r\n    target_libc = \"local\",\r\n    abi_version = \"local\",\r\n    abi_libc_version = \"local\",\r\n    cxx_builtin_include_directories = [\"/usr/lib/gcc/aarch64-linux-gnu/10/include\",\r\n    \"/usr/local/include\",\r\n    \"/usr/include/aarch64-linux-gnu\",\r\n    \"/usr/include\",\r\n    \"/usr/include/c++/10\",\r\n    \"/usr/include/aarch64-linux-gnu/c++/10\",\r\n    \"/usr/include/c++/10/backward\"],\r\n    tool_paths = {\"ar\": \"/usr/bin/ar\",\r\n        \"ld\": \"/usr/bin/ld\",\r\n        \"cpp\": \"/usr/bin/cpp\",\r\n        \"gcc\": \"/usr/bin/gcc\",\r\n        \"dwp\": \"/usr/bin/dwp\",\r\n        \"gcov\": \"/usr/bin/gcov\",\r\n        \"nm\": \"/usr/bin/nm\",\r\n        \"objcopy\": \"/usr/bin/objcopy\",\r\n        \"objdump\": \"/usr/bin/objdump\",\r\n        \"strip\": \"/usr/bin/strip\"},\r\n    compile_flags = [\"-U_FORTIFY_SOURCE\",\r\n    \"-fstack-protector\",\r\n    \"-Wall\",\r\n    \"-Wunused-but-set-parameter\",\r\n    \"-Wno-free-nonheap-object\",\r\n    \"-fno-omit-frame-pointer\"],\r\n    opt_compile_flags = [\"-g0\",\r\n    \"-O2\",\r\n    \"-D_FORTIFY_SOURCE=1\",\r\n    \"-DNDEBUG\",\r\n    \"-ffunction-sections\",\r\n    \"-fdata-sections\"],\r\n    dbg_compile_flags = [\"-g\"],\r\n    cxx_flags = [\"-std=c++11\"],\r\n    link_flags = [\"-fuse-ld=gold\",\r\n    \"-Wl,-no-as-needed\",\r\n    \"-Wl,-z,relro,-z,now\",\r\n    \"-B/usr/bin\",\r\n    \"-pass-exit-codes\",\r\n    \"-lstdc++\",\r\n    \"-lm\"],\r\n    link_libs = [],\r\n    opt_link_flags = [\"-Wl,--gc-sections\"],\r\n    unfiltered_compile_flags = [\"-fno-canonical-system-headers\",\r\n    \"-Wno-builtin-macro-redefined\",\r\n    \"-D__DATE__=\\\"redacted\\\"\",\r\n    \"-D__TIMESTAMP__=\\\"redacted\\\"\",\r\n    \"-D__TIME__=\\\"redacted\\\"\"],\r\n    coverage_compile_flags = [\"--coverage\"],\r\n    coverage_link_flags = [\"--coverage\"],\r\n    supports_start_end_lib = True,\r\n)\r\n\r\n# Android tooling requires a default toolchain for the armeabi-v7a cpu.\r\ncc_toolchain(\r\n    name = \"cc-compiler-armeabi-v7a\",\r\n    toolchain_identifier = \"stub_armeabi-v7a\",\r\n    toolchain_config = \":stub_armeabi-v7a\",\r\n    all_files = \":empty\",\r\n    ar_files = \":empty\",\r\n    as_files = \":empty\",\r\n    compiler_files = \":empty\",\r\n    dwp_files = \":empty\",\r\n    linker_files = \":empty\",\r\n    objcopy_files = \":empty\",\r\n    strip_files = \":empty\",\r\n    supports_param_files = 1,\r\n)\r\n\r\narmeabi_cc_toolchain_config(name = \"stub_armeabi-v7a\")\r\n```\r\n Now it works almost properly(at least I have it built successfully after hours , but it crashes when it's being imported) .\r\n```\r\n\u276f python3\r\nPython 3.9.4 (default, Apr  4 2021, 19:38:44)\r\n[GCC 10.2.1 20210401] on linux                                                     Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nRuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\r\nRuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\r\nImportError: numpy.core._multiarray_umath failed to import\r\nImportError: numpy.core.umath failed to import\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/__init__.py\", line 46, in <module>\r\n    from tensorflow.python import data\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/__init__.py\", line 25, in <module>\r\n    from tensorflow.python.data import experimental\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 99, in <module>\r\n    from tensorflow.python.data.experimental import service\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 140, in <module>\r\n    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 25, in <module>\r\n    from tensorflow.python.data.experimental.ops import compression_ops\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 20, in <module>\r\n    from tensorflow.python.data.util import structure\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/util/structure.py\", line 26, in <module>\r\n    from tensorflow.python.data.util import nest\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/util/nest.py\", line 40, in <module>\r\n    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/sparse_tensor.py\", line 28, in <module>\r\n    from tensorflow.python.framework import constant_op\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/constant_op.py\", line 29, in <module>\r\n    from tensorflow.python.eager import execute\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\", line 27, in <module>\r\n    from tensorflow.python.framework import dtypes\r\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/dtypes.py\", line 33, in <module>\r\n    _np_bfloat16 = _pywrap_bfloat16.TF_bfloat16_type()\r\nTypeError: Unable to convert function return value to a Python type! The signature was\r\n        () -> handle\r\n>>>\r\n```\r\nPackage versions : `absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.1 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.28.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-2.10 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.8 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 setuptools-56.0.0 six-1.15.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.4 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1`\r\nThese packages are automatically installed by `pip install ./tensorflow-2.6.0-cp39-cp39-linux_armv8l.whl` , and I think it has already solved the dependency problem . I wonder why it crashes . Maybe it requires higher version of numpy ?\r\n I'm going to write an issue of bazel , and if this bug with `python-3.9` cannot be solved , I'll have to write a new issue of tensorflow about it . Later I'll try different versions of `numpy` and see which one is compatible with `tensorflow` .", "Python 3.9 support is added with TF 2.5 rc1, so all upcoming later versions of TF should support it as well. You may try with latest numpy version just to be sure.", "> Python 3.9 support is added with TF 2.5 rc1, so all upcoming later versions of TF should support it as well. You may try with latest numpy version just to be sure.\r\n\r\nI tried `numpy-1.20.5` and it works with `tensorflow-2.6.0` . This problem has been partly solved .\r\nBut when I try to run a simple test program , it doesn't work properly .\r\nProgram source code ( from official tensorflow tutorials ) :\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nprint(tf.__version__)\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\ntrain_images = train_images / 255.0\r\n\r\ntest_images = test_images / 255.0\r\nmodel = keras.Sequential([\r\n            keras.layers.Flatten(input_shape=(28, 28)),\r\n            keras.layers.Dense(128, activation='relu'),\r\n            keras.layers.Dense(10)\r\n                ])\r\nmodel.compile(optimizer='adam',\r\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n    metrics=['accuracy'])\r\nmodel.fit(train_images, train_labels, epochs=10)\r\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\nprint('\\nTest accuracy:', test_acc)\r\nprobability_model = tf.keras.Sequential([model,tf.keras.layers.Softmax()])\r\npredictions = probability_model.predict(test_images)\r\nprint(predictions[0],np.argmax(predictions[0]),test_labels[0])\r\n```\r\nLogs :\r\n```\r\n\u276f python3 test.py\r\n2.6.0\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\r\n26427392/26421880 [==============================] - 16s 1us/step\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\r\n8192/5148 [===============================================] - 0s 56us/step\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\r\n4423680/4422102 [==============================] - 2s 0us/step\r\n2021-04-14 21:57:02.877681: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2021-04-14 21:57:03.587573: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:180] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-04-14 21:57:03.591844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 19200000 Hz\r\nEpoch 1/10\r\n1875/1875 [==============================] - 23s 12ms/step - loss: inf - accuracy: 0.1185\r\nEpoch 2/10\r\n1875/1875 [==============================] - 24s 13ms/step - loss: 3938612167119114297465147773419520.0000 - accuracy: 0.1164\r\nEpoch 3/10\r\n1875/1875 [==============================] - 23s 12ms/step - loss: inf - accuracy: 0.1085\r\nEpoch 4/10\r\n1875/1875 [==============================] - 24s 13ms/step - loss: nan - accuracy: 0.1010\r\nEpoch 5/10\r\n1875/1875 [==============================] - 22s 12ms/step - loss: nan - accuracy: 0.0974\r\nEpoch 6/10\r\n1875/1875 [==============================] - 22s 12ms/step - loss: nan - accuracy: 0.1001\r\nEpoch 7/10\r\n1875/1875 [==============================] - 22s 12ms/step - loss: nan - accuracy: 0.0996\r\nEpoch 8/10\r\n1875/1875 [==============================] - 20s 11ms/step - loss: nan - accuracy: 0.0992\r\nEpoch 9/10\r\n1875/1875 [==============================] - 22s 12ms/step - loss: nan - accuracy: 0.0999\r\nEpoch 10/10\r\n1875/1875 [==============================] - 22s 12ms/step - loss: nan - accuracy: 0.1023\r\n313/313 - 3s - loss: nan - accuracy: 0.1000\r\nTest accuracy: 0.10000000149011612\r\n[nan nan nan nan nan nan nan nan nan nan] 0 9\r\n```\r\nThere are only 10 types of objects in the dataset `keras.datasets.fashion_mnist` , so it seems that the program can't classify the pictures at all .\r\nDo you know how to fix this problem ? Thanks .", "I tried with latest tf-nightly version and results look correct. See [gist](https://colab.research.google.com/gist/ymodak/32ff22b1e2cbedd91cd0fa0fab894b3d/git48453.ipynb)\r\nI would suggest using a more stable version (current) to check like TF 2.5.0-rc1", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48453\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48453\">No</a>\n"]}, {"number": 48451, "title": "Warning when using a TFAutoModelWithLMHead logit outputs in the graph mode", "body": "I've built a translation model following [this TensorFlow tutorial](https://www.tensorflow.org/tutorials/text/nmt_with_attention). The overall structure of my code is the same, although I added GPT in the decoder function to get help from this language model and create better translations. Right now this is how I import the model:\r\n```\r\ngpt_model = TFAutoModelWithLMHead.from_pretrained(model_name_or_path,\r\n                                                  output_attentions=False,\r\n                                                  return_dict=False,\r\n                                                  output_hidden_states=False,\r\n                                                  use_cache=False\r\n                                                  )\r\n\r\ngpt_tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\r\n```\r\n\r\nand in the dencoder function, I give one input_id to the GPT model, and output the logits in the graph mode:\r\n\r\n`gpt_model(input_id)[0][:, -1, :]`\r\n\r\n Right now my question is why do I get the following warning and how can I silence them properly when training in graph mode?\r\n```\r\nepoch  0\r\nWARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\r\nWARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f90975dfde0>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n```\r\n\r\nand the following error:\r\n```\r\nWARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\r\nWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\r\n```\r\n\r\nThe second warning doesn't seem consistent as I have already set all these values to False in the model config. I also tried decorating the model in the following way and then using it, but it didn't work either. (I don't know if it's even correct to do so)\r\n\r\n`gpt_model = tf.autograph.experimental.do_not_convert(gpt_model)\r\n`\r\n\r\nI'm running all the code in Colab with GPU mode on.\r\n\r\nThanks in advance", "comments": ["@mitramir55 \r\n\r\nCould you please fill the issue template\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following details\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory\r\n\r\nand the exact sequence of commands / steps that you executed before running into the problem. Thanks!\r\n", "Hi @UsharaniPagadala, thank you for your response.\r\n\r\nI'm working with Google Colab and this problem occurs in all modes (with or without GPU or TPU) with the usual memory it offers to normal users (13 gigabytes).\r\nI'm using:\r\nTensorFlow 2.4.1\r\nPython 3.7.10\r\nIn short, I run the GPT model (Persian GPT model) in the graph mode and generate logits for predicting the next tokens based on the target tokens (till time step t) in the target sentence. Then these logits are linearly combined with the seq2seq model output and together they predict the next token id.\r\nThis warning does not occur when I just run the seq2seq translation model and only appears when I generate tokens using GPT too.\r\n\r\n[Here is a copy of the model and preprocessing steps](https://colab.research.google.com/drive/16dddt-NS4xmeYCCChhkgTvgnEf7ePZ3o?usp=sharing). I've titled every part of the code and you can go straight to the last section called \"The Training\". Please tell me if there is any more information needed. \r\n\r\n\r\nThanks in advance. ", "@mitramir55 \r\nThese two messages are just a warning, you can ignore them if you are not concerned. Basically, these messages will always be displayed everytime the graph node is executed, and only in graph mode.", "Thank you for your response. I guess the warning prompt should be changed because each time I run my code it tells me to contact the TensorFlow team.\r\n`\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.`", "@mitramir55 \r\nCan you confirm if you are using:\r\n```imported keras from tensorflow (from tensorflow import keras)```\r\nAlso, please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/45354#issuecomment-740039243) from a similar issue and check if it helps. [#47898] Thanks!", "Yes, for all layers, loss, and the optimizer I use tf.keras.layers\\optimizers\\...\r\nThanks for sharing these links, but I was looking for a solution or a reason behind this type of warning instead of just suppressing it. Something like this is also printed out when training a simple text classification neural net in Colab (without the graph mode on):\r\n\r\n![image](https://user-images.githubusercontent.com/53291220/117398023-a22c0c80-af12-11eb-8145-9ee18998016c.png)\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Apologies for the delay in resolving your issue here. I am afraid that the code snippet provided are insufficient to reproduce the problem and also the warning messages you are referring to arise from [transformers module](https://github.com/huggingface/transformers/issues).\r\nhttps://github.com/huggingface/transformers/blob/a26f4d620874b32d898a5b712006a4c856d07de1/src/transformers/modeling_tf_utils.py#L295\r\n>WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\r\nWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\r\n\r\n[Transformers discussion forum](https://discuss.huggingface.co/) and their github repo is suitable place for this question.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48451\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48451\">No</a>\n"]}, {"number": 48450, "title": "Tensorflow is extremely slow during startup", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux, x86_64, 5.10.28-1-lts\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary, from conda\r\n- TensorFlow version (use command below): Tensorflow 2.4.1\r\n- Python version: Python 3.8.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: cudatoolkit 10.1.243, cudnn 7.6.5 (both from conda); cuda 11.2.2 (from Arch pacman, system-wide)\r\n- GPU model and memory: Nvidia GTX 3080, 10018 MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI just write some code to train a simple model, and the Tensorflow loading time is too long. Here are some log:\r\n\r\n```\r\n>>> python Train.py\r\n2021-04-10 14:16:40.493971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-10 14:16:46.296137: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-04-10 14:16:46.306974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-04-10 14:16:46.522294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:73:00.0 name: GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2021-04-10 14:16:46.522374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-10 14:16:46.558851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-10 14:16:46.558999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-04-10 14:16:46.578194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-04-10 14:16:46.582360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-04-10 14:16:46.612937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-04-10 14:16:46.618842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-04-10 14:16:46.673830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-04-10 14:16:46.676207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-04-10 14:16:46.678545: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-04-10 14:16:46.689923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:73:00.0 name: GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2021-04-10 14:16:46.689992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-10 14:16:46.690048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-10 14:16:46.690069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-04-10 14:16:46.690089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-04-10 14:16:46.690108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-04-10 14:16:46.690129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-04-10 14:16:46.690149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-04-10 14:16:46.690169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-04-10 14:16:46.691482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-04-10 14:16:46.691918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n```\r\nI would like to draw your attention to the fact that there is **a seven-minute gap** between the above and the following logs (they are continuously output, I did not intercept them)\r\n```\r\n2021-04-10 14:23:02.128175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-04-10 14:23:02.128248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2021-04-10 14:23:02.128266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2021-04-10 14:23:02.130070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9037 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:73:00.0, compute capability: 8.6)\r\n2021-04-10 14:23:02.131846: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-04-10 14:23:03.051975: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2021-04-10 14:23:03.052030: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2021-04-10 14:23:03.052589: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2021-04-10 14:23:03.058752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\r\n2021-04-10 14:23:03.159864: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\r\n2021-04-10 14:23:03.159975: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2021-04-10 14:23:03.345523: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-04-10 14:23:03.376433: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\r\nEpoch 1/10\r\n2021-04-10 14:23:07.935855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-10 14:24:36.693386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n  1/100 [..............................] - ETA: 26:48:40 - loss: 0.0891 - accuracy: 0.2930\r\n```\r\nAnd here, another 15 minutes log gap\r\n```\r\n2021-04-10 14:39:18.561866: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2021-04-10 14:39:18.561893: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2021-04-10 14:39:18.562690: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\r\n  2/100 [..............................] - ETA: 39s - loss: 0.0836 - accuracy: 0.3271     2021-04-10 14:39:18.780340: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\r\n2021-04-10 14:39:18.784724: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \r\n2021-04-10 14:39:18.786618: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2021-04-10 14:39:18.790988: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18\r\n2021-04-10 14:39:18.792157: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.trace.json.gz\r\n2021-04-10 14:39:18.825724: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18\r\n2021-04-10 14:39:18.829485: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.memory_profile.json.gz\r\n2021-04-10 14:39:18.829700: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18Dumped tool data for xplane.pb to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.xplane.pb\r\nDumped tool data for overview_page.pb to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.overview_page.pb\r\nDumped tool data for input_pipeline.pb to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.input_pipeline.pb\r\nDumped tool data for tensorflow_stats.pb to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.tensorflow_stats.pb\r\nDumped tool data for kernel_stats.pb to ./logs/20210410-142303/train/plugins/profile/2021_04_10_14_39_18/GuServer.kernel_stats.pb\r\n\r\n100/100 [==============================] - 999s 243ms/step - loss: 0.0518 - accuracy: 0.5508 - val_loss: 0.0583 - val_accuracy: 0.4046\r\n```\r\nand start here, everything goes well. In short, the Tensorflow need about 23 minutes to startup and work, and I'm not sure what went wrong.\r\n\r\n**Standalone code to reproduce the issue**\r\nI believe this problem is not code-specific. I try to run the [example code provided on tensorflow official website](https://www.tensorflow.org/tutorials/quickstart/beginner), and the same problem occurs. So I think this problem can be reproduced with any code which using tensorflow on my computer.\r\n", "comments": ["For anyone who meet the same problem, I finally resolve this by installing the nightly version, and everything goes well now. I'll close this issue, and wish this can really help someone."]}, {"number": 48449, "title": "Can not convert a tf model to tf.lite format", "body": "tf version: 2.4.1\r\n\r\nHere is my model constrution:\r\n\r\n\r\n```\r\nclass TransformerBlock(layers.Layer):\r\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\r\n        super(TransformerBlock, self).__init__()          \r\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\r\n        self.ffn = keras.Sequential(\r\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\r\n        )\r\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\r\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\r\n        self.dropout1 = layers.Dropout(rate)\r\n        self.dropout2 = layers.Dropout(rate)\r\n\r\n    def call(self, inputs, training):\r\n        attn_output = self.att(inputs, inputs)\r\n        attn_output = self.dropout1(attn_output, training=training)\r\n        out1 = self.layernorm1(inputs + attn_output)\r\n        ffn_output = self.ffn(out1)\r\n        ffn_output = self.dropout2(ffn_output, training=training)\r\n        return self.layernorm2(out1 + ffn_output)\r\n\r\n\r\nclass TokenAndPositionEmbedding(layers.Layer):\r\n    def __init__(self, maxlen, vocab_size, embed_dim):\r\n        super(TokenAndPositionEmbedding, self).__init__()\r\n        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\r\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\r\n\r\n    def call(self, x):\r\n        maxlen = tf.shape(x)[-1]\r\n        positions = tf.range(start=0, limit=maxlen, delta=1)\r\n        positions = self.pos_emb(positions)\r\n        x = self.token_emb(x)\r\n        return x + positions\r\n\r\n# https://tfhub.dev/tensorflow/albert_en_preprocess/3\r\npreprocessor_file = \"./albert_en_preprocess_3\"\r\npreprocessor_layer = hub.KerasLayer(preprocessor_file)\r\n\r\n\r\ndef get_model_transormer(num_classes):\r\n    embed_dim = 32  # Embedding size for each token\r\n    num_heads = 2  # Number of attention heads\r\n    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\r\n    \r\n    preprocessor = hub.load(preprocessor_file)\r\n    vocab_size = preprocessor.tokenize.get_special_tokens_dict()['vocab_size'].numpy()\r\n\r\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) \r\n\r\n    encoder_inputs = preprocessor_layer(text_input)['input_word_ids']\r\n\r\n    embedding_layer = TokenAndPositionEmbedding(encoder_inputs.shape[1], vocab_size, embed_dim)\r\n    x = embedding_layer(encoder_inputs)\r\n    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\r\n    x = transformer_block(x)\r\n    x = layers.GlobalAveragePooling1D()(x)\r\n    x = layers.Dropout(0.1)(x)\r\n    x = layers.Dense(20, activation=\"relu\")(x)\r\n    x = layers.Dropout(0.1)(x)\r\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\r\n\r\n    #outputs = layers.Dense(1, activation=\"sigmoid\")(x)\r\n    model = keras.Model(inputs=text_input, outputs=outputs)\r\n\r\n    model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"acc\"])\r\n    #model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\r\n    return model\r\n\r\nmodel = get_model_transormer(4)\r\nmodel.save('model_charl')\r\n```\r\n\r\nAfter saving the model I want to convert it to tf.lite model:\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('./model_charl')\r\n#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\n\r\nThis is the error message:\r\n\r\n\r\n> 2021-04-10 04:20:30.488392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n> 2021-04-10 04:20:30.488415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n> loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): error: requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> ---------------------------------------------------------------------------\r\n> Exception                                 Traceback (most recent call last)\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n>     212                                                  debug_info_str,\r\n> --> 213                                                  enable_mlir_converter)\r\n>     214       return model_str\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n>      37       debug_info_str,\r\n> ---> 38       enable_mlir_converter)\r\n>      39\r\n> \r\n> Exception: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> \r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> ConverterError                            Traceback (most recent call last)\r\n> <ipython-input-4-def2ce8a009f> in <module>\r\n>       2 #converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n>       3 converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n> ----> 4 tflite_quant_model = converter.convert()\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)\r\n>     737     converter_kwargs.update(quant_mode.converter_flags())\r\n>     738\r\n> --> 739     result = _convert_saved_model(**converter_kwargs)\r\n>     740     calibrate_and_quantize, flags = quant_mode.quantizer_flags()\r\n>     741     if calibrate_and_quantize:\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in convert_saved_model(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)\r\n>     635       None,  # input_data, unused\r\n>     636       None,  # debug_info_str, unused\r\n> --> 637       enable_mlir_converter=True)\r\n>     638   return data\r\n>     639\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n>     214       return model_str\r\n>     215     except Exception as e:\r\n> --> 216       raise ConverterError(str(e))\r\n>     217\r\n>     218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n> \r\n> ConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from", "comments": ["Could you use the tf-nightly version and enable the select tf option?", "Hi @yananchen1989 I will suggest you try this \r\n\r\n`import tensorflow as tf`\r\n`converter = tf.lite.TFLiteConverter.from_saved_model('/content/Model_Weights')` # path to the SavedModel directory\r\n`tflite_model = converter.convert()`\r\n`with open('tflite_model','wb') as file: file.write(tflite_model)`", "> Hi @yananchen1989 I will suggest you try this\r\n> \r\n> `import tensorflow as tf`\r\n> `converter = tf.lite.TFLiteConverter.from_saved_model('/content/Model_Weights')` # path to the SavedModel directory\r\n> `tflite_model = converter.convert()`\r\n> `with open('tflite_model','wb') as file: file.write(tflite_model)`\r\n\r\n`converter = tf.lite.TFLiteConverter.from_saved_model('model_charl')`\r\n\r\n> WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa998398c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n\r\nand then \r\n\r\n`[tflite_model = converter.convert()]`\r\n\r\n> \r\n> Exception: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> \r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> ConverterError                            Traceback (most recent call last)\r\n> <ipython-input-7-c548bab089a8> in <module>\r\n> ----> 1 tflite_model = converter.convert()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    737     converter_kwargs.update(quant_mode.converter_flags())\r\n    738\r\n--> 739     result = _convert_saved_model(**converter_kwargs)\r\n    740     calibrate_and_quantize, flags = quant_mode.quantizer_flags()\r\n    741     if calibrate_and_quantize:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in convert_saved_model(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)\r\n    635       None,  # input_data, unused\r\n    636       None,  # debug_info_str, unused\r\n--> 637       enable_mlir_converter=True)\r\n    638   return data\r\n    639\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    214       return model_str\r\n    215     except Exception as e:\r\n--> 216       raise ConverterError(str(e))\r\n    217\r\n    218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\n> ConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12076\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12243\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13370\") at \"StatefulPartitionedCall_1\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from", "> Could you use the tf-nightly version and enable the select tf option?\r\n\r\nwell, it would be perfect to solve this issue within 2.4.1 since we are not allowed to use model from tf-nightly in the production environment.", "@yananchen1989 \r\n\r\nCould you please confirm if the issue is resolved? if yes, please feel free to move this issue to closed status.Thanks\r\n\r\n\r\n", "You can try out tf 2.5 versions since they are under the rc version and it will be released soon.", "@yananchen1989 \r\n\r\nplease confirm if the issue still persist", "I will try tf version 2.5 in the future. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48449\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48449\">No</a>\n", "I upgrade my tf version to 2.5.0rc3 and tensorflow-text to version 2.5.0rc0\r\nthe model as I described above, still can not work in this line of code:\r\n`tflite_quant_model = converter.convert()`\r\n\r\n\r\n\r\nHere are the errors:\r\n\r\n> \r\n> 2021-05-10 02:00:48.593906: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\r\n> 2021-05-10 02:00:48.593961: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\r\n> 2021-05-10 02:00:48.593972: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.\r\n> 2021-05-10 02:00:48.594267: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: ./model_charl\r\n> 2021-05-10 02:00:48.622519: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\r\n> 2021-05-10 02:00:48.622580: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./model_charl\r\n> 2021-05-10 02:00:48.622681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2021-05-10 02:00:48.622690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]\r\n> 2021-05-10 02:00:48.734750: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n> 2021-05-10 02:00:48.861432: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ./model_charl\r\n> 2021-05-10 02:00:48.949085: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 354818 microseconds.\r\n> loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12070\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12237\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13489\") at \"StatefulPartitionedCall_1\")): error: 'tf.TensorListReserve' op requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12070\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12237\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13489\") at \"StatefulPartitionedCall_1\")): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> ---------------------------------------------------------------------------\r\n> Exception                                 Traceback (most recent call last)\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n>     293                                                  debug_info_str,\r\n> --> 294                                                  enable_mlir_converter)\r\n>     295       return model_str\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n>      37       debug_info_str,\r\n> ---> 38       enable_mlir_converter)\r\n>      39\r\n> \r\n> Exception: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12070\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12237\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13489\") at \"StatefulPartitionedCall_1\")): 'tf.TensorListReserve' op requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12070\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12237\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13489\") at \"StatefulPartitionedCall_1\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> \r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> ConverterError                            Traceback (most recent call last)\r\n> <ipython-input-7-c3524bf98e8f> in <module>\r\n> ----> 1 tflite_quant_model = converter.convert()\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)\r\n>     911     converter_kwargs.update(quant_mode.converter_flags())\r\n>     912\r\n> --> 913     result = _convert_saved_model(**converter_kwargs)\r\n>     914     if self.experimental_new_quantizer:\r\n>     915       calibrate_and_quantize, flags = quant_mode.quantizer_flags(\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in convert_saved_model(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)\r\n>     725       None,  # input_data, unused\r\n>     726       None,  # debug_info_str, unused\r\n> --> 727       enable_mlir_converter=True)\r\n>     728   return data\r\n>     729\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n>     295       return model_str\r\n>     296     except Exception as e:\r\n> --> 297       raise ConverterError(str(e))\r\n>     298\r\n>     299   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n> \r\n> ConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12070\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12237\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13489\") at \"StatefulPartitionedCall_1\")): 'tf.TensorListReserve' op requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n> <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"map/TensorArrayV2_2@__inference_bert_pack_inputs_layer_call_and_return_conditional_losses_4831\" at \"bert_pack_inputs/PartitionedCall@__inference_model_layer_call_and_return_conditional_losses_4887\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_4897\") at \"StatefulPartitionedCall@__inference_restored_function_body_12070\") at \"model/keras_layer/StatefulPartitionedCall@__inference__wrapped_model_12237\") at \"StatefulPartitionedCall@__inference_signature_wrapper_13489\") at \"StatefulPartitionedCall_1\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\r\n> <unknown>:0: note: loc(\"StatefulPartitionedCall_1\"): called from", "@yananchen1989 could you try the select tf option? https://www.tensorflow.org/lite/guide/ops_select\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\ntflite_model = converter.convert()\r\n```", "@abattery please help fix. We are about to implement the tf.lite version model, with the preprocessor layer embedded, into the production environment - the android mobile devices.", "@abattery  \r\nThanks for your help. I just try your codes,\r\n\r\n![WX20210510-100723](https://user-images.githubusercontent.com/26405281/117597133-8c6b5100-b177-11eb-8b56-d36ce13d0f78.png)\r\n\r\nit is OK?", "It looks okay to me. The above message is a warning that the above operators are now being fallback to the Select TF option.", "> It looks okay to me. The above message is a warning that the above operators are now being fallback to the Select TF option.\r\n\r\nthanks. I will train and test this model to validate its effectiveness.\r\nI will give you the feedbacks several days later.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48449\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48449\">No</a>\n", "If you hit other issues, please file another issue instead of reopening this issue in order to keep each issue focused."]}, {"number": 48448, "title": "Is there a way to set training = True after the model is trained?", "body": "There are similar questions that I have it now, such as this: [#36936](https://github.com/tensorflow/tensorflow/issues/36936).\r\n\r\nI did not find a solution or answer.\r\n\r\nI have a model that have Batch Normalization and Dropouts. As a result, I always have to set training = True to perform image segmentation, etc. For instance;\r\n\r\n```\r\nimport tensorflow as tf\r\nmy_model = tf.keras.models.load_model(\"model\")\r\nresult = my_model(inputImage, training = True)\r\n\r\n```\r\n\r\nIf I donot provide training = True, the result.numpy() is nan values.\r\n\r\nIn addition in Python, I want to use this in tensorflow/java. As a result, I donot know how to provide training = True in tensorflow java and I opened a new issue for tensorflow/java [#284](https://github.com/tensorflow/java/issues/284) for this question as well.\r\n\r\nI wonder if there is a way to hack or set the trained_model such that, it does not require` training = True `anymore? I thought if I can do this in Python and save the model again, I may not need it in tensorflow/java again.\r\n\r\n\r\n\r\n", "comments": ["@micosacak \r\n\r\nCan you share more details for us to analyse, simple stand alone code to replicate the issue faced or a colab gist with the code and error. Thanks\r\n\r\n\r\n\r\n", "Here is the Python code below [or from here:](https://www.tensorflow.org/tutorials/generative/dcgan)\r\n\r\n```\r\nimport tensorflow as tf\r\nimport glob\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport os\r\nimport PIL\r\nfrom tensorflow.keras import layers\r\nimport time\r\n\r\nfrom IPython import display\r\n\r\n(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\r\ntrain_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\r\n\r\nBUFFER_SIZE = 60000\r\nBATCH_SIZE = 256\r\n\r\n# Batch and shuffle the data\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\n\r\ndef make_generator_model():\r\n    model = tf.keras.Sequential()\r\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\r\n    model.add(layers.BatchNormalization())\r\n    model.add(layers.LeakyReLU())\r\n    model.add(layers.Reshape((7, 7, 256)))\r\n    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\r\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\r\n    assert model.output_shape == (None, 7, 7, 128)\r\n    model.add(layers.BatchNormalization())\r\n    model.add(layers.LeakyReLU())\r\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\r\n    assert model.output_shape == (None, 14, 14, 64)\r\n    model.add(layers.BatchNormalization())\r\n    model.add(layers.LeakyReLU())\r\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\r\n    assert model.output_shape == (None, 28, 28, 1)\r\n    return model\r\n\r\ngenerator = make_generator_model()\r\n\r\nnoise = tf.random.normal([1, 100])\r\ngenerated_image = generator(noise, training=False)\r\n\r\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')\r\n\r\ndef make_discriminator_model():\r\n    model = tf.keras.Sequential()\r\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\r\n    model.add(layers.LeakyReLU())\r\n    model.add(layers.Dropout(0.3))\r\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\r\n    model.add(layers.LeakyReLU())\r\n    model.add(layers.Dropout(0.3))\r\n    model.add(layers.Flatten())\r\n    model.add(layers.Dense(1))\r\n    return model\r\n\r\ndiscriminator = make_discriminator_model()\r\ndecision = discriminator(generated_image)\r\nprint (decision)\r\n# This method returns a helper function to compute cross entropy loss\r\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n\r\ndef discriminator_loss(real_output, fake_output):\r\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\r\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\r\n    total_loss = real_loss + fake_loss\r\n    return total_loss\r\n\r\ndef generator_loss(fake_output):\r\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\r\n\r\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\r\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n\r\ncheckpoint_dir = './training_checkpoints'\r\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\r\n                                 discriminator_optimizer=discriminator_optimizer,\r\n                                 generator=generator,\r\n                                 discriminator=discriminator)\r\n\r\n\r\nEPOCHS = 50\r\nnoise_dim = 100\r\nnum_examples_to_generate = 16\r\n\r\n# You will reuse this seed overtime (so it's easier)\r\n# to visualize progress in the animated GIF)\r\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\r\n\r\n# Notice the use of `tf.function`\r\n# This annotation causes the function to be \"compiled\".\r\n@tf.function\r\ndef train_step(images):\r\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\r\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n      generated_images = generator(noise, training=True)\r\n      real_output = discriminator(images, training=True)\r\n      fake_output = discriminator(generated_images, training=True)\r\n      gen_loss = generator_loss(fake_output)\r\n      disc_loss = discriminator_loss(real_output, fake_output)\r\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\r\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\r\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\r\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\r\n\r\ndef train(dataset, epochs):\r\n  for epoch in range(epochs):\r\n    start = time.time()\r\n    for image_batch in dataset:\r\n      train_step(image_batch)\r\n    # Produce images for the GIF as you go\r\n    display.clear_output(wait=True)\r\n    generate_and_save_images(generator,\r\n                             epoch + 1,\r\n                             seed)\r\n    # Save the model every 15 epochs\r\n    if (epoch + 1) % 15 == 0:\r\n      checkpoint.save(file_prefix = checkpoint_prefix)\r\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\r\n  # Generate after the final epoch\r\n  display.clear_output(wait=True)\r\n  generate_and_save_images(generator,\r\n                           epochs,\r\n                           seed)\r\n  return generator  \r\n\r\ndef generate_and_save_images(model, epoch, test_input):\r\n  # Notice `training` is set to False.\r\n  # This is so all layers run in inference mode (batchnorm).\r\n  predictions = model(test_input, training=False)\r\n  fig = plt.figure(figsize=(4, 4))\r\n  for i in range(predictions.shape[0]):\r\n      plt.subplot(4, 4, i+1)\r\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\r\n      plt.axis('off')\r\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\r\n  plt.show()\r\n\r\ngenerator = train(train_dataset, EPOCHS)\r\n#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\r\n\r\ngenerator.save(\"model\")\r\nmyModel = tf.keras.models.load_model(\"model\")\r\n\r\npredict = myModel(test_input, training = True)\r\n\r\n```\r\n\r\nNow, everytime we have to provide `training = True `. Is there a way after loading the model again and change some values in the loaded model, which will not require `training = True `. By this way, we may do not have to `feed` in any flags in Java.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 48447, "title": "[r2.5 port][ROCm] Port PR#47650 and PR#48441 to r2.5", "body": "Adds proper AMP support for ROCm FP16 enabled devices for TF2.5 release branch. \r\nReferencing PRs https://github.com/tensorflow/tensorflow/pull/47650 and https://github.com/tensorflow/tensorflow/pull/48441\r\n\r\n@cheshire ", "comments": ["2.5 has already been cut. We'll add it to the next release. Hope that works."]}, {"number": 48446, "title": "Update bot_config.yml", "body": "", "comments": ["closing this PR as I have included the changed here. https://github.com/tensorflow/tensorflow/pull/48423"]}, {"number": 48445, "title": "[r2.5 port][ROCm] Port PR 48346 to r2.5 ", "body": "/cc @mihaimaruseac @angerson\r\n\r\n#48346\r\n\r\n", "comments": []}, {"number": 48444, "title": " [r2.5 port][ROCm] Port PR 47980 to r2.5 ", "body": "/cc @mihaimaruseac @angerson\r\n\r\n#47980\r\n", "comments": []}, {"number": 48443, "title": " [r2.5 port][ROCm] Port PR 47491 to r2.5", "body": "/cc @mihaimaruseac @angerson\r\n\r\n#47491", "comments": ["Can you fix the merge conflict please?"]}, {"number": 48442, "title": "[r2.5 port][ROCm] Port PR 47646 to r2.5", "body": "/cc @mihaimaruseac @angerson\r\n\r\n#47646", "comments": []}, {"number": 48441, "title": "[ROCm] Added to AMP allow list to include BatchMatMul", "body": "Updated AMP allowlist to include BatchMatMul for ROCm missing from when PR https://github.com/tensorflow/tensorflow/pull/47650 was merged. \r\n\r\n@cheshire ", "comments": []}, {"number": 48440, "title": "[r2.5 port][ROCm] Port PR 47937 to r2.5", "body": "/cc @mihaimaruseac @angerson \r\n\r\n#47937", "comments": []}, {"number": 48439, "title": "MultiWorkerMirroredStrategy:tensorflow.python.framework.errors_impl.InternalError: x root error(s) found.", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:No\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:source\r\n-   **TensorFlow version (use command below)**:2.3.3\r\n-   **Python version**:3.6\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:7.3.1\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\ntensorflow.python.framework.errors_impl.InternalError: 5 root error(s) found.\r\n  (0) Internal:  Missing 1-th output from node replica_3/sequential/dropout/dropout/Dropout (defined at /threading.py:916) \r\n\t [[GroupCrossDeviceControlEdges_1/Identity_7/_203]]\r\n  (1) Internal:  Missing 1-th output from node replica_3/sequential/dropout/dropout/Dropout (defined at /threading.py:916) \r\n  (2) Internal:  Missing 1-th output from node replica_3/sequential/dropout/dropout/Dropout (defined at /threading.py:916) \r\n\t [[GroupCrossDeviceControlEdges_0/SGD/SGD/update_1_1/Const/_147]]\r\n  (3) Internal:  Missing 1-th output from node replica_3/sequential/dropout/dropout/Dropout (defined at /threading.py:916) \r\n\t [[GroupCrossDeviceControlEdges_2/SGD/SGD/update_0/Const/_163]]\r\n  (4) Internal:  Missing 1-th output from node replica_3/sequential/dropout/dropout/Dropout (defined at /threading.py:916) \r\n\t [[div_no_nan_1/_119]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_7311]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function -> train_function -> train_function -> train_function\r\n\r\nThe above is the error message.I don't know the cause of it.\r\n\r\n### Source code / logs\r\nimport json\r\nimport math\r\nimport os\r\nimport sys\r\nimport numpy as np\r\nimport unet\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\r\nos.environ.pop('TF_CONFIG', None)\r\nimport tensorflow as tf\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\ndef build_and_compile_cnn_model():\r\n    model = unet.build()\r\n    model.compile(\r\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-9))\r\n    return model\r\n\r\ndef _is_chief(task_type, task_id):\r\n    # Note: there are two possible TF_CONFIG configuration.\r\n    # 1) In addition to worker tasks, a chief task type is use;\r\n    # in this case, this function should be modified to\r\n    # return task_type == 'chief'.\r\n    # 2) Only worker task type is used; in this case, worker 0 is\r\n    # regarded as the chief. The implementation demonstrated here\r\n    # is for this case.\r\n    # For the purpose of this colab section, we also add task_type is None\r\n    # case because it is effectively run with only single worker.\r\n    return (task_type == 'worker' and task_id == 0) or task_type is None\r\n\r\ndef get_temp_dir(dirpath, task_id):\r\n    base_dirpath = 'workertemp' + str(task_id)\r\n    temp_dir = os.path.join(dirpath, base_dirpath)\r\n    tf.io.gfile.makedirs(temp_dir)\r\n    return temp_dir\r\n\r\ndef write_filepath(filepath, task_type, task_id):\r\n    dirpath = os.path.dirname(filepath)\r\n    base = os.path.basename(filepath)\r\n    if not _is_chief(task_type, task_id):\r\n        dirpath = get_temp_dir(dirpath, task_id)\r\n    return os.path.join(dirpath, base)\r\n\r\nif __name__ == '__main__':\r\n    # I use default TFConfigClusterResolver,and set the environment variable below\r\n    # In total two processes are opened and 'index' of the other one is '1'\r\n    # like this\r\n    tf_config = {\r\n        'cluster': {'worker': ['10.1.11.60:15536', '10.1.11.59:19203']},\r\n        'task': {'type': 'worker', 'index': 0}\r\n    }\r\n    os.environ['TF_CONFIG'] = json.dumps(tf_config)\r\n\r\n    batch_size = 4\r\n\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n    with strategy.scope():\r\n        test_model = build_and_compile_cnn_model()\r\n    # I use handwriting dataset\r\n    train_data = np.load('train_data.npy')\r\n    train_label = np.load('train_label.npy')\r\n    # train_data shape is (60000, 28, 28, 1)\r\n    # Only use the first 1000 pictures to train the model\r\n    train_data = train_data[0:1000]\r\n    train_label = train_label[0:1000]\r\n    len_data = len(train_data)\r\n    len_label = len(train_label)\r\n    \r\n    # Abandon partial batch\r\n    steps_per_epoch = math.floor(len_data / batch_size)\r\n    \r\n    # Set save path just like tutorial\r\n    checkpoint_dir = \"./ckpt\"\r\n    checkpoint_name = \"./ckpt/chief_ckpt\"\r\n    if not os.path.exists(checkpoint_dir):\r\n        os.makedirs(checkpoint_dir)\r\n    \r\n    tf_config = json.loads(os.environ['TF_CONFIG'])\r\n    task_type = tf_config['task']['type']\r\n    task_rank = tf_config['task']['index']\r\n    write_model_path = write_filepath(checkpoint_name, task_type, task_rank)\r\n    \r\n    callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=write_model_path + '_{epoch:04d}.h5',\r\n                                                    save_best_only=False,\r\n                                                    save_weights_only=True,\r\n                                                    save_freq='epoch')]\r\n    \r\n    # Model loads latest weights\r\n    checkpoints = [checkpoint_dir + '/' + name for name in os.listdir(checkpoint_dir) if name.endswith('.h5')]\r\n    if checkpoints:\r\n        latest_checkpoint = max(checkpoints, key=os.path.getctime)\r\n        test_model.load_weights(latest_checkpoint)\r\n    \r\n    test_model.fit(x=train_data,\r\n                   y=train_label,\r\n                   batch_size=batch_size,\r\n                   epochs=3,\r\n                   steps_per_epoch=steps_per_epoch,\r\n                   callbacks=callbacks,\r\n                   verbose=1 if task_rank == 0 else 0)\r\n    \r\nunet.py:\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.layers import Reshape\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras import *\r\nimport tensorflow as tf\r\n\r\ndef build():\r\n    model = Sequential()\r\n    model.add(layers.Conv2D(14, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv1\", input_shape=(28, 28, 1)))\r\n    model.add(layers.MaxPool2D(pool_size=(2, 2), name=\"pool1\"))\r\n    model.add(layers.Conv2D(28, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv2_1\"))\r\n    model.add(layers.Conv2D(28, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv2_2\"))\r\n    model.add(layers.MaxPool2D(pool_size=(2, 2), name=\"pool2\"))\r\n    model.add(layers.Conv2D(56, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv3_1\"))\r\n    model.add(layers.Conv2D(56, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv3_2\"))\r\n    model.add(layers.MaxPool2D(pool_size=(2, 2), name=\"pool3\"))\r\n    model.add(layers.Conv2D(112, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv4_1\"))\r\n    model.add(layers.Conv2D(112, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv4_2\"))\r\n    model.add(layers.Dropout(0.5))\r\n    model.add(layers.MaxPool2D(pool_size=(2, 2), name=\"pool4\"))\r\n    model.add(layers.Conv2D(224, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv5_1\"))\r\n    model.add(layers.Conv2D(224, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv5_2\"))\r\n    model.add(layers.Dropout(0.5))\r\n    model.add(layers.Conv2DTranspose(112, 2, padding='same',activation='relu',kernel_initializer='he_normal',name='up6'))\r\n    model.add(layers.Conv2D(112, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv6_1\"))\r\n    model.add(layers.Conv2D(112, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv6_2\"))\r\n    model.add(layers.Conv2DTranspose(256,2 , padding='same',activation='relu',kernel_initializer='he_normal',name='up7'))\r\n    model.add(layers.Conv2D(56, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv7_1\"))\r\n    model.add(layers.Conv2D(56, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv7_2\"))\r\n    model.add(layers.Conv2DTranspose(28, 2, padding='same',activation='relu',kernel_initializer='he_normal', name='up8'))\r\n    model.add(layers.Conv2D(28, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv8_1\"))\r\n    model.add(layers.Conv2D(28, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv8_2\"))\r\n    model.add(layers.Conv2DTranspose(64,2 , padding='same',activation='relu',kernel_initializer='he_normal',name='up9'))\r\n    model.add(layers.Conv2D(14, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv9_1\"))\r\n    model.add(layers.Conv2D(14, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv9_2\"))\r\n    model.add(layers.Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv9_3\"))\r\n    model.add(layers.Conv2D(2, 1, activation='sigmoid', padding='same', kernel_initializer='he_normal',\r\n    name=\"conv10\"))\r\n    model.add(layers.Flatten())\r\n    model.add(layers.Dense(10, activation='softmax'))\r\n    model.add(Reshape((10,)))\r\n    return model", "comments": ["Is someone there?I badly need your help!!!!", "@Mullich123,\r\nOn running the given code snippet, I am facing an error stating `AttributeError: module 'unet' has no attribute 'build'`. \r\n\r\nIn order to reproduce the issue reported here, could you please provide a minimal code snippet and the dataset you are using. Thanks!", "Also, please update TensorFlow to the latest stable version **TF v2.4.1** with **CUDA 11.0**, **cuDNN 8.0** and check if you are facing the same error. Thanks!", "Thanks for your debugging!Well,I just can't understand the meaning of this error,could you tell me how the error happens?", "@Mullich123,\r\nWithout a reproducible code it would be difficult for us to determine the source of the error. \r\n\r\nCould you please provide a minimal code snippet, which we can run at our end and debug the issue. Thanks!", "I've been updated my issues and file below is trainset I use which has been preprocessed.\r\n[hand_trainset.zip](https://github.com/tensorflow/tensorflow/files/6316862/hand_trainset.zip)\r\n", "Hi @Mullich123, can you please make sure that your code is fully formatted? Copy and pasting unformatted code can lead to lots of errors and makes it more difficult for us to reproduce and debug the issue. Thanks!\r\n\r\nAlso, please try running your code with `tf.distribute.get_strategy()` instead of `MultiWorkerMirroredStrategy` and let me know what happens.", "Wonderful, it runs normally with tf.distribute.get_strategy()!!!!!!So why it is?\r\nMy code is completely from the official tutorial:Multi-worker training with Keras.\r\nI make it just by changing 'strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()'\r\nto 'strategy = tf.distribute.get_strategy()'. ", "`get_strategy()` is the default strategy. It implements the `tf.distribute.Strategy` interface but is a pass-through and provides no actual distribution. I was curious to see the results with this strategy because it helps to isolate where the issue is. If you can reformat your code so that it's properly indented, etc, I can try to reproduce the error on my end to help you debug.", "Well, I swear I do reformat my code and it looks normal with indentations in edit window.But it comes out like above.", "Can you put it in a colab notebook?", "Sorry,I ...... don\u2019t know how to use colab notebook.Here is my code:\r\n[unet_code.zip](https://github.com/tensorflow/tensorflow/files/6348057/unet_code.zip)\r\n", "I don't see any obvious issues with your code. Can you provide a small dataset so I can try to reproduce the issue?\r\n\r\nI would also suggest trying to upgrade to 2.4 as MultiWorkerMirroedStrategy moved out of experimental in 2.4 so you can use `tf.distribute.MultiWorkerMirroredStrategy` and you don't need to worry about setting the steps per epoch either.\r\n\r\nCan you also try running without the callbacks and let me know what happens?\r\n", "I've given you my dataset above,don't you see it?", "Yes, I see the dataset now. Thanks, I will try to reproduce this when I get a chance. In the meantime did you try the two suggestions in my previous comment?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48439\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48439\">No</a>\n"]}, {"number": 48438, "title": "Cannot build Tensorflow with Cuda", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5\r\n- Python version: 3.9\r\n- Installed using virtualenv? pip? conda?: venv + pip\r\n- Bazel version (if compiling from source):  3.7.2\r\n- GCC/Compiler version (if compiling from source): gcc version 10.2.1 20210110 (Debian 10.2.1-6)\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: Tesla T4\r\n\r\n**Describe the problem**\r\n\r\n```\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11.2\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8.1.1\r\n\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]:\r\n\r\n\r\nPlease specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /usr/include/linux/,/home/admin/cuda/include/\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 653, in <module>\r\n    main()\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 645, in main\r\n    for key, value in sorted(find_cuda_config().items()):\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 583, in find_cuda_config\r\n    result.update(_find_cuda_config(cuda_paths, cuda_version))\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 255, in _find_cuda_config\r\n    cuda_header_path, header_version = _find_header(base_paths, \"cuda.h\",\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 243, in _find_header\r\n    return _find_versioned_file(base_paths, _header_paths(), header_name,\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 233, in _find_versioned_file\r\n    actual_version = get_version(file)\r\n  File \"/home/admin/tensorflow/third_party/gpus/find_cuda_config.py\", line 250, in get_header_version\r\n    version = int(_get_header_version(path, \"CUDA_VERSION\"))\r\nValueError: invalid literal for int() with base 10: ''\r\nAsking for detailed CUDA configuration...\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\n(venv) admin@ip-172-30-0-223:~/tensorflow$ ./configure\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is /home/admin/venv/bin/python3]:\r\n\r\n\r\nFound possible Python library paths:\r\n  /home/admin/venv/lib/python3.9/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/admin/venv/lib/python3.9/site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nCould not find any cudnn.h, cudnn_version.h matching version '' in any subdirectory:\r\n        ''\r\n        'include'\r\n        'include/cuda'\r\n        'include/*-linux-gnu'\r\n        'extras/CUPTI/include'\r\n        'include/cuda/CUPTI'\r\n        'local/cuda/extras/CUPTI/include'\r\nof:\r\n        '/lib'\r\n        '/lib/x86_64-linux-gnu'\r\n        '/lib32'\r\n        '/usr'\r\n        '/usr/lib/x86_64-linux-gnu/libfakeroot'\r\n        '/usr/local/cuda'\r\n        '/usr/local/cuda/targets/x86_64-linux/lib'\r\n\r\nAsking for detailed CUDA configuration...\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]:\r\n```\r\n\r\nWhat is the correct way to specify CUDA + cuDNN versions and paths? Thank you in advance.\r\n", "comments": ["@l1x \r\n\r\nCan you please follow the below box with the version that you have chosen [11.2 and 8.1] and let us know [you may also refer to #42367:\r\n```Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10.0]: 11.0\r\n\r\nPlease specify the location where CUDA 10.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-11.0\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 8.0\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-11.0```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48438\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48438\">No</a>\n"]}, {"number": 48437, "title": "Update version numbers for TensorFlow 2.5.0-rc1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 5 -> 5\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.5.0-rc0\" found in source directory \n\"tensorflow/\". Good.\nWARNING: Below are potentially instances of lingering old version string \n\"2.5.0rc0\" in source directory \"tensorflow/\" that are not updated by this \nscript. Please check them manually!\ntensorflow/tools/pip_package/setup.py:104:2.5.0rc0\n```", "comments": []}, {"number": 48436, "title": "Converting training loop to compilable Keras model", "body": "I was recently going through this TF tutorial: https://www.tensorflow.org/tutorials/text/nmt_with_attention\r\n How do I convert the [training loop](https://www.tensorflow.org/tutorials/text/nmt_with_attention#training) in this tutorial to a Keras model which I can then compile using model.compile?\r\n\r\nIt is especially the variable input lengths and for loop that it is making this challenging ", "comments": ["@arunraja-hub \r\nKindly open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.\r\nThanks!", "@Saduf2019 I have asked this question on Stackoverflow (https://stackoverflow.com/questions/66629176/convert-training-loop-to-compilable-tf-model) a few weeks ago but there is no reply\r\nSo I posted here\r\nIf you can help that would be great", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 48435, "title": "new soc_id support for hexagon delegate", "body": "We are developing products based on the Qualcomm Snapdragon 865 and have been using the hexagon delegate to use the dsp on the SXR2130 variant with soc_id 356. Recently Qualcomm has migrated us to the QCS8250 variant of the 865, exact same processor, just differentiated by longer term support in the IOT group. This part has soc_id 481 which appears to not be recognized by the hexagon delegate. It looks like there needs to be an entry for 481 in the SocSkelTable that matches 356.\r\n\r\nHow does that happen? Does Qualcomm notify Google of new soc_id's and how does a new release happen? We are also working this through our Qualcomm contacts. If this is already known and a release is going to happen please provide any timetable information for a new release.\r\n\r\nThank you.\r\n\r\nJay", "comments": ["@karimnosseir could you take a look at this question?", "@jklloyd23 Happy to add it np.\r\nWill update you when new version is released.\r\n\r\n", "libhexagon_interface.so is updated with the soc 481 now enabled.\r\nCan you please try again by fetching from master branch.", "Closing please reopen if there are issues.\r\n\r\nThanks"]}, {"number": 48434, "title": "Bug fix #47954.", "body": "Fixes #47954: let `TextVectorization` process unbatched input (string literals) correctly.", "comments": ["@eli-osherovich  Can you please check @mattdangerw's comments and keep us posted ? Thanks!", "@gbaned Added unit tests.", "@eli-osherovich can you please check sanity build failures ?", "@rthadur \r\nThese were linting errors: \r\n```\r\nFound 3 non-allowlisted pylint errors:\r\ntensorflow/python/keras/layers/preprocessing/text_vectorization_test.py:318: [C0301(line-too-long), ] Line too long (81/80)\r\ntensorflow/python/keras/layers/preprocessing/text_vectorization_test.py:331: [C0301(line-too-long), ] Line too long (81/80)\r\ntensorflow/python/keras/layers/preprocessing/text_vectorization_test.py:344: [C0301(line-too-long), ] Line too long (81/80)\r\n```\r\n\r\nFixed.", "@gbaned  ping.", "Ubuntu sanity fails on a couple of completely unrelated lines:\r\n```\r\nFound 2 non-allowlisted pylint errors:\r\ntensorflow/compiler/tests/binary_ops_test.py:721: [E1130(invalid-unary-operand-type), BinaryOpsTest._testDivision] bad operand type for unary -: max\r\ntensorflow/compiler/tests/binary_ops_test.py:753: [E1130(invalid-unary-operand-type), BinaryOpsTest._testRemainder] bad operand type for unary -: max\r\n```", "@rthadur  ping\r\n", "@eli-osherovich no worries , will try to pull this again.", "It looks like there is a merge conflict. Can you rebase over latest master?", "@mattdangerw ,\r\n\r\nI do not see any conflict. The failed tests seem to be unrelated.... I would say, TF should check its build flow for:\r\n1) robustness issues (cannot download llvm ?)\r\n2) commits that break tests can somehow make their way into the code. And those tests start firing on future (unrelated) commits.\r\n", "Are those failures related to this PR?\r\n\r\nFor example, I do not see how the following error (MacOS failure) is related to it.\r\n\r\n```ModuleNotFoundError: No module named 'tensorflow.python.ops.gen_decode_proto_ops'```\r\n", "@rthadur , @mattdangerw \r\n\r\nDo we want to commit this PR or not?", "@eli-osherovich we do! Thanks for being patient. Changes to these lookup layers are often very challenging to land I have found.\r\n\r\nIt looks like we have real failures for this CL for the currently default compilation mode for TPUs. Nothing in this CL is wrong, but it is exposing a bug in TPU soft placement.\r\n\r\nI'm looking into this now. I think we can just disable the failing tests in the bad compilation mode, but we lack public symbols to even check that right now. Hopefully no more action needed on your part, can just patch in the changes that are needed when they are ready. Thanks again!"]}, {"number": 48433, "title": "Upgrade grpcio to 1.37.0", "body": "Since grpcio releases a new minor version every week, block upgrades\r\nto before the next major version.", "comments": ["See here for the grpcio frequency: https://github.com/grpc/grpc/releases"]}, {"number": 48432, "title": "can not converting my model .h5 to .tflite and giving me this error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["@Dhaval-Jotaneeya Please share simple stand alone code such that we can replicate the issue faced or if possible share a colab gist.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48432\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48432\">No</a>\n"]}, {"number": 48430, "title": "tf.nn.embedding_lookup gradient shape is no longer fully defined in 2.5.0rc0", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: `2.5.0rc0`\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\n\r\nIn TensorFlow 2.5.0rc0, the dense shape of the `tf.nn.embedding_lookup` gradient is no longer fully defined. The shape is `(None, None)` instead of the static shape of the embedding variable.\r\n\r\n The same code worked in previous TensorFlow versions.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe `shape` attribute of the sparse gradient should be the fully defined shape of the embedding variable.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass MyLayer(tf.keras.layers.Layer):\r\n    def build(self, input_shape):\r\n        self.embedding = tf.Variable(tf.random.uniform([50, 16]))\r\n\r\n    def call(self, x):\r\n        return tf.nn.embedding_lookup(self.embedding, x)\r\n\r\nlayer = MyLayer()\r\n\r\n@tf.function\r\ndef _run(x):\r\n    with tf.GradientTape() as tape:\r\n        y = layer(x)\r\n        loss = tf.math.reduce_sum(y)\r\n    gradients = tape.gradient(loss, layer.weights)\r\n    print(\"Gradient shape:\", gradients[0].shape)\r\n\r\n_run(tf.random.uniform([4, 16], minval=0, maxval=50, dtype=tf.int64))\r\n```\r\n\r\n**Other info / logs**\r\n\r\nOutput with 2.5.0rc0 (incorrect):\r\n\r\n```text\r\nGradient shape: (None, None)\r\n```\r\n\r\nOutput with 2.4.1 (correct):\r\n\r\n```text\r\nGradient shape: (50, 16)\r\n```", "comments": ["@jvishnuvardhan,\r\nI was able to reproduce the issue. Code works fine with TF v2.4.1, whereas with TF v2.5.0-rc0 and TF-nightly the output is `None`.\r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/6e31d91ae1ddf017ea1e9f1df9d90761/48430.ipynb). Thanks!", "The regression was introduced in this commit: https://github.com/tensorflow/tensorflow/commit/7ba58c1fe7ce110dfd91127ef3c9b629a5ad5e32", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48430\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48430\">No</a>\n", "Fixed in master, still needs a cherry-pick or a rollback in the release branch (probably the former).\r\n\r\nThank you for testing the release and the great report!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48430\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48430\">No</a>\n"]}, {"number": 48429, "title": "tf.data.experimental.enable_debug_mode() doesn't enable breakpoint", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Desktop\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v1.12.1-53831-ga8b6d5ff93a 2.5.0-rc0\r\n- Python version: Python 3.6.8 \r\n- CUDA/cuDNN version: CPU\r\n- GPU model and memory: CPU\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.data.experimental.enable_debug_mode()\r\ntf.config.run_functions_eagerly(True)\r\n\r\n\r\ndef func(x):\r\n    x = x + 1  # BREAKPOINT HERE\r\n    return x\r\n\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\ndataset = dataset.map(func)\r\n# dataset = dataset.map(lambda x: tf.py_function(func, [x], tf.int32))  # doesn't work either\r\nfor item in dataset:\r\n    print(item)\r\n\r\n```\r\n\r\nThe breakpoint is not hit. (using pycharm professional 2020.3 )\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect that the breakpoint is hit \r\n", "comments": ["@cgebbe \r\nI ran your code on tf 2.4 and nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/de6e076dfbc72fcc7862620fc634908e/untitled583.ipynb), i face a different error on 2.4.", "@jayxiaojieshi could you please help investigate this issue? thank you", "I have tested it with installing tf-nightly and adding break point to the source code in post-mortem debug mode with pdb.\r\nAnd the behavior can be re-produced. If we add break point within the function, it is not enabled, while if we add break point in other places (like add a simple print \"hello, world\" line), it is enabled.", "Also I have tried with deleting both lines \"tf.data.experimental.enable_debug_mode()\r\ntf.config.run_functions_eagerly(True)\" or only deleting the line \"tf.data.experimental.enable_debug_mode()\", the break point within the function is not enabled. \r\nDoes that suggest the behavior has nothing to do with tf.data debug mode?", "@jayxiaojieshi are you saying that the [following example](https://www.tensorflow.org/guide/effective_tf2#use_tfconfigexperimental_run_functions_eagerly_when_debugging) works for a tf.function but does not work for tf.data user-defined function (even when `tf.data.experimental.enable_debug_mode()`  is called)?", "Yeah, for tf.function, during the process of execution the break point within the function will be enabled only once, while without \"@tf.function\" it will not be enabled. ", "> Yeah, for tf.function, during the process of execution the break point within the function will be enabled only once, while without \"@tf.function\" it will not be enabled.\r\n\r\nFor above comments I am testing with post-mortem debug mode with pdb, with \"python -m pdb script.py\" and setting break points with \"break script.py:XXX\". \r\nActually for the [example](https://www.tensorflow.org/guide/effective_tf2#use_tfconfigexperimental_run_functions_eagerly_when_debugging) you mentioned, both tf.function or user-defined function work well. The break point will be enabled every time the function is called. \r\n\r\n\r\n", "@jayxiaojieshi could you please provide a code snippet that updates the example provided by the user to illustrate how can pdb be used together with `tf.data.experimental.enable_debug_mode()` to insert breakpoints into tf.data user-defined functions and also update the `tf.data.experimental.enable_debug_mode()` documentation with this example? thanks", "Sure, think the code below will work. \r\ncmd to run: python script.py\r\n\r\n```\r\nimport tensorflow as tf\r\nimport pdb\r\n\r\ntf.data.experimental.enable_debug_mode()\r\n\r\ndef func(x):\r\n    pdb.set_trace()\r\n    x = x + 1\r\n    return x\r\n\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\ndataset = dataset.map(func)\r\n\r\nfor item in dataset:\r\n    print(item)\r\n```", "It does not work for me. While first invocation of `func` (which occurs during tracing) triggers the breakpoint as expected, the subsequent invocation of `func` (which occurs during input pipeline execution) fails with `ValueError: signal only works in main thread`. Can you please confirm that you have verified that all four invocations of `func` that your example would exercise trigger the breakpoint?", "Interesting. It works well on my side. With first stop shows:\r\n```\r\n->  x = (ag__.ld(x)+1)\r\n```\r\n\r\nOther three shows:\r\n```\r\n-> x = x+1\r\n```", "Just tested different version of Python. Python 3.8 is required to see the desired behavior, while for Python 3.6, 3.7 there will be errors. ", "Thank you Jay. I was running the repro with an internal build of TensorFlow that uses Python 3.6, which explains the error.\r\n\r\nI was able to find a solution to the problem I was encountering. For the example to work with Python 3.6 or Python 3.7, one has to do `pdb.Pdb(nosigint=True).set_trace()` instead of `pdb.set_trace()`.\r\n\r\nSo to summarize, the following program illustrates how to add breakpoints to tf.data user-defined functions:\r\n\r\n```\r\nimport pdb\r\nimport tensorflow as tf\r\n\r\ntf.data.experimental.enable_debug_mode()\r\n\r\ndef func(x):\r\n    pdb.Pdb(nosigint=True).set_trace()\r\n    x = x + 1\r\n    return x\r\n\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\ndataset = dataset.map(func)\r\n\r\nfor item in dataset:\r\n    print(item)\r\n```\r\n\r\n@cgebbe please let us know if this addresses your question and if it does, feel free to close the issue. Thanks.", "@jsimsa and @jayxiaojieshi : Thank you a lot for the support! The last example is working for me in the sense that a terminal with PDB pops up upon execution. Haven't tested the other examples.\r\n\r\nOne big question: Is it somehow possible to trigger the Pycharm Debugger instead of PDB? The former one is arguably more convenient... ", "If PDB works but PyCharm does not, please contact the PyCharm team for help with this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48429\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48429\">No</a>\n", "One last question: Can you explain why the parameter nosigint=True is necessary? \r\n\r\nBased on the explanation from https://docs.python.org/3/library/pdb.html#pdb.Pdb, it seems to have something to do with Pressing Ctrl+C, so nothing necessary for the task at hand.\r\n\r\nHowever, without it, I get the following error:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: ValueError: signal only works in main thread\r\n....\r\nValueError: signal only works in main thread\r\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]\r\n```", "1) When running in debug mode, for technical reasons, tf.data executes user-defined functions using a background thread.\r\n2) The implementation of `pdb.set_trace()` uses `signal`, which as per the error message is not supported in the main thread. Either Python 3.8 removed the use of `signal` in `pdb` or added support for `signal` in background threads.", "In PyCharm, one can trigger a breakpoint in a function called by `Dataset.map()` by adding the following line within that function:\r\n\r\n```python\r\nimport pydevd; pydevd.settrace()\r\n```\r\n\r\nExample:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# haven't tested whether these are needed or not\r\ntf.data.experimental.enable_debug_mode()\r\ntf.config.run_functions_eagerly(True)\r\n\r\n\r\ndef func(x):\r\n    import pydevd; pydevd.settrace()\r\n    x = x + 1  # BREAKPOINT HERE\r\n    return x\r\n\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\ndataset = dataset.map(func)\r\nfor item in dataset:\r\n    print(item)\r\n```\r\n\r\nAlso note that you will **not** need to install `pydevd` separately, as it is bundled with PyCharm. Simply add that line and run debugging.\r\n\r\n(found in [this](https://stackoverflow.com/a/59346218/1214547) StackOverflow answer)"]}, {"number": 48428, "title": "model.fit() raises exception", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: cuda 10\r\n- GPU model and memory: 12GB\r\n\r\n**Describe the current behavior**\r\n\r\nmodel.fit() fails with following error\r\n```text\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/backprop.py in _num_elements(grad)\r\n    615   if isinstance(grad, ops.IndexedSlices):\r\n--> 616     return functools.reduce(operator.mul, grad.values._shape_tuple(), 1)  # pylint: disable=protected-access\r\n    617   raise ValueError(\"`grad` not a Tensor or IndexedSlices.\")\r\n\r\nTypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nSystemError                               Traceback (most recent call last)\r\n23 frames\r\n<ipython-input-3-3050b60a914a> in <module>()\r\n     87 \r\n     88 siamese_model.summary()\r\n---> 89 siamese_model.fit(data_gen, epochs=1)\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    501       # This is the first call of __call__, so we have to initialize.\r\n    502       initializer_map = object_identity.ObjectIdentityDictionary()\r\n--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n    504     finally:\r\n    505       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    406     self._concrete_stateful_fn = (\r\n    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 408             *args, **kwds))\r\n    409 \r\n    410     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1846     if self.input_signature:\r\n   1847       args, kwargs = None, None\r\n-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1849     return graph_function\r\n   1850 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n   2149         if graph_function is None:\r\n-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n   2151           self._function_cache.primary[cache_key] = graph_function\r\n   2152         return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2039             arg_names=arg_names,\r\n   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2041             capture_by_value=self._capture_by_value),\r\n   2042         self._function_attributes,\r\n   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    913                                           converted_func)\r\n    914 \r\n--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n    916 \r\n    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    357         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    360 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)\r\n     71     strategy = distribution_strategy_context.get_strategy()\r\n     72     outputs = strategy.experimental_run_v2(\r\n---> 73         per_replica_function, args=(model, x, y, sample_weights))\r\n     74     # Out of PerReplica outputs reduce or pick values to return.\r\n     75     all_outputs = dist_utils.unwrap_output_dict(\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)\r\n    758       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\r\n    759                                 convert_by_default=False)\r\n--> 760       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    761 \r\n    762   def reduce(self, reduce_op, value, axis):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)\r\n   1785       kwargs = {}\r\n   1786     with self._container_strategy().scope():\r\n-> 1787       return self._call_for_each_replica(fn, args, kwargs)\r\n   1788 \r\n   1789   def _call_for_each_replica(self, fn, args, kwargs):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)\r\n   2130         self._container_strategy(),\r\n   2131         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\r\n-> 2132       return fn(*args, **kwargs)\r\n   2133 \r\n   2134   def _reduce_to(self, reduce_op, value, destinations):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    290   def wrapper(*args, **kwargs):\r\n    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\r\n--> 292       return func(*args, **kwargs)\r\n    293 \r\n    294   if inspect.isfunction(func) or inspect.ismethod(func):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)\r\n    262       y,\r\n    263       sample_weights=sample_weights,\r\n--> 264       output_loss_metrics=model._output_loss_metrics)\r\n    265 \r\n    266   if reset_metrics:\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)\r\n    309           sample_weights=sample_weights,\r\n    310           training=True,\r\n--> 311           output_loss_metrics=output_loss_metrics))\r\n    312   if not isinstance(outs, list):\r\n    313     outs = [outs]\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)\r\n    266           model._backwards(tape, scaled_total_loss)\r\n    267         else:\r\n--> 268           grads = tape.gradient(scaled_total_loss, trainable_weights)\r\n    269           if isinstance(model.optimizer,\r\n    270                         loss_scale_optimizer.LossScaleOptimizer):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\r\n   1012         output_gradients=output_gradients,\r\n   1013         sources_raw=flat_sources_raw,\r\n-> 1014         unconnected_gradients=unconnected_gradients)\r\n   1015 \r\n   1016     if not self._persistent:\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\r\n     74       output_gradients,\r\n     75       sources_raw,\r\n---> 76       compat.as_str(unconnected_gradients.value))\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/backprop.py in _aggregate_grads(gradients)\r\n    596   assert gradients, \"No gradients to aggregate\"\r\n    597 \r\n--> 598   if len(gradients) == 1:\r\n    599     return gradients[0]\r\n    600   if all(isinstance(g, ops.Tensor) for g in gradients):\r\n\r\nSystemError: <built-in function len> returned a result with an error set\r\n```\r\n\r\n**Describe the expected behavior**\r\nmodel.fit() should work and training should proceed\r\n\r\n**Standalone code to reproduce the issue**\r\nCode can be found here:\r\nhttps://colab.research.google.com/drive/1Ab_brNm3JhKmMZhLNyl014mkeZhlatHn?usp=sharing\r\n\r\nReasoning behind code:\r\n+  Samples are document pairs which need to be classified into 4 categories. \r\n+ We train a Albert finetuned siamese model.\r\n+ Doc 1 is short while doc 2 is long. So we decided to split doc 2 into 10 (roughly equal sized chunks).\r\n+ After getting the hidden representation for each of the 10 parts of doc 2, we combine them using GlobalMaxPool1D over timesteps.\r\n+ Further we combine the representations of doc1 and doc2 and do the prediction using softmax activation.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@dhakrasp \r\nI ran the code on tf 2.4 and do not face any error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/240e2e9cf9c97e52479b8f1359f0890a/untitled.ipynb).\r\nCan you please upgrade your tf version and transformer version and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48428\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48428\">No</a>\n"]}, {"number": 48427, "title": "what's the api for get_or_create_global_step() in tf2.0", "body": "", "comments": ["@xiongma \r\nCould you please check [this](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/get_or_create_global_step) if it helps.Thanks"]}, {"number": 48426, "title": "some qunstions of nnapi delegate", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI don't quite understand the relationship between libtensorflowlite.so and libnnapi_delegate.so\uff0cif I only nnapi delegate, is it OK to just use libnnapi_delegate.so?\r\n\r\n", "comments": ["@ToBigboss \r\nYour question is not clear, are you facing any error, please share error logs in case you are facing any such issues, also please fill the template for us to analyse the issue faced.", "> @ToBigboss\r\n> Your question is not clear, are you facing any error, please share error logs in case you are facing any such issues, also please fill the template for us to analyse the issue faced.\r\n\r\nI want to build tflite-nnapi delegate lib with c/c++ api\uff0cI compiled it using the following command line\uff1a\r\nbazel build -c opt --config=android_arm64 //tensorflow/lite/delegates/nnapi:nnapi_delegate\r\nand libnnapi_delegate.so is compiled in bazal-bin\uff0cbut I don't see libtensorflowlite.so, so I compile  libtensorflowlite.so with the following command line: \r\nbazel build --cxxopt='--std=c++11' //tensorflow/lite:lib tensorflowlite.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a --verbose_ failures\r\nThere's only libtensorflowlite.so in the bazel-bin.\r\n\r\nmy qunstion is:\r\n1. if i want to use nnapi delegate, Is it OK to just use libnnapi_delegate.so? do I need library libtensorflowlite.so?\r\n2. can you provide sample code for using nnapi delegate with c/c++ api?", "Jared, can you please help with this issue.\r\n\r\nThanks", "Hi @ToBigboss . Can you add more details about your deployment environment? In particular:\r\n- What build system are you using for your Android app/deployment?\r\n- Are you already using TFLite via C++ in your app? If so, were you building from source? Or using prebuilt binaries?\r\n\r\nA few notes to your equestions:\r\n\r\n> if i want to use nnapi delegate, Is it OK to just use libnnapi_delegate.so? do I need library libtensorflowlite.so?\r\n\r\nThe NNAPI delegate is only useful with the core TFLite library, so you would need both. However, we haven't historically distributed the NNAPI delegate as a separate library on Android (for the prebuilt libraries), so we don't have the necessary build rule to produce a *standalone* NNAPI delegate `.so` that is fully self-contained (the libnnapi_delegate.so artifact you see isn't self-contained).\r\n\r\n> can you provide sample code for using nnapi delegate with c/c++ api?\r\n\r\nI'll file an internal feature request for this. We recently [published a sample](https://github.com/tensorflow/examples/tree/master/lite/examples/super_resolution/android) showing how to use the C API for the prebuilt libraries we publish for Android. If we extended that to show how to use the NNAPI delegate, would that be useful?", "> Hi @ToBigboss . Can you add more details about your deployment environment? In particular:\r\n> \r\n> * What build system are you using for your Android app/deployment?\r\n> * Are you already using TFLite via C++ in your app? If so, were you building from source? Or using prebuilt binaries?\r\n> \r\n> A few notes to your equestions:\r\n> \r\n> > if i want to use nnapi delegate, Is it OK to just use libnnapi_delegate.so? do I need library libtensorflowlite.so?\r\n> \r\n> The NNAPI delegate is only useful with the core TFLite library, so you would need both. However, we haven't historically distributed the NNAPI delegate as a separate library on Android (for the prebuilt libraries), so we don't have the necessary build rule to produce a _standalone_ NNAPI delegate `.so` that is fully self-contained (the libnnapi_delegate.so artifact you see isn't self-contained).\r\n> \r\n> > can you provide sample code for using nnapi delegate with c/c++ api?\r\n> \r\n> I'll file an internal feature request for this. We recently [published a sample](https://github.com/tensorflow/examples/tree/master/lite/examples/super_resolution/android) showing how to use the C API for the prebuilt libraries we publish for Android. If we extended that to show how to use the NNAPI delegate, would that be useful?\r\n\r\n_1.What build system are you using for your Android app/deployment?_\r\nphone\uff1axiaomi 11\r\nCPU\uff1asnapdragon 888\r\nandroid 11\r\nMIUI 12.0.16\r\n\r\n_2.Are you already using TFLite via C++ in your app? If so, were you building from source? Or using prebuilt binaries?_\r\nyes\uff0ci want to use TFLite via c++ api\uff0cand i build libtensorflow.so and libnnapi_delegate.so from source with bazel. I'm trying to use cmake to compile libtensorflow.so and libnnapi_delegate.so into libtflite_nnapi.so\uff0cbut the generated library is too large.", "Have you already been able to make use of the hexagon dsp ? I'm not quite sure if nnapi or the hexagon delegate is the way to go. For what I learned the hexagon 1.21 version does not yet support the snapdragon 888.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48426\">No</a>\n"]}, {"number": 48425, "title": "A large mount of data to load and fit to train  causing Anaconda kernel died and restart", "body": "I\u2018m doing a semantic segmentation task\uff0ci have thousands of pictures and labels. The kernel will died and restart when i use anaconda to train pictures that exceed 1600, but the kernel will not died when i train 1000 pictures.But the result is so bad and i want to train more than 10000 pictures.It hint the information when i use the Pycharm:\r\n\r\n2021-04-09 11:06:08.187912: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found\r\n2021-04-09 11:06:08.190073: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found\r\n2021-04-09 11:06:08.191626: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2021-04-09 11:06:08.192304: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2021-04-09 11:06:08.192482: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1496] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\r\nProcess finished with exit code -1073741819 (0xC0000005)\r\n\r\n\r\nI tried to solve this problem but failed.\r\nMy system information are:\r\nPython version: 3.8\r\nCUDA/cuDNN version: 10.1\u30017.6\r\nTensorFlow version : 2.4.1\r\nWindows10\r\n\r\nFallowing is my code of loading the datasets\uff1a\r\n\r\nimport cv2\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport os\r\n\r\npath = 'D:\\CDS\\cropped\\label\\_label_1_6.png'\r\ndef create_one_hot_labels(path):\r\n    NCLASSES = 6\r\n    img = cv2.imread(path)\r\n    labels = np.zeros((img.shape[0], img.shape[1], NCLASSES))\r\n    for i in range(img.shape[0]):\r\n        for j in range(img.shape[1]):\r\n            if (img[i, j, 0] == 0.) and (img[i, j, 1] == 0.) and (img[i, j, 2] == 0.):  #black \r\n                labels[i, j, 0] = 1  #to create one-hot-label making the third dimension have shape of six\r\n            elif (img[i, j, 0] == 0.) and (img[i, j, 1] == 0.) and (img[i, j, 2] == 255.): #red\r\n                labels[i, j, 1] = 1 \r\n            elif (img[i, j, 0] == 0.) and (img[i, j, 1] == 255.) and (img[i, j, 2] == 0.): #green\r\n                labels[i, j, 2] = 1\r\n            elif (img[i, j, 0] == 255.) and (img[i, j, 1] == 0.) and (img[i, j, 2] == 0.): #blue\r\n                labels[i, j, 3] = 1\r\n            elif (img[i, j, 0] == 255.) and (img[i, j, 1] == 255.) and (img[i, j, 2] == 0.): #cyan\r\n                labels[i, j, 4] = 1\r\n            else:\r\n                labels[i, j, 5] = 1\r\n    labels = np.reshape(labels, (-1, NCLASSES))\r\n    return labels\r\n\r\nfor i in range(1200):\r\n    one_hot_label = create_one_hot_labels(paths_label[i*16])\r\n    one_hot_label = np.array(one_hot_label).astype(np.float32)\r\n    labels.append(one_hot_label)      #train labels\r\n\r\nX_train = []\r\nfor j in range(1200):\r\n    img = cv2.imread(paths_image[j*16])\r\n    img = (np.array(img) / 255).astype(np.float32)\r\n    X_train.append(img)           #train data\r\n\r\nfor i in range(700):\r\n    one_hot_label = create_one_hot_labels(paths_label[i*37])\r\n    one_hot_label = np.array(one_hot_label).astype(np.float32)\r\n    val_labels.append(one_hot_label)\r\n\r\nX_val = []\r\nfor j in range(700):\r\n    img = cv2.imread(paths_image[j*37])\r\n    img = (np.array(img) / 255.).astype(np.float32)\r\n    X_val.append(img)        #validation data\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\nBATCH_SIZE = 20\r\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, labels))\r\n# val_ds = tf.data.Dataset.from_tensor_slices((X_val, val_labels))\r\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, val_labels))\r\ntrain_ds = train_ds.cache()\r\ntrain_ds = train_ds.apply(\r\n  tf.data.experimental.shuffle_and_repeat(buffer_size=200))\r\ntrain_ds = train_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\r\nval_ds = val_ds.batch(BATCH_SIZE)\r\n\r\nmiou = tf.keras.metrics.MeanIoU(num_classes=6)\r\nmodel.compile(optimizer=keras.optimizers.Adam(3e-3),\r\n              loss='categorical_crossentropy',\r\n              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=6)])\r\nimport tensorflow as tf\r\n\r\nEPOCHS = 500\r\nVAL_SUBSPLITS = 5\r\nVALIDATION_STEPS = 700//BATCH_SIZE//VAL_SUBSPLITS\r\nSTEPS_PER_EPOCH = 1200//BATCH_SIZE\r\n\r\nmodel_history = model.fit(train_ds, epochs=EPOCHS,\r\n                          steps_per_epoch=STEPS_PER_EPOCH,\r\n                          validation_steps=VALIDATION_STEPS,\r\n                          validation_data=val_ds,\r\n\r\n                          callbacks=[early_stopping, tensorboard_callback, csv_log])\r\n\r\nSo my problem is if the way of loading the dataset is wrong and how can i load more than 10000 pictures to train. Or if i have the problem in the version of the configuration.\r\n\r\nMany thanks\r\n", "comments": ["@Cuids \r\nCode shared is full of indentation errors, could you please share a colab gist with issue reported or simple stand alone indented code with all dependencies such that we can replicate the issue reported.\r\nThanks.\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]