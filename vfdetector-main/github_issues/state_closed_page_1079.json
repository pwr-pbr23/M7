[{"number": 20904, "title": "build_all_ios.sh error", "body": "```\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/Tensor:79:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/ThreadPool:58:\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/SimpleThreadPool.h:153:5: error: \r\n      thread-local storage is not supported for the current target\r\n    EIGEN_THREAD_LOCAL PerThread per_thread;\r\n    ^\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:15:35: note: \r\n      expanded from macro 'EIGEN_THREAD_LOCAL'\r\n#define EIGEN_THREAD_LOCAL static __thread\r\n                                  ^\r\n<command line>:3:18: note: expanded from here\r\n#define __thread thread_local\r\n                 ^\r\nIn file included from tensorflow/core/common_runtime/graph_runner.cc:21:\r\nIn file included from ./tensorflow/core/common_runtime/graph_runner.h:23:\r\nIn file included from ./tensorflow/core/common_runtime/device.h:35:\r\nIn file included from ./tensorflow/core/framework/allocator.h:23:\r\nIn file included from ./tensorflow/core/framework/numeric_types.h:20:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/Tensor:79:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/ThreadPool:59:\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:326:5: error: \r\n      thread-local storage is not supported for the current target\r\n    EIGEN_THREAD_LOCAL PerThread per_thread_;\r\n    ^\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:15:35: note: \r\n      expanded from macro 'EIGEN_THREAD_LOCAL'\r\n#define EIGEN_THREAD_LOCAL static __thread\r\n                                  ^\r\n<command line>:3:18: note: expanded from here\r\n#define __thread thread_local\r\n                 ^\r\nIn file included from tensorflow/core/common_runtime/local_device.cc:18:\r\nIn file included from ./tensorflow/core/common_runtime/local_device.h:19:\r\nIn file included from ./tensorflow/core/common_runtime/device.h:35:\r\nIn file included from ./tensorflow/core/framework/allocator.h:23:\r\nIn file included from ./tensorflow/core/framework/numeric_types.h:20:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/Tensor:79:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/ThreadPool:58:\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/SimpleThreadPool.h:153:5: error: \r\n      thread-local storage is not supported for the current target\r\n    EIGEN_THREAD_LOCAL PerThread per_thread;\r\n    ^\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:15:35: note: \r\n      expanded from macro 'EIGEN_THREAD_LOCAL'\r\n#define EIGEN_THREAD_LOCAL static __thread\r\n                                  ^\r\n<command line>:3:18: note: expanded from here\r\n#define __thread thread_local\r\n                 ^\r\nIn file included from tensorflow/core/common_runtime/local_device.cc:18:\r\nIn file included from ./tensorflow/core/common_runtime/local_device.h:19:\r\nIn file included from ./tensorflow/core/common_runtime/device.h:35:\r\nIn file included from ./tensorflow/core/framework/allocator.h:23:\r\nIn file included from ./tensorflow/core/framework/numeric_types.h:20:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/Tensor:79:\r\nIn file included from /Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/ThreadPool:59:\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:326:5: error: \r\n      thread-local storage is not supported for the current target\r\n    EIGEN_THREAD_LOCAL PerThread per_thread_;\r\n    ^\r\n/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:15:35: note: \r\n      expanded from macro 'EIGEN_THREAD_LOCAL'\r\n#define EIGEN_THREAD_LOCAL static __thread\r\n                                  ^\r\n<command line>:3:18: note: expanded from here\r\n#define __thread thread_local\r\n                 ^\r\ngcc --std=c++11 -DIS_SLIM_BUILD -fno-exceptions -DNDEBUG -O3 -mios-simulator-version-min=9.0 -arch i386 -mno-sse -fembed-bitcode -D__thread=thread_local -DUSE_GEMM_FOR_CONV -Wno-c++11-narrowing -DTF_LEAN_BINARY -D__ANDROID_TYPES_SLIM__ -fno-exceptions -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator11.3.sdk -MT /Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_I386/tensorflow/core/common_runtime/memory_types.o -MMD -MP -MF /Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/dep/ios_I386//tensorflow/core/common_runtime/memory_types.Td -I. -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/ -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/eigen -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/gemmlowp -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/fft2d -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/downloads/double_conversion -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/proto/ -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/proto_text/ -I/Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include -I/usr/local/include -c tensorflow/core/common_runtime/memory_types.cc -o /Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_I386/tensorflow/core/common_runtime/memory_types.o\r\n2 errors generated.\r\nmake: *** [/Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_I386/tensorflow/core/common_runtime/local_device.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n2 errors generated.\r\nmake: *** [/Users/viatom/tensorflow/tensorflow/contrib/makefile/gen/obj/ios_I386/tensorflow/core/common_runtime/graph_runner.o] Error 1\r\n+ '[' 2 -ne 0 ']'\r\n+ echo 'i386 compilation failed.'\r\ni386 compilation failed.\r\n+ exit 1\r\n\r\n```\r\nI tried running `tensorflow/contrib/makefile/build_all_ios.sh` and then this issue occurred. I searched for a lot of similar issue, but not fixed the issue. \r\nSo, i need help.", "comments": ["-r 1.9\r\n-mac 10.13.4 (17E199)", "I recently fixed this for TFLite: https://github.com/tensorflow/tensorflow/issues/20900 the issue might be similar.", "@shashishekhar #20900 It helped me fixed this issue, thanks.", "@ChaosYang, could you submit a PR, please! That would be awesome.", "I am having the same issue.  and I am using tensorflow r1.10 branch and xcode 9.4.1.  https://github.com/tensorflow/tensorflow/issues/20900 does not help since flatbuffers is not dowloaded anymore .", "Nagging Assignee @aselle: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 20903, "title": "Preinstalled tensorflow on ubuntu image ", "body": "Hi \r\nIs There any Ubuntu image that comes with Tensorflow preinstalled,it will be more easier to start learning Tensorflow more quickly for beginners \r\nI actually I have troubles with installing Tensorflow-gpu\r\n\r\nThanks ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "The dockerhub tensorflow image can be used to try tensorflow:\r\n\r\nhttps://hub.docker.com/r/tensorflow/tensorflow/", "Thanks @wdirons! This question has been answered, so I'm closing the issue. "]}, {"number": 20902, "title": "[tf.keras] Add custom scalar tensorboard summary for metrics", "body": "It can be very useful to view training and validation loss in a single chart inside tensorboard.\r\n\r\nCurrently this is only easily possible by using two different summary writers that write to different tags: https://stackoverflow.com/questions/47877475/keras-tensorboard-plot-train-and-validation-scalars-in-a-same-figure/48393723\r\n\r\nThis PR extends the keras callback to display trainings and validation metrics in a single chart using the [custom scalar plugin](https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/custom_scalar):\r\n\r\n![tb_custom](https://user-images.githubusercontent.com/13285808/42854540-9758f9e2-8a3c-11e8-963b-813c2a33291b.png)\r\n\r\nNote: https://github.com/tensorflow/tensorboard/pull/1294 is required to properly display multiple runs.", "comments": ["4921064dd535d84aa031f8116e583b151dd46e97 introduced batch-level metrics.\r\n\r\nThe latest commit modifies this PR to work with the latest master:\r\n![localhost_6006_ 1](https://user-images.githubusercontent.com/13285808/43274921-c511300a-9100-11e8-900b-4a158a93f2bc.png)\r\n", "@lgeiger Could you please add a unit test?", "> Could you please add a unit test?\r\n\r\nI'll take a look at it next week.", "@lgeiger any updates?", "Sorry for the long wait, I'll try to revisit this PR soon to support tf@2.0", "In TF@2.0, Keras uses two TensorBoard writers for eval and train so this PR isn't needed anymore. Closing."]}, {"number": 20901, "title": "\"Getting Started with TensorFlow\" tutorial is missing input_shape argument", "body": "In the tutorial \"_Getting Started with TensorFlow_\" there is a code segment for image classification, using the MNIST dataset. The segment includes a Keras Sequential model, which is missing the `input_shape` argument in the first layer. \r\n\r\nIn particular, I propose changing: \r\n- `tf.keras.layers.Flatten()` to `tf.keras.layers.Flatten(input_shape = (28, 28))`.\r\n\r\n\"_Getting Started with TensorFlow_\" link: https://www.tensorflow.org/tutorials/", "comments": ["Thanks. Seems to run ok without it: https://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/get_started/_index.ipynb", "Thanks, the issue emanates from the version of TensorFlow. I tested two different versions, 1.5.1 and 1.9.0. \r\n\r\n- In 1.9.0 the code, as written in the tutorial, runs without error. \r\n\r\n- In 1.5.1, the missing `input_shape` argument error is returned after executing the segment `model=`...", "So I think everything's good then?\r\nThis is a new feature in 1.9. The docs reflect the latest stable release.\r\n\r\n"]}, {"number": 20900, "title": "[Tensorflow lite] iOS build for any archs fails : error: no matching member function for call to 'Verify'", "body": "-----------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.3\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 2.7 / 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: 4.2.1\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.2)\r\nTarget: x86_64-apple-darwin17.4.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: tensorflow/contrib/lite/build_ios_universal_lib.sh\r\n\r\n### Describe the problem\r\niOS build for any architecture will fail.\r\nI checked 'verifier' exist and defined in tensorflow/contrib/lite/tools/ and Verify is in there.\r\nIf i am right I guess it is related to the feature 'template deduction' which is c++11 or gcc version \r\nI am not sure if this failure comes from the bug of the code or my environmental setups but I think I throughly read the build documentation and followed the guidelines.\r\n\r\nHere is my practice.\r\n\r\n1. I installed xcode from the app store, (success)\r\n - run xcode-select --install\r\n2. install homebrew (success)\r\n3. brew install automake libtool (success)\r\n4. git cloned tensorflow, (no issue)\r\n5. download_install_dependencies (success)\r\n\r\n\r\n### Source code / logs\r\n...\r\nclang++ -fPIC -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -pthread  -std=c++11 -fPIC -O3 -DNDEBUG -miphoneos-version-min=9.0 -DGEMMLOWP_ALLOW\r\n_SLOW_SCALAR_FALLBACK -DTFLITE_USE_APPLE_ACCELERATE_FOR_CONV -fembed-bitcode -Wno-c++11-narrowing -mno-thumb -fno-exceptions -isysroot \r\n/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS11.4.sdk -arch arm64 -O3 -I. -I/Users/con\r\ntinuumai/tensorflow/tensorflow/contrib/lite/../../../ -I/Users/june/tensorflow/tensorflow/contrib/lite/downloads/ -I/Users/conti\r\nnuumai/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/Users/june/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I\r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/Users/june/tensorflow/tensorflow/contrib/lite/down\r\nloads/farmhash/src -I/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/Users/june/tensorflo\r\nw/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/kernels/lsh_projection.cc -o /Users/june/tens\r\norflow/tensorflow/contrib/lite/gen/obj/ios_arm64/tensorflow/contrib/lite/kernels/lsh_projection.o                                      clang: warning: argument unused during compilation: '-mno-thumb' [-Wunused-command-line-argument]                                      5 warnings generated.                                                                                                                  In file ```\r\n**included from tensorflow/contrib/lite/interpreter.cc:33:                                                                       \r\n**./tensorflow/contrib/lite/schema/schema_generated.h:1730:21: error: no matching member function for call to 'Verify'                   \r\n           verifier.Verify(min()) &&                                                                                                   \r\n           ~~~~~~~~~^~~~~~** **                                                                                                             \r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1775:29: note: candidate \r\n      template ignored: couldn't infer template argument 'T'                                                                           \r\n  template<typename T> bool Verify(uoffset_t elem) const {                                                                             \r\n                            ^                                                                                                          /Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1784:29: note: candidate \r\n      function template not viable: requires 2 arguments, but 1 was provided                                                           \r\n  template<typename T> bool Verify(const uint8_t *base, voffset_t elem_off)\r\n                            ^\r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1763:8: note: candidate\r\n      function not viable: requires 2 arguments, but 1 was provided\r\n  bool Verify(uoffset_t elem, size_t elem_len) const {\r\n       ^\r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1780:8: note: candidate\r\n      function not viable: requires 3 arguments, but 1 was provided\r\n  bool Verify(const uint8_t *base, voffset_t elem_off, size_t elem_len) const {\r\n       ^\r\nIn file included from tensorflow/contrib/lite/interpreter.cc:33:\r\n./tensorflow/contrib/lite/schema/schema_generated.h:1732:21: error: no matching member function for call to 'Verify'\r\n           verifier.Verify(max()) &&\r\n           ~~~~~~~~~^~~~~~\r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1775:29: note: candidate\r\n      template ignored: couldn't infer template argument 'T'\r\n  template<typename T> bool Verify(uoffset_t elem) const {\r\n                            ^\r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1784:29: note: candidate\r\n      function template not viable: requires 2 arguments, but 1 was provided\r\n  template<typename T> bool Verify(const uint8_t *base, voffset_t elem_off)\r\n                            ^\r\n/Users/june/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include/flatbuffers/flatbuffers.h:1763:8: note: candidate\r\n      function not viable: requires 2 arguments, but 1 was provided\r\n\r\n```\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/2203945/log.txt)\r\n", "comments": ["I had the same problem\uff01\uff01\uff01\uff01\uff01", "I have the same problem.!", "I tried replacing the downloaded version of flatbuffers with an older one and it worked (1.8.0)", "Are flatbuffers the only one needed to be replaced? I have tried doing this, but it did not work.", "Replacing flatbuffers makes tf-lite compile on a system with Xcode 9.2 and OSX 10.13.3 for me.\r\n\r\nI am stuck at a later point with my current system (Xcode 9.4.1 / OSX 10.13.6). \r\n\r\n", "I find that it will still download the latest version of flatbuffers if I simply checkout to r1.8 branch of the tensorflow repository. To download the 1.8 version of flatbuffers, I should go to [https://github.com/google/flatbuffers/tree/v1.8.0](the flatbuffers repository). Then, I can build without error. Thanks @davlhd .", "@wiseosho : Thank you for the report, looks like a lot of people are hitting this, I am looking into it. @davlhd what other error are you seeing after replacing flatbuffers?", "@shashishekhar \r\nI get `error: invalid argument '--std=c++11' not allowed with 'C'`\r\n because of `CCFLAGS := ${CXXFLAGS}` inside _tensorflow/contrib/lite/Makefile_. I need to change it to \r\n```\r\nCCFLAGS := ${CXXFLAGS} -O3 -DNDEBUG\r\nCXXFLAGS += --std=c++11 -O3 -DNDEBUG\r\n```\r\nto make sure the c++11 argument is only put into CCFLAGS. After that I got \r\n\r\n```\r\ntensorflow/contrib/lite/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:326:5: error: thread-local storage is not supported for the current\r\n      target\r\n    EIGEN_THREAD_LOCAL PerThread per_thread_;\r\n    ^\r\ntensorflow/contrib/lite/downloads/eigen/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:15:35: note: expanded from macro 'EIGEN_THREAD_LOCAL'\r\n#define EIGEN_THREAD_LOCAL static __thread\r\n```\r\nand thats where I left it for the moment.\r\n\r\nBut all of this could be due to some setup error on my side.", "@davlhd Thankyou! I changed the flatbuffers version to v1.8.0 and it works.\r\nIn my case, the error @davlhd mentioned pop up for x86_64 architecture( i386 I didn't try) . If I build only for arm64 architecture (which I need), I can build with no more issues.\r\n\r\nHere is my modification.\r\n\r\n1. change download_dependencies.sh ( line 38, FLATBUFFERS_URL=.../master.zip\" -> .../v1.8.0.zip\")\r\n2. comment out and get rid of any other architectures except arm64 architecture.\r\n", "Looks like this is a problem with Xcode 9.3, it make take a few days to fix it. I will suggest to use Xcode 9.2 for now, while we fix it.", "@shashishekhar Do you mean Xcode 9.3 or later, including Xcode 9.4.1 are all affected by this issue?\r\n", "I have a fix, currently under review should be merged by end of tomorrow.\r\nessentially: change MIN_SDK_VERSION := 10.0 which has C++ thread_local support and pass \r\n-D__thread=thread_local \r\n", "Change from \r\n```bash\r\nFLATBUFFERS_URL=\"https://github.com/google/flatbuffers/archive/master.zip\"\r\nto \r\nFLATBUFFERS_URL=\"https://github.com/google/flatbuffers/archive/v1.8.0.zip\"\r\n```\r\nindownload_dependencies.sh", "I think we should also add the concrete revisions for each dependency in the `download_dependecies.sh` rather then depend on `master` for example. Otherwise this issue can happen in the future when any \"dependency\" updates its `master`.\r\n\r\nFor example, I also see that `NEON_2_SSE_URL` has also the dependency on `master` rather than on the concrete revision.", "I git pulled the repository and checked all architectures build. \r\nThanks for @shashishekhar, @davlhd and others for the support.\r\n ", "Patch: https://github.com/tensorflow/tensorflow/commit/474b40bc7cb33d25f9bdc187d021e94a807bf1bd is merged, closing.", "I have the Same issue \u3002\u3002\u3002\u3002 I have user master branch", "Against tensorflow v1.10.0: flatbuffers 1.9.0 also worked for me. 1.10.0 did not work."]}, {"number": 20899, "title": "load_op_library fails with undefined symbol in 1.7, but not 1.1", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux SLES 12.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 3.5.4 (as Anaconda environment)\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5 (for custom Op)\r\n- **CUDA/cuDNN version**: 7.1.2\r\n- **GPU model and memory**: Nvidia Tesla M40 11443MiB\r\n- **Exact command to reproduce**: `tf.load_op_library('zero_out.so')`\r\n\r\n### Describe the problem\r\nWhen I follow the instructions on the [adding a new op page](https://www.tensorflow.org/extend/adding_an_op#top_of_page), loading the example `zero_out.so` fails with `tensorflow.python.framework.errors_impl.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv` in tensorflow 1.7. However, the same procedure succeeds with tensorflow 1.1, python 3.5.2.   \r\nI have seen similar issues (e.g. #9137), however adding `-D_GLIBCXX_USE_CXX11_ABI=0` doesn't help (and probably shouldn't, as GCC < 5). The closest issue is seemingly #17619 since the problem seems to be with the linker being unable to find the correct library at run time.\r\n\r\n### Source code / logs\r\nZero-out source code is available on the [adding a new op page](https://www.tensorflow.org/extend/adding_an_op#top_of_page).\r\n\r\n**Full Traceback**\r\n\r\n```sh\r\n>>> import tensorflow as tf\r\n>>> tf.load_op_library('zero_out.so')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/anaconda3/envs/TF17/lib/python3.5/site-packages/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\r\n  File \"/usr/local/anaconda3/envs/TF17/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv\r\n```\r\n", "comments": ["Moving to a different system with a single conda environment solved the issue - so the issue is unrelated to tensorflow and is perhaps an issue with having multiple tensorflow versions in the same machine.  Sorry for the spam. Closing issue.\r\n\r\nI still haven't figured out how to point tensorflow at the right libraries in the system with multiple environments, but if I figure out a solution, I will post it here.", "**update**: This appears not due to having multiple environments, but that tensorflow binaries that I installed via conda were built with GCC 5.x using the C++11 ABI\r\n\r\nUser defined op libraries (in this case, zero_out.so) are linked against `/path/to/tf/libtensorflow_framework.so`. If I check the symbol table of that library in the failing conda env (tf17) for `_ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv`, nothing shows up. However, if I remove the \u201cEv: at the end, I get this:\r\n\r\n```sh\r\niriley@iriley_cpu> nm libtensorflow_framework.so | grep _ZN10tensorflow8internal21CheckOpMessageBuilder9NewString\r\n000000000055e75c T _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev\r\n```\r\n\r\nNote the `cxx11` towards the end of the symbol name. If you have GCC 5.x, setting -`D_GLIBCXX_USE_CXX11_ABI=1` should fix the problem.", "Per ContinuumIO/anaconda-issues/issues/9826, all anaconda packages are built with the C++11 ABI. A solution that worked for me (again, per the mentioned issue) is to use the anaconda `gxx_linux-64` compiler to compile the op.", "I faced the same while using the conda distribution. Installing tensorflow from pip solved the problem. \r\n\r\nThat is probably built with gcc4.8.", "you just need to add `*.so` compiled file generated by model implementation.\r\nas follows add this line before session and import meta graph.\r\n`tf.load_op_library('<compiled_filename>.so')`\r\nthis function add a new op in tensorflow runtime.\r\nfor example. i compiled a model that contains a `RoiPooling` layer and generated `roi_pooling.so` file. so that i added this line to my code\r\n`tf.load_op_library('op/roi_pooling.so')`\r\n\r\nand finally it works : )"]}, {"number": 20898, "title": "Print errors during bazel tests.", "body": "Adding the test_output flag to print for errors.", "comments": []}, {"number": 20897, "title": "R1.10", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 20896, "title": "Added simple_load module", "body": "- Added `simple_load` module to complement `simple_save`. This is useful for testing your generated model artifact in python as well as reloading a previously saved model for batch prediction at a later date.\r\n- Updated `saved_model` documentation to include references to both `simple_save` and `simple_load`. Previously this was not mentioned at all.", "comments": ["Thanks! Please also run the test suite and update the API goldens.", "- Updated golden API. It could use some documentation to mention that you need to configure your build with python 2 to test/update the golden API.\r\n- Ran tests with `bazel test --config=opt //tensorflow/python/saved_model/...` and got successful output:\r\n```\r\nINFO: Build completed successfully, 1 total action\r\n//tensorflow/python/saved_model:loader_test                     (cached) PASSED in 2.2s\r\n//tensorflow/python/saved_model:saved_model_test                (cached) PASSED in 3.9s\r\n//tensorflow/python/saved_model:signature_def_utils_test        (cached) PASSED in 1.4s\r\n//tensorflow/python/saved_model:simple_load_test                (cached) PASSED in 2.0s\r\n//tensorflow/python/saved_model:simple_save_test                (cached) PASSED in 1.6s\r\n//tensorflow/python/saved_model:utils_test                      (cached) PASSED in 1.4s\r\n```\r\n", "(API is addition is good)", "@k-w-w , can you comment on whether this is still necessary given recent changes you have made?", "I think this would be a good addition as the `simple_save` complement. The `SavedModelLoader` still requires the user to learn about the inner workings of a SavedModel (Metagraph tags, and SignatureDef keys), and `SavedModelEstimator` loads the SavedModel with the estimator framework (which the user may not be familiar with).\r\n\r\n`simple_save` and `simple_load` covers the use case for building a graph and loading it back in using Python with minimal overhead.", "Looks like you'll need to rerun the API goldens as well, @jonathanlunt . After that + the lint fixes above, we can pull and merge-- many thanks", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "I was going to make updates since I have time again now, but it seems like the SavedModel serialization is changing for the 2.0 release. I am going to close this because it will be irrelevant if the `simple_save` API goes away in future version.\r\n\r\nRegarding serialization, I have an ask (@drpngx and others)... I hope core contributors are thinking very carefully about end-users when it comes to the updated serialization API. I am not looking forward to interfacing with the `saved_model.export` code in the future. It exposes additional internal objects/functions to the user and it seems primarily motivated by the Keras/Eager APIs. None of these things are useful to users like me.\r\n", "CC @allenlavoie \r\n@jonathanlunt : Could you provide some specifics on what about the future serialization APIs is problematic? (Perhaps in a discussion on developers@tensorflow.org instead of the comments on this pull request :))"]}, {"number": 20895, "title": "NCCL 2.x Release notes section updated.", "body": "", "comments": ["@case540 sorry, didn't notice that it was for 1.10 branch. I'll let you handle this one."]}, {"number": 20894, "title": "Update bazel version in docs", "body": "Update bazel version for mac/linux install_sources.md.", "comments": ["It will get propagated when you merge it back ;)"]}, {"number": 20893, "title": "Link lib and header where ./configure expects", "body": "", "comments": ["XLA had one test flake due to OOM. Going to just merge this anyways", "will someone help to cherry-pick this back to master branch? tks.", "@nbcsm yes this will make it's way back to master. Tagging @case540 who will do the merge."]}, {"number": 20892, "title": "Upgrade Bazel to 0.14.1", "body": "PiperOrigin-RevId: 204763605", "comments": []}, {"number": 20891, "title": "Feature Request: tf.Session().as_default() should have a flag to keep the session alive", "body": "### Describe the problem\r\nI find a scenario in which keeping a session alive (even after closing the context manager) is useful. Let's say that I have a method `train(steps)` that will train a model for the next `steps` iterations. Given the current API r1.9, I could think of no other way than to save and restore the session between method calls. That would incur a huge overhead indeed! \r\n\r\nI could think of two possible ways out:\r\n- providing an API to set a default session at will without automatically closing the session. It could come in a form of a context manager.\r\n- adding a flag to the `.as_default()` method in `tf.Session()` to keep it alive after the context manager is closed.\r\n\r\n### Source code / logs\r\nThe following code shows the hypothetical scenario.\r\n\r\n```\r\nmodel = # some model\r\nmodel.train(100) # train for 100 iterations\r\n# default session should be None here (this rules out the usage of InteractiveSession)\r\nmodel.train(100) # train for another 100 iterations\r\n```\r\n\r\nThe following code shows the two possible solutions:\r\n\r\n```\r\n# a new context mananger to set default session\r\nsess = tf.Session()\r\nwith tf.session_as_default(sess):\r\n    ...\r\nsess.close()\r\n\r\n# adding a flag to the as_default method\r\nsess = tf.Session()\r\nwith sess.as_default(keep_session=True):\r\n    ...\r\nwith sess.as_default():\r\n    ...\r\n# session closed\r\n```", "comments": ["`tf.Session.as_default()` doesn't close the session when you exit the context:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nc = tf.constant(42)\r\nsess = tf.Session()\r\n\r\nwith sess.as_default():\r\n  assert c.eval() == 42\r\n\r\nassert tf.get_default_session() is None\r\n\r\nwith sess.as_default():\r\n  assert c.eval() == 42\r\n\r\nsess.close()\r\n```\r\n\r\nI don't think we need a flag here, because you can always use an explicit `sess.close()`. If you really need the second context to close on (e.g.) an exception, you can use the following:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nc = tf.constant(42)\r\nsess = tf.Session()\r\n\r\nwith sess.as_default():\r\n  assert c.eval() == 42\r\n\r\nassert tf.get_default_session() is None\r\n\r\nwith sess:  # NOTE: Using a session with no `.as_default()` as a context will auto-close on exit.\r\n  assert c.eval() == 42\r\n```", "@mrry  That was a fool of me. A huge misconception I had."]}, {"number": 20890, "title": "Version cc generated only once", "body": "This is a fix of an issue with tensforflow version cc", "comments": ["Closing based on discussion in #21035."]}, {"number": 20889, "title": "Documentation update", "body": "Looks like it was copy-pasted from moutput_arrays", "comments": []}, {"number": 20888, "title": "Use the latest release version instead of master", "body": "Master branch is subject to change, so to make build predictable it's better to lock dependencies on the particular version\r\n", "comments": ["Nagging Reviewer @andrehentz: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 65 days with no activity and the `awaiting review` label has been applied.", "@slevental Please rebase to resolve conflicts.\r\n"]}, {"number": 20887, "title": "tf_nightly fails with from tensorflow.python.keras._impl.keras.backend import abs \"cannot import name 'abs'\"", "body": "```\r\npip install tf_nightly\r\npython\r\nimport tensorflow\r\n\r\nPython 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) \r\n[GCC 7.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 81, in <module>\r\n    from tensorflow.python import keras\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/__init__.py\", line 24, in <module>\r\n    from tensorflow.python.keras import activations\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/activations/__init__.py\", line 22, in <module>\r\n    from tensorflow.python.keras._impl.keras.activations import elu\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/__init__.py\", line 21, in <module>\r\n    from tensorflow.python.keras._impl.keras import activations\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/activations.py\", line 23, in <module>\r\n    from tensorflow.python.keras._impl.keras import backend as K\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\", line 38, in <module>\r\n    from tensorflow.python.layers import base as tf_base_layers\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 25, in <module>\r\n    from tensorflow.python.keras.engine import base_layer\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/__init__.py\", line 23, in <module>\r\n    from tensorflow.python.keras.engine.base_layer import InputSpec\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 33, in <module>\r\n    from tensorflow.python.keras import backend\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend/__init__.py\", line 22, in <module>\r\n    from tensorflow.python.keras._impl.keras.backend import abs\r\nImportError: cannot import name 'abs'\r\n>>> ```", "comments": ["There was another issue #20778 which looks similar, but is on Windows 10.", "This looks similar to https://github.com/tensorflow/tensorflow/issues/20778\r\n\r\nwhich is caused by old files from the prior install not being removed. Maybe try uninstalling tensorflow, manually removing the tensorflow directory under site-packages and reinstalling tensorflow.", "Indeed, trying in fresh environment works."]}, {"number": 20886, "title": "Freezing + fake quantization of graph", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source (v1.8) / binary (v1.9)\r\n- **TensorFlow version (use command below)**:  v1.8.0-0-g93bc2e2072 1.8.0 AND v1.9.0-0-g25c197e023 1.9.0\r\n- **Python version**: 3.6 \r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**: (result of gcc -v) gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9) \r\n- **CUDA/cuDNN version**: Not used\r\n- **GPU model and memory**: Not used\r\n- **Exact command to reproduce**: Code given below\r\n\r\n### Describe the problem\r\nProblem described [here](https://stackoverflow.com/questions/51327204/freezing-quantizing-fake-quantized-graph), but didn't have any luck; essentially, I cannot freeze a graph which has been fake quantized using [tf.contrib.quantize.create_training_graph()](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/quantize/python/quantize_graph.py). I have a sample below (there may be a better way to add a freezing operation at the end of the [graph quantization test](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/quantize/python/quantize_graph.py) script).\r\n\r\nThe code shown spits out the following error (or variants dependent on architecture):\r\n\r\n> ValueError: Input 0 of node import/weights_quant/AssignMinLast was passed float from import/weights_quant/min:0 incompatible with expected float_ref\r\n\r\nI may be doing something wrong - this arises regardless of which order I apply the creation of training/eval graphs and which of the 3 methods I use for freezing the graph. I also tried the fixes [here](https://github.com/davidsandberg/facenet/issues/161) to no avail.\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef conv_simple(_input):\r\n    _input_r = tf.reshape(_input, shape=[-1, 28, 28, 1])\r\n    _conv1 = tf.nn.conv2d(_input_r, tf.Variable(tf.random_normal([3, 3, 1, 64], stddev=0.1)), strides=[1, 1, 1, 1],\r\n                          padding='SAME')\r\n    _conv2 = tf.nn.bias_add(_conv1, tf.Variable(tf.random_normal([64], stddev=0.1)))\r\n    _conv3 = tf.nn.relu(_conv2)\r\n    _pool = tf.nn.max_pool(_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n    _dense = tf.reshape(_pool, [-1, 14 * 14 * 64])\r\n    _out = tf.add(tf.matmul(_dense, tf.Variable(tf.random_normal([14 * 14 * 64, 10], stddev=0.1))),\r\n                  tf.Variable(tf.random_normal([10], stddev=0.1)), name='Output')\r\n    out = {\r\n        'input_r': _input_r, 'conv1': _conv1, 'conv2': _conv2, 'conv3': _conv3\r\n        , 'pool': _pool, 'dense': _dense, 'out': _out\r\n    }\r\n    return out\r\n\r\n\r\n# tf Graph input\r\nx = tf.placeholder(tf.float32, [None, 784], name='X')\r\n_pred = conv_simple(x)['out']\r\n\r\ntf.contrib.quantize.create_training_graph()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    # FREEZE GRAPH\r\n    output_graph_def = sess.graph.as_graph_def()\r\n    input_names = [\"X\"]\r\n    output_names = [\"Output\"]\r\n    LOG_DIR = '/some/path/to/log/dir/'\r\n\r\n    output_graph_def = tf.graph_util.convert_variables_to_constants(\r\n        sess,  # The session is used to retrieve the weights\r\n        output_graph_def,  # The graph_def is used to retrieve the nodes\r\n        output_names  # The output node names are used to select the useful nodes,\r\n    )\r\n\r\n    g = tf.import_graph_def(output_graph_def)\r\n```\r\n\r\n", "comments": ["I think this issue may be fixed with correct usage of tf.contrib.create_eval_graph()\r\nThere are currently two issues I have there:\r\n\r\n1. If I use create_eval_graph() after create_training_graph() it doesn't correctly change the graph\r\n2. If I freeze the graph after create_eval_graph() (having not applied create_training_graph()) it fails, giving the following error:\r\n\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Output/weights_quant/min\r\n> [[Node: _retval_Output/weights_quant/min_0_53 = _Retval[T=DT_FLOAT, index=53, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Output/weights_quant/min)]]\r\n\r\nIntuitively I feel create_eval_graph() applied after create_training_graph() should work and also have values initialised correctly but it doesn't want to play nice!\r\n\r\nI also thought it may be I need to run more data through the graph after creating the eval_graph but this did not work.", "Got the same problem,don't know how to solve.", "Get the same problem", "Just do not use tf.contrib.xxx in the case that you will try to load graph. Similar issue here:\r\nhttps://stackoverflow.com/questions/43287850/unable-to-use-freeze-graph-py-with-tf-contrib-image-rotate-in-tf-1-0-1?rq=1", "I've solved this problem by using create_training_graph() right after the construction or building of the graph and right before running the session while training.And while freezing and deploying the graph for inference, I put create_eval_graph() right  after the construction of the graph and right before converting variables in the graph to constants.Hope this can hope!", "@meixiaofeng Could you please post your code? I wish to add fake quantization in Keras model and wondering where to put the quantization functions. Thanks.", "@Basil-M hi, I meet the same problem. Have you solved the problem?", "Same issue here as well.  The only thing I can reason out of this is it's just not designed to manipulate the altered training graph to an altered eval graph.  It may be worth trying to extract the weights out of the training graph and then move them into a newly constructed eval graph before attempting this.  I believe that the API is designed for use with the Estimator API but at this moment I'm only in guessing mode.\r\n\r\n@ZJPUBG I'm converting my model from Keras to a TensorFlow API one because I couldn't figure out how to utilize these functions with Keras as well.", "I did not get success with resolving the error.\r\n@meixiaofeng it will be very helpful if you post your code here. ", "I solved this problem by \r\nfollowing the document here,https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md .While training, I refer to this file https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_train.py ,and while for deployment, I refer code here https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py .This is actually very simple!", "Got the same problem too. \r\nThe only solution is, as I think, is reconstructing your graph when you want to make evaluation\r\nAnd I solved it by such idea indeed.", "@hzhyhx1117 Hi, I have same error when using create_training_graph() and create_eval_graph().\r\nI have a question about reconstructing the graph. Do you mean to restart a session and reload the checkpoint to evaluate?\r\nBecause I am currently use this method but still can not work, when I use 'toco' to convert the graph, it gave me error as bellow:\r\n`ValueError: Input 0 of node Lenet/conv1/weights_quant/AssignMinLast was passed float from Lenet/conv1/weights_quant/min:0 incompatible with expected float_ref.`\r\nDid you use tf.reset_default_graph() to reset the graph or something else to solve it? I really appreciate it if you could give any instruction in detail.", "Wait, I used layers from slim instead of the following\r\n\r\ndef conv_simple(_input):\r\n    _input_r = tf.reshape(_input, shape=[-1, 28, 28, 1])\r\n    _conv1 = tf.nn.conv2d(_input_r, tf.Variable(tf.random_normal([3, 3, 1, 64], stddev=0.1)), strides=[1, 1, 1, 1],\r\n                          padding='SAME')\r\n    _conv2 = tf.nn.bias_add(_conv1, tf.Variable(tf.random_normal([64], stddev=0.1)))\r\n    _conv3 = tf.nn.relu(_conv2)\r\n    _pool = tf.nn.max_pool(_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n    _dense = tf.reshape(_pool, [-1, 14 * 14 * 64])\r\n    _out = tf.add(tf.matmul(_dense, tf.Variable(tf.random_normal([14 * 14 * 64, 10], stddev=0.1))),\r\n                  tf.Variable(tf.random_normal([10], stddev=0.1)), name='Output')\r\n    out = {\r\n        'input_r': _input_r, 'conv1': _conv1, 'conv2': _conv2, 'conv3': _conv3\r\n        , 'pool': _pool, 'dense': _dense, 'out': _out\r\n    }\r\n    return out\r\n\r\nIt worked with slim.\r\nBut for the layers of tf.nn fake layers arenot being added.\r\n\r\nAre you people discussing the solution for the above code ( layers not from slim )\r\n?\r\n", "> @hzhyhx1117 Hi, I have same error when using create_training_graph() and create_eval_graph().\r\n> I have a question about reconstructing the graph. Do you mean to restart a session and reload the checkpoint to evaluate?\r\n> Because I am currently use this method but still can not work, when I use 'toco' to convert the graph, it gave me error as bellow:\r\n> `ValueError: Input 0 of node Lenet/conv1/weights_quant/AssignMinLast was passed float from Lenet/conv1/weights_quant/min:0 incompatible with expected float_ref.`\r\n> Did you use tf.reset_default_graph() to reset the graph or something else to solve it? I really appreciate it if you could give any instruction in detail.\r\n\r\nHi, I have the exactly same error like yours. Did you solve this problem? (I used code from Pocketflow and then converted the checkpoint file to a pb file. After that I use TFLite converter, it turns out this error.)", "The problem is, you cannot apply `create_eval_graph` to the graph on which you already called `create_training_graph`.\r\nTo solve this, I save variables after training with fake quantization using `tf.train.Saver.save`.\r\nThen I simply create a new graph from scratch, call `create_eval_graph` and finally restore the variables using `tf.train.Saver.restore`.\r\nRemeber to call execute `tf.global_variables_initializer()` after both `create_training_graph` and `create_eval_graph`.", "Fixed `tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Output/weights_quant/min` error by adding `tf.global_variables_initializer()` after `create_eval_graph`", "I am also getting same error, even though i used create_training_graph and initailaized using tf.global_variables_initializer() . The tflite gives errors as below .\r\ntoco --graph_def_file=frozen_graph_quantize.pb --output_file=tflite_model.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE  --inference_type=QUANTIZED_UINT8 --input_shape=\"1,784\" --input_array=input_x --output_array=ArgMax --std_dev_value 127 --mean_value 255 --default_ranges_min 0  --default_ranges_max 6  --inference_input_type=QUANTIZED_UINT8\r\n\r\n\r\n\r\n2019-07-15 17:02:53.729357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-15 17:02:53.731481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-07-15 17:02:53.732792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-07-15 17:02:53.734200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3010 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 426, in import_graph_def\r\n    graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input 0 of node conv1/weights_quant/AssignMinLast was passed float from conv1/weights_quant/min:0 incompatible with expected float_ref.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\Scripts\\toco-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 442, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 438, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 122, in _convert_model\r\n    converter = _get_toco_converter(flags)\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 109, in _get_toco_converter\r\n    return converter_fn(**converter_kwargs)\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 274, in from_frozen_graph\r\n    _import_graph_def(graph_def, name=\"\")\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 430, in import_graph_def\r\n    raise ValueError(str(e))\r\nValueError: Input 0 of node conv1/weights_quant/AssignMinLast was passed float from conv1/weights_quant/min:0 incompatible with expected float_ref.\r\n\r\nAny ideas on how i can solve this?\r\n", "Any suggestions please !", "Hi @ignvinay \r\n\r\nare you getting the same toco error for the case of using create eval graph before freezing the graph ? \r\n\r\n\r\n", "Yeah @ved27 .\r\nAny suggestions to resolve this ?", "Hi \r\n\r\nSo , can you post the code ? or a snippet of that \r\n\r\nI hope you are creating the graph and calling create eval graph and loading it from a checkpoint \r\n", "Freezing of buffer is as follows : \r\n\r\n`with tf.Session() as sess:\r\n    \r\n    y_conv, keep_prob = deepnn(x)\r\n    with tf.name_scope('loss'):\r\n      cross_entropy = tf.losses.sparse_softmax_cross_entropy(\r\n        labels=y_, logits=y_conv)\r\n      cross_entropy = tf.reduce_mean(cross_entropy)\r\n\r\n    graph = tf.get_default_graph()\r\n    \r\n    with graph.as_default():\r\n      tf.contrib.quantize.create_training_graph(input_graph=graph,\r\n                                          quant_delay=200) #2000000\r\n    \r\n    init = tf.global_variables_initializer()\r\n\r\n    with tf.name_scope('adam_optimizer'):\r\n      train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n\r\n    #with tf.name_scope('accuracy1'):\r\n    correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\r\n    correct_prediction = tf.cast(correct_prediction, tf.float32)\r\n    accuracy = tf.reduce_mean(correct_prediction,name='accuracy')\r\n    saver = tf.train.Saver(sharded=True)\r\n    sess.run(init)\r\n    sess.run(tf.global_variables_initializer())\r\n    \r\n    for i in range(200):\r\n      batch = mnist.train.next_batch(50)\r\n      if i % 100 == 0:\r\n        \r\n        train_accuracy = accuracy.eval(feed_dict={\r\n            x: batch[0], y_: batch[1], keep_prob: 1.0})\r\n        print('step %d, training accuracy %g' % (i, train_accuracy))\r\n      train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\r\n    \r\n    \r\n    print('test accuracy %g' % accuracy.eval(feed_dict={\r\n        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\r\n    \r\n   \r\n    #tf.saved_model.simple_save(sess,'export_1',inputs={\"input_x\":x},outputs={\"ArgMax\":y_conv})\r\n    #builder = tf.saved_model.builder.SavedModelBuilder('export_path')\r\n    #signature = predict_signature_def(inputs={\"input_x\":x},outputs={\"ArgMax\":y_conv})\r\n    # using custom tag instead of: tags=[tag_constants.SERVING]\r\n    #builder.add_meta_graph_and_variables(sess=sess,\r\n    #                                 tags=[\"myTag\"],\r\n    #                                 signature_def_map={'predict': signature})\r\n    #builder.save()\r\n    # this step will take care of frezzing graph \r\n    gd = sess.graph.as_graph_def()\r\n    out_graph_def = tf.graph_util.convert_variables_to_constants(sess,gd,\r\n                                                 [\"ArgMax\"])\r\n    \r\n    tf.train.write_graph(out_graph_def,\"./\", \"frozen_train_quantize.pb\", as_text=False)`\r\n\r\ntoco command line is given as above in my post.", "Please let me know how to solve this.", "Hi ,\r\n\r\nIs create_eval_graph(..) used in the above ?\r\n\r\nI can suggest you to use the above api after deepcnn() for inference and load from ckpt and save the frozen file ", "After deepnn(), called create_training_graph, which will do quantization.\r\nSo how can i call create_eval_graph, which is meant for inference.\r\n\r\nCan you post your suggested code , please.\r\n", "For inference , you are not supposed to use create training graph . And hence I asked earlier if you used create eval graph .\r\n\r\nUse create eval graph - and freeze the graph to send that as input to toco . \r\n\r\n Refer to any example of the official quantized networks using tensorflow ", "This is not at inference. Its during training.", "Toco is used for inference . And hence you need a frozen pb file for inference \r\n\r\nThe frozen pb file needs to be generated from inference graph ", "The frozen graph generated using tf.train.write_graph(out_graph_def,\"./\", \"frozen_train_quantize.pb\", as_text=False)` is incorrect ?", "\r\n\r\nAs mentioned , the frozen pb file needs to be generated from inference graph\r\n\r\n", "Introduced additional code as below : \r\nwith tf.Session() as sess:\r\n  inference_graph(sess)\r\n\r\n\r\nwhere function is : \r\n\r\n```\r\ndef inference_graph(sess):\r\n  # Call the eval rewrite which rewrites the graph in-place with\r\n  # FakeQuantization nodes and fold batchnorm for eval.\r\n  g = tf.get_default_graph()\r\n  tf.contrib.quantize.create_eval_graph(input_graph=g)\r\n\r\n  # Save the checkpoint and eval graph proto to disk for freezing\r\n  # and providing to TFLite.\r\n  with open('test', \"w\") as f:\r\n    f.write(str(g.as_graph_def()))\r\n  saver = tf.train.Saver()\r\n  saver.save(sess, \"checkpoint_name\")\r\n```\r\n\r\nI get the errors as : \r\n    raise ValueError('Training op found in graph, exiting %s' % train_op_list)\r\nValueError: Training op found in graph, exiting {'ApplyAdam'}", "\r\nThis link for ref.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/contrib/quantize/README.md", "Same code i used .", "Try to make training and inference codes in separate files \r\n\r\nIt seems the gradient thingy is present and hence that error ", "Yes, even in new file the same error.\r\nThat gradient problem, i am not able remove.\r\nCode snippet in new file : \r\n`sess=tf.Session() \r\nsaver = tf.train.import_meta_graph('checkpoints/model.ckpt.meta')\r\nsaver.restore(sess,'checkpoints/model.ckpt')\r\ngraph = tf.get_default_graph()\r\n\r\nwith tf.Session() as sess:\r\n        g = tf.get_default_graph()\r\n        tf.contrib.quantize.create_eval_graph(input_graph=graph)\r\n        with open('test', \"w\") as f:\r\n                f.write(str(g.as_graph_def()))`\r\n\r\nif you have quantized model, can you please share your code snippet.", "Hi ,\r\n\r\ndo not import from meta as it has info of training .\r\n\r\ncall your deepnn , followed by create eval graph ; \r\n\r\n\r\n\r\n- y_conv, keep_prob = deepnn(x)\r\n- graph = tf.get_default_graph()\r\n- tf.contrib.quantize.create_eval_graph(input_graph=graph)\r\n\r\n- then create saver and restore \r\n\r\nand then freeze as follows \r\nsess.graph.as_graph_def()\r\nout_graph_def = tf.graph_util.convert_variables_to_constants(sess,gd,\r\n                                             [\"Outputnode_name\"])\r\n\r\n\r\n\r\n\r\n\r\n", "Got it. Thanks.\r\nBut tflite conversion still gives error \r\n``\r\n(tflite) D:\\Vinay\\gyrus\\models>toco --graph_def_file=frozen_inference_quantize.pb --output_file=tflite_model.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_UINT8 --input_shape=\"1,784\" --input_array=input_x --output_array=ArgMax --std_dev_value 127 --mean_value 255 --default_ranges_min 0 --default_ranges_max 6\r\n2019-07-17 22:03:55.657362: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2019-07-17 22:03:56.502116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:\r\nname: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.30GiB\r\n2019-07-17 22:03:56.506268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-07-17 22:03:56.915974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-07-17 22:03:56.918685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-07-17 22:03:56.919975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-07-17 22:03:56.921397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3010 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\Scripts\\toco-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 442, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 438, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 191, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 455, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 442, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"C:\\Users\\GF63\\.conda\\envs\\tflite\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-07-17 22:03:58.832651: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 61 operators, 94 arrays (0 quantized)\r\n2019-07-17 22:03:58.833307: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 61 operators, 94 arrays (0 quantized)\r\n2019-07-17 22:03:58.906787: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 25 operators, 42 arrays (1 quantized)\r\n2019-07-17 22:03:58.941310: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 24 operators, 41 arrays (1 quantized)\r\n2019-07-17 22:03:58.941785: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting \"dropout/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set\r\n\"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-07-17 22:03:58.942427: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 20 operators, 35 arrays (1 quantized)\r\n2019-07-17 22:03:58.942767: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting \"dropout/dropout/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set\r\n\"seed\" or \"seed2\" attr non-zero to fix this\r\n2019-07-17 22:03:58.943375: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 20 operators, 35 arrays (1 quantized)\r\n2019-07-17 22:03:58.943717: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 16 operators, 31 arrays (1 quantized)\r\n2019-07-17 22:03:58.944040: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before default min-max range propagation graph transformations: 16 operators, 31 arrays (1 quantized)\r\n2019-07-17 22:03:58.944393: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After default min-max range propagation graph transformations pass 1: 16 operators, 31 arrays (1 quantized)\r\n2019-07-17 22:03:58.944778: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 16 operators, 31 arrays (1 quantized)\r\n2019-07-17 22:03:58.945131: F tensorflow/lite/toco/graph_transformations/quantize.cc:606] Check failed: is_rnn_state_array``", "Hi ,\r\n\r\n\r\nThis seems another issue .\r\n- Do you have a dropout layer during inference ? - remove it anyway if you have\r\n- What kind of deepnn is yours ? \r\n\r\n\r\n"]}, {"number": 20885, "title": "AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'", "body": "I am using keras where tensorflow as backend.Getting the following error:\r\n\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-8-509bb069f0c0> in <module>()\r\n     10 KEYS = [str(key) for key in range(len(database))]\r\n     11 \r\n---> 12 encoder    = load_model(ENCODER_PATH, custom_objects={'VisualBinaryRegulizer': VisualBinaryRegulizer})\r\n     13 \r\n     14 input_size  = encoder.layers[0].input.shape.as_list()[1:3]\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/saving.py in load_model(filepath, custom_objects, compile)\r\n    259             raise ValueError('No model found in config file.')\r\n    260         model_config = json.loads(model_config.decode('utf-8'))\r\n--> 261         model = model_from_config(model_config, custom_objects=custom_objects)\r\n    262 \r\n    263         # set weights\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/saving.py in model_from_config(config, custom_objects)\r\n    333                         '`Sequential.from_config(config)`?')\r\n    334     from ..layers import deserialize\r\n--> 335     return deserialize(config, custom_objects=custom_objects)\r\n    336 \r\n    337 \r\n\r\n~/.local/lib/python3.5/site-packages/keras/layers/__init__.py in deserialize(config, custom_objects)\r\n     53                                     module_objects=globs,\r\n     54                                     custom_objects=custom_objects,\r\n---> 55                                     printable_module_name='layer')\r\n\r\n~/.local/lib/python3.5/site-packages/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    143                     config['config'],\r\n    144                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\r\n--> 145                                         list(custom_objects.items())))\r\n    146             with CustomObjectScope(custom_objects):\r\n    147                 return cls.from_config(config['config'])\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/network.py in from_config(cls, config, custom_objects)\r\n   1034         # First, we create all layers and enqueue nodes to be processed\r\n   1035         for layer_data in config['layers']:\r\n-> 1036             process_layer(layer_data)\r\n   1037         # Then we process nodes in order of layer depth.\r\n   1038         # Nodes that cannot yet be processed (if the inbound node\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/network.py in process_layer(layer_data)\r\n   1020 \r\n   1021             layer = deserialize_layer(layer_data,\r\n-> 1022                                       custom_objects=custom_objects)\r\n   1023             created_layers[layer_name] = layer\r\n   1024 \r\n\r\n~/.local/lib/python3.5/site-packages/keras/layers/__init__.py in deserialize(config, custom_objects)\r\n     53                                     module_objects=globs,\r\n     54                                     custom_objects=custom_objects,\r\n---> 55                                     printable_module_name='layer')\r\n\r\n~/.local/lib/python3.5/site-packages/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    143                     config['config'],\r\n    144                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\r\n--> 145                                         list(custom_objects.items())))\r\n    146             with CustomObjectScope(custom_objects):\r\n    147                 return cls.from_config(config['config'])\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/network.py in from_config(cls, config, custom_objects)\r\n   1044                 if layer in unprocessed_nodes:\r\n   1045                     for node_data in unprocessed_nodes.pop(layer):\r\n-> 1046                         process_node(layer, node_data)\r\n   1047 \r\n   1048         name = config.get('name')\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/network.py in process_node(layer, node_data)\r\n   1001             if input_tensors:\r\n   1002                 if len(input_tensors) == 1:\r\n-> 1003                     layer(input_tensors[0], **kwargs)\r\n   1004                 else:\r\n   1005                     layer(input_tensors, **kwargs)\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)\r\n    412                 # Raise exceptions in case the input is not compatible\r\n    413                 # with the input_spec specified in the layer constructor.\r\n--> 414                 self.assert_input_compatibility(inputs)\r\n    415 \r\n    416                 # Collect input shapes to build layer.\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/base_layer.py in assert_input_compatibility(self, inputs)\r\n    277         for x in inputs:\r\n    278             try:\r\n--> 279                 K.is_keras_tensor(x)\r\n    280             except ValueError:\r\n    281                 raise ValueError('Layer ' + self.name + ' was called with '\r\n\r\n~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in is_keras_tensor(x)\r\n    467     ```\r\n    468     \"\"\"\r\n--> 469     if not is_tensor(x):\r\n    470         raise ValueError('Unexpectedly found an instance of type `' +\r\n    471                          str(type(x)) + '`. '\r\n\r\n~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in is_tensor(x)\r\n    475 \r\n    476 def is_tensor(x):\r\n--> 477     return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)\r\n    478 \r\n    479 \r\n\r\nAttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 20884, "title": "Add int32/string k/v support for tf.contrib.lookup.HashTable", "body": "This fix tries to address the issue raised in #20869 where there were no int32/string k/v support for tf.contrib.lookup.HashTable. This fix adds the int32/string for the kernel.\r\n\r\nThis fix fixes #20869.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["/cc @gunan @yifeif @martinwicke This PR seems to have been imported separately by tensorflower-gardener in da12c366bd55cd797e433f78034d3848736ebe6f and showed up in master branch.\r\n\r\nBut it is not merged or committed so this PR is still open. Just wondering if there are some additional steps to fully merge and close this PR?", "@yongtang This is due to a new workflow where we use the internal google repository as the single source of truth and commit every PR there first.", "@yifeif should this PR not be closed automatically after being pushed?", "Looking into why this PR is not marked as merged now. Apologies for the inconvenience @yongtang.", "Thanks @rmlarsen @yifeif. It looks like da12c36 already captured all changes in this PR. So it might be safe to close this PR, though let me know if there are anything else that needs to be done.", "@yongtang we found the issue in our tool and this shouldn't happen again once the fix is in. Sorry for the trouble. Is it okay with you if we close this PR?", "Sure. Let me close the PR.", "Thank you @yongtang!"]}, {"number": 20883, "title": "How to distribute custom OPs with pypi?", "body": "We've got an instruction how to build custom OPs https://www.tensorflow.org/extend/adding_an_op\r\n\r\nBut there is no information about how to pack custom ops and distribute them with pypi.\r\nShared library built with system compiler could not be uploaded to pypi due to PEP 513 limitation.\r\nAnd there is no instructions for building custom OPs outside \"user_ops\" dir in tensorflow source.\r\n\r\nSo, some boilerplate for building pip packages with custom OPs required.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS X\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.6\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This issue is a request for documentation improvement, not a bug", "@yifeif is working on documentation on this.", "For now i made such build env for zero_out https://github.com/shkarupa-alex/zero\r\nIt based on https://github.com/tensorflow/lattice (the only working tensorflow + custom ops + bazel repo i found).\r\nThere were a lot of challenges. For example TF r1.9.0 could not be built on fresh MacOs. So repo using TF r1.8.0 but working well with binary TF 1.9 installation.\r\n\r\nGood news: with my repo i built op, built wheel and tested it through test.pypi.org\r\nAnd it's work!\r\n\r\nBan news: i'm not sure about optimal .bazel.rc options and most dependencies with bazel targets because built .so library has size about 6MB. For comparison same .so built with gcc is about 100Kb", "Nagging Assignee @yifeif: It has been 110 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi @shkarupa-alex, we have published a guide at https://github.com/tensorflow/custom-op. It's mostly for linux, but macos shouldn't be too far off. If you have any question or anything to add from your experience building ops, feel free to open an issue or pull request. I'm closing this issue for now. Thanks!"]}, {"number": 20882, "title": "Tf reports DLL load failed but passes existance check if wrong subversion of cudnn used.", "body": "Windows 7, python 3.5\r\n\r\nUsing pip3 install --upgrade tensorflow-gpu yields \"ImportError: DLL load failed: The specified module could not be found.\" when incorrect subversion of cudnn64_7.dll is used. \r\n\r\nNVIDIA provides several versions of cudnn for windows which are all called cudnn64_7.dll.  Thus, the existence checks tf does for the file cudnn64_7.dll pass but when loading the DLL python yields the error mentioned above.\r\n\r\nSuggest adding checks for correct subversion of DLL.  Minimally, let the user know the state can occur as part of the error message.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Lets table this issue until I have more time to investigate."]}, {"number": 20881, "title": "How to use LSTM layer in tfLite ?", "body": "How to use the following code ?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/lstm.cc", "comments": ["@aselle Could you please help me, thank you ?", "This is currently not easy to do. We are working on creating a simple example. Could you give some more details on your exact needs? \r\n", "@aselle \r\n\r\nI am looking for a way to deploy the `CNN+stack_bidirectional_dynamic_rnn+CTC` on mobile devices, and it seems that LSTM layers are not supported by tf-lite, but I happened to find the following code, so I want to know is it possible to support LSTM layers with tf-lite, thank you ?\r\n\r\n[](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/lstm.cc)\r\n", "LSTM's are supported as operations, but it is currently difficult to generate such models automatically. We will keep you posted when we have an easy path to support this.", "@aselle  I am also concerned about this, is it mean that LSTM structure is not supported in tf-lite now or when can it be supported in the future?\r\nCan we  implement it by compose some OPs currently?", "@aselle , I want to run LSTM in tflite also.\r\nWhen can it be supported?", "...", "Any update on when a simple way to do this is coming? Will this convert tf.keras LSTMs?", "Hi, \r\n\r\nI would like to know if tflite at this time support RNN (LSTM, Multi-dim LSTM) ? \r\n\r\nOr at last support inference from a graph having LSTM node ?\r\n", "I'm also trying to convert keras biLSTM to tflite model, but still have the same issues. Waiting for a support"]}, {"number": 20880, "title": "AttributeError: 'DataFrame' object has no attribute 'dtype'", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nAttributeError: 'DataFrame' object has no attribute 'dtype'\r\n\r\n\r\n### Source code / logs\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-14-3c90f2017a02> in <module>()\r\n----> 1 **reg.fit(input_fn=training_input_fn(batch_size=BATCH_SIZE),steps=STEPS_PER_EPOCH)**\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    430                 'in a future version' if date is None else ('after %s' % date),\r\n    431                 instructions)\r\n--> 432       return func(*args, **kwargs)\r\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    434                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\r\n    522       hooks.append(basic_session_run_hooks.StopAtStepHook(steps, max_steps))\r\n    523 \r\n--> 524     loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n    525     logging.info('Loss for final step: %s.', loss)\r\n    526     return self\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _train_model(self, input_fn, hooks)\r\n   1036       random_seed.set_random_seed(self._config.tf_random_seed)\r\n   1037       global_step = training_util.create_global_step(g)\r\n-> 1038       features, labels = input_fn()\r\n   1039       self._check_inputs(features, labels)\r\n   1040       training_util._get_or_create_global_step_read()  # pylint: disable=protected-access\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py in input_fn()\r\n    194         num_threads=num_threads,\r\n    195         enqueue_size=batch_size,\r\n--> 196         num_epochs=num_epochs)\r\n    197 \r\n    198     batch = (\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads, seed, name, enqueue_size, num_epochs, pad_value)\r\n    390     elif isinstance(data, collections.OrderedDict):\r\n    391       types = [dtypes.int64\r\n--> 392               ] + [dtypes.as_dtype(col.dtype) for col in data.values()]\r\n    393       queue_shapes = [()] + [col.shape[1:] for col in data.values()]\r\n    394       get_feed_fn = _OrderedDictNumpyFeedFn\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in <listcomp>(.0)\r\n    390     elif isinstance(data, collections.OrderedDict):\r\n    391       types = [dtypes.int64\r\n--> 392               ] + [dtypes.as_dtype(col.dtype) for col in data.values()]\r\n    393       queue_shapes = [()] + [col.shape[1:] for col in data.values()]\r\n    394       get_feed_fn = _OrderedDictNumpyFeedFn\r\n\r\n~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name)\r\n   4370             if self._info_axis._can_hold_identifiers_and_holds_name(name):\r\n   4371                 return self[name]\r\n-> 4372             return object.__getattribute__(self, name)\r\n   4373 \r\n   4374     def __setattr__(self, name, value):\r\n", "comments": ["I saw a similar issue #20738 though there were not enough details. Maybe it is about version compatibility?", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 20879, "title": "NCCL not detected on Arch Linux", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux\r\n- **TensorFlow installed from (source or binary)**: source (r1.9)\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.7.0\r\n- **Bazel version (if compiling from source)**: 0.15.0\r\n- **GCC/Compiler version (if compiling from source)**: 8.1.1\r\n- **CUDA/cuDNN version**: 9.2/7.1.4\r\n- **NCCL version**: 2.2.13\r\n- **GPU model and memory**: Nvidia GTX 1060 3GB\r\n- **Exact command to reproduce**: ./configure\r\n\r\n### Problem\r\n`./configure` does not detect my `libnccl.so.2` located at `/opt/cuda/lib64`.\r\n\r\n#### Output of `./configure`\r\n```\r\nPlease specify the location of python. [Default is /home/mukundan/.pyenv/versions/machine_learning/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/mukundan/.pyenv/versions/machine_learning/lib/python3.7/site-packages\r\nPlease input the desired Python library path to use.\r\nDefault is [/home/mukundan/.pyenv/versions/machine_learning/lib/python3.7/site-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: \r\nGoogle Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: \r\nHadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: \r\nAmazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: \r\nApache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 9.2\r\n\r\n\r\nPlease specify the location where CUDA 9.2 toolkit is installed. Refer to README.md for more details. [Default is /opt/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7.1.4\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /opt/cuda]:\r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]: 2.2.13\r\n\r\n\r\nPlease specify the location where NCCL 2 library is installed. Refer to README.md for more details. [Default is /opt/cuda]:\r\n\r\n\r\nInvalid path to NCCL 2 toolkit, /opt/cuda/lib/libnccl.so.2 or /opt/cuda/include/nccl.h not found. Please use the O/S agnostic package of NCCL 2\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nCUDA/cuDNN version", "modify the code ` nccl_lib_path = 'lib/libnccl.so.%s' % tf_nccl_version` round line 1135 of **configure.py**  or put your so into `/opt/cuda/lib` What's more **Don't forget the license file**!", "Thanks", "or add this line in the ~/.profile to set the environment variable, in Ubuntu, other OS varied accordingly. Actual nccl installation path is also varied\r\n`export NCCL_INSTALL_PATH=\"$CUDA_HOME/targets/x86_64-linux\"`"]}, {"number": 20878, "title": "Issue with converting Keras .h5 files to .tflite files", "body": "There seems to be an issue with the above mentioned conversion.\r\nAccording to this documentation (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#keras) it should be possible to convert a Keras model into a .tflite file. However, when I try to convert the file, the following output is given: \r\n\r\n> tflite_convert: error: one of the arguments --graph_def_file --saved_model_dir is required.\r\n\r\nI made sure that the .h5 contains both the model and the weights. Other conversions like .pb files have worked with this file as well. Also in the help section of the commad there is no reference to --keras_model_file.  \r\n\r\n**Update**\r\nI was using the wrong TF version so I got the error message above. However, using the nightly build results in other error messages: \r\n\r\n> ValueError: Unknown activation function:relu6\r\n\r\nThis error normally occurs when using load_model but there is the possibility to specify custom_objects (like relu6) to avoid it.\r\n\r\nHow can this be done with tflite_convert?", "comments": ["Same issue here", "Hi  @bennyooo \r\nWhy is the issue closed? Is there a solution to this yet ?\r\nI have the same problem.", "I closed it because I was referring to TF 1.9 but the documentation I linked above reffers to the master branch. Anyway I tried the nightly build as well and it still doesn't work (so I'm reopening the issue now). I am currently trying to do this via a frozen graph (.pb) file and will report my findings.\r\n\r\n**Update**\r\nThe frozen graph file can also not be converted. The error is: \r\n\r\n> F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:95] Check failed: other_op->type == OperatorType::kMerge \\nAborted (core dumped)\\n'\r\n> None\r\n\r\nI used the transform_graph tool with the strip_unused_nodes flag beforehand.", "@kumarnikhil936 As @bennyooo noted, support for Keras is not available in 1.9. Please use the nightly build. You can do that by either using \"pip install --upgrade tf_nightly\" or follow the instructions [here](https://www.tensorflow.org/install/install_sources).\r\n\r\n@bennyooo Can you provide your Keras model file and the set of commands (or code) you used to convert your model?", "i thought I can convert the keras model file h5 -> pb -> tflite .. is that right way to go about ?", "@nitheeshmuthuraj TOCO supports converting Keras models directly ([command line documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#keras), [Python API documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md#basic-keras-file)). This is the recommended approach. However, this requires using the nightly build since support was added after 1.9.\r\n\r\nTOCO still accepts frozen GraphDefs, so it is still possible to go from h5 -> pb -> tflite. This is the recommended approach for TensorFlow 1.9 and before.", "@gargn Hi Nupur, the nightly build worked for me. Thanks ", "@kumarnikhil936 : did you convert keras_model.h5 to tflite with nightly build ? \r\nif so please share the documentation... ", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#keras\r\n@nitheeshmuthuraj  Hi Nitheesh, Please refer to the link mentioned above. I used the \"--keras_model_file\" argument and finally, it worked for me in the nightly build. I've finally got the converted tflite file, still to verify functionality.", "I enter this command : tflite_convert \\ --output_file=/tmp/foo.tflite \\ --keras_model_file=C:/Users/n.muthuraj/Desktop/cnn/02/dataset/ashik.h5 \r\nThe Output is : Traceback (most recent call last):                                                                                                                                                                                                             File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper                                                                            return importlib.import_module(mname)                                                                                                                                                                                                      File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module                                                                                                                        return _bootstrap._gcd_import(name[level:], package, level)                                                                                                                                                                                File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import                                                                                                                                                                               File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load                                                                                                                                                                            File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked                                                                                                                                                                   File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked                                                                                                                                                                            File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec                                                                                                                                                                          File \"<frozen importlib._bootstrap_external>\", line 906, in create_module                                                                                                                                                                    File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed                                                                                                                                                               ImportError: DLL load failed: The specified module could not be found.                                                                                                                                                                                                                                                                                                                                                                                                                    During handling of the above exception, another exception occurred:                                                                                                                                                                                                                                                                                                                                                                                                                       Traceback (most recent call last):                                                                                                                                                                                                             File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>                                                                                               from tensorflow.python.pywrap_tensorflow_internal import *                                                                                                                                                                                 File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>                                                                                      _pywrap_tensorflow_internal = swig_import_helper()                                                                                                                                                                                         File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper                                                                            return importlib.import_module('_pywrap_tensorflow_internal')                                                                                                                                                                              File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module                                                                                                                        return _bootstrap._gcd_import(name[level:], package, level)                                                                                                                                                                              ImportError: No module named '_pywrap_tensorflow_internal'                                                                                                                                                                                                                                                                                                                                                                                                                                During handling of the above exception, another exception occurred:                                                                                                                                                                                                                                                                                                                                                                                                                       Traceback (most recent call last):                                                                                                                                                                                                             File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 184, in _run_module_as_main                                                                                                                               \"__main__\", mod_spec)                                                                                                                                                                                                                      File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code                                                                                                                                          exec(code, run_globals)                                                                                                                                                                                                                    File \"C:\\Users\\n.muthuraj\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\tflite_convert.exe\\__main__.py\", line 5, in <module>                                                                                                                File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>                                                                                                               from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import                                                                                                                                                           File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>                                                                                                        from tensorflow.python import pywrap_tensorflow                                                                                                                                                                                            File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>                                                                                               raise ImportError(msg)                                                                                                                                                                                                                   ImportError: Traceback (most recent call last):                                                                                                                                                                                                File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper                                                                            return importlib.import_module(mname)                                                                                                                                                                                                      File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module                                                                                                                        return _bootstrap._gcd_import(name[level:], package, level)                                                                                                                                                                                File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import                                                                                                                                                                               File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load                                                                                                                                                                            File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked                                                                                                                                                                   File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked                                                                                                                                                                            File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec                                                                                                                                                                          File \"<frozen importlib._bootstrap_external>\", line 906, in create_module                                                                                                                                                                    File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed                                                                                                                                                               ImportError: DLL load failed: The specified module could not be found.                                                                                                                                                                                                                                                                                                                                                                                                                    During handling of the above exception, another exception occurred:                                                                                                                                                                                                                                                                                                                                                                                                                       Traceback (most recent call last):                                                                                                                                                                                                             File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>                                                                                               from tensorflow.python.pywrap_tensorflow_internal import *                                                                                                                                                                                 File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>                                                                                      _pywrap_tensorflow_internal = swig_import_helper()                                                                                                                                                                                         File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper                                                                            return importlib.import_module('_pywrap_tensorflow_internal')                                                                                                                                                                              File \"c:\\users\\n.muthuraj\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\__init__.py\", line 126, in import_module                                                                                                                        return _bootstrap._gcd_import(name[level:], package, level)                                                                                                                                                                              ImportError: No module named '_pywrap_tensorflow_internal'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Failed to load the native TensorFlow runtime.                                                                                                                                                                                                                                                                                                                                                                                                                                             See https://www.tensorflow.org/install/install_sources#common_installation_problems                                                                                                                                                                                                                                                                                                                                                                                                       for some common reasons and solutions.  Include the entire stack trace                                                                                                                                                                       above this error message when asking for help.                            \r\nI am not sure where i am going wrong  ", "@nitheeshmuthuraj Please file a separate bug for your issue.", "@gargn I'm afraid I cannot upload the file itself but here is the output of keras.model.summary( ). I hope that helps:\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n__________________________________________________________________________________________________\r\n\r\ninput_1 (InputLayer)            (None, 224, 224, 3)  0                                            \r\n__________________________________________________________________________________________________\r\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \r\n__________________________________________________________________________________________________\r\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \r\n__________________________________________________________________________________________________\r\nConv1_relu (Activation)         (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \r\n__________________________________________________________________________________________________\r\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \r\n__________________________________________________________________________________________________\r\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \r\n__________________________________________________________________________________________________\r\nexpanded_conv_depthwise_relu (A (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \r\n__________________________________________________________________________________________________\r\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\r\n__________________________________________________________________________________________________\r\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \r\n__________________________________________________________________________________________________\r\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_1_expand_relu (Activation (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_1_depthwise_relu (Activat (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_2_expand_relu (Activation (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_2_depthwise_relu (Activat (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \r\n                                                                 block_2_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \r\n__________________________________________________________________________________________________\r\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_3_expand_relu (Activation (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_3_depthwise_relu (Activat (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_4_expand_relu (Activation (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_4_depthwise_relu (Activat (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \r\n                                                                 block_4_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \r\n__________________________________________________________________________________________________\r\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_5_expand_relu (Activation (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_5_depthwise_relu (Activat (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \r\n                                                                 block_5_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \r\n__________________________________________________________________________________________________\r\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_6_expand_relu (Activation (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_6_depthwise_relu (Activat (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_7_expand_relu (Activation (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_7_depthwise_relu (Activat (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \r\n                                                                 block_7_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \r\n__________________________________________________________________________________________________\r\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_8_expand_relu (Activation (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_8_depthwise_relu (Activat (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \r\n                                                                 block_8_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \r\n__________________________________________________________________________________________________\r\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \r\n__________________________________________________________________________________________________\r\nblock_9_expand_relu (Activation (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \r\n__________________________________________________________________________________________________\r\nblock_9_depthwise_relu (Activat (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \r\n__________________________________________________________________________________________________\r\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \r\n                                                                 block_9_project_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \r\n__________________________________________________________________________________________________\r\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_10_expand_relu (Activatio (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_10_depthwise_relu (Activa (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \r\n__________________________________________________________________________________________________\r\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_11_expand_relu (Activatio (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_11_depthwise_relu (Activa (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \r\n__________________________________________________________________________________________________\r\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \r\n                                                                 block_11_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \r\n__________________________________________________________________________________________________\r\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_12_expand_relu (Activatio (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_12_depthwise_relu (Activa (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \r\n__________________________________________________________________________________________________\r\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \r\n                                                                 block_12_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \r\n__________________________________________________________________________________________________\r\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_13_expand_relu (Activatio (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_13_depthwise_relu (Activa (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \r\n__________________________________________________________________________________________________\r\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_14_expand_relu (Activatio (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_14_depthwise_relu (Activa (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \r\n__________________________________________________________________________________________________\r\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \r\n                                                                 block_14_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \r\n__________________________________________________________________________________________________\r\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_15_expand_relu (Activatio (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_15_depthwise_relu (Activa (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \r\n__________________________________________________________________________________________________\r\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \r\n                                                                 block_15_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \r\n__________________________________________________________________________________________________\r\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \r\n__________________________________________________________________________________________________\r\nblock_16_expand_relu (Activatio (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \r\n__________________________________________________________________________________________________\r\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \r\n__________________________________________________________________________________________________\r\nblock_16_depthwise_relu (Activa (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \r\n__________________________________________________________________________________________________\r\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \r\n__________________________________________________________________________________________________\r\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \r\n__________________________________________________________________________________________________\r\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \r\n__________________________________________________________________________________________________\r\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \r\n__________________________________________________________________________________________________\r\nout_relu (Activation)           (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \r\n__________________________________________________________________________________________________\r\ndrop (Dropout)                  (None, 1280)         0           global_average_pooling2d_1[0][0] \r\n__________________________________________________________________________________________________\r\ndistribution (Dense)            (None, 10)           12810       drop[0][0]                       \r\n\r\nThen I used the following code to create the .pb file:\r\n\r\n```\r\ndef serialize_model(model):\r\n    # Serialize the model and get its weights, for quick re-building.\r\n    config = model.get_config()\r\n    weights = model.get_weights()\r\n\r\n    # Re-build a model where the learning phase is now hard-coded to 0.\r\n    # CustomObjectScope necessary for importing a pre-trained MobileNet\r\n    with CustomObjectScope({'relu6': relu6}):\r\n        new_model = Model.from_config(config)\r\n\r\n    new_model.set_weights(weights)\r\n\r\n    input_layers = new_model.input\r\n    print(new_model.input_shape)\r\n\r\n    output_layers = new_model.output\r\n    print(new_model.output_shape)\r\n\r\n    temp_dir = \"graph\"\r\n    checkpoint_prefix = os.path.join(temp_dir, \"saved_checkpoint\")\r\n    checkpoint_state_name = \"checkpoint_state\"\r\n    input_graph_name = \"input_graph.pb\"\r\n    output_graph_name = \"output_graph.pb\"\r\n\r\n    # Temporary save graph to disk without weights included.\r\n    saver = tf.train.Saver()\r\n    checkpoint_path = saver.save(K.get_session(), checkpoint_prefix, global_step=0,\r\n                                 latest_filename=checkpoint_state_name)\r\n    tf.train.write_graph(K.get_session().graph, temp_dir, input_graph_name)\r\n\r\n    input_graph_path = os.path.join(temp_dir, input_graph_name)\r\n    input_saver_def_path = \"\"\r\n    input_binary = False\r\n    output_node_names = model.output.name.split(':')[0]  # model dependent\r\n    restore_op_name = \"save/restore_all\"\r\n    filename_tensor_name = \"save/Const:0\"\r\n    output_graph_path = os.path.join(temp_dir, output_graph_name)\r\n    clear_devices = False\r\n\r\n    # Embed weights inside the graph and save to disk.\r\n    freeze_graph.freeze_graph(input_graph_path, input_saver_def_path, input_binary, checkpoint_path, output_node_names,\r\n                              restore_op_name, filename_tensor_name, output_graph_path, clear_devices, \"\")\r\n\r\n    # The output_graph is the resulting and functional graph with embedded weights.\r\n    if os.path.exists(\"graph/output_graph.pb\"):\r\n        print(\"Model successfully exported to .pb file\")\r\n```\r\nAfter that I used this command to strip unused nodes:\r\n\r\n> bazel run tensorflow/tools/graph_transforms:transform_graph --\r\n> --in_graph=input.pb\r\n> --out_graph=output.pb --inputs='input_1_2' --outputs='distribution_2/Softmax'\r\n> --transforms='\r\n>   strip_unused_nodes(type=float, shape=\"1,224,224,3\")\r\n>   fold_constants(ignore_errors=true)\r\n>   fold_batch_norms'\r\n\r\nAll these steps worked fine but when trying to export the file into .tflite the errors mentioned in my post above occure.", "I also discovered that when I run the \"old\" optimize_for_inference tool on the .pb file I get the following error when trying to load the created optimized graph:\r\n\r\n> NodeDef expected inputs '' do not match 1 inputs specified;\r\n> Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>; \r\n> NodeDef: import/bn_Conv1_2/cond/batchnorm/add/y = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0.001>](import/bn_Conv1_2/cond/Switch)", "Hi, \r\nWhen I run the command\r\n\r\ntflite_convert   --output_file=/tmp/foo.tflite \\  --keras_model_file=/tmp/keras_model.h5\r\n\r\nI got the following error\r\nFile \"/home/dell/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/keras/engine/sequential.py\", line 336, in from_config\r\nfor layer_config in layer_configs:\r\nUnboundLocalError: local variable 'layer_configs' referenced before assignment\r\n\r\n\r\nI have TF 1.9 as recommended.\r\n\r\nAny hint?", "@SteveIb Please file a separate bug to track your issue.\r\n\r\n@bennyooo The error message for the original issue (from \"resolve_tensorflow_switch.cc:95\") has been updated to give a little more context on the issue. Unfortunately, supporting arbitrary switch statements won't be supported in the near future. The best next step is to figure out how to prune that from the graph.\r\n\r\nAs for the error message in the optimize_for_inference tool. Can you give some clarity on what you mean by the old tool? Namely can you clarify the different paths you went when you got the error in resolve_tensorflow_switch.cc vs in the optimize_for_inference tool?", "I solved it by using by using model.save instead of model.save_weights. I found the same problem on Google. sorry if my question was basic thing in Keras, it seems that my .h5 file was not correct. Thanks.", "@bennyooo Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@SteveIb  i can got a tflite model by h5, but i can't kown how to get a quatilized tflite model", "> i thought I can convert the keras model file h5 -> pb -> tflite .. is that right way to go about ?\r\n\r\nI has been try that, but tflite predict incorrectly when run in android.", "@dlml and @kehuantiantang: Please file separate issues with enough detail to replicate your issue.", "> @dlml and @kehuantiantang: Please file separate issues with enough detail to replicate your issue.\r\n\r\n- First, I retrain a network with Keras, the code seems like below, which is a simple keras code and can save weight to .h file,  then using function save_graph_to_file() to get .pb file. \r\n```python\r\nfrom keras.models import Sequential, Model\r\nfrom keras.models import load_model\r\nimport tensorflow as tf\r\nfrom keras import backend as K\r\nfrom keras.layers import Conv2D, MaxPooling2D, Input\r\nfrom keras.layers import Activation, Dropout, Flatten, Dense\r\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\nimport os\r\nfrom keras import optimizers\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\r\n\r\ntrain_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\r\nval_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\r\nbatch_size = 16\r\nepochs = 200\r\n\r\ninput = Input(shape = (150, 150, 3), name = 'input')\r\nx = Conv2D(32, (3, 3), activation='relu')(input)\r\nx = MaxPooling2D(pool_size=(2, 2))(x)\r\nx = Conv2D(32, (3, 3), activation='relu')(x)\r\nx = Conv2D(32, (3, 3), activation='relu')(x)\r\nx = Conv2D(32, (3, 3), activation='relu')(x)\r\nx = MaxPooling2D(pool_size=(2, 2))(x)\r\nx = Conv2D(64, (3, 3), activation='relu')(x)\r\nx = Conv2D(64, (3, 3), activation='relu')(x)\r\nx = Conv2D(64, (3, 3), activation='relu')(x)\r\nx = Conv2D(64, (3, 3), activation='relu')(x)\r\nx = MaxPooling2D(pool_size=(2, 2))(x)\r\nx = Flatten()(x)\r\n# x = Dense(64, activation='relu')(x)\r\n# x = Dense(2, activation='sigmoid', name = 'output')(x)\r\nx = Dense(5, activation='softmax', name = 'output')(x)\r\nmodel = Model(inputs = input, outputs= x)\r\n\r\nsgd = optimizers.SGD(lr=0.000005, decay=1e-6, momentum=0.9, nesterov=True)\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer=sgd,\r\n              metrics=['accuracy'])\r\n\r\n\r\n\r\n# this is the augmentation configuration we will use for training\r\ntrain_datagen = ImageDataGenerator(\r\n        shear_range=0.2,\r\n        zoom_range=0.2,\r\n        horizontal_flip=True)\r\n\r\n# this is the augmentation configuration we will use for testing:\r\n# only rescaling\r\ntest_datagen = ImageDataGenerator()\r\n\r\n# this is a generator that will read pictures found in\r\n# subfolers of 'data/train', and indefinitely generate\r\n# batches of augmented image data\r\ntrain_generator = train_datagen.flow_from_directory(\r\n        train_path,  # this is the target directory\r\n        target_size=(150, 150),  # all images will be resized to 150x150\r\n        batch_size=batch_size,\r\n        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\r\n\r\n# this is a similar generator, for validation data\r\nvalidation_generator = test_datagen.flow_from_directory(\r\n        val_path,\r\n        target_size=(150, 150),\r\n        batch_size=batch_size,\r\n        class_mode='categorical')\r\n\r\nmodel.fit_generator(\r\n        train_generator,\r\n        steps_per_epoch=1340 // batch_size,\r\n        epochs=epochs,\r\n        validation_data=validation_generator,\r\n        shuffle=True,\r\n        validation_steps=64 // batch_size)\r\nmodel.save('./weight/flower5.h5')  # always save your weights after training or during training\r\n\r\n# convert\r\noutput_names = [node.op.name for node in model.outputs]\r\n\r\nexport_dir = './weight/'\r\nsess = K.get_session()\r\nsave_graph_to_file(sess,  export_dir + \"flower5.pb\", output_names)\r\n\r\ndef save_graph_to_file(sess,  graph_file_name, output_names):\r\n    output_graph_def = graph_util.convert_variables_to_constants(\r\n      sess,  sess.graph.as_graph_def(),  output_names)\r\n    with gfile.FastGFile(graph_file_name, 'wb') as f:\r\n        f.write(output_graph_def.SerializeToString())\r\n```\r\n\r\n- Then  covert .pb file to .tlite file like this:\r\n```bash\r\nIMAGE_SIZE=150\r\nFILE=flower5\r\ntoco \\\r\n  --graph_def_file=weight/${FILE}.pb \\\r\n  --output_file=weight/${FILE}.lite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \\\r\n  --input_array=input_1 \\\r\n  --output_array=output_1/Softmax \\\r\n  --inference_type=FLOAT \\\r\n  --input_data_type=FLOAT\r\n```\r\n\r\n- I order to make sure the convert is correct when use toco, I used tflite file to predict some image and get predict result like that, there are five classes and the label is \"daisy dandelion roses sunflowers tulips\", which get correct softmax result, this means if I use a sunflower image and the model can get highest softmax result in sunflower. \r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom PIL import Image\r\nimport os\r\n# filepath='./weight/flower_gpu.tflite'\r\nfilepath='./weight/flower5.lite'\r\nval_path = '/home/sober/ftp_bk/Dataset/Tmp_Train/flo/'\r\nshape=(150, 150)\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.contrib.lite.Interpreter(model_path=filepath)\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test model on random input data.\r\ninput_shape = input_details[0]['shape']\r\n# change the following line to feed into your own data.\r\n\r\nfor d in os.listdir(val_path):\r\n    dirpath = val_path+ d + '/'\r\n    for f in os.listdir(dirpath):\r\n        file = dirpath + f\r\n        print(file)\r\n        im = Image.open(file)\r\n        im = im.resize(shape, Image.ANTIALIAS)\r\n        im = np.asarray(im)\r\n        im = im[np.newaxis, :]\r\n        im = np.asarray(im)\r\n#         print(np.array2string(model.predict(np.asarray(im)), formatter={'float_kind':lambda x: \"%.2f\" % x}))\r\n        input_data = np.array(im, dtype=np.float32)\r\n        interpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\n        interpreter.invoke()\r\n        output_data = interpreter.get_tensor(output_details[0]['index'])\r\n#         output_data.sort()\r\n        print(np.array2string(output_data, formatter={'float_kind':lambda x: \"%.2f\" % x}))\r\n    \r\n\"daisy dandelion roses sunflowers tulips\"\r\n```\r\n\r\n- Finally, I put label and tflite file to android, and used android tensorflow demo,  I don't change the code and just replace the orgin graph.lite and label.txt file to my .lite .txt file, and test it. but the result shows in demo is just like \"0.2, 0.2, 0.2\" which change a little even though I took photos for sunflower. \r\n> https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2-tflite/#2\r\n\r\n- I don't know how to fix it, because the model predict in computer is right but the result in andorid is\r\nabnormal and not change when predict different object.  ", "i  can convert my h5 to tflite, but i want to use c++ to get output on windows, but i don't know how to do@kehuantiantang", "@kehuantiantang ", "> i can convert my h5 to tflite, but i want to use c++ to get output on windows, but i don't know how to do@kehuantiantang\r\n\r\nI don't understand what you mean of that, you want to make a web application or a program just use C++ that can run in windows ? please describe your question clearly.", "Just a program use C++ that can run in windwos", "@kehuantiantang ", "> Just a program use C++ that can run in windwos\r\n\r\nwhy not to use c++ to call python script\r\n> https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image", "> > @dlml and @kehuantiantang: Please file separate issues with enough detail to replicate your issue.\r\n> \r\n> * First, I retrain a network with Keras, the code seems like below, which is a simple keras code and can save weight to .h file,  then using function save_graph_to_file() to get .pb file.\r\n> \r\n> ```python\r\n> from keras.models import Sequential, Model\r\n> from keras.models import load_model\r\n> import tensorflow as tf\r\n> from keras import backend as K\r\n> from keras.layers import Conv2D, MaxPooling2D, Input\r\n> from keras.layers import Activation, Dropout, Flatten, Dense\r\n> from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n> import os\r\n> from keras import optimizers\r\n> os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\n> os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\r\n> \r\n> train_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\r\n> val_path='/home/sober/code/jupyter/ftp_code/AndroidTensorflow/tensorflow-for-poets-2/tf_files/flower_photos'\r\n> batch_size = 16\r\n> epochs = 200\r\n> \r\n> input = Input(shape = (150, 150, 3), name = 'input')\r\n> x = Conv2D(32, (3, 3), activation='relu')(input)\r\n> x = MaxPooling2D(pool_size=(2, 2))(x)\r\n> x = Conv2D(32, (3, 3), activation='relu')(x)\r\n> x = Conv2D(32, (3, 3), activation='relu')(x)\r\n> x = Conv2D(32, (3, 3), activation='relu')(x)\r\n> x = MaxPooling2D(pool_size=(2, 2))(x)\r\n> x = Conv2D(64, (3, 3), activation='relu')(x)\r\n> x = Conv2D(64, (3, 3), activation='relu')(x)\r\n> x = Conv2D(64, (3, 3), activation='relu')(x)\r\n> x = Conv2D(64, (3, 3), activation='relu')(x)\r\n> x = MaxPooling2D(pool_size=(2, 2))(x)\r\n> x = Flatten()(x)\r\n> # x = Dense(64, activation='relu')(x)\r\n> # x = Dense(2, activation='sigmoid', name = 'output')(x)\r\n> x = Dense(5, activation='softmax', name = 'output')(x)\r\n> model = Model(inputs = input, outputs= x)\r\n> \r\n> sgd = optimizers.SGD(lr=0.000005, decay=1e-6, momentum=0.9, nesterov=True)\r\n> model.compile(loss='categorical_crossentropy',\r\n>               optimizer=sgd,\r\n>               metrics=['accuracy'])\r\n> \r\n> \r\n> \r\n> # this is the augmentation configuration we will use for training\r\n> train_datagen = ImageDataGenerator(\r\n>         shear_range=0.2,\r\n>         zoom_range=0.2,\r\n>         horizontal_flip=True)\r\n> \r\n> # this is the augmentation configuration we will use for testing:\r\n> # only rescaling\r\n> test_datagen = ImageDataGenerator()\r\n> \r\n> # this is a generator that will read pictures found in\r\n> # subfolers of 'data/train', and indefinitely generate\r\n> # batches of augmented image data\r\n> train_generator = train_datagen.flow_from_directory(\r\n>         train_path,  # this is the target directory\r\n>         target_size=(150, 150),  # all images will be resized to 150x150\r\n>         batch_size=batch_size,\r\n>         class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\r\n> \r\n> # this is a similar generator, for validation data\r\n> validation_generator = test_datagen.flow_from_directory(\r\n>         val_path,\r\n>         target_size=(150, 150),\r\n>         batch_size=batch_size,\r\n>         class_mode='categorical')\r\n> \r\n> model.fit_generator(\r\n>         train_generator,\r\n>         steps_per_epoch=1340 // batch_size,\r\n>         epochs=epochs,\r\n>         validation_data=validation_generator,\r\n>         shuffle=True,\r\n>         validation_steps=64 // batch_size)\r\n> model.save('./weight/flower5.h5')  # always save your weights after training or during training\r\n> \r\n> # convert\r\n> output_names = [node.op.name for node in model.outputs]\r\n> \r\n> export_dir = './weight/'\r\n> sess = K.get_session()\r\n> save_graph_to_file(sess,  export_dir + \"flower5.pb\", output_names)\r\n> \r\n> def save_graph_to_file(sess,  graph_file_name, output_names):\r\n>     output_graph_def = graph_util.convert_variables_to_constants(\r\n>       sess,  sess.graph.as_graph_def(),  output_names)\r\n>     with gfile.FastGFile(graph_file_name, 'wb') as f:\r\n>         f.write(output_graph_def.SerializeToString())\r\n> ```\r\n> \r\n> * Then  covert .pb file to .tlite file like this:\r\n> \r\n> ```shell\r\n> IMAGE_SIZE=150\r\n> FILE=flower5\r\n> toco \\\r\n>   --graph_def_file=weight/${FILE}.pb \\\r\n>   --output_file=weight/${FILE}.lite \\\r\n>   --input_format=TENSORFLOW_GRAPHDEF \\\r\n>   --output_format=TFLITE \\\r\n>   --input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \\\r\n>   --input_array=input_1 \\\r\n>   --output_array=output_1/Softmax \\\r\n>   --inference_type=FLOAT \\\r\n>   --input_data_type=FLOAT\r\n> ```\r\n> \r\n> * I order to make sure the convert is correct when use toco, I used tflite file to predict some image and get predict result like that, there are five classes and the label is \"daisy dandelion roses sunflowers tulips\", which get correct softmax result, this means if I use a sunflower image and the model can get highest softmax result in sunflower.\r\n> \r\n> ```python\r\n> import numpy as np\r\n> import tensorflow as tf\r\n> from PIL import Image\r\n> import os\r\n> # filepath='./weight/flower_gpu.tflite'\r\n> filepath='./weight/flower5.lite'\r\n> val_path = '/home/sober/ftp_bk/Dataset/Tmp_Train/flo/'\r\n> shape=(150, 150)\r\n> # Load TFLite model and allocate tensors.\r\n> interpreter = tf.contrib.lite.Interpreter(model_path=filepath)\r\n> interpreter.allocate_tensors()\r\n> \r\n> # Get input and output tensors.\r\n> input_details = interpreter.get_input_details()\r\n> output_details = interpreter.get_output_details()\r\n> \r\n> # Test model on random input data.\r\n> input_shape = input_details[0]['shape']\r\n> # change the following line to feed into your own data.\r\n> \r\n> for d in os.listdir(val_path):\r\n>     dirpath = val_path+ d + '/'\r\n>     for f in os.listdir(dirpath):\r\n>         file = dirpath + f\r\n>         print(file)\r\n>         im = Image.open(file)\r\n>         im = im.resize(shape, Image.ANTIALIAS)\r\n>         im = np.asarray(im)\r\n>         im = im[np.newaxis, :]\r\n>         im = np.asarray(im)\r\n> #         print(np.array2string(model.predict(np.asarray(im)), formatter={'float_kind':lambda x: \"%.2f\" % x}))\r\n>         input_data = np.array(im, dtype=np.float32)\r\n>         interpreter.set_tensor(input_details[0]['index'], input_data)\r\n> \r\n>         interpreter.invoke()\r\n>         output_data = interpreter.get_tensor(output_details[0]['index'])\r\n> #         output_data.sort()\r\n>         print(np.array2string(output_data, formatter={'float_kind':lambda x: \"%.2f\" % x}))\r\n>     \r\n> \"daisy dandelion roses sunflowers tulips\"\r\n> ```\r\n> \r\n> * Finally, I put label and tflite file to android, and used android tensorflow demo,  I don't change the code and just replace the orgin graph.lite and label.txt file to my .lite .txt file, and test it. but the result shows in demo is just like \"0.2, 0.2, 0.2\" which change a little even though I took photos for sunflower.\r\n> \r\n> > https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2-tflite/#2\r\n> \r\n> * I don't know how to fix it, because the model predict in computer is right but the result in andorid is\r\n>   abnormal and not change when predict different object.\r\n\r\nthe problem fixed by the input image and android input image is different, where image in training has not subtract mean and divide by std.", "I want to apply my tflite model on embedded system or andorid system", "I haven't been able to successfully convert anything I train in keras to tflite.  Here's my set up:\r\nTensorflow version: 1.12.0\r\nPython: 3.5\r\nkeras: 2.2.4\r\n\r\nHere's the relevant parts of my python code:\r\n```\r\ndef freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\r\n   \r\n    graph = session.graph\r\n    with graph.as_default():\r\n        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\r\n        output_names = output_names or []\r\n        output_names += [v.op.name for v in tf.global_variables()]\r\n        input_graph_def = graph.as_graph_def()\r\n        if clear_devices:\r\n            for node in input_graph_def.node:\r\n                node.device = ''\r\n        frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n            session, input_graph_def, output_names, freeze_var_names)\r\n        return frozen_graph\r\n\r\n\r\n\r\ndef build_model():\r\n    model = Sequential()\r\n    model.add(keras.layers.InputLayer(input_shape=(128,9,1), name='input_tensor'))\r\n    model.add(keras.layers.Conv2D(128,(7,1),activation='relu'))\r\n    model.add(keras.layers.MaxPooling2D((7,1)))\r\n    model.add(keras.layers.Conv2D(128, (5, 1), activation='relu'))\r\n    model.add(keras.layers.MaxPooling2D((5, 1)))\r\n    model.add(keras.layers.Flatten())\r\n    model.add(keras.layers.Dropout(0.5))\r\n    model.add(keras.layers.Dense(512, activation='relu'))\r\n    model.add(keras.layers.Dense(6, activation='sigmoid'))\r\n\r\n    model.compile(loss=keras.losses.categorical_crossentropy,\r\n                  optimizer=keras.optimizers.SGD(lr=1e-2, decay=1e-6),\r\n                  metrics=['accuracy'])\r\n\r\n    return model\r\n\r\n\r\nmodel = build_model()\r\n\r\n# load data - removed to improve clarity\r\n\r\nmodel.fit(x_train, y_train, epochs=5, shuffle=True, validation_split=0.1)\r\nmodel.save('/home/bryan/fall/trainedModels/test.h5', overwrite=True)\r\nfrozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\r\n\r\ntf.train.write_graph(frozen_graph, '/home/bryan/fall/trainedModels/', 'test.pbtxt', as_text=True)\r\ntf.train.write_graph(frozen_graph, '/home/bryan/fall/trainedModels/', 'test.pb', as_text=False)\r\n```\r\n\r\n\r\n\r\nThis model builds and trains just fine.  \r\n\r\nI then build toco from the latest git source, and run:\r\n\r\n```\r\nbazel-bin/tensorflow/lite/toco/toco \r\n--input_file=/home/bryan/fall/trainedModels/test.pb \r\n--input_format=TENSORFLOW_GRAPHDEF \r\n--output_format=TFLITE \r\n--output_file=test.lite \r\n--inference_type=FLOAT \r\n--input_arrays=input_tensor \r\n--output_arrays=dense_2/Sigmoid \r\n--input_shapes=1,128,9,1\r\n```\r\n\r\n\r\nThis results in the follow error:\r\n\r\n2018-12-09 14:01:02.552275: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 46 operators, 68 arrays (0 quantized)\r\n2018-12-09 14:01:02.552913: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 44 operators, 65 arrays (0 quantized)\r\n2018-12-09 14:01:02.553763: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 44 operators, 65 arrays (0 quantized)\r\n2018-12-09 14:01:02.555039: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found Mul as non-selected output from Switch, but only Merge supported.\r\nAborted (core dumped)\r\n\r\n\r\nany suggestions would be appreciated. ", "> I haven't been able to successfully convert anything I train in keras to tflite. Here's my set up:\r\n> Tensorflow version: 1.12.0\r\n> Python: 3.5\r\n> keras: 2.2.4\r\n> \r\n> Here's the relevant parts of my python code:\r\n> \r\n> ```\r\n> def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\r\n>    \r\n>     graph = session.graph\r\n>     with graph.as_default():\r\n>         freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\r\n>         output_names = output_names or []\r\n>         output_names += [v.op.name for v in tf.global_variables()]\r\n>         input_graph_def = graph.as_graph_def()\r\n>         if clear_devices:\r\n>             for node in input_graph_def.node:\r\n>                 node.device = ''\r\n>         frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n>             session, input_graph_def, output_names, freeze_var_names)\r\n>         return frozen_graph\r\n> \r\n> \r\n> \r\n> def build_model():\r\n>     model = Sequential()\r\n>     model.add(keras.layers.InputLayer(input_shape=(128,9,1), name='input_tensor'))\r\n>     model.add(keras.layers.Conv2D(128,(7,1),activation='relu'))\r\n>     model.add(keras.layers.MaxPooling2D((7,1)))\r\n>     model.add(keras.layers.Conv2D(128, (5, 1), activation='relu'))\r\n>     model.add(keras.layers.MaxPooling2D((5, 1)))\r\n>     #model.add(keras.layers.Reshape((2304,)))\r\n>     model.add(keras.layers.Flatten())\r\n>     model.add(keras.layers.Dropout(0.5))\r\n>     model.add(keras.layers.Dense(512, activation='relu'))\r\n>     model.add(keras.layers.Dense(6, activation='sigmoid'))\r\n> \r\n>     model.compile(loss=keras.losses.categorical_crossentropy,\r\n>                   optimizer=keras.optimizers.SGD(lr=1e-2, decay=1e-6),\r\n>                   metrics=['accuracy'])\r\n> \r\n>     return model\r\n> \r\n> \r\n> model = build_model()\r\n> \r\n> # load data - removed to improve clarity\r\n> \r\n> model.fit(x_train, y_train, epochs=5, shuffle=True, validation_split=0.1)\r\n> model.save('/home/bryan/fall/trainedModels/test.h5', overwrite=True)\r\n> frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\r\n> \r\n> tf.train.write_graph(frozen_graph, '/home/bryan/fall/trainedModels/', 'test.pbtxt', as_text=True)\r\n> tf.train.write_graph(frozen_graph, '/home/bryan/fall/trainedModels/', 'test.pb', as_text=False)\r\n> ```\r\n> This model builds and trains just fine.\r\n> \r\n> I then build toco from the latest git source, and run:\r\n> \r\n> ```\r\n> bazel-bin/tensorflow/lite/toco/toco \r\n> --input_file=/home/bryan/fall/trainedModels/test.pb \r\n> --input_format=TENSORFLOW_GRAPHDEF \r\n> --output_format=TFLITE \r\n> --output_file=test.lite \r\n> --inference_type=FLOAT \r\n> --input_arrays=input_tensor \r\n> --output_arrays=dense_2/Sigmoid \r\n> --input_shapes=1,128,9,1\r\n> ```\r\n> This results in the follow error:\r\n> \r\n> 2018-12-09 14:01:02.552275: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 46 operators, 68 arrays (0 quantized)\r\n> 2018-12-09 14:01:02.552913: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 44 operators, 65 arrays (0 quantized)\r\n> 2018-12-09 14:01:02.553763: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 44 operators, 65 arrays (0 quantized)\r\n> 2018-12-09 14:01:02.555039: F tensorflow/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:98] Check failed: other_op->type == OperatorType::kMerge Found Mul as non-selected output from Switch, but only Merge supported.\r\n> Aborted (core dumped)\r\n> \r\n> any suggestions would be appreciated.\r\n\r\nI failed to convert model from .pb to .lite in toco, I think you can try to convert .h5 to .pb followed by [this file](https://github.com/kehuantiantang/AndroidTensorflow/blob/master/keras_to_tensorflow.py), then use toco to convert .pb to .lite. Any detail you can followed by [it](https://github.com/kehuantiantang/AndroidTensorflow/blob/master/Keras%20To%20TensorFlow%20Lite.ipynb), I succeed to convert .h5 --> .pb --> .lite", "@rbgreenway @kehuantiantang Please file new issues with your failure.", "@rbgreenway did you solve the problem ? "]}, {"number": 20877, "title": "correct url", "body": "correct broken url for 1) Eager Execution", "comments": []}, {"number": 20876, "title": "Small typo fix", "body": "", "comments": ["@elielhojman do you mind fixing the pylint error in sanity build? Thank you!"]}, {"number": 20875, "title": "make TFLite kernel tests work again", "body": "The `pow_test.cc` introduced in (51c80b60) doesn't build with\r\n```\r\nbazel test --config opt //tensorflow/contrib/lite/kernels:all\r\n```\r\n\r\ns/int32/int32_t/ to make it build and run", "comments": []}]